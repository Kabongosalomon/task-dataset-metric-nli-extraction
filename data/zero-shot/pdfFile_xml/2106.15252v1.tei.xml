<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 AutoNovel: Automatically Discovering and Learning Novel Visual Categories</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvestre-Alvise</forename><surname>Rebuffi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Ehrhardt</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
						</author>
						<title level="a" type="main">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 AutoNovel: Automatically Discovering and Learning Novel Visual Categories</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-novel category discovery</term>
					<term>deep transfer clustering</term>
					<term>clustering</term>
					<term>classification</term>
					<term>incremental learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We tackle the problem of discovering novel classes in an image collection given labelled examples of other classes. We present a new approach called AutoNovel to address this problem by combining three ideas: (1) we suggest that the common approach of bootstrapping an image representation using the labelled data only introduces an unwanted bias, and that this can be avoided by using self-supervised learning to train the representation from scratch on the union of labelled and unlabelled data; (2) we use ranking statistics to transfer the model's knowledge of the labelled classes to the problem of clustering the unlabelled images; and, (3) we train the data representation by optimizing a joint objective function on the labelled and unlabelled subsets of the data, improving both the supervised classification of the labelled data, and the clustering of the unlabelled data. Moreover, we propose a method to estimate the number of classes for the case where the number of new categories is not known a priori. We evaluate AutoNovel on standard classification benchmarks and substantially outperform current methods for novel category discovery. In addition, we also show that AutoNovel can be used for fully unsupervised image clustering, achieving promising results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>M ODERN machine learning systems can match or surpass human-level performance in tasks such as image classification <ref type="bibr" target="#b0">[1]</ref>, but at the cost of collecting large quantities of annotated training data. Semi-supervised learning (SSL) <ref type="bibr" target="#b1">[2]</ref> can alleviate this issue by mixing labelled with unlabelled data, which is usually much cheaper to obtain. However, these methods still require some annotations for each of the classes that one wishes to learn. We argue that this is not always possible in real applications. For instance, consider the task of recognizing products in supermarkets; thousands of new products are introduced in stores every week, and it would be very expensive to annotate them all. However, new products do not differ drastically from the existing ones, so prior knowledge of older products should help to discover new products automatically as they arise in the data. Unfortunately, machines are still unable to effectively detect and learn new classes without manual annotations.</p><p>In this paper, we thus consider the problem of discovering new visual classes automatically, assuming that a certain number of classes are already known by the model <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> (see <ref type="figure">fig. 1</ref>). This knowledge comes in the form of a labelled dataset of images for a certain set of classes. Given that this data is labelled, off-the-shelf supervised learning techniques can be used to train a very effective classifier for the known classes, particularly if Convolutional Neural Networks (CNNs) are employed. However, this does not mean that the learned features are useful as a representation of the new classes. Furthermore, even if the representation transfers well, one still has the problem of identifying the ? ? <ref type="figure">Fig. 1</ref>: Novel category discovery. Given labelled images from a few known categories (e.g., dog and cat), our objective is to automatically partition unlabelled images from new categories (e.g., monkey and bird) into proper clusters.</p><p>new classes in an unlabelled dataset, which is a clustering problem. We tackle these problems by introducing a novel approach called AutoNovel that combines three key ideas (section 3 and <ref type="figure">fig. 2</ref>). The first idea is to pre-train the image representation (a CNN) using all available images, both labelled and unlabelled, using a self-supervised learning objective. Crucially, this objective does not leverage the known labels, resulting in features that are much less biased towards the labelled classes. Labels are used only after pre-training to learn a classifier specific to the labelled data as well as to fine-tune the last layers of the CNN.</p><p>The second idea is a new approach to transfer the information contained in the labelled images to the problem of clustering the unlabelled ones. Information is transferred by sharing the same representation between labelled and unlabelled images, in order to be able to reuse discriminative features learned on the labelled set. In more detail, pairs of arXiv:2106.15252v1 [cs.CV] 29 Jun 2021 unlabelled images are compared via their representation vectors. The comparison is done using robust ranking statistics, by testing if two images share the same subset of k maximally activated representation components. This test is used to decide if two unlabelled images belong to the same (new) class or not, generating a set of noisy pairwise pseudo-labels. The pseudo-labels are then used to learn a similarity function for the unlabelled images.</p><p>The third idea is, after bootstrapping the representation, to optimise the model by minimizing a joint objective function, containing terms for both the labelled and unlabelled subsets. To do this, we use respectively the given labels and the generated pseudo-labels, thus avoiding the forgetting issue <ref type="bibr" target="#b5">[6]</ref> that may arise with a sequential approach. A further boost is obtained by incorporating incremental learning of the discovered classes in the classification task, which allows information to flow between the labelled and unlabelled images.</p><p>However, this approach still requires knowing the number of new categories in the unlabelled data, which is not a realistic assumption in many applications. We propose a method to estimate the number of classes in the unlabelled data which also transfers knowledge from the set of known classes. The idea is to use part of the known classes as a probe set, adding them to the unlabelled set pretending that part of them are unlabelled, and then running the clustering algorithm described above on the extended unlabelled dataset. This allows us to cross-validate the number of new classes, according to the clustering accuracy on the probe set as well as a cluster quality index on the unlabelled set, resulting in a reliable estimate of the true number of unlabelled classes.</p><p>In addition, AutoNovel can be used for unsupervised image clustering by simply removing the requirement of labelled data, resulting in a simplified version of our method, achieving the state-of-the-art results on image clustering.</p><p>We evaluate AutoNovel on several public benchmarks, outperforming by a large margin all existing techniques that can be applied to novel category discovery, demonstrating the effectiveness of our approach. We also evaluate our category number estimation method, showing reliable estimation of the number of categories in the unlabelled data. We also demonstrate the effectiveness of our method by using it for unsupervised image clustering, achieving state-of-the-art clustering results.</p><p>We have presented preliminary results of this work in <ref type="bibr" target="#b6">[7]</ref>, and this paper extends them in several aspects. First, we include a solution to handle the case of an unknown number of categories in unlabelled data, which we initially introduced in <ref type="bibr" target="#b4">[5]</ref>. Second, we study different alternatives to ranking statistics for generating pairwise pseudo labels and compare their effectiveness. Third, we expand the experiments and study transferring representations from ImageNet-pretrained models to new domains. Fourth, we test the effectiveness of different self-supervised learning methods when used as a component of our method. Fifth, we show that our method can also be used for unsupervised clustering, achieving the state-of-the-art results on public benchmarks.</p><p>The code reproducing our experiments can be found at http://www.robots.ox.ac.uk/ ? vgg/research/auto novel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our work draws inspiration from semi-supervised learning, transfer learning, clustering, and zero-shot learning. We review below the most relevant contributions.</p><p>In semi-supervised learning (SSL) <ref type="bibr" target="#b7">[8]</ref>, a partially labelled training dataset is given and the objective is to learn a model that can propagate the labels from the labelled data to unlabelled data. Most SSL methods focus on the classification task where, usually, both labelled and unlabelled points belong to the same set of classes. On the contrary, our goal is to handle the case where the unlabelled data classes differ from the labelled data. <ref type="bibr" target="#b1">[2]</ref> summarizes the state-of-the-art SSL methods. Among them, the consistency-based methods appear to be the most effective. <ref type="bibr" target="#b8">[9]</ref> proposes a ladder network which is trained on both labelled and unlabelled data using a reconstruction loss. <ref type="bibr" target="#b9">[10]</ref> simplifies this ladder network by enforcing prediction consistency between a data point and its augmented counterpart. As an alternative to data augmentation, they also consider a regularization method based on the exponential moving average (EMA) of the predictions. This idea is further improved by <ref type="bibr" target="#b10">[11]</ref>: instead of using the EMA of predictions, they propose to maintain the EMA of model parameters. The consistency is then measured between the predictions of the current model (student) and the predictions of the EMA model (teacher). More recently (and closer to our work) practitioners have also combined SSL with self-supervision <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> to leverage datasets with very few annotations. Finally, FixMatch <ref type="bibr" target="#b13">[14]</ref> also uses pseudolabels extracted from the most confident images reaching state-of-the-art results in SSL benchmarks. However, they use pseudo-labels as soft targets for the cross-entropy loss, while we use a binary score to evaluate similarity of sample pairs within a mini-batch.</p><p>Transfer learning <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> is an effective way to reduce the amount of data annotations required by pre-training the model on a different dataset. In image classification, for example, it is customary to start from a model pre-trained on the ImageNet <ref type="bibr" target="#b0">[1]</ref> dataset. In most transfer learning settings, however, both the source data and the target data are fully annotated. In contrast, our goal is to transfer information from a labelled dataset to an unlabelled one.</p><p>Many classic (e.g., <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>) and deep learning (e.g., <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>) clustering methods have been proposed to automatically partition an unlabelled data collection into different classes. However, this task is usually ill-posed as there are multiple, equally valid criteria to partition most datasets. We address this challenge by learning the appropriate criterion by using a labelled dataset, narrowing down what constitutes a proper class. We call this setting "transfer clustering".</p><p>To the best of our knowledge, the work most related to ours are <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. In <ref type="bibr" target="#b4">[5]</ref>, the authors also consider discovering new classes as a transfer clustering problem. They first learn a data embedding by using metric learning on the labelled data, and then fine-tune the embedding and learn the cluster assignments on the unlabelled data. In <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, the authors introduce KCL and MCL clustering methods. In both, a similarity prediction network (SPN), also used in <ref type="bibr" target="#b26">[27]</ref>, is first trained on a labelled dataset. Afterwards, the pre-trained SPN is used to provide binary pseudo labels Overview of the AutoNovel learning pipeline for novel category discovery. The first step is to learn an unbiased image representation via self-supervision using both labelled and unlabelled data. This learns well the early layers of the representation. The second step is to fine-tune only the last few layers of the representation using supervision on the labelled subset of the data. The final step is to use the fine-tuned representation, via ranking statistics, to induce clusters in the unlabelled data, while maintaining a good representation on the labelled set.</p><p>for training the main model on an unlabelled dataset. The overall pipelines of the two methods are similar, but the losses differ: KCL uses a contrastive loss based on Kullback-Leibler divergence, which is equivalent to the BCE used in this paper (eq. (3)), and MCL uses the Meta Classification Likelihood loss. Zero-shot learning (ZSL) <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref> can also be used to recognize new classes. However, differently from our work, ZSL also requires additional side information (e.g., class attributes) in addition to the raw images.</p><p>Finally, other works <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> discuss the application of ranking statistics to measuring the similarity of vectors; however, to the best of our knowledge, we are the first to apply ranking statistics to the task of novel category discovery using deep neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>Given an unlabelled dataset D u = {x u i ; i = 1, . . . , M } of images x u i ? R 3?H?W , our goal is to automatically cluster them into a number of classes C u . We also assume to have a second labelled image dataset D l = {(x l i , y l i ); i = 1, . . . , N } where y l i ? {1, . . . , C l } is the class label for image x l i , where the set of C l labelled classes is disjoint from the set of C u unlabelled ones. While the statistics of D l and D u differ, we hypothesize that a general notion of what constitutes a "good class" can be extracted from D l and that the latter can be used to better cluster D u .</p><p>We approach the problem by learning an image representation ? : x ? ?(x) ? R d in the form of a CNN. The goal of the representation is to recognize the known classes and to discover the new ones. In order to learn this representation, we propose AutoNovel, a method that combines three ideas detailed in the next three sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Self-supervised learning</head><p>Given that we have a certain number of labelled images D l at our disposal, the obvious idea is to use these labels to bootstrap the representation ? by minimizing a standard supervised objective such as the cross-entropy loss. However, experiments show that this causes the representation to overly-specialize for the classes in D l , providing a poor representation of the new classes in D u .</p><p>Thus we resist the temptation of using the labels right away and instead use a self-supervised learning method to bootstrap the representation ?. Self-supervised learning has been shown <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref> to produce robust low-level features, especially for the first few layers of typical CNNs. It has the benefit that no data annotations are needed, and thus it can be applied to both labelled and unlabelled images during training. In this way, we achieve the key benefit of ensuring that the representation is initialized without being biased towards the labelled data.</p><p>In detail, we first pre-train our model ? with selfsupervision on the union of D l and D u (ignoring all labels). We use the RotNet [33] approach 1 as our default choice due to its simplicity and efficacy, but any self-supervised method could be used instead. In our experiments, we also experimented with other self-supervised learning methods such as SimCLR <ref type="bibr" target="#b33">[34]</ref> and MoCo <ref type="bibr" target="#b34">[35]</ref>. Interestingly, we found these alternatives perform less effectively than RotNet in our setting, though they have shown better performance for fully supervised downstream tasks such as recognition and detection. We then extend the pre-trained network ? with a classification head ? l :</p><formula xml:id="formula_0">R d ? R C l</formula><p>implemented as a single linear layer followed by a softmax layer. The function ? l ? ? is fine-tuned on the labelled dataset D l in order to learn a classifier for the C l known classes, this time using the labels y i and optimizing the standard cross-entropy (CE) loss:</p><formula xml:id="formula_1">L CE = ? 1 N N i=1 log[? l ? z l i ] yi<label>(1)</label></formula><p>where</p><formula xml:id="formula_2">z l i = ?(x l i ) ? R d is the representation of image x l i .</formula><p>Only ? l and the last macro-block of ? (see section 5 for details) are updated in order to avoid overfitting the representation to the labelled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Transfer learning via ranking statistics</head><p>Once the representation ? and the classifier ? l have been trained, we are ready to look for the new classes in D u . Since the classes in D u are unknown, we represent them by defining a relation among pairs of unlabelled images (x u i , x u j ). The idea is that similar images should belong to the same 1. We present to the network ? randomly-rotated versions R(x) of each image and task it with predicting R. The problem is formulated as a 4-way classification of the rotation angle, with angle in</p><formula xml:id="formula_3">{0 ? , 90 ? , 180 ? , 270 ? }. The model ? ? ?(R(x))</formula><p>is terminated by a single linear layer ? with 4 outputs each scoring an hypothesis. The parameters of ? and ? are optimized by minimizing the cross-entropy loss on the rotation prediction. top k ( ? ( x i)) s ij <ref type="figure">Fig. 3</ref>: Ranking statistics. In this example, we consider top-3 ranks. As the top-3 ranks of z i and z j are the same, s ij = 1. While the top-3 ranks of z j and z k are the different, so s jk = 0.</p><p>(new) class, which we denote by the symbol s ij = 1, while dissimilar ones should not, which we denote by s ij = 0. A similar idea has been applied in the literature (e.g., <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>). The problem is then to obtain the labels s ij .</p><p>Our assumption is that the new classes will have some degree of visual similarity with the known ones. Hence, the learned representation should be applicable to old and new classes equally well. As a consequence, we expect the descriptors z u i = ?(x u i ) and z u j = ?(x u j ) of two images x u i , x u j from the new classes to be close if they are from the same (new) class, and to be distinct otherwise. The way this is done is explained in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Ranking statistics</head><p>Rather than comparing vectors z u i and z u j directly (e.g., by a scalar product), we use a more robust ranking statistics. Specifically, we rank the values in vector z u i by magnitude. Then, if the rankings obtained for two unlabelled images x u i and x u j are the same, they are very likely to belong to the same (new) class, so we set s ij = 1. Otherwise, we set s ij = 0. In practice, it is too strict to require the two rankings to be identical if the dimension of z u i is high (otherwise we may end up with s ij = 0 for all pairs (i, j), i = j). Therefore, we relax this requirement by only testing if the sets of the top-k ranked dimensions are the same (we use k = 5 in our experiments), i.e.:</p><formula xml:id="formula_4">s ij = 1 top k (?(x u i )) = top k (?(x u j )) ,<label>(2)</label></formula><p>where top k : R d ? P({1, . . . , d}) associates to a vector z the subset of indices {1, . . . , d} of its top-k elements. <ref type="figure">Figure 3</ref> shows an example of using ranking statistics to obtain pairwise pseudo labels.</p><p>Once the values s ij have been obtained, we use them as pseudo-labels to train a comparison function for the unlabelled data. In order to do this, we apply a new head</p><formula xml:id="formula_5">? u : R d ? R C u to the image representation z u i = ?(x u i )</formula><p>to extract a new descriptor vector ? u (z u i ) optimized for the unlabelled data. As in section 3.1, the head is composed of a linear layer followed by a softmax. Then, the inner product</p><formula xml:id="formula_6">? u (z u i ) ? u (z u j )</formula><p>is used as a score for whether images x u i and x u j belong to the same class or not. Note that ? u (z u i ) is a normalized vector due to the softmax layer in ? u . This descriptor is trained by optimizing the binary cross-entropy (BCE) loss:</p><formula xml:id="formula_7">L BCE = ? 1 M 2 M i=1 M j=1 [s ij log ? u (z u i ) ? u (z u j ) + (1 ? s ij ) log(1 ? ? u (z u i ) ? u (z u j ))].<label>(3)</label></formula><p>Furthermore, we structure ? u in a particular manner: We set its output dimension to be equal to the number of new classes C u , which is a common practice for clustering in the literature (e.g., <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>). In this manner, we can use the index of the maximum element of each vector y u i = argmax y [? u ? ?(x u i )] y as prediction? u i for the class of image x u i (as opposed to assigning labels via a clustering method such as k-means). Alternatives to ranking statistics. While we adopt ranking statistics to obtain the pairwise pseudo labels for unlabelled data, there exist many other options such as k-means, cosine similarity, and nearest neighbor. In the experiment, we evaluate applying k-means on the unlabelled data in each mini-batch and use the resulting cluster assignments to generate pairwise pseudo labels. We can also compute cosine similarity between vectors and generate binary pseudo-labels based on a predefined threshold ? . Another natural way to generate binary pseudo-labels is using the mutual nearest neighbor criteria, for which we follow <ref type="bibr" target="#b37">[38]</ref> and define</p><formula xml:id="formula_8">s ij = 1 if j = ? 1 i or ? 1 j = i or ? 1 i = ? 1 j 0 otherwise ,<label>(4)</label></formula><p>where ? 1 i denotes the nearest neighbor of image i in the minibatch. As will be shown in the experiments, these alternatives are less effective than using ranking statistics.</p><p>Discussion. There are several reasons why we believe the ranking statistics do well. First, the statistics focus on the topk most active feature components for each image. Intuitively, the magnitude of these components reflects the degree to which they are discriminative for the object in the image. Thus, our ranking statistics only considers the most salient feature components when comparing images, while ignoring noisy components with small values.</p><p>Second, other similarity measures like cosine similarity, which use the whole feature vectors for comparison in a high-dimensional vector space, can potentially suffer from the problem of distance concentration <ref type="bibr" target="#b38">[39]</ref>. The distance concentration is the counter-intuitive phenomenon that, as the data dimensionality increases, all pairwise distances between points may converge to the same value, which is not desired in our case.</p><p>Third, we further relax the comparison by not requiring the order of the top-k ranks to be identical. Instead, we only check the sets of the top-k ranks. This further makes the pairwise comparisons robust to slight discrepancies among the most discriminative feature components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Joint training on labelled and unlabelled data</head><p>We now have two losses that involve the representation ?: the CE loss L CE for the labelled data D l and the pairwise BCE loss L BCE for the unlabelled data D u . They both share the same image embedding ?. This embedding can be trained sequentially, first on the labelled data, and then on the unlabelled data using the pseudo-labels obtained above. However, in this way the model will very likely forget the knowledge learned from the labelled data, which is known as catastrophic forgetting in incremental learning <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>.</p><p>Instead, we jointly fine-tune our model using both losses at the same time. Note that most of the model ? is frozen; we only fine-tune the last macro-block of ? together with the two heads ? u and ? l . <ref type="figure" target="#fig_2">Figure 4</ref> demonstrates the overall architecture for joint learning. Importantly, as we fine-tune the model, the labels s ij are changing at every epoch as the embedding ? l is updated. This in turn affects the ranking statistics used to determine the labels s ij as explained in section 3.2. This leads to a "moving target" phenomenon that can introduce some instability in learning the model. This potential issue is addressed in the next section.</p><formula xml:id="formula_9">? ?(x i ) L CE L BCE z i ? u : ? d ? ? C u ? l : ? d ? ? C l Labelled Unlabelled x l i ? D l x u i ? D u</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Enforcing predictions to be consistent</head><p>In addition to the CE and BCE losses, we also introduce a consistency regularization term, which is used for both labelled and unlabelled data. In semi-supervised learning <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, the idea of consistency is that the class predictions on an image x and on a randomly-transformed counterpart t(x) (for example an image rotation) should be the same. In our case, as will be shown in the experiments, consistency is important to obtain good performance. One reason is that, as noted above, the pairwise pseudo-labels for the unlabelled data are subject to change on the fly during training. Indeed, for an image x u i and a randomly-transformed counterpart t(x u i ), if we do not enforce consistency, we can have top k (?(x u i )) = top k (?(t(x u i ))). According to eq. (2) defining s ij , this could result in different s ij for (x u i , x u j ) depending on the data augmentation applied to the images. This variability of the ranking labels for a given pair could then confuse the training of the embedding.</p><p>Following the common practice in semi-supervised learning, we use the Mean Squared Error (MSE) as the consistency cost. This is given by:</p><formula xml:id="formula_10">L MSE = 1 N N i=1 (? l (z l i ) ? ? l (? l i )) 2 + 1 M M i=1 (? u (z u i ) ? ? u (? u i )) 2 ,<label>(5)</label></formula><p>where? is the representation of t(x).</p><p>The overall loss of our model can then be written as</p><formula xml:id="formula_11">L = L CE + L BCE + ?(r)L MSE ,<label>(6)</label></formula><p>where the coefficient ?(r) is a ramp-up function. This is widely used in semi-supervised learning <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>. Following <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, we use the sigmoid-shaped function</p><formula xml:id="formula_12">?(r) = ?e ?5(1? r T ) 2</formula><p>, where r is current time step and T is the ramp-up length and ? ? R + . As opposed to contrastive learning <ref type="bibr" target="#b33">[34]</ref> this loss is only minimising the distance between positive pairs of samples within a minibatch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Incremental learning scheme</head><p>We also explore a setting analogous to incremental learning. In this approach, after tuning on the labelled set (end of section 3.1), we extend the head ? l to C u new classes, so that ? l :</p><formula xml:id="formula_13">R d ? R C l +C u</formula><p>. The head parameters for the new classes are initialized randomly. The model is then trained using the same loss eq. (6), but the cross-entropy part of the loss is evaluated on both labelled and unlabelled data D l and D u . Since the cross-entropy requires labels, for the unlabelled data we use the pseudo-labels? u i , which are generated on-thefly from the head ? u at each forward pass.</p><p>The advantage is that this approach increments ? l to discriminate both old and new classes, which is often desirable in real applications. It also creates a feedback loop that causes the features z u i to be refined, which in turn generates better pseudo-labels? u i for D u from the head ? u . In this manner, further improvements can be obtained by this cycle of positive interactions between the two heads during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Unsupervised clustering</head><p>Rather than working on the task of novel category discovery, AutoNovel can also be used for standard (unsupervised) clustering by simply removing the use of labelled data (thus dropping step two of the method), obtaining a two-step approach. In the first step, we pre-train our model with selfsupervised learning as before. In the second step, we finetune the last macro block and the linear layer for clustering, using the ranking statistics to provide pseudo pairwise labels. This way, our method can simultaneously learn the feature embedding for clustering as well as the cluster assignments. The training loss in eq. (6) becomes:</p><formula xml:id="formula_14">L = L BCE + ?(r)L MSE .<label>(7)</label></formula><p>To our knowledge, Deep Adaptive Clustering (DAC) <ref type="bibr" target="#b35">[36]</ref> is the deep clustering method most related to this approach, in the sense that DAC also reduces clustering as a binary classification problem. However, our approach differs from DAC in several aspects. First, our method uses ranking statistics to generate pairwise pseudo labels instead of the cosine similarity (though any pairwise labeling method could also be used in our approach). Second, our method optimizes the standard binary cross-entropy loss with a consistency constraint, while DAC optimizes a Bhattacharyya distance with an ad-hoc sample number penalty term. Third, our method incorporates self-supervised learning for pretraining lower level features and only needs to train the last macroblock and the linear layers of the model, which is less likely to suffer from overfitting. By comparison, DAC updates all parameters of the model. As will be seen in the experiment, our method significantly outperforms DAC as well as the recent state-of-the-art method IIC <ref type="bibr" target="#b43">[44]</ref> in several benchmarks. Note that the main objective of this work is novel category discovery rather than clustering, and here we only show that our method can be easily adopted for the problem of clustering achieving superior performance than exiting alternatives.</p><p>Method summary 1 Estimating the number of classes 1: Preparation: 2: Split the probe set D l r into D l ra and D l rv . 3: Extract features of D l r and D u using ?. 4: Main loop: <ref type="bibr">5:</ref> for 0 ? C u i ? C u max do <ref type="bibr">6:</ref> Run k-means on D l r ? D u assuming C lu r = C l r + C u i classes in semi-supervised mode (i.e. forcing data in D l ra to map to the ground-truth class labels).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>Compute ACC for D l rv and CVI for D u . 8: end for 9: Obtain optimal: <ref type="bibr">10:</ref> Let C u * a be the value of C u i that maximise ACC for D l rv and C u * v be the value that maximise CVI for D u and let</p><formula xml:id="formula_15">C u = (C u * a + C u * v )/2. Run semi-supervised k-means on D l</formula><p>r ? D u again assuming C l r +? u classes. 11: Remove outliers: <ref type="bibr">12:</ref> Look at the resulting clusters in D u and drop any that has a mass less than ? of the largest cluster. Output the number of remaining clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ESTIMATING THE NUMBER OF CLASSES</head><p>So far, we have assumed that the number of classes C u in the unlabelled data is known, but this is usually not the case in real applications. Here we propose a new approach to estimate the number of classes in the unlabelled data by making use of labelled probe classes. The probe classes are combined with the unlabelled data and the resulting set is clustered using k-means multiple times, varying the number of classes. The resulting clusters are then examined by computing two quality indices, one of which checks how well the probe classes, for which ground truth data is available, have been identified. The number of categories is then estimated to be the one that maximizes these quality indices.</p><p>In more details, we first split the C l known classes into a probe subset D l r of C l r classes and a training subset D l \ D l r containing the remaining C l ? C l r classes. These C l ? C l r classes are used for supervised feature representation learning, while the C l r probe classes are combined with the unlabelled data for class number estimation. We then further split the C l r probe classes into a subset D l ra of C l ra classes and a subset D l rv of C l rv classes (e.g., C l ra : C l rv = 4 : 1), which we call anchor probe set and validation probe set respectively (see <ref type="figure" target="#fig_3">fig. 5</ref>). We then run a constrained (semisupervised) k-means on D l r ? D u to estimate the number of classes in D u . Namely, during k-means, we force images in the anchor probe set D l ra to map to clusters following their ground-truth labels, while images in the validation probe set D l rv are considered as additional "unlabelled" data. We launch this constrained k-means multiple times by sweeping the number of total categories C lu r in D l r ? D u , and measure the constrained clustering quality on D l r ? D u . We consider two quality indices, given below, for each value of C lu r . The first measures the cluster quality in the labelled validation probe set D l rv , whereas the second measures the quality in the unlabelled data D u . Each index is used to determine an optimal number of classes and the results are averaged. Finally, k-means is run one last time with this value as the number of classes and any outlier clusters in D u , defined as containing less than ? (e.g., ? = 1%) the mass of the largest clusters, are dropped. The details are given in method summary 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cluster quality indices.</head><p>We measure our clustering for class number estimation with two indices. The first index is the average clustering accuracy (ACC), which is applicable to the C l rv labelled classes in the validation probe set D l rv and is given by</p><formula xml:id="formula_16">max g?Sym(C l rv ) 1 N N i=1 1 {? i = g (y i )} ,<label>(8)</label></formula><p>where y i and y i denote the ground-truth label and clustering assignment for each data point x i ? D l rv and Sym(C l rv ) is the group of permutations of C l rv elements (this discounts the fact that the cluster indices may not be in the same order as the ground-truth labels). Permutations are optimized using the Hungarian algorithm <ref type="bibr" target="#b44">[45]</ref>.</p><p>The other index is a cluster validity index (CVI) <ref type="bibr" target="#b45">[46]</ref> which, by capturing notions such as intra-cluster cohesion vs inter-cluster separation, is applicable to the unlabelled data D u . There are several CVI metrics, such as Silhouette <ref type="bibr" target="#b46">[47]</ref>, Dunn <ref type="bibr" target="#b47">[48]</ref>, Davies-Bouldin <ref type="bibr" target="#b48">[49]</ref>, and Calinski-Harabasz <ref type="bibr" target="#b49">[50]</ref>; while no metric is uniformly the best, the Silhouette index generally works well <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b50">[51]</ref>, and we found it to be a good choice for our case too. This index is given by</p><formula xml:id="formula_17">x?D u b(x) ? a(x) max{a(x), b(x)} ,<label>(9)</label></formula><p>where x is a data sample, a(x) is the average distance between x and all other data samples within the same cluster, and b(x) is the smallest average distance of x to all points in any other cluster (of which x is not a member).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data and implementation details</head><p>We evaluate AutoNovel on a variety of standard benchmark datasets: CIFAR10 <ref type="bibr" target="#b51">[52]</ref>, CIFAR100 <ref type="bibr" target="#b51">[52]</ref>, SVHN <ref type="bibr" target="#b52">[53]</ref>, Om-niGlot <ref type="bibr" target="#b53">[54]</ref>, and ImageNet <ref type="bibr" target="#b0">[1]</ref>. Following <ref type="bibr" target="#b4">[5]</ref>, we split these to have 5/20/5/654/30 classes respectively in the unlabelled set. The splits are summarized in table 1. In addition, for OmniGlot and ImageNet we use 20 and 3 different splits respectively, as in <ref type="bibr" target="#b4">[5]</ref>, and report average clustering accuracy (as defined in eq. (8)) on the unlabelled data. While we follow standard practice to split the datasets we note here that most of the time, the number of unlabelled classes is under a hundred. This is a potential limitation of clustering which still proves to be very difficult for classification over thousands of categories <ref type="bibr" target="#b54">[55]</ref>. We use the ResNet-18 <ref type="bibr" target="#b55">[56]</ref> architecture, except for Om-niGlot for which we use a VGG-like network <ref type="bibr" target="#b56">[57]</ref> with six layers to make our setting directly comparable to prior work. We use SGD with momentum <ref type="bibr" target="#b57">[58]</ref> as the optimizer for all but the OmniGlot dataset, for which we use Adam <ref type="bibr" target="#b58">[59]</ref>. For all experiments we use a batch size of 128 and k = 5 which we found work consistently well across datasets.</p><p>In the first self-supervised training step, unless otherwise mentioned, we train our model with the pretext task of rotation predictions (i.e., a four-class classification: 0 ? , 90 ? , 180 ? , and 270 ? ) for 200 epochs and a step-wise decaying learning rate starting from 0.1 and divided by 5 at epochs 60, 120, and 160.</p><p>In the second step of our framework (i.e., supervised training using labelled data), we fine-tune our model on the labelled set for 100 epochs and a step-wise decaying learning rate starting from 0.1 and halved every 10 epochs. From this step onward we fix the first three convolutional blocks of the model, and fine-tune the last convolutional block together with the linear classifier.</p><p>Finally, in the last joint training step, we fine-tune our model for 200/100/90 epochs for {CIFAR10, CIFAR100, SVHN}/OmniGlot/ImageNet, which is randomly sampled from the merged set of both labelled and unlabelled data. The initial learning rate is set to 0.1 for all datasets, and is decayed with a factor of 10 at the 170th/{30th, 60th} epoch for {CIFAR10, CIFAR100, SVHN}/ImageNet. The learning rate of 0.01 is kept fixed for OmniGlot. For the consistency regularization term, we use the ramp-up function as described in section 3.4 with ? = {5.0, 50.0, 50.0, 100.0, 10.0}, and T = {50, 150, 80, 1, 50} for CIFAR10, CIFAR100, SVHN, OmniGlot, and ImageNet respectively.</p><p>In the incremental learning setting, all previous hyper parameters remain the same for our method. We only add a ramp-up on the cross entropy loss on unlabelled data. The ramp-up length is the same as the one used for eq. (4) and we use for all experiments a coefficient of 0.05. For all other methods we train the classifier for 150 epochs with SGD with momentum and learning rate of 0.1 divided by 10 at epoch 50.</p><p>For hyper-parameter tuning, we create a probe validation set from the labelled data by dropping the labels of a few classes. We then tune the hyper-parameters based on the ACC on this probe validation set. We construct the probe validation set to have the same number of classes as the actual unlabelled set. For example, for CIFAR100, we split the 80 labelled classes into a 60-class labelled subset and a 20class probe validation set. We then tune the hyper-parameters 2: Ablation study of AutoNovel. "MSE" means MSE consistency constraint; "CE" means cross entropy loss for training on labeled data; "BCE" means binary cross entropy loss for training on unlabeled data; "S.S." means self-supervision; "I.L." means incremental learning. The evaluation metric is the ACC. based on the novel category discovery performance on the probe validation set. For CIFAR10 and SVHN, due to the small number of labelled classes, we only take 2 classes from the labelled data to construct the probe validation set. We implement our method using PyTorch 1.1.0 and run experiments on NVIDIA Tesla M40 GPUs. Following <ref type="bibr" target="#b4">[5]</ref>, our results are averaged over 10 runs for all datasets, except ImageNet, for which the results are averaged over the three 30-class subsets. In general, we found the results are stable. Our code is publicly available at http://www.robots.ox.ac. uk/ ? vgg/research/auto novel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ablation study</head><p>We validate the effectiveness of the components of Au-toNovel by ablating them and measuring the resulting ACC on the unlabelled data. Note that, since the evaluation is restricted to the unlabelled data, we are solving a clustering problem. The same unlabelled data points are used for both training and testing, except that data augmentation (i.e. image transformations) is not applied when computing the cluster assignments. As can be seen in table 2, all components have a significant effect as removing any of them causes the performance to drop substantially. Among them, the BCE loss is by far the most important one, since removing it results in a dramatic drop of 40-60% absolute ACC points. For example, the full method has ACC 90.4% on CIFAR10, while removing BCE causes the ACC to drop to 26.2%. This shows that that our rank-based embedding comparison can indeed generate reliable pairwise pseudo labels for the BCE loss. Without consistency, cross entropy, or self-supervision, the performance drops by a more modest but still significant 7.8%, 5.7% and 1.0% absolute ACC points, respectively, for CIFAR10. It means that the consistency term plays a role as important as the cross-entropy term by preventing the "moving target" phenomenon described in section 3.4. Finally, by incorporating the discovered classes in the classification task, we get a further boost of 1.3%, 2.0% and 0.2% points on CIFAR10, CIFAR100 and SVHN respectively.</p><p>We also evaluate the evolution of performances of our method with respect to k for ranking statistics. The results on SVHN/CIFAR10/CIFAR100 are shown in <ref type="figure" target="#fig_4">fig. 6</ref>. We found that k = {5, 7} give the best results overall. We also found that for all values of k except 1 results are in general stable.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Novel category discovery</head><p>We compare AutoNovel to baselines and state-of-the-art methods for new class discovery, starting from CIFAR10, CIFAR100, and SVHN in table 3. The first baseline (row 5 in table 3) amounts to applying k-means <ref type="bibr" target="#b18">[19]</ref> to the features extracted by the fine-tuned model (the second step in section 3.1), for which we use the k-means++ <ref type="bibr" target="#b59">[60]</ref> initialization. The second baseline (row 1 in table 3) is similar, but uses as feature extractor a model trained from scratch using only the labelled images, which corresponds to a standard transfer learning setting. By comparing rows 1, 5 and 9 in table 3, we can see that our method substantially outperforms k-means. Next, we compare with the KCL <ref type="bibr" target="#b2">[3]</ref>, MCL <ref type="bibr" target="#b3">[4]</ref> and DTC <ref type="bibr" target="#b4">[5]</ref> methods. By comparing rows 2-4 to 9, we see that our method outperforms these by a large margin. We also try to improve KCL, MCL and DTC by using the same self-supervised initialization we adopt (section 3.1), which indeed results in an improvement (rows 2-4 vs 6-8). However, their overall performance still lags behind ours by a large margin. For example, our method of section 3.4 achieves 95.0% ACC on SVHN, while "KCL w/ S.S.", "MCL w/ S.S." and "DTC w/ S.S." achieve only 65.6%, 53.1% and 75.7% ACC, respectively. Similar trends hold for CIFAR10 and CIFAR100. Finally, the incremental learning scheme of section 3.5 results in further improvements, as can be seen by comparing rows 9 and 10 of table 3. In <ref type="figure" target="#fig_5">fig. 7</ref>, we show the evolution of the learned representation on the unlabelled data from CIFAR10 using t-  SNE <ref type="bibr" target="#b60">[61]</ref>. As can be seen, while the clusters overlap in the beginning, they become more and more separated as the training progresses, showing that our model can effectively discover novel visual categories without labels and learn meaningful embeddings for them. We further compare AutoNovel to others on two more challenging datasets, OmniGlot and ImageNet, in table 4. For OmniGlot, results are averaged over the 20 alphabets in the evaluation set; for ImageNet, results are averaged over the three 30-class unlabelled sets used in <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. Since we have a relatively larger number of labelled classes in these two datasets, we follow <ref type="bibr" target="#b4">[5]</ref> and use metric learning on the labelled classes to pre-train the feature extractor, instead of the self-supervised learning. We empirically found that selfsupervision does not provide obvious gains for these two datasets. This is reasonable since the data in the labelled sets of these two datasets are rather diverse and abundant, so metric learning can provide good feature initialization as there is less class-specific bias due to the large number of pre-training classes. However, by comparing rows 1 and 5 in table 4, it is clear that metric learning alone is not sufficient for the task of novel category discovery. Our method substantially outperforms the k-means results obtained using the features from metric learning -by 11.9% and 10.6% on OmniGlot and ImageNet respectively. Our method also substantially outperforms the current state-of-the-art, achieving 89.1% and 82.5% ACC on OmniGlot and ImageNet respectively, compared with 89.0% and 78.3% of <ref type="bibr" target="#b4">[5]</ref>, thus setting the new state-of-the-art. By comparing table 3 and table 4, we observe that KCL and MCL perform better on the more challenging ImageNet than the smaller datasets CIAR10, CIFAR100 and SVHN. This can be explained by the fact that the pairwise psuedo labels are provided by a similarity prediction network (SPN) which is pretrained on the labelled data. As there are much less labelled data in CIFAR10, CIFAR100 and SVHN than ImageNet, the learned SPN is less reliable, thus resulting in relatively poor performance for novel category discovery on unlabelled data from new classes. 5: Incremental Learning with the novel categories. "old" refers to the ACC on the labelled classes while "new" refers to the unlabelled classes in the testing set. "all" indicates the whole testing set. It should be noted that the predictions are not restricted to their respective subset. "S.S." means self-supervision; "I.L." means incremental learning.  <ref type="figure" target="#fig_3">6?0.2% 88.8?0.2% 89.7?0.1% 71.2?0.1% 56.8?0.3% 68.3?0.1% 96.3?0.1% 96.1?0.0% 96.2?0.1%</ref> (a) Ours (b) + incr. learning <ref type="figure">Fig. 8</ref>: t-SNE on CIFAR10: impact of incremental Learning. Colors of data points denote their ground-truth labels ("old" classes 0-4; "new" classes 5-9). We observe a bigger overlap in (a) between the "old" class 3 and the "new" class 5 when not incorporating Incremental Learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Incremental learning scheme</head><p>Here, we further evaluate our incremental scheme for novel category discovery as described in section 3.5. Methods for novel category discovery such as <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> focus on obtaining the highest clustering accuracy for the new unlabelled classes, but may forget the existing labelled classes in the process. In practice, forgetting is not desirable as the model should be able to recognize both old and new classes. Thus, we argue that the classification accuracy on the labelled classes should be assessed as well, as for any incremental learning setting. Note however that our setup differs substantially from standard incremental learning <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref> where every class is labelled and the focus is on using limited memory. In our case, we can store and access the original data without memory constraints, but the new classes are unlabelled, which is often encountered in practical applications. By construction (section 3.5), our method learns the new classes on top of the old ones incrementally, out of the box. In order to compare AutoNovel to methods such as KCL, MCL and DTC that do not have this property, we proceed as follows. First, the method runs as usual to cluster the unlabelled portion of the data, thus obtaining pseudo-labels for it, and learning a feature extractor as a byproduct. Then, the feature extractor is used to compute features for both the labelled and unlabelled training data, and a linear classifier is trained using labels and pseudo-labels, jointly on all the classes, old and new.</p><p>We report in table 5 the performance of the resulting joint classifier networks on the testing set of each dataset (this is now entirely disjoint from the training set). Our method has similar performances on the old and new classes for CIFAR10 and SVHN, as might be expected as the split between old and new classes is balanced. In comparison, the feature extractor   learned by KCL and MCL works much better for the old classes (e.g., the accuracy discrepancy between old and new classes is 25.3% for KCL on SVHN). Conversely, DTC learns features that work better for the new classes, as shown by the poor performance for the old classes on CIFAR10. Thus, KCL, MCL and DTC learn representations that are biased to either the old or new classes, resulting overall in suboptimal performance. In contrast, our method works well on both old and new classes; furthermore, it drastically outperforms existing methods on both. In <ref type="figure">fig. 8</ref>, we show the t-SNE projection of the learned feature representation on both old and new classes. It can be seen, with incremental learning, the embedding becomes more discriminative between old and new classes. Similarly, in <ref type="figure" target="#fig_7">fig. 9</ref> we compare the confusion matrices w/ and w/o the incremental learning scheme. It can be seen that, with the incremental learning scheme, the clusters for new classes turn out to be more accurate. We notice that the errors are mainly due to the confusion between dog and horse. By looking into the images, we found that images of dogs and horses are confused because of having similar colors or poses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Finding the number of novel categories</head><p>We now experiment under the more challenging (and realistic) scenario where the number of categories in the unlabelled data is unknown. KCL and MCL assume the number of categories to be a large value (i.e., 100) instead of estimating the number of categories explicitly. By contrast, we choose to estimate the number of categories as described in method summary 1 (with C u max = 100 for all our experiments), before running the transfer clustering algorithm, and only then apply our ranking based method to learn the representation and find the cluster assignment. Results for novel category number estimation are reported in <ref type="table" target="#tab_9">table 6 and table 7 on</ref> OmniGlot and ImageNet respectively. The average errors are 4.6 on OmniGlot and 2.33 on ImageNet, which validates the effectiveness of our approach. In table 8, we show the clustering results on OmniGlot and ImageNet, by substituting these estimates to our ranking based method for novel category discovery, and also compare with other methods. The results of traditional methods are those reported in <ref type="bibr" target="#b3">[4]</ref> using raw images for OmniGlot and pretrained features for ImageNet. AutoNovel outperforms the previous state-of-the-art MCL by 5.2% and 9.0% ACC on OmniGlot and ImageNet respectively. We also experiment on KCL, MCL and DTC by using our estimated number of clusters. With this augmentation, both KCL amd MCL improve significantly, indicating that our category number estimation method can also be beneficial for other methods. DTC slightly outperforms our ranking based method by 1.6% on OmniGlot with our estimated category number, while our method outperforms DTC by 2.9% on ImageNet. In addition, we also validate the sensitivity of different methods to the choice of cluster number on the 30-class ImageNet A . We vary the cluster number from 20 to 100. The results are shown in <ref type="figure" target="#fig_8">fig. 10</ref>. It can be seen that the sensitivity to the cluster number is similar for all methods. All methods achieve the best performance when the cluster number equals the ground truth, while the performance drops when the cluster number is off the ground truth. Our method consistently outperforms all others for cluster numbers 25 to 40 (note that our estimated cluster number is 34). For the extreme case with the cluster number of 100, MCL performs the best.  <ref type="table" target="#tab_1">Angelic  20  16  26  22  23  Atemayar Q. 26  17  34  26  25  Atlantean  26  21  41  25  34  Aurek Besh 26  14  28  22  34  Avesta  26  8  32  23  31  Ge ez  26  18  32  25  31  Glagolitic  45  18  45  36  46  Gurmukhi  45  12  43  31  34  Kannada  41  19  44  30  40  Keble  26  16  28  23  25  Malayalam  47  12  47  35  42  Manipuri  40  17  41  33  39  Mongolian  30  28  36  29  33  Old Church S. 45  23  45  38  51  Oriya  46  22  49  32  33  Sylheti  28  11  50  30  22  Syriac Serto 23  19  38  24  26  Tengwar  25  12  41  26  28  Tibetan  42  15  42  34  43  ULOG  26  15  40  27</ref>     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Transferring from ImageNet pretrained model</head><p>Rather than pretraining the model with self-supervised learning, one may also think to transfer representation learned from other datasets. The most common way of transfer learning with modern deep convolutional neural networks is to use ImageNet pretrained models. Here, we explore the potential of leveraging the ImageNet pretrained model to transfer features for novel category discovery. In particular, we take the ImageNet pretrained model as our feature extractor, and finetune the last macro-block and the linear heads of the model using our ranking based method. We experiment on CIFAR10, CIFAR100, and SVHN. The results are shown in table 9. As can be seen, with the ImageNet pretrained representation, the performance of our method on CIFAR10 and CIFAR100 are further improved w.r.t to the results in table 3. The incremental learning scheme succesfully boosts the performance by 0.7% and 3.8% on CIFAR10 and CIFAR100 respectively. For the performance on SVHN, we notice a significant drop between <ref type="table" target="#tab_4">table 3  and table 9</ref>. This is likely due to the small correlation between ImageNet and SVHN, as also noted in other works that try to transfer features from ImageNet to other datasets <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b4">[5]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Alternatives to ranking statistics</head><p>The ranking statistics is the key to transfer knowledge from old classes to new classes in our model. As discussed in section 3.2.1, other methods like k-means, cosine similarity, and nearest neighbor can potentially be used as alternatives to ranking statistics to generate pairwise pseudo labels in AutoNovel. We experiment with such alternatives and the results are shown in table 10. We experiment on two cases for k-means, one by running k-means on the mini-batch (denoted as k-means (batch)) and the other by running kmeans (denoted as k-means (all)) on the whole unlabelled set. As it can be seen, ranking statistics, nearest neighbor and cosine similarity work significantly better than k-means on CIFAR10 and SVHN, while ranking statistics and cosine similarity work notably better than nearest neighbor on CIFAR100 and SVHN. Note that the performance of cosine similarity depends on the choice of a proper threshold ? .</p><p>Here, we report the results using the best thresholds on each dataset (0.85/0.8/0.9 for CIFAR10/CIFAR100/SVHN). The effect of different thresholds is shown in <ref type="figure" target="#fig_9">fig. 11</ref>. It can be seen that, with a carefully chosen threshold, cosine similarity can also be a good measure to generate pairwise pseudo labels in our method, though the results turn to be relatively sensitive to ? . When ? &lt; 0.6, the cosine similarity fails to provide reliable pairwise pseudo labels. Meanwhile, as ? lies in the continues space while k in our ranking based method lies in the discrete integer space, it is easier to set a proper k than ? . Overall, while it can be seen that ranking statistics and cosine similarity exhibit a similar behaviour when grid-searching with a relatively low sensitivity to the best value, we still find that ranking statistics is an interesting alternative to cosine similarity and is relatively unexplored in the context of deep learning. Throughout all of our experiments we demonstrate that ranking statistics performs consistently well and could open the way for more applications. Therefore, unless stated otherwise, ranking statistics is our default choice for all experiments. Through ranking statistics, instead of generating hard (binary) pseudo targets, we can also encode soft rank similarities. To do so, we calculate the shared elements in the top-k rank between two images. Let c be the number of shared elements. The soft similarity is then defined as c k , which can be used to replace the s ij in eq. (3). The results are shown in table <ref type="bibr" target="#b9">10</ref>. We find that k = 5 is not optimal for the soft rank similarity, as the results largely lag behind the hard counterpart. We adopt the validation method introduced in section 5.1 to get k = 15 as a better choice for the soft rank similarity. The results are in general on par with the hard (binary) rank similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Other self-supervised learning methods</head><p>We adopt the RotNet <ref type="bibr" target="#b32">[33]</ref> for the first stage of AutoNovel. However, any other self-supervised representation methods can be applied. Here, we further experiment with the latest self-supervised representation learning methods including SimCLR <ref type="bibr" target="#b33">[34]</ref>, MoCo <ref type="bibr" target="#b34">[35]</ref> and MoCo v2 <ref type="bibr" target="#b64">[65]</ref>, which are the state-of-the-art representation learning methods for the tasks of object recognition and detection. In this experiment, we replace RotNet by the latest self-supervised learning methods in our pipeline, and the other two steps remain the same as before. In table 11, we first directly compare the learned feature representations of different methods by running kmeans on the output of the global average pooling layer on the unlabelled data. All the three alternatives work better than RotNet when comparing the raw features learned with self-supervised learning on CIFAR10 and CIFAR100, while RotNet performs slightly better on SVHN. This is likely due to nature of the pretext tasks used in these self-supervised learning methods. RotNet uses the rotation prediction task, which is less relevant to the down stream task of partitioning the unlabelled data based on their semantic meaning. Differently, the other three methods are contrastive learning based methods, which encourage the images of the same instance to be close in the feature space while the images of different instances to be further away. Interestingly, we find that RotNet consistently outperforms the other three methods for AutoNovel. This reveals that better feature initialization does not necessarily mean better representation fine-tuned on downstream tasks like novel category discovery. Overall, by taking any of these self-supervised learning methods to pre-train our model, the performance can be significantly boosted on novel category discovery by our method.  <ref type="bibr" target="#b18">[19]</ref> SimCLR <ref type="bibr" target="#b33">[34]</ref> 84.7% 41.2% 30.6% MoCo <ref type="bibr" target="#b34">[35]</ref> 58.7% 34.5% 21.3% MoCo v2 <ref type="bibr" target="#b64">[65]</ref> 61.8% 39.3% 28.5% RotNet <ref type="bibr" target="#b32">[33]</ref> 25.5% 10.3%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>31.7%</head><p>Ours SimCLR <ref type="bibr" target="#b33">[34]</ref> 89.0% 54.6% 67.8% MoCo <ref type="bibr" target="#b34">[35]</ref> 87.6% 61.1% 74.6% MoCo v2 <ref type="bibr" target="#b64">[65]</ref> 89.0% 62.5% 76.6% RotNet <ref type="bibr" target="#b32">[33]</ref> 90.4% 73.2%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>95.0%</head><p>To investigate why RotNet appears to be more effective in our experiments, we carry out experiments by freezing different layers of the network and finetuning the rest of the layers employing different self-supervised learning approaches. ResNet18 is composed of four macro-blocks, denoted as layer {1,2,3,4} . In table 12, for each column, we freeze all the parameters before layer i and finetune layer i together with the subsequent layers. head denotes the case where we only finetune the two linear heads while layer 0 denotes the case where we finetune all the parameters. We measure the novel category performance on CIFAR10 for all methods and report the ACC on the unlabelled data. It can be seen that, if we only finetune the linear heads, SimCLR, MoCo and MoCoV2 significantly outperform RotNet, which is consistent with the conclusion in the literature that the contrastive learning based methods can learn more meaningful higher level feature representation. The higher level features for RotNet is focusing on the task of rotation prediction, which is loosely related to the target task of novel category discovery, thus the performance is poor. However, if we finetune more layers, we can see that the performance are similar, while RotNet appears to be more effective for layer 4 and layer 3 . The strong augmentation is essential for the performance of contrastive learning based self-supervision. However, for SVHN, where multiple digits appear in the same image and only the center digit is to be recognized, strong augmentations like cropping is not suitable for training, because random cropping will change the location of the center digits, which is harmful for training. Therefore, the performance of contrastive learning based methods lags behind RotNet on SVHN as in table 11. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9">Unsupervised image clustering</head><p>As discussed in section 3.6, by removing the requirement of labelled data, AutoNovel turns to an unsupervised clustering method that can learn both feature representation and clustering assignment. Here, we compare our method on the clustering problem with the state-of-the-art methods on three popular benchmarks CIFAR10, CIFAR100 and STL10 <ref type="bibr" target="#b65">[66]</ref>. We follow the common practice to use all 10 classes in CIFAR10 and STL10, and the 20 meta classes in CIFAR100 (denoted as CIFAR100-20) in our experiment for fair comparison. The results are presented in table <ref type="bibr" target="#b12">13</ref>. Our method performs on par with the state-of-the-art method IIC <ref type="bibr" target="#b43">[44]</ref> on CIFAR10 and and STL10, while significantly outperforms IIC on CIFAR100-20 by 9.3%. Compared with IIC, which requires extra Sobel filtering on the input data and large batch sizes (660/1000/700 on CIFAR10/CIFAR100-20/STL10), our method only needs the conventional data augmentation (random cropping and horizontal flipping) and a small batch size of 128 for all three datasets. Therefore, our method is a good alternative to state-of-the-art methods for the task of unsupervised image clustering, though this is not the main objective of this work. Moreover, we report the k-means results on the feature representation of the base self-supervised model (i.e., RotNet) on each dataset. Unsurprisingly, the results are not satisfactory, because the high level features of RotNet are learned for the task of rotation prediction, making it less effective in capturing useful semantic information for downstream tasks like clustering. Meanwhile, we also validate the effectiveness of self-supervised pretraining and consistency regularization in eq. <ref type="bibr" target="#b6">(7)</ref>. We can see that by dropping each of them in our method, the performance drops. Without the self-supervised pretraining, the performance drops significantly. This suggests that self-supervised learning captures discriminative low level features for the task of image clustering. Similar to the task of novel category discovery, when applying our approach to unsupervised clustering, the MSE consistency loss is also effective in preventing the "moving target" phenomenon described in section 3.4 during training. We show the confusion matrix on CIFAR10 by our full method in <ref type="figure" target="#fig_10">fig. 12</ref>. As can be seen from the diagonal of the matrix, our method can properly cluster objects into proper clusters. We found airplane and bird are confused with ship because of the shared blue background; cat and dog are confused because of similar poses and colors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>In this paper, we have looked at the problem of discovering new classes in an image collection, leveraging labels available for other, known classes. We have proposed AutoNovel to successfully address this task by combining a few new ideas. First, the use of self-supervised learning for bootstrapping the image representation trades off the representation quality with its generality, and for our problem this leads to a better solution overall. Second, we have shown that ranking statistics are an effective method to compare noisy image descriptors, resulting in robust data clustering. Third, we have shown that jointly optimizing both labelled recognition and unlabelled clustering in an incremental learning setup can reinforce the two tasks while avoiding forgetting. On standard benchmarks, the combination of these ideas results in much better performance than existing methods that solve the same task. For larger datasets with more classes and diverse data (e.g., ImageNet) we note that self-supervision can be bypassed as the pretraining on labelled data already provides a powerful enough representation. In such cases, we still show that the ranking statistics for clustering gives drastic improvement over existing methods. Besides, we have also proposed a method to estimate the number of categories in the unlabelled data, by transferring knowledge from the labelled data to the unlabelled data, allowing our method to handle the more challenging case when number of categories in unknown. Finally, we have shown that AutoNovel can also serve as a simple and effective method for unsupervised image clustering by simply removing the requirement of labelled data, performing on par with the state-of-the-art methods.</p><p>One key assumption in our work is that the classes in labelled and unlabelled data follow a similar category definition, in the sense that all classes belong to the same vision dataset. We assume this is the case for categories collected in the same dataset, because we normally follow a consistent procedure to define classes during data curation. Ideally, it would be great to have a precise measure about the relevance between labelled and unlabelled tasks so that we can have a clear sense on whether certain algorithms are applicable or not for novel category discovery. We consider this as a potential future research direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 2: Overview of the AutoNovel learning pipeline for novel category discovery. The first step is to learn an unbiased image representation via self-supervision using both labelled and unlabelled data. This learns well the early layers of the representation. The second step is to fine-tune only the last few layers of the representation using supervision on the labelled subset of the data. The final step is to use the fine-tuned representation, via ranking statistics, to induce clusters in the unlabelled data, while maintaining a good representation on the labelled set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>?(x i ) = z j = ?(x j ) = z k = ?(x k ) =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Joint learning on labelled and unlabelled data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Data split for category number estimation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 :</head><label>6</label><figDesc>Performance evolution w.r.t. k for ranking statistics. We report results for k = {1, 2, 3, 5, 7, 10, 15, 20, 50}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 :</head><label>7</label><figDesc>Evolution of the t-SNE during the training of CIFAR-10. Performed on unlabelled data (i.e., instances of dog, frog, horse, ship, truck). Colors of data points denote their groundtruth labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 :</head><label>9</label><figDesc>Confusion matrix on unlabelled classes of CIFAR10. Left: our method; Right: our method w/ I.L.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 :</head><label>10</label><figDesc>Performance of different methods with different cluster number on ImageNet A . The ground truth is 30. We vary the cluster number from 20 to 100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 :</head><label>11</label><figDesc>Performance evolution w.r.t. the threshold ? for cosine similarity. We report results for ? = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 0.97}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 :</head><label>12</label><figDesc>0.05 0.08 0.06 0.01 0.00 0.00 0.00 0.34 0.02 0.01 0.76 0.00 0.01 0.00 0.00 0.00 0.00 0.02 0.20 0.18 0.00 0.38 0.14 0.18 0.03 0.05 0.02 0.02 0.00 0.09 0.00 0.04 0.27 0.05 0.50 0.03 0.01 0.00 0.00 0.07 0.00 0.03 0.12 0.62 0.03 0.02 0.10 0.01 0.00 0.03 0.00 0.02 0.20 0.09 0.62 0.00 0.03 0.00 0.00 0.04 0.00 0.06 0.06 0.01 0.02 0.81 0.00 0.00 0.00 0.04 0.00 0.01 0.12 0.07 0.07 0.00 0.67 0.00 0.00 0.02 0.15 0.01 0.03 0.00 0.00 0.00 0.00 0.75 0.02 0.02 0.08 0.00 0.01 0.00 0.00 0.00 0.00 0.04 0Confusion matrix of clustering on CIFAR10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1 :</head><label>1</label><figDesc>Data splits in the experiments.</figDesc><table><row><cell></cell><cell cols="2">labelled classes unlabelled classes</cell></row><row><cell>CIFAR10</cell><cell>5</cell><cell>5</cell></row><row><cell>CIFAR100</cell><cell>80</cell><cell>20</cell></row><row><cell>SVHN</cell><cell>5</cell><cell>5</cell></row><row><cell>OmniGlot</cell><cell>964</cell><cell>659</cell></row><row><cell>ImageNet</cell><cell>882</cell><cell>118</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 3 :</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell cols="4">Novel category discovery results on CIFAR10,</cell></row><row><cell cols="5">CIFAR100, and SVHN. ACC on the unlabelled set. "S.S."</cell></row><row><cell cols="5">means self-supervision; "I.L." means incremental learning.</cell></row><row><cell>No</cell><cell></cell><cell>CIFAR10</cell><cell>CIFAR100</cell><cell>SVHN</cell></row><row><cell>(1)</cell><cell>k-means [19]</cell><cell cols="2">65.5?0.0 % 56.6?1.6%</cell><cell>42.6%?0.0</cell></row><row><cell>(2)</cell><cell>KCL [3]</cell><cell>66.5?3.9%</cell><cell>14.3?1.3%</cell><cell>21.4%?0.6</cell></row><row><cell>(3)</cell><cell>MCL [4]</cell><cell>64.2?0.1%</cell><cell cols="2">21.3?3.4% 38.6%?10.8</cell></row><row><cell>(4)</cell><cell>DTC [5]</cell><cell>87.5?0.3%</cell><cell>56.7?1.2%</cell><cell>60.9%?1.6</cell></row><row><cell>(5)</cell><cell>k-means [19] w/ S.S.</cell><cell>72.5?0.0%</cell><cell>56.3?1.7%</cell><cell>46.7?0.0%</cell></row><row><cell>(6)</cell><cell>KCL [3] w/ S.S.</cell><cell>72.3?0.2%</cell><cell>42.1?1.8%</cell><cell>65.6?4.9%</cell></row><row><cell>(7)</cell><cell>MCL [4] w/ S.S.</cell><cell>70.9?0.1%</cell><cell>21.5?2.3%</cell><cell>53.1?0.3%</cell></row><row><cell>(8)</cell><cell>DTC [5] w/ S.S.</cell><cell>88.7?0.3%</cell><cell>67.3?1.2%</cell><cell>75.7?0.4%</cell></row><row><cell>(9)</cell><cell>Ours</cell><cell>90.4?0.5%</cell><cell>73.2?2.1%</cell><cell>95.0?0.2%</cell></row><row><cell cols="2">(10) Ours w/ I.L.</cell><cell>91.7?0.9%</cell><cell>75.2?4.2%</cell><cell>95.2?0.2%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 4 :</head><label>4</label><figDesc>Novel category discovery results on OmniGlot and ImageNet. ACC on the unlabelled set.</figDesc><table><row><cell>No</cell><cell></cell><cell cols="2">OmniGlot ImageNet</cell></row><row><cell>(1)</cell><cell>k-means [19]</cell><cell>77.2%</cell><cell>71.9%</cell></row><row><cell>(2)</cell><cell>KCL [3]</cell><cell>82.4%</cell><cell>73.8%</cell></row><row><cell>(3)</cell><cell>MCL [4]</cell><cell>83.3%</cell><cell>74.4%</cell></row><row><cell>(4)</cell><cell>DTC [5]</cell><cell>89.0%</cell><cell>78.3%</cell></row><row><cell>(5)</cell><cell>Ours</cell><cell>89.1%</cell><cell>82.5%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>4?0.6% 60.1?0.6% 69.8?0.1% 23.4?0.3% 29.4?0.3% 24.6?0.2% 90.3?0.3% 65.0?0.5% 81.0?0.1% MCL w/ S.S. 81.4?0.4% 64.8?0.4% 73.1?0.1% 18.2?0.3% 18.0?0.1% 18.2?0.2% 94.0?0.2% 48.6?0.3% 77.2?0.1% DTC w/ S.S. 58.7?0.6% 78.6?0.2% 68.7?0.3% 47.6?0.2% 49.1?0.2% 47.9?0.2% 90.5?0.3% 72.8?0.2% 84.0?0.1%</figDesc><table><row><cell></cell><cell></cell><cell>CIFAR10</cell><cell></cell><cell></cell><cell>CIFAR100</cell><cell></cell><cell></cell><cell>SVHN</cell><cell></cell></row><row><cell>Classes</cell><cell>old</cell><cell>new</cell><cell>all</cell><cell>old</cell><cell>new</cell><cell>all</cell><cell>old</cell><cell>new</cell><cell>all</cell></row><row><cell>KCL w/ S.S. 79.Ours w/ I.L. 90.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE 6 :</head><label>6</label><figDesc>Category number estimation on OmniGlot.</figDesc><table><row><cell>Alphabet</cell><cell>GT SKMS [62] KCL [3] MCL [4] Ours</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE 7 :</head><label>7</label><figDesc>Category number estimation results.</figDesc><table><row><cell>Data</cell><cell cols="3">GT Ours Error</cell></row><row><cell>ImageNet A</cell><cell>30</cell><cell>34</cell><cell>4</cell></row><row><cell>ImageNet B</cell><cell>30</cell><cell>31</cell><cell>1</cell></row><row><cell>ImageNet C</cell><cell>30</cell><cell>32</cell><cell>2</cell></row><row><cell>Avgerror</cell><cell>-</cell><cell>-</cell><cell>2.33</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE 8 :</head><label>8</label><figDesc>Novel category discovery with an unknown class number C u .</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>OmniGlot ImageNet</cell></row><row><cell></cell><cell cols="2">Method</cell><cell></cell><cell>ACC</cell><cell>ACC</cell></row><row><cell></cell><cell cols="2">k-means [19]</cell><cell></cell><cell>18.9%</cell><cell>34.5%</cell></row><row><cell></cell><cell cols="2">LPNMF [63]</cell><cell></cell><cell>16.3%</cell><cell>21.8%</cell></row><row><cell></cell><cell cols="2">LSC [64]</cell><cell></cell><cell>18.0%</cell><cell>33.5%</cell></row><row><cell></cell><cell cols="2">KCL [3]</cell><cell></cell><cell>78.1%</cell><cell>65.2%</cell></row><row><cell></cell><cell cols="2">MCL [4]</cell><cell></cell><cell>80.2%</cell><cell>71.5%</cell></row><row><cell></cell><cell cols="3">KCL [3] w/our C u MCL [4] w/our C u DTC [5] w/our C u</cell><cell>80.3% 80.5% 87.0%</cell><cell>71.4% 72.9% 77.6%</cell></row><row><cell></cell><cell cols="2">Ours</cell><cell></cell><cell>85.4%</cell><cell>80.5%</cell></row><row><cell></cell><cell>100</cell><cell></cell><cell></cell></row><row><cell></cell><cell>80</cell><cell></cell><cell></cell></row><row><cell>ACC.</cell><cell>40 60</cell><cell></cell><cell></cell></row><row><cell></cell><cell>20</cell><cell></cell><cell></cell><cell>KCL MCL DTC Ours</cell></row><row><cell></cell><cell>0</cell><cell>20 25 30 35 40</cell><cell cols="2">50 Cluster number</cell><cell>100</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE 9 :</head><label>9</label><figDesc></figDesc><table><row><cell cols="4">Transferring from ImageNet to CI-</cell></row><row><cell cols="2">FAR10/CIFAR100/SVHN.</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">CIFAR10 CIFAR100 SVHN</cell></row><row><cell>k-means [19]</cell><cell>92.4%</cell><cell>78.8%</cell><cell>23.4%</cell></row><row><cell>Ours</cell><cell>95.4%</cell><cell>87.1%</cell><cell>40.2%</cell></row><row><cell>Ours w/I.L.</cell><cell>96.1%</cell><cell>90.9%</cell><cell>38.8%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE 10 :</head><label>10</label><figDesc>Different methods for pairwise pseudo labels.</figDesc><table><row><cell></cell><cell cols="3">CIFAR10 CIFAR100 SVHN</cell></row><row><cell>k-means (batch)</cell><cell>42.9%</cell><cell>74.3%</cell><cell>45.3%</cell></row><row><cell>k-means (all)</cell><cell>62.2%</cell><cell>55.5%</cell><cell>61.5%</cell></row><row><cell>cosine</cell><cell>90.1%</cell><cell>73.3%</cell><cell>95.0%</cell></row><row><cell>nearest neighbor</cell><cell>90.2%</cell><cell>69.7%</cell><cell>78.2%</cell></row><row><cell>ranking statistics</cell><cell>90.4%</cell><cell>73.2%</cell><cell>95.0%</cell></row><row><cell>soft ranking statistics (k = 5)</cell><cell>62.2%</cell><cell>65.2%</cell><cell>72.5%</cell></row><row><cell>soft ranking statistics (k = 15)</cell><cell>89.7%</cell><cell>71.1%</cell><cell>95.2%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>TABLE 11 :</head><label>11</label><figDesc>Different self-supervised learning methods.</figDesc><table><row><cell>CIFAR10 CIFAR100 SVHN</cell></row></table><note>k-means</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>TABLE 12 :</head><label>12</label><figDesc>Performance on fine-tuning different layers on CIFAR10. ACC on the unlabelled set.</figDesc><table><row><cell>Method</cell><cell>head</cell><cell>layer 4</cell><cell>layer 3</cell><cell>layer 2</cell><cell>layer 1</cell><cell>layer 0</cell></row><row><cell>RotNet</cell><cell>39.9%</cell><cell>90.4%</cell><cell>90.8%</cell><cell>88.4%</cell><cell>89.3%</cell><cell>88.9%</cell></row><row><cell>SimCLR</cell><cell>73.1%</cell><cell>89.0%</cell><cell>89.1%</cell><cell>89.5%</cell><cell>90.4%</cell><cell>88.6%</cell></row><row><cell>MoCo</cell><cell>80.8%</cell><cell>87.6%</cell><cell>88.8%</cell><cell>89.3%</cell><cell>90.4%</cell><cell>89.5%</cell></row><row><cell cols="2">MoCoV2 84.6%</cell><cell>89.0%</cell><cell>89.5%</cell><cell>89.0%</cell><cell>90.3%</cell><cell>89.2%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>TABLE 13 :</head><label>13</label><figDesc>Unsupervised image clustering. "k-means on S.S." refers to the k-means results on the representation of the self-supervised model.</figDesc><table><row><cell></cell><cell cols="3">CIFAR10 CIFAR100-20 STL10</cell></row><row><cell>k-means [19]</cell><cell>22.9%</cell><cell>13.0%</cell><cell>19.2%</cell></row><row><cell>JULE [26]</cell><cell>27.2%</cell><cell>13.7%</cell><cell>27.7%</cell></row><row><cell>DEC [22]</cell><cell>30.1%</cell><cell>18.5%</cell><cell>35.9%</cell></row><row><cell>DAC [36]</cell><cell>52.2%</cell><cell>23.8%</cell><cell>47.0%</cell></row><row><cell>IIC [44]</cell><cell>61.7%</cell><cell>25.7%</cell><cell>59.6%</cell></row><row><cell>k-means on S.S.</cell><cell>14.3%</cell><cell>8.8%</cell><cell>15.7%</cell></row><row><cell>Ours w/o S.S.</cell><cell>18.8%</cell><cell>13.0%</cell><cell>22.7%</cell></row><row><cell>Ours w/o MSE</cell><cell>57.7%</cell><cell>31.6%</cell><cell>48.6%</cell></row><row><cell>Ours</cell><cell>61.7%</cell><cell>35.0%</cell><cell>56.4%</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work is supported by the EPSRC Programme Grant Seebibyte EP/M013774/1, Mathworks/DTA DFR02620, and ERC IDIU-638009. We also gratefully acknowledge the support of Nielsen.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Realistic evaluation of deep semi-supervised learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to cluster in order to transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Multi-class classification without multi-class labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schlosser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Odom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to discover novel visual categories via deep transfer clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Catastrophic interference in connectionist networks: The sequential learning problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of Learning and Motivation</title>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Automatically discovering and learning new visual categories with ranking statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ehrhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Semi-supervised learning with ladder networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Honkala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Semi-supervised learning with scarce annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ehrhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arxiv</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">S4l: Self-supervised semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semisupervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A survey of transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A survey on deep transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Reddy</surname></persName>
		</author>
		<title level="m">Data Clustering: Algorithms and Applications</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</title>
		<meeting>the Fifth Berkeley Symposium on Mathematical Statistics and Probability</meeting>
		<imprint>
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mean shift: A robust approach toward feature space analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep adaptive image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Dizaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Towards kmeans-friendly spaces: Simultaneous deep learning and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Deep image category discovery using a transferred similarity function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arxiv</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Zero-shot learning -a comprehensive evaluation of the good, the bad and the ugly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Recent advances in zero-shot recognition: Toward data-efficient understanding of visual content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast, accurate detection of 100,000 object classes on a single machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Ruzon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vijayanarasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yagnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The power of comparative reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yagnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Strelow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Revisiting self-supervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">ICLR</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep selfevolution clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ehrhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10039</idno>
		<title level="m">Lsd-c: Linearly separable deep clusters</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Efficient parameterfree clustering using first neighbor relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Sarfraz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">On the distance concentration awareness of certain data reduction techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kab?n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">icarl: Incremental classifier and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sperl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Gradient episodic memory for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Incremental learning of object detectors without catastrophic forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shmelkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Alahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Memory aware synapses: Learning what (not) to forget</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Aljundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Babiloni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Naval research logistics quarterly</title>
		<imprint>
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An extensive comparative study of cluster validity indices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Arbelaitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gurrutxaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Muguerza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>P?rez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Silhouettes: A graphical aid to the interpretation and validation of cluster analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Applied Mathematics</title>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Well-separated clusters and optimal fuzzy partitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Dunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cybernetics</title>
		<imprint>
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A cluster separation measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Bouldin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A dendrite method for cluster analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cali?ski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harabasz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics-theory and Methods</title>
		<imprint>
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Some new indexes of cluster validity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>Part B</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Scan: Learning to classify images without labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">k-means++: the advantages of careful seeding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM-SIAM symposium on Discrete algorithms</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Semi-supervised kernel mean shift clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Locality preserving nonnegative matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Large scale spectral clustering with landmarkbased representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Improved baselines with momentum contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">An analysis of single layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
