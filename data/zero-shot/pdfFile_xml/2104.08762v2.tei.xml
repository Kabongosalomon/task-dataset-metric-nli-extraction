<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Case-Based Reasoning for Natural Language Queries over Knowledge Bases</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
							<email>rajarshi@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Google Research</orgName>
								<address>
									<addrLine>4 Amazon, 5 EY</addrLine>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dung</forename><surname>Thai</surname></persName>
							<email>dthai@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameya</forename><surname>Godbole</surname></persName>
							<email>agodbole@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay-Yoon</forename><surname>Lee</surname></persName>
							<email>jaylee@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Tan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lazaros</forename><surname>Polymenakos</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
							<email>mccallum@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Case-Based Reasoning for Natural Language Queries over Knowledge Bases</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>It is often challenging to solve a complex problem from scratch, but much easier if we can access other similar problems with their solutions -a paradigm known as case-based reasoning (CBR). We propose a neuro-symbolic CBR approach (CBR-KBQA) for question answering over large knowledge bases. CBR-KBQA consists of a nonparametric memory that stores cases (question and logical forms) and a parametric model that can generate a logical form for a new question by retrieving cases that are relevant to it. On several KBQA datasets that contain complex questions, CBR-KBQA achieves competitive performance. For example, on the COMPLEXWEBQUESTIONS dataset, CBR-KBQA outperforms the current state of the art by 11% on accuracy. Furthermore, we show that CBR-KBQA is capable of using new cases without any further training: by incorporating a few human-labeled examples in the case memory, CBR-KBQA is able to successfully generate logical forms containing unseen KB entities as well as relations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Humans often solve a new problem by recollecting and adapting the solution to multiple related problems that they have encountered in the past <ref type="bibr">(Ross, 1984;</ref><ref type="bibr" target="#b36">Lancaster and Kolodner, 1987;</ref><ref type="bibr">Schmidt et al., 1990)</ref>. In classical artificial intelligence (AI), case-based reasoning (CBR) pioneered by <ref type="bibr">Schank (1982)</ref>, tries to incorporate such model of reasoning in AI systems <ref type="bibr" target="#b32">(Kolodner, 1983;</ref><ref type="bibr">Rissland, 1983;</ref><ref type="bibr" target="#b38">Leake, 1996)</ref>. A sketch of a CBR system <ref type="bibr" target="#b0">(Aamodt and Plaza, 1994)</ref> comprises of -(i) a retrieval module, in which 'cases' that are similar to the given problem are retrieved, (ii) a reuse module, where the solutions of the retrieved cases are reused to synthesize a new solution. Often, the new solution does not work and needs more revision, which is handled by a (iii) revise module.</p><p>In its early days, the components of CBR were implemented with symbolic systems, which had their limitations. For example, finding similar cases and synthesizing new solutions from them is a challenging task for a CBR system implemented with symbolic components. However, with the recent advancements in representation learning <ref type="bibr" target="#b39">(LeCun et al., 2015)</ref>, the performance of ML systems have improved substantially on a range of practical tasks.</p><p>Given a query, CBR-KBQA uses a neural retriever to retrieve other similar queries (and their logical forms) from a case memory (e.g. training set). Next, CBR-KBQA generates a logical form for the given query by learning to reuse various components of the logical forms of the retrieved cases. However, often the generated logical form does not produce the right answer when executed against a knowledge base (KB). This can happen because one or more KB relations needed are never present in the retrieved cases or because KBs are woefully incomplete <ref type="bibr" target="#b49">(Min et al., 2013)</ref>  <ref type="figure">(Figure 1</ref>). To alleviate such cases, CBR-KBQA has an additional revise step that aligns the generated relations in the logical form to the query entities' local neighborhood in the KB. To achieve this, we take advantage of pre-trained relation embeddings from KB completion techniques (e.g. Trans-E <ref type="bibr" target="#b6">(Bordes et al., 2013)</ref>) that learn the structure of the KB.</p><p>It has been shown that neural seq2seq models do not generalize well to novel combinations of previously seen input (Lake and <ref type="bibr" target="#b47">Loula et al., 2018)</ref>. However, CBR-KBQA has the ability to reuse relations from multiple retrieved cases, even if each case contains only partial logic to answer the query. We show that CBR-KBQA is effec-tive for questions that need novel combination of KB relations, achieving competitive results on multiple KBQA benchmarks such as WebQuestionsSP <ref type="bibr" target="#b62">(Yih et al., 2016)</ref>, ComplexWebQuestions (CWQ) (Talmor and <ref type="bibr">Berant, 2018)</ref> and CompositionalFree-baseQuestions (CFQ) <ref type="bibr" target="#b28">(Keysers et al., 2020)</ref>. For example, on the hidden test-set of the challenging CWQ dataset, CBR-KBQA outperforms the best system by over 11% points.</p><p>We further demonstrate that CBR-KBQA, without the need of any further fine-tuning, also generalizes to queries that need relations which were never seen in the training set. This is possible due to CBR-KBQA's nonparametric approach which allows one to inject relevant simple cases during inference, allowing it to reuse new relations from those cases. In a controlled human-in-the-loop experiment, we show that CBR-KBQA can correctly answer such questions when an expert (e.g. database administrator) injects a few simple cases to the case memory. CBR-KBQA is able to retrieve those examples from the memory and use the unseen relations to compose new logical forms for the given query.</p><p>Generalization to unseen KB relations, without any re-training, is out of scope for current neural models. Currently, the popular approach to handle such cases is to re-train or fine-tune the model on new examples. This process is not only time-consuming and laborious but models also suffer from catastrophic forgetting <ref type="bibr" target="#b22">(Hinton and Plaut, 1987;</ref><ref type="bibr" target="#b31">Kirkpatrick et al., 2017)</ref>, making wrong predictions on examples which it previously predicted correctly. We believe that the controllable properties of CBR-KBQA are essential for QA models to be deployed in real-world settings and hope that our work will inspire further research in this direction.</p><p>Recent works such as REALM <ref type="bibr" target="#b20">(Guu et al., 2020)</ref> and RAG <ref type="bibr">(Lewis et al., 2020b)</ref> retrieve relevant paragraphs from a nonparametric memory for answering questions. CBR-KBQA, in contrast, retrieves similar queries w.r.t the input query and uses the relational similarity between their logical forms to derive a logical form for the new query. CBR-KBQA is also similar to the recent retrieve and edit framework <ref type="bibr" target="#b21">(Hashimoto et al., 2018)</ref> for generating structured output. However, unlike us they condition on only a single retrieved example and hence is unlikely to be able to handle complex questions that need reuse of partial logic from multiple questions. Moreover, unlike CBR-KBQA, retrieve and edit does not have a component that can explicitly revise an initially generated output.</p><p>The contributions of our paper are as follows -(a) We present a neural CBR approach for KBQA capable of generating complex logical forms conditioned on similar retrieved questions and their logical forms. (b) Since CBR-KBQA explicitly learns to reuse cases, we show it is able to generalize to unseen relations at test time, when relevant cases are provided. (c) We also show the efficacy of our revise step of CBR-KBQA which allows to correct generated output by aligning it to local neighborhood of the query entity. (d) Lastly, we show that CBR-KBQA significantly outperforms other competitive models on several KBQA benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>This section describes the implementation of various modules of CBR-KBQA. In CBR, a case is defined as an abstract representation of a problem along with its solution. In our KBQA setting, a case is a natural language query paired with an executable logical form. The practical importance of KBQA has led to the creation of an array of recent datasets <ref type="bibr" target="#b66">(Zelle and Mooney, 1996;</ref><ref type="bibr" target="#b5">Bordes et al., 2015;</ref><ref type="bibr">Su et al., 2016;</ref><ref type="bibr" target="#b62">Yih et al., 2016;</ref><ref type="bibr" target="#b68">Zhong et al., 2017a;</ref><ref type="bibr">Ngomo, 2018;</ref><ref type="bibr" target="#b64">Yu et al., 2018;</ref><ref type="bibr">Talmor and Berant, 2018, inter-alia)</ref>. In these datasets, a question is paired with an executable logical form such as SPARQL, SQL, S-expression or graph query. All of these forms have equal representational capacity and are interchangeable <ref type="bibr">(Su et al., 2016)</ref>. <ref type="figure">Figure 2</ref> shows an example of two equivalent logical forms. For our experiments, we consider SPARQL programs as our logical form. Formal definition of task: let q be a natural language query and let K be a symbolic KB that needs to be queried to retrieve an answer list A containing the answer(s) for q. We also assume access to a training set D = {(q 1 , 1 ), (q 2 , 2 ), . . . (q N , N )} of queries and their corresponding logical forms where q i , i represents query and its corresponding logical form, respectively. A logical form is an executable query containing entities, relations and free variables ( <ref type="figure">Figure 2</ref>). CBR-KBQA first retrieves K similar cases D q from D ( ? 2.1). It then generates a intermediate logical form inter by learning to reuse components of the logical forms of the retrieved cases ( ? 2.2). Next, the logical form inter is revised to output the final logical form by aligning to the relations present in the neighborhood subgraph of the query entity to recover from any spurious relations generated in the reuse step ( ? 2.3). Finally, is executed against K and the list of answer entities are returned. We evaluate our KBQA system by calculating the accuracy of the retrieved answer list w.r.t a held-out set of queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Retrieve</head><p>The retrieval module computes dense representation of the given query and uses it to retrieve other similar query representation from a training set. Inspired by the recent advances in neural dense passage retrieval <ref type="bibr" target="#b27">Karpukhin et al., 2020)</ref>, we use a ROBERTA-base encoder to encode each question independently. Also, we want to retrieve questions that have high relational similarity instead of questions which share the same entities (e.g. we prefer to score the query pair (Who is Justin Bieber's brother?, Who is Rihanna's brother?), higher than (Who is Justin Bieber's brother?, Who is Justin Bieber's father?)). To minimize the effect of entities during retrieval, we use a named entity tagger 1 to detect spans of entities and mask them with [BLANK] symbol with a probability p mask , during training. The entity masking strategy has previously been successfully used in learning entity-independent relational representations <ref type="bibr">(Soares et al., 2019)</ref>. The similarity score between two queries is given by the inner product between their normalized vector representations (cosine similarity), where each representation, following standard practice <ref type="bibr" target="#b20">(Guu et al., 2020)</ref>, is obtained from the encoding of the initial [CLS] token of the query.</p><p>Fine-tuning question retriever: In passage retrieval, training data is gathered via distant supervision in which passages containing the answer is marked as a positive example for training. Since in our setup, we need to retrieve similar questions, we use the available logical forms as a source of distant supervision. Specifically, a question pair is weighed by the amount of overlap (w.r.t KB relations) it has in their corresponding logical queries. Following DPR <ref type="bibr" target="#b27">(Karpukhin et al., 2020)</ref>, we ensure there is at least one positive example for each query during training and use a weighted negative log-likelihood loss where the weights are computed by the F 1 score between the set of relations present in the corresponding logical forms. Concretely, let (q 1 , q 2 , . . . , q B ) denote all questions in a minibatch. The loss function is:</p><formula xml:id="formula_0">L = ? i,j w i,j log exp(sim(q i , q j )) j exp(sim(q i , q j ))</formula><p>Here, q i ? R d denotes the vector representation of query q i and sim(q i , q j ) = q i q j . w i,j is computed as the F 1 overlap between relations in the logical pairs of q i and q j . We pre-compute and cache the query representations of the training set D. For query q, we return the top-k similar queries in D w.r.t q and pass it to the reuse module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Reuse</head><p>The reuse step generates an intermediate logical form from the k cases that are fed to it as input from the retriever module. Pre-trained encoderdecoder transformer models such as BART <ref type="bibr" target="#b40">(Lewis et al., 2020a)</ref> and T5 <ref type="bibr" target="#b58">(Raffel et al., 2020)</ref>   <ref type="figure">Figure 2</ref>: An example of a SPARQL logical form for a simple query and its equivalent graph-query. <ref type="bibr" target="#b26">Hwang et al., 2019;</ref><ref type="bibr">Shaw et al., 2020;</ref><ref type="bibr">Suhr et al., 2020)</ref>. We take a similar approach in generating an intermediate logical form conditioned on the retrieved cases. However, one of the core limitation of transformer-based models is its quadratic dependency (in terms of memory), because of full-attention, which severely limits the sequence length it can operate on. For example, BART and T5 only supports sequence length of 512 tokens in its encoder. Recall that for us, a case is a query from the train set and an executable SPARQL program, which can be arbitrarily long.</p><p>To increase the number of input cases, we leverage a recently proposed sparse-attention transformer architecture -BIGBIRD <ref type="bibr" target="#b65">(Zaheer et al., 2020)</ref>. Instead of having each token attend to all input tokens as in a standard transformer, each token attends to only nearby tokens. Additionally, a small set of global tokens attend to all tokens in the input. This reduces the transformer's memory complexity from quadratic to linear, and empirically, BIGBIRD enables us to use many more cases.</p><p>Description of input: The input query q and cases D q = {(q 1 , 1 ), (q 2 , 2 ), . . . (q k , k )} are concatenated on the encoder side.</p><p>Specifically,</p><formula xml:id="formula_1">Input ENC (q, D q ) = q[SEP]q 1 [SEP] 1 , . . . q k [SEP] k ,</formula><p>where [SEP] denotes the standard separator token. Each logical form also contain the KB entity id of each entities in the question (e.g. m.03_r3 for Jamaica in <ref type="figure">Figure 2</ref>). We append the entity id after the surface form of the entity mention in the question string. For example, the query in <ref type="figure">Figure 2</ref> becomes "What do Jamaican m.03_r3 people speak?".</p><p>Training is done using a standard seq2seq crossentropy objective. Large deep neural networks usually benefit from "good" initialization points <ref type="bibr" target="#b15">(Frankle and Carbin, 2019)</ref> and being able to utilize pre-trained weights is critical for seq2seq models. We find it helpful to have a regularization term that minimizes the Kullback-Leibler divergence (KLD) between output softmax layers of (1) when only the query q is presented (i.e not using cases), and (2) when query and cases (D q ) are available <ref type="bibr" target="#b63">(Yu et al., 2013)</ref>. Formally, let f be the seq2seq model, let ? = sof tmax(f (q, D q )) and ? = sof tmax(f (q)) be the decoder's prediction distribution with and without cases, respectively. The following KLD term is added to the seq2seq cross-entropy loss</p><formula xml:id="formula_2">L = L CE (f (q, D q ), l q ) + ? T KLD(?, ? )</formula><p>where ? T ? [0, 1] is a hyper-parameter. Intuitively, this term regularizes the prediction of f (q, D q ) not to deviate too far away from that of the f (q) and we found this to work better than initializing with a model not using cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Revise</head><p>In the previous step, the model explicitly reuses the relations present in D q , nonetheless, there is no guarantee that the query relations in D q will contain the relations required to answer the original query q. This can happen when the domain of q and domain of cases in D q are different even when the relations are semantically similar. For example, in <ref type="figure">Figure 1</ref> although the retrieved relations in NN queries are semantically similar, there is a domain mismatch (person v/s fictional characters). Similarly, large KBs are very incomplete <ref type="bibr" target="#b49">(Min et al., 2013)</ref>, so querying with a valid relation might require an edge that is missing in the KB leading to intermediate logical forms which do not execute.</p><p>To alleviate this problem and to make the queries executable, we explicitly align the generated relations with relations (edges) present in the local neighborhood of the query entity in the KG. We propose the following alignment models:</p><p>Using pre-trained KB embeddings: KB completion is an extensively studied research field <ref type="bibr" target="#b52">(Nickel et al., 2011;</ref><ref type="bibr" target="#b6">Bordes et al., 2013;</ref><ref type="bibr">Socher et al., 2013;</ref><ref type="bibr">Velickovic et al., 2018;</ref><ref type="bibr">Sun et al., 2019b)</ref> and several methods have been developed that learn low dimensional representation of relations such that similar relations are closer to each other in the embedding space. We take advantage of the pre-trained relations obtained from TransE <ref type="bibr" target="#b6">(Bordes et al., 2013)</ref>, a widely used model for KB completion. For each predicted relation, we find the most similar (outgoing or incoming) relation edge (in terms of cosine similarity) that exists in the KB for that entity and align with it. If the predicted edge exists in the KB, it trivially aligns with itself. There can be multiple missing edges that needs alignment ( <ref type="figure">Figure 1</ref>) and we find it more effective to do beam-search instead of greedy-matching the most similar edge at each step.</p><p>Using similarity in surface forms: Similar relations (even across domains) have overlap in their surface forms (e.g. 'siblings' is common term in both 'person.siblings' and 'fic-tional_character.siblings'). Therefore, word embeddings obtained by encoding these words should be similar. This observation has been successfully utilized in previous works (Toutanova and <ref type="bibr">Chen, 2015;</ref><ref type="bibr" target="#b26">Hwang et al., 2019)</ref>. We similarly encode the predicted relation and all the outgoing or incoming edges with ROBERTA-base model. Following standard practices, relation strings are prepended with a [CLS] token and the word pieces are encoded with the ROBERTA-base model and the output embedding of the [CLS] token is considered as the relation representation. Similarity between two relation representations is computed by cosine similarity.</p><p>Our alignment is simple and requires no learning. By aligning only to individual edges in the KB, we make sure that we do not change the structure of the generated LF. We leave the exploration of learning to align single edges in the program to sequence of edges (paths) in the KB as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Data: For all our experiments, the underlying KB is full Freebase containing over 45 million entities (nodes) and 3 billion facts (edges) <ref type="bibr" target="#b4">(Bollacker et al., 2008)</ref>. We test CBR-KBQA on three datasets -We-   <ref type="bibr">Berant, 2018)</ref> and CFQ <ref type="bibr" target="#b28">(Keysers et al., 2020)</ref>. Please refer to ?A.1 for a detailed description of each datasets. Hyperparameters: All hyperparameters are set by tuning on the valdation set for each dataset. We initialize our retriever with the pre-trained ROBERTAbase weights. We set p mask = 0.2 for CWQ and 0.5 for the remaining datasets. We use a BIGBIRD generator network with 6 encoding and 6 decoding sparse-attention layers, which we initialize with pre-trained BART-base weights. We use k=20 cases and decode with a beam size of 5. Initial learning rate is set to 5 ? 10 ?5 and is decayed linearly through training. Further details for the EMNLP reproducibility checklist is given in ?A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Entity Linking</head><p>The first step required to generate an executable LF for a NL query is to identify and link the entities present in the query. For our experiments, we use a combination of an off-the-shelf entity linker and a large mapping of mentions to surface forms. For the off-the-shelf linker, we use a recently proposed high precision entity linker ELQ . To further improve recall of our system, we first identify mention spans of entities in the question by tagging it with a NER 2 system. Next, we link entities not linked by ELQ by exact matching with surface form annotated in FACC1 project <ref type="bibr" target="#b17">(Gabrilovich et al., 2013)</ref>. Our entity linking results are shown in <ref type="table" target="#tab_3">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">KBQA Results</head><p>This section reports the performance of CBR-KBQA on various benchmarks. We report the strict exact match accuracy where we compare the list of predicted answers by executing the generated SPARQL program to the list of gold answers 3 . A question is answered correctly if the two list match exactly. We also report the precision, recall and the F1 score to be comparable to the baselines. Models such as GraftNet <ref type="bibr">(Sun et al., 2018)</ref>   2019a) rank answer entities and return the top entity as answer (Hits@1 in table 1). This is undesirable for questions that have multiple entities as answers (e.g. "Name the countries bordering the U.S.?").</p><p>We also report performance of models that only depend on the query and answer pair during training and do not depend on LF supervision (weaklysupervised setting). Unsurprisingly, models trained with explicit LF supervision perform better than weakly supervised models. Our main baseline is a massive pre-trained seq2seq model with orders of magnitude more number of parameters -T5-11B <ref type="bibr" target="#b58">(Raffel et al., 2020)</ref>. T5 has recently been shown to be effective for compositional KBQA . For each dataset, we fine-tune the T5 model on the query and the LF pairs. <ref type="table">Table 1</ref> reports results of various models on We-bQSP. All reported model except CBR-KBQA and T5-11B directly operate on the KB (e.g. traverse KB paths starting from the query entity) to generate the LF or the answer. As a result, models such as STAGG tend to enjoy much higher recall. On the other hand, much of our logical query is generated by reusing components of similar cases. We also report the results of 'aligning' the LF produced by T5 using our revise step. As shown in <ref type="table">Table 1</ref>, CBR-KBQA outperforms all other models significantly and improves on the strict exact-match accuracy by more than 6 points w.r.t. the best model. Revise step also improves on the performance of T5 suggesting that it is generally applicable. Table 3 reports performance on the hidden test set of CWQ 4 , which was built by extending WebQSP <ref type="bibr">4</ref> The result of our model in the official leaderboard (https://www.tau-nlp.org/ compwebq-leaderboard) is higher (70.4 vs 67.1). This is because the official evaluation script assigns full score if any of the correct answer entities are returned even if there are multiple correct answers for a question. In the paper we report strict exact-match accuracy.  questions with the goal of making a more complex multi-hop questions. It is encouraging to see that CBR-KBQA outperforms all other baselines on this challenging dataset by a significant margin. Finally, we report results on CFQ in <ref type="table" target="#tab_7">Table 4</ref>. On error analysis, we found that on several questions which are yes/no type, our model was predicting the list of correct entities instead of predicting a yes or no. We created a rule-based binary classifier that predicts the type of question (yes/no or other). If the question was predicted as a yes/no, we would output a yes if the length of the predicted answer list was greater than zero and no otherwise. (If the model was already predicting a yes/no, we keep the original answer unchanged). We report results on all the three MCD splits of the dataset and compare with the T5-11B model of  and we find that our model outperforms T5-11B on this dataset as well. It is encouraging to see that CBR-KBQA, even though containing order-of-magnitudes less parameters than T5-11B, outperforms it on all benchmarks showing that it is possible for smaller models with less carbon footprint and added reasoning capabilities to outperform massive pre-trained LMs. <ref type="table">Table 5</ref> show that the revise step is useful for CBR-KBQA on multiple datasets. We also show that the T5 model also benefits from the alignment in revise step with more than 3 points improvement in F1 score on the CWQ dataset. We find that TransE alignment outperforms ROBERTA based alignment, suggesting that graph structure information is more useful than surface form similarity for aligning relations. Moreover, relation names are usually short strings, so they do not provide enough context for LMs to form good representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Efficacy of Revise step</head><p>Next we demonstrate the advantage of the nonparametric property of CBR-KBQA-ability to fix an initial wrong prediction by allowing new cases to be injected to the case-memory. This allows CBR-KBQA to generalize to queries which needs relation never seen during training. Due to space constraints, we report other results (e.g. retriever performance), ablations and other analysis in ?B.  <ref type="table">Table 5</ref>: Impacts of the revise step. We show that the revise step consistently improves the accuracy on We-bQSP and CWQ, especially with the TransE pretrained embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Point-Fixes to Model Predictions</head><p>Modern QA systems built on top of large LMs do not provide us the opportunity to debug an erroneous prediction. The current approach is to finetune the model on new data. However, this process is time-consuming and impractical for production settings. Moreover, it has been shown (and as we will empirically demonstrate) that this approach leads to catastrophic forgetting where the model forgets what it had learned before. <ref type="bibr" target="#b48">(McCloskey and Cohen, 1989;</ref><ref type="bibr" target="#b31">Kirkpatrick et al., 2017)</ref>. On the other hand, CBR-KBQA adopts a nonparametric approach and allows inspection of the retrieved nearest neighbors for a query. Moreover, one could inject a new relevant case into the case-memory (KNN-index), which could be picked up by the retriever and used by the reuse module to fix an erroneous prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Performance on Unseen Relations</head><p>We consider the case when the model generates a wrong LF for a given query. We create a controlled setup by removing all queries from the training set of WebQSP which contain the (people.person.education) relation. This led to a removal of 136 queries from the train set and ensured that the model failed to correctly answer the 86 queries (held-out) in the test set which contained the removed relation in its LF. We compare to a baseline transformer model (which do not use cases) as our baseline. As shown in <ref type="table" target="#tab_11">Table 6</ref>, both baseline and CBR-KBQA do not perform well without any relevant cases since a required KB relation was missing during training. Next, we add the 136 training instances back to the training set and recompute the KNN index. This process involves encoding the newly added NL queries and recomputing the KNN index, a process which is computationally much cheaper than re-training the model again. Row 5 in <ref type="table" target="#tab_11">Table 6</ref> What colors do the school where Donald Stanley Marshall is grad student use?  shows the new result. On addition of the new cases, CBR-KBQA can seamlessly use them and copy the unseen relation to predict the correct LF, reaching 70.6% accuracy on the 86 held-out queries.</p><p>In contrast, the baseline transformer must be fine-tuned on the new cases to handle the new relation, which is computationally more expensive than adding the cases to our index. Moreover, just finetuning on the new instances leads to catastrophic forgetting as seen in row 2 of <ref type="table" target="#tab_11">Table 6</ref> where the baseline model's performance on the initial set decreases drastically. We find it necessary to carefully fine-tune the model on new examples alongside original training examples (in a 1:2 proportion). However, it still converges to a performance which is lower than its original performance and much lower than the performance of CBR-KBQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Human-in-the-Loop Experiment</head><p>During error analysis, we realized that there are queries in the test set of WebQSP that contain KB relations in their LFs which were never seen during training 5 . That means models will never be able to predict the correct LF for the query because of the unseen relation. We conduct a human-inthe-loop experiment <ref type="figure" target="#fig_0">(Figure 3)</ref>     NL query paired with a program which only contain one KB relation.  <ref type="bibr" target="#b5">(Bordes et al., 2015)</ref> which is a large collection of NL queries that can be a mapped to a single KB edge. <ref type="table" target="#tab_7">Table 14</ref> in Appendix D shows various statistics of the missing relations and the number of cases added by humans and from SimpleQuestions. The cases are added to the original KNN-index. By adding a few cases, the performance increases from 0 to 36 F1 (Table 7) without requiring any training. Note unlike the previous controlled experiment in ?3.4.1, we add around 3.87 cases for each unseen relation 6 . Importance of this result: We believe that flexibility of models to fix predictions (without training) is an important desideratum for QA systems deployed in production settings and we hope our results will inspire future research in this direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Further Analysis</head><p>We analyze questions in the evaluation set which require novel combinations of relations never seen in 6 In ?3.4.1, we added 136 cases (v/s 3.87) for one relation. This is why the accuracy in <ref type="table" target="#tab_11">Table 6</ref>     <ref type="table" target="#tab_13">Table 8</ref> shows that our model outperforms the competitive T5 baseline. Also as we saw in the last section, our model is able to quickly adapt to relations never seen in the training set altogether by picking them up from newly added cases. We also compare with a model with the same reuse component of CBR-KBQA but is trained and tested without retrieving any cases from the casememory <ref type="table" target="#tab_16">(Table 9</ref>). Even though the baseline model is competitive, having similar cases is beneficial, especially for the WebQSP dataset. We also report the results when we only use cross-entropy loss for training the BIGBIRD model and not the KLdivergence term. <ref type="table" target="#tab_17">Table 10</ref> reports the performance of CBR-KBQA using different number of retrieved cases. It is encouraging to see the the performance improves with increasing number of cases. evant paragraphs from a nonparametric memory. In contrast, our CBR approach retrieves similar queries and uses their logical forms to derive a new solution. Recently <ref type="bibr" target="#b42">Lewis et al. (2020c)</ref> proposed a model that finds a nearest neighbor (NN) question in the training set and returns the answer to that question. While this model would be helpful if the exact question or its paraphrase is present in the training set, it will not generalize to other scenarios. CBR-KBQA, on the other hand, learns to reason with the retrieved programs of multiple retrieved NN queries and generates a new program for the given query and hence is able to generalize even if the query paraphrase is not present in the train set. Retrieve and edit: CBR-KBQA shares similarities with the RETRIEVE-AND-EDIT framework <ref type="bibr" target="#b21">(Hashimoto et al., 2018)</ref> which utilizes retrieved nearest neighbor for structured prediction. However, unlike our method they only retrieve a single nearest neighbor and will unlikely be able to generate programs for questions requiring relations from multiple nearest neighbors. Generalizing to unseen database schemas: There has been work in program synthesis that generates SQL programs for unseen database schemas <ref type="bibr" target="#b45">Lin et al., 2020)</ref>. However, these work operate on web or Wikipedia tables with small schemas. For example, in WikiTable-Questions <ref type="bibr" target="#b54">(Pasupat and Liang, 2015)</ref> the average. number of columns in a table is 5.8 and in Spider dataset <ref type="bibr" target="#b64">(Yu et al., 2018)</ref>, the average number of columns is 28.1. On the other hand, our model has to consider all possible Freebase relations (in thousands). Previous work perform schema-aware encoding which is not possible in our case because of the large number of relations. The retrieve step of CBR-KBQA can be seen as a pruning step which narrows the number of candidate relations by retrieving relevant questions and their logical forms. Case-based Reasoning for KB completion: Recently, a CBR based KB reasoning approach was proposed by <ref type="bibr">Das et al. (2020a,b)</ref>. They retrieve similar entities and then find KB reasoning paths from them. However, their approach does not handle complex natural language queries and only operate on structured triple queries. Additionally, the logical forms handled by our model have much more expressive power than knowledge base paths. Program Synthesis and Repair: Repairing / revising generated programs has been studied in the field of program synthesis. For example, prior work repairs a program based on syntax of the underlying language <ref type="bibr" target="#b37">(Le et al., 2017)</ref>, by generating sketches <ref type="bibr" target="#b24">(Hua et al., 2018)</ref>. More recently, <ref type="bibr" target="#b61">Gupta et al. (2020)</ref> proposes a framework in which they use a program debugger to revise the program generated by a neural program synthesizer. However, none of these works take advantage of the similarity between semantic relations present in the knowledge base, and hence, unlike us, they do not use embeddings of similar relation to align relations. More generally, many prior efforts have employed neural models to generate SPARQL-like code for semantic parsing <ref type="bibr" target="#b13">(Dong and Lapata, 2016;</ref><ref type="bibr" target="#b2">Balog et al., 2016;</ref><ref type="bibr" target="#b68">Zhong et al., 2017a)</ref>, SQL queries over relational databases <ref type="bibr" target="#b69">(Zhong et al., 2017b)</ref>, program-structured neural network layouts <ref type="bibr" target="#b1">(Andreas et al., 2016)</ref>, or even proofs for mathematical theorems <ref type="bibr" target="#b57">(Polu and Sutskever, 2020)</ref>. Our work differs in our use of the programs of multiple retrieved similar queries to generate the target program. K-NN approach in other NLP applications: <ref type="bibr" target="#b30">Khandelwal et al. (2020)</ref> demonstrate improvements in language modeling by utilizing explicit examples from training data. There has been work in machine translation <ref type="bibr" target="#b18">Gu et al., 2018;</ref><ref type="bibr" target="#b29">Khandelwal et al., 2021)</ref> that uses nearest neighbor translation pair to guide the decoding process. Recently, <ref type="bibr" target="#b23">Hossain et al. (2020)</ref> proposed a retrieve-edit-rerank approach for text generation in which each retrieved candidate from the training set is edited independently and then re-ranked. In contrast, CBR-KBQA generates the program jointly from all the retrieved cases and is more suitable for questions which needs copying relations from multiple nearest neighbors. Please refer to ( ?E) for further related work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Limitations and Future Work</head><p>To the best of our knowledge, we are the first to propose a neuralized CBR approach for KBQA. We showed that our model is effective in handling complex questions over KBs, but our work also has several limitations. First, our model relies on the availability of supervised logical forms such as SPARQL queries, which can be expensive to annotate at scale. In the future, we plan to explore ways to directly learn from question-answer pairs <ref type="bibr" target="#b3">(Berant et al., 2013;</ref><ref type="bibr" target="#b44">Liang et al., 2016)</ref>. Even though, CBR-KBQA is modular and has several advantages, the retrieve and reuse components of our model are trained separately. In future, we plan to explore avenues for end to end learning for CBR.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Hyperparameters</head><p>The WebQSP dataset does not contain a validation split, so we choose 300 training instances to form the validation set. We use grid-search (unless explicitly mentioned) to set the hyperparameters listed below. Case Retriever: We initialize our retriever with the pre-trained ROBERTA-base weights. We set the initial learning rate to 5 ? 10 ?5 and decay it linearly throughout training. We evaluate the retriever based on the percentage of gold LF relations in the LFs of the top-k retrieved cases (recall@k). We train for 10 epochs and use the best checkpoint based on recall@20 on the validation set. We set train and validation batch sizes to 32. For p mask , we try values from <ref type="bibr">[0, 0.2, 0.4, 0.5, 0.7, 0.9, 1]</ref>. When training the retriever, we found p mask = 0.2 works best for COMPLEXWEBQUES-TIONS and p mask = 0.5 for the remaining datasets.</p><p>Seq2Seq Generator: We use a BIGBIRD generator network with 6 encoding and 6 decoding sparse-attention layers, which we initialize with</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Validation Acc WebQSP 71.5 CWQ 82.8 CFQ 69.9 <ref type="table" target="#tab_3">Table 12</ref>: Validation set accuracy of models corresponding to the results reported in the paper pre-trained BART-base weights. We set the initial learning rate to 5 ? 10 ?5 and decay it linearly throughout training. Accuracy after the execution of generated programs on the validation set is used to select the optimal setting and model checkpoint.</p><p>For ? T , we perform random search in range [0, 1]. We finally use ? T =1.0 for all datasets. For k (number of cases), we search over the values <ref type="bibr">[1,</ref><ref type="bibr">3,</ref><ref type="bibr">5,</ref><ref type="bibr">7,</ref><ref type="bibr">10,</ref><ref type="bibr">20]</ref>. For all datasets, we use k=20 cases and decode with a beam size of 5 for decoding. The WebQSP model was trained for 15K gradient steps and all other models were trained for 40K gradient steps.</p><p>Computing infrastructure: We perform our experiments on a GPU cluster managed by SLURM. The case retriever was trained and evaluated on NVIDIA GeForce RTX 2080 Ti GPU. The models for the Reuse step were trained and evaluated on NVIDIA GeForce RTX 8000 GPUs. Revise runs on NVIDIA GeForce RTX 2080 Ti GPU when using ROBERTA for alignment and runs only on CPU when using TRANSE. We report validation set scores in <ref type="table" target="#tab_3">Table 12</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Further Experiments and Analysis B.1 Performance of Retriever</head><p>We compare the performance of our trained retriever with a ROBERTA-base model. We found that ROBERTA model even without any fine-tuning performs well at retrieval. However, fine-tuning ROBERTA with our distant supervision objective improved the overall recall, e.g., from 86.6% to 90.4% on WEBQUESTIONSSP and from 94.8% to 98.4% on CFQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Performance on Unseen Entities</head><p>In <ref type="table" target="#tab_12">Table 7</ref> we showed CBR-KBQA is effective for unseen relations. But what about unseen entities in the test set?. On analysis we found that in WebQSP, CBR-KBQA can copy unseen entities correctly 86.8% (539/621) from the question. This is +1.9% improvement from baseline trans-former model which is able to copy correctly 84.9% (527/621) of the time. Note that unseen entities can be copied from the input NL query and we do not need additional cases to be injected to KNN index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Analysis of the Revise Step</head><p>In the revise step, we attempt to fix programs predicted by our reuse step that did not execute on the knowledge base. The predicted program can be syntactically incorrect or enforce conditions that lead to an unsatisfiable query. In our work, we focus on predicted programs that can be fixed by aligning clauses to relations in the local neighborhood of query entities. We give examples of successful alignments <ref type="table" target="#tab_11">Table 16</ref> as well as failed attempts at alignment <ref type="table" target="#tab_12">Table 17</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Details on Held-Out Experiments</head><p>In this section, we include more details about our held-out experiment described in section 3.4.1. The goal of this experiment is to show that our approach can generalize to unseen relations without requiring any further training of the model. This is a relevant setting to explore, because real-world knowledge bases are often updated with new kinds of relations, and we would like KBQA systems that adapt to handle new information with minimal effort.</p><p>We explicitly hold-out all questions containing a particular relation from the datasets. <ref type="table" target="#tab_5">Table 13</ref> shows the relation type and the number of questions that are removed as a result of removing the relation.    <ref type="bibr" target="#b5">(Bordes et al., 2015)</ref>. Sim-pleQuestions (SQ) is a large dataset containing more than 100K NL questions that are 'simple' in nature -i.e. each NL query maps to a single relation (fact) in the Freebase KB. For each missing relation type, we try to find questions in the SQ dataset that can be mapped to the missing relation. However, even SQ has missing coverage in which case, we manually generate a question and its corresponding SPARQL query by reading the description of the relation. <ref type="table" target="#tab_7">Table 14</ref> shows the number of questions in the evaluation set which at least has a relation never seen during training and also the number of cases that has been added. For example, we 7 were able to collect 292 questions from SQ and we manually created 72 questions for WebQSP. Overall, we add 3.87 new cases per query relation for WebQSP. <ref type="table" target="#tab_14">Table 15</ref> shows some example of cases added manually or from SQ. We look up entity ids for entities from the FACC1 alias table ( ?3.1). Also note, that since we only add questions which are simple in nature, the corresponding SPARQL query can be easily constructed from the missing relation type and the entity id.</p><p>Importance of this result: Through this experiment, we demonstrate two important properties of our model -interpretability and controllability. Database schemas keep changing and new tables keep getting added to a corporate database. When our QA system gets a query wrong, by looking at the retrieved K-nearest neighbors, users can deter-    <ref type="figure">Figure 5</ref>: An example query where our approach correctly utilizes added H-I-L-T cases mine (interpretability) that the required relation is not present in the training set. By adding few cases for the new relations, they can query the DB for similar questions, without needing to train the QA system (controllability). Current black-box NLP models are not capable of doing such point-fixes and our experiment is an initial attempt towards building such systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Further Related Work</head><p>KNN approach in other NLP applications (continued): Wiseman and Stratos (2019) achieved accurate sequence labeling by explicitly and only copying labels from retrieved neighbors. NN models have been used in a numbe NLP applications such as POS tagging <ref type="bibr" target="#b9">(Daelemans et al., 1996)</ref>. An-other recent line of work use training examples at test time to improve language generation <ref type="bibr" target="#b59">(Weston et al., 2018;</ref><ref type="bibr" target="#b53">Pandey et al., 2018;</ref><ref type="bibr" target="#b7">Cao et al., 2018;</ref><ref type="bibr" target="#b55">Peng et al., 2019)</ref>. <ref type="bibr" target="#b25">Hua et al. (2020)</ref> recently proposed a meta-learning approach which utilizes cases retrieved w.r.t. the similarity of the input. However, their main goal is to learn a better parametric model (retriever and generator) from neighboring cases rather than composing and fixing cases to generate answers at test time.</p><p>Question Decomposition One strategy to answer a complex question is to first break it down into simpler subquestions, each of which can be viewed as a natural language program describing how to answer the question. This approach has been shown to be effective as far back as IBM Watson <ref type="bibr" target="#b14">(Ferrucci et al., 2010)</ref> to more recent systems for answering questions about text <ref type="bibr" target="#b50">Min et al., 2019;</ref><ref type="bibr" target="#b56">Perez et al., 2020;</ref><ref type="bibr" target="#b61">Wolfson et al., 2020)</ref> or knowledge bases (Talmor and <ref type="bibr">Berant, 2018)</ref>. These prior studies do not leverage case-based reasoning when generating decompositions and thus may also benefit from similar techniques as proposed in our work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>An expert point-fixes a model prediction by adding a simple case to the KNN index. Initial prediction was incorrect as no query with the relation (educa-tional_institution.colors) was present in the train set. CBR-KBQA retrieves the case from the KNN index and fixes the erroneous prediction without requiring any re-training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>An example query where our approach correctly utilizes added H-I-L-T cases in the SimpleQuestions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Entity linking performance on various datasets bQSP (Yih et al., 2016), CWQ (Talmor and</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Performance on the hidden test set of CWQ.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Performance (accuracy) on the CFQ dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>in which users add simple 'cases' to point-fix erroneous predictions of CBR-KBQA for those queries. A simple case is a</figDesc><table><row><cell>Scenario</cell><cell cols="2">Initial Set Held-Out</cell></row><row><cell>Transformer</cell><cell>59.6</cell><cell>0.0</cell></row><row><cell>+ Fine-tune on additional cases only (100 gradient steps)</cell><cell>1.3</cell><cell>76.3</cell></row><row><cell>+ Fine-tune on additional cases and original data (300 gradient steps)</cell><cell>53.1</cell><cell>57.6</cell></row><row><cell>CBR-KBQA (Ours)</cell><cell>69.4</cell><cell>0.0</cell></row><row><cell>+ Adding additional cases to index (0 gradient steps; 2 sec)</cell><cell>69.4</cell><cell>70.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Robustness and controllability of our method against black-box transformers. CBR-KBQA can easily and quickly adopt to new relations given cases about it, whereas heavily parameterized transformer is not stable, and can undergo catastrophic forgetting when we try to add new relation information intro its parameters.</figDesc><table><row><cell>Scenario</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>Acc</cell></row><row><cell>CBR-KBQA (Ours)</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>+ additional cases</cell><cell cols="4">36.54 38.59 36.39 32.89</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell cols="5">: Results for H-I-T-L experiment. After adding a few</cell></row><row><cell cols="5">cases, we see that we can get the accuracy of OOV questions to</cell></row><row><cell cols="5">improve considerably, without needing to re-train the model.</cell></row><row><cell>Data</cell><cell># Total Q</cell><cell># Q that need comp. reasoning</cell><cell cols="2"># Correct T5 CBR</cell></row><row><cell>CWQ</cell><cell>3531</cell><cell>639</cell><cell>205</cell><cell>270</cell></row><row><cell>CFQ</cell><cell>11968</cell><cell>6541</cell><cell cols="2">3351 3886</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc>We compare the performance of models on questions that need novel combinations of relations not seen during training.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 15</head><label>15</label><figDesc></figDesc><table><row><cell>(Appendix D) shows</cell></row><row><cell>some example of such cases. Because of the simple</cell></row><row><cell>nature of the questions, these cases can be created</cell></row><row><cell>manually (by a user who is knowledgeable about</cell></row><row><cell>the KB schema) or automatically curated from data</cell></row><row><cell>sources such as SimpleQuestions</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>is higher w.r.tTable 7.</figDesc><table><row><cell></cell><cell cols="2">WebQSP CWQ</cell></row><row><cell>Baseline (K = 0)</cell><cell>67.2</cell><cell>65.8</cell></row><row><cell>CBR-KBQA (K = 20)</cell><cell>69.9</cell><cell>67.1</cell></row><row><cell>-KL term in loss</cell><cell>68.1</cell><cell>66.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 9</head><label>9</label><figDesc></figDesc><table><row><cell cols="2">: Ablation experiment with a baseline model</cell></row><row><cell cols="2">that do not use cases and also when the KL divergence</cell></row><row><cell cols="2">term ( ?2.2) is not used in loss function of reuse step .</cell></row><row><cell cols="2">The numbers denote exact match accuracy.</cell></row><row><cell cols="2"># nearest neighbors Accuracy</cell></row><row><cell>K = 0</cell><cell>67.20</cell></row><row><cell>K = 1</cell><cell>68.45</cell></row><row><cell>K = 10</cell><cell>69.23</cell></row><row><cell>K = 20</cell><cell>69.98</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 10 :</head><label>10</label><figDesc>Performance on WebQSP on varying number of nearest neigbors the training set. This means, in order for our model to answer these questions correctly, it would have to retrieve relevant nearest neighbor (NN) questions from the training set and copy the required relations from the logical form of multiple NN queries.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 11</head><label>11</label><figDesc></figDesc><table><row><cell>: Dataset statistics</cell></row><row><cell>A EMNLP Reproducibility Checklist</cell></row><row><cell>A.1 Data</cell></row><row><cell>WebQSP contains 4737 NL questions belonging to</cell></row><row><cell>56 domains covering 661 unique relations. Most</cell></row><row><cell>questions need up to 2 hops of reasoning, where</cell></row><row><cell>each hop is a KB edge. COMPLEXWEBQUES-</cell></row><row><cell>TIONS (CWQ) is generated by extending the We-</cell></row><row><cell>bQSP dataset with the goal of making it a more</cell></row><row><cell>complex multi-hop dataset. There are four types of</cell></row><row><cell>questions: composition (45%), conjunction (45%),</cell></row><row><cell>comparative (5%), and superlative (5%). Answer-</cell></row><row><cell>ing these questions requires up to 4 hops of rea-</cell></row><row><cell>soning in the KB, making the dataset challenging.</cell></row><row><cell>Compositional Freebase Questions (CFQ) is a re-</cell></row><row><cell>cently proposed benchmark explicitly developed</cell></row><row><cell>for measuring compositional generalization. For all</cell></row><row><cell>the datasets above, the logical form (LF) for each</cell></row><row><cell>NL question is a SPARQL query that can be exe-</cell></row><row><cell>cuted against the Freebase KB to obtain the answer</cell></row><row><cell>entity.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 13 :ns:common.topic.notable_types ?x Initial Prediction Who invented the telephone? SELECT DISTINCT ?x WHERE telephone ns:base.argumentmaps.original_idea.innovator ?x Model prediction after adding cases Expert adds relevant simple case to the KNN index SELECT DISTINCT ?x WHERE TCP/IP ns:base.argumentmaps.original_idea.innovator ?x</head><label>13</label><figDesc>Relation type and the corresponding number of NL queries that are held-out.</figDesc><table><row><cell>D Details on Automated Case Collection</cell></row><row><cell>and Human-in-the-Loop Experiments</cell></row><row><cell>While conducting analysis, we also noticed that</cell></row><row><cell>WebQSP has queries in the test set for which the</cell></row><row><cell>required relations are never present in the training</cell></row><row><cell>set. This gives us an opportunity to conduct real</cell></row><row><cell>human-in-the-loop experiments to demonstrate the</cell></row><row><cell>advantage of our model. To add more cases, we</cell></row><row><cell>resort to a mix of automated data collection and</cell></row><row><cell>human-in-the-loop strategy. For each of the miss-</cell></row><row><cell>ing relation, we first try to find NL queries present</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head></head><label></label><figDesc>Cases Added via Dataset # missing relations # questions H-I-T-L SimpleQuestions Avg. # cases per relation</figDesc><table><row><cell>WebQSP</cell><cell>94</cell><cell>79</cell><cell>72</cell><cell>292</cell><cell>3.87</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 14 :</head><label>14</label><figDesc>Number of questions in the evaluation set that needs a relation which is not seen in the training set. Note that, there can be multiple relations in a question that might not be seen during training. The last two columns show the number of cases added both via human-in-the-loop (H-I-T-L) annotation and automatically from SimpleQuestions dataset. where { m.0g_3r base.argumentmaps.original_idea.innovator ?x .} Manual what area is wrvr broadcated in? select ?x where { m.025z9rx broadcast.broadcast.area_served ?x .} SQ Where are Siamese cats originally from? select ?x where { m.012ts8 biology.animal_breed.place_of_origin ?x .} Manual</figDesc><table><row><cell>NL Query</cell><cell>SPARQL</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 15 :Model prediction after adding cases Expert adds relevant simple case to the KNN index</head><label>15</label><figDesc>Examples of few added questions and their corresponding SPARQL queries. Notice that the SPARQL queries are very simple to create once we know the name of the missing relation. The source column indicate whether the question was manually created or automatically added from Simple Questions (SQ) dataset.</figDesc><table><row><cell>Initial Prediction</cell><cell></cell></row><row><cell>What international</cell><cell>SELECT DISTINCT ?x WHERE</cell></row><row><cell>Organisations is the US a member of?</cell><cell>US ns:organization.organization_member.member_of ?y . ?y ns:organization.organization_membership.organization ?x</cell></row><row><cell cols="2">SELECT DISTINCT ?x WHERE</cell></row><row><cell cols="2">China ns:organization.organization_member.member_of ?y .</cell></row><row><cell cols="2">?y ns:organization.organization_membership.organization</cell></row><row><cell>?x</cell><cell></cell></row></table><note>What international organizations is China part of? SELECT DISTINCT ?x WHERE China ns:organization.organization.headquarters ?y ?y ns:location.mailing_address.citytown ?x</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://cloud.google.com/ natural-language</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://cloud.google.com/ natural-language3  We generate the gold answer entities by executing the gold SPARQL query against our Freebase KB</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">There are 94 different unseen relations in test set.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Related WorkRetrieval augmented QA models<ref type="bibr" target="#b8">(Chen et al., 2017;</ref><ref type="bibr" target="#b20">Guu et al., 2020;</ref> Lewis et al., 2020b)  augments a reader model with a retriever to find rel-</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">The H-I-T-L case addition was done by 2 graduate students in the lab.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Prof. Yu Su and Yu Gu (Ohio State  University)  for their help in setting up the Freebase server, Andrew Drozdov, Kalpesh Krishna, Subendhu Rongali and other members of the UMass IESL and NLP groups for helpful discussion and feedback. RD and DT are funded in part by the Chan Zuckerberg Initiative under the project Scientific Knowledge Base Construction and in part by IBM Congitive Horizons Network (CHN). EP is grateful for support from the NSF Graduate Research Fellowship and the Open Philanthropy AI Fellowship. The work reported here was performed in part by the Center for Data Science and the Center for Intelligent Information Retrieval, and in part using high performance computing equipment obtained under a grant from the Collaborative R&amp;D Fund managed by the Massachusetts Technology Collaborative.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Comments:</p><p>The original prediction has missing clauses so alignment produces more answers than target program </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Case-based reasoning: Foundational issues, methodological variations, and system approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnar</forename><surname>Aamodt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enric</forename><surname>Plaza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note>AI communications</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural module networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">L</forename><surname>Gaunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01989</idno>
		<title level="m">Deepcoder: Learning to write programs</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Large-scale simple question answering with memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02075</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neurips</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Retrieve, rerank and rewrite: Soft template based neural summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mbt: A memory-based part of speech tagger-generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Zavrel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Berck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Gillis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WVLC</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-step retrieverreader interaction for scalable open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shehzaad</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simple approach to case-based reasoning in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameya</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shehzaad</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AKBC</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Probabilistic case-based reasoning for open-world knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameya</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Monath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Language to logical form with neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In ACL</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Building watson: An overview of the deepqa project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gondek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">A</forename><surname>Kalyanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">William</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Prager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nico</forename><surname>Schlaefer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Welty</surname></persName>
		</author>
		<idno type="DOI">10.1609/aimag.v31i3.2303</idno>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="59" to="79" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The lottery ticket hypothesis: Finding sparse, trainable neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Carbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Compositional generalization in semantic parsing: Pre-training vs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Furrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Marc Van Zee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sch?rli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.08970</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">specialized architectures. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Facc1: Freebase annotation of clueweb corpora, version 1 (release date 2013-06-26</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>format version 1, correction level 0</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Search engine guided neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">K</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Xinyun Chen, and Dawn Song. 2020. Synthesize, execute and debug: Learning to repair for neural program synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavi</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">Ebert</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neurips</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Realm: Retrievalaugmented language model pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A retrieve-and-edit framework for predicting structured outputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tatsunori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Oren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neurips</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using fast weights to deblur old memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David C</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Plaut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth annual conference of the Cognitive Science Society</title>
		<meeting>the ninth annual conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Simple and effective retrieve-editrerank text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nabil</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Towards practical program repair with on-demand candidate generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinru</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengshi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarfraz</forename><surname>Khurshid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">international conference on software engineering</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="12" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Retrieve, program, repeat: complex knowledge base question answering via alternate meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuncheng</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan-Fang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guilin</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3679" to="3686" />
		</imprint>
	</monogr>
	<note>International Joint Conference on Artificial Intelligence 2020</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonseok</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyeong</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghyun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01069</idno>
		<title level="m">A comprehensive exploration on wikisql with table-aware word contextualization</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Measuring compositional generalization: A comprehensive method on realistic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Sch?rli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hylke</forename><surname>Buisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Furrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergii</forename><surname>Kashubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Momchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danila</forename><surname>Sinopalnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Stafiniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tibor</forename><surname>Tihon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Tsarkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Marc Van Zee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bousquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Nearest neighbor machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generalization through memorization: Nearest neighbor language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kieran</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>PNAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Maintaining organization in a dynamic long-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Janet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kolodner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Generalization without systematicity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brenden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Query graph generation for answering multi-hop complex questions from knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunshi</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Knowledge base question answering with topic units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunshi</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Problem solving in a natural task as a function of experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Juliana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janet</forename><forename type="middle">L</forename><surname>Lancaster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kolodner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Georgia Tech CS Department</title>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">S3: syntax-and semantic-guided repair synthesis via programming by examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan-Bach D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duc-Hiep</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><forename type="middle">Le</forename><surname>Goues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Willem</forename><surname>Visser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Software Engineering</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Cbr in context: The present and future. Case-based reasoning: Experiences, lessons, and future directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leake</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Deep learning. nature</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Retrieval-augmented generation for knowledge-intensive nlp tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandara</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>K?ttler</surname></persName>
		</author>
		<imprint>
			<pubPlace>Mike Lewis, Wen-tau Yih, Tim Rockt?schel</pubPlace>
		</imprint>
	</monogr>
	<note>et al. 2020b.. In Neurips</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Question and answer test-train overlap in open-domain question answering datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.02637</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient one-pass end-to-end entity linking for questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Belinda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kenneth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Forbus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.00020</idno>
		<title level="m">Neural symbolic machines: Learning semantic parsers on freebase with weak supervision</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Bridging textual and tabular data for crossdomain text-to-sql semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Xi Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Nl2bash: A corpus and semantic parser for natural language interface to the linux operating system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglong</forename><surname>Xi Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael D</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ernst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Rearranging the familiar: Testing compositional generalization in recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><surname>Loula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brenden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP Blackbox NLP Workshop</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Catastrophic interference in connectionist networks: The sequential learning problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Psychology of learning and motivation</title>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction with an incomplete knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gondek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Multi-hop reading comprehension through question decomposition and rescoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1613</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6097" to="6109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">2018. 9th challenge on question answering over linked data (qald-9</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>language</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Volker Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Exemplar encoder-decoder for neural conversation generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danish</forename><surname>Contractor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachindra</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Text generation with exemplar-based adaptive decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Unsupervised question decomposition for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.713</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8864" to="8880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Generative language modeling for automated theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Polu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Retrieve and refine: Improved sequence generation models for dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ConvAI Workshop EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Label-agnostic sequence labeling by copying nearest neighbors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Break it down: A question understanding benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Wolfson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mor</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Deutch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="183" to="198" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The value of semantic parse labeling for knowledge base question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jina</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Kl-divergence regularized deep neural network adaptation for improved large vocabulary speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Seide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingning</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanelle</forename><surname>Roman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Big bird: Transformers for longer sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guru</forename><surname>Guruganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinava</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Ontanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Ravula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>In Neurips</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NCAI</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Guiding neural machine translation with retrieved translation pieces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Graham Neubig, and Satoshi Nakamura</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.00103</idno>
		<title level="m">Seq2sql: Generating structured queries from natural language using reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<title level="m">Seq2sql: Generating structured queries from natural language using reinforcement learning. CoRR, abs/1709.00103. WebQSP Question: when did kaley cuoco m.03kxp7 join charmed m.01f3p_ ? Predicted SPARQL: SELECT DISTINCT ?x WHERE { ns:m.03kxp7 ns:tv.tv_character.appeared_in_tv_program ?y . ?y ns:tv.regular_tv_appearance.from ?x . ?y ns:tv.regular_tv_appearance.series ns:m.01f3p_ . } Ground-truth SPARQL: SELECT DISTINCT ?x WHERE { ns:m.03kxp7 ns:tv.tv_actor.starring_roles ?y . ?y ns:tv.regular_tv_appearance.from ?x . ?y ns:tv.regular_tv_appearance.s eries ns:m.01f3p_ . } Revised SPARQL: SELECT DISTINCT ?x WHERE { ns:m.03kxp7 ns:tv.tv_actor.starring_roles ?y . ?y ns:tv.regular_tv_appearance.from ?x . ?y ns:tv.regular_tv_appearance.s eries ns:m.01f3p_ . } CWQ Question: What text in the religion which include Zhang Jue m.02gjv7 as a key figure is considered to be sacred m.02vt2rp ? Predicted SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:religion.religion.deities ns:m.02gjv7</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>c ns:religion.religion.texts ?x . . . . benign filters . . . }</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
				<title level="m">SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:religion.religion.notable_figures ns:m.02gjv7 . ?c ns:religion.religion.texts ?x .} Revised SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:religion.religion.notable_figures ns:m.02gjv7 . ?c ns:religion.religion.texts ?x . . . . benign filters . . . } Question: What is the mascot of the educational institution that has a sports team named the North Dakota State Bison m.0c5s26 ? Predicted SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:education.educational_institution.sports_teams ns:m.0c5s26 . ?c ns:education.educational_institution.mascot ?x . } Ground-truth SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:education.educational_institution.sports_teams ns:m.0c41_v . ?c ns:education.educational_institution.mascot ?x . } Revised SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:education.educational_institution.athletics_brand ns:m.0c5s26 . ?c ns:education.educational_institution.mascot ?x . } Comments: The entity linker has tagged the bison as a university symbol</title>
		<imprint/>
	</monogr>
	<note>m.0c5s26) rather than the Bison football team (m.0c41_v). Alignment helps the model recover from this by picking the relation that connects the tagged entity to the university</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
