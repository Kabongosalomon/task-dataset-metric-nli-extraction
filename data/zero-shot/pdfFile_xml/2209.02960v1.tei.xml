<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Difficulty-Net: Learning to Predict Difficulty for Long-Tailed Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-09-07">7 Sep 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saptarshi</forename><surname>Sinha</surname></persName>
							<email>saptarshi.sinha.hx@hitachi.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Hitachi Ltd. Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Ohashi</surname></persName>
							<email>hiroki.ohashi.uo@hitachi.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Hitachi Ltd. Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Difficulty-Net: Learning to Predict Difficulty for Long-Tailed Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-09-07">7 Sep 2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Long-tailed datasets, where head classes comprise much more training samples than tail classes, cause recognition models to get biased towards the head classes. Weighted loss is one of the most popular ways of mitigating this issue, and a recent work has suggested that class-difficulty might be a better clue than conventionally used class-frequency to decide the distribution of weights. A heuristic formulation was used in the previous work for quantifying the difficulty, but we empirically find that the optimal formulation varies depending on the characteristics of datasets. Therefore, we propose Difficulty-Net, which learns to predict the difficulty of classes using the model's performance in a meta-learning framework. To make it learn reasonable difficulty of a class within the context of other classes, we newly introduce two key concepts, namely the relative difficulty and the driver loss. The former helps Difficulty-Net take other classes into account when calculating difficulty of a class, while the latter is indispensable for guiding the learning to a meaningful direction. Extensive experiments on popular long-tailed datasets demonstrated the effectiveness of the proposed method, and it achieved state-of-theart performance on multiple long-tailed datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Despite the outstanding performance of the recent deep learning (DL) models on public datasets, deploying such models in the real world often leads to a performance drop. One of the causes is that the public datasets are usually almost perfectly class-balanced while real-world data are generally long-tailed, where a few classes (called head classes) consist of a significantly larger number of training samples than the rest of the classes (called tail classes). The 'longtailed recognition' research domain particularly aims at addressing this issue.</p><p>Amongst multiple possible strategies to tackle longtailed recognition problems, cost-sensitive learning is one of the most popular and promising strategies. Most cost-  . Different quantifications of class-difficulties perform better than others in different situations (imbalance ratios). The imbalance in the data is calculated as the ratio of the frequency of the most frequent class to that of the least frequent class. We compute class-wise difficulty (dc) using four different functions of class-wise accuracy (ac) for the CDB-CE <ref type="bibr" target="#b30">[31]</ref> loss function and compare their performance on the CIFAR100-LT. Interestingly, the alternate formulations work better than the originally proposed one (dc = 1 ? ac) in many cases. However, the best performing function changes with the imbalance values. This brings us to the question "Which formulation to choose for my imbalanced dataset?" sensitive learning techniques modify the cost function to penalize the model differently for different samples. This modification is generally done by scaling the cost value using different weights, and the research direction is mainly aimed at finding an effective weight-assignment strategy. One simple and intuitive way is to assign weights using the inverse of the class-frequencies. Recently, more sophisticated approaches such as class-balanced loss <ref type="bibr" target="#b6">[7]</ref> and equalization loss <ref type="bibr" target="#b35">[36]</ref> have been proposed. However, most of these approaches give more weights to the tail classes because they assume that tail classes are always the most difficult to learn. Recently Sinha et al. <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref> empirically showed that the above assumption does not always hold true and further claimed that class-difficulty might be a better clue to decide weights.</p><p>While they proposed an intuitive quantification of the class-level difficulties, this quantification is preliminarily determined regardless of the property of a given dataset, and thus may not be optimal in different situations. In fact, we empirically found that multiple quantifications for class-wise difficulty gave comparable or even better results than <ref type="bibr" target="#b30">[31]</ref> as shown in <ref type="figure" target="#fig_1">Figure 1</ref>. This adds the extra tedious task of selecting the appropriate formulation for a given imbalanced data.</p><p>Motivated by recently proposed Meta-Weight-Net (MWN) <ref type="bibr" target="#b28">[29]</ref>, our research aims to address the above issue by meta-learning a simple model, named Difficulty-Net, to predict class-level difficulty scores and then dynamically distribute the weights based on the scores. Such a strategy removes dependence on any prior formulation for class-wise difficulty and lets the model learn any suitable function to compute it. The key difference with MWN is three folds. First, while MWN is a sample-level weighting method, ours is a class-level weighted approach, whose advantage in long-tailed recognition has been revealed in <ref type="bibr" target="#b30">[31]</ref> and also discussed in Sec. 3.2 and Sec. 4.5. Second, we propose to use relative difficulties rather than absolute difficulties that are used in prior works <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31]</ref> so that the other classes' difficulties are also taken into account when determining the difficulty of a class. Third, we propose a new loss function that drives the learning process of Difficulty-Net in a reasonable direction, without which the performance turned out to degrade.</p><p>To summarize, our key contributions are:</p><p>? We propose Difficulty-Net, which learns to predict class-difficulty in a meta-learning framework.</p><p>? We argue that relative difficulty is more important and effective than absolute difficulty, and provide an empirical evidence for the argument.</p><p>? We propose a new loss function, called driver loss, that guides the learning process in a reasonable direction.</p><p>? We conducted extensive experiments on multiple longtail benchmark datasets and achieved state-of-the-art results. In addition, we provide in-depth analysis on the effect and property of the proposed method in comparison to previous works, which revealed the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related works</head><p>Major strategies to tackle the long-tailed recognition can be broadly categorized as data re-sampling methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b31">32]</ref>, metric learning <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b39">40]</ref>, knowledge transfer <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref>, mixture of experts <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b49">50]</ref>, costsensitive learning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b31">32]</ref> and decoupled learning <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b50">51]</ref>.</p><p>Data re-sampling techniques <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34]</ref> try to neutralize the long-tail by under-sampling from head classes or over-sampling from tail classes.</p><p>Undersampling <ref type="bibr" target="#b33">[34]</ref> generally results in poor representation of the head classes, while a straight-forward over-sampling strategy of replicating tail-class samples causes the model to overfit on the repeated samples. Another popular oversampling technique is synthetic data generation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13]</ref> for the tail classes. Certain class-balanced sampling approaches such as class-aware sampling <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b41">42]</ref> and square-root sampling <ref type="bibr" target="#b18">[19]</ref> have been shown to be more effective than using over-or under-sampling. They typically try to increase the sampling rate for the tail classes during training. However, they still result in overfitting due to the repeated sampling of the same samples from tail classes.</p><p>Metric learning methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b48">49]</ref> aim to learn a high-quality feature extractor that preserves interclass and intra-class relationships in the feature space. They achieve this by learning from pairs <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b48">49]</ref> or triplets <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15]</ref> of input samples. Metric learning has been used in long-tailed recognition <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b37">38]</ref> in hope that highquality feature extractor will mitigate the imbalance between head and tail classes. An effective sampling of the sample groups is the key for efficient training in this scheme. However, such sampling strategies come with the risk of under-representation or overfitting, as explained above.</p><p>Knowledge transfer <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47]</ref> in long-tailed recognition tries to transfer knowledge gained from the head classes to the tail classes. They achieve this either by learning modular transformations from few-shot model parameters to many-shot models <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref> or by designing external modules for feature transfer <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b46">47]</ref>. Designing such modules is usually computationally expensive in real-world usecases <ref type="bibr" target="#b18">[19]</ref>.</p><p>Mixture of experts (MoE) <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b51">52]</ref> is an ensemble-based technique where the expert models are trained to gain diverse knowledge. The aggregated knowledge of the experts is either used directly to alleviate the long-tail <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b49">50]</ref> or used to teach a student model for that purpose <ref type="bibr" target="#b44">[45]</ref>. Despite the increasing popularity of this domain, our research focuses on the improvement of a single model as it can then easily be combined with any mixture.</p><p>Cost-sensitive learning can be achieved by logitadjustment loss <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b36">37]</ref> and weighted loss <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref> approaches. Most prior methods distribute these adjustment or weight values on the basis of classfrequencies. Recently, Sinha et al. <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref> showed that class-difficulty is a better metric for the purpose. However, finding an optimal formulation for calculating classdifficulty is not a trivial task as the optimal formulation usually varies depending on datasets as shown in <ref type="figure" target="#fig_1">Figure 1</ref>. Our research builds on the work of Sinha et al. <ref type="bibr" target="#b30">[31]</ref> and tries to remove the requirement of any prior formulation by using meta-learning. Meta-learning <ref type="bibr" target="#b11">[12]</ref> has previously been used in long-tailed recognition to learn <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b26">27]</ref> or predict <ref type="bibr" target="#b28">[29]</ref> sample weights. The closest to our research is Meta-Weight-Net (MWN) <ref type="bibr" target="#b28">[29]</ref>, which learns a model to predict sample-level weights from training loss. Different from them, we use class-level weighting, which is known to be better than sample-level weighting in long-tailed recognition <ref type="bibr" target="#b30">[31]</ref>.</p><p>Recently, Kang et al. <ref type="bibr" target="#b18">[19]</ref> found that decoupling model learning into representation learning and classifier learning helps long-tailed recognition. Since this finding, most works have tried to improve either the datarepresentation <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b45">46]</ref> or the classifier <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b50">51]</ref>. We show that our method also benefits from this framework and achieves state-of-the-art results based on it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Background</head><p>Generally, the prior assumption is that the tail classes are the most difficult to learn for the models. However, it has recently been empirically shown that the number of training instances of a class might not be the best clue to determine its difficulty because some classes are well-represented even with fewer training samples. On the basis of this finding, Sinha et al. <ref type="bibr" target="#b30">[31]</ref> came up with a simple formulation to directly calculate the difficulty of a class from the model's performance. The formulation says that if the model's classification accuracy on a class c is a c , then the difficulty of the class d c can be computed as d c = 1 ? a c . However, we found two lacking points in the formulation. First, as stated in Sec. 1, we found multiple decreasing functions of accuracy a c that outperformed the above formulation in multiple setups. In the meantime, we also found that the best performing formulation varies inconsistently with the data imbalance and thus it is not possible to preliminarily define the best formulation for a given dataset. Second, while the above formulation helps to compute the absolute difficulty of a class, we believe it is more important to compute the difficulty of a class relative to the other classes because it is reasonable to assign a high difficulty score to a class with high accuracy (i.e. easy class) if the other classes have even higher accuracies. For that purpose, all the classes need to be considered when computing the difficulty of a single class, which is not done in <ref type="bibr" target="#b30">[31]</ref>.</p><p>To address these issues, we propose meta-learning the formulation that is most effective for a given dataset, taking relative difficulties into consideration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Meta-learning via Difficulty-Net</head><p>Difficulty-Net design. Given a dataset of C classes, we aim to learn a formulation that can compute the relative difficulty for each class. For this purpose, we design the formulation for class-wise difficulty as</p><formula xml:id="formula_0">d 1 , d 2 , . . . , d C = D({a c } C c=1 ; ?).<label>(1)</label></formula><p>Note that both d c and a c change as the training progresses, but here we omit the notation of training steps for simplicity.</p><p>D is a neural network with parameters ?. In our implementation, we choose D to be a simple MLP model with two hidden layers. The output layer dimension is kept same as the number of classes and a sigmoid activation at the output ensures the difficulty scores to be in the range (0, 1). The input to D are the model's classification accuracies for all C classes. The design of D ensures that while estimating the difficulty for a class, the model's performance on the other classes is also taken into account. We refer to D as 'Difficulty-Net'.</p><p>Meta-learning objective: Suppose a classification problem in which we are provided a training dataset</p><formula xml:id="formula_1">S train = {x i , y i } N i=1</formula><p>, where x i is the i th training sample and y i ? {1, . . . , C} is its corresponding ground truth label. Given a classifier neural network f (x; ?) with learnable parameters ?, our primary objective is to learn the optimal parameters ? * so that f (x; ? * ) provides the minimum classification loss on the training set S train , i.e.</p><formula xml:id="formula_2">? * = arg min ? 1 N N i=1 L(f (x i ; ?), y i ),<label>(2)</label></formula><p>where L computes the loss corresponding to f 's prediction for a given sample and is typically the cross-entropy loss.</p><p>In long-tailed recognition, the training dataset S train is class-imbalanced. In such cases, optimization using Eq. 2 leads to biased learning of ?. To compensate for the imbalance, we modify the learning objective as most weighted loss approaches do, i.e.</p><formula xml:id="formula_3">? * = arg min ? 1 N N i=1 w i L(f (x i ; ?), y i ),<label>(3)</label></formula><p>where w i is the weight assigned to the training sample x i . In our proposed approach, w i is computed by Difficulty-Net D as</p><formula xml:id="formula_4">w i (A C , ?) = D(A C ; ?) yi ,<label>(4)</label></formula><p>where D(A C ; ?) yi is the difficulty score for class y i predicted by Difficulty-Net and A C = {a c } C c=1 is the set of accuracies of f (x; ?) for all C classes, evaluated prior to this calculation. Therefore, the learning objective for ? * is modified as</p><formula xml:id="formula_5">? * (?) = arg min ? 1 N N i=1</formula><p>However, we found that L meta alone is not enough for Difficulty-Net to learn to estimate difficulties from accuracy. Even for 2 classes with very different accuracy values, Difficulty-Net learned using Eq. 6 tends to give similar difficulty scores for both classes. To address this issue, we add another loss component to drive the learning of Difficulty-Net in a practically correct direction. We call this loss 'driver loss' and calculate it as</p><formula xml:id="formula_6">L dr (A C , ?) = 1 C C c=1 ((1 ?? c ) ? D(A C ; ?) c ) 2 ,<label>(7)</label></formula><p>where? c = a c / k a k is the normalized accuracy of class c. The L dr is built on the motivation that Difficulty-Net should learn to give high difficulty scores to a class, if the accuracy of the class is relatively low. Now the parameters ? of Difficulty-Net D are optimized as</p><formula xml:id="formula_7">? * = arg min ? ?L dr (A C , ?) + 1 M M i=1 L meta i (? * (?)),<label>(8)</label></formula><p>where ? is a hyper-parameter controlling the influence of L dr . Note that too high value of ? will simply cause D to always predict class difficulties as d c = 1 ?? c . We ablate over various values of ? in our experiments.</p><p>Learning method. Following <ref type="bibr" target="#b28">[29]</ref>, our meta-learning method is a 3-step process. Given a classifier network f (x; ? t ) and Difficulty-Net D(; ? t ) at time step t, the first step aims to learn intermediate classifier parameter? t b?</p><formula xml:id="formula_8">? t (? t ) ? ? ? t ? ? 1 b b i=1 w i (A C,t , ? t ) ?L(f (x i ; ?), y i ) ?? ?t ,<label>(9)</label></formula><p>where ? is the step size for gradient descent and b is the number of samples in one mini-batch sampled from the training set S train . A C,t is the classification accuracy of f (x; ? t ) on all the C classes at time step t and is computed on a validation dataset S val .</p><p>The second step updates the parameters ? of Difficulty-Net using the obtained intermediate classifier f (x;? t ) on a mini-batch of size m sampled from the meta-dataset. The update is done by</p><formula xml:id="formula_9">? t+1 ? ? ? t ?? ?(?L dr (A C,t , ?) + 1 m m i=1 L meta i (? t (?))) ?? ?t ,<label>(10)</label></formula><p>where ? is the step size for updating the parameters of Difficulty-Net.</p><p>Finally, the third step uses the updated parameters ? t+1 to update the parameters of the classifier network f (x; ? t ) over the same mini-batch sampled in Eq. 9.</p><formula xml:id="formula_10">? t+1 ? ? ? t ? ? 1 b b i=1 w i (A C,t , ? t+1 ) ?L(f (x i ; ?), y i ) ?? ?t .</formula><p>(11) The above three steps are executed iteratively till convergence or the end of the training. The overall algorithm is presented in Algorithm 1 in the supplementary material.</p><p>For our experiments, we construct the S meta following exactly the same procedure as <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b28">29]</ref>. We also found that S meta is reusable as S val for calculating A C,t . Therefore, we do not use any extra data compared to previous methods. Also, although it is ideal to calculate A C,t for every time step t, we calculate the accuracy only after every epoch in our implementation for saving computational time.</p><p>Difference with MWN and CDB-CE. Although we share a similar meta-learning framework as MWN <ref type="bibr" target="#b28">[29]</ref>, our approach is very different from theirs in more than one way. One difference is that MWN is a sample-level weighting strategy while ours is a class-level weighting strategy. The advantages of class-level weighting over sample-level weighting in long-tailed learning is pointed out in <ref type="bibr" target="#b30">[31]</ref> and also reflected in our experimental results.</p><p>Ours is not the straight-forward combination of MWN <ref type="bibr" target="#b28">[29]</ref> and CDB-CE <ref type="bibr" target="#b30">[31]</ref>. First, both MWN and CDB-CE use absolute difficulties of a sample or a class to determine the weights. We believe, however, the relative difficulty compared with other samples or classes is more important because it is reasonable to assign a high difficulty score to a class with high accuracy (i.e. easy class) if the other classes have even higher accuracies. The proposed method estimates relative difficulties of each class amongst all the classes, and it turned out to be more effective as we will show in Sec. 4.5. Second, the straight-forward combination of these prior works without the driver loss turns out to learn almost nothing and predicts almost identical difficulties for all the classes as we will show in Sec. 4.5. The newly proposed driver loss is essential to guide the training in a reasonable direction.</p><p>The empirical evidences of these arguments are provided in Sec. 4.5 and 4.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>CIFAR100-LT. CIFAR100 <ref type="bibr" target="#b20">[21]</ref> is an object-centric balanced classification data-set comprised of tiny images belonging to 100 different classes. Long-tailed versions of the dataset are artificially created by reducing the training samples per class according to an exponential function as given in <ref type="bibr" target="#b6">[7]</ref>. Following <ref type="bibr" target="#b6">[7]</ref>, we use CIFAR100-LT with imbalance varying in 10-200. ImageNet-LT. ImageNet-LT is a long-tail version of Ima-geNet <ref type="bibr" target="#b8">[9]</ref> created by <ref type="bibr" target="#b23">[24]</ref>. It contains 1000 object categories with heavy imbalance of 256. We use the same train, val and test splits as <ref type="bibr" target="#b23">[24]</ref>. Places-LT. Places-2 <ref type="bibr" target="#b52">[53]</ref> is a large-scale scene-centric image dataset, used for scene recognition tasks. Places-LT is a long-tailed subset of Places-2 with 365 classes and imbalance of 996, created by <ref type="bibr" target="#b23">[24]</ref>. We use the same splits as <ref type="bibr" target="#b23">[24]</ref>.</p><p>For constructing S meta , we followed the setup of previous meta-learning based methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b28">29]</ref> to ensure the fair comparison. Please see the supplementary material for the details. The evaluation results are reported on balanced test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation details</head><p>Following previous long-tailed works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b35">36]</ref>, we use ResNet-32 <ref type="bibr" target="#b13">[14]</ref> for CIFAR-100-LT experiments. On ImageNet-LT, we follow <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b50">51]</ref> and use ResNet-10 <ref type="bibr" target="#b13">[14]</ref>, ResNet-50 <ref type="bibr" target="#b13">[14]</ref>. As in <ref type="bibr" target="#b50">[51]</ref>, we use pretrained (on ImageNet <ref type="bibr" target="#b8">[9]</ref>) ResNet-152 <ref type="bibr" target="#b13">[14]</ref> and finetune it on Places-LT. The basic architecture of Difficulty-Net is the same for all the datasets as explained in Sec. 3.2, i.e. MLP with two hidden layers, but we change the dimension of hidden and output layers as different datasets have different number of classes. We will explain a simple way to select the dimension of hidden layers in the supplementary material. We evaluate our method both in end-to-end (e2e) learning and decoupled learning <ref type="bibr" target="#b18">[19]</ref> settings. For using Difficulty-Net in decoupled learning, we first train the respective model using Difficulty-Net based weighting. Then, following <ref type="bibr" target="#b18">[19]</ref>, we freeze the feature extractor and re-train the classifier without using Difficulty-Net. We use ? = 0.3 for all the experiments unless otherwise stated since we find it works reasonably well as we will show in Sec. 4.5. Further details are provided in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Compared methods</head><p>For comparison, we use multiple SOTA methods including (1) data-resampling: class-balanced sampling (CB sampling) <ref type="bibr" target="#b18">[19]</ref>, (2) cost-sensitive learning: equalization loss (EQL) <ref type="bibr" target="#b35">[36]</ref>, focal loss <ref type="bibr" target="#b22">[23]</ref>, class-balanced loss <ref type="bibr" target="#b6">[7]</ref>, label-distribution-aware-margin (LDAM) loss <ref type="bibr" target="#b1">[2]</ref>, preformulated class-difficulty balanced loss (CDB-CE) <ref type="bibr">[</ref>  <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b27">28]</ref>. The best results are made bold while the second best results are underlined, which applies for the other tables as well.</p><p>(3) metric learning: parametric contrastive learning (PaCo) <ref type="bibr" target="#b5">[6]</ref>, (4) decoupled learning: classifier normalization (? -norm) <ref type="bibr" target="#b18">[19]</ref>, classifier re-training (cRT) <ref type="bibr" target="#b18">[19]</ref>, learnable weight scaling (LWS) <ref type="bibr" target="#b18">[19]</ref>, label-aware smoothing (LAS) <ref type="bibr" target="#b50">[51]</ref>, balanced meta-softmax (BALMS) <ref type="bibr" target="#b25">[26]</ref>, distribution robustness loss (DRO-LT) <ref type="bibr" target="#b27">[28]</ref>, (5) meta learning: Meta-Weight-Net (MWN) <ref type="bibr" target="#b28">[29]</ref>, class-balancing as domain-adaptation (CB-DA) <ref type="bibr" target="#b17">[18]</ref>. For the sake of fairness, we do not compare our method directly with MoE methods <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b44">45]</ref> as they use ensemble of multiple expert models, while we focus on improving the learning for a single expert. However, we verified that the proposed method can exhibit significant performance gains by using simple ensembling techniques and can outperform SOTA MoE methods. The results are found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Main results</head><p>CIFAR100-LT. Following <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b35">36]</ref>, we use AutoAugment <ref type="bibr" target="#b3">[4]</ref> and Cutout <ref type="bibr" target="#b9">[10]</ref> for all our implementations on CIFAR100-LT. As explained in <ref type="bibr" target="#b35">[36]</ref>, this achieves a higher baseline than other commonly followed ones. Therefore, to ensure the fairness of comparison, we re-implemented the compared methods in our training setup using their published codes. Results without using AutoAugment and Cutout are provided in the supplementary material. We achieved better results than originally reported results for all the re-implemented methods except PaCo <ref type="bibr" target="#b5">[6]</ref>, which uses additional augmentation. Therefore, we list the original results of PaCo for reference in addition to the results in the fair setting. PaCo uses an additional center learning rebalance step, for which they employ Balanced Softmax (Bal. Softmax) <ref type="bibr" target="#b25">[26]</ref>. We report the results of PaCo both with and without the use of Bal. Softmax. For the fair comparison with PaCo + Bal. Softmax, we tested Ours + Bal. Softmax in addition to the vanilla variant (Ours). In e2e learning, our proposed approach without combining any other techniques (Ours) achieved better performance than all previous stand-alone methods as seen in <ref type="table" target="#tab_0">Table 1</ref>. The margin of improvement is higher in highimbalanced situations. End-to-end learning with Ours + Bal. Softmax turned out to be very effective and created new SOTA for low imbalanced cases (i.e. 10 and 20).</p><p>In decoupled-learning, we find that when we use feature extractors trained using Difficulty-Net, any popular classifier learning method (e.g. cRT, LWS, LAS) gives improved performance. This shows that our proposed method learns very powerful data representations. Ours + LAS achieved the best results in high imbalanced situations (e.g. 200 and 100), while it achieved the second best in all other cases. <ref type="table">Table 2</ref> shows the results on ImageNet-LT. In e2e learning alone, irrespective of the model used, we achieved better overall accuracy than other e2e methods and comparable accuracy with multiple decoupled methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ImageNet-LT.</head><p>Furthermore, Difficulty-Net based representation learning with popular classifier re-training methods achieved state-of-the-art results. Using both ResNet-10 and ResNet-50, Ours + LAS achieved the best overall accuracy, which re-confirms the effectiveness of this method. More ImageNet-LT results with many-/med-/few-shot splits are available in the supplementary material. <ref type="table" target="#tab_0">Table 1 and Table 2</ref>, it is evident that our Difficulty-Net based weighting is consistently effective when used for the representation learning in decoupled training methods. Therefore, for Places-LT, we only report the results of Ours + {cRT, LWS, LAS} and compare them with previous SOTA results in <ref type="table">Table 3</ref>. The results verify that the representation learned using our method is very powerful and helps us achieve the best overall accuracy by simple classifier re-balancing. Our improvements in overall accuracy is majorly accounted for by significant gains in medium-and few-shot accuracies. Even though our representation learning is effective with any classifier re-training </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Places-LT. From</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>method, especially Ours + LAS significantly boosts results</head><p>for the few-shot classes and achieved SOTA in overall accuracy. PaCo achieved the best results for the medium-shot classes, but it sacrificed the performance on the many-shot classes significantly, resulting in lower overall accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Ablation study</head><p>In this sub-section, we first show the ablation study of our key components, namely relative difficulty and the driver loss. Then we re-verify the effectiveness of the classlevel weighting studied in <ref type="bibr" target="#b30">[31]</ref> in our meta-learning framework. Further, we verify the effectiveness of using the metalearning loss in our method. We conclude this sub-section with the effectiveness of the proposed method by comparing it with the straight-forward combination of CDB-CE <ref type="bibr" target="#b30">[31]</ref> and MWN <ref type="bibr" target="#b28">[29]</ref>.</p><p>Absolute difficulty vs. relative difficulty. For predicting absolute difficulty, we modified Difficulty-Net from Eq. 1 to d c = D abs (a c ; ?) and trained it in the same way as before. The comparison is provided in <ref type="table" target="#tab_2">Table 4</ref> (#7 vs. #9). As can be seen, relative difficulty significantly outperforms absolute difficulty for both low and high imbalance. This verifies the effectiveness of relative difficulty.</p><p>Contribution of L dr . The value of ? in Eq. 8 controls the impact of L dr . Here we analyse the effect of ?. For that, we evaluate the performance of ResNet-32 trained end-to-end using different values of ? and report the results in <ref type="table">Table 5</ref>. It shows that ? = 0, which is equivalent to #6 in <ref type="table" target="#tab_2">Table 4</ref>, works significantly poor especially in high imbalance case, which asserts the importance of using L dr . We find that for higher imbalance, higher ? works better. But, too high ? leads to significant drop in performance. Irrespective of the imbalance, ? = 0.3 works consistently well.</p><p>To further analyse the usefulness of L dr , we visualise the predicted difficulty by Difficulty-Net trained with and without L dr . The results are shown in <ref type="figure">Figure 2</ref>. It shows that using L dr with ? = 0.3 provides a more meaningful learning of Difficulty-Net compared to when not using L dr (? = 0). The latter predicts similar difficulty scores for all the classes inspite of the highly biased accuracy. However, using L dr helps Difficulty-Net to predict high difficulty for less accurate classes.</p><p>Sample-level difficulty vs. Class-level difficulty. We modified the Difficulty-Net to predict sample-level difficulties and compared it with the proposed method. We modified the Difficulty-Net as <ref type="figure">)</ref> where B is the total number of samples in a single batch, l s is the model's cross-entropy loss for samples s, and d s is the predicted difficulty for sample s. Simply, we meta-learn the D sample to predict difficulty of each sample relative to other samples in the same training batch. Note that this variant uses relative difficulty and the driver loss, and thus is different from MWN.</p><formula xml:id="formula_11">d 1 , d 2 , ..., d B = D sample ({l s } B s=1 ; ?</formula><p>In <ref type="table" target="#tab_2">Table 4</ref> (#8 vs. #9), it is seen that class-level difficulty significantly outperforms the sample-level difficulty in overall performance. This proves the effectiveness of class-difficulty in our proposed method. We believe that this happens because the head classes have higher absolute number of hard samples than the tail classes simply because the head classes have much more training samples. In such case, as pointed out in <ref type="bibr" target="#b30">[31]</ref>, sample-level weighting gives higher weights to head classes in total, and therefore cause the model to get biased to the head classes. This is verified by the fact that class-level performs much better especially for the tail classes (med and few-shot) as shown in the supplementary material. Another interesting observation is that our sample-level Difficulty-Net even significantly outperforms MWN (#3 vs. #8), which re-verifies the effectiveness of our newly proposed components, namely relative difficulty and the driver loss.</p><p>Contribution of L meta . Here we verify the usefulness of L meta in our Difficulty-Net training. In <ref type="table" target="#tab_2">Table 4</ref> (#5 vs. #6), we see that using meta-learning loss gives a boost of 0.89% (for imb. 100) which confirms the benefit of using ML.</p><p>The straight-forward combination of CDB-CE and MWN does not work. As stated in Sec. 3.2, ours is not the straight-forward combination of the previous methods. Evidently from Table 4 (#4 vs. #9), such straight-forward combination does not work well, which verifies the contributions of our newly proposed components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Further analysis</head><p>It is evident in <ref type="figure">Figure 2</ref> that Difficulty-Net successfully learns to predict reasonable difficulty from the class-wise accuracies. Here we further analyse how the predicted difficulties change as the training progresses. For this purpose, we plot the entropy of the difficulty scores with the training steps in <ref type="figure">Figure 3</ref>. We compute the entropy as</p><formula xml:id="formula_12">E({d c } C c=1 ) = ? 1 C C c=1 log(C dc k d k )</formula><p>. <ref type="figure">Figure 3</ref> shows that the entropy decreases with the training steps. This suggests that the predicted difficulty scores gradually become more and more uniform, as the model's class-wise perfor-  mance gradually gets balanced. this result empirically supports the rationality of Difficulty-Net.</p><p>Further, we analyse the characteristics of difficulties estimated by Difficulty-Net in comparison with those by <ref type="bibr" target="#b30">[31]</ref>. We pick three classes from the CIFAR100-LT classes (one from each of many-, medium-and few-shot classes) and show how the normalized weights of the classes change as the training progresses. As shown in <ref type="figure" target="#fig_5">Figure 4</ref>, CDB-CE weighting <ref type="bibr" target="#b30">[31]</ref> leads to more fluctuations in the assigned weights, while Difficulty-Net based weighting is more smooth and stable. This suggests that Difficulty-Net has capability of 'remembering' which class is difficult whereas CDB-CE weighting tends to be heavily affected by quick accuracy change at each time step. We believe this characteristic of Difficulty-Net encourages consistent and stable training of the model, ending up in better performance than CDB-CE weighting. Another interesting observation in <ref type="figure" target="#fig_5">Figure 4</ref> is that the difficulties of the three classes  estimated by Difficulty-Net tend to converge as the training progresses ,which is not observed in the case of CDB-CE. This observation is consistent with <ref type="figure">Figure 3</ref>, which showed that the predicted difficulty scores gradually become more uniform as the model's performance gets balanced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper has proposed Difficulty-Net, a novel method for long-tailed recognition that learns to predict difficulty of classes in a meta-learning framework. The proposed method has mainly three key features compared to prior works. First, it removes any dependence on heuristic formulations thanks to its ability to learn any suitable difficulty formulation for a given dataset. Second, it estimates relative difficulty of a class compared to the other classes whereas prior works use only absolute difficulty of a class in question. Third, it employs a new driver loss function that helps to drive Difficulty-Net learning in a reasonable direction. We verified the effectiveness of the proposed method by conducting extensive experiments on multiple datasets. Further analysis also demonstrated the usefulness of relative difficulty and the newly proposed driver loss function.  <ref type="table">Table 5</ref>: The imbalance ratio (Imb.) and the number of samples per class in each datasets. Since the training splits are imbalanced, we show the number of samples in the least and most frequent classes. Note that exactly the same set of images are used for both the validation sets and meta sets. This indicates that meta-learning based methods including ours do not exploit any extra data.</p><p>1. More implementation details 1.1. More details on datasets <ref type="table">Table 5</ref> shows the number of samples in training, validation, and test splits in each dataset. As shown in the table, meta-learning (ML) based methods including ours and <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b28">29]</ref> reuse validation images for constructing S meta , a dataset to be used for meta learning. Note that (1) our proposed method was compared with other ML based methods in exactly the same conditions, (2) we re-ran the experiments using public codes of previous methods and therefore all the methods compared in this paper are evaluated using exactly the same split as shown above, and (3) all the ML based methods including ours do not use any extra data, and therefore they do not receive any unfair benefit compared to other methods by having S meta . All the hyper-parameters were tuned using the validation sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Hyperparameter settings</head><p>For CIFAR100-LT, following <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b5">6]</ref>, we use AutoAugment <ref type="bibr" target="#b3">[4]</ref> and Cutout <ref type="bibr" target="#b9">[10]</ref>. Following <ref type="bibr" target="#b35">[36]</ref>, we train ResNet-32 <ref type="bibr" target="#b13">[14]</ref> for 12.8K steps with a batch size of 128 and an initial learning rate of 0.1. The learning rate is linearly warmed up to 0.2 over the first 400 steps. It is also decayed by 0.1 after 6.4K and 9.6K steps. For the classifier learning stage in decoupled learning methods, we fix the feature extractor and re-train the classifier for 50 steps using class-balanced sampling following <ref type="bibr" target="#b18">[19]</ref>. The learning rate used is 0.1 and is decayed by 0.1 after 30 and 40 epochs. For both the stages, we use a weight decay of 1e?4. CIFAR100-LT experiments are done on a single NVIDIA Tesla V100 GPU.</p><p>For ImageNet-LT, we follow <ref type="bibr" target="#b50">[51]</ref> and train the models for 180 steps with an initial learning rate of 0.05. The batch size used is 128. We use cosine learning rate decay and weight decay of 5e ? 4. In decoupled training, for the second stage we only re-train the classifier for 10 steps using batch size 128 and cosine decayed learning rate with an initial value of 0.05. The models are trained on four NVIDIA Tesla V100 GPUs.</p><p>For Places-LT, following <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b23">24]</ref> we load a ResNet-152 pretrained on ImageNet and then finetune it for 30 steps using an initial learning rate of 0.01 and weight decay of 5e ? 4. The learning rate is decayed by 0.1 after 10 and 20 steps. The batch size used is 128. For the classifier learning stage, we retrain the classifier for 20 steps with a batch size of 256 and initial learning rate of 0.1, which is cosine decayed. The training is done on four NVIDIA Tesla V100 GPUs.</p><p>For all the datasets, we use SGD optimizer with momentum 0.9. For Difficulty-Net learning, we use ADAM optimizer with a learning rate of 0.001 and a weight decay 1e ? 4. All implementations are done on PyTorch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Designing the Difficulty-Net</head><p>As stated in Sec. 3.2, our Difficulty-Net is a MLP with 2 hidden layers. The illustration of our Difficulty-Net is given in <ref type="figure" target="#fig_6">Fig. 5</ref>. The output layer dimension changes with the number of classes in the dataset. Here we provide a simple way to select the hidden layer dimensions H. To come up with the method, we compare the end-to-end training performance using different values for H on 2 different datasets. The results are given in <ref type="table" target="#tab_5">Table 6</ref>.</p><p>We find that the best working H is different for different datasets. Therefore, based on the results, we decide to select H = 2 n such that 2 n?1 ? C &lt; 2 n , where C is the number of classes and n is a positive integer. The value of C and H for the three different datasets that we used are given in <ref type="table" target="#tab_6">Table 7</ref>.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4.">Algorithm for meta-learning via Difficulty-Net</head><p>The algorithm for our Difficulty-Net based learning is provided in Algorithm 1. As stated in Sec. 3.2, our learning method comprises of three main steps (Eq. 9,10 and 11) that are represented by steps 7, 8 and 10 in the algorithm. Note that in our algorithm, S meta is reused as validation set S val for calculating accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">More Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">CIFAR100-LT results without using extra augmentations</head><p>For the CIFAR100-LT results reported in <ref type="table" target="#tab_0">Table 1</ref>, we used extra augmentations (AutoAugment <ref type="bibr" target="#b3">[4]</ref> and Cutout <ref type="bibr" target="#b9">[10]</ref>) to ensure same training setups as recent SOTA meth- Compute A C,t using f (x; ? t ) on S meta 3:</p><p>Sample mini-batch of size b from S train</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Sample mini-batch of size m from S meta 5:</p><p>Compute weights with A C,t and ? t using Eq. 4 <ref type="bibr">6:</ref> Compute intermediate? t (? t ) using Eq. 9 <ref type="bibr">7:</ref> Update ? t to ? t+1 using Eq. 10 8:</p><p>Re-compute Eq. 4 with A C,t and ? t+1 9:</p><p>Update ? t to ? t+1 using Eq. 11 10: end for Output: ? T +1 , ? T +1 ods such as PaCo <ref type="bibr" target="#b5">[6]</ref>, BALMS <ref type="bibr" target="#b25">[26]</ref> and DRO-LT <ref type="bibr" target="#b27">[28]</ref> for fair comparison. As expected, these additional augmentation techniques provide a significant boost in the results. To verify that our proposed method is effective independent of these extra augmentations, we compare the results of our method with other SOTA methods without using the augmentation techniques. The results are reported in <ref type="table" target="#tab_9">Table 8</ref>. With or without extra augmentations, Ours + LAS proves to be very effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">ImageNet-LT results on many-, med-and fewshot classes</head><p>In <ref type="table">Table 2</ref>, we saw that our proposed method helps to achieve the best overall accuracy. Here we study the effectiveness of our method for each of many-, medium-and few-shot classes. The comparison results are given in Table <ref type="bibr" target="#b8">9</ref>. We find that in both e2e learning and decoupled learning, Difficulty-Net based weight assignment helps to significantly boost the performance of the few-shot and mediumshot classes. We believe this result indicates the strong capability of Difficulty-Net based weighting in mitigating biased performance caused by the class imbalance. Especially, Ours + LAS is the most effective for the few-shot classes, irrespective of the model used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">ImageNet-LT Results Using RandAugment</head><p>In <ref type="table">Table 2</ref>, we reproduced the results of PaCo [6] without using RandAugment <ref type="bibr" target="#b4">[5]</ref> for the sake of fair comparison with all the other methods that do not use RandAugment. However, the originally reported results in <ref type="bibr" target="#b5">[6]</ref> use RandAugment as additional augmentation, which are significantly higher than the reproduced results. This suggests that PaCo is greatly benefited by the use of RandAugment. Therefore, we used RandAugment with our method and compared the results with PaCo in   <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b17">18]</ref>. The best results are made bold while the second best results are underlined, which applies for the other tables as well.</p><p>the comparison because Ours + LAS is the best performing decoupled learning method as seen in <ref type="table" target="#tab_0">Table 1</ref>,2 and 3. From <ref type="table" target="#tab_0">Table 10</ref>, we find that using RandAugment benefits our method as well. With or without RandAugment <ref type="bibr" target="#b4">[5]</ref>, Ours+LAS outperformed PaCo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Comparison on ImageNet-LT with MoE methods</head><p>In Sec. 4.4, we did not compare our proposed method directly to mixture of experts (MoE) methods as the latter uses multiple experts while we focus on improving the learning of a single expert. For the fair comparison with MoE methods, we created an ensemble of Difficulty-Net based trained models. For the ensemble creation, we trained two expert models using Ours + LAS decoupled learning. The backbone architectures of these two models were kept the same. The only difference between these models was that one used a linear classifier and the other used a cosine classifier. During inference, we simply took the mean outputs of these two models. The results of this simple ensemble is provided in <ref type="table" target="#tab_0">Table 11</ref>.</p><p>As can be seen, although our ensemble comprises of only two expert models, it performs significantly better than 3experts and 4-experts RIDE <ref type="bibr" target="#b40">[41]</ref>. This shows that our proposed Difficulty-Net is effective in learning expert models for MoE methods. However, the current ensemble is heuristic and a detailed research on contribution of Difficulty-Net in MoE is left for the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">More results on sample-level v/s class-level difficulty</head><p>As empirically verified in <ref type="table" target="#tab_2">Table 4</ref>, class-level difficulty is more effective than sample-level difficulty in our Difficulty-Net. We believe that this happens because as stated in <ref type="bibr" target="#b30">[31]</ref> and Sec. 4.5, the absolute number of hard samples in head classes is significantly higher than that in tail classes due to the inherent long-tail characteristic of the dataset. Using sample-level difficulty gives high weights to all the hard samples irrespective of their classes, resulting in more weights for the head classes and therefore getting the model biased to the head classes.</p><p>We verified this by conducting a simple experiment on CIFAR100-LT. For 2 classes A and B with 376 and 46 training samples respectively, the absolute number of hard samples given high weights by sample-level method was higher for A(50) than B <ref type="bibr" target="#b12">(13)</ref>. Although higher proportion of samples in B(? 28%) received high weights compared to A (? 13%), A got more weights compared to B due to its higher absolute number of hard samples. As a result, the accuracy for A is improved from 46% to 62% and that for B is decreased from 31% to 21%, hence boosting the bias. In such case, using class-level difficulty gives high weights to all samples of B, resulting in more weights for B. As a result, the accuracy on B was improved from 31% to 40%, while that on A was almost maintained (46% to 44%).</p><p>The effectiveness of class-level difficulty in Difficulty-Net for overcoming model bias is further verified in Table 12. Using sample-level difficulty causes the model to get biased towards the many-shot classes while class-level difficulty is particularly useful for improving performance on the med-shot and few-shot classes.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1</head><label>1</label><figDesc>Figure 1. Different quantifications of class-difficulties perform better than others in different situations (imbalance ratios). The imbalance in the data is calculated as the ratio of the frequency of the most frequent class to that of the least frequent class. We compute class-wise difficulty (dc) using four different functions of class-wise accuracy (ac) for the CDB-CE [31] loss function and compare their performance on the CIFAR100-LT. Interestingly, the alternate formulations work better than the originally proposed one (dc = 1 ? ac) in many cases. However, the best performing function changes with the imbalance values. This brings us to the question "Which formulation to choose for my imbalanced dataset?"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 . 3 .</head><label>23</label><figDesc>Difficulty scores for CIFAR100-LT (imbalance=100) classes predicted by Difficulty-Net learned with ? = 0 and ? = 0.The classes are sorted in increasing order of their accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3 EFigure 3 .</head><label>33</label><figDesc>Plotting entropy (E) of difficulty scores predicted by Difficulty-Net against number of training steps. We used CIFAR100-LT (imbalance=100) for this plot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Assigned weights to three different classes during training with CDB-CE<ref type="bibr" target="#b30">[31]</ref> (Left) and our Difficulty-Net (Right). The vertical axis represents assigned weights and the horizontal axis represents training steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Illustration of our Difficulty-Net H CIFAR100-LT ImageNet-LT (C = 100) (C = 1000)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>48.65 53.77 59.22 64.15 MWN + LAS 45.04 49.12 53.95 59.38 64.24 Ours + cRT 47.45 52.01 56.34 61.08 64.80 Ours + LWS 47.91 52.62 56.61 61.38 65.08 Ours + LAS 48.32 52.96 56.90 61.46 65.22</figDesc><table><row><cell>31],</cell></row></table><note>. Top-1 classification accuracy (%) on CIFAR-100-LT. ? denotes copied results from origin paper</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 Table 3</head><label>23</label><figDesc></figDesc><table><row><cell>Method</cell><cell cols="4">ResNet-10 ResNet-50</cell></row><row><cell>e2e training</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CE</cell><cell>34.8</cell><cell></cell><cell></cell><cell>41.6</cell></row><row><cell>Focal loss [23]</cell><cell>30.5</cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>EQL [36]</cell><cell>36.4</cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>CB-DA[18]</cell><cell>36.7</cell><cell></cell><cell></cell><cell>48.0</cell></row><row><cell>CDB-CE [31]</cell><cell>38.5</cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>Bal. Softmax [26]</cell><cell>41.1</cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>PaCo [6]  *</cell><cell>-</cell><cell></cell><cell></cell><cell>49.8</cell></row><row><cell cols="2">+ Bal. Softmax [26]  *  -</cell><cell></cell><cell></cell><cell>53.5</cell></row><row><cell>Ours</cell><cell>41.4</cell><cell></cell><cell></cell><cell>51.2</cell></row><row><cell>+ Bal. Softmax</cell><cell>44.3</cell><cell></cell><cell></cell><cell>53.7</cell></row><row><cell>decoupled learning</cell><cell></cell><cell></cell><cell></cell></row><row><cell>cRT [19]</cell><cell>41.8</cell><cell></cell><cell></cell><cell>47.3</cell></row><row><cell>LWS [19]</cell><cell>41.4</cell><cell></cell><cell></cell><cell>47.7</cell></row><row><cell>MiSLAS [51]</cell><cell>-</cell><cell></cell><cell></cell><cell>52.7</cell></row><row><cell>BALMS [26]</cell><cell>41.8</cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>DRO-LT [28]</cell><cell>-</cell><cell></cell><cell></cell><cell>53.5</cell></row><row><cell>Ours + cRT</cell><cell>43.6</cell><cell></cell><cell></cell><cell>53.5</cell></row><row><cell>Ours + LWS</cell><cell>44.4</cell><cell></cell><cell></cell><cell>53.7</cell></row><row><cell>Ours + LAS</cell><cell>44.6</cell><cell></cell><cell></cell><cell>54.0</cell></row><row><cell>Method</cell><cell cols="3">Many Med Few</cell><cell>All</cell></row><row><cell>CE</cell><cell>45.7</cell><cell cols="2">27.3 8.2</cell><cell>30.2</cell></row><row><cell cols="2">CB sampling [19] -</cell><cell>-</cell><cell>-</cell><cell>30.3</cell></row><row><cell>Focal Loss [23]</cell><cell>41.1</cell><cell cols="3">34.8 22.4 34.6</cell></row><row><cell>cRT [19]</cell><cell>42.0</cell><cell cols="3">37.6 24.9 36.7</cell></row><row><cell>LWS [19]</cell><cell>40.6</cell><cell cols="3">39.1 28.6 37.6</cell></row><row><cell>BALMS [26]</cell><cell>41.2</cell><cell cols="3">39.8 31.6 38.7</cell></row><row><cell>LADE [16]</cell><cell>42.8</cell><cell cols="3">39.0 31.2 38.8</cell></row><row><cell>DisAlign [48]</cell><cell>40.4</cell><cell cols="3">42.4 30.1 39.3</cell></row><row><cell>IEM [54]</cell><cell>46.8</cell><cell cols="3">39.2 28.0 39.7</cell></row><row><cell>MiSLAS [51]</cell><cell>39.6</cell><cell cols="3">43.3 36.1 40.4</cell></row><row><cell>PaCo [6]</cell><cell>37.5</cell><cell cols="3">47.2 33.9 41.2</cell></row><row><cell>Ours + cRT</cell><cell>43.0</cell><cell cols="3">43.8 35.0 41.7</cell></row><row><cell>Ours + LWS</cell><cell>41.4</cell><cell cols="3">43.7 36.9 41.5</cell></row><row><cell>Ours + LAS</cell><cell>42.4</cell><cell cols="3">43.7 36.6 41.7</cell></row></table><note>. Top-1 classification accuracies (%) on ImageNet-LT.* represents reproduced results using author's codes without using RandAugment [5] for fair comparison. Other baseline results are copied from original papers. Results using RandAugment are pro- vided in the supplementary material.. Top-1 classification accuracies (%) for Places-LT.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>#Table 4 .</head><label>4</label><figDesc>Name S vs. C A vs. R ML L dr Imb.=100 Imb.=10 Classification accuracy on CIFAR100-LT with imbalance ratio (Imb.) 100 and 10. "S vs. C" means Sample-level vs. Class-level. "A vs. R" means Absolute difficulty vs. Relative difficulty. ML stands for Meta Learning.</figDesc><table><row><cell></cell><cell cols="3">1 Focal loss [23]</cell><cell></cell><cell>S</cell><cell>A</cell><cell>44.03</cell><cell>61.10</cell></row><row><cell></cell><cell cols="2">2 CDB-CE [31]</cell><cell></cell><cell></cell><cell>C</cell><cell>A</cell><cell>45.25</cell><cell>61.52</cell></row><row><cell></cell><cell cols="2">3 MWN [29]</cell><cell></cell><cell></cell><cell>S</cell><cell>A</cell><cell>44.81</cell><cell>61.44</cell></row><row><cell></cell><cell cols="3">4 CDB-CE + MWN</cell><cell></cell><cell>C</cell><cell>A</cell><cell>45.42</cell><cell>61.87</cell></row><row><cell></cell><cell cols="3">5 Ours w/o L dr and ML</cell><cell></cell><cell>C</cell><cell>R</cell><cell>45.51</cell><cell>62.44</cell></row><row><cell></cell><cell cols="2">6 Ours w/o L dr</cell><cell></cell><cell></cell><cell>C</cell><cell>R</cell><cell>46.40</cell><cell>63.10</cell></row><row><cell></cell><cell cols="4">7 Ours w/o relative difficulty</cell><cell>C</cell><cell>A</cell><cell>46.81</cell><cell>62.32</cell></row><row><cell></cell><cell cols="5">8 Ours w/o class-level weighting S</cell><cell>R</cell><cell>45.76</cell><cell>62.51</cell></row><row><cell></cell><cell>9 Ours</cell><cell></cell><cell></cell><cell></cell><cell>C</cell><cell>R</cell><cell>47.96</cell><cell>63.52</cell></row><row><cell>?</cell><cell>0</cell><cell>0.3</cell><cell>0.6</cell><cell>0.9</cell><cell>1.0</cell></row><row><cell cols="6">Imbalance=100 46.40 47.96 48.03 47.35 46.66</cell></row><row><cell>Imbalance=10</cell><cell cols="5">63.10 63.52 63.44 62.62 62.24</cell></row><row><cell cols="6">Table 5. Accuracy (in e2e learning) for different values of ? on</cell></row><row><cell>CIFAR100-LT.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Difficulty-Net: Learning to Predict Difficulty for Long-Tailed RecognitionSupplementary Material</figDesc><table><row><cell></cell><cell>Imb.</cell><cell>Train</cell><cell cols="2">Val / Meta Test</cell></row><row><cell>CIFAR-LT</cell><cell cols="3">10-200 49-2 / 490 10</cell><cell>100</cell></row><row><cell cols="2">ImageNet-LT 256</cell><cell>5 / 1280</cell><cell>10</cell><cell>50</cell></row><row><cell>Places-LT</cell><cell>996</cell><cell>5 / 4980</cell><cell>10</cell><cell>100</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table><row><cell cols="3">Effect of H on e2e training of ResNet-32</cell></row><row><cell cols="3">and ResNet-10 on CIFAR100-LT (imbalance=100) and</cell></row><row><cell>ImageNet-LT respectively.</cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell>C</cell><cell>H</cell></row><row><cell cols="3">CIFAR100-LT 100 128</cell></row><row><cell cols="3">ImageNet-LT 1000 1024</cell></row><row><cell>Places-LT</cell><cell cols="2">365 512</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>C and H for datasets used in our experiments.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Algorithm 1 Meta-learning using Difficulty-NetRequire: Training set S train , Meta dataset S meta Require: Initial learnable parameters ? 1 and ? 1 Require: Max iterations T , Value of ? Require: Learning rates ?, ? and batch sizes b, m 1: for t = 1 . . . T do</figDesc><table><row><cell>2:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10 .</head><label>10</label><figDesc>We only used Ours + LAS for Focal Loss [23] ? 35.62 38.41 44.32 51.95 55.78 MWN [29] ? 37.91 42.09 46.74 54.37 58.46 Class-Balanced [7] ? 36.23 39.60 45.32 52.99 57.99 CB-DA [18] ? 39.31 43.35 48.53 55.</figDesc><table><row><cell></cell><cell cols="2">Imbalance</cell><cell></cell></row><row><cell>Method</cell><cell>200 100 50</cell><cell>20</cell><cell>10</cell></row><row><cell>e2e training</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">62 59.58</cell></row><row><cell>LDAM [2]  ?</cell><cell>-39.60 -</cell><cell cols="2">-56.91</cell></row><row><cell>EQL [36]  ?</cell><cell cols="3">37.34 40.54 44.70 54.12 58.32</cell></row><row><cell>CDB-CE [31]  ?</cell><cell cols="3">37.40 42.57 46.78 54.22 58.74</cell></row><row><cell>PaCo [6]</cell><cell cols="3">36.96 40.92 46.97 53.66 59.59</cell></row><row><cell cols="4">+ Bal. Softmax [26] 39.55 44.13 48.60 55.89 60.24</cell></row><row><cell>Ours</cell><cell cols="3">39.94 43.82 49.00 55.70 60.25</cell></row><row><cell>+ Bal. Softmax</cell><cell cols="3">41.43 45.81 51.14 56.58 61.33</cell></row><row><cell>decoupled learning</cell><cell></cell><cell></cell><cell></cell></row><row><cell>cRT [19]</cell><cell cols="3">40.13 44.04 48.97 55.67 59.54</cell></row><row><cell>LWS [19]</cell><cell cols="3">40.70 45.05 49.70 56.22 60.00</cell></row><row><cell>LAS [51]</cell><cell cols="3">40.76 45.32 49.96 56.66 59.96</cell></row><row><cell>BALMS [26]</cell><cell cols="3">39.58 44.64 48.52 54.28 58.34</cell></row><row><cell>MWN + cRT</cell><cell cols="3">40.57 44.00 49.47 56.05 59.64</cell></row><row><cell>MWN + LWS</cell><cell cols="3">40.48 44.52 49.10 55.89 59.48</cell></row><row><cell>MWN + LAS</cell><cell cols="3">40.94 44.64 49.15 55.91 59.24</cell></row><row><cell>Ours + cRT</cell><cell cols="3">41.12 45.41 50.50 56.30 60.86</cell></row><row><cell>Ours + LWS</cell><cell cols="3">41.67 46.04 51.27 56.66 61.30</cell></row><row><cell>Ours + LAS</cell><cell cols="3">42.19 46.42 51.60 56.82 61.47</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Top-1 classification accuracy (%) on CIFAR100-LT without using extra augmentation i.e. AutoAugment and Cutout. ? denotes copied results from origin paper</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Top-1 accuracy (%) on many-, medium-and few-shot classes of ImageNet-LT. * represents results reproduced using author's codes without using RandAugment<ref type="bibr" target="#b4">[5]</ref> for fair comparison. Other results are copied from original papers.</figDesc><table><row><cell>Method</cell><cell cols="2">ResNet-10 ResNet-50</cell></row><row><cell>PaCo + Bal. Softmax [6]</cell><cell>-</cell><cell>57.0</cell></row><row><cell>Ours + LAS</cell><cell>46.9</cell><cell>57.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 :</head><label>10</label><figDesc>Top-1 accuracy (%) using RandAugment<ref type="bibr" target="#b4">[5]</ref>. Baseline results are copied from the original paper<ref type="bibr" target="#b5">[6]</ref>.</figDesc><table><row><cell>Method</cell><cell cols="2">ResNet-10 ResNet-50</cell></row><row><cell>LFME [45]</cell><cell>38.8</cell><cell>-</cell></row><row><cell>RIDE (2 experts) [41]</cell><cell>-</cell><cell>54.4</cell></row><row><cell>RIDE (3 experts) [41]</cell><cell>-</cell><cell>54.9</cell></row><row><cell>RIDE (4 experts) [41]</cell><cell>-</cell><cell>55.4</cell></row><row><cell>Ours (2 experts)</cell><cell>47.5</cell><cell>56.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 11 :</head><label>11</label><figDesc>Comparison with mixture of expert methods. Baseline results are copied from the original papers<ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b40">41]</ref>.<ref type="bibr" target="#b46">47</ref>.46 18.99 45.76 74.50 61.01 48.02 62.51 Class-level (ours) 64.47 51.21 24.92 47.96 70.48 64.40 53.36 63.52</figDesc><table><row><cell>Imbalance</cell><cell>100</cell><cell>10</cell></row><row><cell>Difficulty</cell><cell cols="2">Many Med Few All Many Med Few All</cell></row><row><cell>Sample-level</cell><cell>67.00</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 12 :</head><label>12</label><figDesc>Comparison of sample-level difficulty and classlevel difficulty on CIFAR100-LT.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust metric learning based on the rescaled hinge loss</title>
	</analytic>
	<monogr>
		<title level="j">Int. J. Mach. Learn. Cybern</title>
		<editor>Sumia Abdulhussien Razooqi Al-Obaidi, Davood Zabihzadeh, Ali Salim Rasheed, and Reza Monsefi</editor>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2515" to="2528" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Learning imbalanced datasets with labeldistribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Smote: Synthetic minority over-sampling technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitesh</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res. (JAIR)</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation policies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Ekin Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zoph ; Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Dandelion Mane, Vijay Vasudevan, and</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="702" to="703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Parametric contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="715" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Large scale fine-grained categorization and domain-specific transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4109" to="4118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Class rectification hard mining for imbalanced deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Borderline-smote: A new over-sampling method in imbalanced data sets learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Yuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing-Huan</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Intelligent Computing</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">3644</biblScope>
			<biblScope unit="page" from="878" to="887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep metric learning using triplet network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nir</forename><surname>Ailon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Similarity-Based Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Disentangling label distribution for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngkyu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungju</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwanghee</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seokjun</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beomsu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buru</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6626" to="6636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning deep representation for imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5375" to="5384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rethinking classbalanced methods for long-tailed visual recognition from a domain adaptation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prannay</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="18661" to="18673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Overcoming classifier imbalance for long-tail object detection with balanced group softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jintao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10991" to="11000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Kaiming He, and Piotr Dollar. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>TPAMI</publisher>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="318" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Long-tail learning via logit adjustment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Singh Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Balanced meta-softmax for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunjun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunan</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bin Yang, and Raquel Urtasun. Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Distributional robustness loss for long-tail learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dvir</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Chechik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Meta-weight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Clustering and learning from imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Naman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhall</surname></persName>
		</author>
		<idno>abs/1811.00972</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Class-wise difficulty-balanced loss for solving classimbalance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saptarshi</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Ohashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuyuki</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Class-Difficulty Based Methods for Long-Tailed Visual Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saptarshi</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Ohashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuyuki</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4004" to="4012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Inverse random under sampling for class imbalance problem and its application to multi-label classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Muhammad Atif Tahir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3738" to="3750" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Equalization loss v2: A new gradient balance approach for long-tailed object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingru</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1685" to="1694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Equalization loss for long-tailed object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingru</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changbao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Seesaw loss for longtailed instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Contrastive learning based hybrid networks for longtailed image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Peng Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The devil is in classification: A simple framework for long-tail instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhao</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="728" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi-similarity loss with general pair weighting for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengke</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5022" to="5030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Long-tailed recognition by routing diverse distribution-aware experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dynamic curriculum learning for imbalanced data classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiru</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihao</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5016" to="5025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning to learn: Model regression networks for easy small sample learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="616" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning from multiple experts: Self-paced knowledge distillation for long-tailed classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuyu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiguang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="247" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Rethinking the value of labels for improving class-imbalanced learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Feature transfer learning for face recognition with under-represented data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Distribution alignment: A unified framework for long-tail visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shipeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Range loss for deep face recognition with longtailed training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5419" to="5428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Test-agnostic long-tailed recognition by test-time aggregating diverse experts with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanqing</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Improving calibration for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">BBN: Bilateral-branch network with cumulative learning for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Min</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Inflated episodic memory with region self-attention for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
