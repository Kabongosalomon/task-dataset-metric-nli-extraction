<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Occlusion-Robust Object Pose Estimation with Holistic Representation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
							<email>bo.chen@adelaide.edu.au</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Klimavicius</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blackswan</forename><surname>Technologies</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The University of Adelaide</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Tat-Jun Chin</orgName>
								<orgName type="institution">The University of Adelaide</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">marius@blackswan.ltd</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Occlusion-Robust Object Pose Estimation with Holistic Representation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Practical object pose estimation demands robustness against occlusions to the target object. State-of-the-art (SOTA) object pose estimators take a two-stage approach, where the first stage predicts 2D landmarks using a deep network and the second stage solves for 6DOF pose from 2D-3D correspondences. Albeit widely adopted, such two-stage approaches could suffer from novel occlusions when generalising and weak landmark coherence due to disrupted features. To address these issues, we develop a novel occlude-and-blackout batch augmentation technique to learn occlusion-robust deep features, and a multiprecision supervision architecture to encourage holistic pose representation learning for accurate and coherent landmark predictions. We perform careful ablation tests to verify the impact of our innovations and compare our method to SOTA pose estimators. Without the need of any post-processing or refinement, our method exhibits superior performance on the LINEMOD dataset. On the YCB-Video dataset our method outperforms all non-refinement methods in terms of the ADD(-S) metric. We also demonstrate the high data-efficiency of our method. Our code is available at</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Object pose estimation is the task of inferring the relative orientation and position between the target object and the observer. Such inference is crucial in many vision applications such as robotic manipulation <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b10">11]</ref>, augmented reality <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b11">12]</ref>, autonomous driving <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b62">63]</ref> and spacecraft navigation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b48">49]</ref>. The problem can be simplified if depth information is available <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b8">9]</ref>. However, depth sensors are not always practical. Pose estimation from images is thus an important research problem.</p><p>In this paper we consider the problem of object pose estimation from a single RGB image. Our focus lies in the base estimator, i.e., from input image to the output pose, before any refinement step. For the base estimator, a number of works <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b12">13]</ref> adopt direct regression approaches which map the input image that contains the target object to its 6 DOF pose. However, such approaches tend to be sensitive to occlusions and are observed to be similar to performing image retrieval <ref type="bibr" target="#b47">[48]</ref>.</p><p>Rather than directly regressing the pose, two-stage approaches <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b56">57]</ref> first predict landmarks on the object to establish 2D-3D correspondences, then use a Perspective-n-Point (PnP) like algorithm to solve for the pose. Previous results suggest that twostage methods are generally more accurate <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b21">22]</ref>. Their strengths derive from training the model with richer supervision signals (i.e., groundtruth landmarks) rather than just the pose, and injecting tolerance towards inaccurate landmark predictions by robust PnP.</p><p>However, two-stage approaches are not intrinsically immune to occlusion. Current works to improve robustness often take the pixel-wise or patch-wise approach <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b41">42]</ref>, i.e., generating an ensemble of predictions from each image pixel or patch, and aggregate them to obtain a more robust final prediction. Although ensembling can mitigate some occlusion-induced inaccuracies, landmark coherence are easily disrupted by large and novel occlusions, because the network predicts landmarks independently and consistency is only imposed by the PnP algorithm, which is not part of the network <ref type="bibr" target="#b21">[22]</ref>.</p><p>In this paper, we aim to address the shortcomings of current two-stage approaches. Firstly, we enforce occlusionrobust feature learning to enable models to deal with novel and severe occlusions. Secondly, a good pose representation should produce landmarks that are consistent to the object shape, rather than predicting individual landmarks independently. To this end, during model training we encourage a holistic pose representation learning in order to strengthen the connections between landmark predictions and enhance their coherence.</p><p>Our contributions We propose the Robust Object Pose Estimation (ROPE) framework which achieves excellent robustness against occlusions without the need of pose refinement. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, our model predicts landmarks and pose robustly without any post-processing.</p><p>To enforce occlusion-robust feature learning, we combine hide-and-seek <ref type="bibr" target="#b49">[50]</ref>, random erasing <ref type="bibr" target="#b64">[65]</ref> and batch augmentation <ref type="bibr" target="#b20">[21]</ref> and propose a occlude-and-blackout batch augmentation technique for model training. To encourage the model to learn holistic pose representations, we propose a multi-precision supervision architecture, which boosts the model's ability to extrapolate occluded object parts, leading to spatially more accurate and structurally more coherent landmark predictions. To alleviate the need for pose refinement we further utilise the multi-precision supervision architecture to filter landmark predictions with a simple verification step.</p><p>We conduct extensive experiments to verify the efficacy of the proposed techniques, and compare our method to SOTA object pose estimators. In terms of the ADD(-S) metirc, our method outperforms all contestants on LINEMOD <ref type="bibr" target="#b18">[19]</ref> and all non-refinement methods on YCB-Video <ref type="bibr" target="#b61">[62]</ref>. Without any refinement, it is also competitive to SOTA methods that includes a refinement step. Compared to methods that relies on large amount of synthetic training images, we show that ROPE is highly data-efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related works</head><p>Traditional object pose estimation methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b36">37]</ref> rely on hand-crafted features or template matching techniques, which are susceptible to occlusions or other appearance change. Recent advancements of deep learning has nurtured a lot of learning-based methods. We briefly survey a few prominent works from one-stage, two-stage and other methods.</p><p>PoseNet <ref type="bibr" target="#b27">[28]</ref> was a pioneer work on using a deep model to directly regress the 6DOF from an image. Although it was proposed for camera localisation rather than object pose estimation, its principle applies to both tasks. SSD-6D <ref type="bibr" target="#b26">[27]</ref> combines an SSD detector <ref type="bibr" target="#b35">[36]</ref> and a pose regressor in a single network. RenderForCNN <ref type="bibr" target="#b52">[53]</ref> uses an image renderer to synthesize training images as well as groundtruth pose for training a pose regressor.</p><p>Compared to one-stage approaches, two-stage methods typically predicts intermediate features in the first stage, and then solve for the pose in the second stage. This mechanism receives more attention because its intermediate feature learning facilitates more potential improvements. For example, Tekin et al. <ref type="bibr" target="#b56">[57]</ref> apply the YOLO object detector <ref type="bibr" target="#b46">[47]</ref> in the first stage to predict object landmarks. Hu et al. <ref type="bibr" target="#b22">[23]</ref> predict landmark locations for each small patch of the input image. They then aggregate all patch predictions to establish 2D-3D correspondences for solving the pose. Oberweger et al. <ref type="bibr" target="#b40">[41]</ref> on the other hand, only use patches of images to train the landmark predictor. The idea is that at least some patches are not corrupted by the occluder and they could produce accurate landmark heatmaps. The ensemble of heatmaps predicted from many patches are combined to obtain final landmarks. PVNet <ref type="bibr" target="#b43">[44]</ref> predicts the object mask and, for each pixel within the mask, unit vectors that points to the landmarks. It then utilises a generalised Hough voting scheme <ref type="bibr" target="#b1">[2]</ref> to determine the distribution of the landmarks.</p><p>There are other notable works tackling object pose estimation from different perspectives. Sundermeyer et al. <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b54">55]</ref> use autoencoders to learn implicit pose representations by reconstructing the input objects. Cai and Reid <ref type="bibr" target="#b4">[5]</ref> propose a 3D model-free pose estimator via 2D-3D mapping. To make two-stage methods into a single stage pipeline, Hu et al. <ref type="bibr" target="#b21">[22]</ref> and Wang et al. <ref type="bibr" target="#b58">[59]</ref> propose deep architectures to replace the PnP algorithm in the second stage, while Chen et al. <ref type="bibr" target="#b7">[8]</ref> propose a differentiable PnP method to achieve end-to-end learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The ROPE framework</head><p>We focus on the problem of 6DOF object pose estimation from a single RGB image. Given an image I and a known 3D point cloud {z i } n i=1 of the target object, we first predict a set of 2D landmarks {x i } n i=1 in I that correspond to the point cloud, then solve the pose y via a RANSACbased PnP solver from filtered 2D-3D correspondences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Robust landmark prediction</head><p>Our 2D landmark prediction is based on the Mask R-CNN <ref type="bibr" target="#b15">[16]</ref> framework. The specific architecture and training scheme are shown in <ref type="figure" target="#fig_1">Figure 2</ref>. A basic improvement is substituting the original backbone network with HRNet <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b59">60]</ref> to exploit its high-resolution feature maps which preserve rich semantic information and increase spatial accuracy. Next, we describe two key innovations to boost occlusion robustness and landmark coherence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Occlude-and-blackout batch augmentation</head><p>Fundamentally, pose estimation for the typical 3D object will suffer from the problem of self-occlusion. Landmarks that are at the opposite side of the object would be hard to predict since their visual features are hidden. In fact, a practical pose estimator must also contend with additional occlusions due to, e.g., other objects or scene elements that further conceal part of the target object from view. It is thus important that the landmark predictor infers the robust pose information from potentially different kinds occlusions imposed on the object.</p><p>Inspired by the ideas of random erasing <ref type="bibr" target="#b64">[65]</ref>, hideand-seek <ref type="bibr" target="#b49">[50]</ref>, and batch augmentation <ref type="bibr" target="#b20">[21]</ref> (all not originally developed for pose estimation), we develop a novel Occlude-and-blackout Batch Augmentation (OBA) to promote robust landmark prediction under occlusion. For each training batch, after performing regular data augmentations including rotation, translation, scaling and color jitter, we extend the batch by including a copy of itself with extra augmentations, namely, occlude and blackout. Similar to hide-and-seek, we divide the image region enveloped by the object bounding box into a grid of patches and replace each patch, under certain probability, with either noise or a random patch elsewhere from the same image. We then blackout everything outside of the object bounding box. An example is shown in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>With random occlusions the network is forced to infer the pose information from a partial view of the object. Erasing the background helps reducing overfitting and enhance generalisability. Moreover, the OBA augmented images are fed to the network with the original ones in the same batch, and supervised by the same groundtruth labels. This encourages the network to learn occlusion-robust and background-invariant representations.</p><p>If the potential occluders are known beforehand, injecting occluder specific information in the training phase can significantly improve performance <ref type="bibr" target="#b40">[41]</ref>. However this knowledge is often not available in practice. Compared to methods that augment training images with known objects <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b0">1]</ref>, our method is occluder-agnostic yet it generalises well in the testing sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Multi-precision supervision</head><p>Current heatmap-based landmark prediction networks use a single groundtruth Gaussian heatmap per landmark for training. The variance of these heatmaps is a hyper parameter which requires careful tuning: a smaller variance may increase prediction accuracy for each individual landmark however risk structural inconsistency in the case of occlusion, due to the lack of holistic understanding of the object pose. To address this issue we propose a Multi- Precision Supervision (MPS) architecture: using three keypoint heads to predict groundtruth Gaussian heatmaps with different variance.</p><p>In Mask R-CNN, the output feature map of the backbone is aligned with RoI proposals and the RoI features are then passed to the mask head. We replace the mask head with three keypoint heads to regress the landmark heatmaps, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>. Each keypoint head consists of 8 convolutional layers and 2 upsampling layers.</p><p>In the training phase, the groundtruth heatmaps ? * are constructed as 2D Gaussian feature maps centred on groundtruth 2D landmarks x * and spreading with variance ? 2 . We use ? equal to 8, 3 and 1.5 pixels respectively for the three keypoint heads, thus creating low, medium and high precision target heatmaps ? * . The loss function is</p><formula xml:id="formula_0">L JS = JSD(?(?), ? * ),<label>(1)</label></formula><p>where JSD(?) is the Jensen-Shannon divergence <ref type="bibr" target="#b13">[14]</ref> and ?(?) is the channel-wise softmax function, i.e., each channel is normalised to be a probability distribution over the pixels.</p><p>In the testing phase, we only use the predicted heatmaps ? from the high-precision keypoint head to obtain the landmark coordinates x. Instead of simply taking the "argmax" of ? as x, we treat the normalised heatmaps ?(?) as probability maps and take their spatial expectations as x. This has two advantages over the "argmax" approach: it has higher accuracy because it is continuous rather than discrete; it is more robust to outlying pixel values.</p><p>Although only the high-precision heatmaps are used to compute the landmark coordinates, the medium and lowprecision keypoint heads play an important role in the pipeline. Firstly, having target heatmaps with different variances ? 2 helps the model adapt to objects of different sizes.</p><p>This also relieves the need for tuning ? as a hyper parameter for each object. Secondly, heatmaps from the mediumprecision keypoint head are used as an auxiliary for filtering predicted landmarks, as will be explained in the next subsection. Lastly and most importantly, MPS boosts holistic representation learning in the feature maps and increases landmark coherence. An conceptual illustration is shown in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>In <ref type="figure" target="#fig_2">Figure 3</ref>, we take one section of the feature tensor S1 for examination. With single precision supervision, S1 is only responsible for activating the region A1 in the predicted heatmap of Landmark 1. It does not learn useful information about Landmark 2. In the MPS scenario, besides learning about Landmark 1 via A1 and A3, S1 is also exposed to the receptive field of A4 from Landmark 2. This enforces S1 to incorporate relevant information and become more "aware" of the location of Landmark 2. The overall effect is that, each part of the feature tensor not only learns the necessary information to predict a local landmark, but also integrates knowledge of other landmarks to understand a wider context, thus learns a more holistic representation of the target object pose.</p><p>A holistic representation enables heatmap predictions to be more robust against occlusions. As shown in <ref type="figure" target="#fig_3">Figure 4</ref>, when trained without MPS, novel occlusions result in confused heatmap activations. On the other hand, a holistic representation learned via MPS is able to produces stable heatmaps for the occluded landmarks. This also boosts the structural consistency of landmark predictions as shown in <ref type="figure" target="#fig_4">Figure 5</ref> and 7, which is further discussed in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Landmark filtering</head><p>Many pose estimation pipelines include a refinement stage which is either optimisation-based <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b50">51]</ref> or learning-based <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b63">64]</ref>. While such post-processing is effective in boosting prediction accuracy, it adds additional computation burdens which is a disadvantage especially for real-time applications. In order to boost prediction accuracy while at the same time avoiding heavy postprocessing computation, we make use of the multi-heads design of MPS for selecting high-quality landmark predictions before passing them to the PnP solver, thus alleviating the need for significant pose refinement.</p><p>Specifically, for an image I, let {x i } denote the set of predicted landmark coordinates from the high-precision keypoint head, and {x m i } denote the set of landmark coordinates predicted from the medium-precision keypoint head. We then select a subset</p><formula xml:id="formula_1">{x i |?x i ? x m i ? 2 ? ?}<label>(2)</label></formula><p>for the PnP solver to compute the pose. In other words, a landmark prediction from the high-precision head will only be selected for the pose solver if it is verified by the corresponding medium-precision prediction, where ? is the verification threshold. In the case that the selected subset has fewer than 4 points, which is the minimum number required by a PnP solver, we then use the 4 points with the smallest ?x i ? x m i ? 2 values as the subset. While in this work we focus on the base pose estimator and report its performances without any refinement, our pipeline can be easily extended to stack one or multiple refiners such as <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b54">55]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section we conduct experiments to validate the effectiveness of ROPE as well as to compare it to SOTA methods of RGB image-based pose estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and metrics</head><p>We choose the widely used LINEMOD <ref type="bibr" target="#b18">[19]</ref>, its extension Occluded-LINEMOD <ref type="bibr" target="#b2">[3]</ref> and the YCB-Video <ref type="bibr" target="#b61">[62]</ref> datasets for our experiments.</p><p>For LINEMOD, we follow the convention of previous works <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b63">64]</ref> by using 15% of the images of each object as training set and the remaining 85% as testing set. The training images are selected in such a way that the relative rotation between them are larger than a threshold. For each object, we additionally use 1312 rendered images of the isolated object for training, which are obtained from <ref type="bibr" target="#b19">[20]</ref>. For Occluded-LINEMOD the whole dataset is used for testing while images of the corresponding objects in LINEMOD, as well as the rendered images, are used for training. We also follow the protocol of <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b40">41]</ref> for the YCB-Video dataset: we use 80 out of the 92 video sequences as well as the 80000 synthetic images for training, and test on 2949 key frames from the reserved 12 sequences.</p><p>We report the ADD(-S) metric which combines the ADD metric <ref type="bibr" target="#b18">[19]</ref> for asymmetric objects and the ADD-S metric <ref type="bibr" target="#b61">[62]</ref> for symmetric ones. The ADD metric computes the percentage of correctly estimated poses. A pose is considered correct if the object model points, when transformed by the predicted and groundtruth poses respectively, have an average distance of less 10% of the model diameter. For ADD-S, this distance is instead computed based on the closest point distance. The ADD(-S) metric is preferred over the 2D projection metric <ref type="bibr" target="#b3">[4]</ref> because it directly measures the alignment discrepancy in 3D.</p><p>For the YCB-Video dataset we also report the AUC metric proposed in <ref type="bibr" target="#b61">[62]</ref> and adopted in <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b43">44]</ref>. The AUC metric is the area under the ADD(-S) curve when varying the distance threshold for a pose to be deemed correct. We vary this threshold from 0 to 10 cm, in accordance with <ref type="bibr" target="#b61">[62]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation details</head><p>For each object model we apply the farthest point sampling (FPS) algorithm <ref type="bibr" target="#b43">[44]</ref> on the 3D point cloud and select 11 landmarks. The groundtruth 2D landmarks are then obtained by projecting the 3D landmarks with groundtruth camera pose and intrinsics. We use ImgAug <ref type="bibr" target="#b25">[26]</ref> for regular data augmentations including rotation, translation, scaling and color jitter before the OBA. We use the Adam optimizer <ref type="bibr" target="#b28">[29]</ref> and train the model for 250 epochs on LINEMOD and 200 epochs on Occluded-LINEMOD and YCB-Video. We set the landmark verification threshold ? to 1 pixel for all datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation studies</head><p>We conduct various ablation tests to investigate the effect of the proposed OBA and MPS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Model variations</head><p>To verify the efficacy of OBA and MPS, we create two Model Variants (MV) of ROPE:   <ref type="figure">Figure 6</ref>. A toy example for the intuition of incoherence measure c i . The mean residual r i for prediction 1 (blue) and prediction 2 (green) are both 0.608. However, their mean incoherence measure c i are 0.604 and 0.074, respectively. Although both predictions are identical in terms of accuracy, prediction 2 has much better coherence as the green triangle is much more similar in shape to the groundtruth than the blue one.</p><p>1. (MV1: w/ OBA, w/o MPS) While keeping everything else of the original ROPE unchanged, we remove the low and medium-precision keypoint heads, and train the one-head-model with high-precision groundtruth heatmaps.</p><p>2. (MV2: w/o OBA, w/o MPS) On top MV1, we further remove OBA in training. Note that common data augmentations including rotation, translation, scaling and color jitter, are still kept. <ref type="figure" target="#fig_4">Figure 5</ref> shows the overall ADD(-S) on the Occluded-LINEMOD dataset, as well as qualitative results of all model variants. Without both OBA and MPS, object detection can easily fail and landmark prediction is precarious. We can clearly see that occlusion-robust feature learning enforced by OBA significantly increases the reliability of object detection and landmark prediction. In addition, by comparing MV1 and the original model, it is obvious that MPS boosts the structural consistency of the predicted landmarks, especially in occluded regions. This shows that a holistic representation induced by MPS enhances landmark coherence, strengthening the model's ability to extrapolate to the occluded part of the object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Accuracy and coherence of landmarks</head><p>To formally analyse the effect of holistic representation learning, we quantify accuracy and structural consistency of landmark predictions and compare them when trained with and without MPS. For accuracy, we define</p><formula xml:id="formula_2">r i = ?x i ? x * i ? 2<label>(3)</label></formula><p>as the prediction residual of a 2D landmark x i . We also define a measure of incoherence  <ref type="table">Table 1</ref>. Test accuracy on the LINEMOD dataset in terms of the ADD(-S) metric. Objects with a "*" sign are considered as symmetric objects and the ADD-S metric is used. The result of SSD-6D is obtained from <ref type="bibr" target="#b56">[57]</ref>. The result of HybridPose is from its fourth version update in <ref type="bibr" target="#b51">[52]</ref>.  <ref type="table">Table 2</ref>. Test accuracy on the Occluded-LINEMOD dataset in terms of the ADD(-S) metric. Objects with a "*" sign are considered as symmetric objects and the ADD-S metric is used. The result of HybridPose is from its fourth version update in <ref type="bibr" target="#b51">[52]</ref>.</p><formula xml:id="formula_3">c i = ?(x i ? x * i ) ? m? 2<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ADD(-S)</head><p>for a landmark prediction</p><formula xml:id="formula_4">x i where m = 1 n ? n i=1 (x i ? x * i )</formula><p>is the mean error vector for an image. The smaller c i is, the more coherent a prediction x i is, resulting a more consistent structure of prediction to the groundtruth. An intuitive example is shown in <ref type="figure">Figure 6</ref>.</p><p>As shown in <ref type="figure" target="#fig_6">Figure 7</ref>, training with MPS effectively lowers the mean residuals. Furthermore, the mean incoherence are also smaller for all objects. This confirms that a more holistic understanding of the object pose can produce more accurate and structurally consistent landmark predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Comparing to SOTA methods</head><p>We report results on the LINEMOD dataset in Table 1. We group methods into two types depending on whether they include a separate refinement step or not. Our method achieves the best average ADD(-S), as well as the best ADD(-S) on most individual objects. Moreover, our method even outperforms all SOTA methods with refinement, further attesting the power of ROPE. The results on the Occluded-LINEMOD dataset are summarised in Table 2. In the non-refinement group, our method ranked second amongst current SOTA methods overall and best on two individual objects. A sample of qualitative results are provided in <ref type="figure" target="#fig_0">Figures 1 and 5</ref>. The results on the YCB-Video dataset are reported in <ref type="table">Table 3</ref>. Without refinement, ROPE has the best performance when evaluated with ADD(-S).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Data efficiency</head><p>The LINEMOD dataset has about 1200 images for each object, which results in approximately 180 images (15%)  <ref type="table">Table 3</ref>. Test accuracy on the YCB-Video dataset. Objects with a "*" sign are considered as symmetric objects.</p><p>for the training set. To supplement such a small training set many methods generate a large amount of synthetic images. For example, PVNet <ref type="bibr" target="#b43">[44]</ref> renders 20000 images for each object and the same strategy is adopted in <ref type="bibr" target="#b51">[52]</ref>. Although we only use a moderate amount of 1312 synthetic images on top of the 180 in training, we test our model's performance in a extremely data-efficient case: only using the ?180 images for training. As shown in <ref type="table" target="#tab_4">Table 4</ref>, despite having slightly lower ADD(-S) then the baseline, our model achieves an overall accuracy of 93.22% which is close to the current SOTA method GDR <ref type="bibr" target="#b58">[59]</ref>. This is accomplished with as few as around 180 training images, demonstrating superior data efficiency for our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We propose ROPE, a framework for robust object pose estimation against occlusions. We show that enforcing occlusion-robust feature learning and encouraging holistic representation learning are the key to achieve occlusion-robustness. Evaluations on three popularly used benchmark datasets, LINEMOD, Occluded-LINEMOD and YCB-Video, show that ROPE either outperforms or is com-  petitive to SOTA methods, without the need of refinement. Our method is also highly data-efficient.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Qualitative results of our robust object pose estimation on the Occluded-LINEMOD (top and middle) and the YCB-Video (bottom) datasets. Left: prediction of bounding boxes and landmarks of the target object in a test image (zoomed view). Right: prediction of 6DOF poses without post-processing or refinement.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Illustration of an occlude-and-blackout augmented example and the architecture of our heatmap prediction network. For clarity, the backbone and the RPN are represented in the RoI Align module, other modules in the Mask R-CNN framework such as the box head, as well as relevant losses, are not shown. Our model replaces the original mask head with three keypoint heads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Conceptual illustration of holistic representation learning via MPS. Note the difference on the information learned by the feature section S1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>The effect of holistic representation learning in heatmap prediction. Predictions of heatmap 1 are from a model (MV1) trained without MPS while those of heatmap 2 are from the full model (original) with MPS. Details of models (MV1 and original) are provided in Section 4.3.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Comparing performances of model variants on the Occluded-LINEMOD dataset with qualitative examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Comparing the results of training with and without MPS on LINEMOD, while keeping all else equal. The vertical location of each bubble represents the mean prediction residual r i of all landmarks in the testing sets. The size of each bubble indicates the mean incoherence c i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>38.98 53.90 60.10 66.59 66.04 73.40 84.40 79.88 81.90 84.50</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>ADD(-S)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">AUC of ADD(-S)</cell></row><row><cell></cell><cell></cell><cell cols="3">Without refinement</cell><cell></cell><cell></cell><cell cols="2">Without refinement</cell><cell></cell><cell cols="2">With refinement</cell></row><row><cell></cell><cell>HM</cell><cell>Hu</cell><cell cols="2">Hu2 GDR</cell><cell>Ours</cell><cell cols="6">HM PVNet GDR Ours DeepIM CosyPose</cell></row><row><cell></cell><cell>[41]</cell><cell>[23]</cell><cell>[22]</cell><cell>[59]</cell><cell></cell><cell>[41]</cell><cell>[44]</cell><cell>[59]</cell><cell></cell><cell>[34]</cell><cell>[30]</cell></row><row><cell>master chef can</cell><cell cols="2">31.20 33.00</cell><cell>-</cell><cell>-</cell><cell>46.52</cell><cell>69.00</cell><cell>-</cell><cell>-</cell><cell>71.17</cell><cell>71.20</cell><cell>-</cell></row><row><cell>cracker box</cell><cell cols="2">75.00 44.60</cell><cell>-</cell><cell>-</cell><cell>92.63</cell><cell>80.20</cell><cell>-</cell><cell>-</cell><cell>89.86</cell><cell>83.60</cell><cell>-</cell></row><row><cell>sugar box</cell><cell cols="2">47.20 75.60</cell><cell>-</cell><cell>-</cell><cell>99.15</cell><cell>76.20</cell><cell>-</cell><cell>-</cell><cell>93.21</cell><cell>94.10</cell><cell>-</cell></row><row><cell>tomato soup can</cell><cell cols="2">30.20 40.80</cell><cell>-</cell><cell>-</cell><cell>60.90</cell><cell>70.00</cell><cell>-</cell><cell>-</cell><cell>82.53</cell><cell>86.10</cell><cell>-</cell></row><row><cell>mustard bottle</cell><cell cols="2">72.50 70.60</cell><cell>-</cell><cell>-</cell><cell cols="2">100.00 84.80</cell><cell>-</cell><cell>-</cell><cell>95.34</cell><cell>91.50</cell><cell>-</cell></row><row><cell>tuna fish can</cell><cell cols="2">4.31 18.10</cell><cell>-</cell><cell>-</cell><cell>52.96</cell><cell>49.40</cell><cell>-</cell><cell>-</cell><cell>88.01</cell><cell>87.70</cell><cell>-</cell></row><row><cell>pudding box</cell><cell cols="2">48.30 12.20</cell><cell>-</cell><cell>-</cell><cell>79.91</cell><cell>82.20</cell><cell>-</cell><cell>-</cell><cell>90.5</cell><cell>82.70</cell><cell>-</cell></row><row><cell>gelatin box</cell><cell cols="2">37.20 59.40</cell><cell>-</cell><cell>-</cell><cell>58.88</cell><cell>81.80</cell><cell>-</cell><cell>-</cell><cell>89.36</cell><cell>91.90</cell><cell>-</cell></row><row><cell>potted meat can</cell><cell cols="2">40.30 33.30</cell><cell>-</cell><cell>-</cell><cell>58.62</cell><cell>66.20</cell><cell>-</cell><cell>-</cell><cell>74.54</cell><cell>76.20</cell><cell>-</cell></row><row><cell>banana</cell><cell cols="2">6.20 16.60</cell><cell>-</cell><cell>-</cell><cell>36.94</cell><cell>52.90</cell><cell>-</cell><cell>-</cell><cell>58.77</cell><cell>81.20</cell><cell>-</cell></row><row><cell>pitcher base</cell><cell cols="2">53.80 90.00</cell><cell>-</cell><cell>-</cell><cell>99.65</cell><cell>69.90</cell><cell>-</cell><cell>-</cell><cell>92.86</cell><cell>90.10</cell><cell>-</cell></row><row><cell>bleach cleanser</cell><cell cols="2">57.20 70.90</cell><cell>-</cell><cell>-</cell><cell>75.22</cell><cell>73.30</cell><cell>-</cell><cell>-</cell><cell>77.35</cell><cell>81.20</cell><cell>-</cell></row><row><cell>bowl*</cell><cell cols="2">49.50 30.50</cell><cell>-</cell><cell>-</cell><cell>45.07</cell><cell>80.30</cell><cell>-</cell><cell>-</cell><cell>70.81</cell><cell>81.40</cell><cell>-</cell></row><row><cell>mug</cell><cell cols="2">10.50 40.70</cell><cell>-</cell><cell>-</cell><cell>66.04</cell><cell>50.50</cell><cell>-</cell><cell>-</cell><cell>89.1</cell><cell>81.40</cell><cell>-</cell></row><row><cell>power drill</cell><cell cols="2">63.00 63.50</cell><cell>-</cell><cell>-</cell><cell>94.99</cell><cell>78.30</cell><cell>-</cell><cell>-</cell><cell>89.4</cell><cell>85.50</cell><cell>-</cell></row><row><cell>wood block*</cell><cell cols="2">48.20 27.70</cell><cell>-</cell><cell>-</cell><cell>55.37</cell><cell>65.20</cell><cell>-</cell><cell>-</cell><cell>70.62</cell><cell>81.90</cell><cell>-</cell></row><row><cell>scissors</cell><cell cols="2">0.55 17.10</cell><cell>-</cell><cell>-</cell><cell>71.27</cell><cell>28.20</cell><cell>-</cell><cell>-</cell><cell>84.82</cell><cell>60.90</cell><cell>-</cell></row><row><cell>large marker</cell><cell cols="2">11.70 4.80</cell><cell>-</cell><cell>-</cell><cell>11.73</cell><cell>48.20</cell><cell>-</cell><cell>-</cell><cell>53.25</cell><cell>75.60</cell><cell>-</cell></row><row><cell>large clamp*</cell><cell cols="2">12.20 25.60</cell><cell>-</cell><cell>-</cell><cell>68.12</cell><cell>47.20</cell><cell>-</cell><cell>-</cell><cell>77.1</cell><cell>74.30</cell><cell>-</cell></row><row><cell cols="3">extra large clamp* 17.30 8.80</cell><cell>-</cell><cell>-</cell><cell>56.16</cell><cell>47.50</cell><cell>-</cell><cell>-</cell><cell>55.19</cell><cell>73.30</cell><cell>-</cell></row><row><cell>foam brick*</cell><cell cols="2">63.80 34.70</cell><cell>-</cell><cell>-</cell><cell>68.40</cell><cell>85.60</cell><cell>-</cell><cell>-</cell><cell>83.78</cell><cell>81.90</cell><cell>-</cell></row><row><cell>average</cell><cell>37.15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Comparing performances of ROPE in the extremely dataefficient setting (?180) and in the original setting (?1500) on the LINEMOD dataset. Both models are without refinement.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Augmented reality meets deep learning for car instance segmentation in urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Hassan Abu Alhaija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Karthik Mustikovela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generalizing the hough transform to detect arbitrary shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="122" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning 6d object pose estimation using 3d object coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Krull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Uncertainty-driven 6d pose estimation of objects and scenes from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Krull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Ying</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reconstruct locally, localize globally: A model free method for object pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Review of the robustness and applicability of monocular pose estimation systems for relative navigation with an uncooperative spacecraft. Progress in Aerospace Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Lorenzo Pasqualetto Cassinis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eberhard</forename><surname>Fonod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Satellite pose estimation with deep landmark regression and nonlinear pose refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiewei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Parra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Jun</forename><surname>Chin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCVW</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">End-to-end learnable geometric vision by backpropagating pnp optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Parra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiewei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Jun</forename><surname>Chin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fs-net: Fast shape-based network for category-level 6d object pose estimation with decoupled rotation mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Hyung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinming</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1581" to="1590" />
		</imprint>
	</monogr>
	<note>Linlin Shen, and Ales Leonardis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-view 3d object detection network for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huimin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The moped framework: Object recognition and pose estimation for manipulation. The international journal of robotics research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Collet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><forename type="middle">S</forename><surname>Srinivasa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1284" to="1306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robust 3d object tracking from monocular images using stable parts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Crivellaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Verdie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1465" to="1479" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh-Toan</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trung</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.10367</idno>
		<title level="m">Deep-6dpose: Recovering 6d object pose from a single rgb image</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Jensen-shannon divergence and hilbert space embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bent</forename><surname>Fuglede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flemming</forename><surname>Topsoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The International Symposium on Information Theory</title>
		<meeting>The International Symposium on Information Theory</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Discriminative mixture-oftemplates for viewpoint classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhui</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mask r-cnn. TPAMI</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Pvn3d: A deep point-wise 3d keypoints voting network for 6dof pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianran</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqiang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gradient response maps for real-time detection of textureless objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Hinterstoisser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cedric</forename><surname>Cagniart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="876" to="888" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Model based training, detection and pose estimation of texture-less 3d objects in heavily cluttered scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Hinterstoisser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Holzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Bradski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Konolige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bop: Benchmark for 6d object pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Hodan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wadim</forename><surname>Kehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Glentbuch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Kraft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertram</forename><surname>Drost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Ihrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xenophon</forename><surname>Zabulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Augment your batch: Improving generalization through instance repetition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itay</forename><surname>Ben-Nun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Giladi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hoefler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soudry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Single-stage 6d object pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinlin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Segmentation-driven 6d object pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinlin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Hugonot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Comparing images using the hausdorff distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">A</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">J</forename><surname>Klanderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rucklidge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="850" to="863" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">ipose: instance-aware 6d pose estimation of partly occluded objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omid</forename><surname>Hosseini Jafari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Karthik Mustikovela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pertsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">B</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Wada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Crall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Graving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Reinders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarthak</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joy</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?bor</forename><surname>Vecsei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kraft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jirka</forename><surname>Borovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Vallentin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Semen</forename><surname>Zhydenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Pfeiffer</surname></persName>
		</author>
		<ptr target="https://github.com/aleju/imgaug,2020.Online" />
		<editor>Weng, Abner Ayala-Acevedo, Raphael Meudec, Matias Laporte, et al. imgaug</editor>
		<imprint>
			<date type="published" when="2020-02-05" />
			<biblScope unit="page">1</biblScope>
			<pubPlace>Ben Cook, Ismael Fern?ndez, Fran?ois-Michel De Rainville</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ssd-6d: Making rgb-based 3d detection and 6d pose estimation great again</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wadim</forename><surname>Kehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Manhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Posenet: A convolutional network for real-time 6-dof camera relocalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Grimes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cosypose: Consistent multi-view multi-object 6d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Labb?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Carpentier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aubry</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Monocular model-based 3d tracking of rigid objects: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends? in Computer Graphics and Vision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="89" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep supervision with shape concepts for occlusion-aware 3d object parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc-Huy</forename><surname>Zeeshan Zia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deepim: Deep iterative matching for 6d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deepim: Deep iterative matching for 6d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="657" to="678" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cdpn: Coordinates-based disentangled pose network for real-time rgb-based 6-dof object pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Object recognition from local scale-invariant features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep model-based 6d pose refinement in rgb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Manhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wadim</forename><surname>Kehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Pose estimation for augmented reality: a hands-on survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideaki</forename><surname>Uchiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Spindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2633" to="2651" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Global hypothesis generation for 6d object pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Krull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Savchynskyy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Making deep heatmaps robust to partial occlusions for 3d object pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Oberweger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdi</forename><surname>Rad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Pix2pose: Pixel-wise coordinate regression of objects for 6d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiru</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Patten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Vincze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Pvnet: Pixel-wise voting network for 6dof pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hujun</forename><surname>Bao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Fast single shot detection and pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Poirson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Ammirato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Kosecka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Fourth International Conference on 3D Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Bb8: A scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdi</forename><surname>Rad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Yolo9000: better, faster, stronger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Understanding the limitations of cnn-based absolute camera pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qunjie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taixe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Pose estimation for non-cooperative spacecraft rendezvous using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beierle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>D&amp;apos;amico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Aerospace Conference</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Hide-and-seek: Forcing a network to be meticulous for weakly-supervised object and action localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><forename type="middle">Kumar</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Jae</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Hybridpose: 6d object pose estimation under hybrid representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaru</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaru</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.01869</idno>
		<title level="m">Hybridpose: 6d object pose estimation under hybrid representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Render for cnn: Viewpoint estimation in images using cnns trained with rendered 3d model views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Multi-path learning for object pose estimation across domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Durner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<meeting><address><addrLine>Kai O Arras, and Rudolph Triebel</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note>En Yen Puang, Zoltan-Csaba Marton, Narunas Vaskevicius</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Augmented autoencoders: Implicit 3d orientation learning for 6d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Zoltan-Csaba Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolph</forename><surname>Durner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Triebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="714" to="729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Real-time seamless single shot 6d object pose prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bugra Tekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sudipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Densefusion: 6d object pose estimation by iterative dense fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danfei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Mart?n-Mart?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Gdr-net: Geometry-guided direct regression network for monocular 6d object pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Manhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Deep high-resolution representation learning for visual recognition. TPAMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">6d-vnet: End-to-end 6-dof vehicle pose estimation from monocular rgb images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyong</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canqun</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPRW</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Posecnn: A convolutional neural network for 6d object pose estimation in cluttered scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanner</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatraman</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems (RSS)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Pointfusion: Deep sensor fusion for 3d bounding box estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danfei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashesh</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Dpod: 6d pose object detector and refiner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zakharov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Shugurov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Random erasing data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaozi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Single image 3d object detection and pose estimation for grasping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konstantinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samarth</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mabel</forename><surname>Brahmbhatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cody</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Lecce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Craves: Controlling robotic arm with a vision-based economic system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weichao</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangwei</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
