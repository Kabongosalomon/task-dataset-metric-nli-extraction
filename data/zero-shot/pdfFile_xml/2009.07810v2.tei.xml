<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CODEX: A Comprehensive Knowledge Graph Completion Benchmark</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><surname>Safavi</surname></persName>
							<email>tsafavi@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danai</forename><surname>Koutra</surname></persName>
							<email>dkoutra@umich.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CODEX: A Comprehensive Knowledge Graph Completion Benchmark</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present CODEX, a set of knowledge graph COmpletion Datasets EXtracted from Wikidata and Wikipedia that improve upon existing knowledge graph completion benchmarks in scope and level of difficulty. In terms of scope, CODEX comprises three knowledge graphs varying in size and structure, multilingual descriptions of entities and relations, and tens of thousands of hard negative triples that are plausible but verified to be false. To characterize CODEX, we contribute thorough empirical analyses and benchmarking experiments. First, we analyze each CODEX dataset in terms of logical relation patterns. Next, we report baseline link prediction and triple classification results on CODEX for five extensively tuned embedding models. Finally, we differentiate CODEX from the popular FB15K-237 knowledge graph completion dataset by showing that CODEX covers more diverse and interpretable content, and is a more difficult link prediction benchmark. Data, code, and pretrained models are available at https://bit.ly/2EPbrJs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graphs are multi-relational graphs that express facts about the world by connecting entities (people, places, things, concepts) via different types of relationships. The field of automatic knowledge graph completion (KGC), which is motivated by the fact that knowledge graphs are usually incomplete, is an active research direction spanning several subfields of artificial intelligence <ref type="bibr">(Nickel et al., 2015;</ref><ref type="bibr">Wang et al., 2017;</ref><ref type="bibr">Ji et al., 2020)</ref>.</p><p>As progress in artificial intelligence depends heavily on data, a relevant and high-quality benchmark is imperative to evaluating and advancing the state of the art in KGC. However, the field has largely remained static in this regard over the past decade. Outdated subsets of Freebase <ref type="bibr">(Bollacker et al., 2008)</ref> are most commonly used for evaluation in KGC, even though Freebase had known quality issues <ref type="bibr">(Tanon et al., 2016)</ref> and was eventually deprecated in favor of the more recent Wikidata knowledge base <ref type="bibr">(Vrande?i? and Kr?tzsch, 2014)</ref>.</p><p>Indeed, KGC benchmarks extracted from Freebase like <ref type="bibr">FB15K and FB15K-237 (Bordes et al., 2013;</ref><ref type="bibr">Toutanova and Chen, 2015)</ref> are questionable in quality. For example, FB15K was shown to have train/test leakage <ref type="bibr">(Toutanova and Chen, 2015)</ref>. Later in this paper ( ? 6.2), we will show that a relatively large proportion of relations in FB15K-237 can be covered by a trivial frequency rule.</p><p>To address the need for a solid benchmark in KGC, we present CODEX, a set of knowledge graph COmpletion Datasets EXtracted from Wikidata and its sister project Wikipedia. Inasmuch as Wikidata is considered the successor of Freebase, CODEX improves upon existing Freebase-based KGC benchmarks in terms of scope and level of difficulty <ref type="table" target="#tab_0">(Table 1)</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. Our contributions include:</head><p>Foundations We survey evaluation datasets in encyclopedic knowledge graph completion to motivate a new benchmark ( ? 2 and Appendix A).</p><p>Data We introduce CODEX, a benchmark consisting of three knowledge graphs varying in size and structure, entity types, multilingual labels and descriptions, and-unique to CODEX-manually verified hard negative triples ( ? 3). To better understand CODEX, we analyze the logical relation patterns in each of its datasets ( ? 4).</p><p>Benchmarking We conduct large-scale model selection and benchmarking experiments, reporting baseline link prediction and triple classification results on CODEX for five widely used embedding models from different architectural classes ( ? 5).</p><p>Comparative analysis Finally, to demonstrate the unique value of CODEX, we differentiate Multi-domain, with focuses on writing, entertainment, music, politics, journalism, academics, and science ( ? 6.1 and Appendix E) Scope (auxiliary data) Various decentralized versions of FB15K with, e.g., entity types <ref type="bibr">(Xie et al., 2016)</ref>, sampled negatives <ref type="bibr">(Socher et al., 2013)</ref>, and more <ref type="table" target="#tab_9">(Table 8)</ref> Centralized repository of three datasets with entity types, multilingual text, and manually annotated hard negatives ( ? 3)</p><p>Level of difficulty FB15K has severe train/test leakage from inverse relations <ref type="bibr">(Toutanova and Chen, 2015)</ref>; while removal of inverse relations makes FB15K-237 harder than FB15K, FB15K-237 still has a high proportion of easy-to-predict relational patterns ( ? 6.2)</p><p>Inverse relations removed from all datasets to avoid train/test leakage ( ? 3.2); manually annotated hard negatives for the task of triple classification ( ? 3.4); few trivial patterns for the task of link prediction <ref type="bibr">( ? 6.2)</ref> CODEX from FB15K-237 in terms of both content and difficulty <ref type="bibr">( ? 6)</ref>. We show that CODEX covers more diverse and interpretable content, and is a more challenging link prediction benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Existing datasets</head><p>We begin by surveying existing KGC benchmarks. <ref type="table" target="#tab_9">Table 8</ref> in Appendix A provides an overview of evaluation datasets and tasks on a per-paper basis across the artificial intelligence, machine learning, and natural language processing communities. Note that we focus on data rather than models, so we only overview relevant evaluation benchmarks here. For more on existing KGC models, both neural and symbolic, we refer the reader to <ref type="bibr">(Meilicke et al., 2018)</ref> and <ref type="bibr">(Ji et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Freebase extracts</head><p>These datasets, extracted from the Freebase knowledge graph <ref type="bibr">(Bollacker et al., 2008)</ref>, are the most popular for KGC (see <ref type="table" target="#tab_9">Table 8</ref> in Appendix A).</p><p>FB15K was introduced by Bordes et al. <ref type="bibr">(2013)</ref>. It contains 14,951 entities, 1,345 relations, and 592,213 triples covering several domains, with a strong focus on awards, entertainment, and sports.</p><p>FB15K-237 was introduced by Toutanova and Chen (2015) to remedy data leakage in FB15K, which contains many test triples that invert triples in the training set. FB15K-237 contains 14,541 entities, 237 relations, and 310,116 triples. We compare FB15K-237 to CODEX in ? 6 to assess each dataset's content and relative difficulty. <ref type="bibr">-995 (Xiong et al., 2017)</ref> was taken from the Never Ending Language Learner (NELL) sys-tem <ref type="bibr">(Mitchell et al., 2018)</ref>, which continuously reads the web to obtain and update its knowledge. NELL-995, a subset of the 995th iteration of <ref type="bibr">NELL,</ref><ref type="bibr">contains 75,</ref><ref type="bibr">492 entities,</ref><ref type="bibr">200 relations,</ref><ref type="bibr">and 154,</ref><ref type="bibr">213</ref> triples. While NELL-995 is general and covers many domains, its mean average precision was less than 50% around its 1000th iteration <ref type="bibr">(Mitchell et al., 2018)</ref>. A cursory inspection reveals that many of the triples in NELL-995 are nonsensical or overly generic, suggesting that NELL-995 is not a meaningful dataset for KGC evaluation. 1 <ref type="bibr">-10 (Dettmers et al., 2018)</ref> is a subset of YAGO3 <ref type="bibr">(Mahdisoltani et al., 2014)</ref>, which covers portions of Wikipedia, Wikidata, and Word-Net. YAGO3-10 has 123,182 entities, 37 relations, and 1,089,040 triples mostly limited to facts about people and locations. While YAGO3-10 is a highprecision dataset, it was recently shown to be too easy for link prediction because it contains a large proportion of duplicate relations <ref type="bibr" target="#b0">(Akrami et al., 2020;</ref><ref type="bibr">Pezeshkpour et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Other encyclopedic datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NELL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>YAGO3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Domain-specific datasets</head><p>In addition to large encyclopedic knowledge graphs, it is common to evaluate KGC methods on at least one smaller, domain-specific dataset, typically drawn from the WordNet semantic network <ref type="bibr">(Miller, 1998;</ref><ref type="bibr">Bordes et al., 2013)</ref>. Other choices include the Unified Medical Language System (UMLS) database <ref type="bibr">(McCray, 2003)</ref>, the Alyawarra kinship dataset <ref type="bibr">(Kemp et al., 2006)</ref>, the Countries dataset <ref type="bibr">(Bouchard et al., 2015)</ref>, and variants of a synthetic "family tree" <ref type="bibr">(Hinton, 1986)</ref>. As our focus in this paper is encyclopedic knowledge, we do not cover these datasets further. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data collection</head><p>In this section we describe the pipeline used to construct CODEX. For reference, we define a knowledge graph G as a multi-relational graph consisting of a set of entities E, relations R, and factual statements in the form of (head, relation, tail) triples (h, r, t) ? E ? R ? E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Seeding the collection</head><p>We collected an initial set of triples using a type of snowball sampling <ref type="bibr">(Goodman, 1961)</ref>. We first manually defined a broad seed set of entity and relation types common to 13 domains: Business, geography, literature, media and entertainment, medicine, music, news, politics, religion, science, sports, travel, and visual art. Examples of seed entity types include airline, journalist, and religious text; corresponding seed relation types in each respective domain include airline alliance, notable works, and language of work or name. <ref type="table" target="#tab_10">Table 9</ref> in Appendix B gives all seed entity and relation types. Using these seeds, we retrieved an initial set of 380,038 entities, 75 relations, and 1,156,222 triples by querying Wikidata for statements of the form (head entity of seed type, seed relation type, ?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Filtering the collection</head><p>To create smaller data snapshots, we filtered the initial 1.15 million triples to k-cores, which are maximal subgraphs G of a given graph G such that every node in G has a degree of at least k (Batagelj and Zaver?nik, 2011). <ref type="bibr">2</ref> We constructed three CODEX datasets <ref type="table" target="#tab_1">(Table 2)</ref>:</p><p>? CODEX-S (k = 15), which has 36k triples.</p><p>Because of its smaller size, we recommend that CODEX-S be used for model testing and debugging, as well as evaluation of methods that are less computationally efficient (e.g., symbolic search-based approaches).</p><p>? CODEX-M (k = 10), which has 206k triples. CODEX-M is all-purpose, being comparable in size to FB15K-237 ( ? 2.1), one of the most popular benchmarks for KGC evaluation.</p><p>? CODEX-L (k = 5), which has 612k triples. CODEX-L is comparable in size to FB15K ( ? 2.1), and can be used for both general evaluation and "few-shot" evaluation.</p><p>We also release the raw dump that we collected via snowball sampling, but focus on CODEX-S through L for the remainder of this paper.</p><p>To minimize train/test leakage, we removed inverse relations from each dataset <ref type="bibr">(Toutanova and Chen, 2015)</ref>. We computed (head, tail) and (tail, head) overlap between all pairs of relations, and removed each relation whose entity pair set overlapped with that of another relation more than 50% of the time. Finally, we split each dataset into 90/5/5 train/validation/test triples such that the validation and test sets contained only entities and relations seen in the respective training sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Auxiliary information</head><p>An advantage of Wikidata is that it links entities and relations to various sources of rich auxiliary information. To enable tasks that involve joint learning over knowledge graph structure and such additional information, we collected:</p><p>? Entity types for each entity as given by Wikidata's instance of and subclass of relations;</p><p>? Wikidata labels and descriptions for entities, relations, and entity types; and</p><p>? Wikipedia page extracts (introduction sections) for entities and entity types.</p><p>For the latter two, we collected text where available in Arabic, German, English, Spanish, Russian, and Chinese. We chose these languages because they are all relatively well-represented on Wikidata <ref type="bibr">(Kaffee et al., 2017)</ref>. <ref type="table" target="#tab_1">Table 2</ref> provides the coverage by language for each CODEX dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Hard negatives for evaluation</head><p>Knowledge graphs are unique in that they only contain positive statements, meaning that triples not observed in a given knowledge graph are not necessarily false, but merely unseen; this is called the Open World Assumption <ref type="bibr">(Gal?rraga et al., 2013)</ref>. However, most machine learning tasks on knowledge graphs require negatives in some capacity. While different negative sampling strategies exist (Cai and Wang, 2018), the most common approach is to randomly perturb observed triples to generate negatives, following <ref type="bibr">Bordes et al. (2013)</ref>. While random negative sampling is beneficial and even necessary in the case where a large number of negatives is needed (i.e., training), it is not necessarily useful for evaluation. For example, in the task of triple classification, the goal is to discriminate between positive (true) and negative (false) triples. As we show in ? 5.5, triple classification over randomly generated negatives is trivially easy for state-of-the-art models because random negatives are generally not meaningful or plausible. Therefore, we generate and manually evaluate hard negatives for KGC evaluation.</p><p>Generation To generate hard negatives, we used each pre-trained embedding model from ? 5.2 to predict tail entities of triples in CODEX. For each model, we took as candidate negatives the triples (h, r,t) for which (i) the type of the predicted tail entityt matched the type of the true tail entity t; (ii)t was ranked in the top-10 predictions by that model; and (iii) (h, r,t) was not observed in G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Annotation</head><p>We manually labeled all candidate negative triples generated for CODEX-S and CODEX-M as true or false using the guidelines provided in Appendix C. <ref type="bibr">3</ref> We randomly selected among the triples labeled as false to create validation and test negatives for CODEX-S and CODEX-M, examples of which are given in Ta- <ref type="bibr">3</ref> We are currently investigating methods for obtaining highquality crowdsourced annotations of negatives for CODEX-L. ble 3. To assess the quality of our annotations, we gathered judgments from two independent native English speakers on a random selection of 100 candidate negatives. The annotators were provided the instructions from Appendix C. On average, our labels agreed with those of the annotators 89.5% of the time. Among the disagreements, 81% of the time we assigned the label true whereas the annotator assigned the label false, meaning that we were comparatively conservative in labeling negatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Analysis of relation patterns</head><p>To give an idea of the types of reasoning necessary for models to perform well on CODEX, we analyze the presence of learnable binary relation patterns within CODEX. The three main types of such patterns in knowledge graphs are symmetry, inversion, and compositionality <ref type="bibr">(Trouillon et al., 2019;</ref><ref type="bibr">Sun et al., 2019)</ref>. We address symmetry and compositionality here, and omit inversion because we specifically removed inverse relations to avoid train/test leakage ( ? 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Symmetry</head><p>Symmetric relations are relations r for which (h, r, t) ? G implies (t, r, h) ? G. For each relation, we compute the number of its (head, tail) pairs that overlap with its (tail, head) pairs, divided by the total number of pairs, and take those with 50% overlap or higher as symmetric. CODEX datasets have five such relations: diplomatic relation, shares border with, sibling, spouse, and unmarried partner. <ref type="table" target="#tab_3">Table 4</ref> gives the proportion of triples containing symmetric relations per dataset. Symmetric patterns are more prevalent in CODEX-S, whereas the larger datasets are mostly antisymmetric, i.e., (h, r, t) ? G implies (t, r, h) ? G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Composition</head><p>Compositionality captures path rules of the form (h, r 1 , x 1 ), . . . , (x n , r n , t) ? (h, r, t). To learn these rules, models must be capable of "multi-hop" reasoning on knowledge graphs <ref type="bibr">(Guu et al., 2015)</ref>. To identify compositional paths, we use the AMIE3 system <ref type="bibr">(Lajus et al., 2020)</ref>, which outputs rules with confidence scores that capture how many times those rules are seen versus violated, to identify paths of lengths two and three; we omit longer paths as they are relatively costly to compute. We identify 26, 44, and 93 rules in CODEX-S, CODEX-M, and CODEX-L, respectively, with average confidence (out of 1) of 0.630, 0.556, and 0.459. <ref type="table" target="#tab_3">Table 4</ref> gives the percentage of triples per dataset participating in a discovered rule.</p><p>Evidently, composition is especially prevalent in CODEX-L. An example rule in CODEX-L is "if X was founded by Y, and Y's country of citizenship is Z, then the country [i.e., of origin] of X is Z" (confidence 0.709). We release these rules as part of CODEX for further development of KGC methodologies that incorporate or learn rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Benchmarking</head><p>Next, we benchmark performance on CODEX for the tasks of link prediction and triple classification. To ensure that models are fairly and accurately compared, we follow <ref type="bibr">Ruffinelli et al. (2020)</ref>, who conducted what is (to the best of our knowledge) the largest-scale hyperparameter tuning study of knowledge graph embeddings to date.</p><p>Note that CODEX can be used to evaluate any type of KGC method. However, we focus on embeddings in this section due to their widespread usage in modern NLP (Ji et al., 2020).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Tasks</head><p>Link prediction The link prediction task is conducted as follows: Given a test triple (h, r, t), we construct queries (?, r, t) and (h, r, ?). For each query, a model scores candidate head (tail) entitie? h (t) according to its belief that? (t) completes the triple (i.e., answers the query). The goal is of link prediction is to rank true triples (?, r, t) or (h, r,t) higher than false and unseen triples.</p><p>Link prediction performance is evaluated with mean reciprocal rank (MRR) and hits@k. MRR is the average reciprocal of each ground-truth entity's rank over all (?, r, t) and (h, r, ?) test triples. Hits@k measures the proportion of test triples for which the ground-truth entity is ranked in the top-k predicted entities. In computing these metrics, we exclude the predicted entities for which (?, r, t) ? G or (h, r,t) ? G so that known positive triples do not artificially lower ranking scores. This is called "filtering" <ref type="bibr">(Bordes et al., 2013)</ref>.</p><p>Triple classification Given a triple (h, r, t), the goal of triple classification is to predict a corresponding label y ? {?1, 1}. Since knowledge graph embedding models output real-valued scores for triples, we convert these scores into labels by selecting a decision threshold per relation on the validation set such that validation accuracy is maximized for the model in question. A similar approach was used by <ref type="bibr">Socher et al. (2013)</ref>. We compare results on three sets of evaluation negatives: (1) We generate one negative per positive by replacing the positive triple's tail entity by a tail entity t sampled uniformly at random;</p><p>(2) We generate negatives by sampling tail entities according to their relative frequency in the tail slot of all triples; and <ref type="formula">(3)</ref> We use the CODEX hard negatives. We measure accuracy and F1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Models</head><p>We compare the following embedding methods: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Model selection</head><p>As recent studies have observed that training strategies are equally, if not more, important than architecture for link prediction <ref type="bibr">(Kadlec et al., 2017;</ref><ref type="bibr">Lacroix et al., 2018;</ref><ref type="bibr">Ruffinelli et al., 2020)</ref>, we search across a large range of hyperparameters to ensure a truly fair comparison. To this end we use the PyTorch-based LibKGE framework for training and selecting knowledge graph embeddings. <ref type="bibr">4</ref> In the remainder of this section we outline the most important parameters of our model selection process.  Loss functions We consider the following loss functions: (i) MR or margin ranking, which aims to maximize a margin between positive and negative triples; (ii) BCE or binary cross-entropy, which is computed by applying the logistic sigmoid to triple scores; and (iii) CE or cross-entropy between the softmax over the entire distribution of triple scores and the label distribution over all triples, normalized to sum to one.</p><p>Search strategies We select models using the Ax platform, which supports hyperparameter search using both quasi-random sequences of generated configurations and Bayesian optimization (BO) with Gaussian processes. 5 At a high level, for each dataset and model, we generate both quasirandom and BO trials per negative sampling and loss function combination, ensuring that we search over a wide range of hyperparameters for different types of training strategy. Appendix F provides specific details on the search strategy for each dataset, which was determined according to resource constraints and observed performance patterns.  <ref type="table" target="#tab_4">Table 5</ref> gives link prediction results. We find that ComplEx is the best at modeling symmetry and antisymmetry, and indeed it was designed specifically to improve upon bilinear models that do not capture symmetry, like <ref type="bibr">DistMult (Trouillon et al., 2016)</ref>. As such, it performs the best on CODEX-S, which has the highest proportion of symmetric relations. For example, on the most frequent symmetric relation (diplomatic relation), ComplEx achieves 0.859 MRR, compared to 0.793 for ConvE, 0.490 for RESCAL, and 0.281 for TransE. By contrast, TuckER is strongest at modeling compositional relations, so it performs best on CODEX-L, which has a high degree of compositionality. For example, on the most frequent compositional relation in CODEX-L (languages spoken, written, or signed), TuckER achieves 0.465 MRR, compared to 0.464 for RESCAL, 0.463 for ConvE, 0.456 for ComplEx, and 0.385 for TransE. By contrast, since CODEX-M is mostly asymmetric and non-compositional, ComplEx performs best because of its ability to model asymmetry. <ref type="figure">Figure 1</ref>, hyperparameters have a strong impact on link prediction performance: Validation MRR for all models varies by over 30 percentage points depending on the training strategy and input configuration. This finding is consistent with previous observations in the literature <ref type="bibr">(Kadlec et al., 2017;</ref><ref type="bibr">Ruffinelli et al., 2020)</ref>. Appendix F provides the best configurations for each model. Overall, we find that the choice of loss function in particular significantly impacts model performance. Each model consistently achieved its respective peak performance with cross-entropy (CE) loss, a finding which is corroborated by several other KGC comparison papers <ref type="bibr">(Kadlec et al., 2017;</ref><ref type="bibr">Ruffinelli et al., 2020;</ref><ref type="bibr">Jain et al., 2020)</ref>. As far as negative sampling techniques, we do not find that a single strategy is dominant, suggesting that the choice of loss function is more important. <ref type="table" target="#tab_6">Table 6</ref> gives triple classification results. Evidently, triple classification on randomly generated negatives is a nearly-solved task. On negatives generated uniformly at random, performance scores are nearly identical at almost 100% accuracy. Even with a negative sampling strategy "smarter" than uniform random, all models perform well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Link prediction results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of hyperparameters As shown by</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Triple classification results</head><p>Hard negatives Classification performance degenerates considerably on our hard negatives, around 8 to 11 percentage points from relative frequency-based sampling and 13 to 19 percentage points from uniformly random sampling. Relative performance also varies: In contrast to our link prediction task in which ComplEx and TuckER were by far the strongest models, RESCAL is slightly stronger on the CODEX-S hard negatives, whereas ConvE performs best on the CODEX-M hard negatives. These results indicate that triple classification is indeed a distinct task that requires different architectures and, in many cases, different training strategies (Appendix F).</p><p>We believe that few recent works use triple classification as an evaluation task because of the lack of true hard negatives in existing benchmarks. Early works reported high triple classification accuracy on sampled negatives <ref type="bibr">(Socher et al., 2013;</ref><ref type="bibr">Wang et al., 2014)</ref>, perhaps leading the community to believe that the task was nearly solved. However, our results demonstrate that the task is far from solved when the negatives are plausible but truly false.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Comparative case study</head><p>Finally, we conduct a comparative analysis between CODEX-M and FB15K-237 ( ? 2.1) to demonstrate the unique value of CODEX. We choose FB15K-237 because it is the most popular encyclopedic KGC benchmark after FB15K, which was already shown to be an easy dataset by Toutanova and Chen <ref type="formula">(2015)</ref>. We choose CODEX-M because it is the closest in size to FB15K-237.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Content</head><p>We first compare the content in CODEX-M, which is extracted from Wikidata, with that of FB15K-237, which is extracted from Freebase. For brevity, <ref type="figure" target="#fig_2">Figure 2</ref> compares the top-15 relations by mention count in the two datasets. Appendix E provides more content comparisons.</p><p>Diversity The most common relation in CODEX-M is occupation, which is because most people on Wikidata have multiple occupations listed. By contrast, the frequent relations in FB15K-237 are mostly related to awards and film. In fact, over 25% of all triples in FB15K-237 belong to the /award relation domain, suggesting that CODEX covers a more diverse selection of content.</p><p>Interpretability The Freebase-style relations are also arguably less interpretable than those in Wikidata. Whereas Wikidata relations have concise natural language labels, the Freebase relation labels are hierarchical, often at five or six levels of hierarchy ( <ref type="figure" target="#fig_2">Figure 2)</ref>. Moreover, all relations in Wikidata are binary, whereas some Freebase relations are n-nary <ref type="bibr">(Tanon et al., 2016)</ref>, meaning that they connect more than two entities. The relations containing a dot (".") are such n-nary relations, and are difficult to reason about without understanding the structure of Freebase, which has been deprecated. We further discuss the impact of such n-nary relations for link prediction in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Difficulty</head><p>Next, we compare the datasets in a link prediction task to show that CODEX-M is more difficult.</p><p>Baseline We devise a "non-learning" link prediction baseline. Let (h, r, ?) be a test query. Our baseline scores candidate tail entities by their relative frequency in the tail slot of all training triples mentioning r, filtering out tail entities t for which (h, r, t) is already observed in the training set. If all tail entities t are filtered out, we score entities by frequency before filtering. The logic of our approach works in reverse for (?, r, t) queries. In evaluating our baseline, we follow LibKGE's protocol for breaking ties in ranking (i.e., for entities that appear with equal frequency) by taking the mean rank of all entities with the same score.</p><p>Setup We compare our baseline to the best pretrained embedding model per dataset: RESCAL for FB15K-237, which was released by <ref type="bibr">Ruffinelli et al. (2020)</ref>, and ComplEx for CODEX-M. We evaluate performance with MRR and Hits@10. Beyond overall performance, we also compute per-relation improvement of the respective embedding over our baseline in terms of percentage points MRR. This measures the amount of learning beyond frequency statistics necessary for each relation. <ref type="table" target="#tab_7">Table 7</ref> compares the overall performance of our baseline versus the best embedding per dataset, and <ref type="figure" target="#fig_3">Figure 3</ref> shows the improvement of the respective embedding over our baseline per relation type on each dataset. The improvement of the embedding is much smaller on FB15K-237 than CODEX-M, and in fact our baseline performs on par with or even outperforms the  embedding on FB15K-237 for some relation types. To further explore these cases, <ref type="figure" target="#fig_4">Figure 4</ref> gives the empirical cumulative distribution function of improvement, which shows the percentage of test triples for which the level of improvement is less than or equal to a given value on each dataset. Surprisingly, the improvement for both MRR and Hits@10 is less than five percentage points for nearly 40% of FB15K-237's test set, and is zero or negative 15% of the time. By contrast, our baseline is significantly weaker than the strongest embedding method on CODEX-M.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and discussion</head><p>The disparity in improvement is due to two relation patterns prevalent in FB15K-237:  We conclude that while FB15K-237 is a valuable dataset, CODEX is more appropriately difficult for link prediction. Additionally, we note that in FB15K-237, all validation and test triples containing entity pairs directly linked in the training set were deleted <ref type="bibr">(Toutanova and Chen, 2015)</ref>, meaning that symmetry cannot be tested for in FB15K-237. Given that CODEX datasets contain both symmetry and compositionality, CODEX is more suitable for assessing how well models can learn relation patterns that go beyond frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and outlook</head><p>We present CODEX, a set of knowledge graph COmpletion Datasets EXtracted from Wikidata and Wikipedia, and show that CODEX is suitable for multiple KGC tasks. We release data, code, and pretrained models for use by the community at https://bit.ly/2EPbrJs. Some promising future directions on CODEX include:</p><p>? Better model understanding CODEX can be used to analyze the impact of hyperparameters, training strategies, and model architectures in KGC tasks.</p><p>? Revival of triple classification We encourage the use of triple classification on CODEX in addition to link prediction because it directly tests discriminative power.</p><p>? Fusing text and structure Including text in both the link prediction and triple classification tasks should substantially improve performance <ref type="bibr">(Toutanova et al., 2015)</ref>. Furthermore, text can be used for few-shot link prediction, an emerging research direction <ref type="bibr">(Xiong et al., 2017;</ref><ref type="bibr">Shi and Weninger, 2017)</ref>.</p><p>Overall, we hope that CODEX will provide a boost to research in KGC, which will in turn impact many other fields of artificial intelligence. <ref type="table" target="#tab_9">Table 8</ref> provides an overview of knowledge graph embedding papers with respect to datasets and evaluation tasks. In our review, we only consider papers published between 2014 and 2020 in the main proceedings of conferences where KGC embedding papers are most likely to appear: Artificial intelligence (AAAI, IJCAI), machine learning (ICML, ICLR, NeurIPS), and natural language processing (ACL, EMNLP, NAACL).  <ref type="table" target="#tab_10">Table 9</ref> provides all seed entity and relation types used to collect CODEX. Each type is given first by its natural language label and then by its Wikidata unique ID: Entity IDs begin with Q, whereas relation (property) IDs begin with P. For the entity types that apply to people (e.g., actor, musician, journalist), we retrieved seed entities by querying Wikidata using the occupation relation. For the entity types that apply to things (e.g., airline, disease, tourist attraction), we retrieved seed entities by querying Wikidata using the instance of and subclass of relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Seeds for data collection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Negative annotation guidelines</head><p>We provide the annotation guidelines we used to label candidate negative triples ( ? 3.4).</p><p>Task You must label each triple as either true or false. To help you find the answer, we have provided you with Wikipedia and Wikidata links for the entities and relations in each triple. You may also search on Google for the answer, although most claims should be resolvable using Wikipedia and Wikidata alone. If you are not able to find any reliable, specific, clear information supporting the claim, choose false. You may explain your reasoning if need be or provide sources to back up your answer in the optional explanation column.</p><p>Examples False triples may have problems with grammar, factual content, or both. Examples of grammatically incorrect triples are those whose entity or relation types do not make sense, for example:</p><p>? (United States of America, continent, science fiction writer)</p><p>? (Mohandas Karamchand Gandhi, medical condition, British Raj)</p><p>? (Canada, foundational text, Vietnamese cuisine)</p><p>Examples of grammatically correct but factually false triples include:</p><p>? (United States of America, continent, Europe)</p><p>? (Mohandas Karamchand Gandhi, country of citizenship, Argentina)</p><p>? (Canada, foundational text, Harry Potter and the Goblet of Fire)</p><p>? (Alexander Pushkin, influenced by, Leo Tolstoy) -Pushkin died only a few years after Tolstoy was born, so this sentence is unlikely.</p><p>Notice that in the latter examples, the entity types match up, but the statements are still false.</p><p>Tips For triples about people's occupation and genre, try to be as specific as possible. For example, if the triple says (&lt;person&gt;, occupation, guitarist) but that person is mainly known for their singing, choose false, even if that person plays the guitar. Likewise, if a triple says (&lt;person&gt;, genre, classical) but they are mostly known for jazz music, choose false even if, for example, that person had classical training in their childhood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Embedding models</head><p>We briefly overview the five models compared in our link prediction and triple classification tasks. <ref type="bibr">(Nickel et al., 2011)</ref> was one of the first knowledge graph embedding models. Although it is not often used as a baseline, <ref type="bibr">Ruffinelli et al. (2020)</ref> showed that it is competitive when appropriately tuned. RESCAL treats relational learning as tensor decomposition, scoring entity embeddings h, r ? R de and relation embeddings R ? R de?de with the bilinear form h Rt.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESCAL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Seed types</head><p>Entities actor (Q33999), airline (Q46970), airport (Q1248784), athlete (Q2066131), book (Q571), businessperson (Q43845), city (Q515), company (Q783794), country (Q6256), disease (Q12136), engineer (Q81096), film (Q11424), government agency (Q327333), journalist (Q1930187), lake (Q23397), monarch (Q116), mountain (Q8502), musical group (Q215380), musician (Q639669), newspaper (Q11032), ocean (Q9430), politician (Q82955), record label (Q18127), religion (Q9174), religious leader (Q15995642), religious text (Q179461), scientist (Q901), sports league (Q623109), sports team (Q12973014), stadium (Q483110), television program (Q15416), tourist attraction <ref type="formula">(</ref>  TuckER <ref type="bibr" target="#b2">(Balazevic et al., 2019b</ref>) is a linear model based on the Tucker tensor decomposition, which factorizes a tensor into three lower-rank matrices and a core tensor. The TuckER scoring function for a single triple (h, r, t) is given as W ? 1 h ? 2 r ? 3 t, where W is the mode-three core tensor that is shared among all entity and relation embeddings, and ? n denotes the tensor product along the nth mode of the tensor. TuckER can be seen as a generalized form of other linear KGC embedding models like RESCAL and ComplEx.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Content comparison</head><p>We provide additional comparison of the contents in CODEX-M and FB15K-237. <ref type="figure" target="#fig_8">Figure 5</ref>, which plots the top-30 entities by frequency in the two benchmarks, demonstrates that both dataset are biased toward developed Western countries and cultures. However, CODEX-M is more diverse in domain. It covers academia, entertainment, journalism, politics, science, and writing, whereas FB15K-237 covers mostly entertaiment and sports. FB15K-237 is also much more biased toward the United States in particular, as five of its top-30 entities are specific to the US: United States of America, United States dollar, New York City,  Los Angeles, and the United States Department of Housing and Urban Development. <ref type="figure" target="#fig_9">Figure 6</ref> compares the top-15 entity types in CODEX-M and FB15K-237. Again, CODEX-M is diverse, covering people, places, organizations, movies, and abstract concepts, whereas FB15K-237 has many overlapping entity types mostly about entertainment. <ref type="table" target="#tab_0">Table 10</ref> gives our hyperparameter search space. Tables 11, 12, and 13 report the best hyperparameter configurations for link prediction on CODEX-S, CODEX-M, and CODEX-L, respectively. Tables 14 and 15 report the best hyperparameter configurations for triple classification on the hard negatives in CODEX-S and CODEX-M, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Hyperparameter search</head><p>Terminology For embedding initialization, Xv refers to Xavier initialization <ref type="bibr">(Glorot and Bengio, 2010)</ref>. The reciprocal relations model refers to learning separate relation embeddings for queries in the direction of (h, r, ?) versus (?, r, t) (Kazemi and Poole, 2018). The frequency weighting regularization technique refers to regularizing embeddings by the relative frequency of the corresponding entity or relation in the training data.</p><p>Search strategies Recall that we select models using Ax, which supports hyperparameter search using both quasi-random sequences of generated configurations and Bayesian optimization (BO). The search strategy for each CODEX dataset is as follows:</p><p>? CODEX-S: Per negative sampling type/loss combination, we generate 30 quasi-random trials followed by 10 BO trials. We select the best-performing model by validation MRR over all such combinations. In each trial, the model is trained for a maximum of 400 epochs with an early stopping patience of 5. We also terminate a trial after 50 epochs if the model does not reach ? 0.05 MRR.</p><p>? CODEX-M: Per negative sampling type/loss combination, we generate 20 quasi-random trials. The maximum number of epochs and early stopping criteria are the same as for CODEX-S.</p><p>? CODEX-L: Per negative sampling type/loss combination, we generate 10 quasi-random trials of 20 training epochs instead of 400. We reduce the number of epochs to limit resource usage. In most cases, MRR plateaus after 20-30 epochs, an observation which is consistent with <ref type="bibr">(Ruffinelli et al., 2020)</ref>. Then, we take the best-performing model by validation MRR over all such combinations, and retrain that model for a maximum of 400 epochs.</p><p>Note that we search using MRR as our metric, but the triple classification task measures 0/1 accuracy, not ranking performance. For triple classification, we choose the model with the highest validation accuracy among the pre-trained models across all negative sampling type/loss function combinations. We release all pretrained LibKGE models and accompanying configuration files in the centralized CODEX repository. <ref type="table" target="#tab_0">Table 10</ref>: Our hyperparameter search space. We follow the naming conventions and ranges given by <ref type="bibr">Ruffinelli et al. (2020)</ref>, and explain the meanings of selected hyperparameter settings in Appendix F. As most KGC embedding models have a wide range of configuration options, we encourage future work to follow this tabular scheme for transparent reporting of implementation details.   </p><formula xml:id="formula_0">(Normal) - - - - - Interval (Unif) - - ?0.8133 - - Gain (XvNorm) - - - 1.0 1.0 Gain (XvUnif) 1.0 1.0 - - -</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>RESCAL (Nickel et al., 2011), TransE (Bordes et al., 2013), ComplEx (Trouillon et al., 2016), ConvE (Dettmers et al., 2018), and TuckER (Balazevic et al., 2019b). These models represent several classes of architecture, from linear (RESCAL, TuckER, ComplEx) to translational (TransE) to nonlinear/learned (ConvE). Appendix D provides more specifics on each model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>5 https://ax.dev/ Figure 1: Distribution of validation MRR, CODEX-M.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Top-15 most frequent relations in CODEX-M and FB15K-237.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Improvement in MRR of the embedding over our frequency baseline per relation type. Negative means that our baseline outperforms the embedding. The medians are 8.27 and 20.04 percentage points on FB15K-237 and CODEX-M, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Empirical CDF of improvement of the best embedding over our frequency baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>The main evaluation benchmarks are FB15K (Bordes et al., 2013), WN18 (Bordes et al., 2013), FB15K-237 (Toutanova and Chen, 2015), WN18RR (Dettmers et al., 2018), FB13 (Socher et al., 2013), WN11 (Socher et al., 2013), NELL-995 (Xiong et al., 2017), YAGO3-10 (Dettmers et al., 2018), Countries (Bouchard et al., 2015). UMLS (McCray, 2003), Kinship (Kemp et al., 2006), Families (Hinton, 1986), and other versions of NELL (Mitchell et al., 2018).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>(</head><label></label><figDesc>Balazevic et al., 2019b) (Vu et al., 2019) SEARCH17 personalized search (SEARCH17) (Nathani et al., 2019) NELL-995, UMLS, Kinship (Jiang et al., 2019)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Q570116), visual artist (Q3391743), visual artwork (Q4502142), writer (Q36180) Relations airline alliance (P114), airline hub (P113), architect (P84), architectural style (P149), author (P50), capital (P36), cast member (P161), cause of death (P509), chairperson (P488), chief executive officer (P169), child (P40), continent (P30), country (P17), country of citizenship (P27), country of origin (P495), creator (P170), diplomatic relation (P530), director (P57), drug used for treatment (P2176), educated at (P69), employer (P108), ethnic group (P172), field of work (P101), foundational text (P457), founded by (P112), genre (P136), head of government (P6), head of state (P35), headquarters location (P159), health specialty (P1995), indigenous to (P2341), industry (P452), influenced by (P737), instance of (P31), instrument (P1303), language of work or name (P407), languages spoken, written, or signed (P1412), legal form (P1454), legislative body (P194), located in the administrative terroritorial entity (P131), location of formation (P740), medical condition (P1050), medical examinations (P923), member of (P463), member of political party (P102), member of sports team (P54), mountain range (P4552), movement (P135), named after (P138), narrative location (P840), notable works (P800), occupant (P466), occupation (P106), official language (P37), parent organization (P749), part of (P361), place of birth (P19), place of burial (P119), place of death (P20), practiced by (P3095), product or material produced (P1056), publisher (P123), record label (P264), regulated by (P3719), religion (P140), residence (P551), shares border with (P47), sibling (P3373), sport (P641), spouse (P26), studies (P2578), subclass of (P279), symptoms (P780), time period (P2348), tributary (P974), unmarried partner (P451), use (P366), uses (P2283)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Top-30 most frequent entities in CODEX-M and FB15K-237.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Top-15 most frequent entity types in CODEX-M and FB15K-237.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Qualitative comparison of CODEX datasets to existing Freebase-based KGC datasets ( ? 2.1). Freebase variants (FB15K, FB15K-237) CODEX datasets Scope (domains) Multi-domain, with a strong focus on awards, entertainment, and sports ( ? 6.1 and Appendix E)</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>CODEX datasets. (+): Positive (true) triples. (-): Verified negative (false) triples ( ? 3.4). We compute multilingual coverage over all labels, descriptions, and entity Wikipedia extracts successfully retrieved for the respective dataset in Arabic (ar), German (de), English (en), Spanish (es), Russian (ru), and Chinese (zh).</figDesc><table><row><cell></cell><cell>|E| |R|</cell><cell cols="5">Triples E ? R ? E Train (+) Valid (+) Test (+) Valid (-) Test (-)</cell><cell>ar</cell><cell>Multilingual coverage de en es</cell><cell>ru</cell><cell>zh</cell></row><row><cell>CODEX-S</cell><cell>2,034 42</cell><cell>32,888</cell><cell>1827</cell><cell>1828</cell><cell>1827</cell><cell>1828</cell><cell cols="2">77.38 91.87 96.38 91.55 89.17 79.36</cell></row><row><cell cols="2">CODEX-M 17,050 51</cell><cell>185,584</cell><cell cols="2">10,310 10,311</cell><cell cols="2">10,310 10,311</cell><cell cols="2">75.80 95.20 96.95 87.91 81.88 69.63</cell></row><row><cell cols="2">CODEX-L 77,951 69</cell><cell>551,193</cell><cell cols="2">30,622 30,622</cell><cell>-</cell><cell>-</cell><cell cols="2">67.47 90.84 92.40 81.30 71.12 61.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Selected examples of hard negatives in CODEX with explanations. official language, American English) English, not American English, is an official language of Lesotho. (Senegal, part of, Middle East)Senegal is part of West Africa. (Simone de Beauvoir, field of work, astronomy) Simone de Beauvoir's field of work was primarily philosophy.</figDesc><table><row><cell>Negative</cell><cell>Explanation</cell></row><row><cell>(Fr?d?ric Chopin, occupation, conductor)</cell><cell>Chopin was a pianist and a composer, not a conductor.</cell></row><row><cell>(Lesotho, (Vatican City, member of, UNESCO)</cell><cell>Vatican City is a UNESCO World Heritage Site but not a member state.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Relation patterns in CODEX. For symmetry, we give the proportion of triples containing a symmetric relation. For composition, we give the proportion of triples participating in a rule of length two or three.</figDesc><table><row><cell></cell><cell cols="3">CODEX-S CODEX-M CODEX-L</cell></row><row><cell>Symmetry</cell><cell>17.46%</cell><cell>4.01%</cell><cell>3.29%</cell></row><row><cell>Composition</cell><cell>10.09%</cell><cell>16.55%</cell><cell>31.84%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Comparison of link prediction performance on CODEX.</figDesc><table><row><cell></cell><cell></cell><cell>CODEX-S</cell><cell></cell><cell></cell><cell>CODEX-M</cell><cell></cell><cell></cell><cell>CODEX-L</cell><cell></cell></row><row><cell></cell><cell cols="3">MRR Hits@1 Hits@10</cell><cell cols="3">MRR Hits@1 Hits@10</cell><cell cols="3">MRR Hits@1 Hits@10</cell></row><row><cell cols="2">RESCAL 0.404</cell><cell>0.293</cell><cell>0.623</cell><cell>0.317</cell><cell>0.244</cell><cell>0.456</cell><cell>0.304</cell><cell>0.242</cell><cell>0.419</cell></row><row><cell>TransE</cell><cell>0.354</cell><cell>0.219</cell><cell>0.634</cell><cell>0.303</cell><cell>0.223</cell><cell>0.454</cell><cell>0.187</cell><cell>0.116</cell><cell>0.317</cell></row><row><cell cols="2">ComplEx 0.465</cell><cell>0.372</cell><cell>0.646</cell><cell>0.337</cell><cell>0.262</cell><cell>0.476</cell><cell>0.294</cell><cell>0.237</cell><cell>0.400</cell></row><row><cell>ConvE</cell><cell>0.444</cell><cell>0.343</cell><cell>0.635</cell><cell>0.318</cell><cell>0.239</cell><cell>0.464</cell><cell>0.303</cell><cell>0.240</cell><cell>0.420</cell></row><row><cell>TuckER</cell><cell>0.444</cell><cell>0.339</cell><cell>0.638</cell><cell>0.328</cell><cell>0.259</cell><cell>0.458</cell><cell>0.309</cell><cell>0.244</cell><cell>0.430</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 10 in</head><label>10</label><figDesc>Appendix F gives further details and all hyperparameter ranges and values. All experiments were run on a single NVIDIA Tesla V100 GPU with 16 GB of RAM. NegSamp, or randomly corrupting head entities h or tail entities t to create negatives; (b) 1vsAll, or treating all possible head/tail corruptions of (h, r, t) as negatives, including the corruptions that are actually positives; and (c) KvsAll, or treating batches of head/tail corruptions not seen in the knowledge graph as negatives.</figDesc><table><row><cell>Training negatives Given a set of positive train-</cell></row><row><cell>ing triples {(h, r, t)}, we compare three types</cell></row><row><cell>of negative sampling strategy implemented by</cell></row><row><cell>LibKGE: (a)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Comparison of triple classification performance on CODEX by negative generation strategy.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">CODEX-S</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">CODEX-M</cell><cell></cell></row><row><cell></cell><cell cols="2">Uniform</cell><cell cols="2">Relative freq.</cell><cell cols="2">Hard neg.</cell><cell cols="2">Uniform</cell><cell cols="2">Relative freq.</cell><cell cols="2">Hard neg.</cell></row><row><cell></cell><cell>Acc.</cell><cell>F1</cell><cell>Acc.</cell><cell>F1</cell><cell>Acc.</cell><cell>F1</cell><cell>Acc.</cell><cell>F1</cell><cell>Acc.</cell><cell>F1</cell><cell>Acc.</cell><cell>F1</cell></row><row><cell cols="3">RESCAL 0.972 0.972</cell><cell cols="2">0.916 0.920</cell><cell cols="2">0.843 0.852</cell><cell cols="2">0.977 0.976</cell><cell cols="2">0.921 0.922</cell><cell cols="2">0.818 0.815</cell></row><row><cell>TransE</cell><cell cols="2">0.974 0.974</cell><cell cols="2">0.919 0.923</cell><cell cols="2">0.829 0.837</cell><cell cols="2">0.986 0.986</cell><cell cols="2">0.932 0.933</cell><cell cols="2">0.797 0.803</cell></row><row><cell cols="3">ComplEx 0.975 0.975</cell><cell cols="2">0.927 0.930</cell><cell cols="2">0.836 0.846</cell><cell cols="2">0.984 0.984</cell><cell cols="2">0.930 0.933</cell><cell cols="2">0.824 0.818</cell></row><row><cell>ConvE</cell><cell cols="2">0.972 0.972</cell><cell cols="2">0.921 0.924</cell><cell cols="2">0.841 0.846</cell><cell cols="2">0.979 0.979</cell><cell cols="2">0.934 0.935</cell><cell cols="2">0.826 0.829</cell></row><row><cell>TuckER</cell><cell cols="2">0.973 0.973</cell><cell cols="2">0.917 0.920</cell><cell cols="2">0.840 0.846</cell><cell cols="2">0.977 0.977</cell><cell cols="2">0.920 0.922</cell><cell cols="2">0.823 0.816</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Overall performance (MRR) of our frequency baseline versus the best embedding nodel per benchmark. "Improvement" refers to the improvement of the embedding over the baseline.</figDesc><table><row><cell></cell><cell cols="3">Baseline Embedding Improvement</cell></row><row><cell>FB15K-237</cell><cell>0.236</cell><cell>0.356</cell><cell>+0.120</cell></row><row><cell>CODEX-M</cell><cell>0.135</cell><cell>0.337</cell><cell>+0.202</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>An overview of knowledge graph embedding papers published between 2014 and 2020 with respect to datasets and evaluation tasks. Original citations for datasets are given in Appendix A. Link pred. refers to link prediction, and triple class. refers to triple classification, both of which are covered in ? 5.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Datasets</cell><cell></cell><cell></cell><cell cols="2">Evaluation tasks</cell></row><row><cell></cell><cell>Reference</cell><cell>FB15K</cell><cell>FB15K-237</cell><cell>FB13</cell><cell>WN18</cell><cell>WN18RR</cell><cell>WN11</cell><cell>Other</cell><cell>Link pred.</cell><cell>Triple class.</cell><cell>Other</cell></row><row><cell></cell><cell>(Wang et al., 2014)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>FB5M</cell><cell></cell><cell></cell><cell>relation extraction (FB5M)</cell></row><row><cell></cell><cell>(Lin et al., 2015b)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>FB40K</cell><cell></cell><cell></cell><cell>relation extraction (FB40K)</cell></row><row><cell></cell><cell>(Wang et al., 2015)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">NELL (Location, Sports)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(Nickel et al., 2016)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Countries</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(Lin et al., 2016)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>FB24K</cell><cell></cell><cell></cell></row><row><cell>AAAI, IJCAI</cell><cell>(Wang and Cohen, 2016) (Xiao et al., 2016a) (Jia et al., 2016) (Xie et al., 2016)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>FB15K+</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(Shi and Weninger, 2017)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">SemMedDB, DBPedia</cell><cell></cell><cell></cell><cell>fact checking (not on FB15K)</cell></row><row><cell></cell><cell>(Dettmers et al., 2018)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">YAGO3-10, Countries</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(Ebisu and Ichise, 2018)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>(Guo et al., 2018)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>YAGO37</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(Zhang et al., 2020)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>(Vashishth et al., 2020a)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>YAGO3-10</cell><cell></cell><cell></cell></row><row><cell>ICML, ICLR, NeurIPS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>The entity and relation types (Wikidata IDs in parentheses) used to seed CODEX.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>TransE (Bordes et al., 2013)  treats relations as translations between entities, i.e., h + r ? t for h, r, t ? R de , and scores embeddings with negative Euclidean distance ? h + r ? t . TransE is likely the most popular baseline for KGC tasks and the most influential of all KGC embedding papers.</figDesc><table><row><cell>ComplEx (Trouillon et al., 2016) uses a bilinear</cell></row><row><cell>function to score triples with a diagonal relation em-</cell></row><row><cell>bedding matrix and complex-valued embeddings.</cell></row><row><cell>Its scoring function is re h diag(r)t , where t is</cell></row><row><cell>the complex conjugate of t and re denotes the real</cell></row><row><cell>part of a complex number.</cell></row><row><cell>ConvE (Dettmers et al., 2018) is one of the first</cell></row><row><cell>and most popular nonlinear models for KGC.</cell></row><row><cell>It concatenates head and relation embeddings h</cell></row><row><cell>and r into a two-dimensional "image", applies a</cell></row><row><cell>pointwise linearity over convolutional and fully-</cell></row><row><cell>connected layers, and multiplies the result with</cell></row><row><cell>the tail embedding t to obtain a score. Formally,</cell></row><row><cell>its scoring function is given as f (vec(f ([h; r]  *</cell></row><row><cell>?))W)t, where f is a nonlinearity (originally,</cell></row><row><cell>ReLU), [h; r] denotes a concatenation and two-</cell></row><row><cell>dimensional reshaping of the head and relation</cell></row><row><cell>embeddings, ? denotes the filters of the convo-</cell></row><row><cell>lutional layer, and vec denotes the flattening of a</cell></row><row><cell>two-dimensional matrix.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 11 :</head><label>11</label><figDesc>Best link prediction hyperparameter configurations on CODEX-S. ? 10 ?10 1.32 ? 10 ?7 9.58 ? 10 ?13 3.11 ? 10 ?15 3.47 ? 10 ?15 Relation embedding weight 3.37 ? 10 ?14 3.72 ? 10 ?18 0.0229 4.68 ? 10 ?9 3.43 ? 10 ?14</figDesc><table><row><cell cols="2">RESCAL</cell><cell>TransE</cell><cell>ComplEx</cell><cell>ConvE</cell><cell>TuckER</cell></row><row><cell>Best validation MRR</cell><cell>0.4076</cell><cell>0.3602</cell><cell>0.4752</cell><cell>0.4639</cell><cell>0.4574</cell></row><row><cell>Embedding size</cell><cell>512</cell><cell>512</cell><cell>512</cell><cell>256</cell><cell>512</cell></row><row><cell>Training type</cell><cell>1vsAll</cell><cell>NegSamp</cell><cell>1vsAll</cell><cell>1vsAll</cell><cell>KvsAll</cell></row><row><cell>Reciprocal</cell><cell>No</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell># head samples (NegSamp)</cell><cell>-</cell><cell>2</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell># tail samples (NegSamp)</cell><cell>-</cell><cell>56</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Label smoothing (KvsAll)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.0950</cell></row><row><cell>Loss</cell><cell>CE</cell><cell>CE</cell><cell>CE</cell><cell>CE</cell><cell>CE</cell></row><row><cell>Margin (MR)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>p norm (TransE)</cell><cell>-</cell><cell>2</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Optimizer</cell><cell>Adagrad</cell><cell>Adagrad</cell><cell>Adam</cell><cell>Adagrad</cell><cell>Adagrad</cell></row><row><cell>Batch size</cell><cell>128</cell><cell>128</cell><cell>1024</cell><cell>512</cell><cell>256</cell></row><row><cell>Learning rate</cell><cell>0.0452</cell><cell>0.0412</cell><cell>0.0003</cell><cell>0.0117</cell><cell>0.0145</cell></row><row><cell>LR scheduler patience</cell><cell>7</cell><cell>6</cell><cell>7</cell><cell>3</cell><cell>1</cell></row><row><cell>p regularization</cell><cell>3</cell><cell>2</cell><cell>None</cell><cell>3</cell><cell>1</cell></row><row><cell>Entity embedding weight 2.18 Frequency weighting</cell><cell>False</cell><cell>False</cell><cell>True</cell><cell>True</cell><cell>True</cell></row><row><cell>Embedding normalization (TransE)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Entity</cell><cell>-</cell><cell>No</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Relation</cell><cell>-</cell><cell>No</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Dropout</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Entity embedding</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0793</cell><cell>0.0</cell><cell>0.1895</cell></row><row><cell>Relation embedding</cell><cell>0.0804</cell><cell>0.0</cell><cell>0.0564</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>Feature map (ConvE)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.2062</cell><cell>-</cell></row><row><cell>Projection (ConvE)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.1709</cell><cell>-</cell></row><row><cell>Embedding initialization</cell><cell>Normal</cell><cell>XvNorm</cell><cell>XvNorm</cell><cell>XvNorm</cell><cell>XvNorm</cell></row><row><cell>Stdev (Normal)</cell><cell>0.0622</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Interval (Unif)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Gain (XvNorm)</cell><cell>-</cell><cell>1.0</cell><cell>1.0</cell><cell>1.0</cell><cell>1.0</cell></row><row><cell>Gain (XvUnif)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 12 :</head><label>12</label><figDesc>Best link prediction hyperparameter configurations on CODEX-M. ? 10 ?7 1.34 ? 10 ?10 1.37 ? 10 ?10 3.47 ? 10 ?15 Relation embedding weight 2.56 ? 10 ?17 3.72 ? 10 ?18 6.38 ? 10 ?16 4.72 ? 10?10 3.4 ? 10 ?14</figDesc><table><row><cell></cell><cell>RESCAL</cell><cell></cell><cell>TransE</cell><cell>ComplEx</cell><cell>ConvE</cell><cell>TuckER</cell></row><row><cell>Best validation MRR</cell><cell>0.3173</cell><cell></cell><cell>0.2993</cell><cell>0.3351</cell><cell>0.3146</cell><cell>0.3253</cell></row><row><cell>Embedding size</cell><cell>256</cell><cell></cell><cell>512</cell><cell>512</cell><cell>512</cell><cell>512</cell></row><row><cell>Training type</cell><cell>1vsAll</cell><cell cols="2">NegSamp</cell><cell>KvsAll</cell><cell>NegSamp</cell><cell>KvsAll</cell></row><row><cell>Reciprocal</cell><cell>Yes</cell><cell></cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell># head samples (NegSamp)</cell><cell>-</cell><cell></cell><cell>2</cell><cell>-</cell><cell>381</cell><cell>-</cell></row><row><cell># tail samples (NegSamp)</cell><cell>-</cell><cell></cell><cell>56</cell><cell>-</cell><cell>751</cell><cell>-</cell></row><row><cell>Label smoothing (KvsAll)</cell><cell>-</cell><cell></cell><cell>-</cell><cell>0.2081</cell><cell>-</cell><cell>0.0950</cell></row><row><cell>Loss</cell><cell>CE</cell><cell></cell><cell>CE</cell><cell>CE</cell><cell>CE</cell><cell>CE</cell></row><row><cell>Margin (MR)</cell><cell>-</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>p norm (TransE)</cell><cell>-</cell><cell></cell><cell>2</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Optimizer</cell><cell>Adagrad</cell><cell cols="2">Adagrad</cell><cell>Adagrad</cell><cell>Adagrad</cell><cell>Adagrad</cell></row><row><cell>Batch size</cell><cell>256</cell><cell></cell><cell>128</cell><cell>1024</cell><cell>128</cell><cell>256</cell></row><row><cell>Learning rate</cell><cell>0.0695</cell><cell></cell><cell>0.0412</cell><cell>0.2557</cell><cell>0.0024</cell><cell>0.0145</cell></row><row><cell>LR scheduler patience</cell><cell>8</cell><cell></cell><cell>6</cell><cell>6</cell><cell>9</cell><cell>1</cell></row><row><cell>p regularization</cell><cell>2</cell><cell></cell><cell>2</cell><cell>3</cell><cell>1</cell><cell>1</cell></row><row><cell cols="3">Entity embedding weight 1.32 Frequency weighting 9.56 ? 10 ?7 False</cell><cell>False</cell><cell>True</cell><cell>True</cell><cell>True</cell></row><row><cell>Embedding normalization (TransE)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Entity</cell><cell>-</cell><cell></cell><cell>No</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Relation</cell><cell>-</cell><cell></cell><cell>No</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Dropout</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Entity embedding</cell><cell>0.0</cell><cell></cell><cell>0.0</cell><cell>0.1196</cell><cell>0.0</cell><cell>0.1895</cell></row><row><cell>Relation embedding</cell><cell>0.0</cell><cell></cell><cell>0.0</cell><cell>0.3602</cell><cell>0.0348</cell><cell>0.0</cell></row><row><cell>Feature map (ConvE)</cell><cell>-</cell><cell></cell><cell>-</cell><cell>-</cell><cell>0.3042</cell><cell>-</cell></row><row><cell>Projection (ConvE)</cell><cell>-</cell><cell></cell><cell>-</cell><cell>-</cell><cell>0.2343</cell><cell>-</cell></row><row><cell>Embedding initialization</cell><cell>XvUnif</cell><cell></cell><cell>XvUnif</cell><cell>Unif</cell><cell>XvNorm</cell><cell>XvNorm</cell></row><row><cell>Stdev</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Some examples: (politician:jobs, worksfor, county:god), (person:buddha001, parentofperson, person:jesus)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">A similar approach was used to extract the FB15K dataset from Freebase(Bordes et al., 2013).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/uma-pi1/kge</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Micha? Rybak and Xinyi (Carol) Zheng for their contributions. This material is supported by the National Science Foundation under Grant No. IIS 1845491, Army Young Investigator Award No. W911NF1810397, and an NSF Graduate Research Fellowship.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Realistic re-evaluation of knowledge graph completion methods: An experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farahnaz</forename><surname>Akrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><forename type="middle">Samiul</forename><surname>Saeef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Multi-relational poincar? graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivana</forename><surname>Balazevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Tucker: Tensor factorization for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivana</forename><surname>Balazevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
