<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The first neural machine translation system for the Erzya language</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dale</surname></persName>
							<email>dale.david@yandex.ru</email>
						</author>
						<title level="a" type="main">The first neural machine translation system for the Erzya language</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T02:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present the first neural machine translation system for translation between the endangered Erzya language and Russian and the dataset collected by us to train and evaluate it. The BLEU scores are 17 and 19 for translation to Erzya and Russian respectively, and more than half of the translations are rated as acceptable by native speakers. We also adapt our model to translate between Erzya and 10 other languages, but without additional parallel data, the quality on these directions remains low. We release the translation models along with the collected text corpus, a new language identification model, and a multilingual sentence encoder adapted for the Erzya language.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Out of the 7 thousand languages spoken around the world, only a minor fraction is covered by machine translation tools. For example, Google Translate 1 supports only 133 languages, and a recent model by <ref type="bibr">NLLB Team et al. (2022)</ref> supports 202 languages. Most other languages are often considered "lowresource", although some of them have millions of native speakers. In the context of machine translation, the resources that are low are, primarily, parallel and monolingual text corpora. In this work, we create a machine translation system for the previously uncovered Erzya language with only publicly available resources, a very small budget, and limited human efforts. We hope that it will inspire researchers and language activists to enlarge the coverage of existing NLP resources, and in particular, translation systems.</p><p>Our language of choice is Erzya (myv), which is spoken primarily in the Republic of Mordovia, located in the center of the European part of the Russian Federation. The language, along with its close relative Moksha (mdf), belongs to the Mordvinic branch of the Uralic language family. These two languages, although not mutually intelligible <ref type="bibr" target="#b13">(Janurik, 2017)</ref>, are often referred to under the common name "Mordovian". Erzya has had a written tradition since the beginning of the 19th century <ref type="bibr" target="#b20">(Rueter, 2013)</ref>. Its most widely used alphabet is Cyrillic, although there is a Latin-based alternative alphabet 2 . Erzya has supposedly 300 thousand speakers 3 , and it is one of the three official languages in Mordovia. According to the UNESCO classification, the Erzya language has a status of "definitely endangered" <ref type="bibr" target="#b28">(UNESCO, 2010)</ref>. Some researchers <ref type="bibr" target="#b13">(Janurik, 2017)</ref> put it between the levels 6b ("threatened") and 7 ("shifting") on the EGIDS scale <ref type="bibr" target="#b15">(Lewis and Simons, 2010)</ref>, as it is widely used and transmitted between generations in rural communities but is being gradually displaced by Russian in urban areas. More details about the use of Erzya are given by <ref type="bibr" target="#b20">Rueter (2013)</ref>, who is also a major current contributor to Erzya NLP resources.</p><p>As far as we know, prior to this work, no neural machine translation (NMT) systems for Erzya have been published. To fill this gap, we create and publicly release 4 the following deliverables:</p><p>? A language identification model with enhanced recall for Erzya and Moksha languages; </p><formula xml:id="formula_0">? A sentence</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Low-resource NLP and, in particular, machine translation, have attracted a lot of attention. Among the recent ambitious projects are <ref type="bibr" target="#b8">Bapna et al. (2022)</ref> and <ref type="bibr">NLLB Team et al. (2022)</ref> that aim at creating NMT systems for hundreds of languages and rely heavily on collection of large online corpora and transfer learning. Other works, such as <ref type="bibr" target="#b10">H?m?l?inen and Alnajjar (2019)</ref>, focus on efficient use of existing vocabularies and morphosyntactic tools to train machine translation systems for very low-resourced languages.</p><p>As far as we know, there are no published large parallel corpora or NMT systems for Erzya. <ref type="bibr" target="#b21">Rueter and Tyers (2018)</ref> develop an Erzya treebank with a few hundred translations to English and Finnish. ????????????? (2019) present an Erzya web corpus 5 along with the way it was collected, but the corpus is available only via the web interface. For other published corpora, the situation is similar. There exists a half-finished rule-based machine translation system between Erzya and Finnish 6 , and a grammar parser for Erzya 7 . The software package UralicNLP <ref type="bibr" target="#b12">(H?m?l?inen, 2019)</ref> supports Erzya among other languages.</p><p>There have been a few attempts to transfer machine learning-based NLP resources to Erzya from high-resource languages. <ref type="bibr" target="#b6">Alnajjar (2021)</ref> adapt Finnish, English, and Russian word embeddings to Erzya. <ref type="bibr" target="#b16">Muller et al. (2021</ref><ref type="bibr">Muller et al. ( ),?cs et al. (2021</ref> and  evaluate the performance of multilingual BERT-like models on natural language understanding tasks for new languages, including Erzya.</p><p>None of the works known to us train machine learning-based models that are capable of generating Erzya language. After filtering these texts with the language identification model (Section 3.2), we gathered 330K unique Erzya sentences. A bilingual part of the texts was used for mining additional parallel sentences in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology and Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Collection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Language Identification</head><p>To make sure that the extra collected data is in the Erzya language, we train a FastText <ref type="bibr" target="#b14">(Joulin et al., 2016)</ref> language classifier for the 323 languages present in Wikipedia. The 267 thousand training texts were sampled from Wikipedia with probabilities proportional to n 1/5 lang , where n lang is the size of Wikipedia in that language 15 . To increase the recall for Erzya and Moksha languages, we augment this training dataset with Erzya and Moksha Bible texts. The resulting model has 89% accuracy and 86% macro F1 score on the Wikipedia test set (sampled with the same temperature). For Erzya, it has 97% precision and 82% recall. Hyperparameters for all trained models are listed in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Erzya Sentence Encoder</head><p>To compute sentence embeddings, we use an encoder based on LaBSE <ref type="bibr" target="#b9">(Feng et al., 2022)</ref>, with an extended vocabulary. First, we use the BPE algorithm <ref type="bibr" target="#b23">(Sennrich et al., 2016)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>over a monolingual</head><p>Erzya corpus to add 19K extra merged tokens to the vocabulary. Then, we fine-tune the model on the limited initial parallel data (the Bible, OPUS, and dictionaries): we update only the token embeddings matrix, using the contrastive loss from <ref type="bibr" target="#b9">Feng et al. (2022)</ref> over computed sentence embeddings. Finally, after collecting more parallel sentences, we fine-tune the full model on a mixture of tasks: contrastive loss over sentence embeddings, standard masked language modeling loss, and sentence pair classification to distinguish correct translations from random pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Mining Parallel Sentences</head><p>When mining parallel sentences, we strive for high precision. To compensate for the questionable quality of our sentence encoder, we apply the following procedure 16 .</p><p>? We perform only local mining, i.e. we compare sentences only across paired documents (for Wikipedia and translated books), or within one document (for the web sources). ? To evaluate similarity of two sentences, we multiply the cosine similarity between their LaBSE embeddings by the ratio of the length of the shortest sentence to that of the longest one. ? We further penalize the similarities by partially subtracting from them the average similarities of each sentence to its closest neighbors, similarly to using distance margin from <ref type="bibr" target="#b7">Artetxe and Schwenk (2019)</ref>. ? Given two documents in Russian and Erzya, we use dynamic programming to select a sequence of sentence pairs that have the maximal sum of pairwise similarity scores and go in the same order in both documents. ? We accept only the sentence pairs with a score above a threshold, which was manually tuned for each source of texts. In total, this approach yielded 21K more unique parallel sentence pairs. The manual inspection found that more than 90% of them were matched correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Training Machine Translation Models</head><p>To benefit from transfer learning, we base our model on the mBART50 model <ref type="bibr" target="#b25">(Tang et al., 2020)</ref> pretrained on multiple languages, including two Uralic ones (Finnish and Estonian). We extend its BPE vocabulary with 19K new Erzya tokens, using the same method as in Section 3.3, and add a new myv_XX language code to it. Embeddings for the new tokens are initialized as the averages of the embeddings of the Russian tokens aligned with them in the parallel corpus 17 , inspired by <ref type="bibr" target="#b31">Xu and Hong (2022)</ref>.</p><p>We make two copies of this model and train them to translate in the myv-ru and ru-myv directions, respectively. The myv-ru model is trained on the joint parallel corpus of sentences and words.</p><p>The ru-myv model is trained on the union of this corpus and the back-translated corpus generated by the myv-ru model from the monolingual myv data.</p><p>After training the models on these two languages, we adapt them to 10 more languages: ar, de, en, es, fi, fr, hi, tr, uk, and zh, resulting in the myv-mul and mul-myv models (below, by mul we denote any of these 10 languages). We fine-tune the two models jointly, using a version of online-back translation and self-training. Specifically, we generate the training pairs in four alternating steps:</p><p>1. Sample a ru-mul sentence pair from the CCMatrix <ref type="bibr" target="#b22">(Schwenk et al., 2021)</ref> dataset, translate from ru to myv with the mul-myv model; 2. Sample a ru-mul pair from the CCMatrix, translate from mul to myv with the mul-myv model; 3. Sample a ru-myv pair from our parallel corpus, translate from myv to mul with the myvmul model; 4. Sample a myv text from the monolingual myv corpus, translate from mul to myv and ru with the myv-mul model. At each step, we update both models on the myvmul and myv-ru pairs in both directions. For the self-training updates, we multiply the loss by the coefficient ? ST = 0.05 to decrease the impact of self-training relatively to back-translation (the choice of the coefficient is suggested by experiments in <ref type="bibr" target="#b11">He et al. (2022)</ref>).</p><p>During the initial experiments, we noticed that, when translating from Russian to Erzya, the model often just copied Russian phrases with only word endings sometimes changed. Sometimes this is acceptable because Erzya has multiple Russian loanwords, but often there exist native words that are preferable. To alleviate this problem, in step 1 we generate 5 alternative ru-myv translations using diverse beam search <ref type="bibr" target="#b29">(Vijayakumar et al., 2016)</ref>, and choose the one with the largest proportion of words recognized as myv by our language identification model. This problem was also the reason why we chose to train two different models from translation to Erzya and from Erzya: this way, the decoder and encoder of a model never work with the same language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>For model evaluation, we prepare a held-out corpus of 3000 aligned Erzya-Russian sentences from 6 diverse sources: the Bible, Erzya folk tales (Sheyanova, 2017), the Soviet 1938 constitution, descriptions of folk children's games (??????????, 2009), modern Erzya fiction and poetry, and Wikipedia. To evaluate English and Finnish translation, we use translations from the Erzya universal-dependency treebank <ref type="bibr" target="#b21">(Rueter and Tyers, 2018)</ref>: 441 sentence pairs for en, and 309 for fi. We split all these sets into development and test parts, and report the results on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Automatic Metrics</head><p>For all evaluated directions (between myv and ru, en, fi) we calculate BLEU <ref type="bibr" target="#b18">(Papineni et al., 2002)</ref> and ChrF++ <ref type="bibr" target="#b19">(Popovi?, 2017)</ref>. Both these metrics estimate the proportion of common parts in the translation and the reference, but BLEU is calculated as precision over word n-grams, whereas ChrF++ aggregates precision and recall of word and character n-grams (which is more suitable for morphologically rich languages such as Erzya and Russian). The values of these metrics on the test set are given in <ref type="table">Table 1</ref>. For translation from and to Russian, the BLEU scores are 17 and 19 points, respectively. For English and Finnish, however, BLEU is well below 10. We hypothesize that the low quality may be attributed to the domain mismatch between the Erzya-origin and Englishor Finnish-origin training corpora, but without detailed test sets we cannot verify this.</p><p>For the Russian test set, the performance varies greatly depending on the domain <ref type="table" target="#tab_3">(Table 2)</ref>. The constitution has the highest scores because its Erzya  text is saturated with Russian loanwords and is easy to generate and understand. For Wikipedia, the scores are also high, probably because its Erzya articles are often translated from Russian in a rather literal way. The other domains have a more artistic style, and the translations are on average much less literal. Some examples of the translations and references are given in <ref type="table" target="#tab_4">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Manual Evaluation</head><p>We recruit three native speaker volunteers to evaluate some translations manually. The evaluation protocol is similar to <ref type="bibr">XSTS (NLLB Team et al., 2022)</ref>, but evaluates fluency in addition to semantic similarity. The scores are between 1 (a useless translation) and 5 (a perfect translation), with 3 points standing for an acceptable translation without serious errors. Criteria for each score are given in Appendix C.</p><p>Each of the 3 annotators rated a few randomly sampled translations from the dev split of each source: 12 pairs in the ru-myv and 17 pairs in the myv-ru directions, which amounts to 87 sentence pairs annotations in total. The average length of the labelled texts was 97 characters, or 14 words.</p><p>It turned out that, despite the specified annotation criteria, the annotators were calibrated very differently: their average ratings were 2.9, 3.5, and 4.1. We chose a pessimistic aggregation strategy: for each of the 29 evaluated sentence pairs, we took the worst of the scores by our 3 volunteers.</p><p>For translation to Erzya, the average pessimistic score was 2.75, and 58% translations were rated as acceptable (i.e. all the 3 reviewers rated them Type Text source (ru) ? ??? ??? ???????????? ???? ??????? ???????: ?????? ????? ?? ???? ????? ????, ? ???? ?????? ???? ??????????; ? ??? ???? ????????. source <ref type="bibr">(myv)</ref> ???? ???? ??????? ??????? ?????? ??????: ????? ?????? ???? ???????, ?? ????????? ?????? ???????????, ?????? ??????????. translation (ru-myv) ?? ???? ???? ??????? ????? ?????? ??????: ???????? ?? ????????? ???????, ???? ???????? ???????? ???????????; ????? ???????? ??????????. translation (myv-ru) ??? ??? ??? ??????? ??????? ??????: ????? ??????? ????? ?? ????, ?? ??? ???????????, ???? ?? ?????. source <ref type="bibr">(myv)</ref> ???? ?????, ????????? ?????? ???????, ???? ?? ???????????, ??????????????? ????????? ?????????? ????? ??????. source (en) Like his mother, he prepared flat rings, and stuck them onto the patty in the same way, and smoothed out the seams with his wet hands. source (fi) Samalla tavalla kuin?itins? Ket?ai valmisti litteit? rinkuloita liitti ne samalla tavalla, ja siloitti liitoksen m?r?ll? k?dell?. translation (myv-en) Like his mother, he prepared flat circles, and also filled the canvas with a needle. translation (myv-fi)</p><p>Kuten?iti, valmistelee tasa-alaiset kent?t, my?s venytet??n, ly?d??n venytt?j?n k?sill?. translation (en-myv) ???? ??????, ??? ????????? ?????? ??????, ???? ????? ????????? ????? ??????????? ?? ???????? ?????? ????????? ?????. translation <ref type="bibr">(fi-myv)</ref> ???? ??, ???? ????? ?????? ????????? ?????? ????????, ??? ???????? ????? ???? ????? ?? ???????? ?????? ?????????????. with at least 3 points). For translation to Russian, the average score was 2.71, with 53% acceptable translations. An additional comment from the annotators was that some of the source Erzya texts were inadequate. In particular, some games sentences contained grammatical errors 18 , and most constitution sentences contained Russian words with Erzya endings instead of their Erzya equivalents. This suggests that one of the next steps in improving our NMT system might be to filter the training and evaluation data for better language quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>In this paper, we present the first NMT system for the endangered Erzya language, capable of translating between it and 11 diverse languages, primarily Russian. During its development, we have collected about 30K parallel Russian-Erzya sentences and 300K monolingual Erzya sentences, and trained a language identification model and a BERT-based sentence encoder that support Erzya. All the resources are publicly released. These efforts have occupied about two man-weeks of working time and almost no expenses 19 . We hope that these results will inspire the NLP community to develop resources for other endangered languages. <ref type="bibr">18</ref> We are not certain whether these errors are due to the low quality of the source text, or to the natural variations within the Erzya language. <ref type="bibr">19</ref> All the expenses incurred totalled $9.99 for the paid subscription to the Google Colab system (https://colab. research.google.com/signup).</p><p>The quality of our system may be improved by collecting more texts in Erzya and filtering them better than we did. Another promising direction is a more efficient usage of the vocabularies and parsers that are already available for the language, e.g. for generating synthetic training data. Finally, we hope to attract more native speakers for creating larger and cleaner train and test datasets.</p><p>One open research question is that of transfer between languages: whether Erzya translation benefits from knowledge of, for example, Hungarian or Estonian, and whether knowledge of Erzya can bring improvements to other languages, such as Moksha. In further studies, we hope to shed some light on this direction as well. <ref type="table">Table 4</ref>: The sources used to construct the training and evaluation datasets. The "size" column denotes the number of sentences or phrases in the source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Models' hyperparameters B.1 Language identification</head><p>For the language identification model, we use the official FastText implementation 20 . We train it with initial learning rate of 0.05 for 100 epochs, using minimum word count of 100, 64-dimensional embeddings and 200K hash buckets for character n-grams with n from 1 to 4. Then we quantize the model with retraining on the same dataset, a cutoff of 50000, and norm pruning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Sentence encoder</head><p>For the sentence encoder model, we use a PyTorch port of LaBSE 21 , in which we remove tokens for all languages, except Russian and English, and add Erzya tokens. For vocabulary extension, we set the minimal token count for stopping BPE at 30.</p><p>After extending the vocabulary, we fine-tune the model on the initial parallel sentences and phrases using the LaBSE contrastive loss with margin 0.3 and batch size 4 for 500K steps, updating only the embeddings, and passing the gradient only through the encoded myv sentence. We use the Adafactor optimizer with learning rate of 10 ?5 and clipping the gradient norm at 1. Then we update the model for 500K steps with learning rate 2 ? 10 ?6 , updating all the parameters, and alternating batches with the LaBSE loss, MLM loss, and the loss of classifying the correct and incorrect sentence pairs. Incorrect pairs are generated either by sampling one of the sentences randomly, or by randomly inserting, deleting, or swapping words in one of the sentences in a correct parallel pair. for 4 epochs: on the first epoch, only token embeddings were updated, and on the remaining epochs, all parameters were updated.</p><p>The myv-mul and mul-myv models were initialized from myv-ru and ru-myv, respectively. They were jointly trained for 40K updates with batch size of 1.</p><p>For inference, we used beam size of 5 and repetition penalty of 5.0. Both the sentence encoder and the translation models were trained using the PyTorch 23 and Transformers 24 Python packages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Quality annotation guidelines</head><p>The following annotation criteria (in Russian) were suggested to the annotators in Section 4.3.</p><p>? 5 points: a perfect translation. The meaning and the style are reproduced completely, the grammar and word choice are correct, the text looks natural. ? 4 points: a good translation. The meaning is reproduced completely or almost completely, the style and the word choice are natural for the target language. ? 3 points: an acceptable translation. The general meaning is reproduced; the mistakes in word choice and grammar do not hinder understanding; most of the text is grammatically correct and in the target language. ? 2 points: a bad translation. The text is mainly understandable and mainly in the target language, but there are critical mistakes in meaning, grammar, or word choice. ? 1 point: a useless translation. A large part of the text is in the wrong language, or is incomprehensible, or has little relation to the original text.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>:2209.09368v1 [cs.CL] 19 Sep 2022 of the translations are rated as acceptable.</figDesc><table><row><cell>encoder for Erzya compatible with</cell></row><row><cell>LaBSE (Feng et al., 2022);</cell></row><row><cell>? A small parallel Erzya-Russian corpus and a</cell></row><row><cell>larger monolingual Erzya corpus;</cell></row><row><cell>? Two neural models for translation between</cell></row><row><cell>Erzya and 11 other languages.</cell></row><row><cell>For translation between Russian and Erzya, we</cell></row><row><cell>validate our models both by automatic metrics and</cell></row><row><cell>with judgments of native speakers. More than half</cell></row></table><note>2 http://valks.erzja.info (currently blocked in Russia)3 In the 2010 census, 430 thousand people reported speaking Erzya or Moksha, but their proportions are unclear.4 The source code and links to other resources are provided at https://github.com/slone-nlp/myv-nmt.arXiv</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Scores by section on the myv-ru test set.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>A few examples of translations and references.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">* The research was conducted between the author's employments at Skolkovo Institute of Science and Technology (Skoltech) and at Meta AI. 1 https://translate.google.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">http://lib.e-mordovia.ru 10 https://fennougrica.kansalliskirjasto.fi</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14">https://www.livejournal.com 15 We adopted the idea of temperature sampling with T=5 fromTran et al. (2021)  and several other works.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16">For more details on the mining procedure, please read the source code in the repository that we release.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17">We compute alignments with a naive formula: the alignment weight between tokens ti and tj is estimated as n 2 ij n j n j , where ni and nj are their respective frequencies in the parallel corpus, and nij is the number of sentence pairs with ti in one sentence and tj in another.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23">https://pytorch.org 24 https://huggingface.co/docs/transformers/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>We gratefully acknowledge support from the volunteers who participated in the manual evaluation of translation quality: Semyon Tumaikin, Zinyoronj Santyai, and Evgenia Chugunova. We are also grateful to the reviewers for their suggestions which helped to improve this work.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Data sources</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source</head><p>Type Size <ref type="bibr">Erzya-Russian dictionaries: marlamuter.com, mordovians.ru, mordvarf.com, ????? et al. (2011</ref><ref type="bibr" target="#b36">), ??????? (2011</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fenno-Ugrica</surname></persName>
		</author>
		<ptr target="https://fennougrica.kansalliskirjasto.fi" />
		<imprint>
			<biblScope unit="page" from="2022" to="2030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Livejournal</surname></persName>
		</author>
		<idno>Ac- cessed: 2022-08-01</idno>
		<ptr target="https://www.livejournal.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>??????</surname></persName>
		</author>
		<ptr target="https://rus4all.ru/myv/" />
		<imprint>
			<biblScope unit="page" from="2022" to="2030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">????????? ???????????????? ??????????????? ??????? ????????????? (???????? ????????). ???????, ???????. 2022a. The wikimedia dump service</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">??????</forename><surname>??????</surname></persName>
		</author>
		<ptr target="https://dumps.wikimedia.org/myvwiki/20220601/.Ac-cessed:2022-08-01" />
		<imprint>
			<date type="published" when="1938" />
			<biblScope unit="page" from="2022" to="2030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wikisource</surname></persName>
		</author>
		<ptr target="https://wikisource.org/wiki/Main_Page/?oldid=895127" />
		<imprint>
			<biblScope unit="page" from="2022" to="2030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Evaluating transferability of BERT models on uralic languages</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Workshop on Computational Linguistics of Uralic Languages</title>
		<editor>Judit?cs, D?niel L?vai, and Andras Kornai. 2021</editor>
		<meeting>the Seventh International Workshop on Computational Linguistics of Uralic Languages<address><addrLine>Syktyvkar, Russia (Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="8" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Alnajjar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.13275</idno>
		<title level="m">When word embeddings become endangered</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Marginbased parallel corpus mining with multilingual sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1309</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3197" to="3203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Building machine translation systems for the next thousand languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Caswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Daan Van Esch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengmeng</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallavi</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Baljekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.03983</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Languageagnostic BERT sentence embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangxiaoyu</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveen</forename><surname>Arivazhagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.62</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="878" to="891" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A template based approach for training nmt for lowresource uralic languages -a pilot with finnish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mika</forename><surname>H?m?l?inen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Alnajjar</surname></persName>
		</author>
		<idno type="DOI">10.1145/3377713.3377801</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 2nd International Conference on Algorithms, Computing and Artificial Intelligence, ACAI 2019</title>
		<meeting>the 2019 2nd International Conference on Algorithms, Computing and Artificial Intelligence, ACAI 2019<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="520" to="525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bridging the data gap between training and inference for unsupervised neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.456</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6611" to="6623" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">UralicNLP: An NLP library for Uralic languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mika</forename><surname>H?m?l?inen</surname></persName>
		</author>
		<idno type="DOI">10.21105/joss.01345</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">37</biblScope>
			<biblScope unit="page">1345</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Erzya-russian bilingual discourse: A structural analysis of intrasentential code-switching patterns. Szeged: Szegedi Tudom?nyegyetem PhD dissertation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogl?rka</forename><surname>Janurik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Manuscript</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Bag of tricks for efficient text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01759</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Assessing endangerment: expanding fishman&apos;s gids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary F</forename><surname>Simons</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">When being unseen from mBERT is just the beginning: Handling new languages with multilingual language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beno?t</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djam?</forename><surname>Seddah</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.38</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="448" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><forename type="middle">R</forename><surname>Nllb Team</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Costa-Juss?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Onu?</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maha</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Elbayad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elahe</forename><surname>Heffernan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janice</forename><surname>Kalbassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Licht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Skyler</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bapi</forename><surname>Youngblood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Akula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prangthip</forename><surname>Mejia-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hansanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Necip Fazil Ayan</title>
		<imprint/>
	</monogr>
	<note>and Jeff Wang. 2022. No language left behind: Scaling human-centered machine translation</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">chrF++: words helping character n-grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi?</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-4770</idno>
	</analytic>
	<monogr>
		<title level="m">Copenhagen, Denmark. Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="612" to="618" />
		</imprint>
	</monogr>
	<note>Proceedings of the Second Conference on Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The erzya language. where is it spoken??tudes finno-ougriennes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Rueter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards an opensource universal-dependency treebank for Erzya</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Rueter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Tyers</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-0210</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Workshop on Computational Linguistics of Uralic Languages</title>
		<meeting>the Fourth International Workshop on Computational Linguistics of Uralic Languages<address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="106" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">CCMatrix: Mining billions of high-quality parallel sentences on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.507</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6490" to="6500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Skaz forms of Mordovian literature. The Research Institute of the Humanities by the Government of the Republic of Mordovia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina Ivanovna</forename><surname>Sheyanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>Saransk</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chau</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Jen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.00401</idno>
		<title level="m">Multilingual translation with extensible multilingual pretraining and finetuning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Parallel data, tools and interfaces in OPUS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
		<meeting>the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2214" to="2218" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sergey Edunov, and Angela Fan. 2021. Facebook AI&apos;s WMT21 news translation task submission</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chau</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Machine Translation</title>
		<meeting>the Sixth Conference on Machine Translation</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="205" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Unesco atlas of the world&apos;s languages in danger (pdf)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Unesco</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Diverse beam search: Decoding diverse solutions from neural sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ashwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Vijayakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramprasath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02424</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Expanding pretrained models to thousands more languages via lexicon-based adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.61</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="863" to="877" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sub-word alignment is still useful: A vest-pocket method for enhancing lowresource machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minhan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hong</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-short.68</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2022" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="613" to="619" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">????????-??????? ?????-???????? ?????? ??????. ????????? ?????-???????? ????????????</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?????????????</forename><surname>??????? ?????????????</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="528" to="537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">?????????? ???????? ????. ?????????? ??. ????????????</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">??????????</forename><surname>??????? ?????????</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Saransk</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">?????????? ???????? ?????? ? ???????</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><forename type="middle">?</forename><surname>????????</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">???????? ?.E. ????????? ?????</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">412</biblScope>
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>?????</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><forename type="middle">?</forename><surname>???????????</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><forename type="middle">?</forename><surname>??????</surname></persName>
		</author>
		<title level="m">????????? ????. ??????? ???????. ???????????? ??????????? ????????????</title>
		<meeting><address><addrLine>???????</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">???????????????-????????? ???????. ?????????? ????? ??????? ?????-???????? ???????</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">???????</forename><surname>????????? ????????</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<pubPlace>???????</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?????</forename><surname>??????</surname></persName>
		</author>
		<ptr target="http://lazalyk.narod.ru/business.html" />
		<title level="m">??????-????????? ???????</title>
		<imprint>
			<biblScope unit="page" from="2022" to="2030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Machine translation models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Both myv-ru and ru-myv models were initialized from mBART50 22 with the vocabulary extended with Erzya tokens. They were trained with Adafactor optimizer using batch size of 8 and learning rate of 10 ?</title>
		<ptr target="https://github.com/facebookresearch/fastText21https://huggingface.co/sentence-transformers/LaBSE22https://huggingface.co/facebook/mbart-large-50-many-to-many-mmt" />
		<imprint>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
