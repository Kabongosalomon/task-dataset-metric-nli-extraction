<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
							<email>wangliang@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhao</surname></persName>
							<email>zhaowei01@yuanfudao.com</email>
							<affiliation key="aff1">
								<orgName type="department">Yuanfudao AI Lab</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoyu</forename><surname>Wei</surname></persName>
							<email>weizhuoyu@yuanfudao.com</email>
							<affiliation key="aff1">
								<orgName type="department">Yuanfudao AI Lab</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingming</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Yuanfudao AI Lab</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge graph completion (KGC) aims to reason over known facts and infer the missing links. Text-based methods such as KG-BERT (Yao et al., 2019)  learn entity representations from natural language descriptions, and have the potential for inductive KGC. However, the performance of text-based methods still largely lag behind graph embedding-based methods like TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref> and RotatE (Sun et al., 2019b). In this paper, we identify that the key issue is efficient contrastive learning. To improve the learning efficiency, we introduce three types of negatives: in-batch negatives, pre-batch negatives, and self-negatives which act as a simple form of hard negatives. Combined with InfoNCE loss, our proposed model SimKGC can substantially outperform embedding-based methods on several benchmark datasets. In terms of mean reciprocal rank (MRR), we advance the state-of-the-art by +19% on WN18RR, +6.8% on the Wikidata5M transductive setting, and +22% on the Wikidata5M inductive setting. Thorough analyses are conducted to gain insights into each component. Our code is available at https://github.com/ intfloat/SimKGC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large-scale knowledge graphs (KGs) are important components for knowledge-intensive applications, such as question answering <ref type="bibr" target="#b38">(Sun et al., 2019a)</ref>, recommender systems <ref type="bibr" target="#b14">(Huang et al., 2018)</ref>, and intelligent conversational agents <ref type="bibr" target="#b9">(Dinan et al., 2019)</ref> etc. KGs usually consist of a set of triples <ref type="bibr">(h, r, t)</ref>, where h is the head entity, r is the relation, and t is the tail entity. Popular public KGs include Freebase <ref type="bibr" target="#b1">(Bollacker et al., 2008)</ref>, Wikidata <ref type="bibr" target="#b43">(Vrande?i? and Kr?tzsch, 2014)</ref>, YAGO <ref type="bibr" target="#b37">(Suchanek et al., 2007)</ref>, ConceptNet <ref type="bibr" target="#b36">(Speer et al., 2017)</ref>, and Word-Net <ref type="bibr" target="#b26">(Miller, 1992)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mount Everest</head><p>Asia is Earth's largest and most populous continent...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Asia</head><p>A mountain is an elevated portion of the Earth's crust? Mountain ... was a British surveyor and geographer who...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>George Everest</head><p>The United Kingdom ... is a sovereign country in northwestern Europe... Existing KGC methods can be categorized into two families: embedding-based and text-based methods. Embedding-based methods map each entity and relation into a low-dimensional vector, without using any side information such as entity descriptions. This family includes TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref>, TransH <ref type="bibr" target="#b48">(Wang et al., 2014)</ref>, Ro-tatE <ref type="bibr" target="#b39">(Sun et al., 2019b)</ref>, and TuckER <ref type="bibr" target="#b0">(Balazevic et al., 2019)</ref> etc. By comparison, text-based methods <ref type="bibr" target="#b54">(Yao et al., 2019;</ref><ref type="bibr" target="#b50">Xie et al., 2016;</ref><ref type="bibr" target="#b47">Wang et al., 2021c)</ref> incorporate available texts for entity representation learning, as shown in <ref type="figure" target="#fig_1">Figure 1</ref>. Intuitively, text-based methods should outperform embedding-based counterparts since they have access to additional input signals. However, results on popular benchmarks (e.g., WN18RR, FB15k-237, Wikidata5M) tell a different story: text-based methods still lag behind even with pre-trained language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>United Kingdom</head><p>We hypothesize that the key issue for such performance degradation is the inefficiency in contrastive learning. Embedding-based methods do not involve the expensive computation of text en-coders and thus can be extremely efficient to train with a large negative sample size. For example, the default configuration of RotatE 1 trains 1000 epochs with a negative sample size of 64 on the Wikidata5M dataset. While the text-based method KEPLER <ref type="bibr" target="#b47">(Wang et al., 2021c)</ref> can only train 30 epochs with a negative sample size of 1 due to the high computational cost incurred by RoBERTa.</p><p>In this paper, inspired by the recent progress on contrastive learning, we introduce three types of negatives to improve the text-based KGC method: in-batch negatives, pre-batch negatives, and selfnegatives. By adopting bi-encoder instead of crossencoder <ref type="bibr" target="#b54">(Yao et al., 2019)</ref> architecture, the number of in-batch negatives can be increased by using a larger batch size. Vectors from previous batches are cached and act as pre-batch negatives <ref type="bibr" target="#b18">(Karpukhin et al., 2020)</ref>. Additionally, mining hard negatives can be beneficial for improving contrastive learning. We find that the head entity itself can serve as hard negatives, which we call "self-negatives". As a result, the negative sample size can be increased to the scale of thousands. We also propose to change the loss function from margin-based ranking loss to InfoNCE, which can make the model focus on hard negatives.</p><p>One advantage of text-based methods is that they enable inductive entity representation learning. Entities that are not seen during training can still be appropriately modeled, while embeddingbased methods like TransE can only reason under the transductive setting 2 . Inductive knowledge graph completion is important in the real world as new entities are coming out every day. Moreover, text-based methods can leverage state-of-the-art pre-trained language models to learn better representations. A line of recent work <ref type="bibr" target="#b35">(Shin et al., 2020;</ref><ref type="bibr" target="#b29">Petroni et al., 2019)</ref> attempts to elicit the implicitly stored knowledge from BERT. The task of KGC can also be regarded as a way to retrieve such knowledge.</p><p>Two entities are more likely to be related if connected by a short path in the graph. Empirically, we find that text-based models heavily rely on the semantic match and ignore such topological bias to some degree. We propose a simple re-ranking strategy by boosting the scores of the head entity's k-hop neighbors.</p><p>We evaluate our proposed model SimKGC by 1 https://github.com/DeepGraphLearning/ graphvite 2 All entities in the test set also appear in the training set. conducting experiments on three popular benchmarks: WN18RR, FB15k-237, and Wikidata5M (both transductive and inductive settings). According to the automatic evaluation metrics (MRR, Hits@{1,3,10}), SimKGC outperforms state-ofthe-art methods by a large margin on the WN18RR (MRR 47.6 ? 66.6), Wikidata5M transductive setting <ref type="bibr">(MRR 29.0 ? 35.8)</ref>, and inductive setting <ref type="bibr">(MRR 49.3 ? 71.4</ref>). On the FB15k-237 dataset, our results are also competitive. To help better understand our proposed method, we carry out a series of analyses and report human evaluation results. Hopefully, SimKGC will facilitate the future development of better KGC systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Knowledge Graph Completion involves modeling multi-relational data to aid automatic construction of large-scale KGs. In translationbased methods such as TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref> and TransH <ref type="bibr" target="#b48">(Wang et al., 2014)</ref>, a triple (h, r, t) is a relation-specific translation from the head entity h to tail entity t. Complex number embeddings are introduced by <ref type="bibr" target="#b42">Trouillon et al. (2016)</ref> to increase the model's expressiveness. RotatE <ref type="bibr" target="#b39">(Sun et al., 2019b</ref>) models a triple as relational rotation in complex space. <ref type="bibr" target="#b28">Nickel et al. (2011);</ref><ref type="bibr" target="#b0">Balazevic et al. (2019)</ref> treat KGC as a 3-D binary tensor factorization problem and investigate the effectiveness of several factorization techniques. Some methods attempt to incorporate entity descriptions. DKRL <ref type="bibr" target="#b50">(Xie et al., 2016)</ref> uses a CNN to encode texts, while KG-BERT <ref type="bibr" target="#b54">(Yao et al., 2019)</ref>, StAR <ref type="bibr" target="#b44">(Wang et al., 2021a)</ref>, and BLP <ref type="bibr" target="#b6">(Daza et al., 2021)</ref> both adopt pre-trained language models to compute entity embeddings. GraIL <ref type="bibr" target="#b40">(Teru et al., 2020)</ref> and BERTRL <ref type="bibr" target="#b56">(Zha et al., 2021)</ref> conduct inductive relation prediction by utilizing subgraph or path information. In terms of benchmark performance <ref type="bibr" target="#b47">(Wang et al., 2021c</ref>), text-based methods still underperform methods like RotatE.</p><p>Pre-trained Language Models including BERT <ref type="bibr" target="#b8">(Devlin et al., 2019)</ref>, GPT <ref type="bibr" target="#b32">(Radford et al., 2018)</ref>, and T5 <ref type="bibr" target="#b33">(Raffel et al., 2019)</ref> have led to a learning paradigm shift in NLP. Models are first pre-trained on large amounts of unlabeled text corpora with language modeling objectives, and then fine-tuned on downstream tasks. Considering their good performance in few-shot and even zero-shot scenarios <ref type="bibr" target="#b3">(Brown et al., 2020)</ref>, one interesting question is: "Can pre-trained language models be used as knowledge bases?" <ref type="bibr" target="#b29">Petroni et al. (2019)</ref> proposed to probe language models with manually designed prompts. A series of following work <ref type="bibr" target="#b35">(Shin et al., 2020;</ref><ref type="bibr" target="#b58">Zhong et al., 2021;</ref><ref type="bibr" target="#b16">Jiang et al., 2020)</ref> focus on finding better prompts to elicit the knowledge implicitly stored in the model parameters. Another line of work <ref type="bibr" target="#b23">Liu et al., 2020;</ref><ref type="bibr" target="#b47">Wang et al., 2021c)</ref> injects symbolic knowledge into language model pre-training, and shows some performance boost on several knowledge-intensive tasks.</p><p>Contrastive Learning learns useful representations by contrasting between positives and negatives <ref type="bibr" target="#b20">(Le-Khac et al., 2020)</ref>. The definitions of positives and negatives are task-specific. In selfsupervised vision representation learning <ref type="bibr" target="#b13">He et al., 2020;</ref><ref type="bibr" target="#b11">Grill et al., 2020)</ref>, a positive pair is two augmented views of the same image, while a negative pair is two augmented views of different images. Recently, contrastive learning paradigm has witnessed great successes in many different fields, including multi-modal pre-training <ref type="bibr" target="#b31">(Radford et al., 2021)</ref>, video-text retrieval , and natural language understanding <ref type="bibr" target="#b12">(Gunel et al., 2021)</ref> etc. In the NLP community, by leveraging the supervision signals from natural language inference data <ref type="bibr" target="#b10">(Gao et al., 2021)</ref>, QA pairs <ref type="bibr" target="#b27">(Ni et al., 2021)</ref>, and parallel corpora <ref type="bibr" target="#b46">(Wang et al., 2021b)</ref>, these methods have surpassed non-contrastive methods <ref type="bibr" target="#b34">(Reimers and Gurevych, 2019)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Notations</head><p>A knowledge graph G is a directed graph, where the vertices are entities E, and each edge can be represented as a triple (h,r,t), where h, r, and t correspond to head entity, relation, and tail entity, respectively. The link prediction task of KGC is to infer the missing triples given an incomplete G. Under the widely adopted entity ranking evaluation protocol, tail entity prediction (h, r, ?) requires ranking all entities given h and r, similarly for head entity prediction (?, r, t). In this paper, for each triple (h,r,t), we add an inverse triple (t,r ?1 ,h), where r ?1 is the inverse relation of r. Based on such reformulation, we only need to deal with the tail entity prediction problem <ref type="bibr" target="#b25">(Malaviya et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Architecture</head><p>Our proposed model SimKGC adopts a biencoder architecture. Two encoders are initialized with the same pre-trained language model but do not share parameters.</p><p>Given a triple (h,r,t), the first encoder BERT hr is used to compute the relation-aware embedding for the head entity h. We first concatenate the textual descriptions of entity h and relation r with a special symbol [SEP] in between. BERT hr is applied to get the last-layer hidden states. Instead of directly using the hidden state of the first token, we use mean pooling followed by L 2 normalization to get the relation-aware embedding e hr , as mean pooling has been shown to result in better sentence embeddings <ref type="bibr" target="#b10">(Gao et al., 2021;</ref><ref type="bibr" target="#b34">Reimers and Gurevych, 2019)</ref>. e hr is relation-aware since different relations will have different inputs and thus have different embeddings, even though the head entity is the same.</p><p>Similarly, the second encoder BERT t is used to compute the L 2 -normalized embedding e t for the tail entity t. The input for BERT t only consists of the textual description for entity t.</p><p>Since the embeddings e hr and e t are both L 2 normalized, the cosine similarity cos(e hr , e t ) is simply the dot product between two embeddings:</p><p>cos(e hr , e t ) = e hr ? e t e hr e t = e hr ? e t (1)</p><p>For tail entity prediction (h, r, ?), we compute the cosine similarity between e hr and all entities in E, and predict the one with the largest score:</p><formula xml:id="formula_0">argmax t i cos(e hr , e t i ), t i ? E (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Negative Sampling</head><p>For knowledge graph completion, the training data only consists of positive triples. Given a positive triple (h, r, t), "negative sampling" needs to sample one or more negative triples to train discriminative models. Most existing methods randomly corrupt h or t and then filter out false negatives that appear in the training graph G. The negatives for different triples are not shared and therefore independent. The typical number of negatives are ? 64 for embedding-based methods <ref type="bibr" target="#b39">(Sun et al., 2019b)</ref>, and ? 5 for text-based methods <ref type="bibr" target="#b44">(Wang et al., 2021a)</ref>. We combine three types of negatives to improve the training efficiency without incurring significant computational and memory overhead.</p><p>In-batch Negatives (IB) This is a widely adopted strategy in visual representation learning  and dense passage retrieval <ref type="bibr" target="#b18">(Karpukhin et al., 2020)</ref> etc. Entities within the same batch can be used as negatives. Such in-batch negatives allow the efficient reuse of entity embeddings for bi-encoder models.</p><p>Pre-batch Negatives (PB) The disadvantage of in-batch negatives is that the number of negatives is coupled with batch size. Pre-batch negatives  use entity embeddings from previous batches. Since these embeddings are computed with an earlier version of model parameters, they are not consistent with in-batch negatives. Usually, only 1 or 2 pre-batches are used. Other methods like MoCo <ref type="bibr" target="#b13">(He et al., 2020)</ref> can also provide more negatives. We leave the investigation of MoCo as future work.</p><p>Self-Negatives (SN) Besides increasing the number of negatives, mining hard negatives <ref type="bibr" target="#b10">(Gao et al., 2021;</ref><ref type="bibr" target="#b51">Xiong et al., 2021)</ref> is also important for improving contrastive representation learning. For tail entity prediction (h, r, ?), text-based methods tend to assign a high score to the head entity h, likely due to the high text overlap. To mitigate this issue, we propose self-negatives that use the head entity h as hard negatives. Including self-negatives can make the model rely less on the spurious text match.</p><p>We use N IB , N PB , and N SN to denote the aforementioned three types of negatives. During training, there may exist some false negatives. For example, the correct entity happens to appear in another triple within the same batch. We filter out such entities with a binary mask 3 . Combining them all, the collection of negatives N (h, r) is:</p><formula xml:id="formula_1">{t |t ? N IB ? N PB ? N SN , (h, r, t ) / ? G} (3)</formula><p>Assume the batch size is 1024, and 2 pre-batches are used, we would have |N IB | = 1024 ? 1, |N PB | = 2 ? 1024, |N SN | = 1, and |N (h, r)| = 3072 negatives in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Graph-based Re-ranking</head><p>Knowledge graphs often exhibit spatial locality. Nearby entities are more likely to be related than entities that are far apart. Text-based KGC methods are good at capturing semantic relatedness but may not fully capture such inductive bias. We propose a simple graph-based re-ranking strategy: increase the score of candidate tail entity t i by ? ? 0 if t i is in k-hop neighbors E k (h) of the head entity h based on the graph from training set:</p><formula xml:id="formula_2">argmax t i cos(e hr , e t i ) + ?1(t i ? E k (h)) (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Training and Inference</head><p>During training, we use InfoNCE loss with additive margin <ref type="bibr" target="#b53">Yang et al., 2019)</ref>:</p><formula xml:id="formula_3">L = ? log e (?(h,r,t)??)/? e (?(h,r,t)??)/? + |N | i=1 e ?(h,r,t i )/? (5)</formula><p>The additive margin ? &gt; 0 encourages the model to increase the score of the correct triple (h,r,t). ?(h, r, t) is the score function for a candidate triple, here we define ?(h, r, t) = cos(e hr , e t ) ? [?1, 1] as in Equation 1. The temperature ? can adjust the relative importance of negatives, smaller ? makes the loss put more emphasis on hard negatives, but also risks over-fitting label noise. To avoid tuning ? as a hyperparameter, we re-parameterize log 1 ? as a learnable parameter.</p><p>For inference, the most time-consuming part is O(|E|) BERT forward pass computation of entity embeddings. Assume there are |T | test triples. For each triple (h, r, ?) and (t, r ?1 , ?), we need to compute the relation-aware head entity embedding and use a dot product to get the ranking score for all entities. In total, SimKGC needs |E| + 2 ? |T | BERT forward passes, while cross-encoder models like KG-BERT <ref type="bibr" target="#b54">(Yao et al., 2019)</ref> needs |E| ? 2 ? |T |. Being able to scale to large datasets is important for practical usage. For bi-encoder models, we can precompute the entity embeddings and retrieve top-k entities efficiently with the help of fast similarity search tools like Faiss <ref type="bibr" target="#b17">(Johnson et al., 2021</ref>   <ref type="bibr" target="#b47">(Wang et al., 2021c)</ref>. The statistics are shown in <ref type="table" target="#tab_1">Table  1</ref>. <ref type="bibr" target="#b2">Bordes et al. (2013)</ref> proposed the WN18 and FB15k datasets. Later work <ref type="bibr" target="#b41">(Toutanova et al., 2015;</ref><ref type="bibr" target="#b7">Dettmers et al., 2018)</ref> showed that these two datasets suffer from test set leakage and released WN18RR and FB15k-237 datasets by removing the inverse relations. The WN18RR dataset consists of ? 41k synsets and 11 relations from WordNet <ref type="bibr" target="#b26">(Miller, 1992)</ref>, and the FB15k-237 dataset consists of ? 15k entities and 237 relations from Freebase. The Wikidata5M dataset is much larger in scale with ? 5 million entities and ? 20 million triples. It provides two settings: transductive and inductive. For the transductive setting, all entities in the test set also appear in the training set, while for the inductive setting, there is no entity overlap between train and test set. We use "Wikidata5M-Trans" and "Wikidata5M-Ind" to indicate these two settings.</p><p>For textual descriptions, we use the data provided by KG-BERT <ref type="bibr" target="#b54">(Yao et al., 2019)</ref> for WN18RR and FB15k-237 datasets. The Wiki-data5M dataset already contains descriptions for all entities and relations.</p><p>Evaluation Metrics Following previous work, our proposed KGC model is evaluated with entity ranking task: for each test triple (h, r, t), tail entity prediction ranks all entities to predict t given h and r, similarly for head entity prediction. We use four automatic evaluation metrics: mean reciprocal rank (MRR), and Hits@k(k ?{1,3,10}) (H@k for short). MRR is the average reciprocal rank of all test triples. H@k calculates the proportion of correct entities ranked among the top-k. MRR and H@k are reported under the filtered setting <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref>, The filtered setting ignores the scores of all known true triples in the training, val-idation, and test set. All metrics are computed by averaging over two directions: head entity prediction and tail entity prediction.</p><p>We also conduct a human evaluation on the Wikidata5M dataset to provide a more accurate estimate of the model's performance.</p><p>Hyperparameters The encoders are initialized with bert-base-uncased (English). Using better pre-trained language models is expected to improve performance further. Most hyperparameters except learning rate and training epochs are shared across all datasets to avoid dataset-specific tuning. We conduct grid search on learning rate with ranges {10 ?5 , 3?10 ?5 , 5?10 ?5 }. Entity descriptions are truncated to a maximum of 50 tokens. Temperature ? is initialized to 0.05, and the additive margin for InfoNCE loss is 0.02. For re-ranking, we set ? = 0.05. 2 pre-batches are used with logit weight 0.5. We use AdamW optimizer with linear learning rate decay. Models are trained with batch size 1024 on 4 V100 GPUs. For the WN18RR, FB15k-237, and Wikidata5M (both settings) datasets, we train for 50, 10, and 1 epochs, respectively. Please see Appendix A for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Main Results</head><p>We reuse the numbers reported by <ref type="bibr" target="#b47">Wang et al. (2021c)</ref> for TransE and DKRL, and the results for RotatE are from the official GraphVite 4 benchmark. In <ref type="table" target="#tab_3">Table 2</ref> and 3, our proposed model SimKGC IB+PB+SN outperforms state-of-theart methods by a large margin on the WN18RR, Wikidata5M-Trans, and Wikidata5M-Ind datasets, but slightly lags behind on the FB15k-237 dataset (MRR 33.6% vs 35.8%). To the best of our knowledge, SimKGC is the first text-based KGC method that achieves better results than embedding-based counterparts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wikidata5M-Trans</head><p>Wikidata5M-Ind MRR H@1 H@3 H@10 MRR H@1 H@3 H@10 embedding-based methods TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref> 25.3 17.0 31.   We report results for various combinations of negatives. With in-batch negatives only, the performance of SimKGC IB is already quite strong thanks to the large batch size (1024) we use. Adding selfnegatives tends to improve H@1 but hurt H@10. We hypothesize that self-negatives make the model rely less on simple text match. Thus they have negative impacts on metrics that emphasize recall, such as H@10. Combining all three types of negatives generally has the best results but not always.</p><p>Compared to other datasets, the graph for the FB15k-237 dataset is much denser (average degree is ? 37 per entity), and contains fewer entities (? 15k). To perform well, models need to learn generalizable inference rules instead of just modeling textual relatedness. Embedding-based methods are likely to hold an advantage for this scenario. It is possible to ensemble our method with embedding-based ones, as done by <ref type="bibr" target="#b44">Wang et al. (2021a)</ref>. Since this is not the main focus of this paper, we leave it as future work. Also, <ref type="bibr" target="#b4">Cao et al. (2021)</ref> points out that many links in the FB15k-237 dataset are not predictable based on the available information. These two reasons help explain the unsatisfactory performance of SimKGC.</p><p>Adding self-negatives is particularly helpful for the inductive setting of Wikidata5M dataset, with MRR rising from 60.3% to 71.3%. For inductive KGC, text-based models rely more heavily on text match than the transductive setting. Self negatives can prevent the model from simply predicting the given head entity.</p><p>In terms of inference time, the most expensive part is the forward pass with BERT. For the Wikidata5M-Trans dataset, SimKGC requires ? 40 minutes to compute ? 4.6 million embeddings with 2 GPUs, while cross-encoder models such as KG-BERT <ref type="bibr" target="#b54">(Yao et al., 2019)</ref> would require an estimated time of 3000 hours. We are not the first work that enables fast inference, models such as ConvE <ref type="bibr" target="#b7">(Dettmers et al., 2018)</ref> and StAR <ref type="bibr" target="#b44">(Wang et al., 2021a)</ref> also share similar advantages. Here we just want to re-emphasize the importance of inference efficiency and scalability when designing new models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head><p>We conduct a series of analyses to gain further insights into our proposed model and the KGC task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">What Makes SimKGC Excel?</head><p>Compared to existing text-based methods, SimKGC makes two major changes: using more negatives, and switching from margin-based ranking loss to InfoNCE loss. To guide the future work on knowledge graph completion, it is crucial to understand which factor contributes most to the superior performance of SimKGC.  In <ref type="table" target="#tab_6">Table 4</ref>, we use SimKGC IB with batch size 256 as a baseline. By reducing the number of negatives from 255 to 5, MRR drops from 64.4 to 48.8. Changing the loss function from InfoNCE to the following margin loss makes MRR drop to 39.5:</p><formula xml:id="formula_4">1 |N | |N | i=1 max(0, ? + ?(h, r, t i ) ? ?(h, r, t)) (6)</formula><p>Consistent with Equation 5, ?(h, r, t i ) is cosine similarity score for a candidate triple, and ? = 0.8.</p><p>To summarize, both InfoNCE loss and a large number of negatives are important factors, while the loss function seems to have bigger impacts. For InfoNCE loss, the hard negatives naturally contribute larger gradients, and adding more negatives can lead to more robust representations.  also draws a similar conclusion: such hardness-aware property is vital for the success of contrastive loss.</p><p>We also propose a variant "margin-? " loss by changing the weight in Equation 6 from 1 <ref type="figure">r, t)</ref>) and ? = 0.05. Similar to InfoNCE loss, "margin-? " loss makes the model pay more attention to hard negatives and leads to better performance as shown in <ref type="table" target="#tab_6">Table 4</ref>. It is similar to the "self-adversarial negative sampling" proposed by <ref type="bibr" target="#b39">Sun et al. (2019b)</ref>. Most hyperparameters are tuned based on InfoNCE loss. We expect the margin-? loss to achieve better results with a bit more hyperparameter optimization. In <ref type="figure" target="#fig_3">Figure 2</ref>, we quantitatively illustrate how MRR changes as more negatives are added. There is a clear trend that the performance steadily improves from 48.8 to 67.1. However, adding more negatives requires more GPU memory and may cause optimization difficulties <ref type="bibr" target="#b55">(You et al., 2020;</ref>. We do not experiment with batch size larger than 1024.</p><formula xml:id="formula_5">|N | to exp(s(t i )/? ) |N | j=1 exp(s(t j )/? ) , where s(t i ) = max(0, ? + ?(h, r, t i ) ? ?(h,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ablation on Re-ranking</head><p>Our proposed re-ranking strategy is a simple way to incorporate topological information in the knowledge graph. For graphs whose connectivity patterns exhibit spatial locality, re-ranking is likely to help.   In <ref type="table" target="#tab_9">Table 6</ref>, we see a slight but stable increase for all metrics on the Wikidata5M-Trans dataset. Note that this re-ranking strategy does not apply to inductive KGC since entities in the test set never appear in the training data. Exploring more effective ways such as graph neural networks  instead of simple re-ranking would be a future direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Fine-grained Analysis</head><p>1-1 1-n spouse capital of lake inflows head of government child has part notable work side effect n-1 n-n instance of place of birth given name work location cast member member of influenced by nominated for We classify all relations into four categories based on the cardinality of head and tail arguments following the rules by <ref type="bibr" target="#b2">Bordes et al. (2013)</ref>: oneto-one(1-1), one-to-many(1-n), many-to-one(n-1), and many-to-many(n-n). Examples are shown in    <ref type="table" target="#tab_12">Table 8</ref>, predicting the "n" side is generally more difficult, since there are many seemingly plausible answers that would confuse the model. Another main reason is the incompleteness of the knowledge graph. Some predicted triples might be correct based on human evaluation, especially for 1-n relations in head entity prediction, such as "instance of", "place of birth" etc. In <ref type="table" target="#tab_8">Table 5</ref>, for the first example, "Marbletown", "Ulster County", and "New York" are both correct answers. The second example illustrates the case for relation "place of birth": a lot of people share the same place of birth, and some triples may not exist in the knowledge graph. This helps explain the low performance of "1-n" relations for the Wikidata5M-Trans dataset. In the third example, SimKGC predicts a closely related but incorrect entity "http server".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Human Evaluation</head><p>The analyses above suggest that automatic evaluation metrics such as MRR tend to underestimate the model's performance. To have a more accurate estimation of the performance, we conduct human evaluation and list the results in <ref type="table">Table 9</ref>. An average of 49% of the wrong predictions according to H@1 are correct according to human annotators. If we take this into account, the H@1 of our proposed model would be much higher. How to accurately correct wrong unknown (h, r, ?) 24% 54% 22% (?, r, t) 74% 14% 12% Avg 49% 34% 17% <ref type="table">Table 9</ref>: Human evaluation results on the Wikidata5M-Trans dataset. (h, r, ?) and (?, r, t) denote tail entity and head entity prediction respectively. We randomly sample 100 wrong predictions according to H@1 from test set. The "unknown" category indicates annotators are unable to decide whether the prediction is correct or wrong based on the textual information.</p><p>measure the performance of KGC systems is also an interesting future research direction. To examine our proposed model qualitatively, we visualize the entity embeddings from 8 largest categories 5 with 50 randomly selected entities per category. Entity embeddings are computed with BERT t in Section 3.2. In <ref type="figure" target="#fig_4">Figure 3</ref>, different categories are well separated, demonstrating the high quality of the learned embeddings. One interesting phenomenon is that the two categories "Community" and "Village" have some overlap. This is reasonable since these two concepts are not mutually exclusive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Entity Visualization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper proposes a simple method SimKGC to improve text-based knowledge graph completion. We identify that the key issue is how to perform efficient contrastive learning. Leveraging the recent progress in the field of contrastive learning, SimKGC adopts a bi-encoder architecture and combines three types of negatives. Experiments on the WN18RR, FB15k-237, and Wikidata5M datasets show that SimKGC substantially outperforms stateof-the-art methods.</p><p>For future work, one direction is to improve the interpretability of SimKGC. In methods like Ro-tatE <ref type="bibr" target="#b39">(Sun et al., 2019b)</ref> and TransE <ref type="bibr" target="#b2">(Bordes et al., 2013)</ref>, a triple can be modeled as rotation in complex space or relational translation, while SimKGC does not enable such easy-to-understand interpretations. Another direction is to explore effective ways to deal with false negatives <ref type="bibr" target="#b15">(Huynh et al., 2020)</ref> resulting from the incompleteness of knowledge graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Broader Impacts</head><p>Future work could use SimKGC as a solid baseline to keep improving text-based knowledge graph completion systems. Our experimental results and analyses also reveal several promising research directions. For example, how to incorporate global graph structure in a more principled way? Are there other loss functions that perform better than the In-foNCE loss? For knowledge-intensive tasks such as knowledge base question answering (KBQA), information retrieval, and knowledge-grounded response generation, etc., it would be interesting to explore the new opportunities brought by the improved knowledge graph completion systems.  In <ref type="table" target="#tab_1">Table 10</ref>, we show the hyperparameters that are shared across all the datasets. For learning rate, we use 5 ? 10 ?5 , 10 ?5 , and 3 ? 10 ?5 for WN18RR, FB15k-237, and Wikidata5M datasets, respectively. For re-ranking, we use 5-hop neighbors for WN18RR and 2-hop neighbors for other datasets. Each epoch takes ? 3 minutes for WN18RR, ? 12 minutes for FB15k-237, and ? 12 hours for Wikidata5M (both settings). Our implementation is based on open-source project transformers 6 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Details on Hyperparameters</head><p>For inverse relation r ?1 , we add a prefix word "inverse" to the description of r. For examples, if r = "instance of", then r ?1 = "inverse instance of". Some entities in the WN18RR and FB15k-237 dataset have very short textual descriptions. We concatenate them with the entity names of its neighbors in the training set. To avoid label leakage during training, we dynamically exclude the correct entity in the input text.    <ref type="table" target="#tab_1">Table 13</ref>: Ablation for the additive margin ? of In-foNCE loss on the FB15k-237 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B More Analysis Results</head><p>In <ref type="table" target="#tab_1">Table 11</ref> and 12, we show how the batch size affects model performance on the Wikidata5M-Trans and FB15k-237 dataset.</p><p>In Equation 5, we use a variant of InfoNCE loss that has an additive margin ?. In our experiments, such a variant performs consistently better than the standard InfoNCE loss, though the improvement is quite marginal, as shown in <ref type="table" target="#tab_1">Table 13</ref>.</p><p>In  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>etc. Despite their usefulness * Work done while at Yuanfudao AI Lab.in practice, they are often incomplete. Knowledge graph completion (KGC) techniques are necessary for the automatic construction and verification of knowledge graphs. Earth's highest mountain above sea level...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>An example of knowledge graph. Each entity has its name and textual descriptions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>on semantic similarity benchmarks. Karpukhin et al. (2020); Qu et al. (2021); Xiong et al. (2021) adopt contrastive learning to improve dense passage retrieval for open-domain question answering, where the positive passages are the ones containing the correct answer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>MRR on the WN18RR dataset w.r.t the number of negatives with SimKGC IB . We use a batch size of 1024 for all experiments, and change the number of negatives with a binary mask over the softmax logits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3</head><label>3</label><figDesc>: 2-D visualization of the entity embeddings from the Wikidata5M-Trans dataset with t-SNE<ref type="bibr" target="#b24">(Maaten and Hinton, 2008)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the datasets used in this paper. "Wikidata5M-Trans" and "Wikidata5M-Ind" refer to the transductive and inductive settings, respectively.</figDesc><table><row><cell>4 Experiments</cell></row><row><cell>4.1 Experimental Setup</cell></row><row><cell>Datasets We use three datasets for evaluation:</cell></row><row><cell>WN18RR, FB15k-237, and Wikidata5M</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Main results for the Wikidata5M dataset. "IB", "PB", and "SN" refer to in-batch negatives, pre-batch negatives, and self-negatives respectively. Embedding-based methods are inherently unable to perform inductive</figDesc><table><row><cell>Method</cell><cell cols="8">WN18RR MRR H@1 H@3 H@10 MRR H@1 H@3 H@10 FB15k-237</cell></row><row><cell>embedding-based methods</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TransE (Bordes et al., 2013)  ?</cell><cell>24.3</cell><cell>4.3</cell><cell>44.1</cell><cell>53.2</cell><cell>27.9</cell><cell cols="2">19.8 37.6</cell><cell>44.1</cell></row><row><cell>DistMult (Yang et al., 2015)  ?</cell><cell>44.4</cell><cell cols="2">41.2 47.0</cell><cell>50.4</cell><cell>28.1</cell><cell cols="2">19.9 30.1</cell><cell>44.6</cell></row><row><cell>RotatE (Sun et al., 2019b)  ?</cell><cell>47.6</cell><cell cols="2">42.8 49.2</cell><cell>57.1</cell><cell>33.8</cell><cell cols="2">24.1 37.5</cell><cell>53.3</cell></row><row><cell cols="2">TuckER (Balazevic et al., 2019)  ? 47.0</cell><cell cols="2">44.3 48.2</cell><cell>52.6</cell><cell>35.8</cell><cell cols="2">26.6 39.4</cell><cell>54.4</cell></row><row><cell>text-based methods</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>KG-BERT (Yao et al., 2019)</cell><cell>21.6</cell><cell>4.1</cell><cell>30.2</cell><cell>52.4</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>42.0</cell></row><row><cell>MTL-KGC (Kim et al., 2020)</cell><cell>33.1</cell><cell cols="2">20.3 38.3</cell><cell>59.7</cell><cell>26.7</cell><cell cols="2">17.2 29.8</cell><cell>45.8</cell></row><row><cell>StAR (Wang et al., 2021a)</cell><cell>40.1</cell><cell cols="2">24.3 49.1</cell><cell>70.9</cell><cell>29.6</cell><cell cols="2">20.5 32.2</cell><cell>48.2</cell></row><row><cell>SimKGC IB</cell><cell>67.1</cell><cell cols="2">58.5 73.1</cell><cell>81.7</cell><cell>33.3</cell><cell cols="2">24.6 36.2</cell><cell>51.0</cell></row><row><cell>SimKGC IB+PB</cell><cell>66.6</cell><cell cols="2">57.8 72.3</cell><cell>81.7</cell><cell>33.4</cell><cell cols="2">24.6 36.5</cell><cell>51.1</cell></row><row><cell>SimKGC IB+SN</cell><cell>66.7</cell><cell cols="2">58.8 72.1</cell><cell>80.5</cell><cell>33.4</cell><cell cols="2">24.7 36.3</cell><cell>50.9</cell></row><row><cell>SimKGC IB+PB+SN</cell><cell>66.6</cell><cell cols="2">58.7 71.7</cell><cell>80.0</cell><cell>33.6</cell><cell cols="2">24.9 36.2</cell><cell>51.1</cell></row></table><note>KGC. According to the evaluation protocol by Wang et al. (2021c), the inductive setting only ranks 7, 475 entities in the test set, while the transductive setting ranks ? 4.6 million entities, so the reported metrics for the inductive setting are much higher. Results are statistically significant under paired student's t-test with p-value 0.05.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Main results for WN18RR and FB15k-237 datasets.</figDesc><table /><note>? : numbers are from Wang et al. (2021a).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Analysis of loss function and the number of negatives on the WN18RR dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>triple (Rest Plaus Historic District, is located in, New York) evidence . . . a national historic district located at Marbletown in Ulster County, New York. . . SimKGC Marbletown triple (Timothy P. Green, place of birth, St. Louis) evidence William Douglas Guthrie (born January 17, 1967 in St. Louis, MO) is a professional boxer. . . SimKGC William Douglas Guthrie triple(TLS termination proxy, instance of, networked software) evidence . . . a proxy server that is used by an institution to handle incoming TLS connections. . .</figDesc><table><row><cell cols="2">SimKGC http server</cell></row><row><cell>triple</cell><cell>(1997 IBF World Championships, followed by, 1999 IBF World Championships)</cell></row><row><cell>evidence</cell><cell>The 10th IBF World Championships (Badminton) were held in Glasgow, Scotland, between 24 May and 1 June 1997. . .</cell></row><row><cell cols="2">SimKGC 2000 IBF World Junior Championships</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Examples of SimKGC prediction results on the test set of the Wikidata5M-Trans dataset. The entity to predict is in bold font. We only show a snippet of relevant texts in the row of "evidence" for space reason.</figDesc><table><row><cell cols="2">MRR H@1 H@3 H@10</cell></row><row><cell>w/ re-rank 35.8</cell><cell>31.3 37.6 44.1</cell></row><row><cell>w/o re-rank 35.5</cell><cell>31.0 37.3 43.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>: Ablation of re-ranking on the Wikidata5M-</cell></row><row><cell>Trans dataset.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Examples for different categories of relations on the Wikidata5M-Trans dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>MRR for different kinds of relations on the Wikidata5M dataset with SimKGC IB+PB+SN .</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 7 .</head><label>7</label><figDesc></figDesc><table /><note>As shown in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 10 :</head><label>10</label><figDesc>Shared hyperparameters for our proposed SimKGC model.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 11 :</head><label>11</label><figDesc>Effects of batch size on the Wikidata5M-Trans dataset with SimKGC IB .</figDesc><table><row><cell cols="3">batch size MRR H@1 H@3 H@10</cell></row><row><cell>256</cell><cell>32.4</cell><cell>23.3 35.4 50.9</cell></row><row><cell>512</cell><cell>32.7</cell><cell>23.7 35.6 51.0</cell></row><row><cell>1024</cell><cell>33.3</cell><cell>24.6 36.2 51.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 12 :</head><label>12</label><figDesc>Effects of batch size on the FB15k-237 dataset with SimKGC IB .</figDesc><table><row><cell cols="4">margin ? MRR H@1 H@3 H@10</cell></row><row><cell>0</cell><cell>33.4</cell><cell>24.8 36.0</cell><cell>50.9</cell></row><row><cell>0.02</cell><cell>33.6</cell><cell>24.9 36.2</cell><cell>51.1</cell></row><row><cell>0.05</cell><cell>33.6</cell><cell>25.0 36.2</cell><cell>50.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 14</head><label>14</label><figDesc>, we show more examples of SimKGC predictions on the Wikidata5M-Trans 6 https://github.com/huggingface/ transformers triple (captive state (film), instance of, movie) evidence Captive State is a 2019 American crime science fiction thriller film directed by Rupert Wyatt and co-written by Wyatt and Erica Beeney.. . . SimKGC 3-D movies triple (Lionel Belasco, occupation, composer) evidence Lionel Belasco (1881 -c. 24 June 1967) was a prominent pianist, composer and bandleader, best known for his calypso recordings. SimKGC bandleaders triple (Johan Nordhagen, country of citizenship, Norway) evidence Waqas Ahmed (born 9 June 1991) is a Norwegian cricketer. . . . SimKGC Waqas Ahmed triple (Carlos Pe?a Romulo, position held, philippine resident commissioner) evidence Francis Burton Harrison was an American-born Filipino statesman who served in the United States House of Representatives and was appointed Governor-General of the Philippines . . . SimKGC Francis Burton Harrison</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 14 :</head><label>14</label><figDesc>More examples of SimKGC prediction results on the test set of Wikidata5M-Trans. dataset to help better understand our model's behavior. Full model predictions on test datasets are available in our public code repository.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">False negatives that do not appear in the training data will not be filtered.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://graphvite.io/docs/latest/ benchmark</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We utilize the "instance of" relation to determine the entity category.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank anonymous reviewers and area chairs for their valuable comments, and ACL Rolling Review organizers for their efforts.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">TuckER: Tensor factorization for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivana</forename><surname>Balazevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1522</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5185" to="5194" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garc?a-Dur?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Lake Tahoe, Nevada, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-12-05" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
	<note>Proceedings of a meeting held</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mc-Candlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<meeting><address><addrLine>Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam; NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>December 6-12, 2020, virtual</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Are missing links predictable? an inferential benchmark for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonggang</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.534</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6855" to="6865" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Inductive entity representations from text via link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Daza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Cochez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Groth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="798" to="808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Convolutional 2d knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018-02-02" />
			<biblScope unit="page" from="1811" to="1818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Wizard of wikipedia: Knowledge-powered conversational agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Simcse: Simple contrastive learning of sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingcheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno>abs/2104.08821</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent -A new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><surname>Bernardo ?vila Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Valko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-06" />
		</imprint>
	</monogr>
	<note>virtual</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning for pre-trained language model fine-tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beliz</forename><surname>Gunel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-05-03" />
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR42600.2020.00975</idno>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020-06-13" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="9726" to="9735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving sequential recommendation with knowledge-enhanced memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongjian</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3209978.3210017</idno>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval, SIGIR 2018</title>
		<meeting><address><addrLine>Ann Arbor, MI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018-07-08" />
			<biblScope unit="page" from="505" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Boosting contrastive self-supervised learning with false negative cancellation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maryam</forename><surname>Khademi</surname></persName>
		</author>
		<idno>abs/2011.11765</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">How can we know what language models know?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00324</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="423" to="438" />
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Billionscale similarity search with gpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="535" to="547" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.550</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6769" to="6781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multi-task learning for knowledge graph completion with pre-trained language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bosung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesuk</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoong</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungyun</forename><surname>Seo</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-main.153</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1737" to="1743" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Contrastive representation learning: A framework and review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Le-Khac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">F</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smeaton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>IEEE Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning dense representations of phrases at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mujeen</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.518</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6634" to="6647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Hit: Hierarchical transformer with momentum contrast for video-text retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengsheng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiru</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyuan</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>ArXiv preprint, abs/2103.15049</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">2020. K-BERT: enabling language representation with knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiruo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Second Innovative Applications of Artificial Intelligence Conference</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="2901" to="2908" />
		</imprint>
	</monogr>
	<note>The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Commonsense knowledge base completion with structural and semantic context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">WordNet: A lexical database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech and Natural Language: Proceedings of a Workshop Held at</title>
		<meeting><address><addrLine>Harriman, New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992-02-23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Sentence-t5: Scalable sentence encoders from pre-trained text-to-text models. ArXiv preprint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmo</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
		<idno>abs/2108.08877</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Volker Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on Machine Learning<address><addrLine>Bellevue, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2011-06-28" />
			<biblScope unit="page" from="809" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1250</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2463" to="2473" />
		</imprint>
	</monogr>
	<note>Language models as knowledge bases?</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingqi</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiyang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxiang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.466</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="5835" to="5847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning, ICML 2021</title>
		<meeting>the 38th International Conference on Machine Learning, ICML 2021</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021-07" />
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="8748" to="8763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Tim Salimans, and Ilya Sutskever</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><forename type="middle">M</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>ArXiv preprint, abs/1910.10683</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using Siamese BERTnetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1410</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasaman</forename><surname>Razeghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.346</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4222" to="4235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Conceptnet 5.5: An open multilingual graph of general knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robyn</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, February 4-9</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence, February 4-9<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4444" to="4451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Yago: a core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="DOI">10.1145/1242572.1242667</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on World Wide Web</title>
		<meeting>the 16th International Conference on World Wide Web<address><addrLine>Banff, Alberta, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007-05-08" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">PullNet: Open domain question answering with iterative retrieval on knowledge bases and text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tania</forename><surname>Bedrax-Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1242</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2380" to="2390" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Rotate: Knowledge graph embedding by relational rotation in complex space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Inductive relation prediction by subgraph reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Komal</forename><surname>Teru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="9448" to="9457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Representing text for joint embedding of text and knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallavi</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1174</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1499" to="1509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Th?o</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
		<ptr target="JMLR.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33nd International Conference on Machine Learning</title>
		<meeting>the 33nd International Conference on Machine Learning<address><addrLine>New York City, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-19" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2071" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Wikidata: a free collaborative knowledgebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Vrande?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Kr?tzsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Structureaugmented text representation learning for efficient knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1737" to="1748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Understanding the behaviour of contrastive loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaping</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2495" to="2504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Aligning cross-lingual sentence representations with dual momentum contrast</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingming</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Kepler: A unified model for knowledge embedding and pre-trained language representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaocheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="176" to="194" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Eighth AAAI Conference on Artificial Intelligence<address><addrLine>Qu?bec City, Qu?bec, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2014-07-27" />
			<biblScope unit="page" from="1112" to="1119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4" to="24" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Representation learning of knowledge graphs with entity descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016-02-12" />
			<biblScope unit="page" from="2659" to="2665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Approximate nearest neighbor negative contrastive learning for dense text retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwok-Fung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><surname>Overwijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-05-03" />
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Improving multilingual sentence embedding using bidirectional dual encoder with additive margin softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><forename type="middle">Hern?ndez</forename><surname>?brego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandy</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinlan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Hsuan</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Kurzweil</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/746</idno>
		<ptr target="ijcai.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJ-CAI 2019</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJ-CAI 2019<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-10" />
			<biblScope unit="page" from="5370" to="5378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Kgbert: Bert for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengsheng</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Luo</surname></persName>
		</author>
		<idno>abs/1909.03193</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Large batch optimization for deep learning: Training BERT in 76 minutes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sashank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Hseu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinadh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwen</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
		<idno>abs/2103.07102</idno>
		<title level="m">ductive relation prediction by bert</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">ERNIE: Enhanced language representation with informative entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1139</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1441" to="1451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Factual probing is [MASK]: Learning vs. learning to recall</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zexuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.398</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="5017" to="5033" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
