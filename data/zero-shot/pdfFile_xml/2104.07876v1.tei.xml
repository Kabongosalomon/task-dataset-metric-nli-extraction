<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Stable Learning for Out-Of-Distribution Generalization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingxuan</forename><surname>Zhang</surname></persName>
							<email>xingxuanzhang@hotmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cui</surname></persName>
							<email>cuip@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renzhe</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjun</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheyan</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Stable Learning for Out-Of-Distribution Generalization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Approaches based on deep neural networks have achieved striking performance when testing data and training data share similar distribution, but can significantly fail otherwise. Therefore, eliminating the impact of distribution shifts between training and testing data is crucial for building performance-promising deep models. Conventional methods assume either the known heterogeneity of training data (e.g. domain labels) or the approximately equal capacities of different domains. In this paper, we consider a more challenging case where neither of the above assumptions holds. We propose to address this problem by removing the dependencies between features via learning weights for training samples, which helps deep models get rid of spurious correlations and, in turn, concentrate more on the true connection between discriminative features and labels. Extensive experiments clearly demonstrate the effectiveness of our method on multiple distribution generalization benchmarks compared with state-of-the-art counterparts. Through extensive experiments on distribution generalization benchmarks including PACS, VLCS, MNIST-M, and NICO, we show the effectiveness of our method compared with state-of-the-art counterparts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Many machine learning approaches tend to exploit subtle statistical correlations existing in the training distribution for predictions which have been shown to be effective under the I.I.D. hypothesis, i.e., testing and training data is independently sampled from the identical distribution. In real cases, however, such a hypothesis can hardly be satisfied due to the complex generation mechanism of real data such as data selection biases, confounding factors, or other peculiarities <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b22">23]</ref>. The testing distribution may incur uncontrolled and unknown shifts from the *Corresponing author, also with Beijing Key Lab of Networked Multimedia The lightness of the saliency map indicates how much attention that the models pay on particular area of the input image (i.e. lighter area plays a more crucial role for the prediction than the darker area). Due to the spurious correlation, the ResNet-18 model tends to focus on both dogs and the water while our model focuses mostly on dogs.</p><p>training distribution, which makes most machine learning models fail to make trustworthy predictions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b58">59]</ref>. To address this issue, out-of-distribution (OOD) generalization is proposed for improving the generalization ability of models under distribution shifts <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b31">32]</ref>. Essentially, when there incurs a distribution shift, the accuracy drop of current models is mainly caused by the spurious correlation between the irrelevant features (i.e. the features that are irrelevant to a given category, such as features of context, figure style, etc.) and category labels, and this kind of spurious correlations are intrinsically caused by the subtle correlations between irrelevant features and relevant features (i.e. the features that are relevant to a given category) <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b1">2]</ref>. Taking the recognition task of 'dog' category as an example, as depicted in <ref type="figure" target="#fig_0">Figure 1</ref>, if dogs are in the water in most training images, the visual features of dogs and water would be strongly correlated, thus leading to the spurious correlation between visual features of water with the label 'dog'. As a result, when encountering images of dogs without water, or other objects (such as cats) with water, the model is prone to produce false predictions.</p><p>Recently, such distribution (domain) shift problems have been intensively studied in the domain generalization (DG) literature <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b37">38]</ref>. The basic idea of DG is to divide a category into multiple domains so that irrelevant features vary across different domains while relevant features remain invariant <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b46">47]</ref>. Such training data makes it possible for a well-designed model to learn the invariant representations across domains and inhibit the negative effect from irrelevant features, leading to better generalization ability under distribution shifts. Some pioneering methods require clear and significant heterogeneity, namely that the domains are manually divided and labeled <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b48">49]</ref>, which cannot be always satisfied in real applications. More recently, some methods are proposed to implicitly learn latent domains from data <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b67">68]</ref>, but they implicitly assume that the latent domains are balanced, meaning that the training data is formed by balanced sampling from latent domains. In real cases, however, the assumption of domain balance can be easily violated, leading to the degeneration of these methods. This is also empirically validated in our experiments as shown in Section 4.</p><p>Here we consider a more realistic and challenging setting where the domains of training data are unknown and we do not implicitly assume that the latent domains are balanced. With this goal, a strand of research on stable learning are proposed <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b32">33]</ref>. Given that the statistical dependence between relevant and irrelevant features is a major cause of model crash under distribution shifts, they propose to realize out-of-distribution generalization by decorrelating the relevant and irrelevant features. Since there is no extra supervision for separating relevant features from irrelevant features, a conservative solution is to decorrelate all features. Recently, this notion has been demonstrated to be effective in improving the generalization ability of linear models. <ref type="bibr" target="#b33">[34]</ref> proposes a sample weighting approach with the goal of decorrelating input variables, and <ref type="bibr" target="#b58">[59]</ref> theoretically proves why such sample weighting can make a linear model produce stable predictions under distribution shifts. But they are all developed under the constraints of linear frameworks. When extending these ideas into deep models to tackle more complicated data types like images, we confront two main challenges. First, the complex non-linear dependencies among features are much more difficult to be measured and eliminated than the linear ones. Second, the global sample weighting strategy in these methods requires excessive storage and computational cost in deep models, which is infeasible in practice.</p><p>To address these two challenges, we propose a method called StableNet. In terms of the first challenge, we propose a novel nonlinear feature decorrelation approach based on Random Fourier Features <ref type="bibr" target="#b52">[53]</ref> with linear computational complexity. As for the second challenge, we propose an efficient optimization mechanism to perceive and remove correlations globally by iteratively saving and reloading features and weights of the model. These two modules are jointly optimized in our method. Moreover, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>, StableNet can effectively partial out the irrelevant features (i.e. water) and leverage truly relevant features for prediction, leading to more stable performances in the wild non-stationary environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Domain Generalization. Domain generalization (DG) considers the generalization capacities to unseen domains of deep models trained with multiple source domains. A common approach is to extract domain-invariant features over multiple source domains <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b46">47]</ref> or to aggregate domain-specific modules <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>. Several works propose to enlarge the available data space with augmentation of source domains <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b71">72]</ref>. There are several approaches that exploit regularization with meta-learning <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b10">11]</ref> and Invariant Risk Minimization (IRM) framework <ref type="bibr" target="#b1">[2]</ref> for DG. Despite the promising results of DG methods in the well-designed experimental settings, some strong assumptions such as the manually divided and labeled domains and the balanced sampling process from each domain actually hinder the DG methods from real applications. Feature Decorrelation. As the correlations between features affect or even impair the model prediction, several works have focused on remove such correlation in the training process. Some pioneering works based on Lasso framework <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b7">8]</ref> propose to decorrelate features by adding a regularizer that imposes the highly correlated features not to be selected simultaneously. Recently, several works theoretically bridge the connections between correlation and model stability under misspecification <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b33">34]</ref>, and propose to address such a problem via a sample reweighting scheme. However, the above methods are all developed under linear frameworks which can not handle complex data types such as images and videos in computer vision applications. More related works and discussions are in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Sample Weighting for Distribution Generalization</head><p>We address the distribution shifts problem by weighting samples globally to directly decorrelate all the features for every input sample, thus statistical correlations between relevant and irrelevant features are eliminated. Concretely, StableNet gets rid of both linear and non-linear dependencies between features by utilizing the characteristics of Random Fourier Features (RFF) and sample weighting. To adapt the global decorrelation method to modern deep models, we further propose the saving and reloading global correlation mechanism, to decrease the usage of storage and computational cost when the training data are of a large scale. The formulations and theoretical explanations are shown in Section 3.1. In Section 3.2, we introduce the saving and reloading global correlation method, which makes calculating correlation globally possible with deep models. Notations X ? R m X denotes the space of raw pixels, Y ? R m Y denotes the outcome space and Z ? R m Z denotes the representation space. m X , m Y , m Z are the dimensions of space X , Y, Z, respectively. f : X ? Z denotes the representation function and g : Z ? Y denotes the prediction function. We have n samples X ? R n?m X with labels Y ? R n?m Y and we use X i and y i to denote the i-th sample. The representations learned by neural networks are donated as Z ? R n?m Z and the i-th variable in the representation space is donated as Z :,i . We use w ? R n to denote sample weights. u and v are Random Fourier Features mapping functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Sample weighting with RFF</head><p>Independence testing statistics To eliminate the dependence between any pair of features Z :,i and Z :,j in the representation space, we introduce hypothesis testing statistics that measures the independence between random variables. Suppose there are two one-dimensional random variables A, B (Here we use A and B to represent random variables instead of Z :,i and Z :,j for simplicity of notation.) and we sample (A 1 , A 2 , . . . A n ) and (B 1 , B 2 , . . . B n ) from the distribution of A and B, respectively. The main problem is how relevant these two variables are based on the samples.</p><p>Consider a measurable, positive definite kernel k A on the domain of random variable A and the corresponding RKHS is denoted by H A . If k B and H B are similarly defined, the cross-covariance operator ? AB <ref type="bibr" target="#b13">[14]</ref> from H B to H A is as follows:</p><formula xml:id="formula_0">h A , ? AB h B =E AB [h A (A)h B (B)] ? E A [h A (A)]E B [h B (B)]<label>(1)</label></formula><p>for all h A ? H A and h B ? H B . Then, the independence can be determined by the following proposition <ref type="bibr" target="#b14">[15]</ref>.</p><formula xml:id="formula_1">Proposition 3.1 If the product k A k B is characteristic, E[k A (A, A)] &lt; ? and E[k B (B, B)] &lt; ?, we have ? AB = 0 ?? A ? B<label>(2)</label></formula><p>Hilbert-Schmidt Independence Criterion (HSIC) <ref type="bibr" target="#b19">[20]</ref>, which requires that the squared Hilbert-Schmidt norm of ? AB should be zero, can be applied as a criterion to supervise feature decorrelation <ref type="bibr" target="#b2">[3]</ref>. However, the calculation of HSIC requires noticeable computational cost which grows as the batch size of training data increases, so it is inapplicable to training deep models on large datasets. More approaches of independence test are discussed in Appendix B.2. Actually, Frobenius norm corresponds to the Hilbert-Schmidt norm in Euclidean space <ref type="bibr" target="#b60">[61]</ref>, so that the independent testing statistic can be based on Frobenius norm. Let the partial cross-covariance matrix be:</p><formula xml:id="formula_2">?AB = 1 n ? 1 n i=1 u(Ai) ? 1 n n j=1 u(Aj) T ? v(Bi) ? 1 n n j=1 v(Bj) ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">u(A) = (u 1 (A), u 2 (A), . . . u n A (A)) , u j (A) ? H RFF , ?j, v(B) = (v 1 (B), v 2 (B), . . . v n B (B)) , v j (B) ? H RFF , ?j.<label>(4)</label></formula><p>Here we sample n A and n B functions from H RFF respectively and H RFF denotes the function space of Random Fourier Features with the following form</p><formula xml:id="formula_4">H RFF = h : x ? ? 2 cos(?x + ?) | ? ? N (0, 1), ? ? Uniform(0, 2?) ,<label>(5)</label></formula><p>i.e. ? is sampled from the standard Normal distribution and ? is sampled from the Uniform distribution. Then, the independence testing statistic I AB is defined as the Frobenius norm of the partial cross-covariance matrix, i.e.,</p><formula xml:id="formula_5">I AB = ? AB 2 F .</formula><p>Notice that I AB is always non-negative. As I AB decreases to zero, the two variables A and B tends to be independent. Thus I AB can effectively measure the independence between random variables. The accuracy of independence test grows as n A and n B increase. Empirically, setting both n A and n B to 5 is solid enough to judge the independence of random variables <ref type="bibr" target="#b60">[61]</ref>.</p><p>Learning sample weights for decorrelation Inspired by <ref type="bibr" target="#b33">[34]</ref>, we propose to eliminate the dependence between features in the representation space via sample weighting and measure general independence via RFF.</p><p>We use w ? R n + to denote the sample weights and n i=1 w i = n. After weighting, the partial cross-covariance matrix for random variables A and B in Equation 3 can be calculated as follows:</p><formula xml:id="formula_6">?AB;w = 1 n ? 1 n i=1 wiu(Ai) ? 1 n n j=1 wju(Aj) T ? wiv(Bi) ? 1 n n j=1 wjv(Bj) .<label>(6)</label></formula><p>Here u and v are the RFF mapping functions explained in <ref type="bibr">Equation 4</ref>. StableNet targets independence between any pair of features. Specifically, for feature Z :,i and Z :,j , the corresponding partial cross-covariance matrix should be ? Z:,iZ:,j ;w 2 F , shown in Equation <ref type="bibr" target="#b5">6</ref>. We propose to optimize w by</p><formula xml:id="formula_7">w * = arg min w??n 1?i&lt;j?m Z ? Z:,iZ:,j ;w 2 F ,<label>(7)</label></formula><p>where ? n = w ? R n + | n i=1 w i = n . Hence, weighting training samples with the optimal w * can mitigate the dependence between features to the greatest extent Generally, our algorithm iteratively optimize sample weights w, representation function f , and prediction func-tion g as follows:</p><formula xml:id="formula_8">f (t+1) , g (t+1) =arg min f,g n i=1 w (t) i L(g(f (X i )), y i ), w (t+1) =arg min w??n 1?i&lt;j?m Z ? Z (t+1) :,i Z (t+1) :,j ;w 2 F . (8) where Z (t+1) = f (t+1) (X)</formula><p>, L(?, ?) represents the cross entropy loss function and t represents the time stamp. Initially, w (0) = (1, 1, . . . , 1) T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Learning sample weights globally</head><p>Equation 8 requires a specific weight learned for each sample. However, in practice, especially for deep learning tasks, it requires enormous storage and computational cost to learn sample weights globally. Moreover, with SGD for optimization, only part of the samples are observed in each batch, hence global weights for all samples cannot be learned. In this part, we propose a saving and reloading method, which merges and saves features and sample weights encountered in the training phase and reloads them as global knowledge of all the training data to optimize sample weights.</p><p>For each batch, the features used to optimize the sample weights are generated as follows:</p><formula xml:id="formula_9">Z O = Concat (Z G1 , Z G2 , ? ? ?, Z Gk , Z L ) , w O = Concat (w G1 , w G2 , ? ? ?, w Gk , w L ) .<label>(9)</label></formula><p>Here we slightly abuse the notation Z O and w O to mean the features and weights used to optimize the new sample weights, respectively, Z G1 , ? ? ?, Z Gk , w G1 , ? ? ?, w Gk are global features and weights, which are updated at the end of each batch and represent global information of the whole training dataset. Z L and w L are features and weights in the current batch, representing the local information. The operation for merging all features in Equation 9 is the concatenating operation along samples, i.e. if the batch size is</p><formula xml:id="formula_10">B, Z O is a matrix of size ((k + 1)B) ? m Z and w O is a ((k + 1)B)-dimensional vector.</formula><p>In this way, we reduce the storage and the computational cost from O(N ) to O(kB).</p><p>While training for each batch, we keep w Gi fixed and only w L is learnable under Equation <ref type="bibr" target="#b7">8</ref>. At the end of each iteration of training, we fuse the global information (Z Gi , w Gi ) and the local information (Z L , w L ) as follows:</p><formula xml:id="formula_11">Z Gi = ? i Z Gi + (1 ? ? i )Z L , w Gi = ? i w Gi + (1 ? ? i )w L .<label>(10)</label></formula><p>Here for each group of global information (Z Gi , w Gi ), we use k different smoothing parameters ? i for considering both long-term memory (? i is large) and short-term memory (? i is small) in global information and k indicates that the presaved features are k times of that of original features.</p><p>Finally, we substitute all (Z Gi , w Gi ) with (Z Gi , w Gi ) for the next batch.</p><p>In the training phase, we iteratively optimize sample weights and model parameters with Equation 8. In the inference phase, the predictive model directly conduct prediction without any calculation of sample weights. The detailed procedure of our method is shown in Appendix B.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental settings and datasets</head><p>We validate StableNet in a variety of settings. To cover more general and challenging cases of distribution shifts, we adopt four experimental settings as follows: Unbalanced. In the common DG setting, the capacities of source domains are assumed to be comparable. However, considering most datasets are a mixture of latent unknown domains, one can hardly assume that the amount of samples from these domains are consistent since these datasets are not generated by equally sampling from latent domains. We simulate this scenario with this setting. Domains are split into source domains and target domains. The capacities of various domains can vary significantly. Note that this setting, where the capacities of available domains are unbalanced while the proportion of each class remains consistent across domains, is completely different from the settings of the class imbalance problem. This setting is to evaluate the generalization ability of models when the heterogeneity is unclear and insignificant. Flexible. We consider a more challenging but common in real-world setting where domains for different categories can be various. For instance, birds can be on trees but hardly in the water while fishes are the opposite. If we consider the backgrounds in images as an indicator of domain division, images for class 'bird' can be divided into domain 'on tree' but cannot into domain 'in water' while images for class 'fish' are otherwise, resulting in the diversity of domains among different classes. Thus this setting simulates a widely existing scenario in the real-world. In such cases, the level of the distribution shifts varies in different classes, requiring a strong ability of generalization given the statistical correlations between relevant features and categoryirrelevant features vary. Adversarial. We consider the most challenging scenario, where the model is under adversarial attack and the spurious correlations between domains and labels are strong and misleading. For instance, we assume a scenario where the category 'dog' is usually associated with the domain 'grass' and the category 'cat' with the domain 'sofa' in the training data, while the category 'dog' is usually associated with the domain 'sofa' and the category 'cat' with the domain 'grass' in the testing data. If the ratio of domain 'grass' in the im-ages from class 'dog' is significantly higher than others, the predictive model may tend to recognize grass as a dog. Classic. This setting is the same as the common setting in DG. The capacities of various domains are comparable. Therefore this setting is to evaluate the generalization ability of models when the heterogeneity of training data is significant and clear, which is less challenging compared with the previous three settings. Datasets. We consider four datasets to carry through these four settings, namely PACS <ref type="bibr" target="#b35">[36]</ref>, VLCS <ref type="bibr" target="#b65">[66]</ref>, MNIST-M <ref type="bibr" target="#b15">[16]</ref> and NICO <ref type="bibr" target="#b21">[22]</ref>. Introduction to these datasets and details of implementation are in Appendix C.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Unbalanced setting</head><p>Given this setting requires all the classes in the dataset share the same candidate set of domains, which is incompatible with NICO, we adopt PACS and VLCS for this setting. Three domains are considered as source domains and the other one as target. To make the amount of data from heterogeneous sources clearly differentiated, we set one domain as the dominant domain. For each target domain, we randomly select one domain from the source domains as the dominant source domain and adjust the ratio of data from the dominant domain and the other two domains. Details of ratios and partition are shown in Appendix C.2.</p><p>Here we show the results when the capacity ratio of three source domains is 5:1:1 in <ref type="table" target="#tab_4">Table 1</ref> and our method outperforms other methods in all the target domains on both PACS and VLCS. Moreover, StableNet achieves best performance consistently under all the other ratios as shown in Appendix C.2. These results indicate that the subtle statistical correlations between relevant and irrelevant features are strong enough to significantly harm the generalization across domains. When the correlations are eliminated, the model is able to learn the true connections between relevant features and labels and inference according to them only, thus generalize better. For adversarially trained methods like DG-MMLD <ref type="bibr" target="#b45">[46]</ref>, the supervision from minor domains is insufficient and the ability of the model to discriminate irrelevant features is impaired. For augmentation of source domains based methods like M-ADA <ref type="bibr" target="#b51">[52]</ref>, the impact of the dominant domain is not diminished while the minor ones are still insignificant after the augmentation. Methods like RSC <ref type="bibr" target="#b26">[27]</ref> adopt regularization to prevent the model from overfitting on source domains and the samples from minor domains can be considered as outliers and ignored. Therefore, the subtle correlations between relevant features and irrelevant features especially in minor domains are not eliminated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Unbalanced + flexible setting</head><p>We adopt PACS, VLCS and NICO to evaluate the unbalanced + flexible setting. For PACS and VLCS, we randomly select one domain as the dominant domain for each <ref type="table" target="#tab_4">Table 1</ref>: Results of the unbalanced setting on PACS and VLCS. We reimplement the methods that require no domain labels on PACS and VLCS with ResNet18 <ref type="bibr" target="#b20">[21]</ref> which is pretrained on ImageNet <ref type="bibr" target="#b8">[9]</ref> as the backbone network for all the methods. The reported results are average over three repetitions of each run. The title of each column indicates the name of the domain used as target. The best results of all methods are highlighted with the bold font and the second with underscore.  class, and another domain as the target. For NICO, there are 10 domains for each class, 8 out of which are selected as the source and 2 as the target. We adjust the ratio of the dominant domain to minor domains to adjust the level of distribution shifts. Here we report the results when the dominant ratio is 5:1:1. Details and more results of other divisions are shown in Appendix C.3.</p><p>The results are shown in <ref type="table" target="#tab_1">Table 2</ref>. M-ADA and DG-MMLD fail to outperform ResNet-18 on NICO under this setting. M-ADA, which generates images for training with an autoencoder, may fail when the training data are largescale real-world images and the distribution shifts are not caused by random disturbance. DG-MMLD generates domain labels with clustering and may fail when the data lack explicit heterogeneity or the number of latent domains is too large for clustering. In contrast, StableNet shows a strong ability of generalization when the input data are with complicated structure especially real-world images from unlimited resources. StableNet can capture various forms of dependencies and balance the distribution of input data. On PACS and VLCS, StableNet also outperforms state-of-theart methods, showing the effectiveness of removing statistical dependencies between features especially when the source domains for different categories are not consistent. More experimental results are in Appendix C.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Unbalanced + flexible + adversarial setting</head><p>To exploit the effect of various levels of adversarial attack, we adopt MNIST-M to evaluate our method owing to the numerous (200) optional domains in MNIST-M. Domains in PACS and VLCS are insufficient to generate multi-ple adversarial levels. Hence, we generate a new MNIST-M dataset with three rules: 1) for a given category, there is no overlap between the domains in training and testing; 2) a background image is randomly chosen for each category in the training set, and contexts cropped in the same image are assigned as dominant contexts (domains) for another category in test data so that there are strong spurious correlations between labels and domains; 3) the ratio of dominant context to other contexts varies from 9.5:1 to 1:1 to generate settings with different levels of distribution shifts. Detailed data generating method, adopted backbone network and sample images are in Appendix C.4.</p><p>The results are shown in <ref type="table" target="#tab_2">Table 3</ref>. As the dominant ratio increases, the spurious correlation between domains and categories becomes stronger so that the performance of predictive models drops. When the imbalance in visual features is significant, our method achieves noticeable improvement compared with baseline methods. For regularization-based methods such as RSC, they tend to weaken the supervision from minor domains which may be considered as outliers and therefore the spurious correlations between irrelevant features and labels are strengthened under adversarial attacks, resulting in even poorer results compared with the vanilla ResNet model. As shown in Table 3, RSC fails to outperform vanilla CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Classic setting</head><p>The classic setting is the same as the common setting in DG. Domains are split into source domains and target domains. The capacities of various domains are comparable. Given this setting requires all the classes in the dataset to  share the same candidate set of domains, which is incompatible with NICO, we adopt PACS and VLCS for this setting. We follow the experimental protocol of <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b45">46]</ref> for both the datasets and utilize three domains as source domains and the remaining one as the target. The results are shown in <ref type="table" target="#tab_3">Table 4</ref>. On VLCS, StableNet outperforms other state-of-the-art methods in two out of four target cases and achieves the highest average accuracy. On PACS, StableNet achieves the highest accuracy on the target domain 'photo' and comparable average accuracy (0.46% less) compared with the state-of-the-art method, RSC. The accuracy gap between StableNet and baseline indicates that even when the numbers of samples from different source domains are approximately the same, the subtle statistical correlations between relevant features and irrelevant features still hold strong and the model generalizes across domains better when the correlations are eliminated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Ablation study</head><p>StableNet relies on Random Fourier Features sampled from Gaussian to balance the training data. The more features are sampled, the more independent the final representations are. In practice, however, generating more features requires more computational cost. In this ablation study, we exploit the effect of sampling size for Random Fourier Features. Moreover, inspired by <ref type="bibr" target="#b64">[65]</ref>, one can further reduce the feature dimension by randomly selecting features used to calculate dependence with different ratios. <ref type="figure">Figure  3</ref> shows the results of StableNet with different dimensions of Random Fourier Features. If we remove all the Random Fourier Features, our regularizer in <ref type="bibr">Equation 12</ref> degenerates and can only model the linear correlation between features. <ref type="figure" target="#fig_1">Figure 2</ref>(a) demonstrates the effectiveness of eliminating non-linear dependence between representations. From <ref type="figure" target="#fig_1">Figure 2(b)</ref>, the non-linear dependence is common in vision features and keep deep models from learning true dependence between input images and category labels.</p><p>We further exploit the effect of the size of presaved features and weights in Equation 9 and the results are shown in <ref type="figure" target="#fig_1">Figure 2(c)</ref>. When the size of presaved features is reduced to 0, sample weights are learned inside of each batch, yielding noticeable variance. Generally, as the presaving size increases, the accuracy raises slightly and the variance drops significantly, indicating that presaved features help to learn sample weights globally and therefore the generalization ability of the model is more stable. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Saliency map</head><p>An intuitive type of explanation for image classification models is to identify pixels that have a strong influence on the final decision <ref type="bibr" target="#b59">[60]</ref>. To demonstrate whether the model focuses on the object or the context (domain) while conducting prediction, we visualize the gradient of the class score function with respect to the input pixels. In the case of stable learning, we adopt the same backbone architecture for all methods, so that we adopt smoothed gradient as suggested by <ref type="bibr" target="#b0">[1]</ref>, which generates saliency maps depending on the learned parameters of the models instead of the architecture. Visualization results are shown in <ref type="figure">Figure 4</ref>. Saliency maps of the baseline model show that various contexts draw noticeable focus of the classifier while fail to make decisive contributions to our model. More visualization results are in Appendix C.6, which further demonstrate that StableNet focuses more on visual parts which are both distinguishing and invariant when the postures or positions of objects vary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In the paper, to improve the generalization of deep models under distribution shifts, we proposed a novel method called StableNet which can eliminate the statistical correlation between relevant and irrelevant features via sample weighting. Extensive experiments across a wide range of settings demonstrated the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Detailed Training Procedure of StableNet</head><p>In the training phase, StableNet learns a set of sample weights for each batch with the global knowledge of correlations between features saved before. The parameters of the model and the sample weights are optimized iteratively.</p><p>As shown in Algorithm 1, for each input batch (X L , Y L ), the corresponding representations Z L = f (X L ) is concatenated with pre-saved global representations Z G1 , Z G2 , ? ? ? , Z Gk , as shown in <ref type="bibr">Equation 11</ref>.</p><formula xml:id="formula_12">Z O = Concat (Z G1 , Z G2 , ? ? ? , Z Gk , Z L ) .<label>(11)</label></formula><p>Then the model learns the local weights with global weights w G1 , w G2 , ? ? ? , w Gk by optimizing Equation <ref type="bibr" target="#b11">12</ref>.</p><formula xml:id="formula_13">w L = arg min w?? B 1?i&lt;j?m Z ? Z O :,i Z O :,j ;w O 2 F ,<label>(12)</label></formula><p>where B is the batch size and</p><formula xml:id="formula_14">w O = Concat (w G1 , w G2 , ? ? ? , w Gk , w) .</formula><p>The loss for optimizing the representation extractor f and the classifier g is calculated by conducting sample weights w L and penalties for input samples as shown in Equation <ref type="bibr" target="#b12">13</ref>.</p><formula xml:id="formula_15">L f,g = B i=1 w Li L(g(f (X Li )), Y Li ).<label>(13)</label></formula><p>The present features and weights are integrated with the previous global features and weights as shown in Equation <ref type="bibr" target="#b13">14</ref>.</p><formula xml:id="formula_16">Z Gi = ? i Z Gi + (1 ? ? i )Z L , w Gi = ? i Z Gi + (1 ? ? i )w L .<label>(14)</label></formula><p>In the inference phase, given the back propagation is disabled, StableNet escapes the sample weighting phase and conduct prediction directly.</p><p>In practice, the optimization also requires a regularizer of weight decay. We set the weight of the regularizer to 0.3 and the learning rate for sample weights to 3.0 unless otherwise noted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Other Approaches for Independence Test</head><p>Despite the fact that there are several approaches to be used as the supervision of feature independence, they can hardly be used to optimize deep models within acceptable cost. For instance, Hilbert-Schmidt Independence Criterion (HSIC), which can be used in independent component analysis (ICA) <ref type="bibr" target="#b18">[19]</ref>, is applied as a criterion for feature decorrelation in <ref type="bibr" target="#b2">[3]</ref>. However, the calculation of HSIC requires noticeable computational cost which grows as the batch size of training data increases, so it is inapplicable to training deep models on large datasets. Another approach, Mutual Information (MI), requires variational bounds to estimate <ref type="bibr" target="#b50">[51]</ref>, which are hard to be assembled with common convolutional networks such as ResNet <ref type="bibr" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Correlation between the Unbalanced Setting and the Problem of Unbalanced Classes</head><p>There are many works focus on the class imbalance problem <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b70">71]</ref>. But our unbalanced setting is a completely different problem. The key of problem of class imbalance is learning a better classifier to improve the recognition accuracy of minor classes, while the unbalanced setting valuates the ability of learning the correlation between object-relevant features and labels using the heterogeneity of unbalanced domains. In our setting, the proportion of different classes , which our settings do not focus on, may be different in both the unbalanced setting and the classic setting. Experiments show that methods for the class imbalance problem is not effective (comparable or worse compared with ResNet-18) in the unbalanced setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Correlation between our method and feature disentanglement</head><p>There are many works attempt learning disentangled features for robust or explainable representations <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b23">24]</ref> with strong constrains on features. These disentanglement methods such as VAE <ref type="bibr" target="#b29">[30]</ref> force features to be disentangled, which changes the semantic implication of features, while StableNet learns sample weights to adjust the data structure while the semantic of features is not effected given disentanglement is not our target but a path to learn true correlation between relevant features and labels. We fail to train VAEbased models that outperform the ResNet-18 model in all of our settings. Back propagate with weighted prediction loss as Equation <ref type="formula" target="#formula_0">13</ref> 9:</p><p>Save features and weights as Equation <ref type="formula" target="#formula_0">14</ref> 10:</p><p>end for 11: end for B. Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Datasets</head><p>We adopt 4 datasets to conduct experiments in our 4 settings. We briefly introduce them as follows.</p><p>MNIST-M is generated by the method in the original paper, which is blending digits from the original MNIST dataset over patches extracted from images in BSDS500 dataset.</p><p>VLCS consists of 5 object categories shared by the PAS-CAL VOC 2007, LabelMe, Caltech and Sun datasets. We follow the standard protocol of <ref type="bibr" target="#b17">[18]</ref> and divide each domain into a training set (70%) and validation set (30%) randomly.</p><p>PACS is a widely used benchmark for domain generalization which consists of 7 object categories spanning 4 image styles, namely photo, art-painting, cartoon and sketch. We adopt the protocol in <ref type="bibr" target="#b35">[36]</ref> to split the training and val set.</p><p>NICO is dedicately designed for Non-I.I.D (distribution shifts) image classification. The images from each category can be wildly various and labeled with 10 contexts. For PACS and VLCS, we adopt ResNet-18 <ref type="bibr" target="#b20">[21]</ref> as the backbone model. Given the images from PACS and VLCS are not sufficient to train a randomly initialized deep model like ResNet-18, we use the weights pretrained on ImageNet <ref type="bibr" target="#b8">[9]</ref>. For NICO, randomly initialized ResNet-18 is used as the backbone model. For PACS and VLCS, We train all the methods 30 epochs. The initial learning rate is 0.01 and decays with a rate of 0.1 at epoch 24. For NICO, we train all the methods 60 epochs. We set initial learning rate to 0.02 which decays with a rate of 0.1 at epoch 30. The weight decay is set to 0.0005 for all the three datasets. For MNIST-M, we use a 4-layer convolutional network as the backbone and the structure is shown in <ref type="table" target="#tab_5">Table 5</ref>. The models are trained 30 epochs. The learning rate is 0.02 and decays with a rate of 0.1 at epoch 20. The weight decay is 0.001. For JiGen <ref type="bibr" target="#b6">[7]</ref>, DG-MMLD <ref type="bibr" target="#b45">[46]</ref> and RSC <ref type="bibr" target="#b26">[27]</ref>, we adopt the code published by the authors of original papers and the hyperparameters reported in original papers. For M-ADA <ref type="bibr" target="#b51">[52]</ref>, we train the model for 5000 iterations on MNIST-M, PACS and VLCS, 8000 iterations on NICO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Training Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3. More Results and Data Split Details of Unbalanced Setting</head><p>In the unbalanced setting, , we randomly choose a dominant domain for each target domain for both PACS and VLCS. The ratio of data amount from dominant domain to other domains are 5:1:1 in Section 4.2. To simulate a more general setting, we also evaluate DG methods on settings where domain ratio is 3:1:1 and 2:1:1. The numbers of samples from each domain on PACS are shown in <ref type="table" target="#tab_4">Table  17</ref>, 13, and 15. The numbers of samples from each domain on VLCS are shown in <ref type="table" target="#tab_4">Table 18</ref>, 14 and 16.</p><p>The results of the unbalanced setting when the domain ratio is 3:1:1 on PACS and VLCS are shown in <ref type="table" target="#tab_6">Table 6</ref>. Sta-bleNet outperforms all the other state-of-the-art methods on all the target domains on VLCS and three out of four domains on PACS. StableNet achieves the highest average accuracy across four domains both on PACS and VLCS. The  results of the unbalanced setting when the domain ratio is 2:1:1 on PACS and VLCS are shown in <ref type="table" target="#tab_7">Table 7</ref>. StableNet also shows strong ability of generalization consistently in all the three unbalanced settings, which indicates the effectiveness of StableNet on more general settings of distribution shift problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4. More Results and Data Split Details of Unbalanced + Flexible Setting</head><p>In the unbalanced + flexible setting, we randomly choose a dominant domain for each target domain for both PACS and VLCS. The ratio of data amount from dominant domain to other domains are 5:1:1 in Section 4.3. We evaluate DG methods on unbalanced + flexible settings where the domain ratio is 5:1:1, 3:1:1, 2:1:1 and 1:1:1, respectively. Note that when the ratio is set to 1:1:1, this setting degenerates to flexible setting where the numbers of samples from different domains are approximately the same.</p><p>Actually, the classic DG setting is not sufficient for evaluating the generalization ability of models since the target domain is unique when the source domains are determined. So given the source domains, only the performance on a given target domain is evaluated while the goal of generalization is to generalize to any target domains. The unbalanced + flexible setting, however, can evaluate the ability of generalization to any domains since the model are tested on all the domains for given source domains. In other words, the model is trained once and tested on all the domains, while in the classic DG setting, the model is tested on one single domain for each training. Moreover, there are no overlap between source domains and the target domain for a single class so the generalization ability is evaluated.</p><p>The results of the unbalanced + flexible setting when the domain ratio is 3:1:1 and 2:1:1 on PACS and VLCS are shown in <ref type="table" target="#tab_8">Table 8</ref> and <ref type="table" target="#tab_9">Table 9</ref>, respectively. Note that the target domain for each class is randomly chosen so that there are two domains containing no test data. Details of data split of this setting are shown in <ref type="table" target="#tab_4">Table 17 and Table 18</ref>. Given the capacities of different target domains can be significantly various, we report the weighted average accuracy (denoted by 'overall' in the table) of all domains instead of naive average accuracy for the unbalanced + flexible setting, which is different from all the reported average accuracy for other settings. We show the accuracy of methods on all the domains. StableNet outperforms all the other stateof-the-art methods on almost all the target domains and on average accuracy on PACS and VLCS. Moreover, StableNet achieves the highest average accuracy across four domains both on PACS and VLCS. The results of the unbalanced + flexible setting when the domain ratio is 1:1:1 on PACS and VLCS are shown in <ref type="table" target="#tab_4">Table 10</ref>, where StableNet also outperforms other state-of-the-art counterparts.  The MNIST-M are generated by blending digit figures from the original MNIST dataset over patches extracted from images in BSDS500 dataset. The backgrounds are cropped from 200 images, resulting in 200 domains. The backgrounds from the same domain may be different given they are randomly cropped from the same image. We generate the adversarial setting by splitting the domains into 10 subsets responding to the classes. We randomly choose 1 subset for 1 class in the training data and choose 1 domain in the subset as the dominant domain. The ratio of the data from dominant domain to the data from other domains varies from 9.5:1 to 1:1. The subset chosen for one class for training is set to another class for testing, as well as the dominant domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.6. NICO</head><p>NICO is a dataset designed for distribution shifts problem. There are 19 categories and 10 contexts (domains) for each category. The domains for different category are various. The standard for split of contexts varies for different categories. For instance, some of the context are divided by the background of images such as 'on water' or 'on grass' while some by the posture of objects such as 'running' or 'standing'. Examples of images from NICO are shown in <ref type="figure">Figure 6</ref>.</p><p>There is a baseline method called CNBB in the original paper of NICO. We do not report the results of CNBB for the reason that it is designed for AlexNet and we fail to achieve reasonable results in our framework with CNBB. CNBB adopts Tanh function as the activation function and amplifies features from (-1, 1) to approach to {-1, 1} by a quantization loss shown as follows:</p><formula xml:id="formula_17">L = ? p i=1 g ? (x i ) 2 2<label>(15)</label></formula><p>This loss harms ResNet significantly and it is hard to find proper hyperparameters for CNBB with ResNet as the backbone network. Hence, we do not report the results of CNBB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.7. Examples of saliency maps</head><p>Examples of saliency maps are shown in <ref type="figure" target="#fig_4">Figure 7</ref>. The bright lines in saliency maps generated by JiGen demonstrates the effectiveness of the jigsaw puzzle, in which the model focuses more on the margins of any possible puzzles. And the highlight on the object in saliency maps generated by our method show that our model tends to focus on the object instead of the context. Therefore, our method help deep models learn the true connections between features and labels, resulting in models with stronger ability of generalization under distribution shifts.                 </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Visualization of saliency maps produced by the vanilla ResNet-18 model and StableNet when most of the training images containing dogs in the water.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The overall architecture of the proposed StableNet. LSWD refers to learning sample weighting for decorrelation as described in Section 3.1. Final loss is used to optimized the classification network. Detailed learning procedure of StableNet is in Section 3.1 and Appendix B.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Results of ablation study on NICO. All the experiments adopt NICO since NICO consists of a wide range of domains and objects and all domains come from real-world images which make the indication of results more reliable. The RFF dimension in (a) indicates the dimension of Fourier features, where 10x indicates that the dimension of Fourier features are 10 times the size of original features and 0.3x indicates the sampling ratio is 30%. StableNet-N and StableNet-L indicate the original StableNet and the degenerated version of StableNet that only eliminates the linear correlation between features. Presaved size in (c) indicates the dimension of the presaved features and 0x indicates no features are saved. Saliency maps of the ResNet-18 model and StableNet. The brighter the pixel is, the more contributions it makes to prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Example Images from MNIST-M Example images with category and context labels from NICO</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>More saliency maps of the ResNet-18 model and StableNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results of the unbalanced + flexible setting on PACS, VLCS and NICO. For details about the number of runs, meaning of column titles and fonts, seeTable 1.</figDesc><table><row><cell cols="6">JiGen M-ADA DG-MMLD RSC ResNet-18 StableNet (ours)</cell></row><row><cell>PACS 40.31</cell><cell>30.32</cell><cell>42.65</cell><cell>39.49</cell><cell>39.02</cell><cell>45.14</cell></row><row><cell>VLCS 76.75</cell><cell>69.58</cell><cell>78.96</cell><cell>74.81</cell><cell>73.77</cell><cell>79.15</cell></row><row><cell>NICO 54.42</cell><cell>40.78</cell><cell>47.18</cell><cell>57.59</cell><cell>51.71</cell><cell>59.76</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results of the unbalanced + flexible + adversarial setting on MNIST-M. Random donates each digit is blended over a randomly chosen background. DR0.5 donates that in each class, the proportion of the dominant domain in all the training data is 50% and other notations with 'DR' are similar. Random DR0.5 DR0.6 DR0.7 DR0.8 DR0.9 DR0.95 Avg.</figDesc><table><row><cell>Settings</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>JiGen</cell><cell>97.18</cell><cell>94.97</cell><cell>92.99</cell><cell>90.64</cell><cell>78.97</cell><cell>68.79</cell><cell>69.34</cell><cell>84.70</cell></row><row><cell>M-ADA</cell><cell>95.92</cell><cell>94.45</cell><cell>92.29</cell><cell>88.87</cell><cell>85.89</cell><cell>70.32</cell><cell>67.08</cell><cell>84.97</cell></row><row><cell>DG-MMLD</cell><cell>96.89</cell><cell>94.61</cell><cell>92.59</cell><cell>89.72</cell><cell>88.44</cell><cell>69.13</cell><cell>71.39</cell><cell>86.11</cell></row><row><cell>RSC</cell><cell>96.94</cell><cell>93.43</cell><cell>89.44</cell><cell>85.78</cell><cell>81.68</cell><cell>69.15</cell><cell>65.12</cell><cell>83.08</cell></row><row><cell>CNNs</cell><cell>96.93</cell><cell>93.76</cell><cell>91.93</cell><cell>88.13</cell><cell>81.48</cell><cell>68.43</cell><cell>66.11</cell><cell>83.82</cell></row><row><cell>StableNet (ours)</cell><cell>97.35</cell><cell>95.33</cell><cell>93.49</cell><cell>91.24</cell><cell>87.04</cell><cell>75.69</cell><cell>75.46</cell><cell>87.94</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Results of the classic setting on PACS and VLCS. All the results on PACS are obtained from the original papers of these methods. We reimplement the methods that require no domain labels on VLCS since these methods are tested with AlexNet<ref type="bibr" target="#b30">[31]</ref> in original papers while we adopt ResNet18<ref type="bibr" target="#b20">[21]</ref> as the backbone network for all the methods. The methods that require domain labels are labelled with asterisk.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>PACS</cell><cell></cell><cell></cell><cell>VLCS</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Art.</cell><cell cols="5">Cartoon Sketch Photo Avg. Caltech Labelme Pascal</cell><cell>Sun</cell><cell>Avg.</cell></row><row><cell>JiGen</cell><cell>79.42</cell><cell>75.25</cell><cell>71.35 96.03 80.51</cell><cell>96.17</cell><cell>62.06</cell><cell cols="3">70.93 71.40 75.14</cell></row><row><cell>M-ADA</cell><cell>64.29</cell><cell>72.91</cell><cell>67.21 88.23 73.16</cell><cell>74.33</cell><cell>48.38</cell><cell cols="3">45.31 33.82 50.46</cell></row><row><cell>DG-MMLD</cell><cell>81.28</cell><cell>77.16</cell><cell>72.29 96.09 81.83</cell><cell>97.01</cell><cell>62.20</cell><cell cols="3">73.01 72.49 76.18</cell></row><row><cell>D-SAM* [12]</cell><cell>77.33</cell><cell>72.43</cell><cell>77.83 95.30 80.72</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">Epi-FCR* [38] 82.10</cell><cell>77.00</cell><cell>73.00 93.90 81.50</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>FAR* [28]</cell><cell>79.30</cell><cell>77.70</cell><cell>74.70 95.30 81.70</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MetaReg* [4]</cell><cell>83.70</cell><cell>77.20</cell><cell>70.30 95.50 81.70</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>RSC</cell><cell>83.43</cell><cell>80.31</cell><cell>80.85 95.99 85.15</cell><cell>96.21</cell><cell>62.51</cell><cell cols="3">73.81 72.10 76.16</cell></row><row><cell>ResNet-18</cell><cell>76.61</cell><cell>73.60</cell><cell>76.08 93.31 79.90</cell><cell>91.86</cell><cell>61.81</cell><cell cols="3">67.48 68.77 72.48</cell></row><row><cell cols="2">StableNet (ours) 81.74</cell><cell>79.91</cell><cell>80.50 96.53 84.69</cell><cell>96.67</cell><cell>65.36</cell><cell cols="3">73.59 74.97 77.65</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Algorithm 1</head><label>1</label><figDesc>Training procedure of StableNet Input: EPOCH NUMBER, BALANCING EPOCH NUMBER Output: Learned model 1: for epoch ? 1 to EPOCH NUMBER do 2:for batch ? 1 to BATCH NUMBER do</figDesc><table><row><cell>3:</cell><cell>Forward propagate</cell></row><row><cell>4:</cell><cell>Reload global features as Equation 11</cell></row><row><cell>5:</cell><cell>for epoch balancing ? 1 to BALANCING EPOCH NUMBER do</cell></row><row><cell>6:</cell><cell>Optimize sample weights as Equation 12</cell></row><row><cell>7:</cell><cell>end for</cell></row><row><cell>8:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>The structure of CNNs for MNIST-M</figDesc><table><row><cell>Layer</cell><cell>Details</cell></row><row><cell>Input</cell><cell>3 ? 28 ? 28</cell></row><row><cell>Conv</cell><cell>Kernel Size 7, Stride 1, Out Channel 32, BN, ReLU</cell></row><row><cell>Conv</cell><cell>Kernel Size 5, Stride 2, Out Channel 32, BN, ReLU</cell></row><row><cell>Dropout</cell><cell>p = 0.4</cell></row><row><cell>Conv</cell><cell>Kernel Size 3, Stride 1, Out Channel 64, BN, ReLU</cell></row><row><cell>Conv</cell><cell>Kernel Size 3, Stride 2, Out Channel 64, BN, ReLU</cell></row><row><cell>Dropout</cell><cell>p = 0.4</cell></row><row><cell>FC</cell><cell>Out Channel 16, ReLU</cell></row><row><cell>SoftMax</cell><cell>Class Num</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Results of the unbalanced setting when the domain ratio is 3:1:1 on PACS and VLCS. The reported results are average over three repetitions of each run. The title of each column indicates the name of the domain used as target. The best results of all methods are highlighted with the bold font.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>PACS</cell><cell></cell><cell></cell><cell>VLCS</cell></row><row><cell></cell><cell>Art.</cell><cell cols="5">Cartoon Sketch Photo Avg. Caltech Labelme Pascal</cell><cell>Sun</cell><cell>Avg.</cell></row><row><cell>JiGen [7]</cell><cell>76.25</cell><cell>71.60</cell><cell>68.79 92.05 77.17</cell><cell>84.82</cell><cell>58.45</cell><cell cols="2">64.42 56.06 65.94</cell></row><row><cell>M-ADA [52]</cell><cell>65.76</cell><cell>66.98</cell><cell>54.49 90.33 69.39</cell><cell>66.25</cell><cell>53.13</cell><cell cols="2">43.80 47.30 52.62</cell></row><row><cell cols="2">DG-MMLD [46] 81.98</cell><cell>73.53</cell><cell>74.32 92.65 80.61</cell><cell>79.42</cell><cell>58.29</cell><cell cols="2">64.96 51.16 63.46</cell></row><row><cell>Focal loss [41]</cell><cell>75.56</cell><cell>70.13</cell><cell>67.91 90.75 76.09</cell><cell>75.22</cell><cell>53.98</cell><cell cols="2">56.61 53.88 59.92</cell></row><row><cell>RSC [27]</cell><cell>84.44</cell><cell>74.82</cell><cell>70.87 94.66 81.20</cell><cell>82.31</cell><cell>59.55</cell><cell cols="2">65.32 56.11 65.82</cell></row><row><cell>ResNet-18</cell><cell>75.90</cell><cell>73.34</cell><cell>69.22 93.82 78.07</cell><cell>81.66</cell><cell>61.75</cell><cell cols="2">60.20 57.33 65.24</cell></row><row><cell cols="2">StableNet (ours) 79.15</cell><cell>79.96</cell><cell>75.44 95.19 82.44</cell><cell>85.51</cell><cell>65.46</cell><cell cols="2">63.65 59.93 68.64</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Results of the unbalanced setting when the domain ratio is 2:1:1 on PACS and VLCS. For the number of each run and the use of font, seeTable 6.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>PACS</cell><cell></cell><cell></cell><cell>VLCS</cell></row><row><cell></cell><cell>Art.</cell><cell cols="5">Cartoon Sketch Photo Avg. Caltech Labelme Pascal</cell><cell>Sun</cell><cell>Avg.</cell></row><row><cell>JiGen</cell><cell>74.20</cell><cell>71.60</cell><cell>68.88 93.15 76.96</cell><cell>89.29</cell><cell>64.41</cell><cell cols="2">66.38 55.46 68.89</cell></row><row><cell>M-ADA</cell><cell>74.32</cell><cell>57.03</cell><cell>59.40 93.67 71.11</cell><cell>87.03</cell><cell>63.52</cell><cell cols="2">54.58 52.03 64.29</cell></row><row><cell>DG-MMLD</cell><cell>79.94</cell><cell>71.67</cell><cell>68.58 92.85 78.26</cell><cell>86.39</cell><cell>66.67</cell><cell cols="2">65.39 54.59 68.26</cell></row><row><cell>RSC</cell><cell>80.51</cell><cell>69.53</cell><cell>68.96 94.36 78.34</cell><cell>87.59</cell><cell>65.05</cell><cell cols="2">65.67 54.37 68.17</cell></row><row><cell>ResNet-18</cell><cell>75.75</cell><cell>68.35</cell><cell>64.59 93.37 75.52</cell><cell>84.77</cell><cell>64.62</cell><cell cols="2">65.38 52.59 66.84</cell></row><row><cell cols="2">StableNet (ours) 80.56</cell><cell>75.33</cell><cell>71.48 94.29 80.42</cell><cell>91.29</cell><cell>67.87</cell><cell cols="2">66.72 56.55 70.61</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Results of the unbalanced + flexible setting when the domain ratio is 3:1:1 on PACS and VLCS. For the number of each run and the use of font, seeTable 6.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>PACS</cell><cell></cell><cell></cell><cell></cell><cell>VLCS</cell><cell></cell></row><row><cell></cell><cell>Art.</cell><cell cols="6">Cartoon Sketch Photo Overall Caltech Labelme Pascal</cell><cell>Sun</cell><cell>Overall</cell></row><row><cell>JiGen</cell><cell>57.95</cell><cell>-</cell><cell>27.70 90.02</cell><cell>44.03</cell><cell>97.71</cell><cell>-</cell><cell cols="2">61.50 67.12</cell><cell>76.31</cell></row><row><cell>M-ADA</cell><cell>49.58</cell><cell>-</cell><cell>15.21 79.92</cell><cell>33.33</cell><cell>97.55</cell><cell>-</cell><cell cols="2">44.17 60.32</cell><cell>69.09</cell></row><row><cell>DG-MMLD</cell><cell>68.57</cell><cell>-</cell><cell>37.65 91.91</cell><cell>52.56</cell><cell>99.85</cell><cell>-</cell><cell cols="2">65.37 67.16</cell><cell>78.08</cell></row><row><cell>RSC</cell><cell>66.10</cell><cell>-</cell><cell>26.48 90.52</cell><cell>44.55</cell><cell>99.82</cell><cell>-</cell><cell cols="2">56.79 65.25</cell><cell>75.09</cell></row><row><cell>ResNet-18</cell><cell>57.11</cell><cell>-</cell><cell>28.54 89.79</cell><cell>45.07</cell><cell>99.25</cell><cell>-</cell><cell cols="2">63.37 63.55</cell><cell>75.93</cell></row><row><cell cols="2">StableNet (ours) 71.82</cell><cell>-</cell><cell>38.16 92.36</cell><cell>54.10</cell><cell>99.75</cell><cell>-</cell><cell cols="2">67.53 68.89</cell><cell>79.28</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>Results of the unbalanced + flexible setting when the domain ratio is 2:1:1 on PACS and VLCS. For the number of each run and the use of font, seeTable 6.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>PACS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>VLCS</cell><cell></cell></row><row><cell></cell><cell>Art.</cell><cell cols="7">Cartoon Sketch Photo Overall Caltech Labelme Pascal</cell><cell>Sun</cell><cell>Overall</cell></row><row><cell>JiGen</cell><cell>50.14</cell><cell>87.08</cell><cell cols="2">16.45 81.55</cell><cell>40.12</cell><cell>7.11</cell><cell>39.55</cell><cell cols="2">39.85 31.90</cell><cell>37.99</cell></row><row><cell>M-ADA</cell><cell>43.86</cell><cell>81.60</cell><cell>9.88</cell><cell>63.51</cell><cell>32.17</cell><cell>6.02</cell><cell>35.34</cell><cell cols="2">29.59 22.22</cell><cell>27.88</cell></row><row><cell>DG-MMLD</cell><cell>66.46</cell><cell>91.78</cell><cell cols="2">30.64 80.07</cell><cell>51.71</cell><cell>10.44</cell><cell>44.57</cell><cell cols="2">41.85 42.86</cell><cell>41.72</cell></row><row><cell>RSC</cell><cell>53.02</cell><cell>88.09</cell><cell cols="2">16.59 83.58</cell><cell>41.24</cell><cell>1.20</cell><cell>36.87</cell><cell cols="2">26.89 30.00</cell><cell>30.78</cell></row><row><cell>ResNet-18</cell><cell>56.62</cell><cell>80.56</cell><cell cols="2">20.98 77.58</cell><cell>42.83</cell><cell>45.42</cell><cell>33.72</cell><cell cols="2">39.17 23.81</cell><cell>36.49</cell></row><row><cell cols="2">StableNet (ours) 67.85</cell><cell>92.01</cell><cell cols="2">29.57 88.92</cell><cell>52.68</cell><cell>59.88</cell><cell>48.15</cell><cell cols="2">49.58 42.86</cell><cell>49.27</cell></row><row><cell cols="5">B.5. Details about the generation of MNIST-M in</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">the setting of composional + dominant + flexible +</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>adversarial</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>Results of the unbalanced + flexible setting when the domain ratio is 1:1:1 on PACS and VLCS. For the number of each run and the use of font, seeTable 6.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>PACS</cell><cell></cell><cell></cell><cell></cell><cell>VLCS</cell><cell></cell></row><row><cell></cell><cell>Art.</cell><cell cols="6">Cartoon Sketch Photo Overall. Caltech Labelme Pascal</cell><cell>Sun</cell><cell>Overall.</cell></row><row><cell>JiGen</cell><cell>61.84</cell><cell>94.37</cell><cell>26.67 87.76</cell><cell>44.91</cell><cell>99.97</cell><cell>17.93</cell><cell cols="2">59.84 53.34</cell><cell>69.71</cell></row><row><cell>M-ADA</cell><cell>3.06</cell><cell>80.45</cell><cell>22.87 85.38</cell><cell>36.42</cell><cell>89.92</cell><cell>5.75</cell><cell cols="2">46.30 41.54</cell><cell>58.02</cell></row><row><cell>DG-MMLD</cell><cell>65.77</cell><cell>97.19</cell><cell>43.44 89.87</cell><cell>57.07</cell><cell>100.00</cell><cell>20.00</cell><cell cols="2">60.43 55.12</cell><cell>70.61</cell></row><row><cell>RSC</cell><cell>62.64</cell><cell>96.97</cell><cell>23.99 89.75</cell><cell>43.69</cell><cell>100.00</cell><cell>15.17</cell><cell cols="2">54.03 50.09</cell><cell>66.87</cell></row><row><cell>ResNet-18</cell><cell>64.68</cell><cell>95.56</cell><cell>24.39 90.25</cell><cell>44.15</cell><cell>96.25</cell><cell>3.91</cell><cell cols="2">49.34 49.30</cell><cell>63.93</cell></row><row><cell cols="2">StableNet (ours) 67.66</cell><cell>98.52</cell><cell>41.90 95.85</cell><cell>57.41</cell><cell>100.00</cell><cell>24.14</cell><cell cols="2">63.60 63.19</cell><cell>74.70</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 :</head><label>11</label><figDesc>Data split details of unbalanced setting on PACS dataset when the domain ratio is 5:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell cols="2">Art painting: 2048 Cartoon: 405</cell><cell>Photo: 405</cell><cell>Sketch: 784</cell></row><row><cell>Sketch: 3929</cell><cell cols="3">Art painting: 779 Cartoon: 779 Photo: 331</cell></row><row><cell>Photo: 1670</cell><cell cols="2">Art painting: 327 Sketch: 327</cell><cell>Cartoon: 466</cell></row><row><cell>Cartoon: 2344</cell><cell>Photo: 463</cell><cell>Sketch: 463</cell><cell>Art painting: 407</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12 :</head><label>12</label><figDesc>Data split details of unbalanced setting on VLCS dataset when the domain ratio is 5:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell>Caltech: 991</cell><cell cols="2">Labelme: 196 Pascal: 196</cell><cell>Sun: 458</cell></row><row><cell>Sun: 2297</cell><cell>Caltech: 350</cell><cell cols="2">Labelme: 372 Pascal: 470</cell></row><row><cell>Pascal: 2363</cell><cell>Caltech: 448</cell><cell>Sun: 401</cell><cell>Labelme: 370</cell></row><row><cell cols="2">Labelme:1589 Pascal: 367</cell><cell>Sun: 367</cell><cell>Caltech: 196</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 13 :</head><label>13</label><figDesc>Data split details of unbalanced setting on PACS dataset when the domain ratio is 3:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell cols="2">Art painting: 2048 Cartoon: 678</cell><cell>Photo: 678</cell><cell>Sketch: 784</cell></row><row><cell>Sketch: 3929</cell><cell cols="3">Art painting: 1217 Cartoon: 1238 Photo: 331</cell></row><row><cell>Photo: 1670</cell><cell>Art painting: 551</cell><cell>Sketch: 538</cell><cell>Cartoon: 466</cell></row><row><cell>Cartoon: 2344</cell><cell>Photo: 776</cell><cell>Sketch: 761</cell><cell>Art painting: 407</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 14 :</head><label>14</label><figDesc>Data split details of unbalanced setting on VLCS dataset when the domain ratio is 3:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell>Caltech: 991</cell><cell cols="2">Labelme: 327 Pascal: 327</cell><cell>Sun: 458</cell></row><row><cell>Sun: 2297</cell><cell>Caltech: 473</cell><cell cols="2">Labelme: 583 Pascal: 470</cell></row><row><cell>Pascal: 2363</cell><cell>Caltech: 641</cell><cell>Sun: 647</cell><cell>Labelme: 370</cell></row><row><cell cols="2">Labelme: 1859 Pascal: 616</cell><cell>Sun: 612</cell><cell>Caltech: 196</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 15 :</head><label>15</label><figDesc>Data split details of unbalanced setting on PACS dataset when the domain ratio is 2:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell cols="2">Art painting: 2048 Cartoon: 1020</cell><cell>Photo: 1020</cell><cell>Sketch: 784</cell></row><row><cell>Sketch: 3929</cell><cell cols="3">Art painting: 1424 Cartoon: 1681 Photo: 331</cell></row><row><cell>Photo: 1670</cell><cell>Art painting: 831</cell><cell>Sketch: 715</cell><cell>Cartoon: 466</cell></row><row><cell>Cartoon: 2344</cell><cell>Photo: 1136</cell><cell>Sketch: 1062</cell><cell>Art painting: 407</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 16 :</head><label>16</label><figDesc>Data split details of unbalanced setting on VLCS dataset when the domain ratio is 2:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell>Caltech: 991</cell><cell cols="2">Labelme: 467 Pascal: 494</cell><cell>Sun: 458</cell></row><row><cell>Sun: 2297</cell><cell>Caltech: 627</cell><cell cols="2">Labelme: 846 Pascal: 470</cell></row><row><cell>Pascal: 2363</cell><cell>Caltech: 855</cell><cell>Sun: 953</cell><cell>Labelme: 370</cell></row><row><cell cols="2">Labelme: 1859 Pascal: 927</cell><cell>Sun: 914</cell><cell>Caltech: 196</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 17 :</head><label>17</label><figDesc>Data split details of unbalanced + flexible setting on PACS dataset when the domain ratio is 5:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell>Class</cell><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell>Dog</cell><cell>Cartoon: 350</cell><cell cols="2">Art painting: 70 Photo: 70</cell><cell>Sketch: 772</cell></row><row><cell cols="2">Elephant Cartoon: 411</cell><cell cols="2">Art painting: 82 Sketch: 82</cell><cell>Photo: 202</cell></row><row><cell>Giraffe</cell><cell>Photo: 163</cell><cell cols="3">Art painting: 32 Cartoon: 32 Sketch: 753</cell></row><row><cell>Guitar</cell><cell>Photo: 167</cell><cell>Cartoon: 33</cell><cell>Sketch: 33</cell><cell>Art painting: 184</cell></row><row><cell>Horse</cell><cell>Cartoon: 291</cell><cell>Photo: 58</cell><cell>Sketch: 58</cell><cell>Art painting: 201</cell></row><row><cell>House</cell><cell>Cartoon: 259</cell><cell cols="2">Art painting: 51 Sketch: 51</cell><cell>Photo: 280</cell></row><row><cell>Person</cell><cell cols="2">Art painting: 404 Cartoon: 80</cell><cell>Photo: 80</cell><cell>Sketch: 160</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 18 :</head><label>18</label><figDesc>Data split details of unbalanced + flexible setting on VLCS dataset when the domain ratio is 5:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell>Class</cell><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell>0</cell><cell>Labelme: 39</cell><cell>Caltech: 7</cell><cell>Pascal: 7</cell><cell>Sun: 14</cell></row><row><cell>1</cell><cell cols="2">Labelme: 592 Caltech: 86</cell><cell>Sun: 118</cell><cell>Pascal: 489</cell></row><row><cell>2</cell><cell>Pascal: 210</cell><cell>Caltech: 42</cell><cell cols="2">Labelme: 42 Sun: 725</cell></row><row><cell>3</cell><cell>Pascal: 205</cell><cell cols="2">Labelme: 29 Sun: 21</cell><cell>Caltech: 47</cell></row><row><cell>4</cell><cell cols="2">Labelme: 606 Pascal: 121</cell><cell>Sun: 121</cell><cell>Caltech: 609</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 19 :</head><label>19</label><figDesc>Data split details of unbalanced + flexible setting on PACS dataset when the domain ratio is 3:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell>Class</cell><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell>Dog</cell><cell>Cartoon: 389</cell><cell cols="2">Art painting: 129 Photo: 129</cell><cell>Sketch: 772</cell></row><row><cell cols="2">Elephant Cartoon: 457</cell><cell cols="3">Art painting: 152 Sketch: 152 Photo: 202</cell></row><row><cell>Giraffe</cell><cell>Photo: 182</cell><cell>Art painting: 60</cell><cell cols="2">Cartoon: 60 Sketch: 753</cell></row><row><cell>Guitar</cell><cell>Photo: 186</cell><cell>Cartoon: 61</cell><cell>Sketch: 61</cell><cell>Art painting: 184</cell></row><row><cell>Horse</cell><cell>Cartoon: 324</cell><cell>Photo: 108</cell><cell cols="2">Sketch: 108 Art painting: 201</cell></row><row><cell>House</cell><cell>Cartoon: 288</cell><cell>Art painting: 95</cell><cell>Sketch: 80</cell><cell>Photo: 280</cell></row><row><cell>Person</cell><cell cols="2">Art painting: 449 Cartoon: 149</cell><cell>Photo: 149</cell><cell>Sketch: 160</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 20 :</head><label>20</label><figDesc>Data split details of unbalanced + flexible setting on VLCS dataset when the domain ratio is 3:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell>Class</cell><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell>0</cell><cell>Labelme: 56</cell><cell>Caltech: 18</cell><cell>Pascal: 18</cell><cell>Sun: 14</cell></row><row><cell>1</cell><cell cols="2">Labelme: 846 Caltech: 86</cell><cell>Sun: 281</cell><cell>Pascal: 489</cell></row><row><cell>2</cell><cell>Pascal: 300</cell><cell>Caltech: 83</cell><cell cols="2">Labelme: 62 Sun: 725</cell></row><row><cell>3</cell><cell>Pascal: 294</cell><cell cols="2">Labelme: 29 Sun: 21</cell><cell>Caltech: 47</cell></row><row><cell>4</cell><cell cols="2">Labelme: 866 Pascal: 288</cell><cell>Sun: 288</cell><cell>Caltech: 609</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 21 :</head><label>21</label><figDesc>Data split details of unbalanced + flexible setting on PACS dataset when the domain ratio is 2:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell>Class</cell><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell>Dog</cell><cell>Photo: 189</cell><cell>Art painting: 94</cell><cell>Cartoon: 94</cell><cell>Sketch: 772</cell></row><row><cell cols="3">Elephant Art painting: 255 Sketch: 127</cell><cell cols="2">Cartoon: 127 Photo: 202</cell></row><row><cell>Giraffe</cell><cell>Photo: 182</cell><cell>Art painting: 90</cell><cell>Cartoon: 90</cell><cell>Sketch: 753</cell></row><row><cell>Guitar</cell><cell>Cartoon: 135</cell><cell>Art painting: 67</cell><cell>Sketch: 67</cell><cell>Photo: 186</cell></row><row><cell>Horse</cell><cell>Sketch: 816</cell><cell>Photo: 199</cell><cell cols="2">Cartoon: 324 Art painting: 201</cell></row><row><cell>House</cell><cell>Photo: 280</cell><cell cols="2">Art painting: 140 Sketch: 80</cell><cell>Cartoon: 288</cell></row><row><cell>Person</cell><cell>Cartoon: 405</cell><cell>Sketch: 160</cell><cell>Photo: 202</cell><cell>Art painting: 449</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 22 :</head><label>22</label><figDesc>Data split details of unbalanced + flexible setting on VLCS dataset when the domain ratio is 2:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell>Class</cell><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell>0</cell><cell cols="2">Labelme: 56 Caltech: 27</cell><cell>Sun: 14</cell><cell>Pascal: 231</cell></row><row><cell>1</cell><cell>Caltech: 86</cell><cell cols="2">Labelme: 43 Sun: 43</cell><cell>Pascal: 489</cell></row><row><cell>2</cell><cell cols="2">Labelme: 62 Pascal: 30</cell><cell>Sun: 30</cell><cell>Caltech: 83</cell></row><row><cell>3</cell><cell>Pascal: 294</cell><cell>Caltech: 47</cell><cell cols="2">Labelme: 29 Sun: 21</cell></row><row><cell>4</cell><cell cols="3">Pascal: 1049 Caltech: 524 Sun: 524</cell><cell>Labelme: 866</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 23 :</head><label>23</label><figDesc>Data split details of unbalanced + flexible setting on PACS dataset when the domain ratio is 1:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell>Class</cell><cell></cell><cell>Source</cell><cell></cell><cell>Target</cell></row><row><cell>Dog</cell><cell>Cartoon: 389</cell><cell cols="2">Art painting: 389 Photo: 189</cell><cell>Sketch: 772</cell></row><row><cell cols="2">Elephant Cartoon: 457</cell><cell cols="2">Art painting: 255 Sketch: 457</cell><cell>Photo: 202</cell></row><row><cell>Giraffe</cell><cell>Photo: 182</cell><cell cols="3">Art painting: 182 Cartoon: 182 Sketch: 753</cell></row><row><cell>Guitar</cell><cell>Photo: 186</cell><cell cols="2">Art painting: 184 Sketch: 184</cell><cell>Cartoon: 135</cell></row><row><cell>Horse</cell><cell>Cartoon: 324</cell><cell>Photo: 199</cell><cell>Sketch: 324</cell><cell>Art painting: 201</cell></row><row><cell>House</cell><cell>Cartoon: 288</cell><cell cols="2">Art painting: 288 Sketch: 80</cell><cell>Photo: 280</cell></row><row><cell>Person</cell><cell cols="2">Art painting: 449 Cartoon: 405</cell><cell>Photo: 432</cell><cell>Sketch: 160</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 24 :</head><label>24</label><figDesc>Data split details of unbalanced + flexible setting on VLCS dataset when the domain ratio is 1:1:1. The dominant domain for each target domain is highlighted with the bold font.</figDesc><table><row><cell>Class</cell><cell></cell><cell>Source</cell><cell>Target</cell></row><row><cell>0</cell><cell>Labelme: 56</cell><cell>Caltech: 56 Pascal: 56</cell><cell>Sun: 14</cell></row><row><cell>1</cell><cell cols="2">Labelme: 846 Caltech: 86 Sun: 652</cell><cell>Pascal: 489</cell></row><row><cell>2</cell><cell>Pascal: 100</cell><cell cols="2">Caltech: 83 Labelme: 62 Sun: 725</cell></row><row><cell>3</cell><cell>Pascal: 94</cell><cell>Caltech: 47 Sun: 21</cell><cell>Labelme: 29</cell></row><row><cell>4</cell><cell cols="2">Labelme: 866 Pascal: 866 Sun: 866</cell><cell>Caltech: 609</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ian Goodfellow, Moritz Hardt, and Been Kim. Sanity checks for saliency maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julius</forename><surname>Adebayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Muelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9505" to="9515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Invariant risk minimization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyojin</forename><surname>Bahng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seong Joon</forename><surname>Oh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.02806</idno>
		<title level="m">Learning de-biased representations with biased representations</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Towards domain generalization using metaregularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Metareg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="998" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A meta-transfer objective for learning to disentangle causal mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tristan</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasim</forename><surname>Rahaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosemary</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olexa</forename><surname>Bilaniuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Pal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.10912</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arka</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Watters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lerchner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03599</idno>
		<title level="m">Understanding disentangling in beta-vae</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fabio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio D&amp;apos;</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Uncorrelated lasso</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sibao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Q</forename><surname>Chris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep domain generalization with structured low-rank constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="304" to="313" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Domain generalization via model-agnostic learning of semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Coelho De Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="6450" to="6461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Domain generalization with domain-specific aggregation modules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Antonio D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="187" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploring the landscape of spatial robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<idno>PMLR, 2019. 1</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="1802" to="1811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dimensionality reduction for supervised learning with reproducing kernel hilbert spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="73" to="99" />
			<date type="published" when="2004-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Kernel measures of conditional dependence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="489" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1180" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Measuring statistical dependence with hilbertschmidt norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on algorithmic learning theory</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A kernel statistical test of independence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Choon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Teo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">J</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="585" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards non-iid image classification: A dataset and baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheyan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">107383</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.12261</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to decompose and disentangle representations for video prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Ting</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De-An</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><forename type="middle">F</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Niebles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Domain generalization via multidomain discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoubo</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laiwan</forename><surname>Chan</surname></persName>
		</author>
		<idno>PMLR, 2020. 2</idno>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="page" from="292" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unsupervised representation disentanglement using cross domain features and adversarial learning in variational autoencoder based voice conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Chin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Te</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Chou</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Huai</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Tsao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Min</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Emerging Topics in Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Self-challenging improves cross-domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02454</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Feature alignment and restoration for domain generalization and adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuiling</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibo</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.12009</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Undoing the damage of dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="158" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Out-of-distribution generalization via risk extrapolation (rex)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joern-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Binas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinghuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Le Priol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00688</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Stable prediction across unknown environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Athey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research Papers</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stable prediction with model misspecification and agnostic distribution shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoxuan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Athey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Building machines that learn and think like people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brenden M Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tomer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and brain sciences</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.03463</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Episodic training for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Overcoming classifier imbalance for long-tail object detection with balanced group softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jintao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Discovering causal signals in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6979" to="6987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Best sources forward: domain generalization through source-specific nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1353" to="1357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Robust place categorization with deep domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2093" to="2100" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Deep learning: A critical appraisal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Marcus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.00631</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Domain generalization using a mixture of multiple latent domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihiko</forename><surname>Matsuura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5715" to="5725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krikamol</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multi-view domain generalization for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4193" to="4201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Efficient domain generalization via common-specific low-rank decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praneeth</forename><surname>Netrapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
		<idno>PMLR, 2020. 2</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="7728" to="7738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">On variational bounds of mutual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tucker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.06922</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning to learn single domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengchun</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Random features for largescale kernel machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1177" to="1184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning to compose domain-specific transformations for data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeshan</forename><surname>Ehrenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Dunnmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3236" to="3246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Do imagenet classifiers generalize to imagenet?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<idno>PMLR, 2019. 1</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="5389" to="5400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Learning to optimize domain specific normalization for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seonguk</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yumin</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongwoo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.04275</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Generalizing across domains via cross-gradient training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.10745</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">On image classification: Correlation v.s. causality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Stable learning via sample reweighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheyan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Kuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5692" to="5699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Smilkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><surname>Vi?gas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Wattenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03825</idno>
		<title level="m">Smoothgrad: removing noise by adding noise</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Approximate kernel-based conditional independence tests for fast non-parametric causal discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Strobl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Visweswaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Causal Inference</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">One pixel attack for fooling deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><forename type="middle">Vasconcellos</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kouichi</forename><surname>Sakurai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="828" to="841" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Test-time training for out-ofdistribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Independently interpretable lasso: A new regularizer for sparse regression with uncorrelated variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaaki</forename><surname>Takada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taiji</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hironori</forename><surname>Fujisawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="454" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Random selection of factors preserves the correlation structure in a linear factor model to a high degree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jani</forename><surname>Antti J Tanskanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kari</forename><surname>Lukkarinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vatanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plos one</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">206551</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Unbiased look at dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 2011 IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1521" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongseok</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5334" to="5344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zexue</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zachary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.06256</idno>
		<title level="m">Learning robust representations by projecting superficial statistics out</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Select-additive learning: Improving generalization in multimodal sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaksha</forename><surname>Meghawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="949" to="954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Learning from extrinsic and intrinsic supervisions for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lequan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caizi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.09316</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Deep generative model for robust imbalance classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilin</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liping</forename><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Deep domain-adversarial image generation for domain generalisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="13025" to="13032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Learning to generate novel domains for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="561" to="578" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
