<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning What Not to Segment: A New Perspective on Few-Shot Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunbo</forename><surname>Lang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gong</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binfei</forename><surname>Tu</surname></persName>
							<email>binfeitu@mail.nwpu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Han</surname></persName>
							<email>jhan@nwpu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning What Not to Segment: A New Perspective on Few-Shot Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently few-shot segmentation (FSS) has been extensively developed. Most previous works strive to achieve generalization through the meta-learning framework derived from classification tasks; however, the trained models are biased towards the seen classes instead of being ideally class-agnostic, thus hindering the recognition of new concepts. This paper proposes a fresh and straightforward insight to alleviate the problem. Specifically, we apply an additional branch (base learner) to the conventional FSS model (meta learner) to explicitly identify the targets of base classes, i.e., the regions that do not need to be segmented. Then, the coarse results output by these two learners in parallel are adaptively integrated to yield precise segmentation prediction. Considering the sensitivity of meta learner, we further introduce an adjustment factor to estimate the scene differences between the input image pairs for facilitating the model ensemble forecasting. The substantial performance gains on PASCAL-5 i and COCO-20 i verify the effectiveness, and surprisingly, our versatile scheme sets a new state-of-the-art even with two plain learners. Moreover, in light of the unique nature of the proposed approach, we also extend it to a more realistic but challenging setting, i.e., generalized FSS, where the pixels of both base and novel classes are required to be determined. The source code is available at github.com/chunbolang/BAM.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Benefiting from the well-established large-scale datasets <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b28">29]</ref>, a wealth of convolutional neural network (CNN) based computer vision techniques have undergone rapid development over the past few years <ref type="bibr">[15-17, 27, 28, 35, 43-45, 48]</ref>. However, collecting sufficient labeled data is notoriously time-consuming and labor-intensive, especially for dense prediction tasks, such as instance segmentation <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b58">59]</ref> and semantic segmentation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b44">45]</ref>. In striking contrast with the machine learning paradigms, * Gong Cheng is the corresponding author. <ref type="figure">Figure 1</ref>. Comparison of our BAM and previous work. (a) Conventional approaches typically employ meta-learning frameworks to train the FSS models, which is inevitably biased towards base classes rather than being ideally class-agnostic, thus hindering the recognition of target objects for novel class (e.g., cat ( ? )). (b)</p><p>Our BAM introduces an additional branch, namely base learner, to explicitly predict the regions of base classes. In this way, the distractor objects (e.g., person ( ? ) and sofa ( ? )) in the query image can be suppressed significantly after the ensemble module. (c) Extension of our BAM under the generalized FSS settings, where the pixels of both base and novel classes are required to be determined. The refined results are again merged with the output of the base learner to generate comprehensive predictions. humans can easily recognize new concepts or patterns from a handful of examples, which greatly stimulates the research interest of the community <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b52">53]</ref>. Thus, few-shot learning (FSL) is proposed to address this problem by building a network that can be generalized to unseen domains with scarce annotated samples available <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b56">57]</ref>.</p><p>In this paper, we undertake the application of FSL in the field of semantic segmentation, termed as few-shot segmentation (FSS), where the model leverages only very few labeled training data to segment the targets of a specific semantic category from the raw image <ref type="bibr" target="#b45">[46]</ref>. Fueled by the success of few-shot classification, most existing FSS approaches strive to achieve generalization through metalearning frameworks <ref type="bibr">[23, 30-34, 36-38, 47, 55, 56, 58, 61, 62, 64-67]</ref>. A series of learning tasks (episodes) are sampled from the base dataset to mimic the few-shot scenarios of novel classes, i.e., match training and testing conditions. However, it is woefully inadequate and underpowered. Meta-training on the base dataset with abundant annotated samples inevitably introduces a bias towards the seen classes rather than being ideally class-agnostic, thus hindering the recognition of new concepts <ref type="bibr" target="#b9">[10]</ref>. Notably, when countering hard query samples that share similar categories with base data, the generalization performance might be on the verge of collapse. We argue that aside from designing more powerful feature extraction modules <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b60">61]</ref>, adjusting the use of base datasets containing sufficient training samples is also an alternative method to alleviate the above-mentioned bias problem, which has been neglected in previous works. To this end, we introduce an additional branch (base learner) to the conventional FSS model (meta learner) to explicitly predict the targets of base classes (see <ref type="figure">Fig. 1</ref>). Then, the coarse results output by these two learners in parallel are adaptively integrated to generate accurate predictions. The central insight behind such an operation is to identify confusable regions in the query image through a high-capacity segmentation model trained within the traditional paradigm, further facilitating the recognition of novel objects. Incidentally, the proposed scheme is named BAM as it consists of two unique learners, i.e., base and the meta.</p><p>Moreover, we notice that meta learners are typically sensitive to the quality of support images, and the large variances between the input image pairs could lead to severe performance degradation. On the contrary, base learners tend to provide highly reliable segmentation results and stable performance due to the single query image as input. Based on this observation, we further propose to leverage the evaluation results of the scene differences between query-support image pairs to adjust the coarse predictions derived from meta learners. Inspired by the style loss that is extensively adopted in the domain of image style transfer <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b19">20]</ref>, we first calculate the difference of the Gram matrices of the two input images and then utilize the Frobenius norm to obtain the overall indicator for guiding the adjustment process. As illustrated in <ref type="figure">Fig. 1(b)</ref>, the distractor objects of base classes (e.g., person and sofa) in the query image are suppressed significantly after the ensemble module, achieving accurate localization of novel objects (e.g., cat). Furthermore, in light of the unique character of the proposed approach, we also extend the current task to a more realistic but challenging setting (i.e., generalized FSS), where the pixels of both base and novel classes are required to be determined, as presented in <ref type="figure">Fig. 1(c)</ref>. To sum up, our primary contributions can be concluded as follows:</p><p>? We propose a simple but efficient scheme to address the bias problem by introducing an additional branch to explicitly predict the regions of base classes in the query images, which sheds light on future works.</p><p>? We propose to estimate the scene differences between the query-support image pairs through the Gram matrix for mitigating the adverse effects caused by the sensitivity of meta learner.</p><p>? Our versatile scheme sets new state-of-the-arts on FSS benchmarks across all settings, even with two plain learners.</p><p>? We extend the proposed approach to a more challenging setting, i.e., generalized FSS, which simultaneously identifies the targets of base and novel classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Semantic Segmentation. Semantic segmentation is a fundamental computer vision task that aims to recognize each pixel of the given images according to a set of predefined semantic categories <ref type="bibr" target="#b44">[45]</ref>. Recently, tremendous progress has been made in this field benefited from the advantages of fully convolutional networks (FCNs) <ref type="bibr" target="#b34">[35]</ref>. Various robust network designs have been proposed successively, also bringing with them some fundamental techniques, such as dilated convolution <ref type="bibr" target="#b62">[63]</ref>, encoder-decoder structure <ref type="bibr" target="#b44">[45]</ref>, multi-level feature aggregation <ref type="bibr" target="#b25">[26]</ref>, attention mechanism <ref type="bibr" target="#b17">[18]</ref>, etc. However, conventional segmentation models require sufficient annotated samples to produce satisfactory results and hardly generalize to unseen categories without fine-tuning, thereby hindering to some extent their practical applications. In this work, atrous spatial pyramid pooling (ASPP) module <ref type="bibr" target="#b3">[4]</ref> based on dilated convolution is introduced into the meta learner to enlarge the receptive filed, and PSPNet <ref type="bibr" target="#b67">[68]</ref> is served as the base learner to predict the distractor objects of base categories.</p><p>Few-Shot Learning. The computer vision community has made ongoing efforts over the years to render a network with the ability to generalize to novel categories. Most current methods in the few-shot learning (FSL) domain follow the meta-learning framework proposed in <ref type="bibr" target="#b53">[54]</ref>, where a set of learning tasks (episodes) are sampled from the base dataset to mimic the few-shot scenarios. On this basis, FSL approaches can be further subdivided into three branches: (i) metric-based <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50]</ref>, (ii) optimizationbased <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b41">42]</ref>, and (iii) augmentation-based <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Our work is closely related to the metric-based approach that determines the affinity between the support prototypes <ref type="bibr" target="#b48">[49]</ref> and query features with a specific distance measure, such as Euclidean distance and cosine distance. Inspired by the generalized setting in FSL <ref type="bibr" target="#b21">[22]</ref>, we attempt to help recognize new targets by predicting the regions of base classes in the query images, and the segmentation task in a low-data regime is also extended to this setting.</p><p>Few-Shot Segmentation. Few-shot segmentation (FSS) is a natural application of the FSL technique for dense prediction tasks, and it has received increased attention in recent years. Previous approaches typically employ a twobranch structure, i.e., support branch and query branch, to transfer annotation information and interact between extracted features. Shaban et al. <ref type="bibr" target="#b45">[46]</ref> proposed the pioneering work in this field, termed OSLSM, in which the support (conditional) branch is utilized to generate the classifier weights for query branch prediction. Later on, Zhang et al. <ref type="bibr" target="#b66">[67]</ref> exploited the masked average pooling operation to obtain representative support features, which also served as the fundamental technology for subsequent works. More recently, some relevant research abandoned the training process of heavy backbone networks in favor of building powerful blocks on the fixed ones to boost performance, such as CANet <ref type="bibr" target="#b65">[66]</ref>, PFENet <ref type="bibr" target="#b50">[51]</ref>, ASGNet <ref type="bibr" target="#b22">[23]</ref>, SAGNN <ref type="bibr" target="#b59">[60]</ref>, and MM-Net <ref type="bibr" target="#b57">[58]</ref>.</p><p>However, the generalization performance of these methods heavily depends on the meta-learning framework, which could be fragile even with the fine-tuning process. More specifically, the trained FSS models are biased towards base classes due to the unbalanced data distribution and large domain shift. We observe that very few works in this field explicitly study the generalization degradation problem but focus on designing high-capacity interaction modules between the two branches. Tian et al. <ref type="bibr" target="#b50">[51]</ref> leverages the high-level features extracted from the fixed backbone network to evaluate the similarity, providing important segmentation cues for the query images. Such a parameterfree approach could help the network learn to capture more generic patterns, thereby improving generalization. Instead, this paper concentrates on a more fundamental perspective to address the bias problem by explicitly identifying the confusable regions of base classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem Definition</head><p>Few-shot segmentation aims at performing segmentation with only a few labeled data. Current approaches typically train models within the meta-learning paradigm, also known as episodic training. Specifically, given two image sets D train and D test that are disjoint in terms of object categories, the models are expected to learn transferable knowledge on D train with sufficient annotated samples and thus exhibit good generalization on D test with scarce annotated examples. In particular, both sets are composed of numerous episodes, each of which contains a small support set</p><formula xml:id="formula_0">S = {(x s i , m s i )} K i=1</formula><p>and a query set Q = {(x q , m q )}, where x * and m * represent a raw image and its correspond-ing binary mask for a specific category c, respectively. The models are optimized during each training episode to make predictions for the query image x q under the condition of the support set S. Once the training is complete, we will evaluate their few-shot segmentation performance on D test across all the test episodes, without further optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Proposed Method</head><p>To alleviate the bias problem of current FSS methods, we propose to build an additional network to explicitly predict the regions of base classes in the query images, thereby facilitating the segmentation of novel objects. Without loss of generality, we present the overall architecture of our model under the 1-shot setting (see <ref type="figure">Fig. 2</ref>). The proposed BAM consists of three major components including two complementary learners (i.e., base learner and meta learner) and an ensemble module. The two learners with a shared backbone are used to recognize the base and novel classes, respectively. Then, the ensemble module receives their coarse predictions and an adjustment factor ? to suppress the falsely activated regions of base classes, further producing accurate segmentation. Moreover, we also propose to learn the fusion weights of different support images under the K-shot setting based on ?, aiming to provide better guidance for the query branch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Base Learner</head><p>As mentioned in Sec. 2, current FSS models are biased towards the seen classes, which impedes the recognition of novel concepts. Based on this observation, we propose to introduce an additional branch, i.e., the base learner, to explicitly predict the regions of base classes in the query images. Specifically, given a query image x q ? R 3?H?W , we first apply the encoder network E and convolutional block to extract its intermediate feature maps f q b , which can be formulated as:</p><formula xml:id="formula_1">f q b = F conv (E (x q )) ? R c?h?w ,<label>(1)</label></formula><p>where F conv denotes the sequential convolution operations * . c, h, w are the channel dimension, height, and width, respectively, and h?w indicates the minimum resolution among all extracted feature maps. Then, the decoder network D b progressively enlarges the spatial scale of intermediate feature maps f q b , and finally yields the prediction results, which can be defined as:</p><formula xml:id="formula_2">p b = softmax (D b (f q b )) ? R (1+N b )?H?W ,<label>(2)</label></formula><p>where softmax(?) operation is conducted along the channel dimension to generate probability maps p b . N b represents the number of base categories ? . <ref type="figure">Figure 2</ref>. Overall architecture of the proposed BAM, which is composed of three essential components: a base learner, a meta learner, and an ensemble module. In each training episode, the two learners extract the features of input image pairs (x s , x q ) with a shared encoder and make predictions for the specific base category c (note that c denotes the novel category in the meta-testing phase) and the remaining base categories, respectively. Then, the coarse predictions are fed to the ensemble module along with an adjustment factor ? to suppress the falsely activated regions of base categories, further producing accurate segmentation results. For ease of understanding, we present the probability maps in the form of segmentation masks, but they are actually two-dimensional floating-point matrices, i.e., p ? [0, 1] H?W . MAP represents the masked average pooling operation <ref type="bibr" target="#b66">[67]</ref>.</p><p>Unlike the episodic learning paradigm widely adopted in few-shot scenarios, we follow the standard supervised learning paradigm to train the base learner. The cross entropy (CE) loss is leveraged to evaluate the difference between the prediction p b and the ground-truth m q b at all spatial locations, which can be denoted as:</p><formula xml:id="formula_3">L base = 1 n bs n bs i=1 CE p b;i , m q b;i ,<label>(3)</label></formula><p>where n bs is the number of training samples in each batch.</p><p>Why not train two learners jointly? A natural way to predict the regions of base classes in the query images is to follow the standard semantic segmentation network, such as PSPNet <ref type="bibr" target="#b67">[68]</ref>, DeepLab <ref type="bibr" target="#b3">[4]</ref>, etc. However, it is unrealistic to additionally build such a large network on the basis of the original few-shot model, which will introduce too many parameters and slow down the inference speed. Therefore, we attempt to design a unified framework in which two learners share the same backbone network. Nevertheless, we notice that the advanced FSS methods <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b65">66]</ref> typically freeze the backbone network during training to enhance generalization. Such an operation is inconsistent with the learning scheme of the standard segmentation model and will undoubtedly affect the performance of the base learner. More importantly, it is unknown whether the base learner can be trained well with the episodic learning paradigm, so a twostage training strategy is eventually adopted. In Sec. 5.3, we will discuss the effects of different training methods and network designs on segmentation accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Meta Learner</head><p>Given a support set S = {x s , m s } and a query image x q , the goal of the meta learner is to segment the objects in x q that share the same category as the annotation mask m s under the guidance of S. In our work, we first follow <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b65">66]</ref> to concatenate the features derived from block2 and block3. Then, a 1?1 convolution is applied to reduce the channel dimension and generate intermediate feature maps:</p><formula xml:id="formula_4">f s m = F 1?1 (E (x s )) ? R c?h?w ,<label>(4)</label></formula><formula xml:id="formula_5">f q m = F 1?1 (E (x q )) ? R c?h?w ,<label>(5)</label></formula><p>where E is the encoder network shared with both base and meta learners, and F 1?1 denotes the 1?1 convolution that encodes the input features to 256 dimensions. Furthermore, we calculate the prototype through the masked average pooling (MAP) <ref type="bibr" target="#b66">[67]</ref> w.r.t. (f s m , m s ) to provide crucial class-related cues:</p><formula xml:id="formula_6">v s = F pool (f s m I (m s )) ? R c ,<label>(6)</label></formula><p>where F pool is the average-pooling operation, represents Hadamard product, and I is a function that reshapes m s to be the same shape as f s m through interpolation and expansion techniques such that I : R H?W ? R c?h?w . Afterwards, the target regions in f q m are activated under the guidance of v s , and the final prediction results are generated through the decoder network, which can be summarized as:</p><formula xml:id="formula_7">p m = softmax (D m (F guidance (v s , f q m ))) ? R 2?H?W ,<label>(7)</label></formula><p>where D m denotes the decoder network of the meta learner. F guidance is an essential module of FSS that passes the annotation information from the support branch to the query branch to provide specific segmentation cues. It represents the "expand &amp; concatenate" operations <ref type="bibr" target="#b65">[66]</ref> in our work. Similarly, we calculate the BCE loss between p m and m q to update all parameters of the meta learner: where n e denotes the number of training episodes in each batch.</p><formula xml:id="formula_8">L meta = 1 n e ne i=1 BCE p m;i , m q i ,<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ensemble</head><p>Considering that meta learners are typically sensitive to the quality of support images, we further propose to leverage the evaluation results of the scene differences between query-support image pairs to adjust the coarse predictions derived from meta learners. Specifically, we first integrate the foreground probability maps generated by the base learner to obtain the prediction of the background region relative to the few-shot task:</p><formula xml:id="formula_9">p f b = N b i=1 p i b ,<label>(9)</label></formula><p>where the superscript of p f b stands for the foreground, and the subscript "b" stands for the base learner.</p><p>Then, we leverage the low-level features f s low , f q low ? R C1?H1?W1 extracted from the fixed backbone network to calculate the Gram matrices of support and query images, respectively (see <ref type="figure" target="#fig_0">Fig. 3</ref>). Please note that the relevant operations of these two input images are similar, and that of the support one can be summarized as:</p><formula xml:id="formula_10">A s = F reshape (f s low ) ? R C1?N ,<label>(10)</label></formula><formula xml:id="formula_11">G s =A s A T s ? R C1?C1 ,<label>(11)</label></formula><p>where N =H 1 ?W 1 and F reshape reshapes the size of the input tensor to C 1 ?N . With the calculated Gram matrices , the Frobenius norm is evaluated on their difference to obtain the overall indicator ? for guiding the adjustment process:</p><formula xml:id="formula_12">? = G s ? G q F ,<label>(12)</label></formula><p>where ? F denotes the Frobenius norm of the input matrix. After that, the coarse results of the two learners are integrated under the guidance of adjustment factor ?, further yielding the final segmentation predictions p f :</p><formula xml:id="formula_13">p 0 f = F ensemble F ? p 0 m , p f b ,<label>(13)</label></formula><formula xml:id="formula_14">p f =p 0 f ? F ? p 1 m ,<label>(14)</label></formula><p>where p m , p b denote the predictions of the meta learner and base learner respectively. The superscript "0" and "1" represent the background and foreground respectively. Both F ? and F ensemble are 1?1 convolution operations with specific initial parameters. The goal of the former is to adjust the coarse results of the meta learner, while the goal of the latter is to integrate the two learners. ? indicates the concatenation operation along channel dimension. Finally, the overall loss during the meta-training phase can be evaluated by:</p><formula xml:id="formula_15">L = L final + ?L meta ,<label>(15)</label></formula><formula xml:id="formula_16">L final = 1 n e ne i=1 BCE (p q i , m q i ),<label>(16)</label></formula><p>where ? is set to 1.0 in all experiments, and L meta is the loss function of the meta learner defined by Eq. (8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">K-Shot Setting</head><p>When the task is extended to the K-shot (K&gt;1) setting, more than one annotated (support) images are available. Current FSS methods typically average the prototypes extracted from the support branch and then utilize the averaged features to guide the subsequent segmentation process, which assumes that the contribution of each sample is the same <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b55">56]</ref>. However, such an approach might be suboptimal since the samples with significant scene differences from the query images cannot provide more-targeted guidance. Therefore, we further propose to adaptively estimate the weight of each support image based on the adjustment factor ?, where a smaller value indicates a greater contribution and vice versa.</p><p>Specifically, given the adjustment factor ? i of each support sample, we first integrate them into a unified vector ? t ? R K through the concatenation operation. Then, two fully connected (FC) layers are applied to generate the fusion weights ? of the support images:</p><formula xml:id="formula_17">? = soft max w T 2 ReLU w T 1 ? t ? R K ,<label>(17)</label></formula><p>where w 1 ? R K? K r , w 2 ? R K r ?K are the weights of the FC layers, and r represents the dimensionality reduction factor. At last, we make a weighted summation to achieve the final ? for ensemble.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Extension to Generalized FSS</head><p>The proposed BAM is originally designed for standard FSS tasks, but it could be easily extended to generalized settings, where the regions of base and novel classes in the query images are required to be determined. In this work, we simply fuse the results of the base learner and the final results after ensemble according to a predefined threshold ? to obtain the holistic segmentation predictionsm g , which can be formulated as:  where (x, y) denotes the spatial location.m b represents the base segmentation masks, which can be calculated by:</p><formula xml:id="formula_18">m (x,y) g = ? ? ? ? ? 1 p 1;(x,y) f &gt; ? m (x,y) b p 1;(x,y) f ? ? andm (x,y) b = 0 0 otherwise ,<label>(18)</label></formula><formula xml:id="formula_19">m b = arg max (p b ) ? {0, 1, ..., N b } H?W ,<label>(19)</label></formula><p>where arg max(?) is performed along the channel dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Setup</head><p>Datasets. We evaluate the performance of our approach on two widely-used FSS datasets, namely PASCAL-5 i <ref type="bibr" target="#b45">[46]</ref> and COCO-20 i <ref type="bibr" target="#b37">[38]</ref>. PASCAL-5 i is proposed by Shaban et al. and created from PASCAL VOC 2012 <ref type="bibr" target="#b8">[9]</ref> with additional annotations from SDS <ref type="bibr" target="#b13">[14]</ref>, while COCO-20 i is presented in <ref type="bibr" target="#b37">[38]</ref> and built from MSCOCO <ref type="bibr" target="#b28">[29]</ref>. The object categories of both datasets are evenly divided into four folds, and the experiments are conducted in a crossvalidation manner. For each fold, we randomly sample 1,000 pairs of support and query images for validation. Evaluation metrics. Following the previous works <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b60">61]</ref>, we adopt mean intersection-over-union (mIoU) and foreground-background IoU (FB-IoU) as the evaluation metrics for experiments. Implementation details. The training process of the proposed approach can be divided into two stages, i.e., pretraining and meta-training. For the first stage, we adopt the standard supervised learning paradigm to train the base learner on each fold of the FSS dataset, which consists of 16/61 classes (including background) for PASCAL-5 i /COCO-20 i . PSPNet <ref type="bibr" target="#b67">[68]</ref> is served as the base learner in our work, and it is trained on PASCAL-5 i for 100 epochs and COCO-20 i for 20 epochs. SGD optimizer with initial learning rate 2.5e-3 is used for updating the parameters, and the training batch size is set to 12. For the second stage, we jointly train the meta learner and ensemble module in an episodic learning fashion, and the parameters of the base learner are fixed in this stage. Note that two learners share the same encoder to extract the features of input images, which is also not optimized to facilitate generalization. The rest of the network layers are trained with SGD optimizer on PASCAL-5 i for 200 epochs and COCO-20 i for 50 epochs. The batch size and learning rate are set to 8 and 5e-2 respectively on both datasets. We follow the data augmentation techniques in <ref type="bibr" target="#b50">[51]</ref> for training. A variant of PFENet <ref type="bibr" target="#b50">[51]</ref> is served as the meta learner in our work, where the FEM is replaced by ASPP <ref type="bibr" target="#b3">[4]</ref> to reduce complexity. We average the results of 5 trails with different random seeds. The proposed model is implemented in PyTorch and runs on NVIDIA RTX 2080Ti GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparison with State-of-the-Arts</head><p>Quantitative results. <ref type="table">Tables 1 and 2</ref>    benchmarks. It can be found that our BAM outperforms the advanced FSS models with a considerable margin and sets new state-of-the-arts under all settings. With VGG16 backbone, the proposed method achieves 4.71%p (1-shot) and 4.66%p (5-shot) of mIoU improvements over previous best results on PASCAL-5 i . As for COCO-20 i , our 1-shot and 5-shot results respectively surpass the best competitor, i.e., HSNet, by 7.03%p and 4.26%p mIoU with ResNet50 backbone, demonstrating its remarkable capability of handling complex tasks. Moreover, we also make comparisons of our model with other advanced approaches in terms of FB-IoU on PASCAL-5 i (see <ref type="table">Tab.</ref> 3). Once again, the proposed BAM achieves substantial improvements, especially for the 1-shot results with ResNet50 backbone.</p><p>Qualitative results. To better analyze and understand the proposed model, we further take several episodes during the meta-testing phase and visualize the corresponding segmentation results, as shown in <ref type="figure" target="#fig_2">Fig. 4</ref>. It can be found in our results (4 th row), the falsely activated targets of base classes are significantly suppressed compared to the baseline method (3 rd row), which verify the effectiveness of the base learner and ensemble module.    <ref type="table">Table 6</ref>. Ablation studies on support annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Ablation Study</head><p>We conduct a series of ablation studies to investigate the impact of each component on segmentation performance. Note that the experiments in this section are performed on PASCAL-5 i dataset using VGG16 backbone unless specified otherwise. Ablation study on two learners. As mentioned in Sec. 4.1, the two learners could be trained jointly or separately. In our experiments, the latter scheme exhibits better performance, as shown in the first two rows of Tab. 4. We attribute this phenomenon to different utilization of the backbone by the two learners. Specifically, one tends to fix the parameters to enhance generalization, while the other tends to update the parameters to extract more discriminative features, which is challenging to balance in the end-to-end training paradigm. Moreover, we notice that the performance of the model without L meta becomes slightly worse, indicat-  <ref type="table">Table 7</ref>. Quantitative results on PASCAL-5 i under generalized FSS setting. "E" denotes the ensemble module. ing the necessity of constraining the prediction results of meta learner.</p><p>Ablation study on ensemble module. The initial weights of the model have a significant influence on the training process and even the final result. Thus, we conduct relevant ablation studies on this aspect of the ensemble module, which can be regarded as a crucial component of BAM. In our experiments, the ensemble module with initial weights 1 and 0 for meta learner and base learner respectively is markedly superior to other schemes, achieving 2.73% mIoU improvements over the module with randomly initialized weights, as presented in the 3 rd and 4 th rows of Tab. 4. Furthermore, we also investigate the effect of the adjustment factor ? on performance, the results of which indicates that adjusting the coarse predictions of the meta learner according to ? plays an essential role in model ensemble forecasting. <ref type="figure" target="#fig_3">Figure 5</ref> presents the comparison results between the methods using different low-level features to estimate ?, where the case with B 2 features shows a better trade-off between segmentation accuracy and computational complexity.</p><p>Ablation study on K-shot fusion schemes. As described in Sec. 4.4, we propose to adaptively adjust the fusion weight of each support sample according to the value of ?. Compared with other solutions, the proposed scheme achieves a sizeable gain (see Tab. 5) under 5-shot setting, further demonstrating the significance of such a factor that mea-sures the differences between images for FSS task.</p><p>Ablation study on support annotations. To evaluate the performance of BAM in complex scenarios, we perform experiments with different support annotations. Specifically, in addition to the standard dense mask annotation, bounding box annotation is also introduced for comparison. As can be noticed in Tab. 6, the model with bounding box annotations produces competitive results compared to the model with costly pixel-wise annotations, indicating strong robustness of the proposed scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Generalized Few-Shot Segmentation</head><p>In light of the unique nature of the proposed approach, we extend it to a more realistic but challenging setting, i.e., generalized FSS. We simply merge the final output with the output of the base learner according to a predefined threshold ? to generate the overall segmentation results without any learnable parameters (Eq. <ref type="formula" target="#formula_1">(18)</ref>). Inspired by the work related to few-shot classification and detection <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">22]</ref>, we also define three metrics to evaluate the performance under generalized setting: mIoU n , mIoU b , and mIoU a , denoting the mIoU scores of the novel classes, base classes, and all classes, respectively. As shown in Tab. 7, with the ensemble module, the performance of the segmentation model is enhanced across the board, not just for novel classes. Moreover, the qualitative results in <ref type="figure" target="#fig_4">Fig. 6</ref> also illustrate its satisfactory capability of handling generalized FSS tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We proposed a novel scheme to alleviate the bias problem of FSS models towards the seen concepts. The core idea of our scheme is to leverage the base learner to identify the confusable (base) regions in the query images and further refine the prediction of the meta learner. Surprisingly, even with two plain learners, our scheme also sets new state-of-the-arts on FSS benchmarks. Moreover, we extended the current task to a more challenging generalized setting and produced strong baseline results. We hope that our work could shed light on future research to address the bias or semantic confusion problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>The calculation process of the adjustment factor ? for the low-level features f s low and f q low .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>present the mIoU results of different approaches on PASCAL-5 i and COCO-20 i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Qualitative results of the proposed BAM and baseline approach under 1-shot setting. The left panel is from PASCAL-5 i , and the right one is from COCO-20 i . Each row from top to bottom represents the support images with ground-truth (GT) masks (blue), query images with GT masks (green), baseline results (red), and our results (red), respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Ablation studies on the low-level features f low with ResNet50 backbone. Bi denotes the feature maps extracted from the i-th convolutional blocks of backbone network. FLOPs means floating point operations per second.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Segmentation results of the proposed approach under generalized FSS setting. Note that white in the query mask represents the novel category, while the other colors represent the base categories. Best viewed in color and zoom in, especially the bicycle in the 2 nd row.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Performance comparison on PASCAL-5 i in terms of mIoU. "Baseline" means the meta learner that shares the encoder network E pre-trained by the base learner. Results in bold denote the best performance, while the underlined ones indicate the second best. Performance comparison on COCO-20 i in terms of mIoU. "Baseline" means the meta learner with pre-trained E in our work.</figDesc><table><row><cell></cell><cell cols="2">Backbone</cell><cell></cell><cell></cell><cell>Method</cell><cell cols="6">1-shot Fold-0 Fold-1 Fold-2 Fold-3</cell><cell cols="2">Mean</cell><cell cols="2">5-shot Fold-0 Fold-1 Fold-2 Fold-3</cell><cell>Mean</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">SG-One (TCYB'19) [67]</cell><cell>40.20</cell><cell>58.40</cell><cell cols="2">48.40</cell><cell cols="2">38.40</cell><cell cols="2">46.30</cell><cell>41.90</cell><cell>58.60</cell><cell>48.60</cell><cell>39.40</cell><cell>47.10</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">PANet (ICCV'19) [56]</cell><cell>42.30</cell><cell>58.00</cell><cell cols="2">51.10</cell><cell cols="2">41.20</cell><cell cols="2">48.10</cell><cell>51.80</cell><cell>64.60</cell><cell>59.80</cell><cell>46.50</cell><cell>55.70</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">FWB (ICCV'19) [56]</cell><cell>47.00</cell><cell>59.60</cell><cell cols="2">52.60</cell><cell cols="2">48.30</cell><cell cols="2">51.90</cell><cell>50.90</cell><cell>62.90</cell><cell>56.50</cell><cell>50.10</cell><cell>55.10</cell></row><row><cell></cell><cell>VGG16</cell><cell></cell><cell cols="3">CRNet (CVPR'20) [33] PFENet (TPAMI'20) [51]</cell><cell>-56.90</cell><cell>-68.20</cell><cell cols="2">-54.40</cell><cell cols="2">-52.40</cell><cell cols="2">55.20 58.00</cell><cell>-59.00</cell><cell>-69.10</cell><cell>-54.80</cell><cell>-52.90</cell><cell>58.50 59.00</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">HSNet (ICCV'21) [37]</cell><cell>59.60</cell><cell>65.70</cell><cell cols="2">59.60</cell><cell cols="2">54.00</cell><cell cols="2">59.70</cell><cell>64.90</cell><cell>69.00</cell><cell>64.10</cell><cell>58.60</cell><cell>64.10</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Baseline</cell><cell>59.90</cell><cell>67.51</cell><cell cols="2">64.93</cell><cell cols="2">55.72</cell><cell cols="2">62.02</cell><cell>64.02</cell><cell>71.51</cell><cell>69.39</cell><cell>63.55</cell><cell>67.12</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BAM (ours)</cell><cell>63.18</cell><cell>70.77</cell><cell cols="2">66.14</cell><cell cols="2">57.53</cell><cell cols="2">64.41</cell><cell>67.36</cell><cell>73.05</cell><cell>70.61</cell><cell>64.00</cell><cell>68.76</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">CANet (ICCV'19) [66]</cell><cell>52.50</cell><cell>65.90</cell><cell cols="2">51.30</cell><cell cols="2">51.90</cell><cell cols="2">55.40</cell><cell>55.50</cell><cell>67.80</cell><cell>51.90</cell><cell>53.20</cell><cell>57.10</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">PGNet (ICCV'19) [65]</cell><cell>56.00</cell><cell>66.90</cell><cell cols="2">50.60</cell><cell cols="2">50.40</cell><cell cols="2">56.00</cell><cell>57.70</cell><cell>68.70</cell><cell>52.90</cell><cell>54.60</cell><cell>58.50</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">CRNet (CVPR'20) [33]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell></cell><cell cols="2">55.70</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>58.80</cell></row><row><cell></cell><cell cols="2">ResNet50</cell><cell cols="3">PPNet (ECCV'20) [34] PFENet (TPAMI'20) [51]</cell><cell>48.58 61.70</cell><cell>60.58 69.50</cell><cell cols="2">55.71 55.40</cell><cell cols="2">46.47 56.30</cell><cell cols="2">52.84 60.80</cell><cell>58.85 63.10</cell><cell>68.28 70.70</cell><cell>66.77 55.80</cell><cell>57.98 57.90</cell><cell>62.97 61.90</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">HSNet (ICCV'21) [37]</cell><cell>64.30</cell><cell>70.70</cell><cell cols="2">60.30</cell><cell cols="2">60.50</cell><cell cols="2">64.00</cell><cell>70.30</cell><cell>73.20</cell><cell>67.40</cell><cell>67.10</cell><cell>69.50</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Baseline</cell><cell>65.68</cell><cell>71.41</cell><cell cols="2">65.56</cell><cell cols="2">58.93</cell><cell cols="2">65.40</cell><cell>67.28</cell><cell>72.38</cell><cell>69.16</cell><cell>66.25</cell><cell>68.77</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BAM (ours)</cell><cell>68.97</cell><cell>73.59</cell><cell cols="2">67.55</cell><cell cols="2">61.13</cell><cell cols="2">67.81</cell><cell>70.59</cell><cell>75.05</cell><cell>70.79</cell><cell>67.20</cell><cell>70.91</cell></row><row><cell cols="2">Backbone Method FWB [38]</cell><cell cols="13">1-shot Fold-0 Fold-1 Fold-2 Fold-3 Mean Fold-0 Fold-1 Fold-2 Fold-3 Mean 5-shot 18.35 16.72 19.59 25.43 20.02 20.94 19.24 21.94 28.39 22.63</cell><cell>Backbone</cell><cell>Method</cell><cell>FB-IoU (%) 1-shot 5-shot</cell></row><row><cell></cell><cell>PFENet [51]</cell><cell></cell><cell>35.40</cell><cell>38.10</cell><cell>36.80</cell><cell cols="3">34.70 36.30 38.20</cell><cell cols="2">42.50</cell><cell cols="2">41.80</cell><cell cols="2">38.90 40.40</cell><cell>OSLSM [46]</cell><cell>61.30</cell><cell>61.50</cell></row><row><cell>VGG16</cell><cell>PRNet [32] Baseline</cell><cell></cell><cell>27.46 38.42</cell><cell>32.99 43.75</cell><cell>26.70 44.32</cell><cell cols="3">28.98 29.03 31.18 39.84 41.58 45.93</cell><cell cols="2">36.54 48.88</cell><cell cols="2">31.54 47.87</cell><cell cols="2">32.00 32.82 46.96 47.41</cell><cell>VGG16</cell><cell>co-FCN [41] PFENet [51] HSNet [37]</cell><cell>60.10 72.00 73.40</cell><cell>60.20 72.30 76.60</cell></row><row><cell></cell><cell>BAM (ours)</cell><cell></cell><cell>38.96</cell><cell>47.04</cell><cell>46.41</cell><cell cols="3">41.57 43.50 47.02</cell><cell cols="2">52.62</cell><cell cols="2">48.59</cell><cell cols="2">49.11 49.34</cell><cell>BAM (ours)</cell><cell>77.26</cell><cell>81.10</cell></row><row><cell></cell><cell>HFA [31]</cell><cell></cell><cell>28.65</cell><cell>36.02</cell><cell>30.16</cell><cell cols="3">33.28 32.03 32.69</cell><cell cols="2">42.12</cell><cell cols="2">30.35</cell><cell cols="2">36.19 35.34</cell><cell>PGNet [65] PPNet [34]</cell><cell>69.90 69.19</cell><cell>70.50 75.76</cell></row><row><cell></cell><cell>ASGNet [23]</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>34.56</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell></cell><cell>-</cell><cell>42.48</cell><cell>ResNet50</cell><cell>PFENet [51]</cell><cell>73.30</cell><cell>73.90</cell></row><row><cell>ResNet50</cell><cell>HSNet [37] Baseline</cell><cell></cell><cell>36.30 41.92</cell><cell>43.10 45.35</cell><cell>38.70 43.86</cell><cell cols="3">38.70 39.20 43.30 41.24 43.09 46.98</cell><cell cols="2">51.30 51.87</cell><cell cols="2">48.20 49.49</cell><cell cols="2">45.00 46.90 47.81 49.04</cell><cell>HSNet [37] BAM (ours)</cell><cell>76.70 79.71</cell><cell>80.60 82.18</cell></row><row><cell></cell><cell>BAM (ours)</cell><cell></cell><cell>43.41</cell><cell>50.59</cell><cell>47.49</cell><cell cols="3">43.42 46.23 49.26</cell><cell cols="2">54.20</cell><cell cols="2">51.63</cell><cell cols="2">49.55 51.16</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Averaged FB-IoU over 4 folds on PASCAL-5 i .</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Ablation studies of different design choices under the 1shot setting. "PT" denotes the pre-training for base learner. "Init." represents the specific initial weights of the ensemble module.</figDesc><table><row><cell>Method</cell><cell>mIoU (%)</cell><cell>?</cell></row><row><cell>1-shot baseline</cell><cell>64.41</cell><cell>0</cell></row><row><cell>Mask-OR [46]</cell><cell>65.15</cell><cell>0.74</cell></row><row><cell>Mask-Avg [66]</cell><cell>65.92</cell><cell>1.51</cell></row><row><cell>Feature-Avg [41]</cell><cell>66.83</cell><cell>2.42</cell></row><row><cell>Reweighting (ours)</cell><cell>68.76</cell><cell>4.35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Ablation studies on the 5shot fusion scheme.</figDesc><table><row><cell>Annotation</cell><cell>mIoU (%) 1-shot 5-shot</cell></row><row><cell cols="2">Pixel-wise labels 64.41 68.76</cell></row><row><cell>Bounding boxes</cell><cell>62.25 66.17</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">* Taking ResNet<ref type="bibr" target="#b15">[16]</ref> feature extractor as an example, Fconv is the last convolutional block, namely block4. ? Typically, N b = 15 for PASCAL-5 i<ref type="bibr" target="#b45">[46]</ref> and 60 for COCO-20 i<ref type="bibr" target="#b37">[38]</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">? Taking the third convolutional block B 2 of ResNet50<ref type="bibr" target="#b15">[16]</ref> backbone as an example, the FLOPs is 3.78G with f low ? R 512?60?60 .</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported in part by the National Natural Science Foundation of China under Grants 62136007 and U20B2068, and in part by the Shaanxi Science Foundation for Distinguished Young Scholars under Grant 2021JC-16.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material for Learning What Not to Segment: A New Perspective on Few-Shot Segmentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Calculation of FLOPs</head><p>Floating point operations per second (FLOPs) is utilized to evaluate the computational complexity of our model in the ablation study (refer to Sec. 5.3). Here we introduce the specific calculation process. Given the low-level features f s low , f q low ? R C?H?W , we first compute the corresponding Gram matrices G s , G q . Second, we perform subtraction G s ?G q to evaluate the difference. Finally, we calculate the Frobenius norm of the difference to get an overall indicator ?. The number of FLOPs can be defined as:</p><p>where N = H ? W , and the three terms in the first row correspond to the three processes above ? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation Details</head><p>As mentioned in Sec. 4.5, we simply fuse the predictions of the base learner and the final predictions after ensemble according to a predefined threshold ? =0.9 to obtain the holistic segmentation resultsm g , as presented in Eq. <ref type="bibr" target="#b17">(18)</ref>. There is actually another alternative extension scheme, which can be defined as: The differences between two schemes are as follows: the former is mainly based on the final predictions, leveraging the base learner to determine the base pixels in the background region; the latter, by contrast, is primarily based on the predictions of the base learner, using the final predictions to determine the novel pixels in the background region. In our experiments, BAM achieves similar results using both schemes, with the former slightly better; however, the baseline approach (w/o ensemble module) can only produce tolerable results when the latter scheme is adopted, which further verifies the importance of the ensemble module to correct the coarse predictions of meta learners.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bolya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanyi</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Jae</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.06218</idno>
		<title level="m">Yolact++: Better real-time instance segmentation</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Yolact: Real-time instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bolya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanyi</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Jae</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9157" to="9166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image block augmentation for one-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zitian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Gang</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3379" to="3386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image deformation meta-networks for one-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zitian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8680" to="8689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Task-wise attention guided part complementary learning for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruimin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunbo</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science China Information Sciences</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generalized few-shot object detection without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibo</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="4527" to="4536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">S</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bethge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.06576</idno>
		<title level="m">A neural algorithm of artistic style</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Image style transfer using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">S</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2414" to="2423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semantic contours from inverse detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Arbel?ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="991" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Piotr Doll?r, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ccnet: Criss-cross attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="603" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Task agnostic meta-learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamal</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11719" to="11727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural style transfer: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongcheng</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yezhou</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zunlei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwen</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingli</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3365" to="3385" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Centermask: Realtime anchor-free instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngwan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongyoul</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="13906" to="13915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Few-shot learning with global class representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoxue</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiange</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="9715" to="9724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adaptive prototype learning and allocation for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Sevilla-Lara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joongkyu</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="8334" to="8343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Finding task-relevant features for few-shot learning by category traversal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scribblesup: Scribble-supervised convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3159" to="3167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Refinenet: Multi-path refinement networks for highresolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1925" to="1934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Anti-aliasing semantic reconstruction for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9747" to="9756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Harmonic feature activation for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Prototype refinement network for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinlu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongqiang</forename><surname>Qin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.03579</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Crnet: Cross-reference networks for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weide</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Songyang Zhang, and Xuming He. Part-aware prototype network for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Simpler is better: Few-shot semantic segmentation with classifier weight transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihe</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8741" to="8750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Hypercorrelation squeeze for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhong</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahyun</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.01538</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Feature weighting and boosting for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khoi</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinisa</forename><surname>Todorovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Large kernel matters-improve semantic segmentation by global convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiming</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4353" to="4361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Conditional networks for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Rakelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alyosha</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santosh</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Unet: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Irfan Essa, and Byron Boots. One-shot learning for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirreza</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shray</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.03410</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Amp: Adaptive masked proxies for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mennatullah</forename><surname>Siam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Boris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jagersand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5249" to="5258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.05175</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Prior guided feature enrichment network for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis &amp; Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joaquin</forename><surname>Vanschoren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.03548</idno>
		<title level="m">Meta-learning: A survey</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A perspective view and survey of meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Vilalta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youssef</forename><surname>Drissi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence review</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="77" to="95" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Matching networks for one shot learning. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Few-shot semantic segmentation with democratic attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haochen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianbin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiantong</forename><surname>Zhen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="730" to="746" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XIII 16</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Panet: Few-shot image semantic segmentation with prototype alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Hao Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtian</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daquan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning to learn: Model regression networks for easy small sample learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="616" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Learning meta-class memory for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxi</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Polarmask: Single shot instance segmentation with polar representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoge</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuebo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12193" to="12202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Scaleaware graph neural network for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Guo-Sen Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Prototype mixture models for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Mining latent classes for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.15402</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07122</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Self-guided and cross-guided learning for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8312" to="8321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Pyramid graph networks with connection attentions for region-based one-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiushuang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Canet: Class-agnostic segmentation networks with iterative refinement and attentive few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="5217" to="5226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Sg-one: Similarity guidance network for one-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.09091</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
