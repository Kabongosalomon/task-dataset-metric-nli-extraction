<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SimpleTrack: Understanding and Rethinking 3D Multi-object Tracking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Pang</surname></persName>
							<email>ziqip2@illinois.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uiuc</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tusimple</surname></persName>
						</author>
						<title level="a" type="main">SimpleTrack: Understanding and Rethinking 3D Multi-object Tracking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>3D multi-object tracking (MOT) has witnessed numerous novel benchmarks and approaches in recent years, especially those under the "tracking-by-detection" paradigm.</p><p>Despite their progress and usefulness, an in-depth analysis of their strengths and weaknesses is not yet available. In this paper, we summarize current 3D MOT methods into a unified framework by decomposing them into four constituent parts: pre-processing of detection, association, motion model, and life cycle management. We then ascribe the failure cases of existing algorithms to each component and investigate them in detail. Based on the analyses, we propose corresponding improvements which lead to a strong yet simple baseline: SimpleTrack. Comprehensive experimental results on Waymo Open Dataset and nuScenes demonstrate that our final method could achieve new stateof-the-art results with minor modifications.</p><p>Furthermore, we take additional steps and rethink whether current benchmarks authentically reflect the ability of algorithms for real-world challenges. We delve into the details of existing benchmarks and find some intriguing facts. Finally, we analyze the distribution and causes of remaining failures in SimpleTrack and propose future directions for 3D MOT. Our code is available at https: //github.com/TuSimple/SimpleTrack.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Multi-object tracking (MOT) is a composite task in computer vision, combining both the aspects of localization and identification. Given its complex nature, MOT systems generally involve numerous interconnected parts, such as the selection of detections, the data association, the modeling of object motions, etc. Each of these modules has its special treatment and can significantly affect the system performance as a whole. Therefore, we would like to ask which components in 3D MOT play the most important roles, and how can we improve them? * This work is complete during the first author's internship at TuSimple.</p><p>Bearing such objectives, we revisit the current 3D MOT algorithms <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref>. These methods mostly adopt the "tracking by detection" paradigm, where they directly take the bounding boxes from 3D detectors and build up tracklets across frames. We first break them down into four individual modules and examine each of them: preprocessing of input detections, motion model, association, and life cycle management. Based on this modular framework, we locate and ascribe the failure cases of 3D MOT to the corresponding components and discover several overlooked issues in the previous designs.</p><p>First, we find that inaccurate input detections may contaminate the association. However, purely pruning them by a score threshold will sacrifice the recall. Second, we find that the similarity metric defined between two 3D bounding boxes need to be carefully designed. Neither distancebased nor simple IoU works well. Third, the object motion in 3D space is more predictable than that in the 2D image space. Therefore, the consensus between motion model predictions and even poor observations (low score detections) could well indicate the existence of objects. Illuminated by these observations, we propose several simple yet non-trivial solutions. The evaluation on Waymo Open Dataset <ref type="bibr" target="#b33">[34]</ref> and nuScenes <ref type="bibr" target="#b7">[8]</ref> suggests that our final method "SimpleTrack" is competitive among the 3D MOT algorithms (in Tab. <ref type="bibr" target="#b5">6</ref> and Tab. <ref type="bibr" target="#b6">7)</ref>.</p><p>Besides analyzing 3D MOT algorithms, we also reflect on current benchmarks. We emphasize the need for high-frequency detections and the proper handling of output tracklets in evaluation. To better understand the upper bound of our method, we further break down the remaining errors based on ID switch and MOTA metrics. We believe these observations could inspire the better design of algorithms and benchmarks.</p><p>In brief, our contributions are as follow:</p><p>? We decompose the pipeline of "tracking-by-detection" 3D MOT framework and analyze the connections between each component and failure cases.</p><p>? We propose corresponding treatments for each module and combine them into a simple baseline.  nuScenes.</p><p>? We also analyze existing 3D MOT benchmarks and explain the potential influences of their designs. We hope that our analyses could shed light for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Most 3D MOT methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref> adopt the "tracking-by-detection" framework because of the strong power of detectors. We first summarize the representative 3D MOT work and then highlight the connections and distinctions between 3D and 2D MOT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">3D MOT</head><p>Many 3D MOT methods are composed of hand-crafted rule-based components. AB3DMOT <ref type="bibr" target="#b36">[37]</ref> is the common baseline of using IoU for association and a Kalman filter as the motion model. Its notable followers mainly improve on the association part: Chiu et al. <ref type="bibr" target="#b9">[10]</ref> and CenterPoint <ref type="bibr" target="#b42">[43]</ref> replace IoU with Mahalanobis and L2 distance, which performs better on nuScenes <ref type="bibr" target="#b7">[8]</ref>. Some others notice the importance of life cycle management, where CBMOT <ref type="bibr" target="#b2">[3]</ref> proposes a score-based method to replace the "count-based" mechanism, and P?schmann et al. <ref type="bibr" target="#b27">[28]</ref> treats 3D MOT as optimization problems on factor graphs. Despite the effectiveness of these improvements, a systematic study on 3D MOT methods is in great need, especially where these designs suffer and how to make further improvements. To this end, our paper seeks to meet the expectations.</p><p>Different from the methods mentioned above, many others attempt to solve 3D MOT with fewer manual designs. <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b37">38]</ref> leverage rich features from RGB images for association and life cycle control, and Chiu et al. <ref type="bibr" target="#b8">[9]</ref> specially uses neural networks to handle the feature fusion, association metrics, and tracklet initialization. Recently, OGR3MOT <ref type="bibr" target="#b43">[44]</ref> follows Guillem et al. <ref type="bibr" target="#b6">[7]</ref> and solves 3D MOT with graph neural networks (GNN) in an end-to-end manner, focusing on the data association and the classification of active tracklets, especially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">2D MOT</head><p>2D MOT shares the common goal of data association with 3D MOT. Some notable attempts include probabilistic approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32]</ref>, dynamic programming <ref type="bibr" target="#b10">[11]</ref>, bipartite matching <ref type="bibr" target="#b5">[6]</ref>, min-cost flow <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b45">46]</ref>, convex optimization <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b44">45]</ref>, and conditional random fields <ref type="bibr" target="#b41">[42]</ref>. With the rapid progress of deep learning, many methods <ref type="bibr">[7, 12-14, 19, 40]</ref> learn the matching mechanisms and others <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26]</ref> learn the association metrics.</p><p>Similar to 3D MOT, many 2D trackers <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b47">48]</ref> also benefit from the enhanced detection quality and adopt the "tracking-by-detection" paradigm. However, the objects on RGB images have varied sizes because of scale variation; thus, they are harder for association and motion models. But 2D MOT can easily take advantage of rich RGB information and use appearance models <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39]</ref>, which is not available in LiDAR based 3D MOT. In summary, the design of MOT methods should fit the traits of each modality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">3D MOT Pipeline</head><p>In this section, we decompose 3D MOT methods into the following four parts. An illustration is in <ref type="figure" target="#fig_0">Fig. 1</ref> .</p><p>Pre-processing of Input Detections. It pre-processes the bounding boxes from detectors and selects the ones to be used for tracking. Some exemplar operations include selecting the bounding boxes with scores higher than a certain threshold. (In "Pre-processing" <ref type="figure" target="#fig_0">Fig. 1</ref>, some redundant bounding boxes are removed.)</p><p>Motion Model. It predicts and updates the states of objects. Most 3D MOT methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b36">37]</ref> directly use the Kalman filter, and CenterPoint <ref type="bibr" target="#b42">[43]</ref> uses the velocities predicted by detectors from multi-frame data. (In "Prediction" and "Motion Model Update" <ref type="figure" target="#fig_0">Fig. 1.)</ref> Association. It associates the detections with tracklets. The association module involves two steps: similarity computation and matching. The similarity measures the distance between a pair of detection and tracklet, while the matching step solves the correspondences based on the precomputed similarities. AB3DMOT <ref type="bibr" target="#b36">[37]</ref> proposes the baseline of using IoU with Hungarian algorithm, while Chiu et al. <ref type="bibr" target="#b9">[10]</ref> uses Mahalanobis distance and greedy algorithm, and CenterPoint <ref type="bibr" target="#b42">[43]</ref> adopts the L2 distance. (In "Association" <ref type="figure" target="#fig_0">Fig. 1</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.)</head><p>Life Cycle Management. It controls the "birth", "death" and "output" policies. "Birth" determines whether a detection bounding box will be initialized as a new tracklet; "Death" removes a tracklet when it is believed to have moved out of the attention area; "Output" decides whether a tracklet will output its state. Most of the MOT algorithm adopts a simple count-based rule <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43]</ref>, and CB-MOT <ref type="bibr" target="#b2">[3]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Analyzing and Improving 3D MOT</head><p>In this section, we analyze and improve each module in the 3D MOT pipeline. For better clarification, we ablate the effects of every modification by removing it from the final variant of SimpleTrack. By default, the ablations are all on the validation split with the CenterPoint <ref type="bibr" target="#b42">[43]</ref> detection. We also provide additive ablation analyses and the comparison with other methods in Sec. 4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Pre-processing</head><p>To fulfill the recall requirements, current detectors usually output a large number of bounding boxes with scores roughly indicating their quality. However, if these boxes are treated equally in the association step of 3D MOT, the bounding boxes with low quality or severe overlapping may deviate the trackers to select the inaccurate detection for extending or forming tracklets (as in the "raw detection" of <ref type="figure">Fig. 2</ref>). Such a gap between the detection and MOT task needs careful treatment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scene Layout</head><p>Raw Detection Score Filter NMS Ground Truth (Black) Detection Bounding Boxes (Light Blue) Detection Scores (Dark Blue) <ref type="figure">Figure 2</ref>. Comparison between score filtering and NMS. To remove the redundant bounding boxes on row 2, score filtering needs at least a 0.24 threshold, but this will eliminate the detections on row 1. However, NMS can well satisfy both by removing the overlapping on row 2 and maintaining the recall on row 1. 3D MOT methods commonly use confidence scores to filter out the low-quality detections and improve the precision of input bounding boxes for MOT. However, such an approach may be detrimental to the recall as they directly abandon the objects with poor observations (top row in <ref type="figure">Fig. 2</ref>). It is also especially harmful to metrics like AMOTA, which needs the tracker to use low score bounding boxes to fulfill the recall requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NMS AMOTA? AMOTP? MOTA? IDS</head><p>To improve the precision without significantly decreasing the recall, our solution is simple and direct: we apply stricter non-maximum suppression (NMS) to the input detections. As shown in the right of <ref type="figure">Fig. 2</ref>, the NMS operation alone can effectively eliminate the overlapped low-quality bounding boxes while keeping the diverse low-quality observations, even on regions like sparse points or occlusion. Therefore, by adding NMS to the pre-processing module, we could roughly keep the recall, but greatly improves the precision and benefits MOT.</p><p>On WOD, our stricter NMS operation removes 51% and 52% bounding boxes for vehicles and pedestrians and nearly doubles the precision: 10.8% to 21.1% for vehicles, 5.1% to 9.9% for pedestrians. At the same time, the recall drops relatively little from 78% to 74% for vehicles and 83% to 79% for pedestrians. According to Tab. <ref type="bibr" target="#b0">1</ref>  the pedestrian (right part of Tab. 2), where the object detection task is harder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Motion Model</head><p>Motion models depict the motion status of tracklets. They are mainly used to predict the candidate states of objects in the next frame, which are the proposals for the following association step. Furthermore, the motion models like the Kalman filter can also potentially refine the states of objects. In general, there are two commonly adopted motion models for 3D MOT: Kalman filter (KF), e.g. AB3DMOT <ref type="bibr" target="#b36">[37]</ref>, and constant velocity model (CV) with predicted speeds from detectors, e.g. CenterPoint <ref type="bibr" target="#b42">[43]</ref>. The advantage of KF is that it could utilize the information from multiple frames and provide smoother results when facing low-quality detection. Meanwhile, CV deals better with abrupt and unpredictable motions with its explicit speed predictions, but its effectiveness on motion smoothing is limited. In Tab. 3 and Tab. 4, we compare the two of them on WOD and nuScenes, which provides clear evidence for our claims.</p><p>In general, these two motion models demonstrate similar performance. On nuScenes, CV marginally outperforms KF, while it is the opposite on WOD. The advantages of KF on WOD mainly come from the refinement for the bounding boxes. To verify this, we implement the "KF-PD" variant, which uses KF only for providing motion predictions prior to association, and the outputs are all original detections. Eventually, the marginal gap between "CV" and "KF-PD" in Tab. 3 supports our claim. On nuScenes, the CV motion model is slightly better due to the lower frame rates on nuScenes (2Hz). To prove our conjecture, we apply KF and CV both under a higher frequency 10Hz setting on nuScenes 1 , and KF marginally outperforms CV by 0.696 versus 0.693 in AMOTA this time.</p><p>To summarize, the Kalman Filter fits better for high-  frequency cases because of more predictable motions, and the constant velocity model is more robust for low-frequency scenarios with explicit speed prediction. Since inferring the speed is not yet common for detectors, we adopt the Kalman filter for SimpleTrack without loss of generality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Association</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Association Metrics: 3D GIoU</head><p>IoU based <ref type="bibr" target="#b36">[37]</ref> and distance based <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b42">43]</ref> association metrics are the two prevalent choices in 3D MOT. As in <ref type="figure" target="#fig_2">Fig. 3</ref>, they have typical but different failure modes. IoU computes the overlapping ratios between bounding boxes, so it cannot connect the detections and motion predictions if the IoU between them are all zeros, which are common at the beginnings of tracklets or on objects with abrupt motions (the left of <ref type="figure" target="#fig_2">Fig. 3</ref>). The representatives for distance-based metrics are Mahalanobis <ref type="bibr" target="#b9">[10]</ref> and L2 <ref type="bibr" target="#b42">[43]</ref> distances. With larger distance thresholds, they can handle the failure cases of IoU based metrics, but they may not be sensitive enough for nearby detection with low quality. We explain such scenarios on the right of <ref type="figure" target="#fig_2">Fig. 3</ref>. On frame k, the blue motion prediction has smaller L2 distances to the green false positive detection, thus it is wrongly associated. Illuminating by such example, we conclude that the distance-based metrics lack discrimination on orientations, which is just the advantage of IOU based metrics.</p><p>To get the best of two worlds, we propose to generalize "Generalized IoU" (GIoU) <ref type="bibr" target="#b30">[31]</ref> to 3D for association. Briefly speaking, for any pair of 3D bounding boxes B 1 , B 2 , their 3D GIoU is as Eq. 1, where I, U are the intersection and union of B 1 and B 2 . C is the enclosing convex hull of U . V represents the volume of a polygon. We set GIoU &gt; ?0.5 as the threshold for every category of objects  </p><formula xml:id="formula_0">V U = V B1 + V B2 ? V I , GIoU(B 1 , B 2 ) = V I /V U ? (V C ? V U )/V C .<label>(1)</label></formula><p>As in <ref type="figure" target="#fig_2">Fig 3,</ref> the GIoU metric can handle both patterns of failures. The quantitative results in <ref type="figure" target="#fig_4">Fig. 4</ref> also show the ability of GIoU for improving the association on both WOD and nuScenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Matching Strategies</head><p>Generally speaking, there are two approaches for the matching between detections and tracklets: 1) Formulating the problem as a bipartite matching problem, and then solving it using Hungarian algorithm <ref type="bibr" target="#b36">[37]</ref>. 2) Iteratively associating the nearest pairs by greedy algorithm <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b42">43]</ref>.</p><p>We find that these two methods heavily couples with the association metrics: IoU based metrics are fine with both, while distance-based metrics prefer greedy algorithms. We hypothesize that the reason is that the range of distancebased metrics are large, thus methods optimizing global optimal solution, like the Hungarian algorithm, may be adversely affected by outliers. In <ref type="figure" target="#fig_5">Fig. 5</ref>, we experiment with all the combinations between matching strategies and association metrics on WOD. As demonstrated, IoU and GIoU function well for both strategies, while Mahalanobis and L2 distance demand greedy algorithm, which is also consistent with the conclusions from previous work <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Life Cycle Management</head><p>We analyze all the ID-Switches on WOD 2 , and categorize them into two groups as in <ref type="figure">Fig. 6</ref>: wrong association and early termination. Different from the major focus of many work, which is association, we find that the early termination is actually the dominating cause of ID-Switches: <ref type="bibr" target="#b1">2</ref> We use py-motmetrics <ref type="bibr" target="#b22">[23]</ref> for the analysis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scenario</head><p>Demonstration Description</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wrong Association</head><p>The tracker switches from GT1 to GT 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Early Termination</head><p>Tracker A dies early, GT switches to tracker B.  <ref type="figure">Figure 6</ref>. Illustration for two major types of ID-Switches. 95% for vehicle and 91% for pedestrian. Among the early terminations, many of them are caused by point cloud sparsity and spatial occlusion. To alleviate this issue, we utilize the free yet effective information: consensus between motion models and detections with low scores. These bounding boxes are usually of low localization quality, however they are strong indication of the existence of objects if they agree with the motion predictions. Then we use these to extend the lives of tracklets.</p><p>Bearing such motivation, we propose "Two-stage Association." Specifically, we apply two rounds of association with different score thresholds: a low one T l and a high one T h (e.g. 0.1 and 0.5 for pedestrian on WOD). In stage one, we use the identical procedure as most current algorithms <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43]</ref>: only the bounding boxes with scores higher than T h are used for association. In stage two, we focus on the tracklets unmatched to detections in stage one  <ref type="figure">Figure 7</ref>. Comparison for "One-stage" and "Two-stage" association with a hypothetical example. "Extend" means "extending the life cycles," and "Predict" means "using motion predictions due to no association." Suppose T h = 0.5 and T l = 0.1 are the score thresholds, the "one-stage" method early terminates the tracklet because of consecutively lacking associations.  <ref type="table">Table 5</ref>. Ablation for "Two-stage Association" on WOD. "One" and "Two" denotes the previous one-stage association and our two-stage association methods. Details in Sec. <ref type="bibr">4.4.</ref> and relax the conditions on their matches: detections having scores larger than T l will be sufficient for a match. If the tracklet is successfully associated with one bounding box in stage two, it will still keep being alive. However, as the low score detections are generally in poor quality, we don't output them to avoid false positives, and they are also not used for updating motion models. Instead, we use motion predictions as the latest tracklet states, replacing the low quality detections.</p><p>We intuitively explain the differences between our "Twostage Association" and traditional "One-stage Association" in <ref type="figure">Fig. 7</ref>. Suppose T = 0.5 is the original score threshold for filtering detection bounding boxes, the trackers will then neglect the boxes with scores 0.4 and 0.2 on frames 3 and 4, which will die because of lacking matches in continuous frames and this eventually causes the final ID-Switch. In comparison, our two-stage association can maintain the active state of the tracklet.</p><p>In Tab. 5, our approach greatly decreases the ID-Switches without hurting the MOTA. This proves that Sim-pleTrack is effective in extending the life cycles by using detections more flexibly. Parallel to our work, a similar approach is also proven to be useful for 2D MOT <ref type="bibr" target="#b46">[47]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Integration of SimpleTrack</head><p>In this section, we integrate the aforementioned techniques into the unified SimpleTrack and demonstrate how they improve the performance step by step.</p><p>In <ref type="figure" target="#fig_6">Fig. 8, we</ref>   <ref type="table">Table 6</ref>. Comparison on WOD test split (L2). CenterPoint <ref type="bibr" target="#b42">[43]</ref> detections are used. We mark the best in red and the second in blue.</p><p>We list the methods using public detection. For AB3DMOT <ref type="bibr" target="#b36">[37]</ref> and Chiu et al. <ref type="bibr" target="#b9">[10]</ref>, we report their best leaderboard entries.  <ref type="table">Table 7</ref>. Comparison on nuScenes test split. CenterPoint <ref type="bibr" target="#b42">[43]</ref> detections are used. We list the methods using public detection. We mark the best in red and the second in blue. For CBMOT <ref type="bibr" target="#b2">[3]</ref> and OGR3MOT <ref type="bibr" target="#b43">[44]</ref>, we report their numbers with CenterPoint <ref type="bibr" target="#b42">[43]</ref> detection. Our numbers using both 2Hz and 10Hz frame rate detections are reported (details of our 10Hz setting are in Sec. 5).</p><p>the properties of vehicles and pedestrian are much different, each technique is applicable to both. On nuScenes, every proposed improvement is also effective for both the AMOTA and ID-Switch. We also report the test set performance and compare with other 3D MOT methods. Combining our techniques leads to new state-of-the-art results (in Tab. 6, Tab. 7). <ref type="bibr" target="#b2">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Rethinking nuScenes</head><p>Besides the techniques mentioned above, we delve into the design of benchmarks. The benchmarks greatly facilitate the development of research and guide the designs of algorithms. Contrasting WOD and nuScenes, we have the following findings: 1) The frame rate of nuScenes is 2Hz, while WOD is 10Hz. Such low frequency adds unnecessary difficulties to 3D MOT (Sec. 5.1). 2) The evaluation of nuScenes requires high recalls with low score thresholds. And it also pre-processes the tracklets with interpolation, which encourages trackers to output the confidence scores reflecting the entire tracklet quality, but not the frame quality (Sec. 5.2). We hope these two findings could inspire the community to rethink the benchmarks and evaluation protocols of 3D tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Detection Frequencies</head><p>Tracking generally benefits from higher frame rates, because motion is more predictable in short intervals. We  compare the frequencies of point clouds, annotations, and common MOT frame rates on the two benchmarks in Tab. 8. On nuScenes, it has 20Hz point clouds but only 2Hz annotations. This leads to most common detectors and 3D MOT algorithms work under 2Hz, even they actually utilize all the 20Hz LiDAR data and operate faster than 2Hz. Therefore, we investigate the effect of high-frequency data as follows.</p><p>Although the information is more abundant with high frequency (HF) frames, it is non-trivial to incorporate them because nuScenes only evaluates on the low-frequency frames, which we refer to as "evaluation frames." In Tab. 9, simply using all the 10Hz frames does not improve the performance. This is because the low-quality detection on the HF frames may deviate the trackers and hurt the performance on the sampled evaluation frames. To overcome this issue, we explore by first applying the "One-stage Association" on HF frames, where only the bounding boxes with scores larger than T h = 0.5 are considered and used for motion model updating. We then adopt the "Two-stage Association" (described in Sec.4.4) by using the boxes with scores larger than T l = 0.1 to extend the tracklets. As in Tab. 9, our approach significantly improves both the AMOTA and ID-Switches. We also try to even increase the frame rate to 20Hz, but this barely leads to further improvements due to the deviation issue. So SimpleTrack uses the 10Hz setting in our final submission to the test set. <ref type="bibr" target="#b3">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Tracklet Interpolation</head><p>The AMOTA metric used in nuScenes calculates the average MOTAR <ref type="bibr" target="#b36">[37]</ref> at different recall thresholds, which re- <ref type="bibr" target="#b3">4</ref> Because of the submission time limits to nuScenes test set, we are only able to report the "10Hz-One" variant in Tab. 7. It will be updated to "10Hz-Two" once we had the chance.  <ref type="table">Table 9</ref>. MOT with higher frame rates on nuScenes. "10Hz" is the vanilla baseline of using all the detections on high frequency (HF) frames. "-One" denotes "One-stage," and "-Two" denotes "Two-stage." Details in Sec. <ref type="bibr" target="#b4">5</ref>  <ref type="table">Table 10</ref>. Improvement from "outputting motion model predictions" on nuScenes (2Hz setting).</p><p>quires the trackers output the boxes of all score segments. In order to further improve the recall, we output the motion model predictions for frames and tracklets without associated detection bounding boxes, and empirically assign them lower scores than any other detection. In our case, their scores are 0.01 ? S P , where S P is the confidence score of the tracklet in the previous fram. As shown in Tab. 10, this simple trick improves the overall recall and AMOTA. However, we discover that enhancing the recall is not the only reason for such improvement. Besides the bounding boxes, the scores of the motion model predictions also make a significant contribution. This starts with the evaluation protocol on nuScenes, where they interpolate the input tracklets to fill in the missing frames and change all the scores with their tracklet-average scores as illustrated in <ref type="figure" target="#fig_7">Fig. 9</ref>. Under this context, our approach can explicitly penalize the low-quality tracklets, which generally contain more missing boxes replaced by motion model predictions.</p><p>In summary, such interpolation on nuScenes encourages the trackers to treat tracklet quality holistically and output calibrated quality-aware scores. However the quality of  boxes may vary a lot across frames even for the same tracklet, thus we suggest depicting the quality of a tracklet by only one score is imperfect. Moreover, future information is also introduced in this interpolation step and it changes the tracklet results. This could also bring the concern on whether the evaluation setting is still a fully online one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Error Analyses</head><p>In this section, we conduct analyses on the remaining failure cases of SimpleTrack and propose potential future directions for improving "tracking by detection" paradigm. Without loss of generality, we use WOD as an example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Upper Bound Experiment Settings</head><p>To quantitatively evaluate the causes of failure cases, we contrast SimpleTrack with two different oracle variants. The results are summarized in Tab. 11. GT Output erases the errors caused by "output" policy. We compute the IoU between the bounding boxes from Simple-Track with the GT boxes at the "output" stage, then use the IoU to decide if a box should be output instead of the detection score. <ref type="bibr" target="#b4">5</ref> GT All is the upper bound of tracking performance with CenterPoint boxes. We greedily match the detections from CenterPoint to GT boxes, keep the true positive and assign them ground-truth ID.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Analyses for "Tracking By Detection"</head><p>ID-Switches. We break down the causes of ID-Switches as in <ref type="figure">Fig. 6</ref>. Although early termination has been greatly decreased by the scale of 86% for vehicle and 70% for pedestrian with "Two-stage Association," it still takes up 88% and 72% failure cases in the remaining ID-Switches in Simple-Track for vehicle and pedestrian, respectively. We inspect these cases and discover that most of them result from longterm occlusion or the returning of objects from being temporarily out of sight. Therefore, in addition to improving the association, potential future work can develop appearance models like in 2D MOT <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39]</ref> or silently maintain their states to re-identify these objects after they are back. FP and FN. The "GT All" in Tab. 11 shows the upper bound for MOT with CenterPoint <ref type="bibr" target="#b42">[43]</ref> detection, and we analyze the class of vehicle for example. Even with "GT All" the false negatives are still 0.215, which are the detection FN and can hardly be fixed under the "tracking by detection" framework. Comparing "GT All" and SimpleTrack, we find that the tracking algorithm itself introduces 0.119 false negatives. We further break them down as follows. Specifically, the difference between "GT Output" and "GT ALL" indicates that the 0.043 false negatives are caused by the uninitialized tracklets resulting from NMS and score threshold in pre-processing. The others come from life-cycle management. The "Initialization" requires two frames of accumulation before outputting a tracklet, which is same as AB3DMOT <ref type="bibr" target="#b36">[37]</ref>. This yields a marginal 0.005 false negatives. Our "Output" logic uses detection score to decide output or not, taking up the false negatives number 0.076. Based on these analyses, we can conclude that the gap is mainly caused by the inconsistency between the scores and detection quality. By using historical information, 3D MOT can potentially provide better scores compared to single frame detectors, and this has already drawn some recent attention <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b43">44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions and Future Work</head><p>In this paper, we decouple the "tracking by detection" 3D MOT algorithms into several components and analyze their typical failures. With such insights, we propose corresponding enhancements of using NMS, GIoU, and Two-stage Association, which lead to our SimpleTrack. In addition, we also rethink the frame rates and interpolation pre-processing in nuScenes. We eventually point out several possible future directions for "tracking by detection" 3D MOT.</p><p>However, beyond the "tracking by detection" paradigm, there are also branches of great potential. For better bounding box qualities, 3D MOT can refine them using long term information <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b40">41]</ref>, which are proven to outperform the detections based only on local frames. The future work can also transfer the current manual rule-based methods into learning-based counterparts, e.g. using learning based intraframe mechanisms to replace the NMS, using inter-frame reasoning to replace the 3D GIoU and life cycle management, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Life Cycle Management. The life cycle management</head><p>is the same as AB3DMOT <ref type="bibr" target="#b36">[37]</ref>, 3 hits to start outputting a tracker and consecutive 2 misses terminates a tracklet. We set the threshold for outputting detection bounding boxes as 0.7 for vehicle and cyclist, and 0.5 for pedestrian. In our "Two-stage association," we adopt the low score threshold as 0.  <ref type="table">Table A</ref>. Results on WOD validation split (L2). We mark the best in red and the second in blue. For fair comparison, we list the methods using the public CenterPoint <ref type="bibr" target="#b42">[43]</ref> detection, * means the numbers from our own implementations.  <ref type="table">Table B</ref>. Results on nuScenes validation set. We mark the best in red and the second in blue. For fair comparison, we list the methods using public CenterPoint <ref type="bibr" target="#b42">[43]</ref> detection, the numbers marked with * are our own implementations, the numbers marked with <ref type="bibr" target="#b43">[44]</ref> are from OGR3MOT <ref type="bibr" target="#b43">[44]</ref>. nuScenes 1. Pre-process. We apply NMS according to IoU threshold equal to 1/10. After NMS, all the remaining detections are kept as the input to 3D MOT algorithms. 2. Association. We adopt the same settings as on Waymo Open Dataset. 3. Motion Model. The settings for our motion model is identical to that on Waymo Open Dataset. 4. Life Cycle Management. We adopt the similar strategy as the tracking algorithm in Center Point <ref type="bibr" target="#b42">[43]</ref>, where the trackers start outputting upon the first association, and are terminated after two continuous misses.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>3D MOT pipeline. For simplicity, we only visualize the steps between frame k and frame k+1. Best view in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>improves birth and death by amending the logic of tracklet confidences. (In "Life Cycle Management"Fig. 1.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Illustration of association metrics. Left: IoU versus GIoU. Right: L2 Distance versus GIoU. Details are in Sec. 4.3.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Comparison of association metrics on WOD (left &amp; middle) and nuScenes (right). "M-Dis" is the short for Mahalanobis distance. The best method is closest to the bottom-right corner, having the lowest ID-Switches and highest MOTA/AMOTA. on both WOD and nuScenes for this pair of associations to enter the subsequent matching step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Comparison of matching strategies on WOD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Improvements from SimpleTrack on WOD (left &amp; middle) and nuScenes (right). We use the common baselines of AB3DMOT<ref type="bibr" target="#b36">[37]</ref> on WOD and Chiu et al.<ref type="bibr" target="#b9">[10]</ref> on nuScenes. For nuScenes, the improvements of "10Hz-Two" (using 10Hz detection and two-stage association) is in Sec. 5.1, and "Pred" (outputting motion model predictions) is in Sec. 5.2. The names for modifications are on the x-axis. Better MOTA and ID-Switch values are higher on the y-axis for clearer visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>How the motion predictions and nuScenes interpolation changes tracklet scores. Dashed arrows are the directions for interpolation. On Frame 2 and 4 the boxes with score 0.05 are our motion predictions. The "0.5" and "0.32" are the tracklet-average scores with or without motion predictions. Details in Sec. 5.2.MethodVehicle Pedestrian MOTA? IDS(%)? FP? FN? MOTA? IDS(%)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The results are competitive on the Waymo Open Dataset and arXiv:2111.09621v1 [cs.CV] 18 Nov 2021</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Tracking on Frame k</cell><cell></cell><cell>Tracking on Frame k+1</cell></row><row><cell cols="2">Frame k Detections</cell><cell>Selected Detections</cell><cell></cell><cell></cell><cell>Frame k+1 Detections</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Association</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Pre-processing</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Motion Model</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Update</cell><cell></cell></row><row><cell cols="2">Frame k-1 Tracklets</cell><cell>Motion Predictions</cell><cell></cell><cell>Life Cycle Management</cell><cell>Frame k Tracklets</cell></row><row><cell></cell><cell>Prediction</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Tracklet (Red)</cell><cell>Motion Prediction (Blue)</cell><cell>Ground Truth (Black)</cell><cell>Detection (Green)</cell><cell>Data in Pipeline (Gray)</cell><cell>MOT Operations (Pink)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .Table 2</head><label>12</label><figDesc>Ablation for NMS on nuScenes.</figDesc><table><row><cell>?</cell></row></table><note>. Ablation for NMS on WOD.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .Table 4</head><label>34</label><figDesc>and Tab. 2, this largely benefits the performance, especially on Comparison of motion models on Waymo Open Dataset. "KF" denotes Kalman filters; "CV" denotes constant velocity model; "KF-PD" denotes the variant using Kalman filter only for motion prediction. Details in Sec. 4.2.</figDesc><table><row><cell>Method</cell><cell></cell><cell>Vehicle</cell><cell></cell><cell></cell><cell>Pedestrian</cell></row><row><cell></cell><cell cols="5">MOTA? MOTP? IDS(%)? MOTA? MOTP? IDS(%)?</cell></row><row><cell>KF</cell><cell cols="2">0.5612 0.1681</cell><cell>0.08</cell><cell cols="2">0.5776 0.3125</cell><cell>0.42</cell></row><row><cell>CV</cell><cell cols="2">0.5515 0.1691</cell><cell>0.14</cell><cell cols="2">0.5661 0.3159</cell><cell>0.58</cell></row><row><cell>KF PD</cell><cell cols="2">0.5516 0.1691</cell><cell>0.14</cell><cell cols="2">0.5654 0.3158</cell><cell>0.63</cell></row><row><cell></cell><cell cols="5">Method AMOTA? AMOTP? MOTA? IDS ?</cell></row><row><cell></cell><cell>KF</cell><cell>0.687</cell><cell>0.573</cell><cell>0.592</cell><cell>519</cell></row><row><cell></cell><cell>CV</cell><cell>0.690</cell><cell>0.564</cell><cell>0.592</cell><cell>516</cell></row></table><note>. Comparison of motion models on nuScenes. Abbrevia- tions are identical to Tab. 3. Details in Sec. 4.2.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Details in Sec. 4.4.</figDesc><table><row><cell>Method</cell><cell>Vehicle</cell><cell></cell><cell>Pedestrian</cell><cell></cell></row><row><cell></cell><cell cols="4">MOTA? MOTP? IDS(%)? MOTA? MOTP? IDS(%)?</cell></row><row><cell>One</cell><cell>0.5567 0.1682</cell><cell>0.46</cell><cell>0.5718 0.3125</cell><cell>0.96</cell></row><row><cell>Two</cell><cell>0.5612 0.1681</cell><cell>0.08</cell><cell>0.5776 0.3125</cell><cell>0.42</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>illustrate how the performance of 3D MOT trackers improve from the baselines. On WOD, although</figDesc><table><row><cell>Method</cell><cell>Vehicle</cell><cell></cell><cell>Pedestrian</cell><cell></cell></row><row><cell></cell><cell cols="4">MOTA? MOTP? IDS(%)? MOTA? MOTP? IDS(%)?</cell></row><row><cell cols="2">AB3DMOT [37] 0.5773 0.1614</cell><cell>0.26</cell><cell>0.5380 0.3163</cell><cell>0.73</cell></row><row><cell>Chiu et al. [10]</cell><cell>0.4932 0.1689</cell><cell>0.62</cell><cell>0.4438 0.3227</cell><cell>1.83</cell></row><row><cell>CenterPoint [43]</cell><cell>0.5938 0.1637</cell><cell>0.32</cell><cell>0.5664 0.3116</cell><cell>1.07</cell></row><row><cell>SimpleTrack</cell><cell>0.6030 0.1623</cell><cell>0.08</cell><cell>0.6013 0.3114</cell><cell>0.40</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 .</head><label>8</label><figDesc>Frequency comparison of benchmarks.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 .</head><label>11</label><figDesc>Oracle Experiments on WOD.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>1. [37] 0.5572 0.1679 0.40 0.5224 0.3098 2.74 Chiu et al.</figDesc><table><row><cell>Method</cell><cell>Vehicle</cell><cell></cell><cell>Pedestrian</cell><cell></cell></row><row><cell></cell><cell cols="4">MOTA? MOTP? IDS(%)? MOTA? MOTP? IDS(%)?</cell></row><row><cell>AB3DMOT  [10]</cell><cell>0.5406 0.1665</cell><cell>0.37</cell><cell>0.4810 0.3086</cell><cell>3.34</cell></row><row><cell>CenterPoint [43]</cell><cell>0.5505 0.1691</cell><cell>0.26</cell><cell>0.5493 0.3137</cell><cell>1.13</cell></row><row><cell>SimpleTrack</cell><cell>0.5612 0.1681</cell><cell>0.08</cell><cell>0.5776 0.3125</cell><cell>0.42</cell></row></table><note>**</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Validation split comparisons are in the supplementary.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The ID-Switch increases because we output more bounding boxes and IDs. The 0.003 false positives in pedestrians are caused by some boxes matching with the same GT box in crowded scenes.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment. We would like to thank Tianwei Yin for kindly helping us during our applying the CenterPoint detection to 3D multi-object tracking.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Appendix for SimpleTrack</head><p>A. <ref type="bibr" target="#b0">1</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. Validation Split Comparison</head><p>We compare our SimpleTrack with other 3D MOT methods on the validation splits as in Tab. A and Tab. B. In the experiments, our SimpleTrack also demonstrates strong performance. On both Tab. A and Tab. B, our Simple-Track can outperform the methods without learning based modules, which is consistent with the test set performance in the main paper (Tab. 6 and Tab. 7). In addition, we find it interesting in Tab. B that the learning based method OGR3MOT <ref type="bibr" target="#b43">[44]</ref> can achieve better performance than our 2Hz SimpleTrack, which demonstrate the potential of applying learning techniques for 3D MOT. However, such advantage of OGB3MOT vanishes for AMOTA on the test set, as in the Tab. 7 of the main paper. This suggests that our learning-free modifications may have the ability to adapt to the domain gaps in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Experimental Setup</head><p>Due to the space constraints, we discuss the detailed hyper-parameters and settings for our SimpleTrack here.</p><p>Waymo Open Dataset 1. Pre-process. We use CenterPoint detection <ref type="bibr" target="#b42">[43]</ref>, and then apply NMS with the IoU threshold equals to 1/4 onto the detection bounding boxes.</p><p>2. Association. We use GIoU as the association metric and Hungarian algorithm to solve the matchings. The threshold for GIoU is -0.5 across all types of objects.</p><p>3. Motion Model. We use the default Kalman filter parameters as AB3DMOT <ref type="bibr" target="#b36">[37]</ref>, and pair the usages of Hungarian algorithm.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tracking and data association</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaakov</forename><surname>Bar-Shalom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">E</forename><surname>Fortmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter G</forename><surname>Cable</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">FANTrack: 3D multi-object tracking with feature association network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erkan</forename><surname>Baser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkateshwaran</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prarthana</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Czarnecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Score refinement for confidence-based 3D multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuri</forename><surname>Benbarka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jona</forename><surname>Schr?der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Zell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiple object tracking using k-shortest paths optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Berclaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Fleuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Engin</forename><surname>Turetken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1806" to="1819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tracking without bells and whistles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Meinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taixe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Simple online and realtime tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongyuan</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lionel</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Upcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning a neural solver for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Braso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taixe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">nuScenes: A multimodal dataset for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Bankiti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">H</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourabh</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venice</forename><forename type="middle">Erin</forename><surname>Liong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anush</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giancarlo</forename><surname>Baldan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Beijbom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Probabilistic 3D multi-modal, multi-object tracking for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hsu-Kuang Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rares</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeannette</forename><surname>Ambrus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bohg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICRA</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Probabilistic 3D multi-object tracking for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hsu-Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Prioletti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeannette</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bohg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.05673</idno>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multicamera people tracking with a probabilistic occupancy map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Fleuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Berclaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Lengagne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="267" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learnable graph matching: Incorporating graph partitioning with deep feature learning for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Lifted disjoint paths with application in multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Hornakova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Swoboda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Graph neural ased end-to-end data association framework for online multiple-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiantong</forename><surname>Zhen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.05315</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Ea-gerMOT: 3D multi-object tracking via sensor fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljosa</forename><surname>Osep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<idno>arxiv:2104.14682</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multiple hypothesis tracking revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chanho</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arridhana</forename><surname>Ciptadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Online multi-object tracking by quadratic pseudo-boolean optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyang</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning by tracking: Siamese CNN for robust target association</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Canton-Ferrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Graph networks for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingting</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Enhancing the association in multi-object tracking via neighbor graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.00265</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">GSM: Graph similarity model for multi-object trackin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiankun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">RetinaTrack: Online single stage joint detection and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronny</forename><surname>Votel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<ptr target="https://github.com/cheind/py-motmetrics.5" />
	</analytic>
	<monogr>
		<title level="j">Py motmetrics Contributors. py-motmetrics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Quasi-dense similarity learning for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlu</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haofeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Model-free vehicle tracking and state estimation in point cloud sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IROS</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">TPM: Multiple object tracking with tracklet-plane matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinlong</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilei</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erui</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">107480</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Globally-optimal greedy algorithms for tracking a variable number of objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Factor graph based 3D multi-object tracking in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>P?schmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Pfeifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Protzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS, 2020</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Offboard 3D object detection from point cloud sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahyar</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Najibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khoa</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyang</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anguelov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An algorithm for tracking multiple targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="843" to="854" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generalized intersection over union</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Joint probabilistic data association revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Seyed Hamid Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Tracking the untrackable: Learning to track multiple cues with long-term dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Kretzschmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xerxes</forename><surname>Dotiwalla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Chouard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijaysai</forename><surname>Patnaik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tsui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Caine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiquan</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksei</forename><surname>Timofeev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krivokon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<idno>arxiv:1912.04838</idno>
		<title level="m">Jonathon Shlens, Zhifeng Chen, and Dragomir Anguelov. Scalability in perception for autonomous driving: Waymo Open Dataset</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Subgraph decomposition for multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multi-person tracking by multicut and deep matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">3D multi-object tracking: A baseline and new evaluation metrics. IROS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinshuo</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianren</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Kitani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">GNN3DMOT: Graph neural network for 3D multiobject tracking with 2D-3D multi-feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinshuo</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunze</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Kitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Simple online and realtime tracking with a deep association metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolai</forename><surname>Wojke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietrich</forename><surname>Paulus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIP</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">How to train your deep multi-object tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljosa</forename><surname>Osep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Ban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Horaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier Alameda-Pineda</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Auto4D: Learning to label 4D objects from sequential point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<idno>arxiv:2101.06586</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning affinities and dependencies for multi-target tracking using a CRF model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ram</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Centerbased 3D object detection and tracking. CVPR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwei</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Learnable online graph representations for 3D multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Nico</forename><surname>Zaech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Liniger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.11747</idno>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Global multi-object tracking using generalized minimum clique graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afshin</forename><surname>Amir Roshan Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Dehghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gmcp-Tracker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Global data association for multi-object tracking using network flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakant</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.06864</idno>
		<title level="m">Byte-Track: Multi-object tracking by associating every detection box</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">FairMOT: On the fairness of detection and re-identification in multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
