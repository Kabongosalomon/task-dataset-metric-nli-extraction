<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Overcoming Catastrophic Forgetting with Hard Attention to the Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Serr?</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D?dac</forename><surname>Sur?s</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Miron</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
						</author>
						<title level="a" type="main">Overcoming Catastrophic Forgetting with Hard Attention to the Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Catastrophic forgetting occurs when a neural network loses the information learned in a previous task after training on subsequent tasks. This problem remains a hurdle for artificial intelligence systems with sequential learning capabilities. In this paper, we propose a task-based hard attention mechanism that preserves previous tasks' information without affecting the current task's learning. A hard attention mask is learned concurrently to every task, through stochastic gradient descent, and previous masks are exploited to condition such learning. We show that the proposed mechanism is effective for reducing catastrophic forgetting, cutting current rates by 45 to 80%. We also show that it is robust to different hyperparameter choices, and that it offers a number of monitoring capabilities. The approach features the possibility to control both the stability and compactness of the learned knowledge, which we believe makes it also attractive for online learning or network compression applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the renewed interest in neural networks, old problems re-emerge, specially if the solution is still open. That is the case with the so-called catastrophic forgetting or catastrophic interference problem <ref type="bibr" target="#b25">(McCloskey &amp; Cohen, 1989;</ref><ref type="bibr" target="#b31">Ratcliff, 1990)</ref>. In essence, catastrophic forgetting corresponds to the tendency of a neural network to forget what it learned upon learning from new or different information. For instance, when a network is first trained to convergence on one task, and then trained on a second task, it forgets how to perform the first task.</p><p>Overcoming catastrophic forgetting is an important step in the advancement towards more general artificial intelligence systems <ref type="bibr" target="#b21">(Legg &amp; Hutter, 2007)</ref>. Such systems should be able to seamlessly remember different tasks, and to learn them sequentially, following a lifelong learning paradigm <ref type="bibr" target="#b39">(Thrun &amp; Mitchell, 1995)</ref>. Apart from being more biologically plausible <ref type="bibr" target="#b2">(Clegg et al., 1998)</ref>, there are many practical situations which require a sequential learning system (cf. <ref type="bibr" target="#b39">Thrun &amp; Mitchell, 1995)</ref>. For instance, it may be unattainable for a robot to retrain from scratch its underlying model upon encountering a new object/task. After accumulating a large number of objects/tasks and their corresponding information, performing concurrent or multitask learning at scale may be too costly.</p><p>Storing previous information and using it to retrain the model was among the earliest attempts to overcome catastrophic forgetting; a strategy named "rehearsal" <ref type="bibr" target="#b33">(Robins, 1995)</ref>. The use of memory modules in this context has been a subject of research until today <ref type="bibr" target="#b32">(Rebuffi et al., 2017;</ref><ref type="bibr">Lopez-Paz &amp; Ranzato, 2017)</ref>. However, due to efficiency and capacity constrains, memory-free approaches were also introduced, starting with what was termed as "pseudorehearsal" <ref type="bibr" target="#b33">(Robins, 1995)</ref>. This approach has found some success in transfer learning situations where one needs to maintain a certain accuracy on the source task after learning the target task <ref type="bibr" target="#b12">(Jung et al., 2016;</ref><ref type="bibr" target="#b22">Li &amp; Hoiem, 2017)</ref>. Within the pseudo-rehearsal category, we could also consider recent approaches that substitute the memory module by a generative network <ref type="bibr" target="#b40">(Venkatesan et al., 2017;</ref><ref type="bibr">Shin et al., 2017;</ref><ref type="bibr" target="#b29">Nguyen et al., 2017)</ref>. Besides the difficulty of training a generative network for a sequence of tasks or certain types of data, both rehearsal and pseudo-rehearsal approaches imply some form of concurrent learning, that is, having to re-process 'old' instances for learning a new task.</p><p>The other popular strategy to overcome catastrophic forgetting is to reduce representational overlap <ref type="bibr" target="#b6">(French, 1991)</ref>. This can be done at the output, intermediate, and also input levels <ref type="bibr" target="#b9">(Gutsein &amp; Stump, 2015;</ref><ref type="bibr" target="#b11">He &amp; Jaeger, 2018)</ref>. A clean way of doing that in a soft manner is through so-called "structural regularization" <ref type="bibr" target="#b44">(Zenke et al., 2017)</ref>, either present in the loss function <ref type="bibr" target="#b15">(Kirkpatrick et al., 2017;</ref><ref type="bibr" target="#b44">Zenke et al., 2017)</ref> or at a separate merging step <ref type="bibr" target="#b20">(Lee et al., 2017)</ref>. With these strategies, one seeks to prevent major changes in the weights that were important for previous tasks. Dedicating specific sub-parts of the network for each task is another arXiv:1801.01423v3 <ref type="bibr">[cs.</ref>LG] 29 May 2018 way of reducing representational overlap <ref type="bibr" target="#b34">(Rusu et al., 2016;</ref><ref type="bibr" target="#b5">Fernando et al., 2017;</ref><ref type="bibr" target="#b43">Yoon et al., 2018)</ref>. The main tradeoff in representational overlap is to effectively distribute the capacity of the network across tasks while maintaining important weights and reusing previous knowledge.</p><p>In this paper, we propose a task-based hard attention mechanism that maintains the information from previous tasks without affecting the learning of a new task. Concurrently to learning a task, we also learn almost-binary attention vectors through gated task embeddings, using backpropagation and minibatch stochastic gradient descent (SGD). The attention vectors of previous tasks are used to define a mask and constrain the updates of the network's weights on current tasks. Since masks are almost binary, a portion of the weights remains static while the rest adapt to the new task. We call our approach hard attention to the task (HAT). We evaluate HAT in the context of image classification, using what we believe is a high-standard evaluation protocol: we consider random sequences of 8 publicly-available data sets representing different tasks, and compare with a dozen of recent competitive approaches. We show favorable results in 4 different experimental setups, cutting current rates by 45 to 80%. We also show robustness with respect to hyperparameters and illustrate a number of monitoring capabilities. We make our code publicly-available 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Putting Hard Attention to the Task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Motivation</head><p>The primary observation that drives the proposed approach is that the task definition or, more pragmatically, its identifier, is crucial for the operation of the network. Consider the task of discriminating between bird and dog images. When training the network to do so, it may learn some set of intermediate features. If the second task is to discriminate between brown and black animals using the same data (assuming it only contained birds and dogs that were either brown or black), the network may learn a new set of features, some of them with not much overlap with the first ones. Thus, if training data is the same in both tasks, one important difference should be the task description or identifier. Our intention is to learn to use the task identifier to condition every layer, and to later exploit this learned conditioning to prevent forgetting previous tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Architecture</head><p>To condition to the current task t, we employ a layer-wise attention mechanism <ref type="figure" target="#fig_0">(Fig. 1)</ref>. Given the output of the units 2 of 1 https://github.com/joansj/hat 2 In the remaining of the paper, we will use 'units' to refer to both linear units (or fully-connected neurons) and convolutional filters. HAT can be extended to other parametric layers. layer l, h l , we element-wise multiply h l = a t l h l . However, an important difference with common attention mechanisms is that, instead of forming a probability distribution, a t l is a gated version of a single-layer task embedding e t l , a t l = ? se t l ,</p><p>where ?(x) ? [0, 1] is a gate function and s is a positive scaling parameter. We use a sigmoid gate in our experiments, but note that other gating mechanisms could be used. All layers l = 1, . . . L ? 1 operate equally except the last one, layer L, where a t L is binary hard-coded. The operation of layer L is equivalent to a multi-head output <ref type="bibr" target="#b0">(Bakker &amp; Heskes, 2003)</ref>, which is routinely employed in the context of catastrophic forgetting (for example <ref type="bibr" target="#b34">Rusu et al., 2016;</ref><ref type="bibr" target="#b22">Li &amp; Hoiem, 2017;</ref><ref type="bibr" target="#b29">Nguyen et al., 2017)</ref>.</p><p>The idea behind the gating mechanism of Eq. 1 is to form hard, possibly binary attention masks which, act as "inhibitory synapses" <ref type="bibr" target="#b26">(McCulloch &amp; Pitts, 1943)</ref>, and can thus activate or deactivate the output of the units of every layer. In this way, and similar to PathNet <ref type="bibr" target="#b5">(Fernando et al., 2017)</ref>, we dynamically create and destroy paths across layers that can be later preserved when learning a new task. However, unlike PathNet, the paths in HAT are not based on modules, but on single units. Therefore, we do not need to pre-assign a module size nor to set a maximum number of modules per task. Given some network architecture, HAT learns and automatically dimensions individual-unit paths, which ultimately affect individual layer weights. Furthermore, instead of learning paths in a separate stage using genetic algorithms, HAT learns them together with the rest of the network, using backpropagation and SGD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Network Training</head><p>To preserve the information learned in previous tasks upon learning a new task, we condition the gradients according to the cumulative attention from all the previous tasks. To obtain a cumulative attention vector, after learning task t and obtaining a t l , we recursively compute a ?t l = max a t l , a ?t?1 l , using element-wise maximum and the all-zero vector for a ?0 l . This preserves the attention values for units that were important for previous tasks, allowing them to condition the training of future tasks.</p><p>To condition the training of task t + 1, we modify the gradient g l,ij at layer l with the reverse of the minimum of the cumulative attention in the current and previous layers:</p><formula xml:id="formula_1">g l,ij = 1 ? min a ?t l,i , a ?t l?1,j g l,ij ,<label>(2)</label></formula><p>where the unit indices i and j correspond to the output (l) and input (l ? 1) layers, respectively. In other words, we expand the vectors a ?t l and a ?t l?1 to match the dimensions of the gradient tensor of layer l, and then perform a elementwise minimum, subtraction, and multiplication ( <ref type="figure" target="#fig_0">Fig. 1</ref>). We do not compute any attention over the input data if this consists of complex signals like images or audio. However, in the case such data consisted of separate or independent features, one could also consider them as the output of some layer and apply the same methodology.</p><p>Note that, with Eq. 2, we create masks to prevent large updates to the weights that were important for previous tasks. This is similar to the approach of PackNet (Mallya &amp; Lazebnik, 2017), which was made public during the development of HAT. In PackNet, after an heuristic selection and retraining, a binary mask is found and later applied to freeze the corresponding network weights. In this regard, HAT differs from PackNet in three important aspects. Firstly, our mask is unit-based, with weight-based masks automatically derived from those. Therefore, HAT also stores and maintains a lightweight structure. Secondly, our mask is learned, instead of heuristically-or rule-driven. Therefore, HAT does not need to pre-assign compression ratios nor to determine parameter importance through a post-training step. Thirdly, our mask is not necessarily binary, allowing intermediate values between 0 and 1. This can be useful if we want to reuse weights for learning other tasks, at the expense of some forgetting, or we want to work in a more online mode, forgetting the oldest tasks to remember new ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Hard Attention Training</head><p>To obtain a totally binary attention vector a t l , one could use a unit step function as gate. However, since we want to train the embeddings e t l with backpropagation ( <ref type="figure" target="#fig_0">Fig. 1</ref>), we prefer a differentiable function. To construct a pseudo-step function that allows the gradient to flow, we use a sigmoid with a positive scaling parameter s (Eq. 1). This scaling is introduced to control the polarization, or 'hardness', of the pseudo-step function and the resulting output a t l . Our strategy is to anneal s during training, inducing a gradient flow, and set s = s max during testing, using s max 1 such that Eq. 1 approximates a unit step function. Notice that when s ? ? we get a t l,i ? {0, 1}, and that when s ? 0 we get a t l,i ? 1/2. We will use the latter to start a training epoch with all network units being equally active, and progressively polarize them within the epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>During a training epoch, we incrementally linearly anneal the value of s by</head><formula xml:id="formula_2">s = 1 s max + s max ? 1 s max b ? 1 B ? 1 ,<label>(3)</label></formula><p>where b = 1, . . . B is the batch index and B is the total number of batches in an epoch. The hyperparameter s max ? 1 controls the stability of the learned tasks or, in other words the plasticity of the network's units. If s max is close to 1, the gating mechanism operates like a regular sigmoid function, without particularly enforcing the binarization of a t l . This provides plasticity to the units, with the model being able to forget previous tasks at the backpropagation stage (Sec. 2.3). If, alternatively, s max is a larger number, the gating mechanism starts operating as a unit step function. This provides stability with regard to previously learned tasks, preventing changes in the corresponding weights at the backpropagation stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Embedding Gradient Compensation</head><p>In preliminary analysis, we empirically observed that embeddings e t l were not changing much, and that the magnitude of the gradient was weak on those weights. After some investigation, we realized that the major part of the problem was due to the introduced annealing scheme (Eq. 3). To illustrate the effect of the annealing scheme on the gradients of e t l , consider a uniformly distributed embedding e t l,i across the active range of a standard sigmoid, e t l,i ? [?6, 6]. If we do not perform any annealing and set s = 1, we obtain a cumulative gradient after one epoch that has a bell-like shape and spans the whole sigmoid range <ref type="figure" target="#fig_1">(Fig. 2)</ref>. Contrastingly, if we set s = s max , we obtain a much larger magnitude, but in a much lower range (e t l,i ? [?1, 1] in <ref type="figure" target="#fig_1">Fig. 2</ref>). The annealed version of s yields a distribution in-between, with a lower range than s = 1 and a lower magnitude than s = s max . A desirable situation would be to have a wide range, ideally spanning the range of s = 1, and a large cumulative magnitude, ideally proportional to the one in the active region when s = s max . To achieve that, we apply a gradient compensation before updating e t l . In essence, the idea of the embedding gradient compensation is to remove the effects of the annealed sigmoid and to artificially impose the desired range and magnitude motivated in the previous paragraph. To do so, we divide the gradient q l,i by the derivative of the annealed sigmoid, and multiply by the desired compensation,</p><formula xml:id="formula_3">q l,i = s max ? e t l,i 1 ? ? e t l,i s? se t l,i 1 ? ? se t l,i q l,i ,</formula><p>which, after operating, yields</p><formula xml:id="formula_4">q l,i = s max cosh se t l,i + 1 s cosh e t l,i + 1 q l,i .</formula><p>For numerical stability, we clamp |se t l,i | ? 50 and constrain e t l,i to remain within the active range of the standard sigmoid, e t l,i ? [?6, 6]. In any case, however, q l,i ? 0 when we hit those limits. That is, we are in the constant regions of the pseudo-step function. Notice also that, by Eq. 3, the minimum s is never equal to 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Promoting Low Capacity Usage</head><p>It is important to realize that the hard attention values a t l,i that are 'active', that is, a t l,i ? 1, directly determine the units that will be dedicated to task t. Therefore, in order to have some model capacity reserved for future tasks, we promote sparsity on the set of attention vectors A t = {a t 1 , . . . a t L?1 }. To do so, we add a regularization term to the loss function L that takes into account the set of cumulative attention vectors up to task t ? 1,</p><formula xml:id="formula_5">A &lt;t = {a &lt;t 1 , . . . a &lt;t L?1 }: L y,?, A t , A &lt;t = L (y,?) + cR A t , A &lt;t , (4)</formula><p>where c is the regularization constant,</p><formula xml:id="formula_6">R A t , A &lt;t = L?1 l=1 N l i=1 a t l,i 1 ? a &lt;t l,i L?1 l=1 N l i=1 1 ? a &lt;t l,i<label>(5)</label></formula><p>is the regularization term, and N l corresponds to the number of units in layer l. Notice that Eq. 5 corresponds to a weighted and normalized L1 regularization over A t . Cumulative attentions over the past tasks A &lt;t define a weight for the current task, such that if a &lt;t l,i ? 1 then a t l,i receives a weight close to 0 and vice versa. This excludes the units that were attended in previous tasks from regularization, unconstraining their reuse in the current task. The hyperparameter c ? 0 controls the capacity spent on each task (Eq. 4). In a sense, it can be thought of as a compressibility constant, affecting the compactness of the learned models: the higher the c, the lower the number of active attention values a t l,i and the more sparse the resulting network is. We set c globally for all tasks and let HAT adapt to the best compression for each individual task.</p><p>The use of L1 regularization to promote network sparsity in the context of catastrophic forgetting has also been considered by <ref type="bibr" target="#b43">Yoon et al. (2018)</ref> with dynamically expandable networks (DEN), which were introduced while developing HAT. In DEN, plain L1 regularization is combined with a considerable set of heuristics such as L2-transfer, thresholding, and a measure of "semantic drift", and is applied to all network weights in the so-called "selective retraining" phase. In HAT, we use an attention-weighted L1 regularization over attention values, which is an independent part of the single training phase of the approach. Instead of considering network weights, HAT focuses on unit attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related Work</head><p>We compare the proposed approach with the conceptually closest works, some of which appeared concurrently to the development of HAT. A more general overview of related work has been done in Sec. 1. A qualitative comparison with three of the most related strategies has been done along Sec. 2. A quantitative comparison with these and other approaches is done in Sec. 4 and Appendix C.</p><p>Both elastic weight consolidation (EWC; <ref type="bibr" target="#b15">Kirkpatrick et al., 2017)</ref> and synaptic intelligence (SI; <ref type="bibr" target="#b44">Zenke et al., 2017)</ref> approaches add a 'soft' structural regularization term to the loss function in order to discourage changes to weights that are important for previous tasks. HAT uses a 'hard' structural regularization, and does it both at the loss function and gradient magnitudes explicitly. EWC measures weights' importance after network training, while SI and HAT compute weights' importance concurrently to network training. EWC and SI use specific formulation while HAT learns attention masks. Incremental moment matching (IMM; <ref type="bibr" target="#b20">Lee et al., 2017)</ref> is an evolution of EWC, performing a separate model-merging step after learning a new task.</p><p>Progressive neural networks (PNNs; <ref type="bibr" target="#b34">Rusu et al., 2016)</ref> distribute the network weights in a column-wise fashion, pre-assigning a column width per task. They employ so-called adapters to reuse knowledge from previous columns/tasks, leading to a progressive increase of the number of weights assigned to future tasks. Instead of blindly pre-assigning column widths, HAT learns such 'widths' per layer, together with the network weights, and adapts them to the difficulty of the current task. PathNet <ref type="bibr" target="#b5">(Fernando et al., 2017</ref>) also pre-assigns some amount of network capacity per task but, in contrast to PNNs, avoids network columns and adapters. It uses an evolutionary approach to learn paths between a constant number of so-called modules (layer subsets) that interconnect between themselves. HAT does not maintain a population of solutions, entirely trains with backpropagation and SGD, and does not rely on a constant set of modules.</p><p>Together with PNNs and PathNet, PackNet (Mallya &amp; Lazebnik, 2017) also employs a binary mask to constrain the network. However, such constrain is not based on columns nor layer modules, but on network weights. Therefore, it allows for a potentially better use of the network's capacity. PackNet is based on heuristic weight pruning, with pre-assigned pruning ratios. HAT also focuses on network weights, but uses unit-based masks to constrain those, which also results in a lightweight structure. It avoids any absolute or pre-assigned pruning ratio, although it uses the compressibility parameter c to influence the compactness of the learned models. Another difference between HAT and the previous three approaches is that it does not use purely binary masks. Instead, the stability parameter s max controls the degree of binarization.</p><p>Dynamically expandable networks (DEN; <ref type="bibr" target="#b43">Yoon et al., 2018)</ref> also assign network capacity depending on the task at hand. However, they do so in a separate stage called "selective retraining". A complex mixture of heuristics and hyperparameters is used to identify "drifting" units, which are duplicated and retrained in another stage. L1 regularization and L2-transfer are employed to condition learning, together with the corresponding regularization constants and an additional set of thresholds. HAT strives for simplicity, restricting the number of hyperparameters to two that have a straightforward conceptual interpretation. Instead of plain L1 regularization over network weights, HAT employs an attention-weighted L1 regularization over attention masks. Attention masks are a lightweight structure that can be plugged in without the need of introducing important changes to a pre-existing network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Setups -Common setups to evaluate catastrophic forgetting in a classification context are based on permutations of the MNIST data <ref type="bibr">(Srivastava et al., 2013)</ref>, label splits of the MNIST data <ref type="bibr" target="#b20">(Lee et al., 2017)</ref>, incrementally learning classes of the CIFAR data sets (Lopez-Paz &amp; Ranzato, 2017), or two-task transfer learning setups where accuracy is measured on both source and target tasks <ref type="bibr" target="#b22">(Li &amp; Hoiem, 2017)</ref>. However, there are some limitations with these setups. Firstly, performing permutations of the MNIST data has been suggested to favor certain approaches, yielding misleading results 3 in the context of catastrophic forgetting <ref type="bibr" target="#b20">(Lee et al., 2017)</ref>. Secondly, using only the MNIST data may not be very representative of modern computer vision tasks, nor particularly challenging <ref type="bibr" target="#b42">(Xiao et al., 2017)</ref>. Thirdly, incrementally adding classes or groups of classes implies the assumption that all data comes from the same joint distribution, which is unrealistic for a real-world setting. Finally, evaluating catastrophic forgetting with only two tasks biases the conclusions towards transfer learning setups, and prevents the analysis of truly sequential learning with more than two tasks. In this paper, we consider the aforementioned MNIST and CIFAR setups (Sec. 4.2). Nonetheless, we primarily evaluate on a sequence of multiple tasks formed by different classification data sets (Sec. 4.1).</p><p>To obtain a generic estimate, we weigh a number of tasks and uniformly randomize their order. After training task t, we compute the accuracies on all testing sets of tasks ? ? t. We repeat 10 times this sequential train/test procedure with 10 different seed numbers, which are also used in the rest of randomizations and initializations (see below). To compare between different task accuracies, and in order to obtain a general measurement of the amount of forgetting, we introduce the forgetting ratio</p><formula xml:id="formula_7">? ? ?t = A ? ?t ? A ? R A ? ?t J ? A ? R ? 1,<label>(6)</label></formula><p>where A ? ?t is the accuracy measured on task ? after sequentially learning task t, A ? R is the accuracy of a random stratified classifier using the class information of task ? , and A ? ?t J is the accuracy measured on task ? after jointly learning t tasks in a multitask fashion. Note that ? ? ?1 and ? ? 0 correspond to performances close to the ones of the random and multitask classifiers, respectively. To report a single number after learning t tasks, we take the average</p><formula xml:id="formula_8">? ?t = 1 t t ? =1 ? ? ?t .</formula><p>Data -We consider 8 common image classification data sets and adapt them, if necessary, to an input size of 32 ? 32 ? 3 pixels. The number of classes goes from 10 to 100, training set sizes from 16,853 to 73,257, and test set sizes from 1,873 to 26,032. For each task, we ran-domly split 15% of the training set and keep it for validation purposes. The considered data sets are: CIFAR10 and CIFAR100 <ref type="bibr" target="#b16">(Krizhevsky, 2009</ref>), FaceScrub <ref type="bibr" target="#b28">(Ng &amp; Winkler, 2014)</ref>, FashionMNIST <ref type="bibr" target="#b42">(Xiao et al., 2017)</ref>, NotMNIST (Bulatov, 2011), <ref type="bibr">MNIST (LeCun et al., 1998)</ref>, SVHN <ref type="bibr" target="#b27">(Netzer et al., 2011)</ref>, and TrafficSigns <ref type="bibr" target="#b38">(Stallkamp et al., 2011)</ref>. For further details on data we refer to Appendix A.</p><p>Baselines -We consider 2 reference approaches plus 9 recent and competitive ones: standard SGD with dropout <ref type="bibr" target="#b8">(Goodfellow et al., 2014)</ref>, SGD freezing all layers except the last one (SGD-F), EWC, IMM (Mean and Mode variants), learning without forgetting (LWF; <ref type="bibr" target="#b22">Li &amp; Hoiem, 2017)</ref>, less-forgetting learning (LFL; <ref type="bibr" target="#b12">Jung et al., 2016)</ref>, PathNet, and PNNs. To find the best hyperparameter combination for each approach, we perform a grid search using a task sequence determined by a single seed. To compute the forgetting ratio ? (Eq. 6), we also run the aforementioned random and multitask classifiers.</p><p>Network -Unless stated otherwise, we employ an AlexNet-like architecture <ref type="bibr" target="#b17">(Krizhevsky et al., 2012)</ref> with 3 convolutional layers of 64, 128, and 256 filters with 4 ? 4, 3 ? 3, and 2 ? 2 kernel sizes, respectively, plus two fullyconnected layers of 2048 units each. We use rectified linear units as activations, and 2 ? 2 max-pooling after the convolutional layers. We also use a dropout of 0.2 for the first two layers and of 0.5 for the rest. A fully-connected layer with a softmax output is used as a final layer, together with categorical cross entropy loss. All layers are randomly initialized with Xavier uniform initialization <ref type="bibr" target="#b7">(Glorot &amp; Bengio, 2010</ref>) except the embedding layers, for which we use a Gaussian distribution N (0, 1). Unless stated otherwise, our code uses PyTorch's defaults for version 0.2.0 <ref type="bibr" target="#b30">(Paszke et al., 2017)</ref>. We adapt the same base architecture to all baseline approaches and match their number of parameters to 7.1 M.</p><p>Training -We train all models with backpropagation and plain SGD, using a learning rate of 0.05, and decaying it by a factor of 3 if there is no improvement in the validation loss for 5 consecutive epochs. We stop training when we reach a learning rate lower than 10 ?4 or we have iterated over 200 epochs (we made sure that all considered approaches reached a stable solution before 200 epochs). Batch size is set to 64. All methods use the same task sequence, data split, batch shuffle, and weight initialization for a given seed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Results</head><p>We first look at the average forgetting ratio ? ?t after learning task t <ref type="figure" target="#fig_2">(Fig. 3)</ref>. A first thing to note is that not all the considered baselines perform better than the SGD references. That is the case of LWF and LFL. For LWF, we observe it is still competitive in the two-task setup for which it was designed, t = 2. However, its performance rapidly degrades for t &gt; 2, indicating that the approach has difficulties in extending  <ref type="table">Table 1</ref>. Average forgetting ratio after the second (? ?2 ) and the last (? ?8 ) task for the considered approaches (10 runs, standard deviation into parenthesis). beyond a transfer learning setup. We find LFL extremely sensitive to the configuration of its hyperparameter, to the point that what is a good value for one seed, turns out to be a bad choice for another seed. Hence the poor average performance for 10 seeds. The highest standard deviations are obtained by LFL and PathNet <ref type="table">(Table 1)</ref>, which suggests a high sensitivity with respect to hyperparameters, initializations, or data sets. Another thing to note is that the IMM approaches only perform similarly or slightly better than the SGD-F reference. We believe this is due to both the different nature of the tasks' data and the consideration of more than two tasks, which complicates the choice of the mixing hyperparameter.</p><p>The best performing baselines are EWC, PathNet, and PNN. PathNet and PNN present contrasting behaviors. Both, by construction, never forget; therefore, the important difference is in their learning capability. PathNet starts by correctly learning the first task and progressively exhibits difficulties to do so for t ? 2. Contrastingly, PNNs exhibits difficulty in the first tasks and becomes better as t increases.</p><p>These contrasting behaviors are due to the way the two approaches allocate the network capacity. As mentioned, they cannot do it dynamically, and therefore need to pre-assign a number of network weights per task. When having more tasks but the same network capacity, this pre-assignment increasingly harms the performance of these baselines, lowering the corresponding curves in <ref type="figure" target="#fig_2">Fig. 3</ref>.</p><p>We now move to the HAT results. First of all, we observe that HAT consistently performs better than all considered baselines for all t ? 2 <ref type="figure" target="#fig_2">(Fig. 3)</ref>. For the case of t = 2, it obtains an average forgetting ratio ? ?2 = ?0.02, while the best baseline is EWC with ? ?2 = ?0.08 <ref type="table">(Table 1)</ref>. For the case of t = 8, HAT obtains ? ?8 = ?0.06, while the best baseline is PNN with ? ?8 = ?0.11. This implies a reduction in forgetting of 75% for t = 2 and 45% for t = 8. Notice that the standard deviation of HAT is lower than the ones obtained by the big majority of the baselines <ref type="table">(Table 1)</ref>. This denotes a certain stability of HAT with respect to different task sequences, data sets, data splits, and network initializations.</p><p>Given the slightly increasing tendency of PNN with t ( <ref type="figure" target="#fig_2">Fig. 3)</ref>, one could speculate that PNN would score above HAT for t &gt; 8. However, our empirical analyzes suggest that that is not the case (presumably due to the capacity pre-assignment and parameter increase problems underlined in Sec. 3 and above). In particular, we observe a gradual lowering of PathNet and PNN curves with increasing sequences from t = 2 to 8. In addition, we observe PathNet and PNN obtaining worse performances than EWC in the case of t = 10 for the incremental class setup (see below and Appendix C.1). In general, none of the baseline methods consistently outperforms the rest across setups and for all t, a situation that we do observe with HAT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Additional Results</head><p>To broaden the strength of our results, we additionally experiment with three common alternative setups. First, we consider an incremental class learning scenario, similar to Lopez-Paz &amp; Ranzato (2017), using class subsets of both CIFAR10 and CIFAR100 data. In this setup, the best baseline after t ? 3 is EWC, with ? ?10 = ?0.18. HAT scores ? ?10 = ?0.09 (55% forgetting reduction). Next, we consider the permuted MNIST sequence of tasks <ref type="bibr">(Srivastava et al., 2013)</ref>. In this setup, the best result we could find in the literature was from SI, with A ?10 = 97.1%. HAT scores A ?10 = 98.6% (52% error rate reduction). Finally, we also consider the split MNIST task of <ref type="bibr" target="#b20">Lee et al. (2017)</ref>. In this setup, the best result from the literature corresponds to the conceptor-aided backpropagation approach <ref type="bibr" target="#b11">(He &amp; Jaeger, 2018)</ref>, with A ?2 = 94.9%. HAT scores A ?2 = 99.0% (80% error rate reduction). The detail for all these setups and results can be found in Appendix C.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Hyperparameters</head><p>In any machine learning algorithm, it is important to assess the sensitivity with respect to the hyperparameters. HAT has two: the stability parameter s max and the compressibility parameter c (Secs. 2.4 and 2.6). A low s max provides plasticity to the units and capacity of adaptation, but the network may easily forget what it learned. A high s max prevents forgetting, but the network may have difficulties in adapting to new tasks. A low c allows to use almost all of the network's capacity for a given task, potentially spending too much in the current task. A high c forces it to learn a very compact model, at the expense of not reaching the accuracy that the original network could have reached. We empirically found good operation ranges s max ? [25, 800] and c ? [0.1, 2.5]. As we can see, any variation within these ranges results in reasonable performance <ref type="figure" target="#fig_5">(Fig. 4)</ref>. Unless stated otherwise, we use s max = 400 and c = 0.75.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Monitoring and Network Pruning</head><p>It is interesting to note that the hard attention mechanism introduced in Sec. 2 offers a number of possibilities to monitor the behavior of our models. For instance, by computing the conditioning mask in Eq. 2 from the hard attention vectors a ?t l , we can assess which weights obtain a high attention value, binarize it, and compute an estimate of the instantaneous network capacity usage <ref type="figure">(Fig. 5</ref>). We may also inform ourselves of the amount of active weights per layer and task (Appendix B.2). Another facet we can monitor is the weight reuse across tasks. By a similar procedure, comparing the conditioning masks between tasks t i and t j , j &gt; i, we can asses the percentage of weights of task t i that are later reused in task t j <ref type="figure">(Fig. 6)</ref>.</p><p>Another by-product of hard attention masks is that we can use them to assess which of the network's weights are important, and then prune the most irrelevant ones <ref type="bibr" target="#b18">(LeCun et al., 1990)</ref>. This way, we can compress the network for further deployment in low-resource devices or time-constrained environments (cf. <ref type="bibr" target="#b10">Han et al., 2016)</ref>. If we want to focus on such compression task, we can set c to a higher value than the one used for catastrophic forgetting and start with a positive random initialization of the embeddings e l . The former will promote more compression while the latter will ensure we start learning the model by putting attention to all weights in the first epochs (full capacity). We empirically found that using c = 1.5 and U(0, 2) yields a reasonable trade-off between accuracy and compression for a single task <ref type="figure" target="#fig_7">(Fig. 7)</ref>. With that, we can compress the network to sizes between 1 and 21% of its original size, depending on the task (Appendix B.3). Comparing these numbers with the compression rates used by PackNet (25 or 50%), we see that HAT generally uses a much more compact model. Comparing with DEN on the specific MNIST and CIFAR100 tasks (18 and 52%), we observe that HAT compresses to 1 and 21%, respectively. Interestingly, and in contrast to these and the majority of network pruning approaches, HAT learns to prune network weights through backpropagation and SGD, and at the same time as the network weights themselves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We introduce HAT, a hard attention mechanism that, by focusing on a task embedding, is able to protect the information of previous tasks while learning new tasks. This hard attention mechanism is lightweight, in the sense that it adds a small fraction of weights to the base network, and is trained together with the main model, with negligible overhead using backpropagation and vanilla SGD. We demonstrate the effectiveness of the approach to control catastrophic forgetting in the image classification context by running a series of experiments with multiple data sets and state-of-the-art approaches. HAT has only two hyperparameters, which intuitively refer to the stability and compactness of the learned knowledge, and whose tuning we demonstrate is not crucial for obtaining good performance. In addition, HAT offers the possibility to monitor the used network capacity across tasks and layers, the unit reuse across tasks, and the compressibility of a model trained for a given task. We hope that our approach may be also useful in online learning or network compression contexts, and that the hard attention mechanism presented here may also find some applicability beyond the catastrophic forgetting problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data</head><p>The data sets used in our experiments are summarized in <ref type="table" target="#tab_1">Table 2</ref>. The MNIST data set <ref type="bibr" target="#b19">(LeCun et al., 1998)</ref> comprises 28 ? 28 monochromatic images of handwritten digits. Fashion-MNIST <ref type="bibr" target="#b42">(Xiao et al., 2017)</ref> comprises gray-scale images of the same size from Zalando's articles 4 . The German traffic sign data set (TrafficSigns; <ref type="bibr" target="#b38">Stallkamp et al., 2011)</ref> contains traffic sign images. We used the version of the data set from the Udacity self-driving car github repository 5 . The NotMNIST data set <ref type="bibr" target="#b1">(Bulatov, 2011)</ref> comprises glyphs extracted from publicly available fonts, making a similar data set to MNIST; we just need to resize the images 6 . The SVHN data set <ref type="bibr" target="#b27">(Netzer et al., 2011)</ref> comprises digits cropped from house numbers in Google Street View images. The FaceScrub data set <ref type="bibr" target="#b28">(Ng &amp; Winkler, 2014)</ref> is widely used in face recognition tasks <ref type="bibr" target="#b13">(Kemelmacher-Shlizerman et al., 2016)</ref>. Because some of the images listed in the original data set were not hosted anymore on the corresponding Internet domains, we use a version of the data set stored on the MegaFace challenge website 7 <ref type="bibr" target="#b13">(Kemelmacher-Shlizerman et al., 2016)</ref>, from which we select the first 100 people with the most appearances 8 . The CIFAR10 and CIFAR100 data sets contain 32 ? 32 color images <ref type="bibr" target="#b16">(Krizhevsky, 2009</ref>).</p><p>To match the image input shape required in our experiments, some of the images in the corresponding data sets need to be resized (FaceScrub, TrafficSigns, and NotMNIST) or padded with zeros (MNIST and FashionMNIST). In addition, for the data sets comprising monochromatic images, we replicate the image across all RGB channels. Note that we do not perform any sort of data augmentation; we just adapt the inputs. We provide the necessary code to perform such adaptations in the links listed above. We report all forgetting ratios ? ?t for t = 1 to 8 in <ref type="table">Table 3</ref>. A total of 10 runs with 10 different seeds are performed and the averages and standard deviations are taken.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Layer Use</head><p>In <ref type="figure" target="#fig_8">Fig. 8</ref> we show an example of layer capacity monitoring as the sequence of tasks evolves. As mentioned in the main paper, we can compute a percent of active weights for a given layer and task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3. Network Compression</head><p>The final results of the network compression experiment reported in the main paper (after reaching convergence) are available in <ref type="table" target="#tab_2">Table 4</ref>. We run HAT on isolated tasks with c = 1.5 and uniform embedding initialization U(0, 2). <ref type="table">Table 3</ref>. Average forgetting ratio ? ?t for the considered approaches (10 runs, standard deviation into parenthesis).  </p><formula xml:id="formula_9">APPROACH ? ?1 ? ?2 ? ?3 ? ?4 ? ?5 ? ?6 ? ?7 ? ?8</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LFL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4. Training Time</head><p>To have an idea of the training time for each of the considered approaches, we report some reference values in <ref type="table" target="#tab_3">Table 5</ref>. We see that HAT is also quite competitive in this aspect. As an additional experiment to complement our evaluation, we consider the incremental CIFAR setup, following a similar approach as Lopez-Paz &amp; Ranzato (2017). We divide both CIFAR10 and CIFAR100 data sets into consecutive-class subsets and use them as tasks, presented in random order according to the seed. We take groups of 2 classes for CIFAR10 and 20 classes for CIFAR100, yielding a total of 10 tasks. We decide to take groups of 2 and 20 classes in order to have a similar number of training instances per task. The rest of the procedure is as in the main paper. The most important results are summarized there. The complete numbers are depicted in <ref type="figure">Fig. 9</ref> and reported in <ref type="table">Table 6</ref>.  <ref type="figure">Figure 9</ref>. Average forgetting ratio ? ?t for the incremental CIFAR task (average after 10 runs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Permuted MNIST</head><p>A common experiment is the one proposed by <ref type="bibr">Srivastava et al. (2013)</ref>, and later employed to evaluate catastrophic forgetting by <ref type="bibr" target="#b8">Goodfellow et al. (2014)</ref>. It consists of taking random permutations of the pixels in the MNIST data set as tasks. Typically, the average accuracy after sequentially training on 10 MNIST permutations is reported. To match the different number of <ref type="table">Table 6</ref>. Average forgetting ratio ? ?t for the incremental CIFAR task (10 runs, standard deviation into parenthesis).  <ref type="table">Table 7</ref>. Accuracy on the permuted MNIST task <ref type="bibr">(Srivastava et al., 2013)</ref>, taking the average after training 10 tasks. The only exception is the generative replay approach, whose performance was assessed after 5 tasks. Superscripts indicate results reported by (1) <ref type="bibr" target="#b29">Nguyen et al. (2017)</ref> and <ref type="formula" target="#formula_1">(2)</ref>  <ref type="bibr" target="#b11">He &amp; Jaeger (2018)</ref>. An asterisk after parameter count indicates that the approach presents some additional structure not included in such parameter count (for instance, some memory module or an additional generative network). parameters used in the literature, we consider a small, medium, and a large network based on a two-layer fully-connected architecture as <ref type="bibr" target="#b44">Zenke et al. (2017)</ref>, with 100, 500, and 2000 hidden units, respectively. For the large network we set dropout probabilities as <ref type="bibr" target="#b15">Kirkpatrick et al. (2017)</ref>. We use s max = 200 and c = 0.5 for the small network, and s max = 400 and c = 0.5 for the medium and large networks. The results are available in <ref type="table">Table 7</ref>.</p><formula xml:id="formula_10">APPROACH ? ?1 ? ?2 ? ?3 ? ?4 ? ?5 ? ?6 ? ?7 ? ?8 ? ?9 ? ?10</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LFL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPROACH PARAMETERS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3. Split MNIST</head><p>Another popular experiment is to split the MNIST data set into tasks and report the average accuracy after learning them one after the other. We follow <ref type="bibr" target="#b20">Lee et al. (2017)</ref> by splitting the data set using labels 0-4 and 5-9 as tasks and running the experiment 10 times. We also match the base network architecture to the one used by <ref type="bibr" target="#b20">Lee et al. (2017)</ref>. We train HAT for 50 epochs with c = 0.1. Results are reported in <ref type="table" target="#tab_5">Table 8</ref>. In preliminary experiments we observed that dropout could increase accuracy by some percentage. However, to keep the same configuration as in the cited reference, we finally did not use it. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Variations to the Proposed Approach</head><p>In this section, we want to mention a number of alternatives we experimented with during the development of HAT. The purpose of the section is not the report a formal set of results, but to inform the reader about potential different choices when implementing HAT, or variations of it, and to give an intuition on the outcome of some of such choices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1. Embedding Learning</head><p>When we realized that the embedding weights e t l were not changing much and that their gradients were small compared to the rest of the network due to the introduced annealing of s, we initially tackled the issue by using a different learning rate for the embeddings. With that, we empirically found that factors of 10-50 times the original learning rate were leading to performances that were almost as good as the final ones reported in the main paper. However, the use of a different learning rate introduced an additional parameter that we could not conceptually relate to catastrophic forgetting and that could have been tricky to tune for a generic setting.</p><p>We also studied the use of an adaptive optimizer such as Adagrad <ref type="bibr" target="#b3">(Duchi et al., 2011)</ref> or Adam <ref type="bibr" target="#b14">(Kingma &amp; Ba, 2015)</ref> for the embedding weights. The idea was that an adaptive optimizer would be able to automatically introduce an appropriate scaling factor. We found that this option was effectively learning suitable values for e t l . However, its performance was worse than the constant-factor SGD boost explained in the previous paragraph. Noticeably, introducing an adaptive optimizer also introduces a number of new hyperparameters: type of optimizer, another learning rate, possible weight decays, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. Annealing</head><p>In our effort to further reduce the number of hyperparameters, we experimented for quite some time with the annealing</p><formula xml:id="formula_11">s = tan ? 4 1 + b ? 1 B ? 1</formula><p>or using variants of</p><formula xml:id="formula_12">s = ? + ? tan ? 2 b ? 1 B ? 1 .</formula><p>The rationale for the first expression is that one starts with a sigmoid ?(sx) that is equivalent to a straight line of 45 degrees for b = 1 and x ? 0. Then, with b increasing, it linearly increases the angle towards 90 degrees at x = 0. The second expression is a parametric evolution of the first one.</p><p>These annealing schedules have the (sometimes desirable) feature that the maximum s is infinite, yielding a true step function in inference time. Therefore, we obtain truly binary attention vectors a t l and no forgetting. In addition, if we use the first expression, we are able to remove the s max hyperparameter. Nonetheless, we found the first expression to perform worse than the solution proposed in the main paper. The introduction of the second expression with ? = 1 and ? &lt; 1 improved the situation, but results were still not as good as the ones in the main paper and the tuning of ? was a bit tricky.</p><p>To conclude this subsection, note that if s max is large, for instance s max &gt; 100, one can use</p><formula xml:id="formula_13">s = s max b ? 1 B ? 1 ,</formula><p>which is a much simpler annealing formula that closely approximates the one in the main paper. However, one needs then to be careful with the denominator of the embedding gradient compensation when s = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3. Gate</head><p>We also studied the use of alternatives to the sigmoid gate. Apart from the rescaled tanh, an interesting alternative we thought of was a clamped version of the linear function, a t l = max 0, min 1,</p><formula xml:id="formula_14">se t l r + 1 2 ,</formula><p>where r defines the 'valid' range for the input of the gate. This gate yields a much simpler formulation for the gradient compensation described in the main paper. However, it implies that we need to set r, which could be considered a further hyperparameter. It also implies that embedding values that are far away from 0, the step transition point, receive a proportionally similar gradient to the ones that are close to it. That is, values of e t l that yield a t l that are very close to 0 or 1 (in the constant region of the pseudo-step function) are treated equal to the ones that are still undecided (in the transition region of the pseudo-step function). We did not test this alternative gate quantitatively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4. Cumulative Attention</head><p>In the most preliminary stages we used a ?t l = 1 ? 1 ? a t l 1 ? a ?t?1 l for accumulating attention across tasks, but it was soon dismissed for the final max-based formula. The previous equation could be interesting for online learning scenarios with limited model capacity, together with a ?t l = max a t l , ? a ?t?1 l , where ? is a constant slightly lower than 1 (for instance ? = 0.9 or ? = 0.99).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.5. Embedding Initialization</head><p>We ran a set of experiments using uniform initialization U(0, k 1 ) for the embeddings e t l instead of Gaussian N (0, 1). We also experimented with N (k 2 , 1). The idea behind these alternative initializations was that, for sufficiently large s max , all or almost all a t l start with a value of 1, which has the effect of distributing the attention over all units for more time at the beginning of training. Using values of k 1 ? [1, 6] and k 2 ? [0.5, 2] yielded competitive results, yet worse than the ones using N (0, 1). Our intuition is that a uniform initialization like U(0, 2) is better for a purely compressive approach, as used in the last experiment of the main paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.6. Attention Regularization</head><p>We initially experimented with a normalized L1 regularization</p><formula xml:id="formula_15">R A t = L?1 l=1 N l i=1 a t l,i L?1 l=1 N l .</formula><p>Results were a small percentage lower than the ones with the attention-weighted regularization of the main paper. We also exchanged the previous L1 regularization with the L2-based regularization</p><formula xml:id="formula_16">R A t = L?1 l=1 N l i=1 (a t l,i ) 2 L?1 l=1 N l .</formula><p>With that, we observed similar accuracies as the L1 regularization, but under different values for the hyperparameter c.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.7. Hard Attention to the Input</head><p>As mentioned in the main paper, no attention mask is used for the input (that is, there is no a t 0 ). We find this is a good strategy for a general image classification problem and for first-layer convolutional filters in particular. However, if the input consists of independent, isolated features, one may think of putting hard attention to the input as a kind of supervised feature selection process. We performed a number of experiments using only fully-connected layers and the MNIST data as above, and introduced additional hard attention vectors a t 0 that directly multiplied the input of the network. The results suggested that it could potentially be a viable option for feature selection and data compression <ref type="figure" target="#fig_0">(Fig. 10</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. A Note on Binary Masks</head><p>After writing a first version of the paper, we realized that the idea of a binary mask that affects a given unit could be potentially traced back to the "inhibitory synapses" of <ref type="bibr" target="#b26">McCulloch &amp; Pitts (1943)</ref>. This idea of inhibitory synapses is quite unconventional and rarely seen today <ref type="bibr" target="#b41">(Wang &amp; Raj, 2017</ref>) and, to the best of our knowledge, no specific way for learning such inputs nor a specific function for them have been proposed. Weight-based binary masks are implicitly or explicitly used by many catastrophic forgetting approaches, at least by <ref type="bibr" target="#b34">Rusu et al. (2016);</ref><ref type="bibr" target="#b5">Fernando et al. (2017)</ref>; Mallya &amp; Lazebnik (2017); <ref type="bibr" target="#b29">Nguyen et al. (2017)</ref>; <ref type="bibr" target="#b43">Yoon et al. (2018)</ref>. HAT is a bit different, as it learns unit-based attention masks with possible (but not necessarily) binary values.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Schematic diagram of the proposed approach: forward (top) and backward (bottom) passes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Illustration of the effect that annealing s has on the gradients q of e t .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Average forgetting ratio ? ?t for the considered approaches (10 runs).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Effect of hyperparameters smax and c on average forgetting ratio ? ?8 . Results for seed 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>Network capacity usage with sequential task learning (seed 0). Dashed vertical lines correspond to a task switch. Percentage of weight reuse across tasks. Seed 0 sequence: (1) FaceScrub, (2) MNIST, (3) CIFAR100, (4) NotMNIST, (5) SVHN, (6) CIFAR10, (7) TrafficSigns, and(8)FashionMNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Validation accuracy A 1 as a function of compression percentage. Every dot corresponds to an epoch and triangles match the accuracy of the SGD approach (no compression).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>00) -0.20 (0.08) -0.41 (0.09) -0.49 (0.07) -0.54 (0.07) -0.57 (0.06) -0.62 (0.06) -0.66 (0.03) IMM-MODE -0.00 (0.01) -0.11 (0.08) -0.27 (0.12) -0.37 (0.10) -0.39 (0.07) -0.45 (0.05) -0.49 (0.06) -0.49 (0.05) SGD-F -0.00 (0.00) -0.20 (0.15) -0.30 (0.15) -0.38 (0.11) -0.42 (0.09) -0.44 (0.08) -0.45 (0.07) -0.44 (0.06) IMM-MEAN -0.00 (0.00) -0.12 (0.10) -0.24 (0.11) -0.32 (0.06) -0.37 (0.06) -0.40 (0.06) -0.42 (0.07) -0.42 (0Layer-wise weight usage with sequential task learning, including (lines) and excluding (bars) the cumulative attention of past tasks. Task sequence corresponds to seed 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>01) -0.19 (0.09) -0.27 (0.09) -0.30 (0.04) -0.30 (0.06) -0.28 (0.04) -0.31 (0.03) -0.32 (0.04) -0.30 (0.05) -0.30 (0.04) IMM-MEAN -0.00 (0.02) -0.14 (0.08) -0.21 (0.10) -0.22 (0.10) -0.25 (0.10) -0.26 (0.08) -0.27 (0.08) -0.28 (0.08) -0.29 (0.07) -0.30 (0.07) IMM-MODE -0.00 (0.01) -0.14 (0.10) -0.21 (0.11) -0.23 (0.06) -0.25 (0.09) -0.23 (0.07) -0.26 (0.05) -0.27 (0.04) -0.25 (0.04) -0.25 (0.04) PNN -0.26 (0.16) -0.26 (0.08) -0.25 (0.05) -0.23 (0.04) -0.22 (0.03) -0.23 (0.03) -0.22 (0.03) -0.21 (0.02) -0.21 (0.02) -0.21 (0.02) EWC -0.00 (0.01) -0.13 (0.09) -0.15 (0.08) -0.16 (0.07) -0.17 (0.06) -0.18 (0.06) -0.19 (0.08) -0.18 (0.07) -0.18 (0.06) -0.18 (0.06) HAT -0.03 (0.04) -0.05 (0.02) -0.05 (0.02) -0.06 (0.01) -0.06 (0.01) -0.07 (0.01) -0.07 (0.01) -0.08 (0.01) -0.08 (0.01) -0.09 (0.01)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 .</head><label>10</label><figDesc>Example of an input mask for MNIST data after training to convergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Telef?nica Research, Barcelona, Spain 2 Universitat Polit?cnica de Catalunya, Barcelona, Spain 3 Universitat Pompeu Fabra, Barcelona, Spain. Correspondence to: Joan Serr? &lt;joan.serra@telefonica.com&gt;. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).</figDesc><table /><note>1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Data sets used in the study: name, reference, number of classes, and number of train and test instances.</figDesc><table><row><cell>DATA SET</cell><cell>CLASSES</cell><cell>TRAIN</cell><cell>TEST</cell></row><row><cell>CIFAR10 (KRIZHEVSKY, 2009)</cell><cell>10</cell><cell cols="2">50,000 10,000</cell></row><row><cell>CIFAR100 (KRIZHEVSKY, 2009)</cell><cell>100</cell><cell cols="2">50,000 10,000</cell></row><row><cell>FACESCRUB (NG &amp; WINKLER, 2014)</cell><cell>100</cell><cell>20,600</cell><cell>2,289</cell></row><row><cell>FASHIONMNIST (XIAO ET AL., 2017)</cell><cell>10</cell><cell cols="2">60,000 10,000</cell></row><row><cell>NOTMNIST (BULATOV, 2011)</cell><cell>10</cell><cell>16,853</cell><cell>1,873</cell></row><row><cell>MNIST (LECUN ET AL., 1998)</cell><cell>10</cell><cell cols="2">60,000 10,000</cell></row><row><cell>SVHN (NETZER ET AL., 2011)</cell><cell>100</cell><cell cols="2">73,257 26,032</cell></row><row><cell>TRAFFICSIGNS (STALLKAMP ET AL., 2011)</cell><cell>43</cell><cell cols="2">39,209 12,630</cell></row><row><cell>B. Raw Results</cell><cell></cell><cell></cell><cell></cell></row><row><cell>B.1. Task Mixture</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .</head><label>4</label><figDesc>Results for the compression experiment reported in the main paper: test accuracy A 1 with SGD, test accuracy A 1 after compressing with HAT, and percentage of network weights used after compression.</figDesc><table><row><cell>DATA SET</cell><cell cols="2">RAW A 1 COMPRESSED A 1</cell><cell>SIZE</cell></row><row><cell>CIFAR10</cell><cell>79.9%</cell><cell>80.8%</cell><cell>13.9%</cell></row><row><cell>CIFAR100</cell><cell>52.7%</cell><cell>49.1%</cell><cell>21.4%</cell></row><row><cell>FACESCRUB</cell><cell>82.7%</cell><cell>82.3%</cell><cell>21.0%</cell></row><row><cell>FASHIONMNIST</cell><cell>92.4%</cell><cell>91.9%</cell><cell>2.3%</cell></row><row><cell>MNIST</cell><cell>99.5%</cell><cell>99.4%</cell><cell>1.2%</cell></row><row><cell>NOTMNIST</cell><cell>90.9%</cell><cell>91.5%</cell><cell>5.7%</cell></row><row><cell>SVHN</cell><cell>94.2%</cell><cell>93.8%</cell><cell>3.1%</cell></row><row><cell>TRAFFICSIGNS</cell><cell>97.5%</cell><cell>98.1%</cell><cell>2.9%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 .</head><label>5</label><figDesc>Wall-clock training time measured on a single NVIDIA Pascal Titan X GPU: total (after learning the 8 tasks), per epoch, and per batch (batches of 64). Batch processing time is measured for a forward pass (Batch-F), and for both a forward and a backward pass (Batch-FB).</figDesc><table><row><cell>APPROACH</cell><cell></cell><cell cols="2">TRAINING TIME</cell><cell></cell></row><row><cell></cell><cell cols="4">TOTAL [H] EPOCH [S] BATCH-F [MS] BATCH-FB [MS]</cell></row><row><cell>PNN</cell><cell>6.0</cell><cell>4.1</cell><cell>10.2</cell><cell>27.5</cell></row><row><cell>PATHNET</cell><cell>4.5</cell><cell>3.6</cell><cell>10.6</cell><cell>23.9</cell></row><row><cell>EWC</cell><cell>3.9</cell><cell>3.1</cell><cell>7.9</cell><cell>19.7</cell></row><row><cell>MULTITASK</cell><cell>3.4</cell><cell>94.8</cell><cell>3.1</cell><cell>15.7</cell></row><row><cell>IMM-MEAN</cell><cell>3.2</cell><cell>2.6</cell><cell>6.9</cell><cell>17.1</cell></row><row><cell>IMM-MODE</cell><cell>3.1</cell><cell>2.5</cell><cell>6.7</cell><cell>16.0</cell></row><row><cell>LWF</cell><cell>2.2</cell><cell>2.2</cell><cell>5.7</cell><cell>14.2</cell></row><row><cell>HAT</cell><cell>2.2</cell><cell>1.6</cell><cell>4.0</cell><cell>11.7</cell></row><row><cell>SGD</cell><cell>1.4</cell><cell>0.9</cell><cell>2.5</cell><cell>6.6</cell></row><row><cell>LFL</cell><cell>1.3</cell><cell>0.9</cell><cell>4.4</cell><cell>9.2</cell></row><row><cell>SGD-F</cell><cell>0.5</cell><cell>0.9</cell><cell>2.5</cell><cell>6.8</cell></row><row><cell>C. Additional Results</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>C.1. Incremental CIFAR</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 8 .</head><label>8</label><figDesc>Average accuracy on the split MNIST task, following the setup of<ref type="bibr" target="#b20">Lee et al. (2017)</ref> using 10 runs (standard deviation into parenthesis). Superscript (1) indicates results reported by<ref type="bibr" target="#b20">Lee et al. (2017)</ref>.</figDesc><table><row><cell>APPROACH</cell><cell>PARAMETERS</cell><cell>A ?2</cell></row><row><cell>SGD (GOODFELLOW ET AL., 2014) 1</cell><cell>1.9 M</cell><cell>71.3% (1.5)</cell></row><row><cell>L2-TRANSFER (EVGENIOU &amp; PONTIL, 2004) 1</cell><cell>1.9 M</cell><cell>85.8% (0.5)</cell></row><row><cell>IMM-MEAN (LEE ET AL., 2017)</cell><cell>1.9 M</cell><cell>94.0% (0.2)</cell></row><row><cell>IMM-MODE (LEE ET AL., 2017)</cell><cell>1.9 M</cell><cell>94.1% (0.3)</cell></row><row><cell>CAB (HE &amp; JAEGER, 2018)</cell><cell>1.9 M</cell><cell>94.9% (0.3)</cell></row><row><cell>HAT</cell><cell>1.9 M</cell><cell>99.0% (0.0)</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Essentially, the MNIST data contains many values close to 0 that allow for an easier identification of the important units or weights which, if permuted, can then be easily frozen without overlapping with the ones of the other tasks (see<ref type="bibr" target="#b20">Lee et al., 2017)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/zalandoresearch/fashion-mnist 5 https://github.com/georgesung/traffic_sign_classification_german 6 Code and processed data available on github: https://github.com/nkundiushuti/notmnist_convert 7 http://megaface.cs.washington.edu/participate/challenge.html 8 Code and processed data available on github: https://github.com/nkundiushuti/facescrub_subset</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Task clustering and gating for bayesian multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Heskes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="83" to="99" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bulatov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Notmnist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dataset</surname></persName>
		</author>
		<ptr target="http://yaroslavvb.blogspot.it/2011/09/notmnist-dataset.html" />
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Clegg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Digirolamo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Keele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="275" to="281" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Regularized multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">PathNet: evolution channels gradient descent in super neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Banarse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zwols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno>1701.08734</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using semi-distributed representations to overcome catastrophic forgetting in connectionist networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>French</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Conf. of the Cognitive Science Society (CogSci)</title>
		<meeting>of the Annual Conf. of the Cognitive Science Society (CogSci)</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="173" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Artificial Intelligence and Statistics (AISTATS)</title>
		<meeting>of the Int. Conf. on Artificial Intelligence and Statistics (AISTATS)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An empirical investigation of catastrophic forgetting in gradient-based neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mizra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Learning Representations (ICLR)</title>
		<meeting>of the Int. Conf. on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reduction of catastrophic forgetting with transfer learning and ternary output codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gutsein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Stump</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Joint Conf. on Neural Networks (IJCNN)</title>
		<meeting>of the Int. Joint Conf. on Neural Networks (IJCNN)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep compression: compressing deep neural networks with pruning, trained quantization and Huffman coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Learning Representations (ICLR)</title>
		<meeting>of the Int. Conf. on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic interference using conceptor-aided backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Learning Representations (ICLR)</title>
		<meeting>of the Int. Conf. on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Less-forgetting learning in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<idno>1607.00122</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The megaface benchmark: 1 million faces for recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4873" to="4882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adam: a method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Learning Representations (ICLR)</title>
		<meeting>of the Int. Conf. on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clopath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the National Academy of Sciences of the USA</title>
		<meeting>of the National Academy of Sciences of the USA</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="3521" to="3526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Toronto, Canada</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Msc thesis</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>Pereira, F., Burges, C. J. C., Bottou, L., and Weinberger, K. Q.</editor>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Optimal brain damage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>Touretzky, D. S.</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1990" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="598" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting by incremental moment matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-T ;</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garnett</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>R.</editor>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="4655" to="4665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Universal intelligence: a definition of machine intelligence. Minds and Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="391" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>PP</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gradient episodic memory for continuum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A ;</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garnett</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>R.</editor>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6449" to="6458" />
		</imprint>
	</monogr>
	<note>Guyon, I</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Overcoming Catastrophic Forgetting with Hard Attention to the Task Mallya, A. and Lazebnik, S. PackNet: adding multiple tasks to a single network by iterative pruning</title>
		<idno>1711.05769</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Catastrophic interference in connectionist networks: the sequential learning problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of Learning and Motivation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="109" to="165" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A logical calculus of the ideas immanent in nervous activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Mcculloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pitts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Bulletin of Mathematical Biophysics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="115" to="133" />
			<date type="published" when="1943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning (NIPS-DeepLearning)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A data-driven approach to cleaning large face datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winkler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int. Conf. on Image Processing (ICIP)</title>
		<meeting>of the IEEE Int. Conf. on Image essing (ICIP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="343" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Variational continual learning. ArXiv</title>
		<imprint>
			<date type="published" when="1710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on The Future of Gradient-based Machine Learning Software &amp; Techniques (NIPS-Autodiff</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Connectionist models of recognition memory: constraints imposed by learning and forgetting functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="285" to="308" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">iCaRL: incremental classifier and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sperl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting, rehearsal and pseudorehearsal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="123" to="146" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<idno>1606.04671</idno>
	</analytic>
	<monogr>
		<title level="j">Progressive neural networks. ArXiv</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Continual learning with deep generative replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garnett</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>R.</editor>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2993" to="3002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Memory-based parameter adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sprechmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Puigdom?nech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Learning Representations (ICLR)</title>
		<meeting>of the Int. Conf. on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Compete to compute</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kazerounian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>Burges, C. J. C., Bottou, L., Welling, M., Ghahramani, Z., and Weinberger, K.</editor>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2310" to="2318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The German traffic sign recognition benchmark: a multi-class classification competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stallkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schlipsing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salmen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Joint Conf. on Neural Networks (IJCNN)</title>
		<meeting>of the Int. Joint Conf. on Neural Networks (IJCNN)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1453" to="1460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Lifelong robot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="25" to="46" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">A strategy for an uncompromising incremental learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<idno>1705.00744</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">On the origin of deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<idno>1702.07800</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno>1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Lifelong learning with dynamically expandable networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Learning Representations (ICLR)</title>
		<meeting>of the Int. Conf. on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Improved multitask learning through synaptic intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zenke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Machine Learning (ICML)</title>
		<meeting>of the Int. Conf. on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3987" to="3995" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
