<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Mixup Regularization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><surname>Carratino</surname></persName>
							<email>luigi.carratino@dibris.unige.it</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodolphe</forename><surname>Jenatton</surname></persName>
							<email>rjenatton@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Vert</surname></persName>
							<email>jean-philippe.vert@m4x.org</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">MaLGa -University of Genova</orgName>
								<address>
									<country>Italy Moustapha Ciss?</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Google Research -Brain team</orgName>
								<address>
									<settlement>Berlin</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Google Research -Brain team</orgName>
								<address>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On Mixup Regularization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Google Research -Brain team, Accra</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Mixup is a data augmentation technique that creates new examples as convex combinations of training points and labels. This simple technique has empirically shown to improve the accuracy of many state-of-the-art models in different settings and applications, but the reasons behind this empirical success remain poorly understood. In this paper we take a substantial step in explaining the theoretical foundations of Mixup, by clarifying its regularization effects. We show that Mixup can be interpreted as standard empirical risk minimization estimator subject to a combination of data transformation and random perturbation of the transformed data. We gain two core insights from this new interpretation. First, the data transformation suggests that, at test time, a model trained with Mixup should also be applied to transformed data, a one-line change in code that we show empirically to improve both accuracy and calibration of the prediction. Second, we show how the random perturbation of the new interpretation of Mixup induces multiple known regularization schemes, including label smoothing and reduction of the Lipschitz constant of the estimator. These schemes interact synergistically with each other, resulting in a self calibrated and effective regularization effect that prevents overfitting and overconfident predictions. We corroborate our theoretical analysis with experiments that support our conclusions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Regularization is an essential component of machine learning models and plays an even more important role in deep learning <ref type="bibr" target="#b12">(Goodfellow et al., 2016)</ref>. Regularization mechanisms can take various forms. They can be explicitly enforced by: (i) applying various penalties to the parameters of the models <ref type="bibr" target="#b22">(Hinton, 1987;</ref><ref type="bibr" target="#b24">Krogh and Hertz, 1991;</ref><ref type="bibr" target="#b4">Bartlett et al., 2017;</ref><ref type="bibr" target="#b28">Neyshabur et al., 2015;</ref><ref type="bibr" target="#b33">Sedghi et al., 2019;</ref>, (ii) injecting noise to the internal representations of the network <ref type="bibr" target="#b35">(Srivastava et al., 2014;</ref><ref type="bibr" target="#b11">Gal and Ghahramani, 2016)</ref> and/or to its outputs <ref type="bibr" target="#b36">(Szegedy et al., 2016;</ref><ref type="bibr" target="#b26">M?ller et al., 2019)</ref>, or (iii) normalizing the activations <ref type="bibr" target="#b17">(He et al., 2016;</ref><ref type="bibr" target="#b32">Salimans and Kingma, 2016)</ref>. Or they can be implicit thanks to: (j) parameter sharing in architectures such as convolutional networks <ref type="bibr" target="#b25">(LeCun et al., 1998)</ref>, (jj) the choice of the optimization algorithm <ref type="bibr" target="#b27">(Neyshabur, 2017)</ref>, e.g., stochastic gradient descent converging to small norm solutions <ref type="bibr" target="#b1">(Arora et al., 2019)</ref>, or (jjj) through data augmentation and transformation <ref type="bibr" target="#b12">(Goodfellow et al., 2016)</ref>. There is a large body of work explaining the effects of the numerous explicit and implicit regularization procedures existing in the literature. For instance, explicit regularization schemes usually proceed from analysis aiming to control specific characteristics of a model such as robustness <ref type="bibr" target="#b18">(Hein and Andriushchenko, 2017;</ref><ref type="bibr" target="#b10">Ciss? et al., 2017)</ref> or calibration <ref type="bibr" target="#b14">(Guo et al., 2017;</ref><ref type="bibr" target="#b26">M?ller et al., 2019)</ref>, while the forms of implicit regularization are often understood through the angle of generalization <ref type="bibr" target="#b27">(Neyshabur, 2017;</ref><ref type="bibr" target="#b1">Arora et al., 2019)</ref>. However, the regularization effects of modern data augmentation procedures are less theoretically understood.</p><p>Data augmentation is a core ingredient for successful deep learning pipelines. It helps to alleviate sample size issues and prevent overfitting. In simple cases, there are known equivalences between data augmentation and other existing explicit regularization procedures, e.g., training with additional noisy points in least-squares regression is equivalent to Tikhonov regularization <ref type="bibr" target="#b6">(Bishop, 1995)</ref>. Similar analysis have recently been performed to explain the regularization effect of dropout <ref type="bibr" target="#b35">(Srivastava et al., 2014;</ref><ref type="bibr" target="#b40">Wager et al., 2013;</ref><ref type="bibr" target="#b41">Wei et al., 2020)</ref>. In this work, we focus on Mixup <ref type="bibr" target="#b43">(Zhang et al., 2018;</ref><ref type="bibr" target="#b38">Tokozume et al., 2018)</ref>, a recently introduced data-augmentation technique that consists in generating examples as random convex combinations of data points and labels from the training set (as illustrated in <ref type="figure">Figure 1</ref>). Despite its simplicity, Mixup has been shown to substantially improve generalization on a broad range of tasks ranging from computer vision <ref type="bibr" target="#b43">(Zhang et al., 2018;</ref><ref type="bibr" target="#b38">Tokozume et al., 2018)</ref> to natural language processing <ref type="bibr" target="#b15">(Guo, 2020)</ref> and semi-supervised learning <ref type="bibr" target="#b5">(Berthelot et al., 2019)</ref>. The success of Mixup has triggered several variations such as adaptive Mixup <ref type="bibr" target="#b16">(Guo et al., 2019)</ref>, manifold Mixup <ref type="bibr" target="#b39">(Verma et al., 2019)</ref> and Cutmix <ref type="bibr" target="#b42">(Yun et al., 2019)</ref>, but the reasons why Mixup and its variants work so well in practice remain poorly understood.</p><p>Mixup's primary motivation was to alleviate overfitting in training deep neural networks <ref type="bibr" target="#b43">(Zhang et al., 2018)</ref>. However, previous studies have also empirically noticed other desirable regularization effects it induces. These include improved calibration <ref type="bibr" target="#b37">(Thulasidasan et al., 2019)</ref>, robustness to input adversarial noise <ref type="bibr" target="#b43">(Zhang et al., 2018)</ref>, and robustness to label corruption <ref type="bibr" target="#b43">(Zhang et al., 2018)</ref>. <ref type="bibr" target="#b43">Zhang et al. (2018)</ref> also showed it helps stabilize notoriously difficult learning problems such as generative adversarial networks. Traditionally, separate regularization methods are applied to induce the above effects. For example, label smoothing <ref type="bibr" target="#b36">(Szegedy et al., 2016;</ref><ref type="bibr" target="#b26">M?ller et al., 2019)</ref> leads to better calibration, while dropout improves generalization <ref type="bibr" target="#b35">(Srivastava et al., 2014;</ref><ref type="bibr" target="#b40">Wager et al., 2013)</ref> and robustness to label corruption <ref type="bibr" target="#b2">(Arpit et al., 2017)</ref>. Lipschitz regularization helps stabilize the training of generative adversarial networks <ref type="bibr" target="#b13">Gulrajani et al., 2017)</ref>. It also leads to increased robustness to adversarial perturbations <ref type="bibr" target="#b18">(Hein and Andriushchenko, 2017;</ref><ref type="bibr" target="#b10">Ciss? et al., 2017)</ref>. <ref type="table" target="#tab_1">Table 1</ref> shows a comparison of various regularization procedure proposed in the literature, and the effect they are known to induce on the model. Although all these desirable regularization effects have been observed empirically, no theoretical explanation has been given yet.</p><p>In this work, we propose the first theoretical analysis of Mixup 1 to better understand the reasons for its empirical success. We show that Mixup can be analyzed through the lenses of empirical risk minimization with random perturbations, and exploit ingredients from previous 1. After we published a first version of this work <ref type="bibr" target="#b9">(Carratino et al., 2020)</ref>, <ref type="bibr" target="#b44">Zhang et al. (2021)</ref> independently derived a similar and complementary analysis of Mixup; we summarize in Section 5 the main differences between both works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original</head><p>Modified Mixup Zoom analysis of dropout <ref type="bibr" target="#b40">(Wager et al., 2013;</ref><ref type="bibr" target="#b23">Khalfaoui et al., 2019;</ref><ref type="bibr" target="#b41">Wei et al., 2020)</ref> to derive a regularized objective function that sharply captures the regularization effects of Mixup. In particular, our analysis sheds some light on the multiple effects that Mixup borrows from the popular regularization mechanisms listed above such as label smoothing <ref type="bibr" target="#b29">(Pereyra et al., 2017</ref>) (output noise) or dropout <ref type="bibr" target="#b35">(Srivastava et al., 2014</ref>) (input noise), and how it uniquely combines them to improve calibration and smooth the Jacobian of the model. We further show that this analysis points out a missing step in learning with Mixup, and we present how applying a simple transformation when evaluating at test time the function learned with Mixup can improves accuracy and calibration. More precisely, we make the following contributions (illustrated in <ref type="figure">Figure 1</ref>):</p><p>? We show that Mixup can be reinterpreted as a standard empirical risk minimization procedure, applied to a transformation of the original data perturbed by random perturbations, and give explicit formulas for the data transformation and the perturbations.</p><p>? In particular, we show that the Mixup transformations shrinks both the inputs and the outputs towards their mean, the later creating a form of regularization by label smoothing. We notably give a formal description of the effect of label smoothing in the case of the cross-entropy loss where it translates into an increase in the entropy of the predictions.</p><p>? We show that Mixup learns functions from a modified version of the input space of the training points to a modified version of the output space of the training points. Thus, we present how to properly evaluate the learned functions to further improve accuracy and calibration.</p><p>? We characterize the random perturbations induced by Mixup on both the inputs and the outputs, as well as their dependency and their correlation structure.</p><p>? We deduce an approximation of the regularization induced by Mixup, and highlight in particular how it regularizes both the model and its derivatives. We discuss in details the specific cases of classification with cross-entropy loss, and least squares regression.</p><p>? We provide empirical support for our interpretation of Mixup regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Calibration Jacobian Reg. Robustness Label Noise Input Normaliz.</p><p>Label smooth. <ref type="bibr" target="#b36">(Szegedy et al., 2016)</ref> Spectral Reg. <ref type="bibr" target="#b10">(Ciss? et al., 2017)</ref> Dropout <ref type="bibr" target="#b40">(Wager et al., 2013)</ref> Temperat. scaling <ref type="bibr" target="#b14">(Guo et al., 2017)</ref> Mixup <ref type="bibr" target="#b43">(Zhang et al., 2018)</ref>  The rest of the paper is organized as follows. In Section 2, we introduce notations used throughout the paper and describe the setting of empirical risk minimization and learning with Mixup. In Section 3, we show how Mixup can be interpreted as an empiricial risk minimization on modified data with random perturbations. In Section 4 we analyze the regularization effect of Mixup through a quadratic Taylor approximation of the formulation derived in Section 3. In Section 5, we discuss in detail several aspects of Mixup that the theoretical analysis in Section 4 and Section 3 suggest, and confront them to experimental validations. The proofs of all results are detailed in the Annex, together with additional experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Notations and setting</head><p>Notations. For any n ? N, [n] = {1, . . . , n} is the set of nonzero integers up to n, 1 n ? R n is the n-dimensional vector of ones, and 0 n and I n ? R n?n are the n-dimensional null and identity matrices, respectively. For any two matrices Z, Z of equal size we note Z, Z = Trace(Z Z ) their Frobenius inner product, and with Z F = Z, Z the Frobenius norm. For any vector x ? R n , matrix M ? R n?m and positive semi-definite matrix Z ? R n?n , we denote by x 2 Z = x Zx the squared semi-norm of x with metric Z, and with M 2 Z = M, ZM = Trace(M ZM ) the squared Frobenius norm with metric Z. For any function f : R a ? R b and vector x ? R a , we denote respectively by ?f (x) ? R b?a and ? 2 f (x) ? R b?a?a the Jacobian and Hessian of f at</p><formula xml:id="formula_0">x, i.e., if f (x) = (f 1 (x 1 , . . . , x a ), . . . , f b (x 1 , . . . , x a )), then [?f (x)] i,j = ?f i /?x j (x) and [? 2 f (x)] i,j,k = ? 2 f i /?x j ?x k (x), for (i, j, k) ? [b] ? [a] ? [a].</formula><p>Note in particular that if f : R a ? R, then the gradient of f is a row vector ?f (x) ? R 1?a . When f has several arguments and we wish to take partial derivatives with respect to some of the arguments, we explicitly name the different arguments as f (u, v) and then indicate as a subscript to the ? sign the argument(s) according to which we take derivatives, e.g., if u ? R au and v ? R av , then ? u f (u, v) ? R b?au is the Jacobian of f with respect to u, and ? 2 uv f ? R b?au?av is the tensor of second derivatives of f of the form</p><formula xml:id="formula_1">[? 2 uv f (u, v)] i,j,k = ? 2 f i /?u j ?v k (u, v) for (i, j, k) ? [b] ? [a u ] ? [a v ].</formula><p>We recall that if f : R au+av ? R is twice continuously differentiable, then ? uv f = ? vu f , by Schwarz's theorem. For any random variable X and measurable function f , we denote by E X f (X) the expectation of f (X), or simply Ef (X) when no confusion is possible. For any shape parameters ?, ? &gt; 0, and any interval [a, b] ? [0, 1], Beta <ref type="bibr">[a,b]</ref> (?, ?) denotes the truncated Beta distribution on [a, b], i.e., the distribution of a random variable with values in <ref type="bibr">[a, b]</ref> and density proportional to</p><formula xml:id="formula_2">x ??1 (1 ? x) ??1 on [a, b].</formula><p>We simply write Beta(?, ?) = Beta [0,1] (?, ?) for the usual Beta distribution. For any p ? [0, 1], Ber(p) denotes the Bernoulli distribution with parameter p. For any c ? N, we denote by</p><formula xml:id="formula_3">? c = {u ? R c ; u 1 c = 1 and for j ? [c], u j ? 0}</formula><p>the simplex in R c , and for any p ? ? c , we denote by Z(p) = ? c j=1 p j log(p j ) the entropy of a categorical distribution with parameter p.</p><p>Learning problem. We consider a training set S n = {(x 1 , y 1 ), . . . , (x n , y n )} made of n input/output pairs, where for each pair i ? [n], x i ? X ? R d and y i ? Y ? R c . This covers in particular the regression or binary classification settings, where c = 1, or the multivariate regression and multiclass classification setting, where y i is an embedding of the class of x i in R c , e.g., the one-hot encoding by taking c equal to the total number of classes and letting y i ? {0, 1} c be the binary vector with all entries equal to zero except for the one corresponding to the class of x i . We further denote the mean input and output as</p><formula xml:id="formula_4">x = 1 n n i=1 x i , y = 1 n n i=1 y i ,</formula><p>and the empirical variance and covariance matrices or inputs and outputs as</p><formula xml:id="formula_5">? xx = 1 n n i=1 (x i ?x)(x i ?x) , ? xy = 1 n n i=1 (x i ?x)(y i ?y) , ? yy = 1 n n i=1 (y i ?y)(y i ?y) .</formula><p>Our goal is to learn from S n a function f : X ? R c to predict the output corresponding to any new input x ? X via ?(f (x)), where ? : R c ? Y maps an R c -valued prediction to an element of Y; standard mappings include the identity ?(y) = y for regression problems, and the softmax operator ?(y) i = e y i / c j=1 e y j for multiclass classification problems. For that purpose, we formulate the inference problem as an optimization problem:</p><formula xml:id="formula_6">min f ?H E(f ) ,<label>(1)</label></formula><p>where H is a class of candidate functions, such as linear functions or deep neural networks, and E(f ) is a risk functional that depends on S n . The most standard risk used in machine learning is the empirical risk, defined for any loss function :</p><formula xml:id="formula_7">Y ? R c ? R by: E Empirical (f ) = 1 n n i=1 (y i , f (x i )) .<label>(2)</label></formula><p>Solving (1) with the empirical risk (2) is often called empirical risk minimization (ERM), and is typically performed in practice by first-order numerical optimization such as stochastic gradient descent <ref type="bibr" target="#b7">(Bottou and Bousquet, 2008)</ref>. Standard losses include the squared error (in regression) and the cross-entropy loss applied to the softmax mapping (in classification, assuming that ?y ? Y, y 1 c = 1, which is true for one-hot encoded classes and their convex combinations):</p><formula xml:id="formula_8">?(y, u) ? Y ? R c , SE (y, u) = 1 2 y ? u 2 , CE (y, u) = log c i=1 e u i ? y u . (3)</formula><p>Mixup. Instead of minimizing the empirical risk (2), Mixup <ref type="bibr" target="#b43">(Zhang et al., 2018)</ref> creates new random input/output samples by taking convex combinations of pairs of training samples, and minimizes the corresponding empirical risk. With our notations, Mixup therefore minimizes the following Mixup risk over f ? H:</p><formula xml:id="formula_9">E Mixup (f ) = 1 n 2 n i=1 n j=1 E ? (?y i + (1 ? ?)y j , f (?x i + (1 ? ?)x j )) ,<label>(4)</label></formula><p>where ? ? Beta(?, ?), and ? is a parameter of Mixup. The minimization of (4) is typically performed by stochastic gradient descent, where ? is sampled at each iteration to obtain a stochastic gradient. In practice, <ref type="bibr" target="#b43">Zhang et al. (2018)</ref> suggest to sample minibatches of training pairs, and generate Mixup random pairs within the minibatch, which also produces a stochastic gradient of (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Mixup as a perturbed ERM</head><p>The Mixup risk (4) is defined as a sum over pairs of samples, making a comparison with standard ERM approaches (2) not direct. The following result shows that the Mixup risk can be equivalently rewritten as a standard empirical risk, over modified input/output pairs (as in the third plot of <ref type="figure">Figure 1</ref>), subject to random perturbations.</p><formula xml:id="formula_10">Theorem 1 Let ? ? Beta [ 1 2 ,1] (?, ?) and j ? Unif([n]</formula><p>) be two random variables with ? &gt; 0, n &gt; 0 and let ? = E ? ?. For any training set S n , let ( x i , y i ) for any i ? [n] be the modified input/output pair given by</p><formula xml:id="formula_11">x i = x + ?(x i ? x) , y i = y + ?(y i ? y) ,<label>(5)</label></formula><p>and (? i , ? i ) be the random perturbations given by:</p><formula xml:id="formula_12">? i = (? ? ?)x i + (1 ? ?)x j ? (1 ? ?)x , ? i = (? ? ?)y i + (1 ? ?)y j ? (1 ? ?)y .<label>(6)</label></formula><p>Then for any i ? [n], E ?,j ? i = E ?,j ? i = 0, and for any function f ? H,</p><formula xml:id="formula_13">E Mixup (f ) = 1 n n i=1 E ?,j ( y i + ? i , f ( x i + ? i )) .<label>(7)</label></formula><p>Both ? i and ? i are random vectors because they are functions of ? and j in <ref type="formula" target="#formula_12">(6)</ref>, which are themselves random variables. We hence use the notation E ?,j in (7). Note also ? ? [1/2, 1] meaning that the transformation from (x i , y i ) to ( x i , y i ) in (5) shrinks the inputs and the outputs towards their mean. Theorem 1 and the expression (7) of the Mixup risk allow us to re-interpret Mixup as a combination of two standard techniques: (i) transforming each input/output pair (x i , y i ) into ( x i , y i ), and (ii) adding zero-mean random perturbations (? i , ? i ) to each transformed pair, before minimizing the empirical risk. This helps us to understand the effects of training a model with Mixup by studying each technique and their interaction. In particular, perturbing input data is a classical approach to regularize ERM estimators <ref type="bibr" target="#b6">(Bishop, 1995;</ref><ref type="bibr" target="#b35">Srivastava et al., 2014;</ref><ref type="bibr" target="#b40">Wager et al., 2013;</ref><ref type="bibr" target="#b41">Wei et al., 2020)</ref>, and we study in detail in the next section the particular regularization induced by the Mixup perturbations on both inputs and outputs, before interpreting the resulting regularization aspects of Mixup due to both data transformation and perturbation in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The regularization effects of Mixup</head><p>We now study the effect of the random perturbations (? i , ? i ) for i ? [n] in the Mixup risk <ref type="bibr">(7)</ref>. While perturbing inputs with additive or multiplicative noise (e.g., dropout), and independently perturbing outputs (resulting, e.g., in label smoothing) have been widely studied, the Mixup perturbation <ref type="formula" target="#formula_13">(7)</ref> is unique in the sense that it is applied to both inputs and outputs simultaneously, and that the input and output perturbations are not independent from each other by <ref type="formula" target="#formula_12">(6)</ref>. In order to study the regularization effect of these perturbations, we first characterize the covariance structure among the input and output perturbations.</p><p>Lemma 2 Let ? and ? 2 be respectively the mean and variance of a Beta [ 1 2 ,1] (?, ?) distributed random variable, and</p><formula xml:id="formula_14">? 2 = ? 2 + (1 ? ?) 2 . For any i ? [n], let ? (i) x x = ? 2 ( x i ? x)( x i ? x) + ? 2 ? x x ? 2 , ? (i) y y = ? 2 ( y i ? y)( y i ? y) + ? 2 ? y y ? 2 , ? (i) x y = ? 2 ( x i ? x)( y i ? y) + ? 2 ? x y ? 2 .<label>(8)</label></formula><p>Then, for any i ? [n], the random perturbations defined in (6) satisfy</p><formula xml:id="formula_15">E ?,j ? i ? i = ? (i) x x , E ?,j ? i ? i = ? (i) y y , and E ?,j ? i ? i = ? (i) x y .<label>(9)</label></formula><p>Following recent lines of work that interpret various random perturbations such as dropout as regularization <ref type="bibr" target="#b40">(Wager et al., 2013;</ref><ref type="bibr" target="#b41">Wei et al., 2020)</ref>, we can now introduce and study an approximate Mixup risk:</p><formula xml:id="formula_16">E Mixup Q (f ) = 1 n n i=1 E ?,j (i) Q ( y i + ? i , f ( x i + ? i )) ,<label>(10)</label></formula><p>obtained by replacing the loss function ( y, f ( x)) by a second-order quadratic Taylor approximation near each modified input/output training pairs ( x i , y i ), namely, for any i ? [n] and (?, ?) ? X ? Y:</p><formula xml:id="formula_17">(i) Q ( y i + ?, f ( x i + ?)) = ( y i , f ( x i )) + ? y ( y i , f ( x i )) ? + ? u ( y i , f ( x i )) ? x f ( x i )? + 1 2 ?? , ?f ( x i ) ? 2 uu ( y i , f ( x i ))?f ( x i ) + ? u ( y i , f ( x i ))? 2 f ( x i ) + 1 2 ?? , ? 2 yy ( y i , f ( x i )) + ?? , ? 2 yu ( y i , f ( x i ))?f ( x i ) ,<label>(11)</label></formula><p>assuming both and f are twice continuously differentiable. Due to its quadratic form as a function of input and output perturbations, the approximate Mixup risk <ref type="formula" target="#formula_6">(10)</ref> can be re-expressed as a regularized ERM risk, as shown in the next result. We note that the expression we derive is in fact valid for any joint perturbation of the inputs and outputs with covariance structure given in <ref type="formula" target="#formula_15">(9)</ref>.</p><p>Theorem 3 For any twice continuously differentiable loss (y, u), the approximate Mixup risk at any twice differentiable f ? H satisfies</p><formula xml:id="formula_18">E Mixup Q (f ) = 1 n n i=1 ( y i , f ( x i )) + R 1 (f ) + R 2 (f ) + R 3 (f ) + R 4 (f ) ,<label>(12)</label></formula><p>where</p><formula xml:id="formula_19">R 1 (f ) = 1 2n n i=1 ?f ( x i ) ? J (i) ? 2 uu ( y i , f ( x i )) 1 2 2 ? (i) x x , R 2 (f ) = 1 2n n i=1 ? (i) x x , ? u ( y i , f ( x i ))? 2 f ( x i ) , R 3 (f ) = ? 1 2n n i=1 ? (i) x y ? 2 yu ( y i , f ( x i )) ? 2 uu ( y i , f ( x i )) ? 1 2 2 ? (i) x x ?1 , R 4 (f ) = 1 2n n i=1 ? (i) y y , ? 2 yy ( y i , f ( x i )) , and ?i ? [n], J (i) = ? ? 2 uu ( y i , f ( x i )) ?1 ? 2 uy ( y i , f ( x i ))? (i) y x ? (i) x x ?1 .<label>(13)</label></formula><p>Theorem 3 captures the effect of the random perturbations in Mixup as a sum of four penalty terms R i (f ) for i ? [4]. They regularize the simple ERM risk applied on the modified inputs x i and smoothed outputs y i . Before discussing the accuracy and practical consequences of this reformulation of Mixup as regularized empirical risk minimization on modified data in the next Section, we now derive the details of this approximation for the cross-entropy, logistic and squared error losses. We begin by presenting the results for the cross-entropy loss:</p><formula xml:id="formula_20">Corollary 4 Let S : R c ? R c be the softmax operator, i.e., for any i ? [c] and u ? R c , S(u) i = e u i / c j=1 e u j , and let H(u) = diag(S(u)) ? S(u)S(u) ? R c?c .</formula><p>The approximate Mixup risk for the cross-entropy loss satisfies</p><formula xml:id="formula_21">E Mixup Q (f ) = 1 n n i=1 CE ( y i , f ( x i )) + R CE 1 (f ) + R CE 2 (f ) + R CE 3 (f ) , where R CE 1 (f ) = 1 2n n i=1 ?f ( x i ) ? J (i) H(f ( x i )) 1 2 2 ? (i) x x , R CE 2 (f ) = 1 2n n i=1 ? (i) x x , (S(f ( x i )) ? y i ) ? 2 f ( x i ) , R CE 3 (f ) = ? 1 2n n i=1 ? (i) x y H(f ( x i )) ? 1 2 2 ? (i) x x ?1 , with ?i ? [n] , J (i) = H(f ( x i )) ?1 ? (i) y x ? (i) x x ?1 .<label>(14)</label></formula><p>In the binary classification setting, minimizing the empirical cross-entropy risk over f : X ? R 2 after one-hot encoding of the two possible classes in R 2 as <ref type="formula" target="#formula_6">(0, 1)</ref> and <ref type="formula" target="#formula_6">(1, 0)</ref> is equivalent to minimizing the following well-known logistic loss over f : X ? R after encoding the two classes in R as 0 and 1:</p><formula xml:id="formula_22">LR (y, u) = log(1 + e u ) ? yu .<label>(15)</label></formula><p>The regularization effect of Mixup in that case is detailed in the following result:</p><p>Corollary 5 Let s : R ? R be the sigmoid operator, i.e., for any u ? R, s(u) = (1 + e ?u ) ?1 , and let v(u) = s(u)(1 ? s(u)) ? R. The approximate Mixup risk for the logistic regression loss satisfies</p><formula xml:id="formula_23">E Mixup Q (f ) = 1 n n i=1 LR ( y i , f ( x i )) + R LR 1 (f ) + R LR 2 (f ) + R LR 3 (f ) , where R LR 1 (f ) = 1 2n n i=1 v(f ( x i )) ?f ( x i ) ? J (i) 2 ? (i) x x , R LR 2 (f ) = 1 2n n i=1 (s(f ( x i )) ? y i ) ? (i) x x , ? 2 f ( x i ) , R LR 3 (f ) = ? 1 2n n i=1 v(f ( x i )) ?1 ? (i) y x ? (i) x x ?1 ? (i) x y , . with ?i ? [n], J (i) = ? (i) y x ? (i) x x ?1 v(f ( x i )) .<label>(16)</label></formula><p>The next result summarizes the form of the approximate Mixup risk in the case of the squared error loss, and shows in particular that Mixup has no effect for linear least-squares regression models.</p><p>Corollary 6 The approximate Mixup risk for the squared error loss satisfies</p><formula xml:id="formula_24">E Mixup Q (f ) = 1 n n i=1 SE ( y i , f ( x i )) + R SE 1 (f ) + R SE 2 (f ) + C ,<label>(17)</label></formula><p>where C is a constant independent of f and</p><formula xml:id="formula_25">R SE 1 (f ) = 1 2n n i=1 ?f ( x i ) ? J (i) 2 ? (i) x x and R SE 2 (f ) = 1 2n n i=1 ? (i) x x , (f ( x i ) ? y i ) ? 2 f ( x i ) , with ?i ? [n], J (i) = ? (i) y x ? (i) x x ?1 .<label>(18)</label></formula><p>In particular, when we consider linear models with intercept of the form</p><formula xml:id="formula_26">f W,b (x) = W x + b for (W, b) ? R c?d ? R c , then the exact Mixup risk satisfies E Mixup (f W,b ) = 2? 2 + 2? 2 + (1 ? ?) 2 2n n i=1 SE (y i , f W,b (x i )) + b ? b 2 + C ,<label>(19)</label></formula><p>where C is a constant that does not depend on (W, b) and b = y ? W x. Consequently, the linear model that minimizes E Mixup is the standard multivariate ordinary least squares (MOLS) predictor that minimizes E ERM on the original data, i.e., Mixup has no effect on linear least-squares regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion and experiments</head><p>Let us now discuss how our analysis relates to a recent similar study by <ref type="bibr" target="#b44">Zhang et al. (2021)</ref>, and empirically assess the validity of our analysis and the regularization properties of Mixup it suggests. To support our discussion, we provide empirical results on CIFAR-10/100 and ImageNet for different networks (LeNet, ResNet-34/50). For each experimental result we report mean and 95% confidence interval using 10 repetitions (unless stated otherwise Validity of the Taylor approximation. To analyze the regularization effect of Mixup, we used a quadratic approximation of the loss function (11). We note that compared to similar approximations that have been proposed to study the regularization effect of input perturbation only, such as dropout <ref type="bibr" target="#b40">(Wager et al., 2013;</ref><ref type="bibr" target="#b41">Wei et al., 2020)</ref>, we must include in the Taylor expansion all second-order terms involving the input perturbation only (term with ?? ), the output perturbation only (term with ?? ), and their interaction (term with ?? ). In the absence of output perturbation (e.g., in the case of dropout), only the term in ?? matters, and in the absence of correlation between input and output perturbation (e.g., dropout combined with independent label smoothing), then the term in ?? does not matter either.</p><p>Mixup is unique in the correlation it creates between input and output perturbations, which is captured by the interaction term with ?? in (11). Regarding the validity of the Taylor approximation, we note that, as for similar work on input perturbation, the approximate Mixup risk <ref type="formula" target="#formula_6">(10)</ref> is only a good approximation to the Mixup risk for "small" perturbations; as noted by <ref type="bibr">Wei et al. (2020, Annex A.2)</ref>, though, this often remains valid even for "large" input perturbation followed by a linear transformation layer. To support empirically the validity of the approximation, <ref type="figure">Figure 2</ref> shows the training and test performance of training a LeNet on CIFAR-10 using Mixup (minimizing (4)), and using the approximate Mixup formulation (minizing (12)), where we dropped the term R 2 (f ) in the regularization since it empirically induces numerical instability due to it non-convexity (see also <ref type="bibr" target="#b41">Wei et al., 2020,</ref> for a discussion about discarding the Hessian regularization  using the approximate Mixup formulation, we learn functions which mimic, both in training and test, the performance of functions learned when training with the standard Mixup procedure. To further mark the validity of the approximation and decouple the contributions of the data transformation (5) and the input perturbation (6), we evaluate for functions learned with Mixup (4), ERM (2) and ERM on modified data:</p><formula xml:id="formula_27">min f ?Z 1 n n i=1 ( y i , f ( x i )) ,<label>(20)</label></formula><p>the regularization terms of the approximation (12) and the loss on modified data (20). From <ref type="figure" target="#fig_0">Figure 3</ref> we see that the functions learned with Mixup are the ones with the smallest values of the regularization terms but not the smallest loss on modified data, which confirms that the model trained with Mixup finds a trade-off between empirical risk and the regularization we study.</p><p>Data modification at test time. By Theorem 1, we see that Mixup implicitly shrinks inputs towards their mean since the Mixup risk involves the empirical risk over modified inputs x i and outputs y i . In particular, this means that the functions that the standard Mixup procedure learns are not functions from the space of input points X to the output points Y, but it learns functions from X to Y , which are spaces defined by the training points and the hyperparameter ? of Mixup as For centered training data (x = y = 0) and homogeneous functions (f (ux) = uf (x) for any (u, x) ? R + ? X , e.g., linear models or neural networks with ReLU activation and linear transformations), this has no impact as pred f (x) = f (x) in that case. For more general models, however, (22) may be a better predictor than f . For example, we clearly see in <ref type="figure">Figure 1</ref> that the asymptotically Bayes optimal classifier under the Mixup distribution matches the one under the empirical distribution of the modified data (up to regularization effects), and not of the original data. Interestingly, when the classes are balanced, i.e., y = 1 c 1 c , the transformation in (22) adds the same constant to each of the c entries of f . In particular, in the multi-class setting, since the softmax is invariant to a constant in the logits, (22) becomes equivalent to a scaling of the logits, commonly referred to as temperature scaling <ref type="bibr" target="#b14">(Guo et al., 2017)</ref>. While temperature scaling is traditionally tuned with a validation set <ref type="bibr" target="#b14">(Guo et al., 2017)</ref>, mixup automatically sets this value, according to the distribution of ?. To point out the advantages of using (22), we compare in <ref type="figure">Figure 4</ref> the performance of ERM, standard Mixup (for different ? values), the same Mixup but with the proper data transformation <ref type="formula" target="#formula_7">(22)</ref> at test time and the same data transformation applied to the ERM estimator. The trained networks are ResNet-34 for CIFAR-10 and CIFAR-100, and ResNet-50 for ImageNet. For CIFAR-10 and 100, we observe overall benefits of using the data transformation for evaluating the functions learned with Mixup: higher test accuracy, lower test loss, and lower expected calibration error (ECE). For ImageNet we have the same benefits, with the only exception of the test loss and the ECE for very low values of ?. Notice indeed that for small values of ? the data transformation (22) has a smaller impact than for bigger values of ?, as lim ??0 ? = 1 while lim ??+? ? = 1 2 . Thus, as observed empirically, the "correction" (22) is more important, as it brings bigger improvements, when training Mixup with bigger ?. Finally, we can observe that when the data transformation (22) is applied to ERM, performance always deteriorate. This supports that <ref type="formula" target="#formula_7">(22)</ref> is a mixup specific improvement. Algorithm 1 shows the few lines of codes that implement the new prediction procedure (22). <ref type="figure">Fig. 4</ref>: Test accuracy, test cross-entropy loss and test expected calibration error (first, second and third column respectively) on the CIFAR-10, CIFAR-100, ImageNet datasets (first, second and third row respectively). We report the mean and the standard error over 10 repetitions for CIFAR-10 and CIFAR-100 and 5 repetitions for ImageNet. The training was done with ResNet-34 for CIFAR-10, CIFAR-100, and with ResNet-50 for ImageNet.</p><formula xml:id="formula_28">X = {x + ?(x ? x) | ?x ? X } , Y = {y + ?(y ? y) | ?y ? Y} ,<label>(21)</label></formula><p>Data modification for out-of-distribution data. Even though our theoretical analysis holds only for in-distribution data, we now empirically investigate whether the benefits of rescaling data at test time that we observe for models trained with Mixup also hold when the test time data come from a different distribution, a setting called out-of-distribution (OOD) data <ref type="bibr" target="#b20">(Hendrycks and Gimpel, 2017)</ref>. Indeed, standard Mixup is known to provide some benefits in out-of-distribution settings compared to models simply trained by ERM, so it is interesting to assess whether the data modification scheme we propose can further boost the accuracy and calibration of models trained with Mixup in that setting. In particular we consider CIFAR-10-C, CIFAR-100-C, ImageNet-C <ref type="bibr" target="#b19">(Hendrycks and Dietterich, 2019)</ref>, ImageNet-A <ref type="bibr" target="#b21">(Hendrycks et al., 2021)</ref>, ImageNetV2 <ref type="bibr" target="#b31">(Recht et al., 2019)</ref>, ImageNet-Vid-Robust, YTBB-Robust <ref type="bibr" target="#b34">(Shankar et al., 2021)</ref>, ObjectNet <ref type="bibr" target="#b3">(Barbu et al., 2019)</ref>. These benchmark datasets are designed by systematically perturbing in a controlled way the in-distribution data (CIFAR-10, CIFAR-100 and ImageNet), e.g., by adding noise or applying transformations to the images. <ref type="table" target="#tab_6">Table 2</ref> details the performance of models trained with Mixup for ? = 0.25 and ? = 0.5, with or without data modification at test time, on out-of-distribution datasets derived from ImageNet, while <ref type="figure">Figure 5</ref> shows similar results for benchmarks derived from CIFAR-10 and CIFAR-100. We see that for most datasets the rescaling improves accuracy and some of the other metrics, but for others and in particular CIFAR-10-C, CIFAR-100-C third column respectively) on the CIFAR-10-C, CIFAR-100-C (first, and second row respectively). We report the mean and the standard error over 10 repetitions. The training was done with ResNet-34 on the standard CIFAR-10, CIFAR-100. <ref type="figure">Fig. 6</ref>: Difference in test performance between Mixup and rescaled Mixup on CIFAR-10-C, CIFAR-100-C for the different corruption intensities. The training was done with ResNet-34 on the standard CIFAR-10, CIFAR-100 dataset and the performance metrics are accuracy, cross-entropy loss, expected calibration error.</p><p>and ImageNet-C, the rescaling worsen almost all metrics with respect of the standard Mixup. We now investigate how the performance of Mixup with or without rescaling differs with respect to the intensity of the noise.   <ref type="bibr" target="#b19">(Hendrycks and Dietterich, 2019)</ref>. For each metric means and standard errors over 10 repetitions are reported.</p><p>In details, the CIFAR-10-C and CIFAR-100-C data are 95 different corrupted versions each of the original CIFAR-10, CIFAR-100 test sets: 19 different corruption types, for 5 different growing corruption intensities. The results that we reported in <ref type="figure">Figure 5</ref> are the averages of the performance of these 95 test sets. In <ref type="figure">Figure 6</ref> instead, for Mixup and rescaled Mixup, we compute the average of the different metrics (test accuracy, test cross-entropy loss, ECE) over the 19 corruption types for each corruption intensity, and we report the difference in performance between Mixup and rescaled Mixup. We can see that as the noise intensity grows the gap between the two methods always grows in favor of standard Mixup, and that only for a few metrics and settings with low noise the rescaled version is better than the standard one. This observations encourage future investigations of the effect of Mixup on OOD data 3 .</p><p>Label smoothing. The transformation that modifies the original labels y i onto y i acts as some form of label smoothing, a technique known to often improve accuracy and calibration <ref type="bibr" target="#b36">(Szegedy et al., 2016;</ref><ref type="bibr" target="#b26">M?ller et al., 2019)</ref>. The transformed labels y i are indeed pulled towards the average label y. Recall from <ref type="bibr" target="#b36">Szegedy et al. (2016)</ref> that label smoothing consists in training a model on the perturbed version of the training labels defined as</p><formula xml:id="formula_29">y LS i = (1 ? ?)y i + ?u(i),</formula><p>where ? is a fixed scalar in [0, 1] and u(i) is a fixed distribution over the labels. It is easy to see that for ? = (1 ? ?) and u(i) = y the two formulations coincide. This implies that Mixup implicitly performs label smoothing, and can benefit from this technique in terms of accuracy or calibration. In the following Proposition 7, we formally prove that, in the case of the cross entropy and linear models, label smoothing translates into an increase in the average entropy of the predictions, or, in other words, that predictions become less certain, as observed in practice. Like in Theorem 4, we use the softmax operator S : R c ? ? c defined for j ? [c] by S(u) j = e u j / ( c k=1 e u k ):</p><p>Proposition 7 Let us consider the following two classification problems with a cross-entropy loss and linear model f (</p><formula xml:id="formula_30">x) = W x parameterized by W ? R c?d , min W ?R c?d 1 n n i=1 CE (y i , W x i )<label>(23)</label></formula><p>and</p><formula xml:id="formula_31">min W ?R c?d 1 n n i=1 CE ( y i , W x i )<label>(24)</label></formula><p>defined without and with label smoothing respectively, i.e., with y i = y + ?(y i ? y) ? ? c for i ? [n]. Let us denote by W and W ls a solution of (23) and (24) respectively, together with p i = S(W x i ) and p i = S(W ls x i ).</p><p>It holds that the average entropy of the predictions of W ls is lower bounded as follows</p><formula xml:id="formula_33">? 1 n n i=1 Z(p i ) + (1 ? ?)Z(y) ? 1 n n i=1 Z( p i ).</formula><p>If predicting with W also reduces the entropy of the average predictor, i.e., 1 n n i=1 Z(p i ) ? Z(y), then label smoothing increases the average entropy of the predictions:</p><formula xml:id="formula_34">1 n n i=1 Z(p i ) ? 1 n n i=1 Z( p i ).</formula><p>To illustrate how both Mixup and label smoothing increase the entropy of predictions compared to ERM, we show on <ref type="figure" target="#fig_1">Figure 7</ref> the histograms of the confidence of the estimators' predictions on test points, for a LeNet neural network trained on CIFAR-10. From the first plot, we notice how standard ERM produces very confident predictions, how label smoothing helps decreasing ERM confidence at test time, and how Mixup naturally produces even less confident predictions. From the second plot, we see that that approximate Mixup, like Mixup, produces less confident prediction, which confirms that the Mixup approximation we study captures well this behavior of Mixup. Jacobian regularization. The first implicit regularization term R 1 (f ) in Theorem 3 penalizes the discrepancy between ?f ( x i ) and J (i) given by (13). We recognize in J (i) the Jacobian of the standard MOLS model trained in the input space on the modified training set, with an increased weight for sample ( x i , y i ) in J (i) . Compared to, e.g., dropout regularization with penalizes the norm of ?f at the training points, we therefore see that Mixup also regularizes the Jacobian of f but with a different and more informative implicit bias, namely, to mimic a good linear model in the input space. Furthermore, we note from the proof of Theorem 3 that this implicit bias results from the correlation between input and output noise, which may explain why independent Mixup in the input and output performs more poorly than standard Mixup <ref type="bibr" target="#b43">(Zhang et al., 2018)</ref>. While this regularization is similar across all points in the squared loss setting (Corollary 6), it is weighted by the Hessian H(p(f ( x i ))) in the cross-entropy loss (Corollary 4). Similar to dropout, this implies that this regularization vanishes when the prediction p(f ( x i )) is confidently near 0 or 1. In the Mixup case, though, the label smoothing effect discussed in the previous paragraph tends to prevent over-confident predictions on the training point (see Proposition 7 for a formal description of that property), therefore ensuring that the Jacobian regularization in R 1 (f ) remains active even for "easy" points. This interaction between label smoothing (due to output Mixup) and Jacobian regularization (due to input Mixup) may explain why Mixup on inputs only performs poorly compared to Mixup on both inputs and outputs (Thulasidasan et al., 2019).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this paper we have proposed the first theoretical analysis that explains the multiple regularization effects of Mixup. We have proved that training with Mixup is equivalent to learning on modified data with the injection of structured noise. Through a Taylor approximation, we have further shown that Mixup amounts to empirical risk minimization on modified points plus multiple regularization terms. Fascinatingly, our derivation shows that Mixup induces varied and complex effects, e.g., calibration, Jacobian regularization, label noise and normalization, while being a simple and cheap data augmentation technique. Further, we have shown how this analysis points out a missing rescaling procedure required to evaluate functions learned with Mixup, and we brought empirical evidence that implementing it improves accuracy and calibration. More broadly, we have studied how a specific combination of data modification and noise injection leads to certain regularizers. An interesting research question is whether we can reverse-engineer this process, namely starting from possibly expensive regularizers and design the corresponding data augmentation technique emulating their effects at a lower computational cost.</p><p>A.1 Proof of Theorem 1</p><p>Proof To simplify notations, let us denote, for any i, j ? [n] and u ? [0, 1],</p><formula xml:id="formula_35">m ij (u) = (uy i + (1 ? u)y j , f (ux i + (1 ? u)x j )) .</formula><p>The Mixup risk (4) can then be written as</p><formula xml:id="formula_36">E Mixup (f ) = 1 n 2 n i=1 n j=1 E ? m ij (?) , ? ? Beta(?, ?) .<label>(26)</label></formula><p>We now separate the values of ? depending on whether or not they are above 1/2 by expressing it as</p><formula xml:id="formula_37">? = ?? 0 + (1 ? ?)? 1 , ? 0 ? Beta [0, 1 2 ] (?, ?) , ? 1 ? Beta [ 1 2 ,1] (?, ?) , ? ? Ber 1 2 .<label>(27)</label></formula><p>By symmetry of the Beta(?, ?) distribution around 1/2, it is clear that ? defined in <ref type="formula" target="#formula_7">(27)</ref> follows a Beta(?, ?) distribution, and furthermore that ? 1 = 1 ? ? 0 follows, like ? 1 , a Beta [ 1 2 ,1] (?, ?) distribution. For any i, j ? [n], we therefore get</p><formula xml:id="formula_38">E ? m ij (?) = E ? 0 ,? 1 ,? m ij (?? 0 + (1 ? ?)? 1 ) = 1 2 [E ? 0 m ij (? 0 ) + E ? 1 m ij (? 1 )] = 1 2 E ? 1 m ji (? 1 ) + E ? 1 m ij (? 1 ) ,</formula><p>where we used the fact that m ij (1 ? u) = m ji (u) to get the third equality. Plugging this equality back into (26), we finally get</p><formula xml:id="formula_39">E Mixup (f ) = 1 2n 2 n i=1 n j=1 E ? 1 m ji (? 1 ) + E ? 1 m ij (? 1 ) = 1 n 2 n i=1 n j=1 E ? 1 m ij (? 1 ) = 1 n n i=1 ? ? 1 n n j=1 E ? 1 m ij (? 1 ) ? ? = 1 n n i=1 i ,<label>(28)</label></formula><p>where</p><formula xml:id="formula_40">i = E ?,j (?y i + (1 ? ?)y j , f (?x i + (1 ? ?)x j )) , ? ? Beta [ 1 2 ,1] (?, ?) , j ? Unif([n])</formula><p>.</p><p>We now easily see that x i and y i defined in (5) satisfy</p><formula xml:id="formula_41">x i = E ?,j [?x i + (1 ? ?)x j ] , y i = E ?,j [?y i + (1 ? ?)y j ] ,</formula><p>and furthermore that ? i and ? i defined in (6) satisfy</p><formula xml:id="formula_42">? i = ?x i + (1 ? ?)x j ? E ?,j [?x i + (1 ? ?)x j ] , ? i = ?y i + (1 ? ?)y j ? E ?,j [?y i + (1 ? ?)y j ] ,</formula><p>from which we deduce that E ?,j ? i = E ?,j ? i = 0 and</p><formula xml:id="formula_43">i = E ?,j y i + ? i , f ( x i + ? i ) .</formula><p>Plugging this equality back into (28) concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Proof of Lemma 2</head><p>Proof From the definition of ? i in (6), we easily get:</p><formula xml:id="formula_44">E ?,j ? i ? i = E ? (? ? ?) 2 x i x i + E ? [(1 ? ?) 2 ]E j [x j x j ] + (1 ? ?) 2 xx + E ? [(? ? ?)(1 ? ?)]E j [x i x j + x j x i ] ? (1 ? ?)E ? [1 ? ?]E j [x j x + xx j ] = ? 2 x i x i + ? 2 E j [x j x j ] + (1 ? ?) 2 xx ? ? 2 (x i x + xx i ) ? 2(1 ? ?) 2 xx = ? 2 (x i x i ? x i x ? xx i ) + ? 2 (? xx + xx ) ? (1 ? ?) 2 xx = ? 2 (x i ? x)(x i ? x) + ? 2 ? xx ,<label>(29)</label></formula><p>where we used the independence between ? and j in the first equality; for the second, the facts that</p><formula xml:id="formula_45">E ? (? ? ?) 2 = ? 2 , E ? [(1 ? ?) 2 ] = ? 2 + (1 ? ?) 2 = ? 2 , E ? [(? ? ?)(1 ? ?)] = ? 2 ? E ? [? 2 ] = ?? 2 ,</formula><p>and E ? [1 ? ?] = 1 ? ?; for the third, we reorganized the terms and used the equality E j x j x j = ? xx + xx by definition of the empirical covariance matrix ? xx ; the last equality is obtained by reorganizing the terms and using the definition of ? 2 . In order to write this covariance matrix in terms of modified inputs, we notice that by definition <ref type="formula" target="#formula_11">(5)</ref> we have</p><formula xml:id="formula_46">x i ? x = ( x i ? x)/? and E j x j = E j x j = x,</formula><p>which implies that the empirical covariance matrix of the modified inputs is ? x x = ? 2 ? xx . Combining these equalities with (29) gives the first equality in (9). The two other equalities can be proved exactly the same way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Proof of Theorem 3</head><p>Proof Given a modified input/output pair ( x, y) ? X ? Y and a function f ? H, the second-order Taylor approximation of the loss G( x, y) = ( y, f ( x)) is, for any (?, ?) ? X ? Y:</p><formula xml:id="formula_47">G Q ( x + ?, y + ?) = G( x, y) + ? x G( x, y)? + ? y G( x, y)? + 1 2 ? ? 2 x x G( x, y)? + 1 2 ? ? 2 y y G( x, y)? + ? ? 2 y x G( x, y)? .<label>(30)</label></formula><p>Using this quadratic approximation at each training point i ? [n] in <ref type="formula" target="#formula_13">(7)</ref>, and using the fact that E ?,j ? i = E ?,j ? i = 0, we get</p><formula xml:id="formula_48">E ?,j G Q ( x i + ? i , y i + ? i ) =G( x i , y i ) + 1 2 E ?,j ? i ? i , ? 2 x x G( x i , y i ) + 1 2 E ?,j ? i ? i , ? 2 y y G( x i , y i ) + E ?,j ? i ? i , ? 2 y x G( x i , y i ) ,<label>(31)</label></formula><p>which we can rewrite as follows by expressing the derivatives of G(x, y) = (y, f (x)) in terms of derivatives of (y, u) and f (x):</p><formula xml:id="formula_49">E ?,j Q ( y i + ? i , f ( x i + ? i )) = ( y i , f ( x i )) + 1 2 E ?,j ? i ? i , ?f ( x i ) ? 2 uu ( y i , f ( x i ))?f ( x i ) + ? u ( y i , f ( x i ))? 2 f ( x i ) + 1 2 E ?,j ? i ? i , ? 2 yy ( y i , f ( x i )) + E ?,j ? i ? i , ? 2 yu ( y i , f ( x i ))?f ( x i ) .<label>(32)</label></formula><p>Replacing the expectations in this equation by their values given by Lemma 2 gives:</p><formula xml:id="formula_50">E ?,j Q ( y i + ? i , f ( x i + ? i )) = ( y i , f ( x i )) + 1 2 ? (i) x x , ?f ( x i ) ? 2 uu ( y i , f ( x i ))?f ( x i ) + 1 2 ? (i) x x , ? u ( y i , f ( x i ))? 2 f ( x i ) + 1 2 ? (i) y y , ? 2 yy ( y i , f ( x i )) + ? (i) y x , ? 2 yu ( y i , f ( x i ))?f ( x i ) .<label>(33)</label></formula><p>We now use the following fact, true for any square symmetric and invertible matrices A and C and rectangular matrices B and Y (such that the matrix multiplications below make sense):</p><formula xml:id="formula_51">A, Y CY ? 2 B, Y = A, (Y ? Z) C(Y ? Z) ? A ?1 , B C ?1 B ,<label>(34)</label></formula><p>where Z = C ?1 BA ?1 , to combine the second and fifth terms together. Indeed, the fifth term (33) can be rewritten as</p><formula xml:id="formula_52">? (i) y x , ? 2 yu ( y i , f ( x i ))?f ( x i ) = ? 2 uy ( y i , f ( x i ))? (i) y x , ?f ( x i ) , ,</formula><p>so plugging into (34) the following matrices:</p><formula xml:id="formula_53">? ? ? ? ? ? ? ? ? ? ? A = ? (i) x x , B = ?? 2 uy ( y i , f ( x i ))? (i) y x , C = ? 2 uu ( y i , f ( x i )) , Y = ?f ( x i ) , gives 1 2 ? (i) x x , ?f ( x i ) ? 2 uu ( y i , f ( x i ))?f ( x i ) + ? (i) y x , ? 2 yu ( y i , f ( x i ))?f ( x i ) = 1 2 ? (i) x x , ?f ( x i ) ? J (i) ? 2 uu ( y i , f ( x i )) ?f ( x i ) ? J (i) ? 1 2 ? (i) y x ? (i) x x ?1 ? (i) x y , ? 2 yu ( y i , f ( x i ))? 2 uu ( y i , f ( x i )) ?1 ? 2 uy ( y i , f ( x i ))<label>(35)</label></formula><p>where J (i) is defined in <ref type="formula" target="#formula_6">(13)</ref>. Theorem 3 then follows by merging the second and fifth terms in (33) using <ref type="formula" target="#formula_11">(35)</ref>, and summing over i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Proof of Corollary 4</head><p>Proof For the definition (3) of the cross-entropy loss CE (y, u), we easily get: Plugging these results back in the four regularization terms in Theorem 3 we conclude the proof.</p><formula xml:id="formula_54">? y CE (y, u) = ?u , ? u CE (y, u) = (S(u) ? y) ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Proof of Corollary 5</head><p>Proof For the definition (15) of the logistic regression loss LR (y, u), we easily get: Plugging these results back in the four regularization terms in Theorem 3 we conclude the proof.</p><formula xml:id="formula_55">? y LR (y, u) = ?u , ? u LR (y, u) = s(u) ? y ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 Proof of Corollary 6</head><p>Proof For the definition (3) of the squared error loss SE (y, u), we easily get:</p><formula xml:id="formula_56">? y SE (y, u) = (y ? u) , ? u SE (y, u) = (u ? y) , ? 2 yy SE (y, u) = ? 2 uu SE (y, u) = I c , ? 2 yu SE (y, u) = ?I c .</formula><p>Plugging these results back in the 4 regularization terms in Theorem 3 proves <ref type="formula" target="#formula_6">(17)</ref>.</p><p>When f is a linear function with intercept of the form f W,b (x) = W x + b, then we first note that SE (y, f W,b (x)) is a quadratic function of (x, y), so the second-order Taylor approximation (11) is exact in that case:</p><formula xml:id="formula_57">SE(i) Q (y, f W,b (x)) = SE (y, f W,b (x)) for any i ? [n]</formula><p>and (x, y) ? X ? Y, and consequently:</p><formula xml:id="formula_58">?(W, b) ? R c?d ? R c , E Mixup Q (f W,b ) = E Mixup (f W,b ) .</formula><p>Applying <ref type="formula" target="#formula_6">(17)</ref> to the case of a linear function f W,b gives us immediately R SE 2 (f W,b ) = 0, because ? 2 f W,b = 0. For the first regularization term, we compute</p><formula xml:id="formula_59">R SE 1 (f W,b ) = 1 2n n i=1 ?f ( x i ) ? J (i) 2 ? (i) x x = 1 2n n i=1 W ? J (i) 2 ? (i) x x = 1 2n n i=1 W W , ? (i) x x ? 2 W, ? (i) y x + C = 1 2n n i=1 ? ? ? 2 n? 2 n j=1 W ( x j ? x) ? ( y j ? y) 2 + ? 2 ? 2 W ( x i ? x) ? ( y i ? y) 2 ? ? + C = ? 2 + ? 2 2n? 2 n i=1 W ( x i ? x) ? ( y i ? y) 2 + C = 2? 2 + (1 ? ?) 2 2n n i=1 W (x i ? x) ? (y i ? y) 2 + C .<label>(36)</label></formula><p>As for the empirical risk term, we can also rewrite it as</p><formula xml:id="formula_60">1 n n i=1 SE ( y i , f W,b ( x i )) = 1 n n i=1 W x i + b ? y i 2 = 1 n n i=1 W ( x i ? x) ? ( y i ? y) + (b ? b) 2 = 1 n n i=1 W ( x i ? x) ? ( y i ? y) 2 + b ? b 2 = ? 2 n n i=1 W (x i ? x) ? (y i ? y) 2 + b ? b 2<label>(37)</label></formula><p>Plugging <ref type="formula" target="#formula_12">(36)</ref> and <ref type="formula" target="#formula_13">(37)</ref> into <ref type="formula" target="#formula_6">(17)</ref> finally gives <ref type="formula" target="#formula_6">(19)</ref>. To see that the minimizer of (19) is the standard MOLS solution, we notice that the obvious solution for b is b = b, which is the intercept of MOLS, while the solution for W should minimize the sum of squared errors over centered points, which is exactly what MOLS does.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.7 Proof of Proposition 7</head><p>Proof We first start by deriving a dual formulation for (24). The derivation for (23) follows along the same lines, up to the replacement of y i by y i .</p><p>Introducing primal variables u i ? R c for i ? [n] with equality constraints W x i = u i and the dual variables ? i ? R c , we obtain the following Lagrangian (see <ref type="bibr" target="#b8">Boyd and Vandenberghe (2004)</ref>):</p><formula xml:id="formula_61">L({u i , ? i } n i=1 , W ) = 1 n n i=1 CE ( y i , u i ) + ? i (W x i ? u i ) = 1 n n i=1 log c j=1 e (u i ) j ? (? i + y i ) u i + W, 1 n n i=1 ? i x i .</formula><p>We recall that the entropy is concave and is the Fenchel conjugate, up to a sign flip, of the log-sum-exp function</p><formula xml:id="formula_62">Z(p) = ? max t?R c p t ? log c j=1 e t j ,<label>(38)</label></formula><p>as for instance detailed in Example 5.5 of (Boyd and Vandenberghe, 2004). We therefore derive the dual function using (38) </p><formula xml:id="formula_63">min {u i } n i=1 ,W L({u i , ? i } n i=1 , W ) = 1 n n i=1 Z(? i + y i ) if</formula><p>where we have made the change of variables ? i = ? i + y i . The dual problem for (23) is identical to (39) up to the replacement of y i by y i . Recalling the definitons in (25) and exploiting the first-order optimality conditions of (23) and (24), we have n i=1 (p i ? y i )x i = 0 and n i=1 ( p i ? y i )x i = 0, so that { p i } n i=1 is feasible for the dual problem (39). Since strong duality applies <ref type="bibr" target="#b8">(Boyd and Vandenberghe, 2004)</ref>, it also holds that { p i } n i=1 maximize (39). Let us consider {q i } n i=1 defined for i ? [n] by q i = ?p i + (1 ? ?)y.</p><p>We can easily observe that q i ? ? c as convex combination of p i , y ? ? c and that</p><formula xml:id="formula_65">n i=1 (q i ? y i )x i = ? n i=1 (p i ? y i )x i + (1 ? ?) n i=1 (y ? y)x i = 0.</formula><p>This implies that {q i } n i=1 is feasible for (39) and we have</p><formula xml:id="formula_66">1 n n i=1 Z(q i ) ? 1 n n i=1 Z( p i ).</formula><p>We get the advertised result by using the concavity of Z so that ?Z(p i ) + (1 ? ?)Z(y) ? Z(q i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiments</head><p>B.1 CIFAR-10 and CIFAR-100</p><p>To learn on CIFAR-10, CIFAR-100 we use ResNet-34 and LeNet. For both architectures the optimizer used for training is SGD with momentum 0.9 for 200 epochs with mini-batch size 128, weight-decay 5 ? 10 ?4 . For ResNet-34 the learning rate is 0.1 reduced by a factor 10 at epoch 60, 120, 160. For LeNet the learning rate is 0.01 reduced by a factor 10 at epoch 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 ImageNet</head><p>To learn on the ImageNet we use ResNet-50. The optimizer used for training is SGD with Nesterov and momentum 0.9 for 200 epochs with mini-batch size 4096 (32 numbers of cores ?128 per core batch-size), weight-decay 5 ? 10 ?5 . The learning rate is 1.6 reduced by a factor 10 at epoch 66, 133, 177.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Two Moons with Random Features</head><p>We report in <ref type="figure">Figure 8</ref> and <ref type="figure">Figure 9</ref> some more results on a synthetic binary classification problem (noisy two-moon problem), where we train a logistic regression model with random Fourier features <ref type="bibr" target="#b30">(Rahimi and Recht, 2008)</ref>. This allowed us to get rid of convergence issues due to the convexity of the problem, but still work with nonlinear models of the input points.</p><p>For each experimental result we report mean and 95% confidence interval using 30 repetitions over 30 different instances of the data. What we notice from these results is similar behaviors as reported for CIFAR-10, CIFAR-100, ImageNet in the main paper.  Data generation. To generate the data we use the sklearn.datasets.make_moons function from the scikit-learn library. We create n = 300 points with noise= 0.01, and split them in 50% for train and 50% for test. We then randomly flip 20% of the training labels to make the learning task more difficult. We repeat this pipeline 30 times for 30 different random seeds. Optimization. To minimize any functional we use stochastic gradient descent with minibatching, with mini-batch size b = 50 and step-size ? = 5.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 :</head><label>3</label><figDesc>Evaluations of the regularization terms of the mixup approximation (left) and of the loss on modified data (right) for functions learned with Mixup, ERM and ERM on modified data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 7 :</head><label>7</label><figDesc>Histograms of confidence of predictions for models trained with different techniques.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>n</head><label></label><figDesc>i=1 ? i x i = 0 and ? i + y i ? ? c , i ) subject to ? i ? ? c , i ? [n], and n i=1 (? i ? y i )x i = 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 :Fig. 9 :</head><label>89</label><figDesc>From left to right: train loss, train and test accuracy during optimization of a logistic regression model trained on the noisy two-moon problem with Mixup, Mixup (rescaled), approximate Mixup and ERM risks. Histograms of confidence of predictions on test points, for models trained with different techniques.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Function</head><label></label><figDesc>space. Let M = 1000, w ? R M and ? : R d ? R M be the feature map defined as ?(x) = 1 ? M cos(Sx + B), where cos : R M ? R M is the element-wise cosine function, S ? R M ?d is the random matrix s.t. S i,j ? N (0, ? 2 ), ?i ? [M ], j ? [d] with ? = 10, and B ? R M s.t. B i ? Unif(0, 2?), ?i ? [M ].The space of candidate solutions H we consider is the class of functions of the form f (x) = w ?(x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Summary of the effects induced by various regularizers. Absence of checkmark means the corresponding effect is not known for this regularizer.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>). All details about experiments are provided in Appendix B, together with other experiments on the simpler setting of learning on the two-moon dataset with random features.Comparison with related work.<ref type="bibr" target="#b44">Zhang et al. (2021)</ref> independently published a similar analysis of the regularization effect of Mixup. Both works provide complementary and coherent views of the effect of Mixup on generalization and robustness, and differ in a few technical aspects that we clarify here. First, we provide an analysis valid for any loss (y, u), where y and u are respectively the predicted and true outputs, while<ref type="bibr" target="#b44">Zhang et al. (2021)</ref> restrict their analysis to the losses of the form (y, u) = h(u)?yu for some function h. Second, Mixup example. One consequence is that our Taylor approximation converges to the exact Mixup risk when the amount of Mixup reduces (i.e., when ? ? +? in the Beta(?, ?) distribution of the mixing parameter), while the one used by<ref type="bibr" target="#b44">Zhang et al. (2021)</ref> does not 2 . Third, the generalization analysis of<ref type="bibr" target="#b44">Zhang et al. (2021)</ref> for generalized linear models (GLM) is performed for a variant of Mixup where the mixed input is x i + (1/? ? 1)x j , while we focus on the standard Mixup ?x i + (1 ? ?)x j . A consequence of this difference is that we identify the importance of rescaling data at test time for standard Mixup (see below), while no such rescaling is needed in the variant considered by<ref type="bibr" target="#b44">Zhang et al. (2021)</ref>. Finally,<ref type="bibr" target="#b44">Zhang et al. (2021)</ref> explore the link between Mixup-induced regularization and adversarial robustness and generalization through Rademacher complexity analysis, which we do not explore in this work but could be done in a similar manner.</figDesc><table><row><cell>0.8 1.0 1.2 1.4 Train loss</cell><cell>0</cell><cell>50</cell><cell>100 Epoch CIFAR10 LeNet Mixup 150 Approximate Mixup 200</cell><cell>0.8 1.0 1.2 1.4 Test loss</cell><cell>0</cell><cell>50</cell><cell>100 Epoch CIFAR10 LeNet Mixup 150 Approximate Mixup 200</cell><cell>0.75 0.50 0.60 0.65 0.70 Test accuracy 0.55</cell><cell>0</cell><cell>50</cell><cell>100 Epoch CIFAR10 LeNet Mixup 150 Approximate Mixup 200</cell></row></table><note>while both works use a second-order Taylor expansion to approximate the loss at a Mixup example, the expansions are different since we do a Taylor expansion near the expected value of the Mixup example, while Zhang et al. (2021, Lemma 3.1) do a Taylor expansion near a non-Fig. 2: From left to right: train loss, test loss and accuracy during optimization of LeNet on CIFAR-10 with Mixup and approximate Mixup.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>). We can see how when training</figDesc><table><row><cell>R(f)</cell><cell>0.00 0.02 0.04 0.06 0.10 0.08</cell><cell></cell><cell>CIFAR10 LeNet</cell><cell cols="2">Mixup ERM on , ERM</cell><cell>1.9 1.4 1.5 1.6 1.7 1.8 i = 1 (y 1 n n i , f(x i ))</cell><cell></cell><cell>CIFAR10 LeNet</cell><cell cols="2">Mixup ERM ERM on ,</cell></row><row><cell></cell><cell>0</cell><cell>50</cell><cell>100 Epoch</cell><cell>150</cell><cell>200</cell><cell>0</cell><cell>50</cell><cell>100 Epoch</cell><cell>150</cell><cell>200</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>where x and y are respectively the average training inputs and outputs points, and ? = E ? ? as defined in Theorem 1. An important consequence is that the function f : X ? Y estimated by Mixup, should ideally be applied at test time to transformed data, to map the test point x test ? X to x test ? X, and the evaluation of the function f ( x Algorithm 1 python code to evaluate according to (22) functions learned with mixup Input: X_test Tensor of test points to evaluate, trained_mode Model trained using mixup, alpha float hyperparameter used by mixup during training, X_train, Y_train Tensor of points used for training with one-hot encoded labels.</figDesc><table><row><cell>import scipy.special as sc</cell></row><row><cell>import torch</cell></row><row><cell>X_bar = torch.mean(X_train, dim=0, keepdim=True)</cell></row><row><cell>Y_bar = torch.mean(Y_train, dim=0, keepdim=True)</cell></row><row><cell># expectation of a truncated beta distribution in [0.5, 1]</cell></row><row><cell>theta_bar = 1. -sc.betainc(alpha + 1., alpha, .5)</cell></row><row><cell>def predict_mixup(X_test, trained_model):</cell></row><row><cell>f_X = trained_model.forward((1. -theta_bar) * X_bar + theta_bar * X_test)</cell></row><row><cell>return Y_bar * (1. -1. / theta_bar) + f_X / theta_bar</cell></row><row><cell>(22)</cell></row></table><note>test ) ? Y should be mapped back to Y. In details, the prediction for point x test should be predf (x test ) = y 1 ? 1/? + 1/? ? f ?x test + (1 ? ?)x .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>7764?0.0022 0.7754?0.0021 0.7780?0.0006 0.7766?0.0009 CE-loss 0.8820?0.0092 0.8964?0.0113 0.8852?0.0046 0.9482?0.0188 ECE 0.0291?0.0031 0.0236?0.0058 0.0280?0.0040 0.0707?0.0127</figDesc><table><row><cell>ImageNet</cell><cell>Metric</cell><cell>mixup(rescaled)</cell><cell>mixup</cell><cell>mixup(rescaled)</cell><cell>mixup</cell></row><row><cell></cell><cell></cell><cell>? = 0.25</cell><cell></cell><cell>? = 0.5</cell><cell></cell></row><row><cell cols="6">standard 0.A Acc Acc 0.0165?0.0011 0.0165?0.0011 0.0229?0.0004 0.0225?0.0005 CE-loss 7.3395?0.0884 6.8075?0.0687 7.1010?0.0879 6.3738?0.0506</cell></row><row><cell></cell><cell>ECE</cell><cell cols="4">0.4322?0.0072 0.3629?0.0075 0.4318?0.0110 0.3161?0.0117</cell></row><row><cell></cell><cell>Acc</cell><cell cols="4">0.4638?0.0021 0.4662?0.0019 0.4719?0.0015 0.4761?0.0011</cell></row><row><cell>C</cell><cell>CE-loss MCE</cell><cell cols="4">2.8050?0.0140 2.7374?0.0094 2.7842?0.0164 2.7206?0.0136 0.6824?0.0025 0.6795?0.0022 0.6735?0.0018 0.6685?0.0014</cell></row><row><cell></cell><cell>ECE</cell><cell cols="4">0.1040?0.0046 0.0652?0.0019 0.1096?0.0054 0.0793?0.0061</cell></row><row><cell></cell><cell>Acc</cell><cell cols="4">0.6560?0.0028 0.6543?0.0029 0.6593?0.0007 0.6575?0.0011</cell></row><row><cell>V2</cell><cell>CE-loss</cell><cell cols="4">1.5208?0.0118 1.5048?0.0122 1.5130?0.0057 1.5295?0.0170</cell></row><row><cell></cell><cell>ECE</cell><cell cols="4">0.0746?0.0053 0.0344?0.0030 0.0715?0.0079 0.0417?0.0096</cell></row><row><cell>Vid-Robust</cell><cell cols="5">Acc (pm-k) 0.5254?0.0043 0.5244?0.0036 0.5224?0.0023 0.5216?0.0035</cell></row><row><cell cols="6">YTBB-Robust Acc (pm-k) 0.4738?0.0037 0.4717?0.0035 0.4705?0.0021 0.4692?0.0017</cell></row><row><cell>ObjectNet</cell><cell>Acc</cell><cell cols="4">0.2756?0.0035 0.2751?0.0034 0.2837?0.0010 0.2825?0.0011</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>Test performance of Mixup and rescaled Mixup on different OOD versions of ImageNet. The training was done with ResNet-50 on the standard ImageNet dataset and the performance metrics are accuracy, cross-entropy loss, expected calibration error and mean corruption error</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">. More precisely, the Taylor approximation remainder inZhang et al. (2021, Lemma 3.1) does not vanish since it is a Taylor expansion near 0 of a random variable that follows a Beta(? + 1, ? + 1) distribution, i.e., that takes values close to 1 with probability 1/2 when ? goes to +?.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">. Codes for reproducing results for ImageNet and various OOD variants are available at https://github. com/google/uncertainty-baselines/tree/master/baselines/imagenet</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Jeremiah Zhe Liu for his feedback on an early version of this work.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Proofs</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gan</forename><surname>Wasserstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Implicit regularization in deep matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadav</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuping</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch? Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="7411" to="7422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devansh</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanis?aw</forename><surname>Jastrz?bski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maxinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tegan</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asja</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Barbu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Alverio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gutfreund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch? Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="9453" to="9463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Spectrally-normalized margin bounds for neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><forename type="middle">J</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matus J</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Telgarsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6241" to="6250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">MixMatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Neural Information Processing Systems</title>
		<meeting>the 33rd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Training with noise is equivalent to Tikhonov regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="116" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The tradeoffs of large scale learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>J. C. Platt, D. Koller, Y. Singer, and S. T. Roweis</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="161" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lieven</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vandenberghe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">On mixup regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><surname>Carratino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Ciss?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodolphe</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Vert</surname></persName>
		</author>
		<idno>2006.06049</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Parseval networks: Improving robustness to adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Ciss?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="854" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dropout as a Bayesian approximation: Representing model uncertainty in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<editor>Maria Florina Balcan and Kilian Q. Weinberger</editor>
		<meeting>The 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1050" to="1059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improved training of Wasserstein GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5767" to="5777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1321" to="1330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Out-of-manifold data augmentation for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><forename type="middle">Nonlinear</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mixup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="4044" to="4051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mixup as locally linear out-of-manifold regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongyi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3714" to="3722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Formal guarantees on the robustness of a classifier against adversarial manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maksym</forename><surname>Andriushchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2263" to="2273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A baseline for detecting misclassified and out-ofdistribution examples in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Computer Vision Foundation / IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
	<note>Natural adversarial examples</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning translation invariant recognition in a massively parallel networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Parallel Architectures and Languages Europe</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beyrem</forename><surname>Khalfaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Vert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.09819</idno>
		<title level="m">Asni: Adaptive structured noise injection for shallow and deep neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A simple weight decay can improve generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">A</forename><surname>Hertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<editor>J. Moody, S. Hanson, and R.P. Lippmann</editor>
		<imprint>
			<publisher>Morgan-Kaufmann</publisher>
			<date type="published" when="1991" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="950" to="957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">When does label smoothing help?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch? Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4694" to="4703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Behnam Neyshabur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.01953</idno>
		<title level="m">Implicit regularization in deep learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Path-SGD: Path-normalized optimization in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnam</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Russ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nati</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Neural Information Processing Systems</title>
		<meeting>the 28th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2422" to="2430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Regularizing neural networks by penalizing confident output distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Pereyra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Workshop Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Random features for large-scale kernel machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<editor>J. Platt, D. Koller, Y. Singer, and S. Roweis</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1177" to="1184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Do ImageNet classifiers generalize to ImageNet?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>Kamalika Chaudhuri and Ruslan Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="5389" to="5400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Durk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<editor>D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="901" to="909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The singular values of convolutional layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanie</forename><surname>Sedghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip M</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Do image classifiers generalize across time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achal</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9641" to="9649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On mixup training: Improved calibration and predictive uncertainty for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gopinath</forename><surname>Sunil Thulasidasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><forename type="middle">A</forename><surname>Chennupati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanmoy</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michalak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch? Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Between-class learning for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Tokozume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5486" to="5494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Manifold mixup: Better representations by interpolating hidden states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Beckham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v97/verma19a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>Kamalika Chaudhuri and Ruslan Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dropout training as adaptive regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Wager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy S</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<editor>C.J. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="351" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The implicit and explicit regularization effects of dropout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sham</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<editor>Hal Daum? III and Aarti Singh</editor>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6023" to="6032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Ciss?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">How does mixup help with robustness and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Kawaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirata</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations. OpenReview.net</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">We consider the Beta distribution in Mixup and its approximation to be Beta(?, ?) with ? = 1</title>
	</analytic>
	<monogr>
		<title level="m">Mixup hyperparameter</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
