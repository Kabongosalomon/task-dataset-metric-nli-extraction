<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Link Prediction with Walk Pooling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liming</forename><surname>Pan</surname></persName>
							<email>pan.liming@njnu.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Shi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Dokmani?</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer and Electronic Information</orgName>
								<orgName type="institution">Nanjing Normal University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Departement Mathematik und Informatik</orgName>
								<orgName type="institution">Universit?t Basel</orgName>
								<address>
									<postCode>4051</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Link Prediction with Walk Pooling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph neural networks achieve high accuracy in link prediction by jointly leveraging graph topology and node attributes. Topology, however, is represented indirectly; state-of-the-art methods based on subgraph classification label nodes with distance to the target link, so that, although topological information is present, it is tempered by pooling. This makes it challenging to leverage features like loops and motifs associated with network formation mechanisms. We propose a link prediction algorithm based on a new pooling scheme called WalkPool. WalkPool combines the expressivity of topological heuristics with the feature-learning ability of neural networks. It summarizes a putative link by random walk probabilities of adjacent paths. Instead of extracting transition probabilities from the original graph, it computes the transition matrix of a "predictive" latent graph by applying attention to learned features; this may be interpreted as feature-sensitive topology fingerprinting. WalkPool can leverage unsupervised node features or be combined with GNNs and trained end-to-end. It outperforms state-of-the-art methods on all common link prediction benchmarks, both homophilic and heterophilic, with and without node attributes. Applying WalkPool to a set of unsupervised GNNs significantly improves prediction accuracy, suggesting that it may be used as a general-purpose graph pooling scheme. * These two authors have equal contribution. ? To whom correspondence should be addressed. 1 Mathematical topology studies (global) properties of shapes that are preserved under homeomorphisms. Our use of "topology" to refer to local patterns is common in the network literature.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graphs are a natural model for relational data such as coauthorship networks or the human protein interactome. Since real-world graphs are often only partially observed, a central problem across all scientific domains is to predict missing links <ref type="bibr" target="#b12">(Liben-Nowell &amp; Kleinberg, 2007)</ref>. Link prediction finds applications in predicting protein interactions <ref type="bibr" target="#b25">(Qi et al., 2006)</ref>, drug responses <ref type="bibr" target="#b31">(Stanfield et al., 2017)</ref>, or completing the knowledge graph <ref type="bibr" target="#b21">(Nickel et al., 2015)</ref>. It underpins recommender systems in social networks <ref type="bibr" target="#b1">(Adamic &amp; Adar, 2003)</ref> and online marketplaces <ref type="bibr" target="#b14">(L? et al., 2012)</ref>. Successful link prediction demands an understanding of the principles behind graph formation.</p><p>In this paper we propose a link prediction algorithm which builds on two distinct traditions:</p><p>(1) complex networks, from which we borrow ideas about the importance of topology, and (2) the emerging domain of graph neural networks (GNNs), on which we rely to learn optimal features. We are motivated by the fact that the existing GNN-based link prediction algorithms encode topological 1 features only indirectly, while link prediction is a strongly</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related work</head><p>Early studies on link prediction use heuristics from social network analysis <ref type="bibr" target="#b13">(L? &amp; Zhou, 2011)</ref>. The homophily mechanism for example <ref type="bibr" target="#b17">(McPherson et al., 2001)</ref> asserts that "similar" nodes connect. Most heuristics are based on connectivity: the common-neighbor index (CN) scores a pair of nodes by the number of shared neighbors, yielding predicted graphs with many triangles; Adami?-Adar index (AA) assumes that a highly-connected neighbor contributes less to the score of a focal link <ref type="bibr" target="#b1">(Adamic &amp; Adar, 2003)</ref>. CN and AA rely on paths of length two. Others heuristics use longer paths, explicitly accounting for long-range correlations <ref type="bibr" target="#b13">(L? &amp; Zhou, 2011)</ref>. The Katz index <ref type="bibr" target="#b8">(Katz, 1953)</ref> scores a pair of nodes by a weighted sum of the number of walks of all possible lengths. PageRank scores a link by the probability that a walker starting at one end of the link reaches the other in the stationary state under a random walk model with restarts.</p><p>Heuristics make strong assumptions such as a particular parametric decay of path weights with length, often tailored to either homophilic or heterophilic graphs. Moreover, they cannot be easily used on graphs with node or edge features. Instead of hard-coded structural features, link prediction algorithms based on GNNs like the VGAE <ref type="bibr" target="#b10">(Kipf &amp; Welling, 2016b)</ref> or <ref type="bibr">SEAL Zhang &amp; Chen (2018)</ref> use learned node-level representations that capture both the structure and the features, yielding unprecedented accuracy.</p><p>Two strategies have proved successful for GNN-based link prediction. The first is to devise a score function which only depends on the two nodes that define a link. The second is to extract a subgraph around the focal link and solve link prediction by (sub)graph classification <ref type="bibr" target="#b38">(Zhang &amp; Chen, 2017)</ref>. In both cases the node representations are either learned in an unsupervised way <ref type="bibr" target="#b10">(Kipf &amp; Welling, 2016b;</ref><ref type="bibr" target="#b15">Mavromatis &amp; Karypis, 2020)</ref> or computed by a GNN trained joinly with the link classifier <ref type="bibr" target="#b41">Zhang et al., 2020)</ref>.</p><p>Algorithms based on two-body score functions achieved state-of-the-art performance when they appeared, but real networks brim with many-body correlations. Graphs in biochemistry, neurobiology, ecology, and engineering <ref type="bibr" target="#b18">(Milo et al., 2004)</ref> exhibit motifs-distinct patterns occuring much more often than in random graphs. Motifs may correspond to basic computational elements and relate to function <ref type="bibr" target="#b27">(Shen-Orr et al., 2002)</ref>. A multilayer GNN generates node representation by aggregating information from neighbors, capturing to some extent many-body and long-range correlations. This dependence is however indirect and complex topological properties such as frequency of motifs are smoothed out.</p><p>The current state-of-the-art link prediction algorithm, SEAL , is based on subgraph classification and thus may account for higher-order correlations. Unlike in vanilla graph classification where a priori all links are equaly important, in graph classification for link prediction the focal link plays a special role and the relative placement of other links with respect to it matters. SEAL takes this into account by labeling each node of the subgraph by its distance to the focal link. This endows the GNN with first-order topological information and helps distinguish relevant nodes in the pooled representation. Zhang and Chen show that node labeling is essential for SEAL's exceptional accuracy. Nevertheless, important structural motifs are represented indirectly (if at all) by such labeling schemes, even less so after average pooling. We hypothesize that a major bottleneck in link prediction comes from suboptimal pooling which fails to account for topology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Our contribution</head><p>Following , we approach link prediction from via subgraph classification. Instead of encoding relative topological information through node labels, we design a new pooling mechanism called WalkPool. WalkPool extracts higher-order structural information by encoding node representations and graph topology into random-walk transition probabilities on some effective latent graph, and then using those probabilities to compute features we call walk profiles. WalkPool generalizes loop-counting ideas used to build expressive graph models <ref type="bibr" target="#b22">(Pan et al., 2016)</ref>. Computing expressive topological descriptors which are simultaneously sensitive to node features is the key difference between WalkPool and SEAL. Using normalized probabilities tuned by graph attention mitigates the well-known issue in graph learning that highly-connected nodes may bias predictions. Transition probabilities and the derived walk profiles have simple topological interpretations.</p><p>WalkPool can be applied to node representations generated by any unsupervised graph representation models or combined with GNNs and trained in end-to-end. It achieves stateof-the-art results on all common link prediction benchmarks. Our code and data are available online at https://github.com/DaDaCheng/WalkPooling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Link prediction on graphs</head><p>We consider an observed graph with N nodes (or vertices), G o = (V, E o ), with V being the node set and E o the set of observed links (or edges). The observed link set E o is a subset E o ? E * of the set of all true links E * . The target of link prediction is to infer missing links from a candidate set E c , which contains both true (in E * ) and false (not in E * ) missing links. Problem 1. (Link prediction) Design an algorithm LearnLP that takes an observed graph G o ? G and produces a link predictor LearnLP(G o ) = ? : V ? V ? {True, False} which accurately classifies links in E c .</p><p>Well-performing solutions to Problem 1 exploit structural and functional regularities in the observed graph to make inferences about unobserved links.</p><p>Path counts and random walks For simplicity we identify the N vertices with integers 1, . . . , N and represent G by its adjacency matrix, A = (a ij ) N i,j=1 ? {0, 1} N ?N with a ij = 1 if {i, j} ? E o and a ij = 0 otherwise. Nodes may have associated feature vectors (x i ? R F , i ? {1, . . . , N }); we collect all feature vectors in the feature matrix X = [x 1 , ? ? ? , x N ] T ? R N ?F .</p><p>Integer powers of the adjacency matrix reveal structural information: [A ? ] ij is the number of paths of length ? connecting nodes i and j. WalkPool relies on random walk transition matrices. For an adjacency matrix A the transition matrix is defined as P = D ?1 A where D = diag(d 1 , . . . , d N ) and d i = j a ij = |N (i)| is the degree of the node i. Thus the probability p ij = d ?1 i a ij that a random walker at node i transitions to node j is inversely proportional to the number of neighbors of i. An extension to graphs with non-negative edge weights W = (w ij ) is straightforward by replacing a ij by w ij . Powers of P are interpretable: [P ? ] ij is the probability that a random walker starting at node i will reach node j in ? hops.</p><p>As we show in Section 3.2, transition probabilities in WalkPool are determined as coefficients of an attention mechanism applied to learned node features. The node features are in turn extracted by a parameterized function f ? , which distills input attributes and to an extent graph topology into an embedding (a vector) for each node. The feature extractor f ? : {0, 1} N ?N ? R N ?F ? R N ?F takes as input the adjacency matrix (which encodes the graph topology) and the input feature matrix, and outputs a distilled node feature matrix. It should thus be equivariant to node ordering in A which is satisfied by GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">WalkPool for link prediction by subgraph classification</head><p>We now describe WalkPool which directly leverages higher-order topological correlations without resorting to link labeling schemes and without making strong a priori assumptions. WalkPool first samples the k-hop subgraph G k {i,j} ? G o enclosing the target link; and then computes random-walk profiles for sampled subgraphs with and without the target link. Random walk profiles are then fed into a link classifier. Computing walk profiles entails 1. Feature extraction: Z = f ? (A, X), where f ? is a GNN; 2. Transition matrix computation: P = AttentionCoefficients ? (Z; G); 3. Walk profiles: Extract entries from P ? for 2 ? ? ? ? c related to the focal link.</p><p>We emphasize that we do not use attention to compute per-node linear combinations of features like <ref type="bibr" target="#b35">Veli?kovi? et al. (2017)</ref> (which is analogous to <ref type="bibr" target="#b34">Vaswani et al. (2017)</ref>), but rather interpret the attention coefficients as random walk transition probabilities. The features Z may be obtained either by an unsupervised GNN such as VGAE (Kipf &amp; Welling, 2016b), or they may be computed by a GNN which is trained jointly with WalkPool. Figure 3: Illustration of walk profiles for ? = 2. We assume p i,j = 1/d i where d i is the degree of node i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sampling the enclosing subgraphs</head><p>Following earlier work we make the assumption that the presence of a link only depends on its neighbors within a (small) radius k. It is known that simple heuristics like AA may already perform well on many graphs, with longer walks not bringing about significant gains. Indeed, SEAL  exploits the fact that an order k heuristic can be accurately calculated from a k-hop subgraph; optimal k is related to the underlying generative model. Keeping k small (as small as 2 in this paper) is pragmatic for reasons beyond diminishing returns: a large k greatly increases memory and compute demands. The size of a 2-hop neighborhood is graph-dependent, but for the highly-connected E.coli and PB datasets we already need to enforce a maximum number of nodes per hop to fit the subgraphs in memory.</p><p>Let d(x, y) be the shortest-path distance between nodes x and y. We fix an arbitrary order of the nodes in V {i,j} and denote the corresponding adjacency matrix by A {i,j} . Without loss of generality, we assume that under the chosen order of nodes, the nodes i and j are labeled as 1 and 2 so that the candidate link {i, j} is mapped to {1, 2} in its enclosing subgraph. We denote the corresponding node feature matrix Z {i,j} , with values inherited from the full graph (the rows of Z {i,j} are a subset of rows of Z).</p><p>For the candidate set of links E c , we construct a set of enclosing subgraphs S c = {G {i,j } : {i, j} ? E c }, thus transforming the link prediction problem into classifying these k-hop enclosing subgraphs. For training, we sample a set of known true and false edges E t and construct its corresponding enclosing subgraph set S t = {G i,j : (i, j) ? E t }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Random-walk profile</head><p>The next step is to classify the sampled subgraphs from their adjacency relations A {i,j} and node representations Z {i,j} . Inspired by the walk-based heuristics, we employ random walks to infer higher-order topological information. Namely, for a subgraph (G = (V, E), Z) (either in S c or S t ) we encode the node representations Z into edge weights and use these edge weights to compute transition probabilities of a random walk on the underlying graph. Probabilities of walks of various lengths under this model yield a profile of the focal link.</p><p>We first encode two-node correlations as effective edge weights,</p><formula xml:id="formula_0">? x,y = Q ? (z x ) T K ? (z y ) ? F ,<label>(1)</label></formula><formula xml:id="formula_1">for all {x, y} ? E, where Q ? : R F ? R F and K ? : R F ? R F are two multilayer perceptrons (MLPs)</formula><p>and F is the output dimension of the MLPs. In order to include higherorder topological information, we compute the random-walk transition matrix P = (p x,y ) from the two-body correlations. We set</p><formula xml:id="formula_2">p x,y = softmax (? x,z ) z?N (x) y := exp(? x,y ) / z?N (x) exp(? x,z )<label>(2)</label></formula><p>for {x, y} ? E and p x,y = 0 otherwise, with N (x) the set of neighbors of x in the enclosing subgraph. The encoding (2) is analogous to graph attention coefficients <ref type="bibr" target="#b35">(Veli?kovi? et al., 2017;</ref><ref type="bibr" target="#b29">Shi et al., 2020)</ref>; unlike graph attention, however, we directly use the coefficients instead of computing linear combinations; this framework also allows multi-head attention.</p><p>Entries of the ? -th power [P ? ] ij are interpreted as probabilities that a random walker goes from i to j in ? hops. These probabilities thus concentrate the topological and node attributes relevant for the focal link into the form of random-walks:</p><p>? Topology is included indirectly through the GNN-extracted node features Z, and directly by the fact that P encodes zero probabilities for non-neighbors and that its powers thus encode probabilities of paths and loops; ? Input features are included directly through the GNN-extracted node features, and refined and combined with topology by the key and value functions Q ? , K ? .</p><p>As a result, WalkPool 2 can be interpreted as trainable heuristics.</p><p>From the matrix P and its powers, we now read a list of features to be used in graph classification. We compute node-level, link-level, and graph-level features:</p><formula xml:id="formula_3">node ? = [P ? ] 1,1 + [P ? ] 2,2 , link ? = [P ? ] 1,2 + [P ? ] 2,1 , graph ? = tr[P ? ]. (3)</formula><p>Computation of all features is illustrated for ? = 2 in <ref type="figure">Figure 3</ref>. Node-level features node ? describe the loop structure around the candidate link (recall that {1, 2} is the focal link in the subgraph). The summation ensures that the feature is invariant to the ordering of i and j, consistent with the fact that we study undirected graphs. Link-level features link ? give the symmetrical probability that a length-? random walk goes from node 1 to 2. Finally, graph-level features graph ? are related to the total probability of length-? loops. All features depend on the node representation Z; we omit this dependence for simplicity. The use of P in WalkPool is different from how graph matrices (e.g., A) are used in GNNs. In GNNs, the powers A ? serve as shift operators between neighborhoods that are multiplied by filter weights and used to weigh node features; WalkPool encodes graph signals into effective edge weights and directly extracts topological information from the entries of P ? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Perturbation extraction</head><p>A true link is by definition always present in its enclosing subgraph while a negative link is always absent. This leads to overfitting if we directly compute the features (3) on the enclosing subgraphs since the presence or absence of the link has a strong effect on walk profiles. For a normalized comparison of true and false links, we adopt a perturbation approach. Given an enclosing subgraph G = (V, E), we define its variants G + = (V, E ?{1, 2}) (resp. G ? = (V, E\{1, 2})) with the candidate link forced to be present (resp. absent). We denote the node-level features (3) computed on G + and G ? by node ?,+ and node ?,? , respectively, and analogously for the link-and graph-level features.</p><p>While the node-and link-level features are similar to the heuristics of counting walks, graph ?,+ and graph ?,? are not directly useful for link prediction as discussed in the introduction: the information related to the presence of {i, j} is obfuscated by the summation over the entire subgraph (by taking the trace).</p><p>SEAL attempts to remedy a similar issue for average (as opposed to tr(P ? )) pooling by labeling nodes by distance from the link. Here we propose a principled alternative. Since transition probabilities are normalized and have clear topological meaning, we can suppress irrelevant information by measuring the perturbation of graph-level features, ?graph ? = graph ?,+ ? graph ?,? . This "background subtraction" induces a data-driven soft limit on the longest loop length so that, by design, ?graph ? concentrates around the focal link.</p><p>In Appendix E, we demonstrate locality of WalkPool. Compared to node labeling, the perturbation approach does not manually assign a relative position (which may wrongly suggest that nodes at the same distance from the candidate link are of equal importance).</p><p>In summary, with WalkPool, for all G ? {G {i,j} : {i, j} ? E c }, we read a list of features as</p><formula xml:id="formula_4">WP ? (G, Z) = ? 1,2 , node ?,+ , node ?,? , link ?,+ , link ?,? , ?graph ? ?c ? =2 ,<label>(4)</label></formula><p>where ? c is the cutoff of the walk length and we treat it as a hyperparameter. The features are finally fed into a classifier; we use an MLP ? ? with a sigmoid activation in the output. The ablation study in <ref type="table">Table 5</ref> (Appendix B) shows that all the computed features contribute relevant predictive information. Walk profile computation is summarized in <ref type="figure" target="#fig_1">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Training the model</head><p>The described model contains trainable parameters ? which are fitted on the given observed set E t of positive and negative training links and their enclosing subgraphs. We train WalkPool with MSE loss (see Appendix G for a discussion of the loss),</p><formula xml:id="formula_5">? * = arg min ? 1 |E t | {i,j}?E t y {i,j} ? ? ? WP ? (G {i,j} , Z {i,j} 2</formula><p>where y {i,j} = 1 if {i, j} ? E o and 0 otherwise is the label indicating whether the link {i, j} is true or false. The fitted model is then deployed on the candidate links E c ; the predicted label for {x, y} ? E c is simply</p><formula xml:id="formula_6">y {x,y} = ? ? * (WP ? * (G {x,y} ), Z {x,y} ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Performance of WalkPool on benchmark datasets</head><p>We use area under the curve (AUC) <ref type="bibr" target="#b3">(Bradley, 1997)</ref> and average precision (AP) as metrics. Precision is the fraction of true positives among predictions. Letting TP (FP) be the number of true (false) positive links, AP = TP/(TP + FP).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>In homophilic (heterophilic) graphs, nodes that are similar (dissimilar) are more likely to connect. For node classification, a homophily index is defined formally as the average fraction of neighbors with identical labels <ref type="bibr" target="#b24">(Pei et al., 2020)</ref>. In the context of link prediction, if we assume that network formation is driven by the similarity (or dissimilarity) of node attributes, then a homophilic graph will favor triangles while a heterophilic graph will inhibit triangles. Following this intuition, we adopt the average clustering coefficient ACC (Watts &amp; Strogatz, 1998) as a topological correlate of homophily.</p><p>We experiment with eight datasets without node attributes and seven with attributes. As graphs without attributes we use: (i) USAir <ref type="bibr" target="#b2">(Batagelj &amp; Mrvar, 2006)</ref> <ref type="bibr" target="#b30">(Spring et al., 2002)</ref>, and (viii) E.coli . Properties and statistics of the datasets, including number of nodes and edges, edge density and ACC can be found in <ref type="table" target="#tab_8">Table 4</ref> of Appendix A.</p><formula xml:id="formula_7">, (ii) NS (Newman, 2006), (iii) PB (Ackland et al., 2005), (iv) Yeast (Von Mering et al., 2002), (v) C.ele (Watts &amp; Strogatz, 1998), (vi) Power (Watts &amp; Strogatz, 1998), (vii) Router</formula><p>In graphs with a very low average clustering coefficient like Power and Router (ACC = 0.080 and 0.012, respectively, see Appendix A), topology-based heuristics usually perform poorly <ref type="bibr" target="#b13">(L? &amp; Zhou, 2011</ref>) (cf. Table 2), since heuristics often adopt the homophily assumption and rely on triangles. We show that by learning the topological organizing patterns, WalkPool performs well even for these graphs.</p><p>For a fair comparison, we use the exact same training and testing sets (including positive and negative links) as SEAL in . 90% of edges are taken as positive training edges and the remaining 10% are the positive test edges. The same number of additionally sampled nonexistent links are taken as training and testing negative edges.</p><p>As graphs with node attributes, we use:  <ref type="bibr" target="#b5">(Craven et al., 1998)</ref>. The properties and statistics of the datasets can be found in <ref type="table" target="#tab_8">Table 4</ref> of Appendix A; further details are provided in Appendix A Following the experimental protocols in <ref type="bibr" target="#b10">(Kipf &amp; Welling, 2016b;</ref><ref type="bibr" target="#b23">Pan et al., 2018;</ref><ref type="bibr" target="#b15">Mavromatis &amp; Karypis, 2020)</ref>, we split the links in three parts: 10% testing, 5% validation, 85% training. We sample the same number of nonexisting links in each group as negative links. On benchmarks without node attributes, we compare WalkPool with eight other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>We consider three walkbased heuristics: AA, Katz and PR; two subgraph-based heuristic learning methods:</p><p>Weisfeiler-Lehman graph kernel (WLK) <ref type="bibr" target="#b28">(Shervashidze et al., 2011)</ref> and WLNM <ref type="bibr" target="#b38">(Zhang &amp; Chen, 2017)</ref>; and latent feature methods: node2vec (N2V) <ref type="bibr" target="#b7">(Grover &amp; Leskovec, 2016)</ref>, spectral clustering (SPC) <ref type="bibr" target="#b33">(Tang &amp; Liu, 2011)</ref>, matrix factorization (MF) <ref type="bibr" target="#b11">(Koren et al., 2009</ref>) and LINE <ref type="bibr" target="#b32">(Tang et al., 2015)</ref>. We additionally consider the GNN-based SEAL, which is the previous state-of-the-art.</p><p>For datasets with node attributes, we combine WalkPool with three unsupervised GNN-based models: the VGAE, adversarially regularized variational graph autoencoder (ARGVA) <ref type="bibr" target="#b23">(Pan et al., 2018)</ref> and Graph Info-Clust (GIC) <ref type="bibr" target="#b15">(Mavromatis &amp; Karypis, 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation details</head><p>In the absence of node attributes, we initialize the node representation Z (0) as an N ? F (0) all-ones matrix, with F (0) = 32. We generate node representations by a two-layered Graph Convolutional Network (GCN) <ref type="bibr" target="#b9">(Kipf &amp; Welling, 2016a)</ref>:</p><formula xml:id="formula_8">Z (k) = GCN Z (k?1) , k ? {1, 2}, where Z (0) = X.</formula><p>We then concatenate the outputs as Z = [Z (0) | Z (1) | Z (2) ] to obtain  <ref type="table">Table 1</ref>: AUC for synthetic graphs over 10 independent trials.</p><p>the final node representation used to compute WP(G, Z) and classify. While a node labeling scheme like the one in SEAL is not needed for the strong performance of WalkPool, we find that labeling nodes by distance to focal link slightly improves results; we thus evaluate WalkPool with and without distance labels.</p><p>For the three datasets with node attributes, we first adopt an unsupervised model to generate an initial node representation Z (0) . This is because standard 2-layer GCNs are not expressive enough to extract useful node features in the presence of node attributes <ref type="bibr" target="#b42">Zhang et al. (2019)</ref>.</p><p>The initial node representation is fed into the same two-layered GCN above, and we take the concatenated representation Z = [Z (0) | Z (1) | Z (2) ] as the input to WalkPool. The concatenation records local multi-hop information and facilitates training by providing skip connections. It gives a small improvement over only using the last-layer embeddings, i.e., Z = Z (2) . The hyperparameters of the model are explained in detail in Appendix C. The runtime of WalkPool can be found in Appendix H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>Synthetic datasets To show that WalkPool successfully learns topology, we use four synthetic datasets: Triangle lattice (ACC = 0.415), 2D-Grid (ACC = 0), Hypercube (ACC = 0), and Star (ACC = 0). We randomly remove 10% links from each graph and run link prediction algorithms. AUC for WalkPool, SEAL, AA, and CN is shown in <ref type="table">Table 1</ref>. In these regular graphs the topological organizing rules are known explicitly. It is therefore clear that a common-neighbor-based heuristic (such as CN or AA) should fail for 2D-grid since none of the connected nodes have common neighbors. WalkPool successfully learns the organizing patterns without prior knowledge about the graph formation rules, using the same hyperparameters as in all other experiments. For Triangle lattice and 2D-grid, WalkPool achieves a near-100% AUC. Small errors are due to hidden the test edges which act as noise; for fewer withheld links the error would vanish. In hypercube and Star, WalkPool achieves an AUC of 100% in all ten trials. The star graph is heterophilic in the sense that no triangles are present; we indeed observe that AA and CN have AUC below 50% since they (on average) flip true and false edges. Datasets without attributes We perform 10 random splits of the data. The average AUCs with standard deviations are shown in <ref type="table" target="#tab_4">Table 2</ref>; the AP results and statistical significance of the results can be found in Appendix D. For WalkPool, we have considered both the cases with and without the DL node labels as input features.</p><p>From <ref type="table" target="#tab_4">Table 2</ref>, WalkPool significantly improves the prediction accuracy on all the datasets we have considered. It also has a smaller standard deviation, indicating that WalkPool is stable on independent data splits (unlike competing learning methods). Among all methods, WalkPool with DL performs the best; the second-best method slightly below is WalkPool without DL. In other words, although DRNL slightly improves WalkPool, nonetheless, WalkPool achieves SOTA performance already without it.</p><p>WalkPool performs stably on both homophilic (high ACC) and heterophilic (low ACC) datasets, achieving state-of-the-art performance on all. Remarkably, on Power and Router where topology-based heuristics such as AA and Katz fail, WalkPool shows strong performance (it also outperforms SEAL by about 5% on Power). This confirms that walk profiles are expressive descriptors of the local network organizing patterns, and that WalkPool can fit their parameters from data without making prior topological assumptions. Experiments with 50% observed training edges can be found in Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets with node attributes</head><p>We apply WalkPool to extract higher-order information from node representations generated via unsupervised learning. We again perform 10   random splits of the data and report the average AUC with standard deviations in <ref type="table" target="#tab_5">Table 3</ref>; for AP see Appendix D. In <ref type="table" target="#tab_5">Table 3</ref>, we show the results of unsupervised models with and without WalkPool. For all the unsupervised models and datasets, WalkPool improves the prediction accuracy. On the Pubmed dataset where the relative importance of topology over features is greater, WalkPool brings about the most significant gains.</p><p>While traditional heuristics cannot include node attributes, WalkPool encodes the node attributes into random walk transition probabilities via the attention mechanism, which allows it to capture structure and node attributes simultaneously. The prediction accuracy relies on the unsupervised GNN which generates the inital node representation. We find that the combination of GIC and WalkPool yields the highest accuracy for all three datasets. Importance of initial node representations is plain since WalkPool is not designed to uncover structure in node attributes. Nonetheless, WalkPool greatly improves performance of unsupervised GNN on the downstream link prediction task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>The topology of a graph plays a much more important role in link prediction than node classification, even with node attributes. Link prediction and topology are entangled, so to speak, since topology is defined by the links. Most GNN-based link prediction methods work with node representations and do not adequately leverage topological information.</p><p>Our proposed WalkPool, to the contrary, jointly encodes node representations and graph topology into learned topological features. The central idea is how to leverage learning: we apply attention to the node representations and interpret the attention coefficients as transition probabilities of a graph random walk. WalkPool is a trainable topological heuristic, thus explicitly considering long-range correlations, but without making ad hoc assumptions like the classical heuristics. This intuition is borne out in practice: combining supervised or unsupervised graph neural networks with WalkPool yields state-of-theart performance on a broad range of benchmarks with diverse structural characteristics.</p><p>Remarkably, WalkPool achieves this with the same set of hyperparameters on all tasks regardless of the network type and generating mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Benchmark datasets description</head><p>Brief description of the benchmark datasets is as follows. For the datasets without node attributes, we have considered:</p><p>? USAir <ref type="bibr" target="#b2">(Batagelj &amp; Mrvar, 2006</ref> As graphs with node attributes, we consider three citation graphs with publications described by binary vectors indicating the absence/presence of the corresponding dictionary word: Finally, we consider three webpage graphs which include web pages from computer science departments of various universities, node features are the bag-of-words representation of web pages.</p><p>? Cornell <ref type="bibr" target="#b5">(Craven et al., 1998)</ref>: a webpage graph with 183 nodes and 277 edges, and the node attribute has dimension 1703; ACC = 0.167. ? Texas <ref type="bibr" target="#b5">(Craven et al., 1998)</ref>: a webpage graph with 183 nodes and 279 edges, and the node attribute has dimension 1703; ACC = 0.198. ? Wisconsin <ref type="bibr" target="#b5">(Craven et al., 1998)</ref>: a webpage graph with 251 nodes and 450 edges, and the node attribute has dimension 1703; ACC = 0.208.</p><p>The benchmark dataset properties and statistics are summarized in <ref type="table" target="#tab_8">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Ablation study</head><p>We conduct ablation studies of WalkPool by excluding or including only each of the node-, link-and graph-level features in (4). We used short notations {node ? } ? {node ?,+ , node ?,? :  <ref type="table" target="#tab_4">Node  332  1589  1222  2375  297  4941  5022  1805  2708  3312  19717  2277  183  183  251  Edges  2126  2742 16714 11693 2148  6594  6258  15660 5278  4552  44324  31371  227  279  450  ACC  0.</ref>   <ref type="table">Table 5</ref>: Ablation study in C.ele</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C. Hyperparamters</head><p>The hyperparamters to reproduce the results are summarized in <ref type="table" target="#tab_10">Table 6</ref>.</p><p>For the split of training, validation and testing edges, we have adopted different setups for datasets with and without node attributes to consist with previous studies. In particular, for datasets without node attributes, 90% of edges are taken as training positive edges and the remaining 10% are for testing positive edges. The corresponding same number of negative edges are sampled randomly for training and testing. Then among the training edges. we randomly selected 5% for validation. The observed graph from which the enclosing subgraphs are sampled consists of all the training positive edges. For the datasets with node attributes, all the edges are divided into 85% for training, 10% for testing and 5% for validation. The observed graph is built only based on the training edges. Some studies of link prediction choose to keep the observed graph connected when sampling the test edges, while others do not adopt this option. For the experiment results shown in the paper, we sample the test edges uniformly random without ensuring the observed graph is connected.</p><p>For sampling the enclosing subgraphs, we set the number of hops as 2 except 3 for the Power dataset. The 2-hop subgraphs sampled from E.coli and PB datasets and Pubmed are relatively numerous in nodes. Thus we set a maximum number nodes per hop for these two datasets to fit into memory. In particular, for each hop during sampling, we randomly select a maximum of 100 nodes if the sampled nodes exceeds.</p><p>For WalkPool, We set ? c = 7 for the cutoff of walk length in all experiments. When ? c becomes large, the transition probabilities converges to a constant, as the random walk reaches stationary. Therefore, a larger value of ? introduces little further information. From experiments, we find that introducing a larger ? c will not increase the accuracy notably.</p><p>For the classifer, we use a MLP with layer sizes 72 ? 1440 ? 1440 ? 720 ? 72 ? 1. We use Relu as the activation function for the hidden layers, and sigmoid function for the output layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D. Results measured by AP and statistical significance of results</head><p>The prediction accuracy measured by AP for datasets with and without node attributes are shown in <ref type="table" target="#tab_12">Table 8</ref> and <ref type="table" target="#tab_14">Table 9</ref>, respectively. From the tables, WalkPool still performs best with the AP metric.</p><p>To verified the statistical significance of the results, we performed a two-sided hypothesis test with the null hypothesis that two independent samples (corresponding to the results of WalkPool and the second best algorithm) have identical average. We compute the corresponding p-value on a per dataset basis for the eight datasets without node attributes. The results are shown in  2.18 ? 10 ?5 6.18 ? 10 ?1 1.60 ? 10 ?3 2.56 ? 10 ?2 6.00 ? 10 ?4 9.90 ? 10 ?3 8.68 ? 10 ?2 7.80 ? 10 ?9  the second best is PR) and Power (where the second-best is SPC). Recall that a p-value of 0.05 or less is customarily considered statistically significant. We see that for all but the NS and Router datasets the p-value is below 0.05. For most datasets it is orders of magnitude below. The AUC on the NS dataset is already very close to 100, thus leaving little space for improvement; for Router it is the large variance of SEAL that gives a p-value a bit above 0.05. Note that even for Router and NS the empirical mean of WalkPool is better. More trials should easily break the statistical tie even in those cases, but we used the same 10 splits as SEAL for a fair comparisons.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix E. Locality of graph-level features</head><p>Let G = (V, E) be an enclosing subgraph, and {1, 2} be the candidate link. We denote the random walk transition matrices on G + and G ? as P and Q, respectively. For any node x, y ? V, let d(x, y) be the shortest path distance on the graph. We define the distance from x to the candidate link to bed(x) = min{d(x, 1), d(x, 2)}. We have the following result.</p><formula xml:id="formula_9">Proposition 1. Let V ? = {x ? V,d(x) &gt; ? }, then [P ? ] x,y = [Q ? ] x,y for all x, y ? V ? .</formula><p>Proof. We prove the result via induction. When ? = 1, after the node-wise normalization from the softmax function in <ref type="formula" target="#formula_2">(2)</ref>, the elements of P and Q are identical among nodes that not neighbors of the candidate link, i.e.,</p><formula xml:id="formula_10">V 1 = {x ? V,d(x) &gt; 1}.</formula><p>Now suppose the claim holds for ? . Let I = {x ? V,d(x) ? ? }, let ?I be the set of nodes that are adjacency to but not in I, and let I c be the set of rest nodes in the graph. We can arrange the order of the nodes that such that P and P ? are of the following block form </p><p>We can do a similar computation to obtain Q ? +1 I c ,I c , with all P replaced by Q in the above equation. By assumption, we have</p><formula xml:id="formula_12">P I c ?I = Q I c ?I P ? ?I,I c = Q ? ?I,I c P I c ,I c = Q I c ,I c , P ? I c ,I c = Q ? I c ,I c ,<label>(7)</label></formula><p>as ?I, I c ? V ? , therefore we obtain P ? +1   may have submitted a paper that will come out tomorrow. We therefore expect a less peaky distribution of link probabilities than node classes, and we choose a loss that minimizes the miscalibration of the model. In this context where we want to predict probabilities as accurately as possible, the MSE loss is known as the Brier score (another textbook use of the Brier score is to calibrate the chance-of-rain forecasts).</p><formula xml:id="formula_13">I c ,I c = Q ? +1 I c ,I c . As I c = V ? +1 ,</formula><p>We have experimented with both the binary cross-entropy (BCE) loss and the MSE loss, and we observed no discernible difference. For example, for the eight datasets without node attributes (the last line of <ref type="table" target="#tab_4">Table 2</ref>), accuracies measured by AUC when using MSE/BCE loss are: 98. <ref type="bibr">68/98.68; 98.95/98.85; 95.60/95.69; 98.37/98.37; 92.79/92.83; 92.56/92.58; 97.27/97.35; 98.58/98.67</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix H. Runtime of WalkPool</head><p>The runtime of WalkPool is similar to that of SEAL when using the same number of hops to construct the subgraphs. On a classical dataset USAir, WalkPool takes 129.62s for 50 epochs with 1-hop subgraph sampling, while SEAL takes 145.94s. The configuration of WalkPool used throughout our paper has two GCN layers followed by several linear layers for computing the powers of matrix P, and a four-layer MLP classifier. As such, from the perspective of runtime, the trainable part of WalkPool architecture is no more complex than that of a typical GNN. For very large datasets, the most time-consuming step is to extract the enclosing subgraphs-this is true for WalkPool and any other subgraph-based link prediction algorithm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The topological organizing rules are not universal across graphs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of WalkPool. A: The input graph and the focal link e; B: enclosing subgraphs with and without e; C: attention-processed features ? random walk transition probabilities; D: extracted walk profile.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(i) Cora (McCallum et al., 2000), (ii) Citeseer (Giles et al., 1998), (iii) Pubmed (Namata et al., 2012), (iv) Chameleon (Rozemberczki et al., 2021), (v) Cornell (Craven et al., 1998), (vi) Texas (Craven et al., 1998), and (vii) Wisconsin</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Comparison of mean and variance of AUC between SEAL and WP with 90% observed links. The datasets are sorted by their clustering coefficients.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>): a graph of US airlines with 332 nodes and 2126 edges; ACC = 0.625. ? NS (Newman, 2006): the collaboration relation of network science researchers with 1589 nodes and 2742 edges; ACC = 0.638. ? PB (Ackland et al., 2005): a graph of hyperlinks between weblogs on US politics with 1222 nodes and 16714 edges; ACC = 0.320. ? Yeast (Von Mering et al., 2002): a protein-protein interaction graph in yeast with 2375 nodes and 11693 edges; ACC = 0.306. ? C.ele (Watts &amp; Strogatz, 1998): the biological neural network of C.elegans with 297 nodes and 2148 edges; ACC = 0.292. ? Power (Watts &amp; Strogatz, 1998): the topology of the Western States Power Grid of the United States with 4941 nodes and 6594 edges; ACC = 0.080. ? Router (Spring et al., 2002): the router-level Internet with 5022 nodes and 6258 edges; ACC = 0.012. ? E.coli (Zhang et al., 2018): the pairwise reaction relation of metabolites in E.coli with 1805 nodes and 15660 edges; ACC = 0.516.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>?</head><label></label><figDesc>Cora (McCallum et al., 2000): a citation graph with 2708 scientific publications and 5278 links. The dictionary consists of 1433 unique words; ACC = 0.241. ? Citeseer (Giles et al., 1998): the dataset consists of 3312 scientific publications with 4552 links; the dictionary consists of 3703 unique words; ACC = 0.141. ? Pubmed (Namata et al., 2012): the dataset consists of 19717 scientific publications with 44324 links. The dictionary consists of 500 unique words; ACC = 0.060. We also consider a Wikipedia page graph where nodes represent web pages and edges represent hyperlinks between them. Node features represent several informative nouns in the pages: ? Chameleon (Rozemberczki et al., 2021): Wikipedia page-page graph under the topic chameleon. The graph consists of 2277 nodes and 31371 edges where each node has an attribute vector of dimension 2325; ACC = 0.377.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>,</head><label></label><figDesc>I P ?I,?I P ?I,I c 0 P I c ,?I P I c ,I c P I,I is the block matrix confined to I and other blocks are defined similarly. By definition, P I,I c = 0 and P I c ,I = 0. Multiplication of the block matrices gives P ? +1 I c ,I c = P I c ,?I P ? ?I,I c + P I c ,I c P ? I c ,I c .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The k-hop enclosing subgraph G k {i,j} for {i, j} is defined as the subgraph induced from G o by the set of nodes and {x, y} ? E o . We omit the dependence on k and write G {i,j} = (V {i,j} , E {i,j} ) for simplicity.</figDesc><table><row><cell>V k {i,j} = {x ? V : d(x, i) ? k or d(x, j) ? k}.</cell></row><row><cell>Then G k {i,j} = (V k {i,j} , E k {i,j} ), where {x, y} ? E k i,j when x, y ? V k {i,j}</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Triangle lattice (50 ? 50) 99.77?0.12 99.54?0.11 95.16?0.90 95.15?0.87 37.14?1.47 2D-grid (50 ? 50) 99.86?0.09 99.51?0.09 49.90?0.09 49.90?0.09 32.43?1.12 Hypercube (2 10 ) 100.00?0.00 99.60?0.10 48.01?0.35 48.01?0.35 37.84?1.19 Star (1000) 100.00?0.00 99.57?0.10 14.50?2.40 14.50?2.40 100.00?0.00</figDesc><table><row><cell>WP</cell><cell>SEAL</cell><cell>AA</cell><cell>CN</cell><cell>VGAE</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>06?1.03 94.45?0.93 92.36?0.34 89.43?0.62 86.95?1.40 58.79?0.88 56.43?0.51 95.36?0.34 Katz 92.88?1.42 94.85?1.10 92.92?0.35 92.24?0.61 86.34?1.89 65.39?1.59 38.62?1.35 93.50?0.44 PR 94.67?1.08 94.89?1.08 93.54?0.41 92.76?0.55 90.32?1.49 66.00?1.59 38.76?1.39 95.57?0.44 WLK 96.63?0.73 98.57?0.51 93.83?0.59 95.86?0.54 89.72?1.67 82.41?3.43 87.42?2.08 96.94?0.29 WLNM 95.95?1.10 98.61?0.49 93.49?0.47 95.62?0.52 86.18?1.72 84.76?0.98 94.41?0.88 97.21?0.27 N2V 91.44?1.78 91.52?1.28 85.79?0.78 93.67?0.46 84.11?1.27 76.22?0.92 65.46?0.86 90.82?1.49 SPC 74.22?3.11 89.94?2.39 83.96?0.86 93.25?0.40 51.90?2.57 91.78?0.61 68.79?2.42 94.92?0.32 MF 94.08?0.80 74.55?4.34 94.30?0.53 90.28?0.69 85.90?1.74 50.63?1.10 78.03?1.63 93.76?0.56 LINE 81.47?10.71 80.63?1.90 76.95?2.76 87.45?3.33 69.21?3.14 55.63?1.47 67.15?2.10 82.38?2.19 SEAL 97.09?0.70 98.85?0.47 95.01?0.34 97.91?0.52 90.30?1.35 87.61?1.57 96.38?1.45 97.64?0.22 WP(ones) 98.52?0.50 98.86?0.42 95.42?0.39 98.16?0.33 92.42?1.22 91.71?0.60 97.18?0.28 98.54?0.20 WP(DL) 98.68?0.48 98.95?0.41 95.60?0.37 98.37?0.25 92.79?1.09 92.56?0.60 97.27?0.28 98.58?0.19</figDesc><table><row><cell>Data</cell><cell>USAir</cell><cell>NS</cell><cell>PB</cell><cell>Yeast</cell><cell>C.ele</cell><cell>Power</cell><cell>Router</cell><cell>E.coli</cell></row><row><cell>AA</cell><cell>95.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Prediction accuracy measured by AUC on eight datasets (90% observed links) without node attributes. Boldface marks the best, underline the second best results.</figDesc><table><row><cell></cell><cell cols="2">VGAE</cell><cell cols="2">ARGVA</cell><cell>GIC</cell></row><row><cell></cell><cell>NO WP</cell><cell>WP</cell><cell>NO WP</cell><cell>WP</cell><cell>NO WP</cell><cell>WP</cell></row><row><cell>Cora</cell><cell>91.98?0.54</cell><cell>94.64?0.55</cell><cell>92.45?1.11</cell><cell>94.71?0.85</cell><cell cols="2">93.68?0.59 95.90?0.50</cell></row><row><cell>Citeseer</cell><cell>91.21?1.14</cell><cell>94.32?0.90</cell><cell>91.71?1.38</cell><cell>94.53?1.77</cell><cell cols="2">95.03?0.65 95.94?0.53</cell></row><row><cell>Pubmed</cell><cell>96.51?0.14</cell><cell>98.49?0.13</cell><cell>96.62?0.12</cell><cell>98.52?0.14</cell><cell cols="2">93.00?0.36 98.72?0.10</cell></row><row><cell cols="2">Chameleon 98.79?0.18</cell><cell>99.51?0.08</cell><cell>98.23?0.24</cell><cell>99.51?0.08</cell><cell cols="2">94.13?0.38 99.52?0.08</cell></row><row><cell>Cornell</cell><cell>70.59?9.03</cell><cell>78.24?7.51</cell><cell cols="2">81.73?4.82 82.39?8.92</cell><cell>63.32?7.47</cell><cell>80.69?7.25</cell></row><row><cell>Texas</cell><cell cols="2">73.71?9.29 76.02?7.05</cell><cell>68.05?8.29</cell><cell>75.62?5.80</cell><cell>65.43?10.39</cell><cell>74.49?6.85</cell></row><row><cell>Wisconsin</cell><cell>75.05?6.88</cell><cell>77.07?6.11</cell><cell>75.69?7.91</cell><cell>79.34?6.32</cell><cell cols="2">74.74?6.28 82.27?6.27</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Prediction accuracy ( AUC) on datasets with node attributes (90% observed links).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>.ele Power Router E.coli Cora Citeseer Pubmed Chameleon Cornell Texas Wisconsin</figDesc><table><row><cell>Dataset</cell><cell>USAir NS</cell><cell>PB</cell><cell>Yeast C</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Benchmark dataset properties and statistics.? ? {2, ? ? ? , ? c }}, and similarly for {link ? }, {?graph ? }. The ablation results for the C.ele dataset is shown in the InTable.5.</figDesc><table><row><cell>Feature feat</cell><cell>? 12</cell><cell cols="3">{node ? } {link ? } {?graph ? }</cell><cell>-</cell></row><row><cell cols="2">AUC (using only feat) 87.90</cell><cell>91.88</cell><cell>92.44</cell><cell>92.29</cell><cell>-</cell></row><row><cell cols="2">AUC (using WP\feat) 92.69</cell><cell>92.66</cell><cell>91.08</cell><cell>92.65</cell><cell>92.82</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 .</head><label>7</label><figDesc>The second best algorithm is SEAL except in C.ele (where</figDesc><table><row><cell>Name</cell><cell>With attributes</cell><cell>No attributes</cell></row><row><cell>optimizer</cell><cell>Adam</cell><cell>Adam</cell></row><row><cell>learning rate</cell><cell>5e-5</cell><cell>5e-5</cell></row><row><cell>weight decay</cell><cell>0</cell><cell>0</cell></row><row><cell>test ratio</cell><cell>0.1</cell><cell>0.1</cell></row><row><cell>validation ratio</cell><cell cols="2">0.05 of training edges 0.05 of all edges</cell></row><row><cell>batch size</cell><cell>32</cell><cell>32</cell></row><row><cell>epochs</cell><cell>50</cell><cell>50</cell></row><row><cell>hops of enclosing subgraph</cell><cell>( * ) 2</cell><cell>2</cell></row><row><cell cols="2">dimension of initial representation Z (0) 16</cell><cell>32</cell></row><row><cell>initial representation Z (0)</cell><cell>ones or DL</cell><cell>unsupervised models</cell></row><row><cell>hidden layers of GCN</cell><cell>32</cell><cell>32</cell></row><row><cell>output layers of GCN</cell><cell>32</cell><cell>32</cell></row><row><cell>hidden layers of attention MLP</cell><cell>32</cell><cell>32</cell></row><row><cell>output layers of attention MLP</cell><cell>32</cell><cell>32</cell></row><row><cell>walk length cutoff ? c</cell><cell>7</cell><cell>7</cell></row><row><cell>heads</cell><cell>2</cell><cell>2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Default hyperparameters for reproducing the reults. ( * ): 3-hop for the Power dataset. Second Best 97.09?0.70 98.85?0.47 95.01?0.34 97.91?0.52 90.32?1.49 91.78?0.61 96.38?1.45 97.64?0.22 WP(DL) 98.68?0.48 98.95?0.41 95.60?0.37 98.37?0.25 92.79?1.09 92.56?0.60 97.27?0.28 98.58?0.19 p-value</figDesc><table><row><cell>Data</cell><cell>USAir</cell><cell>NS</cell><cell>PB</cell><cell>Yeast</cell><cell>C.ele</cell><cell>Power</cell><cell>Router</cell><cell>E.coli</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>p-value by comparing WP and second best algorithm on eight datasets with no attributes. 36?1.00 94.46?0.93 92.36?0.46 89.53?0.63 86.46?1.43 58.76?0.89 56.50?0.51 96.05?0.25 Katz 94.07?1.18 95.05?1.08 93.07?0.46 95.23?0.39 85.93?1.69 79.82?0.91 64.52?0.81 94.83?0.30 PR 95.08?1.16 95.11?1.04 92.97?0.77 95.47?0.43 89.56?1.57 80.56?0.91 64.91?0.85 96.41?0.33 WLK 96.82?0.84 98.79?0.40 93.34?0.89 96.82?0.35 88.96?2.06 83.02?3.19 86.59?2.23 97.25?0.42 WLNM 95.95?1.13 98.81?0.49 92.69?0.64 96.40?0.38 85.08?2.05 87.16?0.77 93.53?1.09 97.50?0.23 N2V 89.71?2.97 94.28?0.91 84.79?1.03 94.90?0.38 83.12?1.90 81.49?0.86 68.66?1.49 90.87?1.48 SPC 78.07?2.92 90.83?2.16 86.57?0.61 94.63?0.56 62.07?2.40 91.00?0.58 73.53?1.47 96.08?0.37 MF 94.36?0.79 78.41?3.85 93.56?0.71 92.01?0.47 83.63?2.09 53.50?1.22 82.59?1.38 95.59?0.31 LINE 79.70?11.76 85.17?1.65 78.82?2.71 90.55?2.39 67.51?2.72 56.66?1.43 71.92?1.53 86.45?1.82 SEAL 97.13?0.80 99.06?0.37 94.55?0.43 98.33?0.37 89.48?1.85 89.55?1.29 96.23?1.71 98.03?0.20 WP(ones) 98.43?0.66 99.04?0.28 95.00?0.46 98.52?0.28 91.14?1.80 92.45?0.72 97.08?0.42 98.74?0.17 WP(DL) 98.66?0.55 99.09?0.29 95.28?0.41 98.64?0.28 91.53?1.33 93.07?0.69 97.20?0.38 98.79?0.21</figDesc><table><row><cell>Data</cell><cell>USAir</cell><cell>NS</cell><cell>PB</cell><cell>Yeast</cell><cell>C.ele</cell><cell>Power</cell><cell>Router</cell><cell>E.coli</cell></row><row><cell>AA</cell><cell>95.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Prediction accuracy measured by AP on eight datasets (90% observed links) without node attributes. Boldface letters are used to mark the best results while underlined letters indicate the second best results.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 9 :</head><label>9</label><figDesc>Prediction accuracy measured by AP on seven datasets (90% observed links) with node attributes.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>the claim follows by induction. 61?0.40 77.13?0.75 87.06?0.17 82.63?0.27 73.37?0.80 53.38?0.22 52.94?0.28 87.66?0.56 Katz 88.91?0.51 82.30?0.93 91.25?0.22 88.87?0.28 79.99?0.59 57.34?0.51 54.39?0.38 89.81?0.46 PR 90.57?0.62 82.32?0.94 92.23?0.21 89.35?0.29 84.95?0.58 57.34?0.52 54.44?0.38 92.96?0.43 WLK 91.93?0.71 87.27?1.71 92.54?0.33 91.15?0.35 83.29?0.89 63.44?1.29 71.25?4.37 92.38?0.46 WLNM 91.42?0.95 87.61?1.63 90.93?0.23 92.22?0.32 75.72?1.33 64.09?0.76 86.10?0.52 92.81?0.30 N2V 84.63?1.58 80.29?1.20 79.29?0.67 90.18?0.17 75.53?1.23 55.40?0.84 62.45?0.81 84.73?0.81 SPC 65.42?3.41 79.63?1.34 78.06?1.00 89.73?0.28 47.30?0.91 56.51?0.94 53.87?1.33 92.00?0.50 MF 91.28?0.71 62.95?1.03 93.27?0.16 84.99?0.49 78.49?1.73 50.53?0.60 77.49?0.64 91.75?0.33 LINE 72.51?12.19 65.96?1.60 75.53?1.78 79.44?7.90 59.46?7.08 53.44?1.83 62.43?3.10 74.50?11.10 SEAL 93.36?0.67 90.88?1.18 93.79?0.25 93.90?0.54 82.33?2.31 65.84?1.10 86.64?1.58 94.18?0.41 WP(ones) 95.16?0.70 90.68?1.04 94.50?0.20 94.89?0.22 87.83?0.83 67.03?0.77 88.09?0.52 95.37?0.22 WP(DL) 95.50?0.74 90.97?0.96 94.57?0.16 95.00?0.21 87.62?1.39 67.72?0.86 88.13?0.61 95.33?0.30</figDesc><table><row><cell>Data</cell><cell>USAir</cell><cell>NS</cell><cell>PB</cell><cell>Yeast</cell><cell>C.ele</cell><cell>Power</cell><cell>Router</cell><cell>E.coli</cell></row><row><cell>AA</cell><cell>88.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 10 :</head><label>10</label><figDesc>Prediction accuracy measured by AUC on eight datasets (50% observed links) without node attributes. Boldface letters are used to mark the best results while underlined letters indicate the second best results. 39?0.39 77.14?0.74 87.24?0.18 82.68?0.27 73.40?0.77 53.37?0.23 52.94?0.27 89.01?0.49 Katz 91.29?0.36 82.69?0.88 91.54?0.16 92.22?0.21 79.94?0.79 57.63?0.52 60.87?0.26 91.93?0.35 PR 91.93?0.50 82.73?0.90 91.92?0.25 92.54?0.23 84.15?0.86 57.61?0.56 61.01?0.30 94.68?0.28 WLK 93.34?0.51 89.97?1.02 92.34?0.34 93.55?0.46 83.20?0.90 63.97?1.81 75.49?3.43 94.51?0.32 WLNM 92.54?0.81 90.10?1.11 91.01?0.20 93.93?0.20 76.12?1.08 66.43?0.85 86.12?0.68 94.47?0.21 N2V 82.51?2.08 86.01?0.87 77.21?0.97 92.45?0.23 72.91?1.74 60.83?0.68 66.77?0.57 85.41?0.94 SPC 70.18?2.16 81.16?1.26 81.30?0.84 92.07?0.27 55.31?0.93 59.10?1.06 59.13?3.22 94.14?0.29 MF 92.33?0.90 66.62?0.89 92.53?0.33 87.28?0.57 77.82?1.59 52.45?0.63 81.25?0.56 94.04?0.36 LINE 71.75?11.85 71.53?0.97 78.72?1.24 83.06?9.70 60.71?6.26 55.11?3.49 64.87?6.76 75.98?14.45 SEAL 94.15?0.54 92.21?0.97 93.42?0.19 95.32?0.38 81.99?2.18 65.28?1.25 87.79?1.71 95.67?0.24 WP(ones) 95.39?0.73 92.15?0.81 94.14?0.27 96.04?0.16 86.49?0.97 69.26?0.64 89.21?0.44 96.35?0.24 WP(DL) 95.87?0.74 92.33?0.76 94.22?0.27 96.15?0.13 86.25?1.42 69.79?0.71 89.17?0.55 96.36?0.34</figDesc><table><row><cell>Data</cell><cell>USAir</cell><cell>NS</cell><cell>PB</cell><cell>Yeast</cell><cell>C.ele</cell><cell>Power</cell><cell>Router</cell><cell>E.coli</cell></row><row><cell>AA</cell><cell>89.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 11 :</head><label>11</label><figDesc>Prediction accuracy measured by AP on eight datasets (50% observed links) without node attributes. Boldface letters are used to mark the best results while underlined letters indicate the second best results.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The output of pooling (e.g., in a CNN) is a often an object of the same type (e.g., a downsampled image). The last layer of a CNN or GNN involves global average pooling which is a graph summarization mechanism similarly as WalkPool, hence the name.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix F. Results with 50% observation</head><p>We further test of the performance of WalkPool under the setup of sparse training set. In particular, we keep only 50% positive links of the graphs for training and use the rest links for testing. The same number of negative links are sampled randomly for the traning set and test set. The results measure by AUC and AP are shown in <ref type="table">Table 10</ref> and 11, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix G. MSE loss and BCE loss</head><p>As link prediction is a classification problem, we usually adopt a classification loss such as binary cross-entropy (BCE). We opted for MSE based on the following heuristic. In node classification, categories are usually clearly defined. For example, in a citation graph, the category of a paper is near-definite. Meanwhile, the topology of real graphs is often fuzzy and evolving. In a co-authorship graph, some authors who have not published together today</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mapping the us political blogosphere: Are conservative bloggers more prominent?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ackland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BlogTalk Downunder 2005 Conference</title>
		<meeting><address><addrLine>Sydney</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Friends and neighbors on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eytan</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social networks</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="230" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Batagelj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Mrvar</surname></persName>
		</author>
		<ptr target="http://vlado.fmf.uni-lj.si/pub/networks/data/" />
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">Pajek datasets website</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The use of the area under the roc curve in the evaluation of machine learning algorithms. Pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bradley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1145" to="1159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Adaptive universal generalized pagerank graph neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olgica</forename><surname>Milenkovic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07988</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning to extract symbolic knowledge from the world wide web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Pipasquo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayne</forename><surname>Freitag</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>Carnegiemellon univ pittsburgh pa school of computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Citeseer: An automatic citation indexing system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lee</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><forename type="middle">D</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third ACM conference on Digital libraries</title>
		<meeting>the third ACM conference on Digital libraries</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data mining</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A new status index derived from sociometric analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="43" />
			<date type="published" when="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Variational graph auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07308</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The link-prediction problem for social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Liben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Nowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American society for information science and technology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1019" to="1031" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Link prediction in complex networks: A survey. Physica A: statistical mechanics and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linyuan</forename><surname>L?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">390</biblScope>
			<biblScope unit="page" from="1150" to="1170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linyuan</forename><surname>L?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mat??</forename><surname>Medo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><forename type="middle">Ho</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Cheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi-Ke</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics Reports</title>
		<imprint>
			<biblScope unit="volume">519</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="49" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Graph infoclust: Leveraging cluster-level node information for unsupervised graph representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Costas</forename><surname>Mavromatis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.06946</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automating the construction of internet portals with machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Kachites</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamal</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Rennie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristie</forename><surname>Seymore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="163" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Birds of a feather: Homophily in social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miller</forename><surname>Mcpherson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynn</forename><surname>Smith-Lovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James M</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of sociology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="415" to="444" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Inbal Ayzenshtat, Michal Sheffer, and Uri Alon. Superfamilies of evolved and designed networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Milo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shalev</forename><surname>Itzkovitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadav</forename><surname>Kashtan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reuven</forename><surname>Levitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Shen-Orr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">303</biblScope>
			<biblScope unit="issue">5663</biblScope>
			<biblScope unit="page" from="1538" to="1542" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Query-driven active surveying for collective classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galileo</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Workshop on Mining and Learning with Graphs</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Finding community structure in networks using the eigenvectors of matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">36104</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A review of relational machine learning for knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="33" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Predicting missing links and identifying spurious links via likelihood analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liming</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linyuan</forename><surname>L?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Kun</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Adversarially regularized graph autoencoder for graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Shirui Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04407</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingzhe</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Chen-Chuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05287</idno>
		<title level="m">Geom-gcn: Geometric graph convolutional networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evaluation of different biological data and computational classification methods for use in protein interaction prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziv</forename><surname>Bar-Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Klein-Seetharaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="490" to="500" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-scale attributed node embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Benedek Rozemberczki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Complex Networks</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Network motifs in the transcriptional regulation network of escherichia coli</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Shen-Orr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shmoolik</forename><surname>Milo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Mangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature genetics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="68" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Weisfeiler-lehman graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nino</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">Jan</forename><surname>Van Leeuwen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Masked label prediction: Unified message passing model for semi-supervised classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsheng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengjie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03509</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Measuring isp topologies with rocketfuel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Spring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ratul</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wetherall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="133" to="145" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Drug response prediction as a link prediction problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Stanfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Co?kun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehmet</forename><surname>Koyut?rk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Line: Largescale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide web</title>
		<meeting>the 24th International Conference on World Wide web</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Leveraging social media networks for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="478" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<title level="m">Graph attention networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Comparative assessment of large-scale data sets of proteinprotein interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Christian Von Mering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berend</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Snel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cornell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peer</forename><surname>Fields</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">417</biblScope>
			<biblScope unit="issue">6887</biblScope>
			<biblScope unit="page" from="399" to="403" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Collective dynamics of &apos;small-world&apos;networks. nature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Watts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strogatz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">393</biblScope>
			<biblScope unit="page" from="440" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Weisfeiler-lehman neural machine for link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="575" to="583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Link prediction based on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="5165" to="5175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Beyond link prediction: Predicting hyperlinks in adjacency space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shali</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Revisiting graph neural networks for link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinglong</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Jin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.16103</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Graph convolutional networks: a comprehensive review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiejun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Maciejewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Social Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
