<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generalizing MLPs With Dropouts, Batch Normalization, and Skip Connections</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taewoon</forename><surname>Kim</surname></persName>
							<email>t.kim@vu.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Vrije Universiteit Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Generalizing MLPs With Dropouts, Batch Normalization, and Skip Connections</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A multilayer perceptron (MLP) is typically made of multiple fully connected layers with nonlinear activation functions. There have been several approaches to make them better (e.g. faster convergence, better convergence limit, etc.). But the researches lack structured ways to test them. We test different MLP architectures by carrying out the experiments on the age and gender datasets. We empirically show that by whitening inputs before every linear layer and adding skip connections, our proposed MLP architecture can result in better performance. Since the whitening process includes dropouts, it can also be used to approximate Bayesian inference. We have open sourced our code, and released models and docker images at https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">MLP and its training objective</head><p>A multilayer perceptron (MLP) is one of the simplest and the oldest artificial neural network architectures. Its origin dates back to 1958 <ref type="bibr" target="#b0">[1]</ref>. Its basic building blocks are linear regression and nonlinear activation functions. One can stack them up to create an MLP with L layers (See <ref type="bibr">Equation 1)</ref>. y = f (L) (W (L) , . . . , f <ref type="bibr" target="#b1">(2)</ref> (W <ref type="bibr" target="#b1">(2)</ref> f <ref type="bibr" target="#b0">(1)</ref> (W <ref type="bibr" target="#b0">(1)</ref> x)), . . . ) <ref type="bibr" target="#b0">(1)</ref> where x,?, W (l) , and f (l) are an input vector, an output vector, the weight matrix, and the nonlinear activation function at the lth layer, respectively. Nonlinearity is necessary since without it, an MLP will collapse into one matrix. The choice of a nonlinear function is a hyperparameter. ReLU <ref type="bibr" target="#b1">[2]</ref> is one of the most widely used activation functions.</p><p>In a supervised setup, where we have a pair of a data sample x (i) and a label y (i) , we aim to reduce the loss (distance) between the model output? (i) and the label y (i) . The loss, L W <ref type="bibr" target="#b0">(1)</ref> ,...,W (L) (? (i) , y (i) ), is parameterized by the weights of all L layers. If we have m pairs of data samples and labels, {(x <ref type="bibr" target="#b0">(1)</ref> , y <ref type="bibr" target="#b0">(1)</ref> ), . . . , (x (m) , y (m) )}, the objective is to minimize the expectation of the loss <ref type="table" target="#tab_2">(See  Equation 2</ref>). E x,y?p data L W <ref type="bibr" target="#b0">(1)</ref> ,...,W (L) (x, y) = 1 m m i=1 L W <ref type="bibr" target="#b0">(1)</ref> ,...,W (L) (x (i) , y (i) )</p><p>Since m can be a large number, we typically batch the m data samples into multiple smaller batches and perform stochastic gradient descent to speed up the optimization process and to reduce memory consumption.</p><p>Backpropagation <ref type="bibr" target="#b2">[3]</ref> is a useful tool to perform gradient descent. This allows us to easily differentiate the loss function with respect to the weights of all L layers, taking advantage of the chain rule.</p><p>So far, we talked about the basics of MLPs and how to optimize them in a supervised setup. In the past decade, there have been many works to improve deep neural network architectures and their performances. In the next section, we'll go through some of the works that can be used to generalize MLPs.</p><p>2 Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dropout</head><p>Dropout <ref type="bibr" target="#b3">[4]</ref> was introduced to prevent neural networks from overfitting. Every neuron in layer l ? 1 has probability 1 ? p of being present. That is, with the probability of p, a neuron is dropped out and the weights that connect to the neurons in layer l will not play a role. p is a hyperparameter whose optimum value can depend on the data, neural network architecture, etc.</p><p>Dropout makes the neural network stochastic. During training, this behavior is desired since this effectively trains many neural networks that share most of the weights. Obviously, the weights that are dropped out won't be shared between the sampled neural networks. This stochasticity works as a regularizer which prevents overfitting.</p><p>The stochasticity isn't always desired at test time. In order to make it deterministic, the weights are scaled down by multiplying by p. That is, every weight that once was dropped out during training will be used at test time, but its magnitude is scaled down to account for the fact that it used to be not present during training.</p><p>In Bayesian statistics, the trained neural network(s) can be seen as a posterior predictive distribution. The authors compare the performance between the Monte-Carlo model averaging and the weight scaling. They empirically show that the difference is minimal.</p><p>In some situations, the stochasticity of a neural network is desired, especially if we want to estimate the uncertainty of model predictions. Unlike regular neural networks, where the trained weights are deterministic, Bayesian neural networks learn the distributions of weights, which can capture uncertainty <ref type="bibr" target="#b4">[5]</ref>. At test time, the posterior predictive distribution is used for inference <ref type="table">(See Equation  3</ref>).</p><formula xml:id="formula_1">p(y | x, X, Y) = p(y | x, X, Y, w)p(w | X, Y)dw (3) where w = {W (i) } L i=1 . Equation 3</formula><p>is intractable. When a regular neural network has dropouts, it's possible to approximate the posterior predictive distribution by performing T stochastic forward passes and averaging the results. This is called "Monte-Carlo dropout" <ref type="bibr" target="#b5">[6]</ref>. In practice, the difference between the Monte-Carlo model averaging and weight scaling is minimal. However, we can use the variance or entropy of the results of T stochastic forward passes to estimate the model uncertainty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Batch normalization</head><p>Batch normalization was first introduced to address the internal covariate shift problem <ref type="bibr" target="#b6">[7]</ref>. Normalization is done simply by subtracting the batch mean from every element in the batch and dividing it by the batch standard deviation. It's empirically shown that batch normalization allows higher learning rates to be used, and thus leading to faster convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Whitening inputs of neural networks</head><p>Whitening decorrelates and normalizes inputs. Instead of using computationally expensive existing techniques, such as ICA (independent component analysis) <ref type="bibr" target="#b7">[8]</ref>, it was shown that using a batch normalization layer followed by a dropout layer can also achieve whitening <ref type="bibr" target="#b8">[9]</ref>. The authors called this the IC (Independent-Component) layer. They argued that their IC layer can reduce the mutual information and correlation between the neurons by a factor of p 2 and p, respectively, where p is the dropout probability.</p><p>The authors suggested that an IC layer should be placed before a weight layer. They empirically showed that modifying ResNet <ref type="bibr" target="#b9">[10]</ref> to include IC layers led to a more stable training process, faster convergence, and better convergence limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Skip connections</head><p>Skip connections were first introduced in convolutional neural networks (CNNs) <ref type="bibr" target="#b9">[10]</ref>. Before then, having deeper CNNs with more layers didn't necessarily lead to better performance, but rather they suffered from the degradation problem. ResNets solved this problem by introducing skip connections. They managed to train deep CNNs, even with 152 layers, which wasn't seen before, and showed great results on some computer vision benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Motivation</head><p>We want to take advantage of the previous works on whitening neural network inputs <ref type="bibr" target="#b8">[9]</ref> and skip connections <ref type="bibr" target="#b9">[10]</ref>, and apply them to MLPs. In each of their original papers, the ideas were tested on CNNs, not on MLPs. However, considering that both a fully connected layer and a convolutional layer are a linear function of f that satisfies <ref type="bibr">Equation 4</ref>, and that their main job is feature extraction, we assume that MLPs can also benefit from them.</p><formula xml:id="formula_2">f (x + y) = f (x) + f (y) and f (ax) = af (x)<label>(4)</label></formula><p>The biggest difference between a convolutional layer and a fully connected layer is that the former works locally, especially spatially, but the latter works globally.</p><p>Also, even the latest neural network architectures, such as the Transformer <ref type="bibr" target="#b10">[11]</ref>, don't use IC layers and skip connections within their fully connected layers. They can potentially benefit from our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Neural network architecture</head><p>Our MLP closely follows <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b9">[10]</ref>. Our MLP is composed of a series of two basic building blocks. One is called the residual block and the other is called the downsample block.</p><p>The residual block starts with an IC layer, followed by a fully connected layer and ReLU nonlinearity. This is repeated twice, as it was done in the original ResNet paper <ref type="bibr" target="#b9">[10]</ref>. The skip connection is added before the last ReLU layer (See <ref type="table">Equation 5</ref>).</p><formula xml:id="formula_3">y = ReLU (W (2) Dropout(BN (ReLU (W (1) Dropout(BN (x))))) + x)<label>(5)</label></formula><p>where x is an input vector to the residual block, BN is a batch normalization layer, Dropout is a dropout layer, ReLU is a ReLU nonlinearity, W 1 is the first fully connected layer, and W 2 is the second fully connected layer. This building preserves the dimension of the input vector. That is, x, y ? R N and W <ref type="bibr" target="#b0">(1)</ref> , W (2) ? R N ?N . This is done intentionally so that the skip connections can be made easily.</p><p>The downsample block also starts with an IC layer, followed by a fully connected layer and ReLU nonlinearity (See <ref type="table">Equation 6</ref>).</p><formula xml:id="formula_4">y = ReLU (W Dropout(BN (x)))<label>(6)</label></formula><p>The dimension is halved after the weight matrix W . That is,</p><formula xml:id="formula_5">x ? R N , W ? R N 2 ?N , and y ? R N 2</formula><p>. This block reduces the number of features so that the network can condense information which will later be used for classification or regression.</p><p>After a series of the two building blocks, one fully connected layer is appended at the end for the regression or classification task. We will only carry out classification tasks in our experiments for simplicity. Therefore, the softmax function is used for the last nonlinearity and the cross-entropy loss will be used for the loss function in Equation 2.</p><p>Although our MLP consists of the functions and layers that already exist, we haven't yet found any works that look exactly like ours. The most similar works were found at <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b12">[13]</ref>.</p><p>[12] used an MLP, whose order is</p><formula xml:id="formula_6">F C ? BN ? ReLU ? Dropout ? F C ? BN ? ReLU ? Dropout,</formula><p>where F C stands for fully-connected. A skip connection is added after the last Dropout. Since ReLU is added between BN and Dropout, their MLP architecture does not benefit from whitening.</p><p>[13] used an MLP, whose order is</p><formula xml:id="formula_7">F C ? BN ? Dropout ? F C ? BN ? Dropout ? ReLU ,</formula><p>where F C stands for fully-connected. A skip connection is added before the last ReLU . Their block does include BN ? Dropout ? F C, like our MLP. However, there is no nonlinearity after the F C. Without nonlinearity after a fully-connected layer, it won't benefit from potentially more complex decision boundaries.</p><p>Since our neural network architecture includes dropouts, we will take advantage of the Monte-Carlo dropout <ref type="bibr" target="#b5">[6]</ref> to model the prediction uncertainty that a model makes on test examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Age and gender datasets</head><p>To test our method in Section 3.2, we chose the age and gender datasets <ref type="bibr" target="#b13">[14]</ref>  <ref type="bibr" target="#b14">[15]</ref>. The Adience dataset <ref type="bibr" target="#b13">[14]</ref> is a five-fold cross-validation dataset. This dataset comes from Flickr album photos and is the most commonly used dataset for age and gender estimation. You can check the leaderboard at https://paperswithcode.com/. The IMDB-WIKI dataset <ref type="bibr" target="#b14">[15]</ref> is bigger than Adience. It comes from celebrity images from IMDB and Wikipedia. We'll report the peformance metrics (i.e. the cross entropy loss and accuracy) on the Adience dataset with five-fold cross-validation so that we can compare our results with others. The IMDB-WIKI dataset is only used for hyperparameter tuning and pretraining.</p><p>The original images from the Adience dataset have the size of 816 ? 816 ? 3 pixels. Although CNNs are known to be good at extracting spatial features from such data, the point of our experiment is to test and compare the MLP architectures. Therefore, we transform the images to fixed-size vectors.</p><p>We use RetinaFace <ref type="bibr" target="#b15">[16]</ref> to get the bounding box and the five facial landmarks, with which we can affine-transform the images to arrays of size 112 ? 112 ? 3 pixels (See <ref type="figure" target="#fig_1">Figure 1</ref>). Besides reducing the size of the data, this also has a benefit of removing background noise.  Next we use ArcFace <ref type="bibr" target="#b16">[17]</ref> to further reduce the size and extract features from the affine-transformed images. ArcFace is a powerful face-embedding extractor which can be used for face recognition. This transformation transforms 112 ? 112 ? 3 pixel arrays to 512-dimensional vectors. It was shown in <ref type="bibr" target="#b17">[18]</ref> that a classifier can be built on such vectors to classify gender. We take this approach further to even classify age as well. <ref type="table" target="#tab_1">Table 1</ref> shows the number of data samples before and after removal, along with the gender distribution. <ref type="table" target="#tab_2">Table 2</ref> shows the number of data samples removed and the reason why they were removed. <ref type="figure" target="#fig_2">Figure  2</ref> shows the age distribution of each dataset. The IMDB-WIKI dataset has a more fine-grained age distribution than the Adience dataset.     <ref type="figure" target="#fig_2">(Figure 2a</ref>) and IMDB-WIKI <ref type="figure" target="#fig_2">(Figure 2b)</ref> datasets. Adience has coarse-grained 8 age categories (i.e. 0-2, 4-6, 8-12, 15-20, 25-32, 38-43, 48-53, and 60-100), while IMDB-WIKI has fine-grained 101 age categories (i.e. from 0 to 100).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training and hyperparameters</head><p>We first pretrain three MLPs with the IMDB-WIKI dataset:</p><p>1. 2-class gender classification.</p><p>2. 8-class age classification 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">101-class age classification.</head><p>There are a number of hyperparameters to be considered to train the models. Some of them are just fixed by following the best practices. For example, we fix the dropout rate to 0.05 as it was shown in <ref type="bibr" target="#b8">[9]</ref>. We use AdamW <ref type="bibr" target="#b18">[19]</ref> for the optimizer, as it was proven to be better than using vanilla Adam <ref type="bibr" target="#b19">[20]</ref>. And we use ExponentialLR for learning rate scheduling. Now the remaining hyperparameters to be determined are the number of residual blocks, number of downsample blocks, batch size, initial learning rate, weight decay coefficient, and multiplicative factor of learning rate decay. They were determined using automatic hyperparameter tuning with Ray Tune <ref type="bibr" target="#b20">[21]</ref>. We also use automatic mixed precision to speed up training. 10% of the IMDB-WIKI datset was held-out from the other 90% so that weights are backpropagated from the 90% of the data, but the best hyperparameters are determined that have the lowest cross-entropy loss on the 10%.</p><p>As for the 2-class gender classification task, the number of residual blocks, number of downsample blocks, batch size, initial learning rate, weight decay coefficient, and multiplicative factor of learning rate decay were chosen to be 4, 4, 512, 2e ? 2, 4e ? 3, and 6e ? 2, respectively.</p><p>As for the 8-class and 101-class age classification tasks, the number of residual blocks, number of downsample blocks, batch size, initial learning rate, weight decay coefficient, and multiplicative factor of learning rate decay were chosen to be 2, 2, 128, 2e ? 3, 1e ? 4, and 4e ? 1, respectively. <ref type="figure" target="#fig_3">Figure 3</ref> shows the neural network architecture of the 2-class gender classification model.  After the models are trained on the IMDB-WIKI dataset, we fine-tune the models on the Adience dataset. This fine-tuning is running five-fold cross-validation five times to get the least biased results. In this case, the 101-class age classification task should be turned into an 8-class classification task, since the Adience dataset only has 8 age classes. We didn't specifically change the network architecture, since it should be able to learn such a thing by itself by updating its weights. <ref type="table">Table 3</ref> shows the loss and accuracy of all of the trained models. The training stopped if validation loss didn't drop for five consecutive epochs, to reduce training time. All of the models are pretty light-weight. The number of parameters is all between 800, 000 and 900, 000. Training time was very fast. We trained everything on our local machine with an RTX 2060 max-q 6GB. Automatic hyperparameter tuning, pretraining on the IMDB-WIKI dataset, and five times of five-fold crossvalidation on the Adience dataset, took about 1 hour and 10 minutes, 5 minutes, and 13 minutes, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Although our models were not specifically designed to have the best age and gender classification performance (e.g. A CNN on raw image data probably would have been a better choice), but to test out different MLP architectures, the performance is very competitive, especially for the gender classification task. However, this table is not so easy to interpret. Good performance on the validation split doesn't necessarily lead to good performance on the test split. Also, low cross-entropy loss on the test split somehow doesn't lead to higher accuracy on the test split either.</p><p>Therefore, we made the cross-entropy loss vs. epochs plots, in <ref type="figure" target="#fig_4">Figure 4</ref>. As you can observe, the biggest performance gap between the model with both the IC layer and skip connections and the models with one or both of them removed is displayed in the validation loss with pretrained initialization. The validation loss is consistently lower than the others when the network is initialized with pretrained models. This shows that a network trained on one dataset with IC layers and skip connections helps to generalize to other datasets.</p><p>As mentioned in 2.1, since our models with the IC layers include dropout, we can use the Monte-Carlo dropout to estimate the prediction uncertainty that a model makes. We ran 512 forward passes and computed the entropy values. Obviously the more forward passes we make, the better the estimate is, since it's sampling from a distribution. The authors in <ref type="bibr" target="#b5">[6]</ref>   <ref type="table">Table 3</ref>: The loss and accuracy of the trained models. The "modified" 8-class age classification models are the ones that were initially trained for the 101-class age classification task, but then repurposed to 8-class classification. Random initialization is done with Kaiming He uniform random initialization <ref type="bibr" target="#b23">[24]</ref>. We ran five-fold cross validation five times. The reported numbers are the averages of the 25 runs. Early stopping was done to save training time. That's why some trainings lasted longer epochs than the others.</p><p>model is very light-weight, running 512 passes on a CPU was not a problem. See <ref type="figure">Figure 5</ref> for the faces with low and high entropy. Interestingly, four out of the ten highest entropy faces are either baby or kid faces, which has low frequency in the Adience dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>MLPs have a long history in neural networks. Although they are ubiquitously used, a systematic research to generalize them has been missing. By placing an IC (Independent-Component) layer to whiten inputs before every fully-connected layer, followed by ReLU nonlinearity, and adding skip connections, our MLP empirically showed it can have a better convergence limit, when its weights are initialized from a pretrained network. Also, since our MLP architecture includes dropouts, we were able to show that our MLP can estimate the uncertainty of model predictions. In the future work, we want to test our idea on different datasets to see how well it can generalize. "modified" 8-class age classification task, respectively. Random initialization is done with Kaiming He uniform random initialization <ref type="bibr" target="#b23">[24]</ref>. We ran five-fold cross validation five times. The reported numbers are the averages of the 25 runs. <ref type="figure">Figure 5</ref>: Top row faces are the ten Adience pictures with the lowest entropy. Their entropy values are all zero, which means that the model is 100% sure of its predictions. Bottom row faces are the ten Adience ones with the highest entropy. Their entropy values are all close to 0.6931, which is the maximum entropy for a binary classification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) Original image, 816 ? 816 ? 3 pixels (b) Affine-transformed to 112 ? 112 ? 3 pixels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>A sample image from the Adience dataset. Instead of using the original images, such asFigure 1a, we use affine-transformed images, as inFigure 1b.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>The age distribution of the IMDB-WIKI dataset The age distribution of the Adience</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>The neural network architecture of the 2-class gender classification model 2 . The skip connections are depicted with the arrows that go over multiple layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>-true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-false skip-connections-false-ic-true skip-connections-false-ic-false -true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-false skip-connections-false-ic-true skip-connections-false-ic-false -true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-false skip-connections-false-ic-true skip-connections-false-ic-false -true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-falseskip-connections-false-ic-true skip-connections-false-ic-false -true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-false skip-connections-false-ic-true skip-connections-false-ic-false -true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-false skip-connections-false-ic-true skip-connections-false-ic-false -true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-false skip-connections-false-ic-true skip-connections-false-ic-false -true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-false skip-connections-false-ic-true skip-connections-false-ic-false -true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-false skip-connections-false-ic-true skip-connections-false-ic-false (i) Training loss, -true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-false skip-connections-false-ic-true skip-connections-false-ic-false (j) Validation loss, -true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-false skip-connections-false-ic-true skip-connections-false-ic-false (k) Training loss, -true-ic-true skip-connections-true-ic-true-nodropout skip-connections-true-ic-false skip-connections-false-ic-true skip-connections-false-ic-false (l) Validation loss, pretrained initialization Cross-entropy loss vs. epoch in training gender and classification, with random and pretrained initialization. The top, middle, and the bottom rows are the 2-class gender, 8-class age, and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The statistics of the Adience and IMDB-WIKI datasets</figDesc><table><row><cell>Dataset</cell><cell>failed to process image</cell><cell>no age found</cell><cell>no gender found</cell><cell>no face detected</cell><cell>bad face quality (det_score &lt;0.9)</cell><cell>more than one face</cell><cell>no face embeddings</cell><cell>total</cell></row><row><cell>Adience</cell><cell>0</cell><cell>748</cell><cell>1,170</cell><cell>322</cell><cell>75</cell><cell>0</cell><cell>0</cell><cell>2,315 (11.95% of original)</cell></row><row><cell>IMDB-WIKI</cell><cell>33,109</cell><cell>2,471</cell><cell>10,938</cell><cell>24,515</cell><cell>4,283</cell><cell>49,457</cell><cell>27</cell><cell>124,800 (23.86 % of original)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The number of images removed</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>used 100 forward passes, but since our model training loss mean (std.) training accuracy mean (std.) validation loss mean (std.) validation accuracy mean (std.) test loss mean (std.) test accuracy mean (std.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>)</cell></row><row><cell>2-class gender classification, random init</cell><cell>0.0650 (0.0074)</cell><cell>0.9800 (0.0030)</cell><cell>0.1180 (0.0150)</cell><cell>0.9639 (0.0063)</cell><cell>0.4353 (0.0785)</cell><cell>0.8406 (0.0273)</cell></row><row><cell>2-class gender classification, random init, no dropout</cell><cell>0.0459 (0.0050)</cell><cell>0.9874 (0.0020)</cell><cell>0.1044 (0.0109)</cell><cell>0.9672 (0.0039)</cell><cell>0.4047 (0.0810)</cell><cell>0.8413 (0.0326)</cell></row><row><cell>2-class gender classification, random init, no IC</cell><cell>0.1879 (0.0618)</cell><cell>0.9425 (0.0102)</cell><cell>0.2067 (0.0623)</cell><cell>0.9336 (0.0121)</cell><cell>0.4622 (0.0914)</cell><cell>0.8207 (0.0389)</cell></row><row><cell>2-class gender classification, random init, no skip connections</cell><cell>0.0666 (0.0067)</cell><cell>0.9805 (0.0021)</cell><cell>0.1176 (0.0130)</cell><cell>0.9614 (0.0052)</cell><cell>0.4217 (0.0865)</cell><cell>0.8340 (0.0345)</cell></row><row><cell>2-class gender classification, random init, no IC, no skip connections</cell><cell>0.6141 (0.1254)</cell><cell>0.6119 (0.1568)</cell><cell>0.6144 (0.1242)</cell><cell>0.6151 (0.1557)</cell><cell>0.6581 (0.0581)</cell><cell>0.5847 (0.1015)</cell></row><row><cell>2-class gender classification, pretrained</cell><cell>0.0332 (0.0021)</cell><cell>0.9917 (0.0009)</cell><cell>0.0810 (0.0167)</cell><cell>0.9772 (0.0049)</cell><cell>0.3120 (0.0604)</cell><cell>0.8887 (0.0255)</cell></row><row><cell>2-class gender classification, pretrained, no dropout</cell><cell>0.0400 (0.0027)</cell><cell>0.9899 (0.0013)</cell><cell>0.0841 (0.0192)</cell><cell>0.9753 (0.0042)</cell><cell>0.2768 (0.0457)</cell><cell>0.8986 (0.0198)</cell></row><row><cell>2-class gender classification, pretrained, no IC</cell><cell>0.0438 (0.0037)</cell><cell>0.9880 (0.0011)</cell><cell>0.0895 (0.0149)</cell><cell>0.9743 (0.0047)</cell><cell>0.2679 (0.0676)</cell><cell>0.9066 (0.0248)</cell></row><row><cell>2-class gender classification, pretrained, no skip connections</cell><cell>0.1110 (0.0050)</cell><cell>0.9707 (0.0021)</cell><cell>0.1389 (0.0128)</cell><cell>0.9596 (0.0059)</cell><cell>0.2833 (0.0338)</cell><cell>0.8937 (0.0171)</cell></row><row><cell>2-class gender classification, pretrained, no IC, no skip connections</cell><cell>0.0633 (0.0033)</cell><cell>0.9833 (0.0012)</cell><cell>0.1041 (0.0177)</cell><cell>0.9693 (0.0061)</cell><cell>0.2835 (0.0659)</cell><cell>0.9034 (0.0227)</cell></row><row><cell>2-class gender classification SOTA [22]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.8966</cell></row><row><cell>8-class age classification, random init</cell><cell>0.0147 (0.0075)</cell><cell>0.9974 (0.0017)</cell><cell>0.2299 (0.0273)</cell><cell>0.9342 (0.0064)</cell><cell>1.6409 (0.1889)</cell><cell>0.5482 (0.0391)</cell></row><row><cell>8-class age classification, random init, no dropout</cell><cell>0.0139 (0.0079)</cell><cell>0.9976 (0.0019)</cell><cell>0.2259 (0.0303)</cell><cell>0.9343 (0.0086)</cell><cell>1.6301 (0.1815)</cell><cell>0.5437 (0.0413)</cell></row><row><cell>8-class age classification, random init, no IC</cell><cell>0.2188 (0.0329)</cell><cell>0.9288 (0.0138)</cell><cell>0.4496 (0.0480)</cell><cell>0.8596 (0.0126)</cell><cell>1.5591 (0.1445)</cell><cell>0.5332 (0.0403)</cell></row><row><cell>8-class age classification, random init, no skip connections</cell><cell>0.0157 (0.0039)</cell><cell>0.9971 (0.0008)</cell><cell>0.2330 (0.0261)</cell><cell>0.9331 (0.0079)</cell><cell>1.6680 (0.1392)</cell><cell>0.5395 (0.0374)</cell></row><row><cell>8-class age classification, random init, no IC, no skip connections</cell><cell>0.4202 (0.0797)</cell><cell>0.8359 (0.0428)</cell><cell>0.7315 (0.0969)</cell><cell>0.7548 (0.0431)</cell><cell>2.0719 (0.2454)</cell><cell>0.4068 (0.0529)</cell></row><row><cell>8-class age classification, pretrained</cell><cell>0.0442 (0.0111)</cell><cell>0.9906 (0.0027)</cell><cell>0.2498 (0.0274)</cell><cell>0.9237 (0.0076)</cell><cell>1.3567 (0.1020)</cell><cell>0.6086 (0.0283)</cell></row><row><cell>8-class age classification, pretrained, no dropout</cell><cell>0.0454 (0.0145)</cell><cell>0.9906 (0.0036)</cell><cell>0.2721 (0.0262)</cell><cell>0.9156 (0.0081)</cell><cell>1.3589 (0.0774)</cell><cell>0.5968 (0.0187)</cell></row><row><cell>8-class age classification, pretrained, no IC</cell><cell>0.0904 (0.0202)</cell><cell>0.9799 (0.0057)</cell><cell>0.3133 (0.0210)</cell><cell>0.9013 (0.0082)</cell><cell>1.3406 (0.0900)</cell><cell>0.6032 (0.0308)</cell></row><row><cell>8-class age classification, pretrained, no skip connections</cell><cell>0.0538 (0.0181)</cell><cell>0.9873 (0.0048)</cell><cell>0.2599 (0.0226)</cell><cell>0.9210 (0.0083)</cell><cell>1.3822 (0.0963)</cell><cell>0.6047 (0.0270)</cell></row><row><cell>8-class age classification, pretrained, no IC, no skip connections</cell><cell>0.1052 (0.0128)</cell><cell>0.9751 (0.0037)</cell><cell>0.3307 (0.0252)</cell><cell>0.8932 (0.0087)</cell><cell>1.3568 (0.1311)</cell><cell>0.5937 (0.0357)</cell></row><row><cell>modified 8-class age classification, random init</cell><cell>0.0188 (0.0040)</cell><cell>0.9968 (0.0008)</cell><cell>0.2354 (0.0271)</cell><cell>0.9343 (0.0073)</cell><cell>1.6534 (0.1735)</cell><cell>0.5445 (0.0397)</cell></row><row><cell>modified 8-class age classification, random init, no dropout</cell><cell>0.0170 (0.0047)</cell><cell>0.9973 (0.0009)</cell><cell>0.2345 (0.0273)</cell><cell>0.9326 (0.0073)</cell><cell>1.6319 (0.1586)</cell><cell>0.5477 (0.0354)</cell></row><row><cell>modified 8-class age classification, random init, no IC</cell><cell>0.4539 (0.0472)</cell><cell>0.8340 (0.0192)</cell><cell>0.5811 (0.0408)</cell><cell>0.7933 (0.0183)</cell><cell>1.3348 (0.1425)</cell><cell>0.5329 (0.0372)</cell></row><row><cell>modified 8-class age classification, random init, no skip connections</cell><cell>0.0198 (0.0049)</cell><cell>0.9965 (0.0009)</cell><cell>0.2336 (0.0270)</cell><cell>0.9326 (0.0081)</cell><cell>1.6528 (0.1671)</cell><cell>0.5435 (0.0371)</cell></row><row><cell>modified 8-class age classification, random init, no IC, no skip connections</cell><cell>0.8561 (0.1304)</cell><cell>0.6270 (0.0584)</cell><cell>0.9393 (0.1106)</cell><cell>0.5967 (0.0519)</cell><cell>1.4231 (0.1128)</cell><cell>0.4270 (0.0388)</cell></row><row><cell>modified 8-class age classification, pretrained</cell><cell>0.0455 (0.0116)</cell><cell>0.9913 (0.0027)</cell><cell>0.2623 (0.0272)</cell><cell>0.9195 (0.0080)</cell><cell>1.3636 (0.0694)</cell><cell>0.6005 (0.0233)</cell></row><row><cell>modified 8-class age classification, pretrained, no dropout</cell><cell>0.0444 (0.0127)</cell><cell>0.9918 (0.0028)</cell><cell>0.2679 (0.0277)</cell><cell>0.9196 (0.0078)</cell><cell>1.4226 (0.1403)</cell><cell>0.5916 (0.0362)</cell></row><row><cell>modified 8-class age classification, pretrained, no IC</cell><cell>0.1100 (0.0216)</cell><cell>0.9726 (0.0064)</cell><cell>0.3482 (0.0238)</cell><cell>0.8930 (0.0065)</cell><cell>1.3880 (0.0790)</cell><cell>0.6030 (0.0216)</cell></row><row><cell>modified 8-class age classification, pretrained, no skip connections</cell><cell>0.0450 (0.0078)</cell><cell>0.9908 (0.0021)</cell><cell>0.2650 (0.0285)</cell><cell>0.9188 (0.0080)</cell><cell>1.4405 (0.0882)</cell><cell>0.5985 (0.0226)</cell></row><row><cell>modified 8-class age classification, pretrained, no IC, no skip connections</cell><cell>0.1311 (0.0221)</cell><cell>0.9655 (0.0068)</cell><cell>0.3538 (0.0230)</cell><cell>0.8890 (0.0065)</cell><cell>1.3887 (0.1497)</cell><cell>0.5967 (0.0344)</cell></row><row><cell>8-class age gender classification SOTA [23]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.6747</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The 101 age categories are converted to the 8 categories by projecting them to the nearest numbers of the Adience dataset.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We didn't add the IC layer (batch norm and dropout) in the beginning of the neural network. The face embedding vectors themselves were supposed to have their own meanings (e.g. the L 2 norm is fixed to 1) and we didn't want to harm them by whitening.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The perceptron: a probabilistic model for information storage and organization in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="386" to="408" />
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on International Conference on Machine Learning, ICML&apos;10</title>
		<meeting>the 27th International Conference on International Conference on Machine Learning, ICML&apos;10<address><addrLine>Madison, WI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">56</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Consistent inference of probabilities in layered networks: Predictions and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esther</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNN International Joint Conference on Neural Networks ; Conference date</title>
		<imprint>
			<date type="published" when="1989-06-22" />
			<biblScope unit="page" from="18" to="24" />
		</imprint>
	</monogr>
	<note>Anon, editor, IJCNN Int Jt Conf Neural Network</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dropout as a bayesian approximation: Representing model uncertainty in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<editor>Maria Florina Balcan and Kilian Q. Weinberger</editor>
		<meeting>The 33rd International Conference on Machine Learning<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="20" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<ptr target="JMLR.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Independent component analysis: algorithms and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="411" to="430" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Rethinking the usage of batch normalization and dropout in the training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Yu</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benben</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyu</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiser</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS&apos;17</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems, NIPS&apos;17<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simple yet effective baseline for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julieta</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayat</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2659" to="2668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Residual mlp network for mental fatigue classification in mining workers from brain data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Q</forename><surname>Ana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Siravenha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N F</forename><surname>Mylena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iraquitan</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renan</forename><forename type="middle">Arthur</forename><surname>Cordeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><forename type="middle">D</forename><surname>Tourinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Schubert</forename><forename type="middle">R</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carvalho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 8th Brazilian Conference on Intelligent Systems (BRACIS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="407" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Age and gender estimation of unfiltered faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eran</forename><surname>Eidinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roee</forename><surname>Enbar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Hassner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2170" to="2179" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dex: Deep expectation of apparent age from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Rasmus Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision Workshops (ICCVW)</title>
		<imprint>
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Retinaface: Single-shot multi-level face localisation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Ververas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Kotsia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Arcface: Additive angular margin loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niannan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4685" to="4694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gender classification using facial embeddings: A novel approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mridul</forename><surname>Chaba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><forename type="middle">Kumar</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Chaba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020. International Conference on Computational Intelligence and Data Science</title>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<biblScope unit="page" from="2634" to="2642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization. CoRR, abs/1412</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">6980</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Tune: A research platform for distributed model selection and training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.05118</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Compacting, picking and growing for unforgetting continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Hao</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-En</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Hung</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Song</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<idno>abs/1910.06562</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fine-grained age estimation in the wild with attention lstm networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Na</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingfang</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenbing</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cir. and Sys. for Video Technol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3140" to="3152" />
			<date type="published" when="2020-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kaiming He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
