<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GLaM: Efficient Scaling of Language Models with Mixture-of-Experts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Du</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Tong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Lepikhin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhong</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Fedus</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongwei</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><forename type="middle">Emma</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kellie</forename><surname>Webster</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Pellat</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Robinson</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Meier-Hellstern</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toju</forename><surname>Duke</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cui</surname></persName>
						</author>
						<title level="a" type="main">GLaM: Efficient Scaling of Language Models with Mixture-of-Experts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Scaling language models with more data, compute and parameters has driven significant progress in natural language processing. For example, thanks to scaling, GPT-3 was able to achieve strong results on in-context learning tasks. However, training these large dense models requires significant amounts of computing resources. In this paper, we propose and develop a family of language models named GLaM (Generalist Language Model), which uses a sparsely activated mixture-of-experts architecture to scale the model capacity while also incurring substantially less training cost compared to dense variants. The largest GLaM has 1.2 trillion parameters, which is approximately 7x larger than GPT-3. It consumes only 1/3 of the energy used to train GPT-3 and requires half of the computation flops for inference, while still achieving better overall zero, one and few-shot performance across 29 NLP tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Language models have played an important role in the progress of natural language processing (NLP) in the past decade. Variants of language models have been used to produce pretrained word vectors <ref type="bibr">(Mikolov et al., 2013;</ref><ref type="bibr" target="#b32">Pennington et al., 2014)</ref>, and contextualized word vectors <ref type="bibr" target="#b33">(Peters et al., 2018;</ref><ref type="bibr">Devlin et al., 2019)</ref> for many NLP applications. The shift towards scaling with more data and larger models <ref type="bibr" target="#b21">Huang et al., 2019;</ref><ref type="bibr" target="#b25">Kaplan et al., 2020)</ref> has enabled complex natural language tasks to be performed with less labeled data. For example, GPT-3 <ref type="bibr" target="#b25">(Brown et al., 2020)</ref> and FLAN <ref type="bibr" target="#b59">(Wei et al., 2021)</ref> demonstrated the Proceedings of the 39 th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the author(s). <ref type="table">Table 1</ref>. Comparison between GPT-3 and GLaM. In a nutshell, GLaM outperforms GPT-3 across 21 natural language understanding (NLU) benchmarks and 8 natural language generative (NLG) benchmarks in average while using about half the FLOPs per token during inference and consuming about one third the energy for training. feasibility of in-context learning for few-shot or even zeroshot generalization, meaning very few labeled examples are needed to achieve good performance on NLP applications. While being effective and performant, scaling further is becoming prohibitively expensive and consumes significant amounts of energy <ref type="bibr" target="#b31">(Patterson et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPT-3 GLaM</head><p>In this work, we show that a large sparsely activated network can achieve competitive results compared to state-of-the-art dense models on few-shot tasks while being more computationally efficient. We present a family of generalist language models called GLaM, that strike a balance between dense and conditional computation. The largest version of GLaM has 1.2T parameters in total with 64 experts per MoE layer <ref type="bibr" target="#b13">Fedus et al., 2021)</ref> where each token in the input batch only activates a subnetwork of 96.6B (8% of 1.2T) parameters. On zero, one and few-shot learning, this model compares favorably to , with significantly improved learning efficiency across 29 public NLP benchmarks, ranging from language completion tasks, open-domain QA tasks, to natural language inference tasks. Thanks to the sparsely activated architecture and the efficient implementation of the model parallelism algorithm, the total energy consumption during training is only one third of GPT-3's. We highlight the comparison between the largest version of GLaM and GPT-3 in <ref type="table">Table 1</ref> and <ref type="figure" target="#fig_1">Figure 1</ref>.   We use GLaM to study the importance of data. Our analysis shows that even for these large models, data quality should not be sacrificed for quantity if the goal is to produce a highquality auto-regressive language model. More importantly, on social dimensions, our results are also the first, to our knowledge, to close the performance gap between stereotypical and anti-stereotypical examples on the WinoGender benchmark, suggesting that large, sparsely activated models may rely less on superficial statistical correlations.</p><p>Finally, although MoE-based sparse models are not yet common in the NLP community, our work shows that sparse decoder-only language models can be more performant than the dense architectures of similar compute FLOPs for the first time within the few-shot in-context learning setting at scale, suggesting that sparsity is one of the most promising directions to achieve high-quality NLP models while saving energy costs <ref type="bibr" target="#b31">(Patterson et al., 2021)</ref>. MoE should therefore be considered as a strong candidate for future scaling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Language models. Neural language models <ref type="bibr">(Mikolov et al., 2010;</ref><ref type="bibr" target="#b54">Sutskever et al., 2011)</ref> have been shown to be useful for many natural language processing tasks. Word embedding models and extensions such as word2vec <ref type="bibr">(Mikolov et al., 2013)</ref>, GloVe <ref type="bibr" target="#b32">(Pennington et al., 2014)</ref> and paragraph vectors <ref type="bibr">(Le &amp; Mikolov, 2014)</ref> have shown good generalization to many tasks simply by transferring the embeddings.</p><p>Pre-training and Fine-tuning. The abundance of compute and data enables training increasingly large models via unsupervised pre-training. This is a natural fit for training neural networks as they exhibit remarkable scalability. Work on using recurrent models such as RNNs and LSTMs for language representation <ref type="bibr">(Dai &amp; Le, 2015;</ref><ref type="bibr" target="#b27">Kiros et al., 2015)</ref> showed that general language models could be fine-tuned to improve various language understanding tasks. More recently, models that used Transformers <ref type="bibr" target="#b55">(Vaswani et al., 2017)</ref> showed that larger models with self-supervision on unlabeled data could yield significant improvements on NLP tasks <ref type="bibr">(Devlin et al., 2019;</ref><ref type="bibr" target="#b62">Yang et al., 2019;</ref><ref type="bibr" target="#b49">Liu et al., 2019;</ref><ref type="bibr" target="#b71">Clark et al., 2020)</ref>. Transfer learning based on pre-training and finetuning <ref type="bibr" target="#b37">(Raffel et al., 2020;</ref><ref type="bibr" target="#b20">Houlsby et al., 2019)</ref> has been extensively studied and demonstrated good performance on downstream tasks. However, a major limitation to this method is that it requires a task-specific fine-tuning.</p><p>In-Context Few-shot Learning. GPT-3 <ref type="bibr" target="#b25">(Brown et al., 2020)</ref> and related work <ref type="bibr" target="#b50">(Shoeybi et al., 2019;</ref><ref type="bibr">Lieber et al., 2021;</ref><ref type="bibr" target="#b59">Wei et al., 2021)</ref> demonstrated that scaling up language models greatly improves task-agnostic, few-shot performance. These language models are applied without any gradient updates, and only few-shot demonstrations specified purely via text interactions with the model are needed.</p><p>Sparsely Gated Networks. Mixture-of-Experts based models have also shown significant advantages. For language modeling and machine translation, <ref type="bibr" target="#b47">Shazeer et al. (2017)</ref> showed that they could effectively use a very large number of weights while only needing to compute a small subset of the computation graph at inference time. There has also been work on scaling sparsely activated MoE architectures <ref type="bibr" target="#b19">(Hestness et al., 2017;</ref><ref type="bibr" target="#b29">Kudugunta et al., 2021)</ref>. <ref type="bibr">Recently, Fedus et al. (2021)</ref> showed results with even larger 1 trillion parameter sparsely activated models (Switch-C). Although both Switch-C and the largest GLaM model have one trillion number of trainable parameters, GLaM is a family of decoder-only language models, and Switch-C is an encoderdecoder based sequence to sequence model. Furthermore, Switch-C is mainly evaluated on fine-tuning benchmarks, e.g., SuperGlue, while GLaM performs well without any <ref type="table">Table 2</ref>. A sample of related models <ref type="bibr">(Devlin et al., 2019;</ref><ref type="bibr" target="#b37">Raffel et al., 2020;</ref><ref type="bibr" target="#b25">Brown et al., 2020;</ref><ref type="bibr">Lieber et al., 2021;</ref><ref type="bibr">Rae et al., 2021;</ref><ref type="bibr" target="#b50">Shoeybi et al., 2019;</ref><ref type="bibr" target="#b13">Fedus et al., 2021)</ref> pre-trained on text corpora. nparams is the total number of trainable model parameters, nact-params is the number of activated model parameters per input token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Name</head><p>Model need for fine-tuning in the few-shot setting shared by GPT-3 where SuperGlue is a subset. <ref type="table">Table 2</ref> summarizes the key differences between GLaM and related models pre-trained on text corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Training Dataset</head><p>To train our model, we build a high-quality dataset of 1.6 trillion tokens that are representative of a wide range of natural language use cases. Web pages constitute the vast quantity of data in our unlabeled dataset. However, their quality ranges from professional writing to low-quality comment and forum pages. Similarly to <ref type="bibr" target="#b25">Brown et al. (2020)</ref>, we develop our own text quality classifier to produce a highquality web corpus out of an original larger raw corpus. We use a feature hash based linear classifier for inference speed. This classifier is trained to classify between a collection of curated text (Wikipedia, books and a few selected websites) and other webpages. We use this classifier to estimate the content quality of a webpage. We then apply this classifier by using a Pareto distribution to sample webpages according to their score. This allows some lower-quality webpages to be included to prevent systematic biases in the classifier <ref type="bibr" target="#b25">(Brown et al., 2020)</ref>. We use this process to generate a high-quality filtered subset For each input token, e.g., 'roses', the Gating module dynamically selects two most relevant experts out of 64, which is represented by the blue grid in the MoE layer. The weighted average of the outputs from these two experts will then be passed to the upper Transformer layer. For the next token in the input sequence, two different experts will be selected.</p><p>of webpages and combine this with books, Wikipedia pages, forums and news pages and other data sources to create the final GLaM dataset. We also incorporate the data from public domain social media conversations used by <ref type="bibr" target="#b2">Adiwardana et al. (2020)</ref>. We set the mixture weights based on the performance of each component in a smaller model and to prevent small sources such as Wikipedia from being over-sampled. <ref type="table" target="#tab_3">Table 3</ref> shows the details of our data component sizes and mixture weights. The mixture weights were chosen based on the performance of the component in a small model and to prevent small datasets such as Wikipedia from being oversampled. To check data contamination, in Section D we conduct an overlap analysis between our training set and the evaluation data and find that it roughly matches that of previous work <ref type="bibr" target="#b25">(Brown et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Model Architecture</head><p>We leverage sparsely activated Mixture-of-Experts (MoE) <ref type="bibr" target="#b13">Fedus et al., 2021)</ref> in GLaM models. Similar to the GShard MoE Transformer , we replace the feed-forward component of every other Transformer layer with an MoE layer, as shown in <ref type="figure" target="#fig_2">Figure 2</ref>. Each MoE layer consists of a collection of independent feed-forward networks as the 'experts'. A gating function then uses a softmax activation function to model a probability distribution over these experts. This distribution indicates how well each expert is able to process the incoming input.</p><p>Even though each MoE layer has many more parameters, the experts are sparsely activated. This means that for a given input token, only a limited subset of experts is used, giving the model more capacity while limiting computation. In our architecture, the subset size is two 1 . Each MoE layer's learnable gating network is trained to use its input to activate the best two experts for each token of an input sequence. During inference, the learned gating network dynamically picks the two best experts for each token. For an MoE layer with E experts, this essentially provides a collection of O(E 2 ) different combinations of feed-forward networks instead of one in the classic Transformer architecture, leading to much more computational flexibility. The final learned representation of a token will be the weighted combination of the outputs from the selected experts.</p><p>We also make additional modifications to the original Transformer architecture. We replace the standard positional embedding with per-layer relative positional bias from <ref type="bibr" target="#b62">Dai et al. (2019)</ref>. In the non-MoE Transformer feed-forward sub-layers, we replace the first linear projection and the activation function with the Gated Linear Unit <ref type="bibr">(Dauphin et al., 2017;</ref><ref type="bibr" target="#b45">Shazeer, 2020)</ref>, which computes the component-wise product of two linear transformation of the input, followed by a Gaussian Error Linear Unit <ref type="bibr" target="#b18">(Hendrycks &amp; Gimpel, 2016)</ref> activation function. We partition the weights and computation of large GLaM models using the 2D sharding algorithm as described in <ref type="bibr" target="#b61">Xu et al. (2021)</ref>, which is described in more details in the Section C of the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiment Setup</head><p>GLaM is a family of dense and sparse decoder-only language models, so we first elaborate our training settings, hyperparameters, and evaluation protocol in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Training Setting</head><p>We train several variants of GLaM to study the behavior of MoE and dense models on the same training data. <ref type="table" target="#tab_4">Table 4</ref> shows the hyperparameter settings of different scale GLaM models ranging from 130 million parameters to 1.2 trillion parameters. Here, E is the number of experts in the MoE layer, B is the mini-batch size, S is the input sequence length, M is the model and embedding dimension, H is 1 Using more experts will cost more compute FLOPs per prediction, pushing the network to be 'denser'. Setting the number of selected experts to be two is based on the trade-off between predictive performance and the training/serving efficiency of the model. the hidden dimension of the feed-forward network, L is the number of layers and N is the number of total devices. Additionally, n params is the total number of trainable model parameters, n act-params is the number of activated model parameters per input token, n heads is the number of selfattention heads, and d head is the hidden dimension of each attention head. We also include the respective dense models with comparable numbers of activated parameters per-token during inference (and thus similar numbers of per-token FLOPs) as references. We adopt the notation of GLaM (Base Dense Size/E) e.g., GLaM (8B/64E) to describe different variants in the GLaM models. For example, GLaM (8B/64E) represents the architecture of an approximate 8B parameter dense model with every other layer replaced by a 64 expert MoE layer. GLaM reduces to a dense Transformer-based language model architecture when each MoE layer only has one expert. We use the notation GLaM (Dense Size) e.g., GLaM (137B) refers to a dense 137B parameter model trained with the same dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Hyperparameters and Training Procedure</head><p>We use the same learning hyperparameters for all GLaM models. More specifically, We use a maximum sequence length of 1024 tokens, and pack each input example to have up to 1 million tokens per batch. The dropout rate is set to 0 since the number of available tokens in the training corpus is much greater than the number of processed tokens during training. Our optimizer is Adafactor <ref type="bibr" target="#b46">(Shazeer &amp; Stern, 2018)</ref> with first-moment decay ? 1 = 0, second-moment decay ? 2 = 0.99 with a 1 ? t ?0.8 decay schedule, update clipping threshold of 1.0, and factored second-moment estimation. We keep the initial learning rate of 0.01 for the first 10K training steps, and then decay it with inverse square root schedule lr t ? 1 ? t . On top of the standard crossentropy loss, we add the MoE auxiliary loss as described in GShard (Lepikhin et al., 2021) with a 0.01 coefficient to encourage expert load balancing so that the gating function will distribute tokens more evenly across all experts. We use the SentencePiece <ref type="bibr" target="#b28">(Kudo &amp; Richardson, 2018)</ref> subword tokenizer with a vocabulary of size of 256K. During training, we use float32 for model weights and bfloat16 for activations. The largest GLaM 64B/64E model was trained on 1,024 Cloud TPU-V4 chips.</p><p>Training models at the trillion parameter scale is extremely expensive even for sparsely activated models. There is little room for hyperparameter tuning. Here we share our training recipes and some implementation tricks for the GLaM models. ? We train smaller-scale models to convergence first. This allows us to expose potential issues in the dataset and infrastructure as early as possible.</p><p>? We skip weight updates for a batch if there are any NaNs or Inf s in the gradients <ref type="bibr" target="#b49">(Shen et al., 2019)</ref>. Note NaN/Inf could still occur during the applying gradient step, in which case we restart from an earlier checkpoint as described below. For example, even if there is no Inf in the existing variable or the gradient, the updated variable could still lead to Inf.</p><p>? We restart from an early healthy checkpoint when encountering rare large fluctuations or even NaN/Inf during training. Randomness of the sequentially loaded batches might help escape from previous failed states in the training after restart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Evaluation Setting</head><p>Protocol. To clearly demonstrate the effectiveness of GLaM models, we mainly focus on evaluating the zero, one and few-shot learning protocols suggested by <ref type="bibr" target="#b35">Radford et al. (2018)</ref>; <ref type="bibr" target="#b25">Brown et al. (2020)</ref>. For the zero-shot learning setting, in most cases, we evaluate each example in the development set directly. For one/few-shot learning, we mainly draw random one/few examples from that task's training set as the only demonstration and context. Such a demonstration is concatenated with the evaluation example with two newlines in between, and then fed into the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmarks.</head><p>To allow for an apples-to-apples comparison between GPT-3 and GLaM, we choose the same suite of evaluation tasks as <ref type="bibr" target="#b25">Brown et al. (2020)</ref>. But for simplicity, we exclude 7 synthetic tasks (arithmetic and word unscramble) and 6 machine translation datasets. With this exclusion, we end up with 29 datasets, which includes 8 natural language generative (NLG) tasks and 21 natural lan-guage understanding (NLU) tasks. These datasets can be further grouped into 7 categories and are listed in section A.</p><p>Natural Language Generative tasks. We compare the language sequences decoded by the models to the ground truth in generative tasks. These tasks are TriviaQA, NQS, WebQS, SQuADv2, LAMBADA, DROP, QuAC and CoQA. The performance is measured by the accuracy of exact match (EM) and F1 score, following the standard for each task in <ref type="bibr" target="#b25">Brown et al. (2020)</ref>. We use beam search with a width of 4 to generate the sequences.</p><p>Natural Language Understanding tasks. Most language understanding tasks require the model to select one correct answer from multiple options. All binary classification tasks are formulated into the form of selecting among two options <ref type="bibr">('Yes' or 'No')</ref>. The prediction is based on the maximum log-likelihood of each option given the context log P (option|context) normalized by the token length of each option. On a few tasks, such as ReCoRD  and COPA , the non-normalized loss can yield better results and thus is adopted. Except for MultiRC  where the F1 metric over the set of answer options (referred to as F1 a ) is reported, the prediction accuracy metric is used for all the other tasks. We use the average of the scores reported in all datasets to report the overall few-shot performance of models on both NLG and NLU tasks. Both Accuracy (EM) and F1 scores have been normalized to lie between 0 and 100. On Trivi-aQA, we also report the testing server score of our one-shot submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head><p>We conduct extensive evaluation on the whole family of GLaM models, to show the advantages of sparsely activated models in language modeling and their scaling trends. We also quantitatively inspect the effectiveness of data quality for language model training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Comparison between MoE and Dense Models</head><p>As previously presented in <ref type="table">Table 1</ref>, GLaM (64B/64E) has competitive performance compared to GPT-3 (175B) for zero, one and few-shot learning. <ref type="figure" target="#fig_1">Figure 1</ref> compares the performance for each category of tasks. In total, GLaM (64B/64E) outperforms GPT-3 in 6 out of 7 categories on average, indicating the performance gain is consistent. For more details on each individual task, see <ref type="table">Table 11</ref>. We include results on the much larger and computationally demanding Megatron-NLG and Gopher for reference. More importantly, as shown in <ref type="table" target="#tab_4">Table 4</ref>, GLaM (64B/64E) activates roughly 96.6B parameters per token during inference, which requires only half of the compute FLOPs needed by GPT-3 given the same input.</p><p>We highlight one particular challenging open-domain question answer task:</p><p>TriviaQA. In open-domain question answer tasks, the model is required to directly answer a given query without access to any additional context. <ref type="bibr" target="#b25">Brown et al. (2020)</ref> show that the few-shot performance of Trivi-aQA is able to grow smoothly with model size, indicating a language model is able to absorb knowledge using its model capacity. As shown in <ref type="table" target="#tab_5">Table 5</ref>, GLaM (64B/64E) is better than the dense model and outperforms the previous finetuned state-of-the-art (SOTA) on this dataset in the opendomain setting. Our one-shot result exceeds the previous finetuned SOTA <ref type="bibr" target="#b63">(Yu et al., 2022)</ref> where additional knowledge graph information is infused by 8.6%, and outperforms the few-shot GPT-3 on the testing server by 5.3%. This suggests that the additional capacity of GLaM plays a crucial role in the performance gain even though the n act-params of GLaM (64B/64E) is only half of that in GPT-3. Comparing to Switch-C, even though both models have similar total number of parameters, GLaM (64B/64E) uses much larger experts (beyond one TPU core) than Switch-C. Therefore, GLaM's one-shot performance on TriviaQA is also better than the fine-tuned results of Switch-C in the open-domain setting. Finally, we report zero, one and few-shot evaluation mainly on the development set for all tasks in <ref type="table">Tables 11, 12</ref>, 13 and 14 of the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Effect of Data Quality</head><p>We study the impact of data quality on the few-shot performance of downstream tasks. We use a modest-size GLaM model (1.7B/64E) to show the effectiveness of filtering text on model quality. We train models with the same hyperparameters on two datasets. One is the original dataset described in Section 3 and the second consists of the dataset with the filtered webpages replaced with the unfiltered webpages. The mixing proportions are fixed as given in <ref type="table" target="#tab_3">Table 3</ref>. KG-FiD (large) <ref type="bibr">(Yu et al., 2022) (finetuned, test)</ref> 69.8</p><formula xml:id="formula_0">Switch-C (finetuned, dev) 47.5 GPT-3 One-shot (dev) 68.0 GPT-3 64-shot (test) 71.2 GLaM One-shot (test) 75.0 GLaM One-shot (dev) 75.8</formula><p>The filtered webpages consist of 143B tokens whereas the unfiltered webpages consist of around 7T tokens.</p><p>Figure 3 (c) and <ref type="bibr">(d)</ref> show that the model trained on filtered data performs consistently better on both NLG and NLU tasks. In particular, the effect of filtering is bigger on NLG than that on NLU. Perhaps this is because NLG often requires generating high-quality language and filtered pretraining corpora is crucial to the generation capability of language models. Our study highlights the fact that the quality of the pretrained data also plays a critical role, specifically, in the performance of downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Scaling Studies</head><p>Scaling up dense language models generally involves making the models deeper by adding more layers, and wider by increasing the embedding dimension of token representations. This process increases the total number of parameters n params of the model. For each prediction on a given input example, these models are 'dense' in that all n params parameters will be activated, i.e., n params = n act-params in <ref type="table" target="#tab_4">Table 4</ref>. Therefore, the effective FLOPs per prediction increases linearly with the model size n params . While the increased FLOPs may lead to boosted predictive performance, it also raises the overall cost per prediction.</p><p>In contrast, GLaM MoE models are sparsely activated in that only a small fraction of the total n params parameters will be activated for each prediction where n params n act-params . Therefore, GLaM MoE models can scale by also growing the size or number of experts in the MoE layer.</p><p>As shown in <ref type="figure" target="#fig_3">Figure 3</ref>(a), the average zero, one and few-shot performance across the generative tasks scales well with the effective FLOPs per prediction which is in turn determined by n act-params . We also find that GLaM MoE models perform consistently better than GLaM dense models for similar effective FLOPs per token. For language understanding tasks shown in <ref type="figure" target="#fig_3">Figure 3</ref>(b), the performance gain of GLaM MoE models has a similar scaling trend to that of the generative tasks. We observe that both MoE and dense models perform similarly at smaller scales but MoE models outperform at</p><formula xml:id="formula_1">GPT3 (zero-shot) GPT3 (one-shot) GPT3 (few-shot) 0.1B/64E 0.1B 1.7B/64E 1.7B 8B/64E 8B 64B/64E</formula><p>137B 20 40 60 0.1 1 10 100 1 000 GFlops per token prediction</p><formula xml:id="formula_2">Score Dense (Few-shot) Dense (One-shot) Dense (Zero-shot) MoE (Few-shot) MoE (One-shot) MoE (Zero-shot) (a) Scaling (NLG) GPT3 (zero-shot) GPT3 (one-shot) GPT3 (few-shot) 0.1B/64E 0.1B 1.7B/64E 1.7B 8B/64E 8B 64B/64E</formula><p>137B 50 60 70 0.1 1 10 100 1 000 GFlops per token prediction larger scales. We also show experiments with scaling the number of experts in Section B where we observe that, for a fixed budget of computation per prediction, adding more experts generally leads to better predictive performance.</p><formula xml:id="formula_3">Score Dense (Few-shot) Dense (One-shot) Dense (Zero-shot) MoE (Few-shot) MoE (One-shot) MoE (Zero-shot) (b) Scaling (NLU) filtered (few-shot) filtered (one-shot)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Efficiency of GLaM</head><p>Existing large dense language models usually require tremendous amounts of computation resources for training and serving <ref type="bibr" target="#b31">(Patterson et al., 2021)</ref>. They also need to consume massive amounts of pretraining data. We investigate the data and compute efficiency of the proposed GLaM models.</p><p>Data Efficiency. <ref type="figure" target="#fig_5">Figure 4</ref> (a-c) and <ref type="figure" target="#fig_5">Figure 4</ref>(e-g) show the learning curves of our models compared to the dense baselines of similar effective FLOPs in both NLG and NLU tasks. The x-axis is the number of tokens used in training where we explicitly include GPT-3's results when it is around 300B tokens. We first observe that GLaM MoE models require significantly less data than dense models of comparable FLOPs to achieve similar zero, one, and fewshot performance. In other words, when the same amount of data is used for training, MoE models perform much better, and the difference in performance becomes larger when training up to 630B. Moreover, GLaM (64B/64E) model trained with 280B tokens outperforms GPT-3 trained with 300B tokens by large margins on 4 out of the 6 learning settings (zero-shot/one-shot NLU and one-shot/few-shot NLG), and matches GPT-3 scores for the remaining setting, i.e., zero-shot NLG tasks. As previously presented in <ref type="table">Table 1</ref>, the GLaM (64B/64E) training after 600B tokens consumes 456 MWh, about 1/3 of the energy cost of 1287 MWh used by GPT-3. Moreover, to reach similar (and slightly exceeded) scores as GPT-3, we train using 1,024 TPU-v4 chips for 574 hours (with 280B tokens). This consumes 213 MWh or 1/6 of the GPT-3 energy cost. The reduced energy consumption of GLaM is due to the MoE architecture and computation efficiency optimizations from TPU-v4 hardware and GSPMD software. Energy calculations can be found in Section F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Ethics and Unintended Biases</head><p>Large language models' zero-and few-shot inference is an exciting capability: being able to control model behaviour intuitively with natural language and small datasets significantly lowers the barrier to prototyping and the development of new applications; it has the potential to help democratise using AI by dramatically decreasing the need for specialist knowledge. However, such opportunities also serve to highlight the importance of the many ethical challenges <ref type="bibr">(Leidner &amp; Plachouras, 2017;</ref><ref type="bibr" target="#b4">Bender et al., 2021;</ref><ref type="bibr" target="#b11">Bommasani et al., 2021)</ref> including representation bias <ref type="bibr" target="#b8">(Blodgett et al., 2020)</ref>, proper selection and handling of training data <ref type="bibr" target="#b40">(Rogers, 2021)</ref> and its documentation <ref type="bibr" target="#b3">(Bender &amp; Friedman, 2018)</ref>, privacy <ref type="bibr" target="#b1">(Abadi et al., 2016b;</ref><ref type="bibr">Carlini et al., 2020)</ref>, and environmental concerns <ref type="bibr" target="#b53">(Strubell et al., 2019;</ref><ref type="bibr" target="#b31">Patterson et al., 2021)</ref>. An important strand of this research focuses on unintended biases learnt by language models, including correlations between gender and profession <ref type="bibr" target="#b10">(Bolukbasi et al., 2016;</ref><ref type="bibr" target="#b42">Rudinger et al., 2018;</ref><ref type="bibr" target="#b67">Zhao et al., 2018)</ref>, negative sentiment about racial and religious groups <ref type="bibr" target="#b37">(Li et al., 2020;</ref><ref type="bibr">Nadeem et al., 2021)</ref>, and about people with disabilities <ref type="bibr" target="#b22">(Hutchinson et al., 2020)</ref>, as well as other social biases  ( <ref type="bibr">Caliskan et al., 2017;</ref><ref type="bibr" target="#b41">Rudinger et al., 2017;</ref><ref type="bibr" target="#b44">Sap et al., 2020;</ref><ref type="bibr" target="#b51">Sotnikova et al., 2021)</ref>. While measuring and mitigating the potential harm of language models is a very active area of research, as recognized by <ref type="bibr" target="#b9">Blodgett et al. (2021)</ref>; <ref type="bibr" target="#b23">Jacobs &amp; Wallach (2021)</ref> there is still a significant need for more rigorous evaluation methods to assess the degree to which language models encode harmful stereotypes <ref type="bibr">(May et al., 2019;</ref><ref type="bibr" target="#b58">Webster et al., 2021)</ref>.</p><p>While there is not yet consensus on measurement methods or criteria for such general purpose large language models, the versatility and power of these models make it important to assess them on a range of metrics. We take inspiration from GPT-3 <ref type="bibr" target="#b25">(Brown et al., 2020)</ref> and examine the co-occurrence in generated text referencing identity terms as well as report on the WinoGender benchmark <ref type="bibr" target="#b42">(Rudinger et al., 2018)</ref>. We also analyse toxicity degeneration similarly to Gopher <ref type="bibr">(Rae et al., 2021)</ref>, and extend the analysis to consider the humanbehavioral baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Co-occurrence prompts</head><p>Following the procedure described in <ref type="bibr" target="#b25">Brown et al. (2020)</ref>, we analyze commonly co-occurring words in the continuations when given prompts like "{term} was very..." where the substituted term references either gender, religions, racial and ethnic identity. For each prompt ( <ref type="table" target="#tab_13">Table 7 of</ref> the appendix), 800 outputs are generated using top-k sampling (k = 40) with a temperature of 1. An off-the-shelf POS tagger <ref type="bibr" target="#b6">(Bird &amp; Loper, 2004</ref>) is used to remove stop words and select only descriptive words (i.e., adjectives and adverbs). Adverbs are included because we noticed a common pattern of errors where adjectives are misclassified as adverbs; for example "pretty" in the phrase "She was very pretty and very accomplished". Like <ref type="bibr" target="#b25">Brown et al. (2020)</ref>, to make the analysis transparent and easily reproducible, we omit any manual human labeling.</p><p>Like the analysis of other large language models that we build on, we note associative biases for all dimensions are obvious, for example "pretty" is the most associated description for the term "She", while it is not in the top-10 for the term "He". <ref type="table">Table 8</ref> shows the most frequently occurring descriptive words in response to prompt-templates for gendered pronouns, and Tables 9 and 10 of the appendix show the same for race and religion prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">WinoGender</head><p>Coreference resolution is a capability that many applications require to perform well, including machine translation <ref type="bibr" target="#b52">(Stanovsky et al., 2019;</ref><ref type="bibr" target="#b57">Webster &amp; Pitler, 2020)</ref>  ence errors in the one-shot setting, we measure WinoGender <ref type="bibr" target="#b42">(Rudinger et al., 2018)</ref>. GLaM (64B/64E) achieves a new state-of-the-art of 71.7% on the full dataset (compared to 64.2% for GPT-3 <ref type="bibr" target="#b25">(Brown et al., 2020)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Toxicity Degeneration</head><p>Toxicity degeneration is when a language model produces text that is unintentionally toxic. To evaluate toxicity degeneration, we adapt the methodology used in <ref type="bibr" target="#b60">(Welbl et al., 2021;</ref><ref type="bibr">Rae et al., 2021)</ref>. We use the RealToxicityPrompts dataset <ref type="bibr" target="#b15">(Gehman et al., 2020)</ref> which consists of sentences that have been split into two parts: a prompt prefix, and a continuation postfix. Like the previous studies, we also use the Perspective API which assigns a probability that the text would be considered to be rude, disrespectful or otherwise likely to make people want to leave a conversation. We then asses how likely a continuation is to be toxic given various likelihoods that the prompt was toxic.</p><p>For each of 10K randomly sampled prompts, we generate 25 continuations, with up to 100 tokens per continuations using top-k sampling (k = 40) with a temperature of 1. The Perspective API requires an non-empty string therefore we assign a score of toxicity 0.0 when the continuation is the empty string; this could represent, for example, a chat bot simply refusing to respond. <ref type="figure" target="#fig_6">Figure 5</ref> shows the relationship between the Toxicity Probability of the Prompt (TPP), and the Toxicity Probability of the Continuation (TPC). Note that, for low TPP, the relatively high human TPC is due to the sampling strategy used to create the underlying dataset: sentences were selected across the toxicity spectrum. Moreover, toxicity can often be identified locally within a sentence, and toxicity in this dataset tends to occur later the sentences. This causes the human-TPC to slightly drop as the TPP increases. In contrast, it is noteworthy that the model's TPC closely follows TPP, reflecting the frequent observation that large language models are sometimes overly-strongly influenced by their prompt, e.g. repeating phrases from the prompt.</p><p>We also analysed the distribution of toxicity probabilities from the API for batches of 25 continuations. This highlighted that, even for low toxicity prompts, it is very likely that some generated continuation will be judged as toxic by most people reviewing it, according to the Perspective API's predicted probability; further details can be found in <ref type="figure">Figure  8</ref>. We also note that this dataset's sampling strategy, and the source it is taken from (Reddit) are likely not reflective of other domains. Moreover, even for very low TPP, applications are likely to want a much lower TPC: even generating 1 in 100 toxic suggestions is likely to be very problematic for applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Discussion</head><p>As observed in previous work on sparsely-activated models <ref type="bibr" target="#b13">(Fedus et al., 2021)</ref>, MoE models are more performant in knowledge-oriented tasks. Open-domain tasks are one way of measuring the amount of knowledge stored in a model. The performance of the MoE model in open-domain QA benchmarks such as TriviaQA demonstrate the significantly increased information capacity of these models compared to dense models of similar effective FLOPs. Despite the in-context learning and training efficiency advantages, the sparsely activated models consist of a higher number of parameters and thus require a larger number of devices. This limits the resource accessibility and increases the serving cost especially when the serving traffic is low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Conclusions</head><p>We propose and develop a family of generalist language models called GLaM, which use a sparsely activated mixture-of-experts architecture to achieve better average scores than not only their dense counterparts of similar effective FLOPs, but also the GPT-3 models on 29 representative NLP tasks in zero, one and few-shot learning. In particular, GLaM (64B/64E), our largest 1.2 trillion parameter MoE language model, achieves better average performance with only one third of energy consumption compared to training GPT-3. We hope that our work will encourage more research into methods for obtaining high-quality data, and using MoE for more efficient scaling of giant language models. G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., <ref type="bibr">Radford</ref> Mostafazadeh, N., Chambers, N., He, X., Parikh, D., Batra, D., Vanderwende, L., Kohli, P., and Allen, J. A corpus and cloze evaluation for deeper understanding of commonsense stories. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Scaling the Number of Experts</head><p>We also study the effects of increasing the number of experts per MoE layer. More concretely, we start with a modest size model of 1.7B, which essentially is a GLaM (1.7B/1E) model where each MoE layer reduces to include only a single feed-forward network as the expert. We then increase the number of experts in each MoE layer from 1 to 256. Despite the fact that the number of experts increases exponentially, the n act-params in each model barely increases due to the sparsity of GLaM. In fact, as shown in <ref type="table" target="#tab_4">Table 4</ref>, they all have almost identical FLOPs per prediction.</p><p>In <ref type="figure">Figure 6</ref>, we observe that, for a fixed budget of computation per prediction, adding more experts generally leads to better predictive performance. This further verifies the performance gain of GLaM sparsely activated models over the dense counterparts when both have similar FLOPs per prediction, thanks to the increased capacity and flexibility from more experts.  <ref type="figure">Figure 6</ref>. Average zero, one and few-shot performance versus the number of experts per layer for a set of modest-size models from 1.7B/1E to 1.7B/256E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Model Partitioning</head><p>We partition the weights and computation of large GLaM models using the 2D sharding algorithm as described in <ref type="bibr" target="#b61">Xu et al. (2021)</ref>, which exploits the 2D topology of the device network of the TPU cluster. We place experts with the same index across different MoE layers on the same device in order to generate an identical computation graph for different MoE layers. As a result, we can wrap the repetitive modules of the MoE Transformer architecture in a while loop control flow statement <ref type="bibr" target="#b0">(Abadi et al., 2016a;</ref><ref type="bibr" target="#b64">Yu et al., 2018)</ref> to reduce compilation time. Our experiments reveal that we should grow the size of the experts to get high quality models. Therefore, when each expert gets sufficiently large, we have to allocate each expert across a set of N E devices. For example, we partition the expert weight tensor with the shape [E, M, H] in the MoE layer along the expert dimension E, and hidden dimension H, and partition the input activation tensors with the shape [B, S, M ] along the batch dimension B and the model dimension M . With this 2D sharding algorithm, we are then able to fully divide those large weight and activation tensors into smaller pieces such that there is no redundancy in data or compute across all devices. We rely on GSPMD's compiler pass <ref type="bibr" target="#b61">(Xu et al., 2021)</ref> to automatically determine the sharding properties for the rest of the tensors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Data Contamination</head><p>As GLaM was trained on over 1.6 trillion tokens of text, it is a valid concern that some of the test data might appear exactly in the pretraining dataset, inflating some of the results. We therefore follow <ref type="bibr" target="#b25">Brown et al. (2020)</ref> and <ref type="bibr" target="#b59">Wei et al. (2021)</ref> and quantify the overlap between pretraining data and evaluation datasets.</p><p>Our analysis uses the same methodology as <ref type="bibr" target="#b59">Wei et al. (2021)</ref>, which, in turn closely follows <ref type="bibr" target="#b25">Brown et al. (2020)</ref>. For each evaluation dataset we report the number of examples which overlap with the pretraining data, defining overlap as having any n-gram, which also appears in the pretraining data (varying n between datasets). We find that the number of validation examples appearing verbatim in the training data roughly matches that of prior work. We report these numbers in <ref type="table" target="#tab_11">Table 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Ethics and Unintended Biases</head><p>Like <ref type="bibr">Rae et al. (2021)</ref>, we also analyzed toxicity degeneration with with respect to model scale. This is shown in <ref type="figure" target="#fig_7">Figure 7</ref>. As with other analysis GLaM's performance on this benchmark, it is fairly consistent across model sizes and with MoE variants. The 0.1B/64E MoE variant, the smallest sparse variant analyzed, is noticeable in the plot and smaller MoE models may be less stable, as noted by <ref type="bibr">Rae et al. (2021)</ref>.</p><p>Following <ref type="bibr">Rae et al. (2021)</ref>, we also analysed the aspect of the distribution of generated toxicity probabilities with respect to model scale. The same pattern of scale-in-variance is observed with respect to the maximal expected toxicity probability of a continuation. The distribution of toxicity probabilities from the API for 25 continuations is plotted    <ref type="figure">Figure 8</ref>. This shows that, even for low toxicity prompts, it is very likely that some generated continuation would be judged as toxic by most people reviewing it, according to the Perspective API's model. <ref type="table" target="#tab_13">Table 7</ref> shows the prompts used for the co-occurrence evaluation; these are the same as those of <ref type="bibr" target="#b25">Brown et al. (2020)</ref>. The top associations for gender templates are shown in <ref type="table" target="#tab_14">Table 8, and Tables 9 and 10</ref> show the same for the race and religion prompt templates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Energy Usage</head><p>The power usage effectiveness (PUE) of the datacenter at the time of training (August and September 2021) was 1.11. Using 326W measured system power per TPU-v4 chip, this leads to a total energy consumption of 213 MWh for GLaM, 1/6 of the energy cost of <ref type="bibr">GPT-3, 1287</ref> MWh. The datacenter PUE was 1.10 at the time of training GPT-3 <ref type="bibr" target="#b31">(Patterson et al., 2021)</ref>. The reduced energy consumption of GLaM is due to the MoE architecture and computation efficiency optimizations from TPU-v4 hardware and GSPMD software. Expected toxicity for non-toxic prompts, 8B-dense <ref type="figure">Figure 8</ref>. Expected toxicity probability given low toxicity probability prompts for 8B Dense variant. This chart shows distributions underlying the expected maximum toxicity metric for the 8B Dense model. The y-axis shows expected toxicity and the x-axis shows the distribution aggregated at different percentiles. At the left, the minimum continuation toxicity reflects that after repeated evaluations of 25 samples the least toxic response for some outlier non-toxic prompts was 0.8 likely to be perceived as toxicity. At the right we see that the worst-case toxicity has an almost uniform distribution across non-toxic prompts. In other words, in 25 samples across low probability toxic prompts, for the majority of trials, there will be a high toxicity probability continuation.</p><p>As a result of low energy consumption, GLaM training has lower CO 2 emissions as well. The net tCO 2 e per MWh of the datacenter at the time was 0.088, training GLaM with 280B tokens emits a total of 18.7 net tCO 2 e, compared to 552 net tCO2e for GPT-3 <ref type="bibr" target="#b31">(Patterson et al., 2021)</ref>. The complete GLaM training using 600B tokens consumes only 456 MWh and emits 40.2 net tCO 2 e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Results on All Tasks for All Model Sizes</head><p>We include the zero/one/few-shot results of different model sizes on all the tasks in <ref type="table">Table 11</ref>, 12, 13 and 14. <ref type="table">Table 8</ref>. Gender: top co-occurrences for prompts like "{term} was very..." "He" "She"</p><p>The top 10 most common descriptive words (and counts).</p><p>much <ref type="formula">(188)</ref> pretty <ref type="formula">(232)</ref> great <ref type="formula">(130)</ref> little <ref type="formula">(185)</ref> well <ref type="formula">(129)</ref> much <ref type="formula">(154)</ref> little <ref type="formula">(129)</ref> beautiful <ref type="formula">(148)</ref> good <ref type="formula">(124)</ref> always <ref type="formula">(142)</ref> always <ref type="formula">(114)</ref> good <ref type="formula">(136)</ref> black <ref type="formula">(103)</ref> black <ref type="formula">(117)</ref> even <ref type="formula">(92)</ref> never (116) many <ref type="formula">(87)</ref> even <ref type="formula">(111)</ref> also <ref type="formula">(83)</ref> well (110)  Jewish, also, religious, responsible, many, even, well, generally, often, different <ref type="table">Table 11</ref>. Scores of GLaM (64B/64E), GPT-3 and Gopher across all 29 benchmarks. We include the significantly larger and more computationally expensive Gopher and Megatron-NLG models for reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zero-shot</head><p>One-shot Few-shot (shots)  <ref type="table" target="#tab_4">Table 14</ref>. Few-shot scores on all 29 benchmarks for GPT3 and different GLaM MoE and dense models. We tune the number of shots up to the respective value in each task used by GPT3. </p><formula xml:id="formula_4">Name Metric Split GPT-3 (175B) GLaM (64B/64E) GPT-3 (175B) GLaM (64B/64E) GPT-3 (175B) Gopher (280B) Megatron-NLG<label>(530B)</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>An overview of the percentage change in predictive performance (higher is better) of GLaM (64B/64E) versus GPT-3 (175B) in the (a) zero-shot, (b) one-shot, and (c) few-shot setting across 7 benchmark categories with 29 public tasks in total. Each bar in panel (a), (b) and (c) represents one benchmark category. Panel (d) compares the FLOPs needed per token prediction and training energy consumption.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>GLaM model architecture. Each MoE layer (the bottom block) is interleaved with a Transformer layer (the upper block).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Average zero, one and few-shot performance of GLaM MoE models versus GLaM dense models for similar effective FLOPs per token over the 8 NLG tasks (a) and 21 NLU tasks (b). Comparison of model performance with filtered and unfiltered training data using GLaM (1.7B/64E). Filtered data improves results significantly over unfiltered data for both (c) NLG and (d) NLU tasks across zero, one and few-shot settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Computation andFigure 4(h) show how the average zero, one and few-shot performance scales with the number of TPU years spent training MoE and dense models. We find that to achieve similar performance on downstream tasks, training sparsely activated models takes much less computational resources than training dense models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Learning efficiency comparison. Average zero-shot , one-shot and few-shot performance of GLaM MoE models versus GLaM dense models as more tokens are processed during training for 9 NLG tasks (a-c) and 21 NLU tasks (e-g). Panel (d) and (h) also display the learning curves against the number of TPU years, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>and question answering(Lamm et al., 2020). To assess whether gendered correlations in GLaM cause it to make corefer-GLaM: Efficient Scaling of Language Models with Mixture-of-Experts The relationship between the Toxicity Probability of the Prompt (TPP), and the Toxicity Probability of the Continuation (TPC). Human refers to the continuation of the original humanwritten sentence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Toxicity degeneration scaling plot. The different shades show different buckets of prompt toxicity probability. The y-axis shows the expected probability of a continuation being toxic. The 0.1B/64E variant is noticeable, but as model parameters scale, the relationship to continuation toxicity constant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Data and mixture weights in GLaM training set.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Tokens (B) Weight in mixture</cell></row><row><cell>Filtered Webpages</cell><cell>143</cell><cell>0.42</cell></row><row><cell>Wikipedia</cell><cell>3</cell><cell>0.06</cell></row><row><cell>Conversations</cell><cell>174</cell><cell>0.28</cell></row><row><cell>Forums</cell><cell>247</cell><cell>0.02</cell></row><row><cell>Books</cell><cell>390</cell><cell>0.20</cell></row><row><cell>News</cell><cell>650</cell><cell>0.02</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Sizes and architectures of both MoE and dense models that we have trained in our experiments. Models are grouped by the number of activated parameters per token. All trained models share the same learning hyperparameters described in Session 5.1.</figDesc><table><row><cell>GLaM Model</cell><cell>Type</cell><cell cols="2">nparams nact-params</cell><cell>L</cell><cell>M</cell><cell>H</cell><cell cols="2">nheads dhead</cell><cell>E</cell></row><row><cell>0.1B 0.1B/64E</cell><cell cols="2">Dense 130M MoE 1.9B</cell><cell>130M 145M</cell><cell>12</cell><cell>768</cell><cell>3,072</cell><cell>12</cell><cell>64</cell><cell>-64</cell></row><row><cell>1.7B</cell><cell>Dense</cell><cell>1.7B</cell><cell>1.700B</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>1.7B/32E</cell><cell>MoE</cell><cell>20B</cell><cell>1.878B</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>32</cell></row><row><cell>1.7B/64E</cell><cell>MoE</cell><cell>27B</cell><cell>1.879B</cell><cell cols="2">24 2,048</cell><cell>8,192</cell><cell>16</cell><cell>128</cell><cell>64</cell></row><row><cell>1.7B/128E</cell><cell>MoE</cell><cell>53B</cell><cell>1.881B</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>128</cell></row><row><cell>1.7B/256E</cell><cell>MoE</cell><cell>105B</cell><cell>1.886B</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>256</cell></row><row><cell>8B 8B/64E</cell><cell>Dense MoE</cell><cell>8.7B 143B</cell><cell>8.7B 9.8B</cell><cell cols="3">32 4,096 16,384</cell><cell>32</cell><cell>128</cell><cell>-64</cell></row><row><cell>137B</cell><cell>Dense</cell><cell>137B</cell><cell>137B</cell><cell cols="3">64 8,192 65,536</cell><cell>128</cell><cell>128</cell><cell>-</cell></row><row><cell>64B/64E</cell><cell>MoE</cell><cell>1.2T</cell><cell>96.6B</cell><cell cols="3">64 8,192 32,768</cell><cell>128</cell><cell>128</cell><cell>64</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>GLaM (64B/64E) one-shot performance significantly outperforms prior SOTAs for open domain settings in the wiki split.</figDesc><table><row><cell>Model</cell><cell>TriviaQA (Open-Domain)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>, A., Sutskever, I., and Amodei, D. Language models are few-shot learners. Dagan, I., Glickman, O., and Magnini, B. The pascal recognising textual entailment challenge. In Qui?onero-Candela, J., Dagan, I., Magnini, B., and d'Alch? Buc, F. (eds.), Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment, pp. 177-190, Berlin, Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Kelcey, M., Devlin, J., Lee, K., Toutanova, K. N., Jones, L., Chang, M.-W., Dai, A., Uszkoreit, J., Le, Q., and Petrov, S. Natural questions: a benchmark for question answering research. Transactions of the Association of Computational Linguistics, 2019. November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp. 311. URL https://aclanthology.org/2020. findings-emnlp.311.</figDesc><table><row><cell>In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F., and Lin, H. (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 1877-1901. Curran Asso-ciates, Inc., 2020. URL https://proceedings. neurips.cc/paper/2020/file/ 1457c0d6bfcb4967418bfb8ac142f64a-Paper. Lai, G., Xie, Q., Liu, H., Yang, Y., and Hovy, E. RACE: Large-scale ReAding comprehension dataset from ex-aminations. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 785-794, Copenhagen, Denmark, September 2017. Asso-pdf. Caliskan, A., Bryson, J. J., and Narayanan, A. Seman-tics derived automatically from language corpora contain ciation for Computational Linguistics. doi: 10.18653/v1/ D17-1082. URL https://aclanthology.org/ D17-1082.</cell><cell>Online, Lieber, O., Sharir, O., Lenz, B., and Shoham, Y. Jurassic-1: Technical details and evaluation. White Paper. AI21 Labs, Heidelberg, 2006. Springer Berlin Heidelberg. ISBN 2021. 978-3-540-33428-6. Dai, A. M. and Le, Q. V. Semi-supervised sequence learning. In Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., and Garnett, R. (eds.), Advances in Neural Information Processing Systems, volume 28. Curran As-Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019. sociates, Inc., 2015. URL https://proceedings. neurips.cc/paper/2015/file/ 7137debd45ae4d0ab9aa953017286b20-Paper. May, C., Wang, A., Bordia, S., Bowman, S. R., and Rudinger, R. On measuring social biases in sentence encoders. In Proceedings of the 2019 Conference of the</cell></row><row><cell>human-like biases. Science, 356(6334):183-186, Apr Lamm, M., Palomaki, J., Alberti, C., Andor, D., Choi, E., 2017. ISSN 1095-9203. doi: 10.1126/science.aal4230. URL http://dx.doi.org/10.1126/science. aal4230. Carlini, N., Tram?r, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T. B., Song, D., Er-lingsson,?., Oprea, A., and Raffel, C. Extracting training data from large language models. CoRR, abs/2012.07805, Soares, L. B., and Collins, M. QED: A framework and dataset for explanations in question answering. CoRR, abs/2009.06354, 2020. URL https://arxiv.org/ abs/2009.06354. Le, Q. and Mikolov, T. Distributed representations of sen-tences and documents. In International conference on machine learning, 2014. 2020. Choi, E., He, H., Iyyer, M., Yatskar, M., Yih, W.-t., Choi, Y., Liang, P., and Zettlemoyer, L. QuAC: Question an-swering in context. In Proceedings of the 2018 Confer-ence on Empirical Methods in Natural Language Pro-cessing, pp. 2174-2184, Brussels, Belgium, October-November 2018. Association for Computational Lin-Leidner, J. L. and Plachouras, V. Ethical by design: Ethics best practices for natural language processing. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing, pp. 30-40, Valencia, Spain, April 2017. Association for Computational Lin-guistics. doi: 10.18653/v1/W17-1604. URL https: //aclanthology.org/W17-1604. guistics. doi: 10.18653/v1/D18-1241. URL https: Lepikhin, D., Lee, H., Xu, Y., Chen, D., Firat, O., Huang, //aclanthology.org/D18-1241. Y., Krikun, M., Shazeer, N., and Chen, Z. GShard: Scal-</cell><cell>pdf. North American Chapter of the Association for Com-putational Linguistics: Human Language Technologies, Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q., and Volume 1 (Long and Short Papers), pp. 622-628, Min-Salakhutdinov, R. Transformer-XL: Attentive language neapolis, Minnesota, June 2019. Association for Compu-models beyond a fixed-length context. In Proceed-tational Linguistics. doi: 10.18653/v1/N19-1063. URL ings of the 57th Annual Meeting of the Association for https://aclanthology.org/N19-1063. Computational Linguistics, pp. 2978-2988, Florence, Italy, July 2019. Association for Computational Lin-Mihaylov, T., Clark, P., Khot, T., and Sabharwal, A. Can a guistics. doi: 10.18653/v1/P19-1285. URL https: suit of armor conduct electricity? a new dataset for open //aclanthology.org/P19-1285. book question answering. In EMNLP, 2018. Dauphin, Y. N., Fan, A., Auli, M., and Grangier, D. Lan-Mikolov, T., Karafi?t, M., Burget, L., Cernock?, J. H., and guage modeling with gated convolutional networks. In Khudanpur, S. Recurrent neural network based language International conference on machine learning, pp. 933-model. In INTERSPEECH, 2010. 941. PMLR, 2017. de Marneffe, M.-C., Simons, M., and Tonhauser, J. The commitmentbank: Investigating projection in naturally Mikolov, T., Chen, K., Corrado, G., and Dean, J. Efficient estimation of word representations in vector space. In Bengio, Y. and LeCun, Y. (eds.), 1st International Confer-occurring discourse. Proceedings of Sinn und Bedeutung, ence on Learning Representations, ICLR 2013, Scottsdale, 23(2):107-124, Jul. 2019. doi: 10.18148/sub/2019.v23i2. Arizona, USA, May 2-4, 2013, Workshop Track Proceed-</cell></row><row><cell>ing giant models with conditional computation and auto-Clark, C., Lee, K., Chang, M.-W., Kwiatkowski, T., Collins, ing difficulty of natural yes/no questions. In Proceed-ings of the 2019 Conference of the North American net/forum?id=qrwe7XHTmYb. Representations, 2021. URL https://openreview. M., and Toutanova, K. BoolQ: Exploring the surpris-matic sharding. In International Conference on Learning</cell><cell>601. ings, 2013. URL http://arxiv.org/abs/1301. URL https://ojs.ub.uni-konstanz. Pre-training of deep bidirectional transformers for lan-Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. BERT: de/sub/index.php/sub/article/view/601. 3781.</cell></row><row><cell>Chapter of the Association for Computational Linguis-Levesque, H., Davis, E., and Morgenstern, L. The wino-</cell><cell>guage understanding. In Proceedings of the 2019 Confer-</cell></row><row><cell>tics: Human Language Technologies, Volume 1 (Long grad schema challenge. In 13th International Confer-</cell><cell>ence of the North American Chapter of the Association</cell></row><row><cell>and Short Papers), pp. 2924-2936, Minneapolis, Min-ence on the Principles of Knowledge Representation and</cell><cell>for Computational Linguistics: Human Language Tech-</cell></row><row><cell>nesota, June 2019. Association for Computational Lin-Reasoning, KR 2012, Proceedings of the International</cell><cell>nologies, Volume 1 (Long and Short Papers), 2019.</cell></row><row><cell>guistics. doi: 10.18653/v1/N19-1300. URL https: //aclanthology.org/N19-1300. Clark, K., Luong, M.-T., Le, Q. V., and Manning, C. D. Elec-tra: Pre-training text encoders as discriminators rather than generators. arXiv preprint arXiv:2003.10555, 2020. Conference on Knowledge Representation and Reason-ing, pp. 552-561. Institute of Electrical and Electronics Engineers Inc., 2012. ISBN 9781577355601. 13th In-ternational Conference on the Principles of Knowledge Representation and Reasoning, KR 2012 ; Conference date: 10-06-2012 Through 14-06-2012.</cell><cell>Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S., and Gardner, M. DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs. In Burstein, J., Doran, C., and Solorio, T. (eds.), Pro-ceedings of the 2019 Conference of the North Ameri-can Chapter of the Association for Computational Lin-</cell></row><row><cell>Li, T., Khashabi, D., Khot, T., Sabharwal, A., and Srikumar,</cell><cell>guistics: Human Language Technologies, NAACL-HLT</cell></row><row><cell>V. UNQOVERing stereotyping biases via underspeci-</cell><cell>2019, Minneapolis, MN, USA, June 2-7, 2019, Vol-</cell></row><row><cell>fied questions. In Findings of the Association for Com-</cell><cell>ume 1 (Long and Short Papers), pp. 2368-2378. As-</cell></row><row><cell>putational Linguistics: EMNLP 2020, pp. 3475-3489,</cell><cell>sociation for Computational Linguistics, 2019. doi:</cell></row></table><note>Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., and Tafjord, O. Think you have solved question answering? try arc, the ai2 reasoning challenge.arXiv:1803.05457v1, 2018.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 .</head><label>6</label><figDesc>Overlap statistics for the subset of datasets that are also used in GPT-3. An evaluation example was dirty if it had any n-gram collision with the pretraining corpus.</figDesc><table><row><cell>Dataset</cell><cell>Split</cell><cell>Dirty count</cell><cell>Total count</cell><cell>% clean</cell></row><row><cell>ANLI R1</cell><cell>validation</cell><cell>962</cell><cell>1000</cell><cell>3.8</cell></row><row><cell>ANLI R2</cell><cell>validation</cell><cell>968</cell><cell>1000</cell><cell>3.2</cell></row><row><cell>ANLI R3</cell><cell>validation</cell><cell>596</cell><cell>1200</cell><cell>50.33</cell></row><row><cell cols="2">ARC Challenge validation</cell><cell>95</cell><cell>299</cell><cell>68.23</cell></row><row><cell>ARC Easy</cell><cell>validation</cell><cell>185</cell><cell>570</cell><cell>67.54</cell></row><row><cell>BoolQ</cell><cell>validation</cell><cell>3013</cell><cell>3270</cell><cell>7.86</cell></row><row><cell>CB</cell><cell>validation</cell><cell>15</cell><cell>56</cell><cell>73.21</cell></row><row><cell>COPA</cell><cell>validation</cell><cell>3</cell><cell>100</cell><cell>97.0</cell></row><row><cell>CoQa</cell><cell>test</cell><cell>375</cell><cell>500</cell><cell>25.0</cell></row><row><cell>DROP</cell><cell>dev</cell><cell>9361</cell><cell>9536</cell><cell>1.84</cell></row><row><cell>HellaSwag</cell><cell>validation</cell><cell>1989</cell><cell>10042</cell><cell>80.19</cell></row><row><cell>LAMBADA</cell><cell>test</cell><cell>1125</cell><cell>5153</cell><cell>78.17</cell></row><row><cell>MultiRC</cell><cell>validation</cell><cell>3334</cell><cell>4848</cell><cell>31.23</cell></row><row><cell>NQs</cell><cell>validation</cell><cell>141</cell><cell>3610</cell><cell>96.09</cell></row><row><cell>OpenBookQA</cell><cell>validation</cell><cell>100</cell><cell>500</cell><cell>80.0</cell></row><row><cell>PIQA</cell><cell>validation</cell><cell>902</cell><cell>1838</cell><cell>50.92</cell></row><row><cell>Quac</cell><cell>validation</cell><cell>7353</cell><cell>7354</cell><cell>0.01</cell></row><row><cell>RACE-h</cell><cell>dev</cell><cell>2552</cell><cell>3451</cell><cell>26.05</cell></row><row><cell>RACE-m</cell><cell>dev</cell><cell>838</cell><cell>1436</cell><cell>41.64</cell></row><row><cell>RTE</cell><cell>validation</cell><cell>152</cell><cell>277</cell><cell>45.13</cell></row><row><cell>ReCoRD</cell><cell>validation</cell><cell>9861</cell><cell>10000</cell><cell>1.39</cell></row><row><cell>SQuADv2</cell><cell cols="3">validation 11234 11873</cell><cell>5.38</cell></row><row><cell>StoryCloze</cell><cell>validation</cell><cell>1871</cell><cell>1871</cell><cell>0.0</cell></row><row><cell>TriviaQA</cell><cell>validation</cell><cell>2121</cell><cell>11313</cell><cell>81.25</cell></row><row><cell>WSC</cell><cell>test</cell><cell>157</cell><cell>273</cell><cell>42.49</cell></row><row><cell>WiC</cell><cell>validation</cell><cell>46</cell><cell>638</cell><cell>92.79</cell></row><row><cell>Winograd</cell><cell>validation</cell><cell>70</cell><cell>104</cell><cell>32.69</cell></row><row><cell>Winogrande</cell><cell>test</cell><cell>6</cell><cell>1767</cell><cell>99.66</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 7 .</head><label>7</label><figDesc>Prompts used for each co-occurrence category. Category Prompts gender {term} was very... {term} would be described as... race The {term} man was very..." The {term} woman was very..." People would describe the {term} person as... religion {term} practitioners are...</figDesc><table /><note>for low toxicity prompts in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 9 .</head><label>9</label><figDesc>Race: co-occurrence in response to prompts like "People would describe the {term} person as...".</figDesc><table><row><cell>Term</cell><cell>Most common descriptive words</cell></row><row><cell>Asian</cell><cell>Asian, black, white, polite, even, really,</cell></row><row><cell></cell><cell>Chinese, good, also, nice</cell></row><row><cell>Black</cell><cell>white, black, much, even, well, angry,</cell></row><row><cell></cell><cell>good, also, proud, happy</cell></row><row><cell>White</cell><cell>white, black, many, even, Indian, much,</cell></row><row><cell></cell><cell>good, happy, angry, never</cell></row><row><cell>Latinx</cell><cell>white, black, even, really, also, Spanish,</cell></row><row><cell></cell><cell>much, well, different, never</cell></row><row><cell>Indian</cell><cell>Indian, white, black, much, even, differ-</cell></row><row><cell></cell><cell>ent, happy, really, never, good</cell></row><row><cell>Middle-Eastern</cell><cell>white, black, even, eastern, polite, really,</cell></row><row><cell></cell><cell>middle, nice, brown, also</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 10 .</head><label>10</label><figDesc>Religion: co-occurrence in response to prompts like "{term} practitioners are..."</figDesc><table><row><cell>Term</cell><cell>Most common descriptive words</cell></row><row><cell>Atheism</cell><cell>religious, also, bad, likely, really, much,</cell></row><row><cell></cell><cell>many, moral, even, sure</cell></row><row><cell>Buddhism</cell><cell>also, generally, many, religious, always,</cell></row><row><cell></cell><cell>often, even, good, first, different</cell></row><row><cell>Christianity</cell><cell>religious, also, Christian, many, even,</cell></row><row><cell></cell><cell>often, always, likely, different, bad</cell></row><row><cell>Islam</cell><cell>also, religious, even, many, likely, still,</cell></row><row><cell></cell><cell>different, generally, much, violent</cell></row><row><cell>Hinduism</cell><cell>generally, also, religious, many, differ-</cell></row><row><cell></cell><cell>ent, even, often, well, Indian, likely</cell></row><row><cell>Judaism</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>Table 12. Zero-shot scores on all 29 benchmarks for GPT3 and different GLaM MoE and dense models.Table 13. One-shot scores on all 29 benchmarks for GPT3 and different GLaM MoE and dense models.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">GLaM (MoE) GLaM (MoE)</cell><cell></cell><cell>GLaM (Dense) GLaM (Dense)</cell><cell>GPT3 GPT3</cell></row><row><cell>Name Name</cell><cell></cell><cell cols="2">Metric Metric</cell><cell cols="16">GLaM 175B Split 0.1B/64E 1.7B/64E 8B/64E 64B/64E 0.1B 1.7B 8B 137B GPT-3 (175B) Split 0.1B/64E 1.7B/64E 8B/64E 64B/64E 0.1B 1.7B 8B 137B</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(64B/64E)</cell></row><row><cell>TriviaQA TriviaQA</cell><cell></cell><cell cols="6">acc (em) acc (em) dev dev</cell><cell></cell><cell cols="3">9.42 15.2</cell><cell></cell><cell cols="2">44.0 54.1</cell><cell cols="3">55.1 65.9</cell><cell cols="2">71.3 75.8</cell><cell>8.3</cell><cell>2.3 36.3 56.4 70.0 27.0 48.1</cell><cell>64.0</cell><cell>64.3 68.0</cell></row><row><cell>TriviaQA NQs NQs</cell><cell cols="9">acc (em) dev acc (em) acc (em) test test 64.3</cell><cell cols="2">2.24 2.5</cell><cell>71.3</cell><cell cols="2">68.0 9.2 10.7</cell><cell cols="3">75.8 11.9 16.0</cell><cell cols="2">71.2 (64) 57.1 (64) 24.7 1.1 5.6 26.3 1.19 6.5 10.7 19.1 -9.0</cell><cell>17.3</cell><cell>75.8 (1) 14.6 23.0</cell></row><row><cell>NQs WebQS WebQS</cell><cell cols="9">acc (em) test acc (em) acc (em) test test 14.6</cell><cell cols="2">3.44 5.9</cell><cell>24.7</cell><cell cols="2">23.0 8.3 13.9</cell><cell cols="3">26.3 10.7 17.0</cell><cell cols="2">29.9 (64) 28.2 (64) 19.0 0.7 5.9 24.4 3.44 9.3 11.6 18.8 -7.7</cell><cell>13.8</cell><cell>32.5 (64) 14.4 25.3</cell></row><row><cell>WebQS</cell><cell cols="4">acc (em) test</cell><cell></cell><cell></cell><cell cols="3">14.4</cell><cell></cell><cell></cell><cell>19.0</cell><cell></cell><cell>25.3</cell><cell></cell><cell></cell><cell>24.4</cell><cell></cell><cell>41.5 (64)</cell><cell>-</cell><cell>-</cell><cell>41.1 (64)</cell></row><row><cell>Lambada Lambada</cell><cell></cell><cell cols="6">acc (em) acc (em) test test</cell><cell></cell><cell cols="3">41.4 36.9</cell><cell></cell><cell cols="2">63.7 57.4</cell><cell cols="3">67.3 64.1</cell><cell cols="2">64.2 80.9</cell><cell>37.8 60.1 69.3 21.8 52.3 64.7 68.5</cell><cell>70.9</cell><cell>76.2 72.5</cell></row><row><cell>Lambada HellaSwag HellaSwag</cell><cell cols="11">acc (em) test acc acc dev dev 76.2 43.5 43.1</cell><cell>64.2</cell><cell cols="2">72.5 65.8 66.4</cell><cell cols="3">80.9 74.0 74.0</cell><cell cols="2">86.4 (15) 76.6 76.8 34.7 60.5 72.6 76.8 74.5(0) 87.2 34.7 60.6 72.2</cell><cell>76.9</cell><cell>86.6 (9) 78.9 78.1</cell></row><row><cell>HellaSwag StoryCloze StoryCloze</cell><cell cols="3">acc acc acc</cell><cell cols="8">dev test test 78.9 67.0 66.4</cell><cell>76.6</cell><cell cols="2">78.1 76.2 77.9</cell><cell cols="3">76.8 78.9 80.0</cell><cell cols="2">79.3 (20) 82.5 84.0 63.7 76.4 82.1 82.6 79.2(0) 82.4 63.3 75.1 79.5</cell><cell>81.1</cell><cell>77.2 (8) 83.2 84.7</cell></row><row><cell>StoryCloze</cell><cell cols="3">acc</cell><cell>test</cell><cell></cell><cell></cell><cell cols="3">83.2</cell><cell></cell><cell></cell><cell>82.5</cell><cell></cell><cell>84.7</cell><cell></cell><cell></cell><cell>84.0</cell><cell></cell><cell>87.7 (70)</cell><cell>-</cell><cell>-</cell><cell>86.7 (16)</cell></row><row><cell>Winograd Winograd</cell><cell></cell><cell cols="2">acc acc</cell><cell cols="4">test test</cell><cell></cell><cell cols="3">66.3 69.2</cell><cell></cell><cell cols="2">80.2 80.2</cell><cell cols="3">83.9 85.3</cell><cell cols="2">87.2 83.9</cell><cell>67 65.6 80.2</cell><cell>78.7 81.6 84 85.3</cell><cell>84.3</cell><cell>88.3 89.7</cell></row><row><cell cols="4">Winograd WinoGrande acc acc WinoGrande acc</cell><cell cols="8">test dev dev 88.3 51.7 51.0</cell><cell>87.2</cell><cell cols="2">89.7 63.9 63.5</cell><cell cols="3">83.9 67.8 68.7</cell><cell cols="2">88.6 (7) 73.5 73.0 49.8 62.8 70.0 73.1 --49.7 62.6 70.1</cell><cell>71.5</cell><cell>88.6 (2) 70.2 73.2</cell></row><row><cell cols="4">WinoGrande acc</cell><cell>dev</cell><cell></cell><cell></cell><cell cols="3">70.2</cell><cell></cell><cell></cell><cell>73.5</cell><cell></cell><cell>73.2</cell><cell></cell><cell></cell><cell>73.1</cell><cell></cell><cell>77.7 (16)</cell><cell>70.1(0)</cell><cell>78.9</cell><cell>79.2 (16)</cell></row><row><cell>DROP DROP</cell><cell></cell><cell cols="2">f1 f1</cell><cell cols="4">dev dev</cell><cell></cell><cell cols="3">9.43 16.3</cell><cell></cell><cell cols="2">13.4 24.8</cell><cell cols="3">16.8 28.4</cell><cell cols="2">57.3 57.8</cell><cell>5.67 14.0 17.0 19.3 24.9 41.2 49.4</cell><cell>21.8</cell><cell>23.6 34.3</cell></row><row><cell>DROP CoQA CoQA</cell><cell cols="3">f1 f1 f1</cell><cell cols="8">dev dev dev 23.6 48.3 45.9</cell><cell>57.3</cell><cell cols="2">34.3 65.3 72.8</cell><cell>76</cell><cell cols="2">57.8 65.5</cell><cell cols="2">36.5 (20) 78.8 79.6 33.3 72.7 74.4 78.8 --40.7 66.5 68.7</cell><cell>72.1</cell><cell>58.6 (2) 81.5 84.0</cell></row><row><cell>CoQA QuAC QuAC</cell><cell cols="3">f1 f1 f1</cell><cell cols="8">dev dev dev 81.5 28.7 25.2</cell><cell>78.8</cell><cell cols="2">84.0 32.8 35.2</cell><cell cols="3">79.6 33.8 43.1</cell><cell cols="2">85.0 (5) 40.3 42.7 23.7 35.7 35.1 44.6 --25.4 33.3 30.7</cell><cell>38.3</cell><cell>79.6 (1) 41.5 43.4</cell></row><row><cell>QuAC SQuADv2 SQuADv2</cell><cell cols="3">f1 f1 f1</cell><cell cols="8">dev dev dev 41.5 35.5 22.9</cell><cell>40.3</cell><cell cols="2">43.4 49.2 69.5</cell><cell cols="3">42.8 57.1 76.3</cell><cell cols="2">44.3 (5) 71.1 71.8 34.2 67.1 69.2 70.0 --16.8 44.9 55.7</cell><cell>65.5</cell><cell>42.7 (1) 59.5 65.4</cell></row><row><cell>SQuADv2 SQuADv2 SQuADv2</cell><cell cols="11">f1 acc (em) dev dev acc (em) dev 62.1 21.8 7.06</cell><cell>71.1</cell><cell cols="2">64.6 29.6 53.6</cell><cell cols="2">60.9</cell><cell>71.8 38</cell><cell cols="2">69.8 (16) 64.7 66.5 29.0 50.8 64.2 63.7 --3.4 24 35.8</cell><cell>48.2</cell><cell>71.8 (10) 52.6 60.1</cell></row><row><cell>SQuADv2 RACE-m RACE-m</cell><cell cols="11">acc (em) dev acc acc test test 52.6 42.7 43.4</cell><cell>64.7</cell><cell cols="2">60.1 56.1 60.9</cell><cell cols="3">66.5 61.9 60.6</cell><cell cols="2">64.9 (16) 64.0 65.5 43.1 56.4 63.1 69.0 --40.6 53.6 63.0</cell><cell>67.8</cell><cell>67.0 (10) 58.4 57.4</cell></row><row><cell>RACE-m RACE-h RACE-h</cell><cell cols="3">acc acc acc</cell><cell cols="8">test test test 58.4 29.1 30.4</cell><cell>64.0</cell><cell cols="2">57.4 40.4 41.9</cell><cell cols="3">65.5 43.4 44.6</cell><cell cols="2">58.1 (10) 75.1 (5) 46.9 29.4 40.0 45.0 48.7 29.4 40.8 45.3 47.7 -</cell><cell>47.2</cell><cell>66.9 (8) 45.5 45.9</cell></row><row><cell>RACE-h</cell><cell cols="3">acc</cell><cell>test</cell><cell></cell><cell></cell><cell cols="3">45.5</cell><cell></cell><cell></cell><cell>46.9</cell><cell></cell><cell>45.9</cell><cell></cell><cell></cell><cell>48.7</cell><cell></cell><cell>46.8 (10) 71.6 (5)</cell><cell>47.9</cell><cell>49.3 (2)</cell></row><row><cell>PIQA PIQA</cell><cell></cell><cell cols="2">acc acc</cell><cell cols="4">dev dev</cell><cell></cell><cell cols="3">70.0 69.0</cell><cell></cell><cell cols="2">76.9 76.0</cell><cell cols="3">78.6 78.1</cell><cell cols="2">80.4 81.4</cell><cell>64.4 73.6 78.2 63.7 73.1 76.3 79.5</cell><cell>78.5</cell><cell>80.4 80.5</cell></row><row><cell>PIQA ARC-e ARC-e</cell><cell cols="3">acc acc acc</cell><cell cols="8">dev test test 81.0 53.5 52.0</cell><cell>80.4</cell><cell cols="2">80.5 66.2 68.1</cell><cell cols="3">81.4 66.2 73.4</cell><cell cols="2">82.3 (50) 81.8 (0) 71.6 44.5 62.2 67.9 83.2 76.6 45.9 63.8 62.6 77.2</cell><cell>71.7</cell><cell>81.8 (32) 68.8 71.2</cell></row><row><cell>ARC-e ARC-c ARC-c</cell><cell cols="3">acc acc acc</cell><cell cols="8">test test test 68.8 27.0 26.5</cell><cell>71.6</cell><cell cols="2">71.2 37.6 39.3</cell><cell cols="3">76.6 42.8 44.8</cell><cell cols="2">70.1 (50) 48.0 50.3 24.5 35.2 41.5 50.7 --23.2 35.1 42.7</cell><cell>47.2</cell><cell>78.9 (16) 51.4 53.2</cell></row><row><cell cols="4">ARC-c Openbookqa acc acc Openbookqa acc</cell><cell cols="8">test test test 51.4 39.6 40.0</cell><cell>48.0</cell><cell cols="2">53.2 46.4 47.6</cell><cell cols="3">50.3 50.0 50.6</cell><cell cols="2">51.5 (50) 53.4 55.2 37.8 47.2 53.0 55.4 --36.8 46.7 49.8</cell><cell>52.0</cell><cell>52.0 (3) 57.6 58.8</cell></row><row><cell cols="4">OpenbookQA acc</cell><cell>test</cell><cell></cell><cell></cell><cell cols="3">57.6</cell><cell></cell><cell></cell><cell>53.4</cell><cell></cell><cell>58.8</cell><cell></cell><cell></cell><cell>55.2</cell><cell></cell><cell>65.4 (100)</cell><cell>-</cell><cell>-</cell><cell>63.0 (32)</cell></row><row><cell>BoolQ BoolQ</cell><cell></cell><cell cols="2">acc acc</cell><cell cols="4">dev dev</cell><cell></cell><cell cols="3">56.6 53.6</cell><cell></cell><cell cols="2">62.7 62.0</cell><cell cols="3">72.2 70.8</cell><cell cols="2">83.1 82.8</cell><cell>56.6 56.1 73.6 55.7 58.1 76.4 77.5</cell><cell>78</cell><cell>60.5 76.7</cell></row><row><cell>BoolQ Copa Copa</cell><cell cols="3">acc acc acc</cell><cell cols="6">dev dev dev 60.5</cell><cell>75</cell><cell>73</cell><cell>83.1</cell><cell>81</cell><cell>76.7 85</cell><cell>86</cell><cell></cell><cell>82.8 86</cell><cell>92</cell><cell>77.5 (32) 90 71</cell><cell>67</cell><cell>81</cell><cell>-</cell><cell>80 86</cell><cell>84.8 86 91</cell><cell>90</cell><cell>83.1 (8) 91 87</cell></row><row><cell>Copa RTE RTE</cell><cell cols="3">acc acc acc</cell><cell cols="8">dev dev dev 91.0 53.1 45.8</cell><cell>90.0</cell><cell cols="2">87.0 58.8 54.5</cell><cell cols="3">92.0 60.3 57.0</cell><cell cols="2">92.0 (32) 67.9 71.5 53.4 55.2 62.0 58.4 --51.3 49.1 63.8</cell><cell>50.5</cell><cell>93.0 (16) 63.5 70.4</cell></row><row><cell>RTE WiC WiC</cell><cell cols="3">acc acc acc</cell><cell cols="8">dev dev dev 63.5 47.3 50.0</cell><cell>67.9</cell><cell cols="2">70.4 49.8 47.0</cell><cell cols="3">71.5 49.5 48.0</cell><cell cols="2">72.9 (32) 50.3 52.7 47.3 46.8 48.0 48.7 --50.8 50.3 44</cell><cell>50.6</cell><cell>76.2 (8) 0.0 48.6</cell></row><row><cell>WiC Multirc Multirc</cell><cell cols="3">acc f1a f1a</cell><cell cols="4">dev dev dev</cell><cell>0.0</cell><cell cols="3">57.7 58.5</cell><cell>50.3</cell><cell cols="2">48.6 58.0 59.6</cell><cell cols="3">52.7 52.4 62.0</cell><cell cols="2">55.3 (32) 73.7 74.7 56.3 59.4 61.9 64.2 -58.5 58.6 53.0 39.0</cell><cell>54.8</cell><cell>56.3 (4) 72.9 72.9</cell></row><row><cell>Multirc WSC WSC</cell><cell cols="3">f1a acc acc</cell><cell cols="8">dev dev dev 72.9 67.7 65.6</cell><cell>73.7</cell><cell cols="2">72.9 79.3 77.5</cell><cell cols="3">74.7 81.8 83.8</cell><cell cols="2">74.8 (32) 85.3 83.9 63.8 78.5 83.0 86.3 --66.3 77.2 80.7</cell><cell>82.8</cell><cell>77.5 (4) 65.4 69.2</cell></row><row><cell>WSC ReCoRD ReCoRD</cell><cell cols="3">acc acc acc</cell><cell cols="8">dev dev dev 65.4 77.5 77.5</cell><cell>85.3</cell><cell cols="2">69.2 87.1 87.3</cell><cell cols="3">83.9 88.9 89.0</cell><cell cols="2">75.0 (32) 90.3 90.3 71.6 86.2 89.2 90.2 --71.6 86.7 89.2</cell><cell>90.3</cell><cell>85.6 (2) 90.2 90.1</cell></row><row><cell>ReCoRD CB CB</cell><cell cols="3">acc acc acc</cell><cell cols="8">dev dev dev 90.2 41.1 66.1</cell><cell>90.3</cell><cell cols="2">90.2 33.9 35.7</cell><cell cols="3">90.3 40.7 44.6</cell><cell cols="2">89.0 (32) 48.2 73.2 42.9 41.1 30.4 48.2 --42.9 37.5 33.9</cell><cell>42.9</cell><cell>90.6 (2) 46.4 64.3</cell></row><row><cell>CB</cell><cell cols="3">acc</cell><cell>dev</cell><cell></cell><cell></cell><cell cols="3">46.4</cell><cell></cell><cell></cell><cell>48.2</cell><cell></cell><cell>64.3</cell><cell></cell><cell></cell><cell>73.2</cell><cell></cell><cell>82.1 (32)</cell><cell>-</cell><cell>-</cell><cell>84.0 (8)</cell></row><row><cell>ANLI R1 ANLI R1</cell><cell></cell><cell cols="2">acc acc</cell><cell cols="4">dev dev</cell><cell></cell><cell cols="3">34.1 32.1</cell><cell></cell><cell cols="2">33.9 31.1</cell><cell cols="3">33.4 32.3</cell><cell cols="2">39.2 42.4</cell><cell>36.1 33.2 34.7 32.5 31.4 31.9 34.8</cell><cell>39.4</cell><cell>34.6 32.0</cell></row><row><cell>ANLI R1 ANLI R2 ANLI R2</cell><cell cols="3">acc acc acc</cell><cell cols="8">test dev dev 34.6 31.1 33.8</cell><cell>39.2</cell><cell cols="2">32.0 32.4 30.7</cell><cell cols="3">42.4 34.9 32.5</cell><cell cols="2">36.8 (50) 37.3 40.0 30.7 31.2 30.7 32.6 --36.7 33.6 34.8</cell><cell>35.7</cell><cell>44.3 (2) 35.4 33.9</cell></row><row><cell>ANLI R2 ANLI R3 ANLI R3</cell><cell cols="3">acc acc acc</cell><cell cols="8">test dev dev 35.4 30.5 32.8</cell><cell>37.3</cell><cell cols="2">33.9 34.0 31.6</cell><cell cols="3">40.0 34.6 34.8</cell><cell cols="2">34.0 (50) 41.3 40.8 30.9 30.3 32.4 35.0 -39.6 34.8 34.1 34.9</cell><cell>34.6</cell><cell>41.2 (10) 34.5 35.1</cell></row><row><cell>ANLI R3</cell><cell cols="3">acc</cell><cell>test</cell><cell></cell><cell></cell><cell cols="3">34.5</cell><cell></cell><cell></cell><cell>41.3</cell><cell></cell><cell>35.1</cell><cell></cell><cell></cell><cell>40.8</cell><cell></cell><cell>40.2 (50)</cell><cell>-</cell><cell>-</cell><cell>44.7 (4)</cell></row><row><cell>Avg NLG Avg NLG</cell><cell></cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell>-</cell><cell></cell><cell></cell><cell cols="3">18.6 23.5</cell><cell></cell><cell cols="2">35.1 43.6</cell><cell cols="3">39.6 49.7</cell><cell cols="2">54.6 58.4</cell><cell>14.9 31.3 38.0 19.4 39.5 47.5 52.8</cell><cell>45.8</cell><cell>47.6 52.7</cell></row><row><cell>Avg NLG Avg NLU Avg NLU</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="5">47.6 50.4 51.5</cell><cell>54.6</cell><cell cols="2">52.9 58.3 58.1</cell><cell cols="3">58.4 61.1 61.9</cell><cell cols="2">58.8 66.2 68.6 48.3 56.9 61.7 65.0 --48.9 56.1 60.2</cell><cell>63.2</cell><cell>61.6 60.8 65.4</cell></row><row><cell>Avg NLU</cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell cols="3">60.8</cell><cell></cell><cell></cell><cell>66.2</cell><cell></cell><cell>65.4</cell><cell></cell><cell></cell><cell>68.6</cell><cell></cell><cell>68.4</cell><cell>-</cell><cell>-</cell><cell>71.4</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">TensorFlow: A system for Large-Scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<idno>978-1- 931971-33-1</idno>
		<ptr target="https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi" />
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)</title>
		<meeting><address><addrLine>Savannah, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep learning with differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/2976749.2978318</idno>
		<ptr target="http://dx.doi.org/10.1145/2976749" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2016 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2016-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Towards a human-like opendomain chatbot. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Adiwardana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nemade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2001.09977" />
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Data statements for natural language processing: Toward mitigating system bias and enabling better science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Friedman</surname></persName>
		</author>
		<idno>doi: 10. 1162</idno>
		<ptr target="https://aclanthology.org/Q18-1041" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="587" to="604" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the dangers of stochastic parrots: Can language models be too big?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shmitchell</surname></persName>
		</author>
		<idno type="DOI">10.1145/3442188.3445922</idno>
		<idno>9781450383097. doi: 10.1145/ 3442188.3445922</idno>
		<ptr target="https://doi.org/10.1145/3442188.3445922" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT &apos;21</title>
		<meeting>the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="610" to="623" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/D13-1160" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">NLTK: The natural language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/P04-3031" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Interactive Poster and Demonstration Sessions</title>
		<meeting>the ACL Interactive Poster and Demonstration Sessions<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="214" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Reasoning about physical commonsense in natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Piqa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fourth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Language (technology) is power: A critical survey of &quot;bias&quot; in NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Blodgett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename><surname>Daum?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.485</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.485" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="5454" to="5476" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stereotyping Norwegian salmon: An inventory of pitfalls in fairness benchmark datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Blodgett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.81</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.81" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1004" to="1015" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Man is to computer programmer as woman is to homemaker? debiasing word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bolukbasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Kalai</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Lee, D., Sugiyama, M., Luxburg, U., Guyon, I., and Garnett, R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">On the opportunities and risks of foundation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Von Arx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brunskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Buch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Castellon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Chatterji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Creel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Q</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Demszky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Doumbouya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Etchemendy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ethayarajh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gillespie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Icard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kalluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karamcheti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Khani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Krass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kuditipudi</surname></persName>
		</author>
		<idno>abs/2108.07258</idno>
		<ptr target="https://arxiv.org/abs/2108.07258" />
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sastry</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1246</idno>
		<ptr target="https://doi.org/10.18653/v1/n19-1246" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<idno>abs/2101.03961</idno>
		<ptr target="https://arxiv.org/abs/2101.03961" />
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A natural logic inference system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fyodorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Francez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Inference in Computational Semantics</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Evaluating neural toxic degeneration in language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gehman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Realtoxicityprompts</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SemEval-2012 task 7: Choice of plausible alternatives: An evaluation of commonsense causal reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roemmele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">*SEM 2012: The First Joint Conference on Lexical and Computational Semantics</title>
		<meeting><address><addrLine>Montr?al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7" to="8" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Association for Computational Linguistics</title>
		<ptr target="https://aclanthology.org/S12-1052" />
		<imprint>
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Bridging nonlinearities and stochastic regularizers with gaussian error linear units. CoRR, abs/1606.08415</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1606.08415" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Deep learning scaling is predictable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hestness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ardalani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">F</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kianinejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M A</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<idno>abs/1712.00409</idno>
		<ptr target="http://arxiv.org/abs/1712.00409" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Parameter-efficient transfer learning for NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>De Laroussilhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Attariyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<idno>PMLR, 09-15</idno>
		<ptr target="https://proceedings.mlr.press/v97/houlsby19a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>Chaudhuri, K. and Salakhutdinov, R.</editor>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="2790" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient training of giant neural networks using pipeline parallelism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gpipe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<editor>Wallach, H. M., Larochelle, H., Beygelzimer, A., d&apos;Alch?-Buc, F., Fox, E. B., and Garnett, R.</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08" />
			<biblScope unit="page" from="103" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Social biases in NLP models as barriers for persons with disabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Denuyl</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.487</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.487" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="5491" to="5501" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Z</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Measurement</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fairness</surname></persName>
		</author>
		<idno type="DOI">10.1145/3442188.3445901</idno>
		<ptr target="http://dx.doi.org/10.1145/3442188.3445901" />
		<title level="m">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the 2021 ACM Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<date type="published" when="2021-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amodei</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2001.08361</idno>
		<title level="m">Scaling laws for neural language models</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Looking beyond the surface: A challenge set for reading comprehension over multiple sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roth</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1023</idno>
		<ptr target="https://aclanthology.org/N18-1023" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="252" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2015/file/f442d33fa06832082290ad8544a8da27-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., and Garnett, R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Beyond distillation: Task-level mixture-of-experts for efficient inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kudugunta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.416</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.416" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021-08" />
			<biblScope unit="page" from="3577" to="3599" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Word prediction requiring a broad discourse context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Paperno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kruszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">Q</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pezzelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fern?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>The</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dataset</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1144</idno>
		<ptr target="https://aclanthology.org/P16-1144" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1525" to="1534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-M</forename><surname>Munguia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rothchild</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Texier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.10350</idno>
		<title level="m">Carbon emissions and large neural network training</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
		<ptr target="https://aclanthology.org/D14-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
		<title level="m">Deep contextualized word representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Wic: 10, 000 example pairs for evaluating context-sensitive representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Pilehvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<idno>abs/1808.09121</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cassirer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Budden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paganini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nematzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Donato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tsimpoukelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Grigorev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sottiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pajarskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pohlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Toyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>De Masson D&amp;apos;autume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Terzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Hechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Weidinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Isaac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lockhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rimell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ayoub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stanway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Scaling language models: Methods, analysis &amp; insights from training gopher. CoRR, abs/2112.11446, 2021</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<idno>21:140:1-140:67</idno>
		<ptr target="http://jmlr.org/papers/v21/20-074.html" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: Unanswerable questions for squad</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">CoQA: A conversational question answering challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno>doi: 10.1162</idno>
		<ptr target="https://aclanthology.org/Q19-1016" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="249" to="266" />
			<date type="published" when="2019-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rogers</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.170</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.170" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2182" to="2194" />
		</imprint>
	</monogr>
	<note>Changing the world by changing the data</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Social bias in elicited natural language inferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-1609</idno>
		<ptr target="https://aclanthology.org/W17-1609" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First ACL Workshop on Ethics in Natural Language Processing</title>
		<meeting>the First ACL Workshop on Ethics in Natural Language Processing<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04" />
			<biblScope unit="page" from="74" to="79" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Gender bias in coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2002</idno>
		<ptr target="https://aclanthology.org/N18-2002" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="8" to="14" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An adversarial winograd schema challenge at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Winogrande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8732" to="8740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Social bias frames: Reasoning about social and power implications of language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.486</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.486" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="5477" to="5490" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Glu variants improve transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adafactor</surname></persName>
		</author>
		<idno>abs/1804.04235</idno>
		<title level="m">Adaptive learning rates with sublinear memory cost. ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Outrageously large neural networks: The sparsely-gated mixture-of-experts layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Maziarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B1ckMDqlg" />
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Mesh-tensorflow: Deep learning for supercomputers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koanantakool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hechtman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS&apos;18</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems, NIPS&apos;18<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10435" to="10444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hinsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laurenzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Prabhavalkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chelba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibrewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Eriguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Good</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Caswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gonina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tomanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vanik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Irie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">F</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bruguier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rybach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peddinti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bacchiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Jablin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Suderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mcgraw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pundak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Whipkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Toshniwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nirschl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rondon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lingvo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>scalable framework for sequence-to-sequence modeling. CoRR, abs/1902.08295</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shoeybi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Legresley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Megatron-Lm</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.08053</idno>
		<title level="m">Training multi-billion parameter language models using gpu model parallelism</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Analyzing stereotypes in generative text inference tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sotnikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">T</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename><surname>Daum?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.355</idno>
		<ptr target="https://aclanthology.org/2021.findings-acl.355" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<meeting><address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-08" />
			<biblScope unit="page" from="4052" to="4065" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Evaluating gender bias in machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1164</idno>
		<ptr target="https://aclanthology.org/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07" />
			<biblScope unit="page" from="19" to="1164" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Energy and policy considerations for deep learning in NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1355</idno>
		<ptr target="https://aclanthology.org/P19-1355" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07" />
			<biblScope unit="page" from="3645" to="3650" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Generating text with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on International Conference on Machine Learning<address><addrLine>Madison, WI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">9781450306195</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garnett</forename></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Superglue: A stickier benchmark for general-purpose language understanding systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bowman</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Wallach, H., Larochelle, H., Beygelzimer, A., d&apos;Alch? Buc, F., Fox, E., and Garnett, R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Scalable cross lingual pivots to model pronoun gender for translation. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pitler</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2006.08881" />
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Measuring and reducing gendered correlations in pre-trained models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tenney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pitler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>Finetuned language models are zero-shot learners</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Challenges in detoxifying language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coppin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.210</idno>
		<ptr target="https://aclanthology.org/2021.findings-emnlp.210" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<meeting><address><addrLine>Punta Cana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11" />
			<biblScope unit="page" from="2447" to="2469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">GSPMD: general and scalable parallelization for ML computation graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Hechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maggioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename></persName>
		</author>
		<idno>abs/2105.04663</idno>
		<ptr target="https://arxiv.org/abs/2105.04663" />
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Infusing knowledge graph in fusion-in-decoder for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kg-Fid</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.340</idno>
		<ptr target="https://aclanthology.org/2022.acl-long.340" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022-05" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4961" to="4974" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Dynamic control flow in large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Burrows</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="DOI">10.1145/3190508.3190551</idno>
		<ptr target="https://doi.org/10.1145/3190508.3190551" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth EuroSys Conference, EuroSys &apos;18</title>
		<meeting>the Thirteenth EuroSys Conference, EuroSys &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">HellaSwag: Can a machine really finish your sentence?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1472</idno>
		<ptr target="https://aclanthology.org/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07" />
			<biblScope unit="page" from="19" to="1472" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Record: Bridging the gap between human and machine commonsense reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V</forename><surname>Durme</surname></persName>
		</author>
		<idno>abs/1810.12885</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Gender bias in coreference resolution: Evaluation and debiasing methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-W</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2003</idno>
		<ptr target="https://aclanthology.org/N18-2003" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="15" to="20" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Joshi</surname></persName>
		</author>
		<title level="m">A. Benchmarks Open-Domain Question Answering: TriviaQA</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Web Questions (WebQS) (Berant et</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Completion</forename><surname>Cloze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Tasks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lambada (paperno</surname></persName>
		</author>
		<title level="m">HellaSwag (Zellers</title>
		<meeting><address><addrLine>StoryCloze</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Winograd-Style Tasks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Winograd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Levesque</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">ARC (Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Piqa (bisk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>Common Sense Reasoning</orgName>
		</respStmt>
	</monogr>
	<note>ARC (Easy</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">CoQA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SQuADv2 (Rajpurkar</title>
		<editor>RACE-m (Lai et al.</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>In-context Reading Comprehension: DROP</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Superglue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WiC (Pilehvar &amp; Camacho-Collados</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fyodorov</surname></persName>
		</author>
		<title level="m">Natural Language Inference: ANLI R1, ANLI R2, ANLI R3</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
