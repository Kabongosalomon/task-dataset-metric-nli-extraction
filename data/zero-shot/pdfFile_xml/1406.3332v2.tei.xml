<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Convolutional Kernel Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-11-14">14 Nov 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaid</forename><surname>Harchaoui</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid Inria</surname></persName>
						</author>
						<title level="a" type="main">Convolutional Kernel Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-11-14">14 Nov 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>An important goal in visual recognition is to devise image representations that are invariant to particular transformations. In this paper, we address this goal with a new type of convolutional neural network (CNN) whose invariance is encoded by a reproducing kernel. Unlike traditional approaches where neural networks are learned either to represent data or for solving a classification task, our network learns to approximate the kernel feature map on training data. Such an approach enjoys several benefits over classical ones. First, by teaching CNNs to be invariant, we obtain simple network architectures that achieve a similar accuracy to more complex ones, while being easy to train and robust to overfitting. Second, we bridge a gap between the neural network literature and kernels, which are natural tools to model invariance. We evaluate our methodology on visual recognition tasks where CNNs have proven to perform well, e.g., digit recognition with the MNIST dataset, and the more challenging CIFAR-10 and STL-10 datasets, where our accuracy is competitive with the state of the art. *</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We have recently seen a revival of attention given to convolutional neural networks (CNNs) <ref type="bibr" target="#b21">[22]</ref> due to their high performance for large-scale visual recognition tasks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30]</ref>. The architecture of CNNs is relatively simple and consists of successive layers organized in a hierarchical fashion; each layer involves convolutions with learned filters followed by a pointwise non-linearity and a downsampling operation called "feature pooling". The resulting image representation has been empirically observed to be invariant to image perturbations and to encode complex visual patterns <ref type="bibr" target="#b32">[33]</ref>, which are useful properties for visual recognition. Training CNNs remains however difficult since high-capacity networks may involve billions of parameters to learn, which requires both high computational power, e.g., GPUs, and appropriate regularization techniques <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>The exact nature of invariance that CNNs exhibit is also not precisely understood. Only recently, the invariance of related architectures has been characterized; this is the case for the wavelet scattering transform <ref type="bibr" target="#b7">[8]</ref> or the hierarchical models of <ref type="bibr" target="#b6">[7]</ref>. Our work revisits convolutional neural networks, but we adopt a significantly different approach than the traditional one. Indeed, we use kernels <ref type="bibr" target="#b25">[26]</ref>, which are natural tools to model invariance <ref type="bibr" target="#b13">[14]</ref>. Inspired by the hierarchical kernel descriptors of <ref type="bibr" target="#b1">[2]</ref>, we propose a reproducing kernel that produces multi-layer image representations.</p><p>Our main contribution is an approximation scheme called convolutional kernel network (CKN) to make the kernel approach computationally feasible. Our approach is a new type of unsupervised convolutional neural network that is trained to approximate the kernel map. Interestingly, our network uses non-linear functions that resemble rectified linear units <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">30]</ref>, even though they were not handcrafted and naturally emerge from an approximation scheme of the Gaussian kernel map.</p><p>By bridging a gap between kernel methods and neural networks, we believe that we are opening a fruitful research direction for the future. Our network is learned without supervision since the label information is only used subsequently in a support vector machine (SVM). Yet, we achieve competitive results on several datasets such as MNIST <ref type="bibr" target="#b21">[22]</ref>, CIFAR-10 <ref type="bibr" target="#b19">[20]</ref> and STL-10 <ref type="bibr" target="#b12">[13]</ref> with simple architectures, few parameters to learn, and no data augmentation. Open-source code for learning our convolutional kernel networks is available on the first author's webpage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Work</head><p>There have been several attempts to build kernel-based methods that mimic deep neural networks; we only review here the ones that are most related to our approach.</p><p>Arc-cosine kernels. Kernels for building deep large-margin classifiers have been introduced in <ref type="bibr" target="#b9">[10]</ref>. The multilayer arc-cosine kernel is built by successive kernel compositions, and each layer relies on an integral representation. Similarly, our kernels rely on an integral representation, and enjoy a multilayer construction. However, in contrast to arc-cosine kernels: (i) we build our sequence of kernels by convolutions, using local information over spatial neighborhoods (as opposed to compositions, using global information); (ii) we propose a new training procedure for learning a compact representation of the kernel in a data-dependent manner.</p><p>Multilayer derived kernels. Kernels with invariance properties for visual recognition have been proposed in <ref type="bibr" target="#b6">[7]</ref>. Such kernels are built with a parameterized "neural response" function, which consists in computing the maximal response of a base kernel over a local neighborhood. Multiple layers are then built by iteratively renormalizing the response kernels and pooling using neural response functions. Learning is performed by plugging the obtained kernel in an SVM. In contrast to <ref type="bibr" target="#b6">[7]</ref>, we propagate information up, from lower to upper layers, by using sequences of convolutions. Furthermore, we propose a simple and effective data-dependent way to learn a compact representation of our kernels and show that we obtain near state-of-the-art performance on several benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hierarchical kernel descriptors.</head><p>The kernels proposed in <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> produce multilayer image representations for visual recognition tasks. We discuss in details these kernels in the next section: our paper generalizes them and establishes a strong link with convolutional neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Convolutional Multilayer Kernels</head><p>The convolutional multilayer kernel is a generalization of the hierarchical kernel descriptors introduced in computer vision <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. The kernel produces a sequence of image representations that are built on top of each other in a multilayer fashion. Each layer can be interpreted as a non-linear transformation of the previous one with additional spatial invariance. We call these layers image feature maps 1 , and formally define them as follows: Definition 1. An image feature map ? is a function ? : ? ? H, where ? is a (usually discrete) subset of [0, 1] d representing normalized "coordinates" in the image and H is a Hilbert space.</p><p>For all practical examples in this paper, ? is a two-dimensional grid and corresponds to different locations in a two-dimensional image. In other words, ? is a set of pixel coordinates. Given z in ?, the point ?(z) represents some characteristics of the image at location z, or in a neighborhood of z. For instance, a color image of size m ? n with three channels, red, green, and blue, may be represented by an initial feature map ? 0 : ? 0 ? H 0 , where ? 0 is an m ? n regular grid, H 0 is the Euclidean space R 3 , and ? 0 provides the color pixel values. With the multilayer scheme, non-trivial feature maps will be obtained subsequently, which will encode more complex image characteristics. With this terminology in hand, we now introduce the convolutional kernel, first, for a single layer. Definition 2 (Convolutional Kernel with Single Layer). Let us consider two images represented by two image feature maps, respectively ? and ? ? : ? ? H, where ? is a set of pixel locations, and H is a Hilbert space. The one-layer convolutional kernel between ? and ? ? is defined as</p><formula xml:id="formula_0">K(?, ? ? ) := z?? z ? ?? ?(z) H ? ? (z ? ) H e ? 1 2? 2 z?z ? 2 2 e ? 1 2? 2 ?(z)?? ? (z ? ) 2 H ,<label>(1)</label></formula><p>1 In the kernel literature, "feature map" denotes the mapping between data points and their representation in a reproducing kernel Hilbert space (RKHS) <ref type="bibr" target="#b25">[26]</ref>. Here, feature maps refer to spatial maps representing local image characteristics at everly location, as usual in the neural network literature <ref type="bibr" target="#b21">[22]</ref>.</p><p>where ? and ? are smoothing parameters of Gaussian kernels, and?(z) :</p><formula xml:id="formula_1">= (1/ ?(z) H ) ?(z) if ?(z) = 0 and?(z) = 0 otherwise. Similarly,? ? (z ? ) is a normalized version of ? ? (z ? ). 2</formula><p>It is easy to show that the kernel K is positive definite (see Appendix A). It consists of a sum of pairwise comparisons between the image features ?(z) and ? ? (z ? ) computed at all spatial locations z and z ? in ?. To be significant in the sum, a comparison needs the corresponding z and z ? to be close in ?, and the normalized features?(z) and? ? (z ? ) to be close in the feature space H. The parameters ? and ? respectively control these two definitions of "closeness". Indeed, when ? is large, the kernel K is invariant to the positions z and z ? but when ? is small, only features placed at the same location z = z ? are compared to each other. Therefore, the role of ? is to control how much the kernel is locally shift-invariant. Next, we will show how to go beyond one single layer, but before that, we present concrete examples of simple input feature maps ? 0 : ? 0 ? H 0 .</p><p>Gradient map. Assume that H 0 = R 2 and that ? 0 (z) provides the two-dimensional gradient of the image at pixel z, which is often computed with first-order differences along each dimension. Then, the quantity ? 0 (z) H0 is the gradient intensity, and? 0 (z) is its orientation, which can be characterized by a particular angle-that is, there exists ? in [0; 2?] such that? 0 (z) = [cos(?), sin(?)]. The resulting kernel K is exactly the kernel descriptor introduced in <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> for natural image patches.</p><p>Patch map. In that setting, ? 0 associates to a location z an image patch of size m ? m centered at z. Then, the space H 0 is simply R m?m , and? 0 (z) is a contrast-normalized version of the patch, which is a useful transformation for visual recognition according to classical findings in computer vision <ref type="bibr" target="#b18">[19]</ref>. When the image is encoded with three color channels, patches are of size m ? m ? 3.</p><p>We now define the multilayer convolutional kernel, generalizing some ideas of <ref type="bibr" target="#b1">[2]</ref>. Definition 3 (Multilayer Convolutional Kernel). Let us consider a set ? k-1 ? [0, 1] d and a Hilbert space H k-1 . We build a new set ? k and a new Hilbert space H k as follows:</p><formula xml:id="formula_2">(i) choose a patch shape P k defined as a bounded symmetric subset of [?1, 1] d , and a set of coor- dinates ? k such that for all location z k in ? k , the patch {z k } + P k is a subset of ? k-1 ; 3 In other words, each coordinate z k in ? k corresponds to a valid patch in ? k-1 centered at z k .</formula><p>(ii) define the convolutional kernel K k on the "patch" feature maps P k ? H k-1 , by replacing in <ref type="bibr" target="#b0">(1)</ref>: ? by P k , H by H k-1 , and ?, ? by appropriate smoothing parameters ? k , ? k . We denote by H k the Hilbert space for which the positive definite kernel K k is reproducing.</p><p>An image represented by a feature map ? k-1 : ? k-1 ? H k-1 at layer k-1 is now encoded in the k-th layer as ? k :</p><formula xml:id="formula_3">? k ? H k , where for all z k in ? k , ? k (z k ) is the representation in H k of the patch feature map z ? ? k-1 (z k + z) for z in P k .</formula><p>Concretely, the kernel K k between two patches of ? k-1 and ? ? k-1 at respective locations z k and z ? k is</p><formula xml:id="formula_4">z?P k z ? ?P k ? k-1 (z k + z) ? ? k-1 (z ? k + z ? ) e ? 1 2? 2 k z?z ? 2 2 e ? 1 2? 2 k ? k-1 (z k +z)?? ? k-1 (z ? k +z ? ) 2 ,<label>(2)</label></formula><p>where . is the Hilbertian norm of H k-1 . In <ref type="figure" target="#fig_1">Figure 1</ref>(a), we illustrate the interactions between the sets of coordinates ? k , patches P k , and feature spaces H k across layers. For two-dimensional grids, a typical patch shape is a square, for example P := {?1/n, 0, 1/n} ? {?1/n, 0, 1/n} for a 3 ? 3 patch in an image of size n ? n. Information encoded in the k-th layer differs from the (k-1)-th one in two aspects: first, each point ? k (z k ) in layer k contains information about several points from the (k-1)-th layer and can possibly represent larger patterns; second, the new feature map is more locally shift-invariant than the previous one due to the term involving the parameter ? k in (2).</p><p>The multilayer convolutional kernel slightly differs from the hierarchical kernel descriptors of <ref type="bibr" target="#b1">[2]</ref> but exploits similar ideas. Bo et al. <ref type="bibr" target="#b1">[2]</ref> define indeed several ad hoc kernels for representing local information in images, such as gradient, color, or shape. These kernels are close to the one defined in (1) but with a few variations. Some of them do not use normalized features?(z), and these kernels use different weighting strategies for the summands of (1) that are specialized to the image modality, e.g., color, or gradient, whereas we use the same weight ?(z) H ? ? (z ? ) H for all kernels. The generic formulation (1) that we propose may be useful per se, but our main contribution comes in the next section, where we use the kernel as a new tool for learning convolutional neural networks. <ref type="bibr" target="#b1">2</ref> When ? is not discrete, the notation in (1) should be replaced by the Lebesgue integral in the paper. <ref type="bibr" target="#b2">3</ref> For two sets A and B, the Minkowski sum A + B is defined as  </p><formula xml:id="formula_5">{a + b : a ? A, b ? B}. ? 0 ? 0 (z 0 ) ? H 0 {z 1 } + P 1 ? 1 (z 1 ) ? H 1 ? 1 {z 2 } + P 2 ? 2 ? 2 (z 2 ) ? H 2 (a) Hierarchy of image feature maps. ? ? k-1 ? k-1 (z) ? k-1 (z k-1 ) (patch extraction) {z k-1 }+P ? k-1 convolution + non-linearity p k ? k (z k-1 ) ? k-1 Gaussian filtering + downsampling = pooling ? ? k ? k (z) (b)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Training Invariant Convolutional Kernel Networks</head><p>Generic schemes have been proposed for approximating a non-linear kernel with a linear one, such as the Nystr?m method and its variants <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b30">31]</ref>, or random sampling techniques in the Fourier domain for shift-invariant kernels <ref type="bibr" target="#b23">[24]</ref>. In the context of convolutional multilayer kernels, such an approximation is critical because computing the full kernel matrix on a database of images is computationally infeasible, even for a moderate number of images (? 10 000) and moderate number of layers. For this reason, Bo et al. <ref type="bibr" target="#b1">[2]</ref> use the Nystr?m method for their hierarchical kernel descriptors.</p><p>In this section, we show that when the coordinate sets ? k are two-dimensional regular grids, a natural approximation for the multilayer convolutional kernel consists of a sequence of spatial convolutions with learned filters, pointwise non-linearities, and pooling operations, as illustrated in <ref type="figure" target="#fig_1">Figure 1</ref>(b). More precisely, our scheme approximates the kernel map of K defined in (1) at layer k by finite-dimensional spatial maps ? k :</p><formula xml:id="formula_6">? ? k ? R p k ,</formula><p>where ? ? k is a set of coordinates related to ? k , and p k is a positive integer controlling the quality of the approximation. Consider indeed two images represented at layer k by image feature maps ? k and ? ? k , respectively. Then, <ref type="figure" target="#fig_1">Figure 1(b)</ref>, ? k (z k ) is a patch from ? k centered at location z k with shape P ? k ; (C) an activation map ? k : ? k-1 ? R p k is computed from ? k-1 by convolution with p k filters followed by a non-linearity. The subsequent map ? k is obtained from ? k by a pooling operation.</p><formula xml:id="formula_7">(A) the corresponding maps ? k and ? ? k are learned such that K(? k-1 , ? ? k-1 ) ? ? k , ? ? k , where ., . is the Euclidean inner-product acting as if ? k and ? ? k were vectors in R |? ? k |p k ; (B) the set ? ? k is linked to ? k by the relation ? ? k = ? k + P ? k where P ? k is a patch shape, and the quantities ? k (z k ) in H k admit finite-dimensional approximations ? k (z k ) in R |P ? k |p k ; as illustrated in</formula><p>We call this approximation scheme a convolutional kernel network (CKN). In comparison to CNNs, our approach enjoys similar benefits such as efficient prediction at test time, and involves the same set of hyper-parameters: number of layers, numbers of filters p k at layer k, shape P ? k of the filters, sizes of the feature maps. The other parameters ? k , ? k can be automatically chosen, as discussed later. Training a CKN can be argued to be as simple as training a CNN in an unsupervised manner <ref type="bibr" target="#b24">[25]</ref> since we will show that the main difference is in the cost function that is optimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Fast Approximation of the Gaussian Kernel</head><p>A key component of our formulation is the Gaussian kernel. We start by approximating it by a linear operation with learned filters followed by a pointwise non-linearity. Our starting point is the next lemma, which can be obtained after a simple calculation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 1 (Linear expansion of the Gaussian Kernel).</head><p>For all x and x ? in R m , and ? &gt; 0,</p><formula xml:id="formula_8">e ? 1 2? 2 x?x ? 2 2 = 2 ?? 2 m 2 w?R m e ? 1 ? 2 x?w 2 2 e ? 1 ? 2 x ? ?w 2 2 dw.<label>(3)</label></formula><p>The lemma gives us a mapping of any x in R m to the function w ?</p><formula xml:id="formula_9">? Ce ?(1/? 2 ) x?w 2 2 in L 2 (R m ),</formula><p>where the kernel is linear, and C is the constant in front of the integral. To obtain a finite-dimensional representation, we need to approximate the integral with a weighted finite sum, which is a classical problem arising in statistics (see <ref type="bibr" target="#b28">[29]</ref> and chapter 8 of <ref type="bibr" target="#b5">[6]</ref>). Then, we consider two different cases.</p><p>Small dimension, m ? 2. When the data lives in a compact set of R m , the integral in (3) can be approximated by uniform sampling over a large enough set. We choose such a strategy for two types of kernels from Eq. (1): (i) the spatial kernels e</p><formula xml:id="formula_10">? 1 2? 2 z?z ? 2 2 ; (ii) the terms e ?( 1 2? 2 ) ?(z)?? ? (z ? ) 2 H</formula><p>when ? is the "gradient map" presented in Section 2. In the latter case, H = R 2 and?(z) is the gradient orientation. We typically sample a few orientations as explained in Section 4.</p><p>Higher dimensions. To prevent the curse of dimensionality, we learn to approximate the kernel on training data, which is intrinsically low-dimensional. We optimize importance weights ?</p><formula xml:id="formula_11">= [? l ] p l=1 in R p + and sampling points W = [w l ] p l=1 in R m?p on n training pairs (x i , y i ) i=1,...,n in R m ? R m : min ??R p + ,W?R m?p 1 n n i=1 e ? 1 2? 2 xi?yi 2 2 ? p l=1 ? l e ? 1 ? 2 xi?w l 2 2 e ? 1 ? 2 yi?w l 2 2 2 .<label>(4)</label></formula><p>Interestingly, we may already draw some links with neural networks. When applied to unit-norm vectors x i and y i , problem (4) produces sampling points w l whose norm is close to one. After learning, a new unit-norm point <ref type="bibr" target="#b0">1]</ref>. Therefore, the finite-dimensional representation of x only involves a linear operation followed by a non-linearity, as in typical neural networks. In <ref type="figure" target="#fig_2">Figure 2</ref>, we show that the shape of f resembles the "rectified linear unit" function <ref type="bibr" target="#b29">[30]</ref>. In dotted red, we plot the "rectified linear unit" function u ? max(u, 0). In blue, we plot non-linear functions of our network for typical values of ? that we use in our experiments.</p><formula xml:id="formula_12">x in R m is mapped to the vector [ ? ? l e ?(1/? 2 ) x?w l 2 2 ] p l=1 in R p , which may be written as [f (w ? l x)] p l=1 , assuming that the norm of w l is always one, where f is the function u ? e (2/? 2 )(u?1) for u = w ? l x in [?1,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Approximating the Multilayer Convolutional Kernel</head><p>We have now all the tools in hand to build our convolutional kernel network. We start by making assumptions on the input data, and then present the learning scheme and its approximation principles.</p><p>The zeroth layer. We assume that the input data is a finite-dimensional map ? 0 : ? ? 0 ? R p0 , and that ? 0 : ? 0 ? H 0 "extracts" patches from ? 0 . Formally, there exists a patch shape P ? 0 such that ? ? 0 = ? 0 + P ? 0 , H 0 = R p0|P ? 0 | , and for all z 0 in ? 0 , ? 0 (z 0 ) is a patch of ? 0 centered at z 0 . Then, property (B) described at the beginning of Section 3 is satisfied for k = 0 by choosing ? 0 = ? 0 . The examples of input feature maps given earlier satisfy this finite-dimensional assumption: for the gradient map, ? 0 is the gradient of the image along each direction, with p 0 = 2, P ? 0 = {0} is a 1?1 patch, ? 0 = ? ? 0 , and ? 0 = ? 0 ; for the patch map, ? 0 is the input image, say with p 0 = 3 for RGB data. The convolutional kernel network. The zeroth layer being characterized, we present in Algorithms 1 and 2 the subsequent layers and how to learn their parameters in a feedforward manner. It is interesting to note that the input parameters of the algorithm are exactly the same as a CNN-that is, number of layers and filters, sizes of the patches and feature maps (obtained here via the subsampling factor). Ultimately, CNNs and CKNs only differ in the cost function that is optimized for learning the filters and in the choice of non-linearities. As we show next, there exists a link between the parameters of a CKN and those of a convolutional multilayer kernel. Algorithm 1 Convolutional kernel network -learning the parameters of the k-th layer. input ? 1 k-1 , ? 2 k-1 , . . . : ? ? k-1 ? R p k-1 (sequence of (k-1)-th maps obtained from training images); P ? k-1 (patch shape); p k (number of filters); n (number of training pairs); 1: extract at random n pairs (x i , y i ) of patches with shape P ? k-1 from the maps ? 1 k-1 , ? 2 k-1 , . . .; <ref type="bibr">2:</ref> if not provided by the user, set ? k to the 0.1 quantile of the data ( x i ? y i 2 ) n i=1 ; 3: unsupervised learning: optimize (4) to obtain the filters W k in R |P ? k-1 |p k-1 ?p k and ? k in R p k ; output W k , ? k , and ? k (smoothing parameter); Algorithm 2 Convolutional kernel network -computing the k-th map form the (k-1)-th one. input ? k-1 : ? ? k-1 ? R p k-1 (input map); P ? k-1 (patch shape); ? k ? 1 (subsampling factor); p k (number of filters); ? k (smoothing parameter); W k = [w kl ] p k l=1 and ? k = [? kl ] p k l=1 (layer parameters); 1: convolution and non-linearity: define the activation map ? k : ? k-1 ? R p k as</p><formula xml:id="formula_13">? k : z ? ? k-1 (z) 2 ? ? kl e ? 1 ? 2 k ? k-1 (z)?w kl 2 2 p k l=1 ,<label>(5)</label></formula><p>where ? k-1 (z) is a vector representing a patch from ? k-1 centered at z with shape P ? k-1 , and the vector? k-1 (z) is an ? 2 -normalized version of ? k-1 (z). This operation can be interpreted as a spatial convolution of the map ? k-1 with the filters w kl followed by pointwise non-linearities; <ref type="bibr">2:</ref> set ? k to be ? k times the spacing between two pixels in ? k-1 ; 3: feature pooling: ? ? k is obtained by subsampling ? k-1 by a factor ? k and we define a new map ? k : ? ? k ? R p k obtained from ? k by linear pooling with Gaussian weights:</p><formula xml:id="formula_14">? k : z ? 2/? u?? k-1 e ? 1 ? 2 k u?z 2 2 ? k (u). (6) output ? k : ? ? k ? R p k (new map);</formula><p>Approximation principles. We proceed recursively to show that the kernel approximation property (A) is satisfied; we assume that (B) holds at layer k-1, and then, we show that (A) and (B) also hold at layer k. This is sufficient for our purpose since we have previously assumed (B) for the zeroth layer. Given two images feature maps ? k-1 and ? ? k-1 , we start by approximating K(? k-1 , ? ? k-1 ) by replacing ? k-1 (z) and ? ? k-1 (z ? ) by their finite-dimensional approximations provided by (B):</p><formula xml:id="formula_15">K(? k-1 , ? ? k-1 ) ? z,z ? ?? k-1 ? k-1 (z) 2 ? ? k-1 (z ? ) 2 e ? 1 2? 2 k z?z ? 2 2 e ? 1 2? 2 k ? k-1 (z)?? ? k-1 (z ? ) 2 2 . (7)</formula><p>Then, we use the finite-dimensional approximation of the Gaussian kernel involving ? k and</p><formula xml:id="formula_16">K(? k-1 , ? ? k-1 ) ? z,z ? ?? k-1 ? k (z) ? ? ? k (z ? )e ? 1 2? 2 k z?z ? 2 2 ,<label>(8)</label></formula><p>where ? k is defined in <ref type="bibr" target="#b4">(5)</ref> and ? ? k is defined similarly by replacing? by? ? . Finally, we approximate the remaining Gaussian kernel by uniform sampling on ? ? k , following Section 3.1. After exchanging sums and grouping appropriate terms together, we obtain the new approximation</p><formula xml:id="formula_17">K(? k-1 , ? ? k-1 ) ? 2 ? u?? ? k z?? k-1 e ? 1 ? 2 k z?u 2 2 ? k (z) ? z ? ?? k-1 e ? 1 ? 2 k z ? ?u 2 2 ? ? k (z ? ) ,<label>(9)</label></formula><p>where the constant 2/? comes from the multiplication of the constant 2/(?? 2 k ) from (3) and the weight ? 2 k of uniform sampling orresponding to the square of the distance between two pixels of ? ? k . 4 As a result, the right-hand side is exactly ? k , ? ? k , where ? k is defined in (6), giving us property (A). It remains to show that property (B) also holds, specifically that the quantity (2) can be approximated by the Euclidean inner-product ? k (z k ), ? ? k (z ? k ) with the patches ? k (z k ) and ? ? k (z ? k ) of shape P ? k ; we assume for that purpose that P ? k is a subsampled version of the patch shape P k by a factor ? k .</p><p>We remark that the kernel (2) is the same as (1) applied to layer k-1 by replacing ? k-1 by {z k }+P k . By doing the same substitution in (9), we immediately obtain an approximation of <ref type="bibr" target="#b1">(2)</ref>. Then, all Gaussian terms are negligible for all u and z that are far from each other-say when u?z 2 ? 2? k . Thus, we may replace the sums u?? ? k z,z ? ?{z k }+P k by u?{z k }+P ? k z,z ? ?? k-1 , which has the same set of "non-negligible" terms. This yields exactly the approximation ? k (z k ), ? ? k (z ? k ) . Optimization. Regarding problem (4), stochastic gradient descent (SGD) may be used since a potentially infinite amount of training data is available. However, we have preferred to use L-BFGS-B <ref type="bibr" target="#b8">[9]</ref> on 300 000 pairs of randomly selected training data points, and initialize W with the K-means algorithm. L-BFGS-B is a parameter-free state-of-the-art batch method, which is not as fast as SGD but much easier to use. We always run the L-BFGS-B algorithm for 4 000 iterations, which seems to ensure convergence to a stationary point. Our goal is to demonstrate the preliminary performance of a new type of convolutional network, and we leave as future work any speed improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We now present experiments that were performed using Matlab and an L-BFGS-B solver <ref type="bibr" target="#b8">[9]</ref> interfaced by Stephen Becker. Each image is represented by the last map ? k of the CKN, which is used in a linear SVM implemented in the software package LibLinear <ref type="bibr" target="#b15">[16]</ref>. These representations are centered, rescaled to have unit ? 2 -norm on average, and the regularization parameter of the SVM is always selected on a validation set or by 5-fold cross-validation in the range 2 i , i = ?15 . . . , 15.</p><p>The patches P ? k are typically small; we tried the sizes m ? m with m = 3, 4, 5 for the first layer, and m = 2, 3 for the upper ones. The number of filters p k in our experiments is in the set {50, 100, 200, 400, 800}. The downsampling factor ? k is always chosen to be 2 between two consecutive layers, whereas the last layer is downsampled to produce final maps ? k of a small size-say, 5?5 or 4?4. For the gradient map ? 0 , we approximate the Gaussian kernel e (1/? 2</p><formula xml:id="formula_18">1 ) ?0(z)?? ? 0 (z ? ) H 0</formula><p>by uniformly sampling p 1 = 12 orientations, setting ? 1 = 2?/p 1 . Finally, we also use a small offset ? to prevent numerical instabilities in the normalization steps?(z) = ?(z)/ max( ?(z) 2 , ?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Discovering the Structure of Natural Image Patches</head><p>Unsupervised learning was first used for discovering the underlying structure of natural image patches by Olshausen and Field <ref type="bibr" target="#b22">[23]</ref>. Without making any a priori assumption about the data except a parsimony principle, the method is able to produce small prototypes that resemble Gabor wavelets-that is, spatially localized oriented basis functions. The results were found impressive by the scientific community and their work received substantial attention. It is also known that such results can also be achieved with CNNs <ref type="bibr" target="#b24">[25]</ref>. We show in this section that this is also the case for convolutional kernel networks, even though they are not explicitly trained to reconstruct data.</p><p>Following <ref type="bibr" target="#b22">[23]</ref>, we randomly select a database of 300 000 whitened natural image patches of size 12 ? 12 and learn p = 256 filters W using the formulation <ref type="bibr" target="#b3">(4)</ref>. We initialize W with Gaussian random noise without performing the K-means step, in order to ensure that the output we obtain is not an artifact of the initialization. In <ref type="figure" target="#fig_3">Figure 3</ref>, we display the filters associated to the top-128 largest weights ? l . Among the 256 filters, 197 exhibit interpretable Gabor-like structures and the rest was less interpretable. To the best of our knowledge, this is the first time that the explicit kernel map of the Gaussian kernel for whitened natural image patches is shown to be related to Gabor wavelets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Digit Classification on MNIST</head><p>The MNIST dataset <ref type="bibr" target="#b21">[22]</ref> consists of 60 000 images of handwritten digits for training and 10 000 for testing. We use two types of initial maps in our networks: the "patch map", denoted by CNK-PM and the "gradient map", denoted by CNK-GM. We follow the evaluation methodology of <ref type="bibr" target="#b24">[25]</ref>   for comparison when varying the training set size. We select the regularization parameter of the SVM by 5-fold cross validation when the training size is smaller than 20 000, or otherwise, we keep 10 0000 examples from the training set for validation. We report in <ref type="table" target="#tab_0">Table 1</ref> the results obtained for four simple architectures. CKN-GM1 is the simplest one: its second layer uses 3 ? 3 patches and only p 2 = 50 filters, resulting in a network with 5 400 parameters. Yet, it achieves an outstanding performance of 0.58% error on the full dataset. The best performing, CKN-GM2, is similar to CKN-GM1 but uses p 2 = 400 filters. When working with raw patches, two layers (CKN-PM2) gives better results than one layer. More details about the network architectures are provided in the supplementary material. In general, our method achieves a state-of-the-art accuracy for this task since lower error rates have only been reported by using data augmentation <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Visual Recognition on CIFAR-10 and STL-10</head><p>We now move to the more challenging datasets CIFAR-10 <ref type="bibr" target="#b19">[20]</ref> and STL-10 <ref type="bibr" target="#b12">[13]</ref>. We select the best architectures on a validation set of 10 000 examples from the training set for CIFAR-10, and by 5-fold cross-validation on STL-10. We report in <ref type="table">Table 2</ref> results for CKN-GM, defined in the previous section, without exploiting color information, and CKN-PM when working on raw RGB patches whose mean color is subtracted. The best selected models have always two layers, with 800 filters for the top layer. Since CKN-PM and CKN-GM exploit a different information, we also report a combination of such two models, CKN-CO, by concatenating normalized image representations together. The standard deviations for STL-10 was always below 0.7%. Our approach appears to be competitive with the state of the art, especially on STL-10 where only one method does better than ours, despite the fact that our models only use 2 layers and require learning few parameters. Note that better results than those reported in <ref type="table">Table 2</ref> have been obtained in the literature by using either data augmentation (around 90% on CIFAR-10 for <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b29">30]</ref>), or external data (around 70% on STL-10 for <ref type="bibr" target="#b27">[28]</ref>). We are planning to investigate similar data manipulations in the future.  <ref type="table">Table 2</ref>: Classification accuracy in % on CIFAR-10 and STL-10 without data augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we have proposed a new methodology for combining kernels and convolutional neural networks. We show that mixing the ideas of these two concepts is fruitful, since we achieve near state-of-the-art performance on several datasets such as MNIST, CIFAR-10, and STL10, with simple architectures and no data augmentation. Some challenges regarding our work are left open for the future. The first one is the use of supervision to better approximate the kernel for the prediction task. The second consists in leveraging the kernel interpretation of our convolutional neural networks to better understand the theoretical properties of the feature spaces that these networks produce.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Positive Definiteness of K</head><p>To show that the kernel K defined in (1) is positive definite (p.d.), we simply use elementary rules from the kernel literature described in Sections 2.3.2 and 3.4.1 of <ref type="bibr" target="#b25">[26]</ref>. A linear combination of p.d. kernels with nonnegative weights is also p.d. (see Proposition 3.22 of <ref type="bibr" target="#b25">[26]</ref>), and thus it is sufficient to show that for all z, z ? in ?, the following kernel on ? ? H is p.d.:</p><formula xml:id="formula_19">(?, ? ? ) ? ?(z) H ? ? (z ? ) H e ? 1 2? 2 ?(z)?? ? (z ? ) 2 H .</formula><p>Specifically, it is also sufficient to show that the following kernel on H is p.d.:</p><formula xml:id="formula_20">(?, ? ? ) ? ? H ? ? H e ? 1 2? 2 ? ? H ? ? ? ? ? H 2 H .</formula><p>with the convention ?/ ? H = 0 if ? = 0. This is a pointwise product of two kernels and is p.d. when each of the two kernels is p.d. The first one is obviously p.d.:</p><formula xml:id="formula_21">(?, ? ? ) ? ? H ? ? H .</formula><p>The second one is a composition of the Gaussian kernel-which is p.d.-, with feature maps ?/ ? H of a normalized linear kernel in H. This composition is p.d. according to Proposition 3.22, item (v) of <ref type="bibr" target="#b25">[26]</ref> since the normalization does not remove the positive-definiteness property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B List of Architectures Reported in the Experiments</head><p>We present in details the architectures used in the paper in <ref type="table">Table 3</ref>  <ref type="table">Table 3</ref>: List of architectures reported in the paper. N is the number of layers; p 1 and p 2 represent the number of filters are each layer; m 1 and m 2 represent the size of the patches P ? 1 and P ? 2 that are of size m 1 ? m 1 and m 2 ? m 2 on their respective feature maps ? 1 and ? 2 ; ? 1 is the subsampling factor between layer 1 and layer 2; S is the size of the output feature map, and the last column indicates the number of parameters that the network has to learn.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Zoom between layer k-1 and k of the CKN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Left: concrete representation of the successive layers for the multilayer convolutional kernel. Right: one layer of the convolutional neural network that approximates the kernel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>ufFigure 2 :</head><label>2</label><figDesc>(u) f (u) = e (2/? 2 )(u?1) f (u) = max(u, 0)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Filters obtained by the first layer of the convolutional kernel network on natural images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Test error in % for various approaches on the MNIST dataset without data augmentation. The numbers in parentheses represent the size p 1 and p 2 of the feature maps at each layer.</figDesc><table><row><cell cols="8">Tr. CNN Scat-1 Scat-2 CKN-GM1 CKN-GM2 CKN-PM1 CKN-PM2 [32] [18] [19] size [25] [8] [8] (12/50) (12/400) (200) (50/200)</cell></row><row><cell>300 7.18</cell><cell>4.7</cell><cell>5.6</cell><cell>4.39</cell><cell>4.24</cell><cell>5.98</cell><cell>4.15</cell><cell>NA</cell></row><row><cell>1K 3.21</cell><cell>2.3</cell><cell>2.6</cell><cell>2.60</cell><cell>2.05</cell><cell>3.23</cell><cell>2.76</cell><cell>NA</cell></row><row><cell>2K 2.53</cell><cell>1.3</cell><cell>1.8</cell><cell>1.85</cell><cell>1.51</cell><cell>1.97</cell><cell>2.28</cell><cell>NA</cell></row><row><cell>5K 1.52</cell><cell>1.03</cell><cell>1.4</cell><cell>1.41</cell><cell>1.21</cell><cell>1.41</cell><cell>1.56</cell><cell>NA</cell></row><row><cell>10K 0.85</cell><cell>0.88</cell><cell>1</cell><cell>1.17</cell><cell>0.88</cell><cell>1.18</cell><cell>1.10</cell><cell>NA</cell></row><row><cell>20K 0.76</cell><cell>0.79</cell><cell>0.58</cell><cell>0.89</cell><cell>0.60</cell><cell>0.83</cell><cell>0.77</cell><cell>NA</cell></row><row><cell>40K 0.65</cell><cell>0.74</cell><cell>0.53</cell><cell>0.68</cell><cell>0.51</cell><cell>0.64</cell><cell>0.58</cell><cell>NA</cell></row><row><cell>60K 0.53</cell><cell>0.70</cell><cell>0.4</cell><cell>0.58</cell><cell>0.39</cell><cell>0.63</cell><cell>0.53</cell><cell>0.47 0.45 0.53</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The choice of ? k in Algorithm 2 is driven by signal processing principles. The feature pooling step can indeed be interpreted as a downsampling operation that reduces the resolution of the map from ? k-1 to ? k by using a Gaussian anti-aliasing filter, whose role is to reduce frequencies above the Nyquist limit.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partially supported by grants from ANR (project MACARON ANR-14-CE23-0003-01), MSR-Inria joint centre, European Research Council (project ALLEGRO), CNRS-Mastodons program (project GARGANTUA), and the LabEx PERSYVAL-Lab (ANR-11-LABX-0025).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning deep architectures for AI. Found</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Mach. Learn</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Object recognition with hierarchical kernel descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Kernel descriptors for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. NIPS</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning for RGB-D based object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Experimental Robotics</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient match kernel between sets of features for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. NIPS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Large-Scale Kernel Machines (Neural Information Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Decoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On invariance in hierarchical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Bouvrie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. NIPS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Invariant scattering convolution networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Pattern Anal</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1872" to="1886" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A limited memory algorithm for bound constrained optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1190" to="1208" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Large-margin classification in infinite neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-column deep neural networks for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Selecting receptive fields in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. NIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AISTATS</title>
		<meeting>AISTATS</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Training invariant support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Decoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="161" to="190" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">DeCAF: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.1531</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">LIBLINEAR: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R.-E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Discriminative learning of sum-product networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Maxout networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">What is the best multi-stage architecture for object recognition?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">P. IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Emergence of simple-cell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="issue">6583</biblScope>
			<biblScope unit="page" from="607" to="609" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Random features for large-scale kernel machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. NIPS</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unsupervised learning of invariant feature hierarchies with applications to object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Kernel methods for pattern analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning invariant representations with local transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-task Bayesian optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Spline models for observational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wahba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>SIAM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Regularization of neural networks using dropconnect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Using the Nystr?m method to speed up kernel machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. NIPS</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Stochastic pooling for regularization of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
