<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exponential Moving Average Normalization for Self-supervised and Semi-supervised Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-06-18">18 Jun 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cai</surname></persName>
							<email>zhaoweic@amazon.com</email>
							<affiliation key="aff0">
								<orgName type="department">Amazon Web Services</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
							<email>ravinash@amazon.com</email>
							<affiliation key="aff0">
								<orgName type="department">Amazon Web Services</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
							<email>smmaji@amazon.com</email>
							<affiliation key="aff0">
								<orgName type="department">Amazon Web Services</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
							<email>fowlkec@amazon.com</email>
							<affiliation key="aff0">
								<orgName type="department">Amazon Web Services</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Amazon Web Services</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
							<email>soattos@amazon.com</email>
							<affiliation key="aff0">
								<orgName type="department">Amazon Web Services</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Exponential Moving Average Normalization for Self-supervised and Semi-supervised Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-06-18">18 Jun 2021</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a plug-in replacement for batch normalization (BN) called exponential moving average normalization (EMAN), which improves the performance of existing student-teacher based self-and semi-supervised learning techniques. Unlike the standard BN, where the statistics are computed within each batch, EMAN, used in the teacher, updates its statistics by exponential moving average from the BN statistics of the student. This design reduces the intrinsic cross-sample dependency of BN and enhances the generalization of the teacher. EMAN improves strong baselines for self-supervised learning by 4-6/1-2 points and semi-supervised learning by about 7/2 points, when 1%/10% supervised labels are available on ImageNet. These improvements are consistent across methods, network architectures, training duration, and datasets, demonstrating the general effectiveness of this technique. The code is available at https://github.com/amazonresearch/exponential-moving-average-normalization.</p><p>2. Model parameter mismatch. In the teacher network, its</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Supervised learning has achieved remarkable success on a variety of visual tasks, benefiting from the availability of large-scale annotated datasets such as ImageNet <ref type="bibr" target="#b37">[37]</ref>, MS-COCO <ref type="bibr" target="#b31">[31]</ref>, and ShapeNet <ref type="bibr" target="#b5">[6]</ref>. However, in some domains such as medical imaging, large amounts of annotations are expensive or time-consuming to collect. Learning effective representations with small amounts (semi-supervised) or no (unsupervised or self-supervised) manual annotation is thus an important problem in computer vision <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b45">45]</ref>.</p><p>Although many choices exist for semi-and selfsupervised learning <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b50">50]</ref>, an effective approach is the family of student-teacher models <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b47">47]</ref>, where the outputs of the teacher are used to guide the learning of the student on the unlabeled data. Within this family, a common approach is to update the teacher  <ref type="figure">Figure 1</ref>. The EMA-teacher framework with standard BN (left) and the proposed EMAN <ref type="bibr">(right)</ref>. ? are the model parameters, and ? and ? 2 BN statistics. EMA denotes exponential moving average updates. im v1 and im v2 are two different views of the same image. No gradient is backpropagated through the teacher model. using exponential moving average (EMA) of the student parameters over its training trajectory <ref type="bibr" target="#b41">[41]</ref>, which we call EMA-teacher, as shown in <ref type="figure">Figure 1</ref> (left). As discussed in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b26">26]</ref>, the temporally averaged teacher, as interpreted as the temporal ensembling of the student checkpoints, can improve generalization. Due to this property, it has been adopted in recent self-supervised learning methods <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b19">19]</ref>. While the objective and the update mechanisms are different for the student and the teacher, both networks use the standard batch normalization (BN) <ref type="bibr" target="#b25">[25]</ref>, as in the early EMA-teacher frameworks <ref type="bibr" target="#b41">[41]</ref>. However, this can lead to two potential problems:</p><p>1. Cross-sample dependency. This is an intrinsic property of BN where the output of a sample is dependent on all other samples in the same batch. This crosssample information leakage may allow the model to "cheat" in semi-or self-supervised learning. To avoid this, some special designs on normalization were applied in <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b21">21]</ref>. For example, <ref type="bibr" target="#b21">[21]</ref> switched to layer normalization <ref type="bibr" target="#b1">[2]</ref>; MoCo <ref type="bibr" target="#b19">[19]</ref> designed Shuf-fleBN where a mini-batch uses BN statistics from other randomly sampled mini-batch; and SimCLR <ref type="bibr" target="#b8">[8]</ref> and BYOL <ref type="bibr" target="#b17">[17]</ref> used Synchronized BN (SyncBN).</p><p>parameters are averaged from the student parameters of previous iterations, but the batch-wise BN statistics are instantly collected at current iteration. This could lead to potential mismatch between the model parameters and the BN statistics in the parameter space. We present a simple replacement for standard BN used in the EMA-teacher framework, called exponential moving average normalization (EMAN). As shown in <ref type="figure">Figure  1</ref> (right), the EMAN statistics (mean ? ? and variance ? ?2 ) in the teacher are exponentially moving averaged from the student BN statistics, similar to the other parameters. The EMAN is simply a linear transform, without batch-wise statistics computation, and thus has removed cross-sample dependency presented in BN in the teacher. Since the normalization statistics and model parameters are both updated using EMA, we expect this to improve stability of training by reducing the potential model parameter mismatches when using BN. This simple design requires only a few lines of code, and can replace other complex normalization schemes (e.g. ShuffleBN, SyncBN, etc.) within various semi-and self-supervised learning techniques.</p><p>We have evaluated EMAN within various EMAteacher frameworks, including recent state-of-the-art semisupervised learning (FixMatch <ref type="bibr" target="#b39">[39]</ref>) and self-supervised learning (MoCo <ref type="bibr" target="#b19">[19]</ref> and BYOL <ref type="bibr" target="#b17">[17]</ref>) techniques. On selfsupervised learning, EMAN improves the performance of MoCo/BYOL by 4-6/1-2 points when 1%/10% labels are available on ImageNet <ref type="bibr" target="#b37">[37]</ref>. On semi-supervised learning, EMAN improves the performance of FixMatch by about 7/2 points for 1%/10% labels, leading to the new state-of-theart performances of 63.0/74.0 top-1 accuracy for 1%/10% labels on ImageNet. These improvements are consistent across methods, network architectures, training duration, and datasets, demonstrating the effectiveness of EMAN as a general technique. In addition, EMAN is just as efficient as standard BN, and does not require cross-GPU communication or synchronization of ShuffleBN or SyncBN. We thus believe that EMAN can be of interest for other future student-teacher variants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Semi-supervised learning leverages unlabeled data to improve the model performance, and has a long history in machine learning <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b51">51]</ref>. We primarily focus on recent deep-learning based approaches. Pseudo-Labeling <ref type="bibr" target="#b29">[29]</ref> generates synthetic labels from the confident predictions to learn on the unlabeled data. Temporal ensembling of predictions was proposed to improve robustness in <ref type="bibr" target="#b28">[28]</ref>. Consistency regularization based methods <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b41">41]</ref> learn by requiring the predictions to be consistent after perturbations on inputs and/or model parameters. For example, ?model <ref type="bibr" target="#b28">[28]</ref> perturbs the model weights, uses dropout <ref type="bibr" target="#b40">[40]</ref>, and enforces that the clean and noisy predictions be consis-tent. Mean-teacher <ref type="bibr" target="#b41">[41]</ref> proposed the EMA-teacher framework, and learns by enforcing consistency between the student and teacher models. FixMatch <ref type="bibr" target="#b39">[39]</ref> assumes consistency between the weakly and strongly augmented inputs. A broader survey of semi-supervised learning techniques can be found in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b51">51]</ref>.</p><p>Unsupervised or self-supervised learning aims to learn representations from data without annotations. It has been particularly effective in natural language processing <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b36">36]</ref>. Early self-supervised learning approaches in computer vision were based on proxy tasks, e.g. solving jigsaw puzzles <ref type="bibr" target="#b34">[34]</ref>, colorization <ref type="bibr" target="#b50">[50]</ref> and rotation prediction <ref type="bibr" target="#b15">[15]</ref>. Recently, the contrastive learning <ref type="bibr" target="#b18">[18]</ref> using instance discrimination has achieved promising results <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b45">45]</ref>. For example, MoCo <ref type="bibr" target="#b19">[19]</ref> and SimCLR <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b9">9]</ref> have narrowed the gap between supervised and unsupervised learning in some domains. BYOL <ref type="bibr" target="#b17">[17]</ref> found that, instead of a contrastive loss, optimizing a feature regression loss can achieve better results than prior work <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b19">19</ref>]. An extensive survey of self-supervised learning can be found in <ref type="bibr" target="#b27">[27]</ref>.</p><p>The student-teacher framework was first introduced in <ref type="bibr" target="#b3">[4]</ref> and developed in <ref type="bibr" target="#b22">[22]</ref> to distill knowledge from the pretrained teacher model to the new student model. While in <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b22">22]</ref>, the teacher is a pretrained and frozen model, other variants are available for different purposes. For example, in <ref type="bibr" target="#b39">[39]</ref> the teacher and the student are identical; in <ref type="bibr" target="#b38">[38]</ref> the teacher is an ensemble of multiple networks; in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b22">22]</ref> the teacher is a more complex network than the student for model compression; in <ref type="bibr" target="#b28">[28]</ref> the teacher is a temporal ensemble of student checkpoints with the step of one epoch; in <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b41">41]</ref>, the teacher is a more smoothly temporal ensemble than <ref type="bibr" target="#b28">[28]</ref> by exponential moving average.</p><p>Normalization is a critical component to enable faster convergence and reduce the dependency on initialization for modern deep networks. While BN <ref type="bibr" target="#b25">[25]</ref> is widely used, it introduces some issues, such as requiring large batch sizes for accurate statistics, and mismatch between how BN is used during training and inference. To address these, other normalization techniques have been proposed. Layer Normalization (LN) <ref type="bibr" target="#b1">[2]</ref> normalizes along the channel and spatial dimension, Instance Normalization (IN) <ref type="bibr" target="#b43">[43]</ref> along only the spatial dimension, and Group Normalization (GN) <ref type="bibr" target="#b44">[44]</ref> operates similar to LN but divides the channels into groups. MABN <ref type="bibr" target="#b48">[48]</ref> shares some similarities with our EMAN, but mainly focuses on the stability of small batch size training and updates its statistics inside a single network. In selfsupervised learning, to avoid the possible information leakage via BN, <ref type="bibr" target="#b21">[21]</ref> used LN, SimCLR <ref type="bibr" target="#b8">[8]</ref> and BYOL <ref type="bibr" target="#b17">[17]</ref> use SyncBN, and MoCo <ref type="bibr" target="#b19">[19]</ref> uses ShuffleBN where a minibatch uses BN statistics from other randomly sampled minibatch. Although these normalization schemes work well in some specific cases, our experiments will show that they do not generalize well across various semi-and self-supervised learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">EMA-Teacher Framework</head><p>The EMA-teacher framework, with architecture shown in <ref type="figure">Figure 1</ref> (left), was first introduced in the Mean Teacher <ref type="bibr" target="#b41">[41]</ref>, to improve the non-smooth temporal ensembling of <ref type="bibr" target="#b28">[28]</ref>. The teacher parameters ? ? are updated by exponential moving average (EMA) from the student parameters ?,</p><formula xml:id="formula_0">? ? := m? ? + (1 ? m)?,<label>(1)</label></formula><p>where the momentum m is a number close to 1, e.g. 0.999. The student network is exactly the same as the standard supervised network, where the parameters ? are learned by standard SGD. In general, there is no gradient backpropagation through the teacher model, and the teacher model is discarded once training finished. This EMA teacher can be interpreted as a smooth temporal ensembling of the student checkpoints along the training trajectories. As discussed in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b26">26]</ref>, this temporal weight averaging mechanism can stabilize training trajectories and present better performances than the standard SGD update. In consistency based semi-and self-supervised learning, training could be less stable <ref type="bibr" target="#b0">[1]</ref>, where the EMA-teacher framework with improved generalization can help. Due to its good performance, this EMA-teacher has derived different variants for different tasks <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b19">19]</ref>.</p><p>While the EMA-teacher has the special update rule for the learnable parameters, it does not for its normalization operators. Instead, the standard BN is used in both student and teacher models as in <ref type="bibr" target="#b41">[41]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Batch Normalization</head><p>BN <ref type="bibr" target="#b25">[25]</ref> can stabilize the learning and enable faster convergence, and thus has been widely adopted. It has different training and inference modes. During training, BN first computes the mean and the variance of the layer inputs for the current batch {x i } n i=1 ,</p><formula xml:id="formula_1">? B = 1 n n i=1 x i , ? 2 B = 1 n n i=1 (x i ? ? B ) 2 ,<label>(2)</label></formula><p>where n is batch size. Next, every sample x in the current batch is normalized using the batch-wise statistics ? B and ? 2 B , and then an affine transformation with learnable parameters ? and ? is applied,</p><formula xml:id="formula_2">x = BN (x) = ? x ? ? B ? 2 B + ? + ?,<label>(3)</label></formula><p>where ? is a small constant for numerical stability. At inference, however, it is not desirable to use the batchwise statistics, ? B and ? 2 B , since the output of an input should be deterministic and not dependent on other inputs in the same batch. The population statistics, E[?] and E[? 2 ], should be used instead. But this requires an additional stage of statistics gathering on a large sample population, which could be undesirable. In many implementations, a more practical and efficient strategy is widely used, collecting the proxy statistics ? and ? 2 by exponential moving average during training,</p><formula xml:id="formula_3">? := ?? + (1 ? ?)? B , ? 2 := ?? 2 + (1 ? ?)? 2 B ,<label>(4)</label></formula><p>where the momentum ? here is usually 0.9. With the proxy statistics ? and ? 2 , the BN at inference become?</p><formula xml:id="formula_4">x = BN (x) = ? x ? ? ? ? 2 + ? + ?,<label>(5)</label></formula><p>which differs from its training mode of (3). This practical strategy is very common in many implementations, e.g. as default in PyTorch and TensorFlow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Exponential Moving Average Normalization</head><p>In the EMA-teacher framework, as introduced in Section 3.1, both the student and the teacher use the standard BN during training,</p><formula xml:id="formula_5">y = f (BN (x), ?), y ? = f (BN (x), ? ? ).<label>(6)</label></formula><p>where f is the intermediate layers of relu-conv, which takes the output of normalization as input. The standard BN is well aligned with the model parameters for a typical network (e.g. the student) which is updated by SGD, since the parameters are optimized with those batch-wise statistics. However, it is no longer the case for the teacher that is updated by EMA. Two reasons suggested that. First, the teacher is used to generate pseudo ground-truth to guide the learning of the student. With batch-wise BN, these generated pseudo labels will be cross-sample dependent, which is not desirable. For example, the pseudo label of x 1 is dependent on x 2 if x 1 and x 2 are in the same training batch. Second, there is a possible mismatch between the model parameters ? ? and batch-wise BN statistics (? B and ? 2 B ) in the teacher model. The former is averaged from the student parameters of previous iterations, but the latter is instantly collected at current iteration, and the former is not optimized for the latter. This mismatch could lead to non-smoothness in the parameter space.</p><p>To resolve these issues, we propose using exponential moving average normalization (EMAN) for the teacher during training (student still uses BN),</p><formula xml:id="formula_6">y ? = f (EM AN (x), ? ? ),<label>(7)</label></formula><p>Algorithm 1 PyTorch-like Pseudocode of EMAN Update # f_s, f_t: encoder networks for student and teacher params_s = f_s.parameters() # learnable parameters params_t = f_t.parameters() # learnable parameters for s, t in zip(params_s, params_t): t = momentum * t + (1-momentum) * s buffers_s = f_s.buffers() # BatchNorm proxy statistics buffers_t = f_t.buffers() # BatchNorm proxy statistics for s, t in zip(buffers_s, buffers_t):</p><formula xml:id="formula_7">t = momentum * t + (1-momentum) * s wherex = EM AN (x) = ? x ? ? ? ? ? ?2 + ? + ?,<label>(8)</label></formula><p>where ? ? and ? ?2 are also exponentially moving averaged from the student ? and ? 2 , in the same way of (1),</p><formula xml:id="formula_8">? ? := m? ? + (1 ? m)?, ? ?2 := m? ?2 + (1 ? m)? 2 .<label>(9)</label></formula><p>The key difference between <ref type="formula" target="#formula_2">(3)</ref> and <ref type="formula" target="#formula_7">(8)</ref> is the normalization factors. They are batch-wise ? B and ? 2 B in <ref type="formula" target="#formula_2">(3)</ref>, but EMA updated ? ? and ? ?2 in <ref type="bibr" target="#b8">(8)</ref>. This new normalization technique for the teacher is simply a linear transform which is no longer dependent on batch statistics. EMAN eliminates cross-sample dependence in the teacher, and there is no mismatch between the model parameters (? ? ) and its normalization factors (? ? and ? ?2 ). Note that although the student is still cross-sample dependent, this is a less serious issue than the cross-sample dependency in the teacher. EMAN is better aligned with the EMA-teacher framework than the standard BN (and probably other normalization), and as we show next, it is generally applicable in different EMA-teacher variants for different tasks <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b41">41</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Applications</head><p>We have applied EMAN to recent state-of-the-art semisupervised learning (FixMatch <ref type="bibr" target="#b39">[39]</ref>) and self-supervised learning (MoCo <ref type="bibr" target="#b19">[19]</ref> and BYOL <ref type="bibr" target="#b17">[17]</ref>) methods. Applying EMAN to these three techniques is simple, requiring a few lines of code change, as shown in Algorithm 1, where the learnable parameter update is adopted as in <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b41">41]</ref>.</p><p>FixMatch <ref type="bibr" target="#b39">[39]</ref> uses identical teacher and student models, with architecture shown in <ref type="figure" target="#fig_2">Figure 2</ref> (left). The teacher generates pseudo labels after thresholding, which are then used to guide the learning of the student with standard cross-entropy loss. A tricky mechanism in FixMatch is to concatenate the strongly and weakly augmented images first and then forward them to the model together. In this case, the teacher and the student are using exactly the same BN statistics. We first reframe FixMatch in the EMA-teacher framework (with standard BN), motivated by its success. However, this change leads to much worse performance, with possible reasons discussed above in this section.  MoCo <ref type="bibr" target="#b19">[19]</ref> has bridged the gap between supervised and unsupervised learning in multiple visual tasks. It can be interpreted as a variant of EMA-teacher, where the key (teacher) model is EMA updated from the query (student) model, and a contrastive loss is constructed between their outputs. MoCo also found it problematic to use BN in both student and teacher, due to possible information leakage. The model would probably "cheat" with local BN statistics to find a low-loss trivial solution rather than learning good representations. Instead, MoCo uses ShuffleBN in the teacher, in which the batch-wise BN statistics are computed inside a randomly shuffled mini-batch samples across distributed GPUs. This ensures that the batch statistics used to compute the query and the key come from two different subsets, avoiding the cheating issue to some extent.</p><p>BYOL <ref type="bibr" target="#b17">[17]</ref> can also be interpreted as a EMA-teacher variant similar to MoCo, although the student/teacher is named as online/target network. It differs from the other contrast based self-supervised learning <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b45">45]</ref> by formulating the self-supervised learning problem as a regression task, bridging the student and teacher outputs with a simple L2 loss. <ref type="bibr" target="#b14">[14]</ref> hypothesizes that the reason why BYOL does not need contrastive loss is BN also plays an role of implicit contrast term, not just normalization. To have stronger implicit contrast and avoid knowledge leakage, SyncBN is adopted in both student and teacher models, in which the BN statistics are collected globally across GPU cards and machines. This requires efficient synchronization technique and leads to slower training speed.</p><p>Our experiments show that using standard BN in both teacher and student models results in poor performances in all these three techniques. Although different solutions have been proposed to avoid that, e.g. Shuffle BN in MoCo and SycnBN in BYOL, they do not generalize well in other techniques as will be shown in our experiments. To have a general and simpler solution, we apply EMAN in all three techniques, as in <ref type="figure">Figure 1</ref> and 2. EMAN can improve over the standard BN by a large margin, and even surpass the ShuffleBN/SyncBN counterparts, universally in FixMatch/MoCo/BYOL. In addition, the training will be simpler and more efficient since EMAN requires no cross-GPU communication or synchronization as needed in Shuf-fleBN/SyncBN. We expect EMAN to be applicable to other student-teacher variants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>ImageNet <ref type="bibr" target="#b37">[37]</ref> is mainly used in all experiments, which contains ?1.28 million images for training and 50K images for validation. The proposed EMAN has been evaluated on the state-of-the-art self-supervised learning (MoCo <ref type="bibr" target="#b19">[19]</ref> and BYOL <ref type="bibr" target="#b17">[17]</ref>) and semi-supervised learning (FixMatch <ref type="bibr" target="#b39">[39]</ref>). For MoCo, the official implementation was used, but Fix-Match and BYOL were reimplemented in PyTorch <ref type="bibr" target="#b35">[35]</ref>. The default network is ResNet-50 <ref type="bibr" target="#b20">[20]</ref> and the default hyperparameters in the corresponding papers were used, unless noted otherwise. For FixMatch, the batch size for labeled (unlabeled) images is 64 (320) with initial learning rate 0.03. For BYOL, the batch size is 512 with initial learning rate 0.9. All experiments were run on a machine with 8 V100 GPU cards. The self-supervised pretrained models were evaluated by 1) linear classification following <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b19">19]</ref>; and 2) kNN classification with k = 20 following <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b52">52]</ref>, on top of the frozen representation. The other settings will be introduced in the following specific experimental sections. More experimental details can be found in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">The Effect of EMAN</head><p>The effect of the proposed EMAN was evaluated. For FixMatch, only 10% labels were used and the rest data as unlabeled. For MoCo and BYOL, we showed the accuracies of the kNN classifier along the training, since it is too expensive to train additional linear classifier. The kNN classifier used 10% train (50% val) as training set (query) FixMatch was reframed to the EMA-teacher framework as in <ref type="figure" target="#fig_2">Figure 2</ref>, using standard BN, denoted as "BN" in <ref type="figure" target="#fig_3">Figure 3 (a)</ref>. However, this architecture change leads to much worse performance than the baseline FixMatch ("baseline"). Switching to standard BN also leads to worse performance than the baseline MoCo (ShuffleBN) and BYOL (SyncBN), as shown in <ref type="figure" target="#fig_3">Figure 3</ref>  To check the generalization, SyncBN and ShuffleBN were also evaluated in the other techniques, as shown in <ref type="table" target="#tab_0">Table 1</ref>, where MoCo and BYOL were measured by linear classification on 10% labeled data. Although they work well within their own technique (i.e., ShuffleBN in MoCo and SyncBN in BYOL), they do not generalize very well across techniques. For example, SyncBN is 1.1 points worse than ShuffleBN in MoCo and even 6.9 points worse than BN in FixMatch; and ShuffleBN is 2.8 points worse than SyncBN in BYOL and even 3.1 points worse than BN in FixMatch. In contrast, EMAN generalizes very well in all three techniques and achieved the best results. Other cross-sample independent normalization techniques were also evaluated in <ref type="table" target="#tab_0">Table 1</ref>, including Group Normalization (GN) <ref type="bibr" target="#b44">[44]</ref> and Instance Normalization (IN) <ref type="bibr" target="#b43">[43]</ref>. But they all lead to inferior performances. Also note that EMAN is as simple as BN, unlike ShuffleBN in MoCo and SyncBN in BYOL which rely on cross-GPU communication or synchronization. For example, switching SyncBN to EMAN in BYOL, the training can be speeded up by about 30% with PyTorch implementation on a machine with 8 GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Self-supervised Evaluation</head><p>We self-supervised pre-train MoCo and BYOL models with EMAN on unlabeled data and then evaluate learned representations on multiple downstream classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linear Classification and Finetuning</head><p>The linear and finetuning evaluation were on different percentages of labeled ImageNet data, including 1%, 10% and 100%. Only the labeled data were used in these experiments. For 1% (10%) labels, five (three) different sets of samples were run and the averaged numbers are shown in <ref type="table" target="#tab_1">Table 2</ref>. We searched the best learning rate from {15,30,60} ({0.2,0.4,0.8}) for MoCo (BYOL) linear evaluation, since they are quite sensitive in these experiments. When finetuning, we found it was important to have different learning rates for the pretrained encoder and the randomly initialized top classifier. We thus used learning rate of 1.0 (0.1) for top classifier for 1% (10%) labels, and searched the best learning rate from {0.0001,0.001,0.01} for the pretrained encoder when finetuning. All experiments were trained for 50 epochs, with  <ref type="table">Table 3</ref>. Comparison with other self-supervised models.</p><p>learning rate dropped by 10 times at 30th and 40th epoch. For linear evaluation in <ref type="table" target="#tab_1">Table 2</ref>, while EMAN models have comparable performances as the baselines for 100% labels, they improve over the baselines by 1-2 points of top-1 accuracy for 10% labels. The gains become bigger (4-5 points) when only 1% labels are available. The observations are consistent across different techniques (MoCo and BYOL), different architectures (ResNet-50 and ResNet-50 of 2? width), and different epochs (200 and 800). Note that the evaluation on 1%/10% labels is more practical than that on 100% labels, since when full dataset is annotated, the advantage of self-supervised pretraining will be reduced. For example, compared with supervised baseline, the selfsupervised models are usually worse for 100% labels, but have significant gains (&gt;30/10 points) for 1%/10% labels, indicating the self-supervised pretraining is much more useful when there is insufficient supervision available.</p><p>Finetuning usually achieved better results than the linear classification, in <ref type="table" target="#tab_1">Table 2</ref>, with increasing gains for more annotations, but they could be worse if the hyperparameters are not carefully tuned as introduced above, especially for fewer labels. The gains by EMAN over those strong baselines are still consistent with the linear classification, and even larger in most of the experiments with 1% labels.</p><p>Comparison with the State-of-the-art The EMAN models were compared with the state-of-the-art self-supervised learning methods for 1%/10% labels in <ref type="table">Table 3</ref>. To have fair comparison, only the results of ResNet-50 was shown where possible. The reported BYOL <ref type="bibr" target="#b17">[17]</ref> was pretrained for 1000 epochs, with 53.2/68.8 top-1 accuracy for 1%/10% labels, but our BYOL-EMAN achieved 55.1/68.1, which was pretrained only for 200 epochs. Our MoCo-EMAN achieved the accuracy of 57.4 for 1% labels, which is much higher than the other methods in the table, and 68.1 for 10% labels. Note that, the comparison between these methods is not completely fair. For example, the SwAV <ref type="bibr" target="#b4">[5]</ref>, with higher accuracy for 10% labels, used much more expensive multicrop strategy, which could also benefit our EMAN models. kNN Classification and Image Retrieval Although the linear classification is a common strategy to evaluate the self-supervised models in recent years <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b19">19]</ref>, it requires additional training, which is not the most direct way to evaluate the representations. Instead, we also compared the kNN accuracies on full train/val data in <ref type="table" target="#tab_3">Table 4</ref>, following <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b52">52]</ref>. With this more direct evaluation, the EMAN still has consistent improvements over the MoCo and BYOL baselines. And they also outperform <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b52">52]</ref> and recent PCL <ref type="bibr" target="#b30">[30]</ref> and SwAV <ref type="bibr" target="#b4">[5]</ref>. We also evaluate on the task of image retrieval (find the most relevant entries for each query) on ImageNet which also requires no additional training. This task is a practical application of self-supervised pretraining, since the accurate annotations are usually unavailable in many scenarios of image retrieval. We used train as the retrieval database and val as queries, and followed <ref type="bibr" target="#b49">[49]</ref> to use the top 1000 retrievals for the evaluation of mean averaged precision (mAP) and recall. <ref type="table" target="#tab_3">Table 4</ref> shows the EMAN also has consistent and nontrivial improvements over the baselines for this task. The PCL <ref type="bibr" target="#b30">[30]</ref> and SwAV <ref type="bibr" target="#b4">[5]</ref> are compared, but they have shown much worse results.</p><p>It has also been shown that the unsupervised learning is still lagging behind supervised learning for kNN classification and image retrieval, although SwAV <ref type="bibr" target="#b4">[5]</ref> has presented minor gap to supervised learning for linear evaluation. However, the EMAN models can learn better feature representations for these two tasks.</p><p>Low-shot Classification Given the superior performances of EMAN in the regimes of few annotations in <ref type="table" target="#tab_1">Table 2</ref>, lowshot classification was evaluated, with k samples per class. Following <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b30">30]</ref>, we trained linear SVMs <ref type="bibr" target="#b11">[11]</ref> on top of the frozen representations. We searched the best SVM cost parameter C ? 2 <ref type="bibr">[?5,5]</ref> , and averaged the numbers of 5 different sets of samples.</p><p>The results in <ref type="table" target="#tab_5">Table 5</ref> have demonstrated that EMAN still improves the MoCo/BYOL baselines in low-shot cases,  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Semi-supervised Evaluation</head><p>The semi-supervised learning experiments of FixMatch are shown in <ref type="table">Table 6</ref> Comparison with the State-of-the-art The FixMatch-EMAN models are compared with the state-of-the-art semisupervised methods in <ref type="table">Table 7</ref>. For 10% labels the proposed FixMatch-EMAN achieves 74.0 top-1 accuracy, beating out the original FixMatch [39] by 2.5 points. Note that this is very close to the fully supervised learning accuracy of 76.1 in <ref type="table" target="#tab_1">Table 2</ref>. For 1% labels, the best previously reported results are SimCLR-v2 of roughly 60.0, with knowledge distillation being trained for 300 epochs after self-supervised pretraining and semi-supervised finetuning. Our FixMatch-EMAN achieved 63.0, which is about 3.0 points higher than SimCLR-v2, with simpler pipeline and fewer epochs (150). Finally, we note the specifically designed semi-supervised learning algorithms (in <ref type="table">Table 7</ref>) outperform self-supervised pre-trainning followed by semi-superivised finetuning (in <ref type="table">Table 3</ref>) for annotation insufficient scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Ablation Studies</head><p>The ablation experiments, with results in  <ref type="table" target="#tab_7">Table 8</ref>. The ablation experiments. "PN" means proxy norm, m EMAN momentum of (9) and ? BN momentum of (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EMAN Momentum</head><p>We have tested different EMAN momentums of (9), but the momentum for parameter update of (1) is remained the same 0.999 as in <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b41">41]</ref>. When m = 0.9 of EMAN, the statistics are updated much faster than the parameters, and the accuracy drops for MoCo but remains almost the same for FixMatch. When m = 0.99999, the statistics are updated much slower, and both MoCo and Fix-Match have much worse performances. These have shown that the normalization statistics should well aligned with the parameters to ensure stable performance.</p><p>Other EMAN-similar Designs Two other designs, achieving similar goals of EMAN in Section 4, were also evaluated. Both of them use <ref type="bibr" target="#b8">(8)</ref> in the teacher during training, but the difference is what proxy statistics ? ? and ? ?2 to use. The first design is to use the collected proxy statistics of the teacher following (4) up to the previous iteration. This is similar to run the inference mode (5) during training in standard BN, but update the proxy statistics using (4) on the fly. The second design is to simply copy the proxy statistics from the student, by setting m = 0 in (9). They are denoted as "teacher PN" and "student PN" in <ref type="table" target="#tab_7">Table 8</ref>, respectively. When using the default BN momentum ? = 0.9, both designs usually lead to worse performance than EMAN. By setting ? = 0.999 to have better aligned statistics with the parameters, better results are available, and the "student PN" achieved very close performances to EMAN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we proposed a simple normalization technique, exponential moving average normalization (EMAN), for EMA-teacher based semi-and self-supervised learning. It resolves the issues of cross-sample dependency and parameter mismatch when using the standard BN in EMAteacher framework. This simple design improves the state of the art in semi-and self-supervised learning. These improvements are consistent across different techniques, network architectures, training duration, and datasets, showing that EMAN is generally applicable.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. FixMatch</head><p>We re-implemented FixMatch in PyTorch, and followed the exactly same hyperparameter settings as in the official FixMatch <ref type="bibr" target="#b39">[39]</ref> 1 . The number of labeled (unlabeled) images in a batch is 64 (320). The loss weight for the supervised (unsupervised) loss is 1.0 (10.0). The EMA momentum m = 0.999. The number of epoch is counted on unlabeled images.</p><p>As discussed in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b26">26]</ref>, the EMA updated teacher model can present more reliable results. We show the accuracy curves of the teachers (with EMAN) for both baseline FixMatch and FixMatch-EMAN on ImageNet validation in <ref type="figure" target="#fig_6">Figure 4</ref>. Although the baseline FixMatch did not use the EMA-teacher framework, we can collect its EMA updated model (both model parameters and BN statistics) during training for the purpose of inference only. It can be found that the EMA teacher indeed has higher and more stable accuracy, especially during the former epochs. This is the reason why we reformulate the baseline FixMatch to EMA-teacher framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. MoCo</head><p>We used the code and followed the exactly same settings as in the official MoCo-v2 [10] 2 . When using EMAN, the training will become less stable at the beginning, because the whole network, including the normalization statistics, is slowly updated, with momentum m = 0.999. In this case, the warn-up learning rate schedule is more important. Without it, MoCo-EMAN will have worse performance in our experiments. In addition, as seen in <ref type="figure" target="#fig_3">Figure 3 (b)</ref>, the kNN accuracy of MoCo-EMAN will have a slight decrease in the last training epochs, because the learning rate is too small. This behavior is quite consistent in our MoCo-EMAN experiments, and the best model is usually at around 90% training epochs. To avoid the decrease, we simply used the 90%-th epoch checkpoint for the evaluation of other downstream tasks. Another solution is to set the minimum learning rate to a not-too-small value, e.g. 0.001, in the cosine learning rate schedule. These two strategies achieved very close performances in our experiments.</p><p>In <ref type="figure" target="#fig_7">Figure 5</ref> (a) and (b), we show the curves of loss and instance discrimination accuracy of MoCo during training. Although they do not directly relate to the actual representations power, they can help to understand what is happening during training. It can be found that the training behaviors are quite different between MoCo-ShuffleBN and MoCo-EMAN. EMAN will make the self-supervised learning task of MoCo more difficult, and lead to higher training loss and lower instance discrimination accuracy. It suggests that EMAN can better prevent the MoCo model from cheating, and could potentially improve the representation power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. BYOL</head><p>We re-implemented BYOL in PyTorch, and followed some hyperparameter settings as in the official BYOL <ref type="bibr" target="#b17">[17]</ref> 3 . The official implementation chooses different hyperparameters for experiments of different numbers of epochs. To be consistent, we set weight decay as 0.000001, and initial EMA momentum as 0.98, for experiments of both 50 and 200 epochs. The initial learning rate was set as 0.9 (1.8) for 50 (200) epochs. In all BYOL experiments, the batch size was 512 on a machine with 8 GPUs.</p><p>The training loss curves of BYOL are also shown in <ref type="figure" target="#fig_7">Figure 5</ref> (c). Similar to the observations from MoCo curves, EMAN will make the self-supervised learning task of BYOL more difficult, and result in higher training loss. It suggests that EMAN can better prevent the BYOL model from cheating, and could potentially improve the representation power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Other Settings</head><p>ImageNet Sampling We sample 1% (10%) images per class for the semi-supervised learning experiments of 1% (10%) labels, which are 12,820 (128,118) images in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linear and Finetuning Evaluation</head><p>In addition to the details in Section 5.2, weight decay = 0 and momentum = 0.9 for linear evaluation, and weight decay = 0.0001, and momentum = 0.9 for finetuning. The standard data augmentation (RandomResizedCrop and RandomHorizontalFlip) was used during training. At inference, the center 224?224 crop was used. kNN Evaluation Different from <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b52">52]</ref>, we did not use the weighting mechanism. Instead, it was just a standard kNN classifier with top k = 20 neighbors, where a query will be classified to the majority class of neighbor samples. The center 224?224 crop was used, also in the experiments of Image Retrieval and Low-shot Classification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>The architecture change of FixMatch using EMAN. im s/im w is the strongly/weakly augmented view of an image, cat concatenation. The other symbols are similar asFigure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>The training accuracy curves of FixMatch, MoCo and BYOL on ImageNet, by using different normalization schemes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(b) and (c). By simply changing the standard BN to the proposed EMAN in the teacher model, significant boosts are available in all Fix-Match/MoCo/BYOL, e.g. roughly 10/6/7 points. This simple change also surpassed all three very strong baseline Fix-Match/MoCo/BYOL by about 2/4/3 points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>The FixMatch accuracy with 10% labels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>(a) and (b) are the training loss and instance discrimination top-1 accuracy of MoCo, and (c) the training loss of BYOL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Accuracy with different normalization.</figDesc><table><row><cell>student</cell><cell>teacher</cell><cell cols="2">FixMatch MoCo</cell><cell>BYOL</cell></row><row><cell>default</cell><cell>default</cell><cell>67.1</cell><cell>54.4</cell><cell>55.4</cell></row><row><cell>BN</cell><cell>BN</cell><cell>58.9</cell><cell>52.5</cell><cell>52.0</cell></row><row><cell>SyncBN</cell><cell>SyncBN</cell><cell>52.0</cell><cell>53.3</cell><cell>55.4</cell></row><row><cell>BN</cell><cell>ShuffleBN</cell><cell>55.8</cell><cell>54.4</cell><cell>52.6</cell></row><row><cell>GN</cell><cell>GN</cell><cell>63.3</cell><cell>49.3</cell><cell>failed</cell></row><row><cell>IN</cell><cell>IN</cell><cell>61.3</cell><cell>46.5</cell><cell>failed</cell></row><row><cell>BN</cell><cell>EMAN</cell><cell>69.2</cell><cell>55.8</cell><cell>56.2</cell></row></table><note>for efficiency purpose (the observations are consistent with all train/val data). FixMatch/MoCo/BYOL was trained for 100/100/50 epochs, where FixMatch drops learning rate by 10 times at 60th and 80th epoch, and MoCo/BYOL uses cosine learning schedule. All training uses linear warm-up learning rate for 5 epochs.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="2">Method</cell><cell>1% labels top-1 top-5 top-1 top-5 top-1 top-5 10% labels 100% labels</cell></row><row><cell cols="2">Supervised [3, 20]</cell><cell>25.4 48.4 56.4 80.4 76.1 92.9</cell></row><row><cell></cell><cell>MoCo</cell><cell>43.2 71.0 58.8 82.6 67.5 88.1</cell></row><row><cell></cell><cell>MoCo-EMAN</cell><cell>48.9 75.3 60.5 83.5 67.7 88.0</cell></row><row><cell></cell><cell>MoCo (2?)</cell><cell>51.5 77.6 64.2 86.0 72.4 90.9</cell></row><row><cell>Linear</cell><cell cols="2">MoCo-EMAN (2?) 56.8 80.4 65.7 86.4 72.3 90.6 MoCo (800) 50.4 76.6 63.0 85.4 70.3 90.0</cell></row><row><cell></cell><cell cols="2">MoCo-EMAN (800) 55.4 79.3 64.0 85.3 70.1 89.3</cell></row><row><cell></cell><cell>BYOL</cell><cell>51.3 76.3 64.8 86.2 71.4 90.2</cell></row><row><cell></cell><cell>BYOL-EMAN</cell><cell>55.1 78.9 66.7 87.3 72.2 90.7</cell></row><row><cell></cell><cell>MoCo</cell><cell>44.8 73.4 63.3 86.1 76.1 92.9</cell></row><row><cell></cell><cell>MoCo-EMAN</cell><cell>50.4 77.8 64.9 87.1 76.0 93.0</cell></row><row><cell>Finetune</cell><cell cols="2">MoCo (2?) MoCo-EMAN (2?) 59.2 83.7 69.7 89.8 78.9 94.3 53.1 79.9 67.9 88.6 79.2 94.6 MoCo (800) 50.9 78.1 66.3 87.7 77.2 93.6</cell></row><row><cell></cell><cell cols="2">MoCo-EMAN (800) 57.4 82.3 68.1 88.5 77.4 93.6</cell></row><row><cell></cell><cell>BYOL</cell><cell>52.1 77.3 67.7 88.5 77.0 93.5</cell></row><row><cell></cell><cell>BYOL-EMAN</cell><cell>54.6 78.6 68.1 88.6 77.1 93.5</cell></row></table><note>. The linear and the finetuning evaluation on ImageNet. The default model is ResNet-50 trained for 200 epochs. "2?" means ResNet-50 of 2? width and "800" means 800 epochs.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>The kNN and image retrieval evaluation on ImageNet. ? indicates numbers run by us from the pretrained model.</figDesc><table><row><cell>Method</cell><cell>Epochs</cell><cell>kNN top-1</cell><cell cols="2">retrieval mAP recall</cell></row><row><cell>Supervised</cell><cell>90</cell><cell>74.8</cell><cell>57.9</cell><cell>37.0</cell></row><row><cell>MoCo</cell><cell>200</cell><cell>54.5</cell><cell>32.4</cell><cell>18.5</cell></row><row><cell>MoCo-EMAN</cell><cell>200</cell><cell>58.0</cell><cell>39.8</cell><cell>24.3</cell></row><row><cell>MoCo</cell><cell>800</cell><cell>60.0</cell><cell>41.4</cell><cell>25.6</cell></row><row><cell>MoCo-EMAN</cell><cell>800</cell><cell>62.8</cell><cell>47.9</cell><cell>30.5</cell></row><row><cell>BYOL</cell><cell>200</cell><cell>62.8</cell><cell>37.5</cell><cell>20.1</cell></row><row><cell>BYOL-EMAN</cell><cell>200</cell><cell>64.9</cell><cell>39.8</cell><cell>20.4</cell></row><row><cell>InstDisc [45]</cell><cell>-</cell><cell>46.5</cell><cell>-</cell><cell>-</cell></row><row><cell>LA [52]</cell><cell>-</cell><cell>49.4</cell><cell>-</cell><cell>-</cell></row><row><cell>PCL [30]</cell><cell>200</cell><cell>54.5</cell><cell>39.5  ?</cell><cell>24.2  ?</cell></row><row><cell>SwAV [5]</cell><cell>800</cell><cell>59.2</cell><cell>35.9  ?</cell><cell>17.5  ?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>The low-shot evaluation. ? indicates numbers run by us from the pretrained model.</figDesc><table><row><cell>Method</cell><cell>Pretrained</cell><cell>Schd.</cell><cell cols="3">1% labels top-1 top-5 top-1 top-5 10% labels</cell></row><row><cell>baseline</cell><cell>None</cell><cell>1?</cell><cell>-</cell><cell>-</cell><cell>67.1 86.7</cell></row><row><cell>EMAN</cell><cell>None</cell><cell>1?</cell><cell>-</cell><cell>-</cell><cell>69.2 88.3</cell></row><row><cell>baseline</cell><cell>MoCo</cell><cell>1?</cell><cell cols="3">51.2 73.5 70.2 89.0</cell></row><row><cell>EMAN</cell><cell>MoCo</cell><cell>1?</cell><cell cols="3">58.1 80.4 72.0 90.2</cell></row><row><cell cols="2">EMAN MoCo-EMAN</cell><cell>1?</cell><cell cols="3">60.9 82.5 72.6 90.5</cell></row><row><cell>baseline</cell><cell>None</cell><cell>3?</cell><cell>-</cell><cell>-</cell><cell>71.1 88.9</cell></row><row><cell>EMAN</cell><cell>None</cell><cell>3?</cell><cell>-</cell><cell>-</cell><cell>72.8 90.3</cell></row><row><cell>EMAN</cell><cell>MoCo</cell><cell>3?</cell><cell cols="3">61.4 82.1 73.9 91.0</cell></row><row><cell cols="2">EMAN MoCo-EMAN</cell><cell>3?</cell><cell cols="3">63.0 83.4 74.0 90.9</cell></row><row><cell></cell><cell cols="5">Table 6. The FixMatch results on ImageNet.</cell></row><row><cell cols="6">as low as k = 1 sample per class. For example, in the ex-</cell></row><row><cell cols="6">periments of ImageNet, MoCo-EMAN is about 4-6 points</cell></row><row><cell cols="6">better than MoCo. The gains for BYOL are smaller, but still</cell></row><row><cell cols="6">1-3 points. Note that, our MoCo-EMAN can achieve 35.8%</cell></row><row><cell cols="6">top-1 accuracy for 1000-way 1-shot ImageNet, which is</cell></row><row><cell cols="6">12.3 points higher than SwAV [5]. Pascal VOC2007 [13]</cell></row><row><cell cols="6">and iNaturalist [23] have also been tested. Since the domain</cell></row><row><cell cols="6">of VOC is similar to ImageNet, we directly used the frozen</cell></row><row><cell cols="6">ImageNet representations for VOC experiments. However,</cell></row><row><cell cols="6">it is not the case for iNaturalist, where ImageNet represen-</cell></row><row><cell cols="6">tations have poor performances, so we train MoCo/BYOL</cell></row><row><cell cols="6">from scratch on iNaturalist for 1000/200 epochs. The im-</cell></row><row><cell cols="6">provements by EMAN are still consistent on both datasets.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell>, fol-</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/google-research/fixmatch 2 https://github.com/facebookresearch/moco</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/deepmind/deepmind-research/tree/master/byol</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">There are many consistent explanations of unlabeled data: Why you should average</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Athiwaratkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Finzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">ton. Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">S4L: self-supervised semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1476" to="1485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Bucilua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandru</forename><surname>Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="535" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2020. 5</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pat</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zimo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03012</idno>
		<title level="m">An information-rich 3d model repository</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Semi-supervised learning (chapelle, o</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Zien</surname></persName>
		</author>
		<editor>. et al.</editor>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="542" to="542" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Big self-supervised models are strong semi-supervised learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<title level="m">Improved baselines with momentum contrastive learning</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (VOC) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Understanding selfsupervised and contrastive learning with bootstrap your own latent (byol)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abe</forename><surname>Fetterman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Albrecht</surname></persName>
		</author>
		<ptr target="https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html,2020.4" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scaling and benchmarking self-supervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6390" to="6399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent: A new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pierre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><forename type="middle">Daniel</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Azar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="9726" to="9735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Data-efficient image recognition with contrastive predictive coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>H?naff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">De</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Fauw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sm Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den Oord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="4182" to="4192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The inaturalist species classification and detection dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><forename type="middle">Mac</forename><surname>Grant Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8769" to="8778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">E</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<title level="m">Snapshot ensembles: Train 1, get M for free</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Averaging weights leads to wider optima and better generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitrii</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timur</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dmitry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<editor>Amir Globerson and Ricardo Silva</editor>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Self-supervised visual feature learning with deep neural networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longlong</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingli</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2017. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04966</idno>
		<title level="m">Prototypical contrastive learning of unsupervised representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Microsoft COCO: common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">8693</biblScope>
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Self-supervised learning of pretext-invariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: A regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Shin-Ichi Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">9910</biblScope>
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>K?pf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<editor>Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala</editor>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">MEAL: multi-model ensemble via adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhankui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4886" to="4893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fixmatch: Simplifying semisupervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Contrastive multiview coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="776" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.08022</idno>
		<title level="m">stance normalization: The missing ingredient for fast stylization</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">11217</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Self-training with noisy student improves imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10684" to="10695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Towards stabilizing batch statistics in backward propagation of batch normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruosi</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Central similarity quantization for efficient image and video retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><forename type="middle">E H</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3080" to="3089" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">9907</biblScope>
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Semi-supervised learning literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry</forename><surname>Xiaojin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison Department of Computer Sciences</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Local aggregation for unsupervised learning of visual embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxu</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">Lin</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Yamins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
