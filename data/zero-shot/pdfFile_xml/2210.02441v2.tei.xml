<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ASK ME ANYTHING: A SIMPLE STRATEGY FOR PROMPTING LANGUAGE MODELS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simran</forename><surname>Arora</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avanika</forename><surname>Narayan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayee</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurel</forename><surname>Orr</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neel</forename><surname>Guha</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kush</forename><surname>Bhatia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Chami</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Numbers Station</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Sala</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ASK ME ANYTHING: A SIMPLE STRATEGY FOR PROMPTING LANGUAGE MODELS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T12:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt that demonstrates how to perform the task and no additional training. Prompting is a brittle process wherein small modifications to the prompt can cause large variations in the model predictions, and therefore significant effort is dedicated towards designing a painstakingly perfect prompt for a task. To mitigate the high degree of effort involved in prompting, we instead ask whether collecting multiple effective, yet imperfect, prompts and aggregating them can lead to a high quality prompting strategy. Our observations motivate our proposed prompting method, ASK ME ANYTHING PROMPTING (AMA). We first develop an understanding of the effective prompt formats, finding question-answering (QA) prompts, which encourage open-ended generation ("Who went to the park?") tend to outperform those that restrict the model outputs ("John went to the park. Output True or False"). Our approach recursively uses the LLM to transform task inputs to the effective QA format. We apply these prompts to collect several noisy votes for the input's true label. We find that these prompts can have very different accuracies and complex dependencies and thus propose to use weak supervision, a procedure for combining the noisy predictions, to produce the final predictions. We evaluate AMA across open-source model families (EleutherAI, BLOOM, OPT, and T0) and sizes (125M-175B parameters), demonstrating an average performance lift of 10.2% over the few-shot baseline. This simple strategy enables the open-source GPT-J-6B model to match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular benchmarks. Averaged across these tasks, the GPT-J-6B model outperforms few-shot GPT3-175B. We release our code for reproducing the results here: https://github.com/HazyResearch/ama_prompting.</p><p>Recent work has evaluated LLM prompting performance on a broad set of tasks and finds the process to be brittlesmall changes to the prompt result in large performance variations <ref type="bibr" target="#b2">[Zhao et al., 2021</ref><ref type="bibr" target="#b3">, Holtzman et al., 2021</ref>. The performance further varies depending on the chosen LLM family <ref type="bibr" target="#b4">[Ouyang et al., 2022</ref> and model size <ref type="bibr" target="#b6">[Wei et al., 2022a</ref><ref type="bibr" target="#b7">, Lampinen et al., 2022</ref>. To improve reliability, significant effort is dedicated towards designing a painstakingly perfect prompt. For instance, Mishra et al. [2021]  and Wu et al. [2022]  recommend that users manually explore large search-spaces of strategies to tune their prompts on a task-by-task basis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large language models (LLMs) are bringing us closer to the goal of task-agnostic machine learning <ref type="bibr" target="#b1">, Bommasani et al., 2021</ref>. Rather than training models for new tasks, LLMs are being applied to new tasks out-of-the box. In this paradigm, termed in-context learning, LLMs are instead controlled via natural language task specifications, or prompts. A prompt is defined by a template, which contains placeholders for the description and demonstrations of the inputs and outputs for the task. <ref type="figure">Figure 1</ref>: AMA first recursively uses the LLM to reformat tasks and prompts to effective formats, and second aggregates the predictions across prompts using weak-supervision. The reformatting is performed using prompt-chains, which consist of functional (fixed, reusable) prompts that operate over the varied task inputs. Here, given the input example, the prompt-chain includes a question()-prompt through which the LLM converts the input claim to a question, and an answer() prompt, through which the LLM answers the question it generated. Different prompt-chains (i.e., differing in the in-context question and answer demonstrations) lead to different predictions for the input's true label.</p><p>This work instead considers aggregating the predictions of multiple effective, yet imperfect, prompts to improve prompting performance over a broad set of models and tasks. Given a task input, each prompt produces a vote for the input's true label, and these votes are aggregated to produce a final prediction. In pursuit of high quality prompting via aggregation, we face the following challenges:</p><p>1. Effective prompts: High quality prompts are a precursor to improvements from aggregation. We take the original prompts which yield near-random performance in  for two SuperGLUE tasks (CB, RTE). Generating multiple prompts in the same format and taking majority vote prediction across prompts has a minor effect (+4% for CB) and can even hurt performance versus the average prompt performance (-2% for RTE). Many proposals for improved prompts focus on a single task type and evaluate on a single model-family and/or size <ref type="bibr" target="#b6">[Wei et al., 2022a</ref><ref type="bibr" target="#b10">, Jung et al., 2022</ref>. We need a structure for prompting that works across tasks and models.</p><p>2. Scalable collection: After identifying effective prompt formats, we need to obtain multiple prompts in these formats -these prompts will be used to collect votes for an input's true label. The original format of a task varies widely and prior works manually rewrite input examples to new formats in a task-specific manner <ref type="bibr" target="#b8">[Mishra et al., 2021</ref>, which is challenging to scale. We need a scalable strategy for reformatting task inputs.</p><p>3. Prompt aggregation: Using the prompts above (for CB and RTE), we see 9.5% average variation in accuracy and that the Jaccard index over errors is 69% higher than if prompt errors were i.i.d. Majority vote (MV) is the primary unsupervised aggregation strategy in prior prompting work <ref type="bibr">[Jiang et al., 2020, Schick and</ref><ref type="bibr" target="#b12">Sch?tze, 2021]</ref>, but it does not account for either property, making it unreliable. We need a strategy that accounts for the varying accuracies and dependencies.</p><p>In this work, we propose ASK ME ANYTHING PROMPTING (AMA), a simple approach that surprisingly enables open-source LLMs with 30x fewer parameters to exceed the few-shot performance of GPT3-175B. In AMA:</p><p>1. We identify properties of prompts that improve effectiveness across tasks, model types, and model sizes. We study standard prompt-formats categorized by prior work  and find prompts that encourage open-ended answers ("Where did John go?") to be more effective than prompts that restrict the model output to particular tokens (e.g. "John went to the park. Output True or False?"). For instance, converting three SuperGLUE tasks (CB, RTE, WSC) from the original restrictive formats in  to open-ended formats provides a 72% performance improvement (Section 3.2). Given a task input, we find that a simple structure of (1) forming questions based on the input and (2) prompting the LLM to answer the questions applies quite generally and improves performance across diverse benchmark tasks.</p><p>2. We propose a strategy for scalably reformatting task inputs to the effective formats found in (1). We propose to transform task inputs to the effective open-ended question-answering format by recursively using the LLM itself in a fixed two step pipeline. We first use question()-prompts, which contain task-agnostic examples of how to transform statements to various (e.g., yes-no, cloze) questions and second use answer()-prompts that demonstrate ways of answering questions (e.g., concise or lengthy answers). Applying prompt-chains-answer(question(x))-gives a final prediction for the input x. 2 Chains are (1) reused across inputs and (2) different pairs of functional prompts can be combined to create variety. We apply the varying functional prompt-chains to an input to collect multiple votes for the input's true label. 3. We propose the use of weak supervision (WS) to reliably aggregate predictions. We find that the errors produced by the predictions of different chains can be highly varying and correlated. While majority vote (MV) may do well on certain sets of prompts, it performs poorly in the above cases. AMA accounts for these cases by identifying dependencies among prompts and using WS, a procedure for modeling and combining noisy predictions without any labeled data <ref type="bibr" target="#b13">[Ratner et al., 2017</ref><ref type="bibr" target="#b14">, Varma et al., 2019</ref>. We apply WS to prompting broadly for the first time in this work, showing it improves the reliability of prompting with off-the-shelf LLMs and no further training. We find that AMA can achieve up to 8.7 points of lift over MV and that on 9 tasks, it recovers dependencies among prompts to boost performance by up to 9.6 points.</p><p>We apply our proposed prompt-aggregation strategy, AMA, to 20 popular language benchmarks and 14 open-source LLMs from 4 model families (EleutherAI <ref type="bibr" target="#b15">[Black et al., 2021, Wang and</ref><ref type="bibr">Komatsuzaki, 2021, EleutherAI]</ref>, BLOOM blo <ref type="bibr">[2022]</ref>, OPT , and T0 ) spanning 3 orders-of-magnitude (125M-175B parameters). Our proof-of-concept provides an improvement over the few-shot (k = 3) baseline by an average of 10.2% ? 6.1% absolute (21.4% ? 11.2% relative) lift across models. We find the largest gains are on tasks where the knowledge required to complete the task is found in the provided context and comparatively less on closed-book tasks (e.g., factual recall). Most excitingly, ASK ME ANYTHING PROMPTING enables an open-source LLM, which is furthermore 30x parameters smaller, to match or exceed the challenging GPT3-175B few-shot baseline results in  on 15 of 20 benchmarks. We hope AMA and future work help address painpoints of using LLMs <ref type="bibr">[Narayan et al., 2022, Arora and</ref> by improving the ability to proceed with less-than-perfect prompts and enabling the use of small, private, and open-source LLMs. <ref type="figure">Figure 2</ref>: Relative lift with model scale using results and prompt-styles reported in <ref type="bibr">Brown et al. [2020] (Left)</ref>. Ablating the promptstyle using the GPT-J-6B model. We include calibration results <ref type="bibr" target="#b2">Zhao et al. [2021]</ref> and the "-" indicates the method cannot be applied to the task (Right).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ASK ME ANYTHING PROMPTING</head><p>We propose ASK ME ANYTHING PROMPTING (AMA), a prompting approach that uses multiple imperfect promptsrather than one painstakingly crafted perfect prompt-and reliably aggregates their outputs. We describe and motivate AMA's prompt format (Section 3.2), how AMA scalably produces collections of prompts (Section 3.3), and AMA's aggregation method (Section 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminaries</head><p>We consider supervised tasks, (X , Y), where x ? X is the example and y ? Y is the output. We have an unlabeled dataset D = {x i } n i=1 for which we wish to predict each y i . We apply LLMs to this task by using a prompt-a natural language prefix that demonstrates how to complete a task. A prompt consists of a prompt template, with placeholders for (1) zero or more in-context task demonstrations and (2) for the inference example x as shown in <ref type="figure" target="#fig_0">Figure 3</ref>. Given a prompt p, we use p : X ? Y to refer the output of the prompted LLM which produces a prediction? = p(x). Specifically, the LLM runs inference on p with x substituted for the placeholder in the template.</p><p>We denote a collection of m prompts as P = [p 1 , p 2 , ..., p m ]. Given input D, we (1) apply a collection P to each x ? D and (2) aggregate their predictions, denoted as P(x) = [p 1 (x), . . . , p m (x)], using an aggregator function ? : Y m ? Y to produce outputs? on each x. We can thus express the procedure via two key components we aim to understand, the prompts P and aggregator ?.</p><p>Running examples For the motivating observations in the rest of this section, we use three SuperGLUE  tasks-CommitmentBank (CB), Recognizing Textual Entailement (RTE), and Winograd Schema Challenge (WSC)-and the DBPedia and AGNews classification tasks <ref type="bibr" target="#b33">[Zhang et al., 2015]</ref>. We evaluate over the GPT-J-6B model <ref type="bibr" target="#b16">Wang and Komatsuzaki [2021]</ref>. CB and RTE require determining the vailidity of a statement is given some context (as in <ref type="figure">Figure 1</ref>), WSC requires outputting the subject corresponding to a given pronoun, and DBPedia and AGNews contain 14 and 4 classes respectively. We use as a running example: determine if the statement "John went to the park" is valid, given the context "John invited Mark to watch Jurassic Park with his family at the theater".</p><p>Simple baseline To provide some intuition on the challenges around effectively designing the two levers, P and aggregator ?, we start with a na?ve baseline with off-the-shelf prompts and the unsupervised majority vote prompt aggregation strategy used in prior work <ref type="bibr">[Jiang et al., 2020, Schick and</ref><ref type="bibr" target="#b12">Sch?tze, 2021]</ref>. We take the prompts proposed in  for GPT-3 and produce P with five prompts for each task by using different sets of in-context examples. Comparing majority vote (MV), the unsupervised aggregation strategy used in prior work, to the average performance of the prompts, MV gives 39.3% (+2.2%) for CB and 54.5% (-2%) for RTE. The delta from aggregating is minor and in the worst case, harmful. Ideally, we would expect that aggregation should lead to improvement by reducing noise, but we find that performance here is only comparable to the single prompt baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Effective Prompt Formats</head><p>First, we explore what makes an effective prompt format towards improving the quality of P(x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Standard prompt formats</head><p>We ground our analysis in three standard categories of prompts used in prior work including , <ref type="bibr">Sanh et al. [2022, inter alia.]</ref>: <ref type="bibr">(1)</ref> questions that restrict the model output particular tokens ("John invited Mark to come watch Jurassic Park. Output True or False?"); (2) cloze-questions which ask the model to fill in the remaining text ("John invited Mark to come watch Jurassic _" and using the LLM to fill-the-blank, "Park"); and (3) traditional (yes-no, Wh) free-form questions ("Where did John invite Mark?"). We compare these three prompting formats and make the following observations: 1. Open-ended prompts appear to outperform restrictive-prompts. We first group the results in  based on the format used for the task, along the above categorizations (see <ref type="figure">Figure 2</ref>). When scaling from GPT3-6.7B to GPT3-175B, we find that the relative gain is far lower on open-ended (cloze and traditional QA) formats vs. restricted formats. Next, CB, RTE, and WSC are originally formatted with restrictive-prompts in , and we form copies of the tasks in the open-ended question (cloze and free-form QA) formats. This improves the performance of the small model on average from 41.7% to 71.5% (+72%) . Intuitively, the task of answering open-ended questions is aligned with the next-token prediction language modeling objective. We observe that more precise questions give larger lifts. For WSC the restrictive prompt form is: "The pronoun 'his' refers to "Mark" in the context. True or False?", given the context "Mark went to the park with his dog.". Reformatting to "What does 'his' refer to?" and evaluating whether the answer is "Mark" provides 38% lift (69.2% accuracy). Yet, further extracting the portion of the context that mentions the pronoun ("his dog"), reformatting ("Whose dog?") and prompting with precise questions gives 49.4% lift (74.7%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>The use of open-ended questions over restrictive-prompts can increase the difficulty of mapping open-ended answers to valid output classes. For tasks with output spaces that are likely observed during pretraining (yes-no questions, sentiment classification), we see that the LLM naturally generates valid? ? Y. For tasks with specialized output classes (i.e. multi-class classification), we need to map the answer to the open-ended question (e.g., "What is the document about?") to a valid output class. For example, given 'Personality and Mental Health ... is a quarterly peer-reviewed academic journal published by ...", we observe that the LLM typically outputs semantically correct summaries of the document topic, e.g. "journal". We find that inserting a step for the LLM to map the open-ended output "journal" to a valid category via the prompt "A 'journal' maps to category: written work" enables a 33.3% and 11.1% lift over the few-shot baseline on DBPedia (14-way classification) and AGNews (4-way) respectively.</p><p>AMA's prompt format Motivated by the above two observations, we proceed in AMA with a two-step prompting pipeline: (1) generating questions based on the input and (2) prompting the LLM to answer the generated questions. These prompts are effective, and to further improve performance we next turn to generating and aggregating over multiple prompt-outputs for each input. For intuition, different questions (with our running example: "Who went to the park?", "Did John go the park?", "Where did John go?") emphasize different aspects of the input and can provide complementary information towards reasoning about the answer. Manually generating multiple prompts per input is challenging, and so we study how to do this at scale in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Creating Prompt Collections at Scale</head><p>Our goal is to produce a collection of prompts, P, that can be applied to tasks at scale. To produce prompts in the effective open-ended question-answering format, our insight is to recursively apply the LLM itself using a chain of functional prompts, referred to as a prompt()-chain. We describe these prompts as functional because they apply a task-agnostic operation to all inputs in the tasks, without any example-level customization. We describe the two functional prompts used in AMA below. We use <ref type="figure">Figure 1</ref> as a running example to explain each type. ). The answer() prompts contain demonstrations of how to answer a question (optionally) given some input context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5</head><p>To create P for aggregation, AMA constructs different prompt()-chains where each unique prompt()-chain is a different view of the task and can emphasize different aspects of x. Inspired by  and <ref type="bibr" target="#b26">Liu et al. [2021]</ref>, we also vary chains through two key levers-the in-context demonstrations and the style of prompt questions-as shown in <ref type="figure" target="#fig_0">Figure 3</ref>. To vary the style of open-ended prompt questions, we construct question() and answer() prompts that produce and answer either Yes/No, Wh, multiple-choice, or cloze-questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Prompt Aggregation</head><p>To aggregate the prompt predictions P(x) into outputs? reliably, we apply tools from weak supervision, a powerful approach for learning high-quality models from weaker sources of signal without labeled data <ref type="bibr" target="#b13">[Ratner et al., 2017]</ref>. We first describe properties of P(x) that illustrate when the simple baseline of majority vote may perform poorly. We then describe our aggregator ? WS , which explicitly identifies and then accounts for these properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline observations</head><p>We understand how to aggregate P(x) by presenting a set of observations on CB, RTE, and WSC. For each, we compare two baselines for constructing P: (1) P T : varying the prompt template with no overlap in the in-context examples, and (2) P E : varying the in-context examples for a fixed prompt template, all with | P | = 5.</p><p>We observe the following properties on P:</p><p>1. Varied overall accuracies: While prompts in P E may seem more similar than those in P T , the gap between the best and worst p i ? P is large in both cases -12.1% for P E and 9.6% for P T . 2. Varied class-conditional accuracies <ref type="bibr" target="#b2">[Zhao et al., 2021]</ref>: Beyond overall prompt accuracy, the average variance of class-conditional prompt accuracies is 9.7% across the tasks and baselines. 3. Highly-correlated outputs: Prompt predictions have dependencies among each other. The Jaccard index over error sets averaged across tasks is 42.2 for P E and 39.9 for P T . For reference, two prompts that produce i.i.d. errors and have 60% accuracy each would have a score of 0.25.</p><p>The three observations present challenges in aggregating predictions via simple approaches like MV. MV tends to do better than using one prompt, but it weights all prompts equally and treats them independently. Such an aggregation method may be sufficient over certain collections of prompts but is not reliable across general P that may exhibit the three properties we have observed.</p><p>AMA's aggregation strategy Given the varying accuracies and dependencies among prompt()-chains, in AMA we draw on recent work in weak supervision <ref type="bibr" target="#b13">[Ratner et al., 2017]</ref>, which is designed to account for these accuracy and dependency properties without relying on labels. We learn a probabilistic graphical model on Pr G,? (y, P(x)) using D and define the aggregator as ? WS (x) = arg max y?Y Pr G,? (y| P(x)), where G is a dependency graph among y and all of the prompts, and ? are the accuracy and correlation parameters of the distribution. Since we lack labeled data y, we cannot estimate G or ? directly from D. We apply work from WS-in particular, structure learning <ref type="bibr" target="#b14">[Varma et al., 2019]</ref> and latent variable estimation <ref type="bibr" target="#b29">[Ratner et al., 2018]</ref>-to learn? and?, which are then used to construct ? WS and predictions? AMA = ? WS (P(x)) on D (see Appendix C for explicit algorithm statements).</p><p>Excitingly, our aggregator is general enough to identify and model a broad range of complex dependencies and varied accuracies that may appear among sets of prompts, without any training. WS hence improves the reliability of aggregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Information Flow in AMA</head><p>Before evaluating end-to-end quality, we look at a simple information theoretic metric to understand the contributions of the individual components -P and ? -in the prompting procedure.</p><p>Information flow metric Specifically, we examine the conditional entropy, H(y|?), which measures the amount of uncertainty remaining in the true label y given a prediction?. Intuitively, H(y|?) will be low when? encodes information relevant to y. In our setting,? = ?(P(x)) is dependent on the two components of the prompting procedure, the prompts P and aggregator ?. The following simple decomposition of H(y|?) enables studying the contribution of each component:</p><formula xml:id="formula_0">H(y|?) = H(y| P(x))</formula><p>Controlled by P prompt quality</p><formula xml:id="formula_1">+ H(y|?) ? H(y| P(x))</formula><p>Controlled by aggregation method ?</p><p>Through the first term H(y| P(x)), H(y|?) depends on the quality and quantity of the individual prompts in P(x) (since H(y| P(x)) ? H(y|p(x))). A set of prompts that contains relevant information for y contributes to a low H(y|? the information in P(x) to predict?. An aggregator ? that more accurately matches the true Pr(y| P(x)) reduces the information loss in the compression step.</p><p>Evaluation We use (1) to evaluate our proposed solution AMA both empirically and theoretically. First considering H(y| P(x)), in <ref type="figure">Figure 4</ref> (Left) we observe AMA outperforms k-shot baselines with expected scaling in terms of both individual prompt()-chain quality (as shown by AMA No Agg) and their quantity.</p><p>Next we consider the gap term H(y|?) ? H(y| P(x)). It enables us to understand why MV is insufficient: it compresses information from P(x) according to a specific construction of Pr(y, P(x)), for which p i (x) ? p j (x)|y for all i, j ? [m], and Pr(p i (x) = c|y = c) for c ? Y is a single better-than-random constant across i and c. When the true distribution is vastly different-as is common-this misspecification results in a large gap between the optimal H(y| P(x)) and H(y|? MV ) in <ref type="figure">Figure 4</ref> (Right). Weak supervision can improve ? over the standard MV baseline to reduce the information loss H(y|? AMA ) ? H(y| P(x)).</p><p>In addition to empirical measurements, we can provide a theoretical characterization for the information flow. In Appendix D, we express H(y|? AMA ) in terms of the individual prompt accuracies under the standard weak supervision model (i.e., Ising model on y and P(x) <ref type="bibr" target="#b29">[Ratner et al., 2018]</ref>).</p><p>There has been recent interest in how LLMs improve primarily along the three axes of parameter scale, training data, and compute <ref type="bibr">, Hoffmann et al., 2022</ref><ref type="bibr" target="#b36">, Wei et al., 2022c</ref>. In <ref type="figure">Figure 4</ref>, as we increase the number of prompts to be aggregated, the conditional entropy reduces. Prompt aggregation may be another useful axis for understanding LLM scaling performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We evaluate ASK ME ANYTHING PROMPTING on 20 popular language benchmarks used in , . We report results across 14 unique LLMs including 4 model families (EleutherAI <ref type="bibr" target="#b15">[Black et al., 2021, Wang and</ref><ref type="bibr" target="#b16">Komatsuzaki, 2021]</ref>, OPT , BLOOM, and T0 ) spanning 3 orders-of-magnitude in size (125M-175B). We aim to validate whether AMA provides consistent lift across diverse  tasks (Section 5.1), works across model families (Section 5.2), and reliably aggregates the predictions across prompts (Section 5.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental details</head><p>We use a diverse set of tasks: SuperGLUE , NLI <ref type="bibr" target="#b37">[Mostafazadeh et al., 2017</ref><ref type="bibr" target="#b38">, Nie et al., 2020</ref>, classification <ref type="bibr" target="#b33">[Zhang et al., 2015</ref><ref type="bibr" target="#b39">, Socher et al., 2013</ref><ref type="bibr" target="#b40">, He and McAuley, 2016</ref>, and QA tasks <ref type="bibr" target="#b41">[Kasai et al., 2022</ref><ref type="bibr" target="#b43">, Berant et al., 2013</ref><ref type="bibr" target="#b44">, Dua et al., 2019</ref>. For all tasks, we compare to published results of the OpenAI few-shot-prompted GPT3-175B parameter model using the numbers reported in  and, for classification tasks, <ref type="bibr" target="#b2">Zhao et al. [2021]</ref>.  uses k ? [32..70] depending on the task and <ref type="bibr" target="#b2">Zhao et al. [2021]</ref> uses k ? [1..8], providing a challenging baseline for comparison.</p><p>For AMA we use 3 ? 6 prompt()-chains to generate predictions per input. We model the correlations between prompt-predictions per task, without using any labeled training data, to obtain the final prediction per example via weak supervision (WS). We report both the average performance over the prompt()-chains (QA) and with AMA's WS aggregation (QA + WS). We report QA + WS across 5 random seeds for the model. Model details and prompt()chains are in the Appendix. 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Main Results</head><p>We report benchmark results in <ref type="table" target="#tab_2">Table 1</ref> comparing the open-source GPT-J-6B and few-shot (k ? [32..70]) GPT3-175B. We find that the open-source 6B parameter model exceeds the average few-shot performance of the GPT3-175B model on 15 of 20 benchmarks. Over the 20 tasks, AMA gives an average improvement of 41% over the 6B parameter model's few-shot (k = 3) performance to achieve this.</p><p>We find that AMA provides the most lift on tasks where all requisite knowledge is included in the task input (e.g., reading comprehension) and that largely rely on model's natural language understanding (NLU) abilities. The lift is lower on tasks that rely on the LLMs memorized knowledge (e.g. commonsense, closed-book). AMA can help close the gap on knowledge-intensive tasks. The closed-book WebQ task includes simple questions, where the answers are likely seen during pretraining. We find that using an open-ended prompt that asks the LM to generate relevant context,  and then prompting the model to answer the original question using the generated context is effective. However, there are limitations as seen on NQ.</p><p>We similarly see limitations when tasks cannot rely on the latent knowledge. We observe a small performance gap between model sizes on RealTimeQA, which includes questions that have temporally changing answers that are less likely to be memorized. Similarly, for tasks requiring domain knowledge, e.g. the "Amazon Instant Video" class in the Amazon task, all model-sizes achieve near-0 performance. In such cases, information retrieval may help close the gap. The flexible LLM interface permits asking and answering questions over diverse knowledge sources such as databases or a search engine <ref type="bibr" target="#b45">[Nakano et al., 2021]</ref>. We provide an extended error analysis <ref type="table" target="#tab_2">Table 1</ref> results in Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation across Models</head><p>Benchmark results We evaluate the lift from AMA over out-of-the-box few-shot performance across different sizes of four open-source LMs (EleutherAI, OPT, BLOOM, and T0) across 7 tasks (4 NLU, 2 NLI, 1 classification). In this analysis, we want to understand the effectiveness of AMA's prompt()-chains reformattings across models and report the average prompt performance over the 3-6 prompt()-chains used per task. EleutherAI, OPT, and BLOOM are GPT models, while T0 is obtained by explicitly fine-tuning a T5 LM <ref type="bibr" target="#b46">[Raffel et al., 2019]</ref> on prompt-input-output tuples.</p><p>Excitingly, the AMA prompt()-chains apply quite generally. We see a 10.2% ? 6.1% absolute (21.4% ? 11.2% relative) lift on average across models and tasks (see <ref type="figure" target="#fig_2">Figure 5a</ref> (a)). We observe the absolute lift increases with model size and levels out, however we note that there are few-models per size grouping. The average absolute (relative) lift by model family (across tasks and sizes) is 11.0% (24.4%) for EleutherAI, 11.0% (23.4%) for BLOOM, and 11.9% (22.7%) for OPT, and 2.9% (8.3%) for T0. We hypothesize the lower lift on T0 arises because the model was fine-tuned on zero-shot prompts, which may compromise its in-context learning abilities.</p><p>Diagnostics for understanding AMA lift To further understand why models see different degrees lift, we create a set of diagnostic tasks that correspond to the steps in prompt()-chains. The diagnostics measure four basic operations -question generation, answer generation, answer selection, and extraction. For each operation, we create 1-3 tasks with 50 manually-labeled samples per task. See Appendix E for task details.</p><p>We measure the average performance across each operation across different sizes of models in the four families (EleutherAI, OPT, BLOOM, and T0). We group models and sizes into four buckets of T0 (3B parameters) and GPT models (&lt; 1B, 1B, and 6 ? 7B parameters). <ref type="figure" target="#fig_2">Figure 5b</ref> shows results where the buckets are ordered by their average AMA lift across the 7 tasks from Section 5.2, meaning T0 (3B) sees the least lift while 6 ? 7B GPT models realize the most lift. We find that overall, models with higher performance across the four operations see more lift with AMA. T0 performs poorly on the generative tasks, indicating the importance of text and question generation for AMA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation against other aggregation methods</head><p>We compare our WS aggregation approach with the standard unsupervised approach, majority vote (MV), on prompt()-chains. We find that AMA can achieve up to 8.7 points of lift over MV, and does not do worse than MV on 16 out of 20 tasks. On the remaining 4 tasks, we perform worse than MV by at most 1.0 points. We also examine the effect of modeling dependencies in WS. We find that on 9 tasks, our approach recovers dependencies in the data (rather than assuming conditionally independent P(x)), which improves performance by up to 9.6 points and an average of 2.2 points. We provide more details and evaluation against labeled data baselines in    compared to majority vote (MV) and weak supervision (WS) over 10 different prompt formats in Prompt-Source. When using the Prompt-Source prompts, the average lift across tasks is 3.6 points for MV and 6.1 points for WS.</p><p>Next, we evaluate T0 on zero-shot prompts from the public PromptSource , which are better aligned with how this model has been trained. Specifically, we take 10 unique PromptSource prompts for CB, WIC, WSC and RTE respectively, and find that aggregating with MV yields an average lift of 3.7 accuracy points and aggregating with WS gives an average lift of 6.1 accuracy points (see <ref type="table" target="#tab_5">Table 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we introduce ASK ME ANYTHING PROMPTING which (1) scalably obtains multiple prompts given a task input and (2) combines the intermediate answers to these prompts using weak supervision to give the final prediction. The steps in AMA stem from our observations on the effectiveness of open-ended questions over restrictive prompts, and the ability to model the varying accuracies and dependencies across a collection of prompts using weaksupervision. Overall, AMA provides lift across four language model families and across model sizes ranging from 125M-175B parameters. Most excitingly, we find that AMA enables a 30x smaller LM to exceed the average performance of few-shot GPT3-175B averaged across 20 popular language benchmarks. Several LM applications involve private data or require operating over large amounts of data -for these applications, using APIs to access closedsource models or hosting large models locally is challenging. We hope the strategies in AMA and subsequent work help enable such applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Reproducibility Statement</head><p>We release prompts and code for reproducing all benchmark results for few-shot and AMA prompting, and our diagnostic evaluation splits here: https://github.com/HazyResearch/ama_prompting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Ethics Statement</head><p>We intend for AMA to aid practitioners in their exploration and use of LLMs-especially smaller, open-source LLMs. However, we recognize that AMA could be used to perform harmful or unethical tasks. AMA is a proof-of-concept; it has error-modes and we recognize the inherent risks to using LLMs. Detailed discussions of these risks are in <ref type="bibr" target="#b1">Bommasani et al. [2021]</ref>, <ref type="bibr" target="#b48">Weidinger et al. [2021]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The computation required in this work was provided by </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Experiment Details</head><p>We use A100 NVidia GPUs to run all experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Models</head><p>We evaluate over 4 model families: T0, BLOOM, EleutherAI, OPT, and GPT3. In our evaluations, we use the following model family variants:</p><formula xml:id="formula_3">EleutherAI (GPT-Neo-125M, GPT-Neo-1.3B, GPT-J-6B, GPT-NeoX-20B), BLOOM (BLOOM-560M, BLOOM-1.7B, BLOOM-7.1B, BLOOM-176B), OPT(OPT-125M, OPT-1.3B, OPT-6.7B, OPT-13B, OPT-175B), T0 (T0-3B)</formula><p>, and GPT-3 (davinci). We download T0, BLOOM, OPT, and EleutherAI models from the HuggingFace Model Hub <ref type="bibr" target="#b49">[HuggingFace, 2021]</ref>. All inference calls to the OpenAI Davinci model were made using the OpenAI API davinci endpoint <ref type="bibr" target="#b50">[OpenAI, 2021]</ref>, the original GPT-3 175B parameter model used in . We access these models by passing our input prompts to the endpoint for a per-sample fee.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Metrics</head><p>For RealTimeQA, the reported GPT-3 performance in <ref type="bibr" target="#b41">Kasai et al. [2022]</ref> is reported over the text-davinci-002 API endpoint. Given that all our GPT-3 evaluations are over davinci, we re-evaluate the GPT-3 performance on RealTimeQA using the davinci endpoint and the few-shot prompt from RealTimeQA 4 .</p><p>We follow the metrics used in . All tasks are scored using matching accuracy except for DROP/Re-alTimeQA that use text f1, WebQ/NQ that use span overlap accuracy, and MultiRC that uses f1a accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Weak Supervision</head><p>For each task, we use an unlabeled dataset constructed from the test set as well as 1000 samples from the training set (ignoring the labels). We run the structure learning part of the weak supervision algorithm (for?) with the default parameters from <ref type="bibr" target="#b14">Varma et al. [2019]</ref>. If the recovered sparse matrix has all entries greater than 1, we pass in an empty edgeset to the next step of learning? (e.g., data is too noisy to learn structure from); otherwise, we pass in the edge with the highest value in the sparse matrix. <ref type="table" target="#tab_4">Table 4</ref> compares AMA's aggregation method against several other baselines for aggregating prompt()-chains, including majority vote. We compare against weighted majority vote (WMV), where we use labeled data to weight according to each prompt's accuracy by constructing ? WMV (P(x)) = m i=1 exp(??? i )1 {p i (x) = y}. ? i is the error of p i on a labeled training set of 1000 examples, and ? is a temperature hyperparameter, for which we perform a sweep over <ref type="bibr">[0.25, 0.5, 1, 2, 4, 8, 16</ref>, 32] using a 20% validation split. We also compare against a simple strategy of using the prompt that performs the best on the labeled set of data (Pick Best). Finally, AMA (no deps) is our method when we pass in an empty edgeset to the algorithm in <ref type="bibr" target="#b29">Ratner et al. [2018]</ref>.   <ref type="table" target="#tab_4">Table 4</ref>: AMA Aggregation method ablation for the GPT-J-6B parameter model, as well as the number of prompt()-chains used for each task. For ReCoRD, and QA tasks (DROP, WebQs, RealTimeQA, NQ), we use 3 prompts each and use majority vote as our aggregation strategy reported in the (QA + WS) columns of <ref type="table" target="#tab_2">Table 1 and Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Weak Supervision Aggregation Ablations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Weak Supervision Algorithm</head><p>We briefly explain the weak supervision algorithm used for constructing ? WS . Weak supervision models learn the latent variable graphical model on the distribution Pr(y, P(x)) using the dataset D, and aggregate votes using the learned distribution by setting ?(x) = arg max y Pr(y|P(x)). Our key insight in our aggregation approach is to parametrize Pr(y, P(x)) so that we can capture variations in accuracy as well as dependencies if they exist. The overall procedure of our aggregation is in Algorithm 1. Formally, we model Pr(y, P(x)) as a probabilistic graphical model</p><formula xml:id="formula_4">Procedure 1: AMA Aggregation Method 1: Input: Dataset D = {x i } n i=1 , collection of prompt()-chains P. Output: Predictions {? i } n i=1</formula><p>. 2: Prompt the LLM with P to produce m predictions P(x) per input x ? D, constructing dataset D P ? R n?m . 3: Learn? = (V,?) via structure learning on D P (Algorithm 1 in <ref type="bibr" target="#b14">Varma et al. [2019]</ref>). 4: Learn Pr? ,? (y, P(x)) using D P and? (Algorithm 1 in <ref type="bibr" target="#b29">Ratner et al. [2018]</ref>). 5: Construct aggregator ? WS (P(x)) = arg max y?Y Pr? ,? (y|P(x)). 6: Returns:</p><formula xml:id="formula_5">? AMA = ? WS (x) for all x ? D. with dependency graph G = (V, E), where V = {y, P(x)}. If p i (x)</formula><p>and p j (x) are not conditionally independent given y and the other prompt()-chains, then</p><formula xml:id="formula_6">(p i (x), p j (x)) ? E. E also contains edges (p i (x), y) for each i ? [m].</formula><p>The algorithm uses P(x) and D to first learn the dependency structure? among prompts using the approach from <ref type="bibr" target="#b14">Varma et al. [2019]</ref>. The key insight from that work is that the inverse covariance matrix ? ?1 over y and P(x) is graph-structured, meaning that ? ?1 ij = 0 iff p i (x) and p j (x) are conditionally independent given y. The graph structure means that the inverse covariance over just P(x) decomposes into sparse and low-rank matrices, which can hence be estimated together using RobustPCA <ref type="bibr" target="#b51">[Cand?s et al., 2011]</ref>, and the sparse matrix can be used to recover the graph. Next, the algorithm uses the recovered? along with P(x) and D to learn the accuracies of the prompts with the approach from <ref type="bibr" target="#b29">Ratner et al. [2018]</ref>. The key insight from that work is to use the sparsity of ? ?1 to construct a system of equations set equal to 0 that recover the latent accuracy parameters. Once the parameters of the distribution are learned, we can compute Pr? ,? (y|P(x)) and aggregate our predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Information-Flow Theoretical Result</head><p>In equation 1, we decompose H(y|?) into H(y|P(x)) and H(y|?) ? H(y|P(x)). For AMA, suppose that the weak supervision algorithm exactly recovers Pr(y, P(x)). That is,? AMA is drawn from Pr(?|P(x)). Then, the second term H(y|?) ? H(y|P(x)) can be thought of as an irreducible error corresponding to how much information about y is lost in converting P(x) into an i.i.d. y randomly drawn from Pr(?|P(x)). Since y is more likely to change values when this distribution has high entropy, the second term is correlated with our first term H(y|P(x)), the amount of randomness in Pr(y|P(x)). We thus focus on obtaining an expression for H(y|P(x)) in terms of individual prompt accuracies.</p><p>We assume that Y = {?1, 1}. We model Pr(y, P(x)) as a probabilistic graphical model with dependency graph G = (V, E), where V = {y, P(x)}. The density of Pr(y, P(x)) follows the following Ising model commonly used in weak supervision <ref type="bibr" target="#b13">[Ratner et al., 2017</ref><ref type="bibr" target="#b30">, Fu et al., 2020</ref>:</p><formula xml:id="formula_7">Pr G,? (y, P(x)) = 1 Z exp ? y y + m i=1 ? i p i (x)y + (i,j)?E ? ij p i (x)p j (x) ,<label>(2)</label></formula><p>where Z is the partition function for normalization and {? y ,</p><formula xml:id="formula_8">? i ? i ? [m], ? ij ? (i, j) ? E}.</formula><p>Each ? i can be viewed as the strength of the correlation between y and p i (x), while each ? ij can be viewed as the strength of the dependence between p i (x) and p j (x). We assume that ? y = 0, which corresponds to Pr(y = 1) = 1 2 . We present our expression for H(y|P(x)). Define ? = [? 1 , . . . , ? m ] to be the vector of canonical parameters corresponding to the strength of correlation between y and each p i (x). Define ? = E [p i (x)], which can be written as 2 Pr(p i (x) = y) ? 1, a notion of accuracy scaled to [?1, 1].</p><p>Note that the above form of the distribution is in terms of canonical parameters ?. This distribution can also be parametrized in terms of the mean parameters corresponding to ?, which are</p><formula xml:id="formula_9">E [y] , E [p i (x)y] for i ? [m], and E [p i (x)p j (x)] for (p i (x), p j (x)) ? E.</formula><p>Theorem 1. Assume Pr(y, P(x)) follows equation 2 above. Then, the conditional entropy H(y|P(x)) can be expressed as</p><formula xml:id="formula_10">H(y|P(x)) = H(y) ? ? ? ? E P(x) log cosh ? P(x)<label>(3)</label></formula><p>The quantity being subtracted from H(y) corresponds to the reduction in entropy of y given that we observe P(x). Within this expression, there are two terms. First, ? ? is correlated with how much signal each p i (x) contains about y. Note that this quantity is symmetric-if p i (x) is negatively correlated with y, it still provides information since both ? i and E [p i (x)y] will be negative. The second term, E P(x) log cosh ? P(x) , is for normalization (otherwise, the first term can grow arbitrarily large with ?). Note that this quantity is independent of ? ij , the interactions between prompts.</p><p>Proof. We can write H(y|P(x)) as H(y, P(x)) ? H(P(x)), and H(y, P(x)) as H(P(x)|y) + H(y). Therefore, H(y|P(x)) = H(y) ? H(P(x)) ? H(P(x)|y) . We focus on simplifying H(P(x)) ? H(P(x)|y):</p><formula xml:id="formula_11">H(P(x)) ? H(P(x)|y) = ? P(x)?{?1,1} m Pr(P(x)) log Pr(P(x)) + P(x)?{?1,1} m ,y Pr(y, P(x)) log Pr(P(x)|y) (4) = ? P(x)?{?1,1} m ,y Pr(P(x), y) log Pr(P(x)) ? log Pr(P(x)|y) = ? P(x)?{?1,1} m</formula><p>Pr(P(x), y = ?1) log Pr(P(x)) ? log Pr(P(x)|y = ?1) + Pr(P(x), y = 1) log Pr(P(x)) ? log Pr(P(x)|y = 1) .</p><p>We now write Pr(P(x)), Pr(P(x)|y = ?1) and Pr(P(x)|y = 1) according to our Ising model in equation</p><formula xml:id="formula_12">2. Let A P(x) = m i=1 ? i p i (x), and let B P(x) = (i,j)?E ? ij p i (x)p j (x), so that Pr(y, P(x)) = 1 Z exp(A P(x) y + B P(x) ): Pr(P(x)) = Pr(P(x), y = ?1) + Pr(P(x), y = 1) = 1 Z exp(A P(x) + B P(x) ) + 1 Z exp(?A P(x) + B P(x) )) = 1 Z exp(B P(x) ) exp(A P(x) ) + exp(?A P(x) ) Pr(P(x)|y = ?1) = 2 Pr(P(x), y = ?1) = 2 Z exp(?A P(x) + B P(x) ))</formula><p>Pr(P(x)|y = 1) = 2 Pr(P(x), y = 1) = 2 Z exp(A P(x) + B P(x) )) Therefore, we have that</p><formula xml:id="formula_13">log Pr(P(x)) ? log Pr(P(x)|y = ?1) = ? log Z + B P(x) + log exp(A P(x) ) + exp(?A P(x) ) ? log 2 + log Z + A P(x) ? B P(x) = ? log 2 + A P(x) + log exp(A P(x) ) + exp(?A P(x) ) log Pr(P(x)) ? log Pr(P(x)|y = 1) = ? log Z + B P(x) + log exp(A P(x) ) + exp(?A P(x) ) ? log 2 + log Z ? A P(x) ? B P(x) = ? log 2 ? A P(x) + log exp(A P(x) ) + exp(?A P(x) )</formula><p>Plugging this back into equation 4, we have</p><formula xml:id="formula_14">P(x)?{?1,1} m ,y Pr(P(x), y)A P(x) y ? Pr(P(x)) log exp(A P(x) ) + exp(?A P(x) ) ? log 2 = P(x)?{?1,1} m ,y Pr(P(x), y)A P(x) y ? Pr(P(x)) log cosh A P(x) =E A P(x) y ? E log cosh A P(x) .</formula><p>Substituting in our definitions of ? and ? give us our desired expression for H(y|P(x)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E AMA Diagnostics</head><p>We present a suite of 8 diagnostic tasks, which can be categorized into four task types: question generation, answer generation, answer selection and extraction. We provided details about the tasks and scoring below.</p><p>Question Generation: We measure the ability of the model to transform a statement to a question. We construct 3 question generation tasks which evaluate the models ability to transform a statement to a yes/no question (see Question Generation (Yes/No)), transform a statement to a whquestion (see Question Generation (wh-)) and finally, transform a statement about a placeholder entity to a question about the placeholder (see Question Generation (@placeholder)). All question generation tasks are scored using the ROUGE score <ref type="bibr" target="#b52">[Lin, 2004]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output</head><p>Where does most of the light come from ?</p><p>Answer Selection:</p><p>We construct 2 answer selection tasks which measure the model's ability to generate an answer that is faithful to a set of provided answer choices. Concretely, we measure the models ability to select object categories from a fixed set of options specified in the context (see Answer Selection <ref type="formula">(category)</ref>). Further, we measure the model's ability to complete a sentence when provided with a context and set of sentence completion candidates (see Answer Selection (completion)). In both tasks, an answer is marked as correct if the generated response is one of the candidates provided in the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer Selection (category)</head><p>Input Select the correct category .</p><p>" The passage " Passage " states : Microsoft Corporation sells : " Choice ":.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output consumer electronics</head><p>Answer Generation:</p><p>We construct 1 answer generation task which measures the model's ability to generate candidate sentence completions given a context and portion of a statement (see Answer Generation). Here, a generated answer is marked as correct if the model generates 2 candidate answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer Generation</head><p>Input Output a list of unique alternatives for each example .</p><p>Example : Barrack Obama believes the :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>List alternatives : -best novel is Harry Potter</head><p>Output -worst book is Harry Potter -United States is great Extraction: We construct 2 extraction tasks which evaluate the ability of the model to extract spans from a given context. The first, and easier task, tests the model's ability to extract an attribute value from a wikibio (see Extraction (Span)). The second, more difficult task, tests the model's ability to extract the sentence from the context that mentions a specified entity (see Extraction <ref type="formula">(Sentence)</ref> Output Caracas , Venezuela ( CNN ) --It ' s been more than 180 years since Venezuelans saw Simon Bolivar ' s face .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Error Analysis</head><p>We bucket the common error modes of AMA into three categories: knowledge, instruction-following, and longcontext.</p><p>Knowledge errors. We find that AMA yields the most gains when the knowledge required to complete the task is explicitly provided in the context (e.g., reading comprehension, extractive QA), which is in line with the trends in <ref type="figure">Figure  6</ref>. We find that AMA provides comparatively less lift on tasks where the model needs to (1) recall encoded factual knowledge or (2) apply common-sense / real-world knowledge to a given context. We provide concrete examples from the Natural Questions dataset (see Knowledge (Factual) below) in which the GPT-J-6B model wrongly answers the question due to a lack of latent factual knowledge. We additionally provide case-examples from the BoolQ dataset where the model's limited real-world knowledge limits its ability to correctly answer the questions where the model's failure to recognize that food that is smoked is cooked, leads it to incorrectly answer the question (see Knowledge (Commonsense) below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge (Factual)</head><p>Input <ref type="figure">Figure 6</ref>: Relative performance gain observed when scaling from GPT3-6.7B to GPT3-175B. Results are directly from  and are categorized by type of knowledge required for the task.</p><p>Question : what ' s the dog ' s name on tom and jerry Answer :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction</head><p>The dog ' s name is " Fido "</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ground Truth</head><p>Spike Knowledge (Commonsense)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>Passage : A Philadelphia roll is a makizushi ( also classified as a kawarizushi ) type of sushi generally made with smoked salmon , cream cheese , and cucumber . It can also include other ingredients , such as other types of fish , avocado , scallions , and sesame seed . Question : is the salmon cooked in a philadelphia roll Answer :</p><p>Prediction false Ground Truth true Instruction-following errors. We find that on tasks with more restrictive output spaces (e.g., multi-way classification tasks), a common failure mode is to generate an answer that is not in the desired output space of the AMA prompt, despite being explicitly prompted to do so. In Listing 3 and 4, we provide sample instances from the DBPedia classification task where GPT-J-6B does not correctly map a descriptive adjective (e.g., automobile or singer) to a valid class specified in the prompt. was an original member of the American singing girl group the Chiffons .</p><p>Summary : This passage is about a singer .</p><p>The summary " Summary " fits " Category ":</p><p>Prediction singer Ground Truth artist Long-context errors. We find that the AMA question() functions struggle to generate accurate statement-question transformations when the input is long or contains complex sentence structures (e.g. compound sentences). We provide sample instances from the SuperGLUE record task where GPT-J-6B fails to transform a sentence with a placeholder subject to a question about the placeholder subject (see Long-context (question()) below). Additionally, we find that the AMA answer() functions struggle to extract the correct span in long contexts (greater than 6 sentences). We show a sample instance from the DROP QA task where GPT-J-6B fails to extract the correct span from the long provided context (see Long-context (answer()) below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Long-context (question())</head><p>Input </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ground Truth</head><p>Who ' s wrath could be felt around noon on Wednesday ?</p><p>Long-context (answer())</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>Context : Looking to avoid back -to -back divisional losses , the Patriots traveled to Miami to face the 6 -4 Dolphins at Dolphin Stadium . After Carpenter ' s kickoff was returned from the 29 -yard line by Matthew Slater , the Patriots began their first possession at their own 40 -yard line . Cassel ' s first two passes were both completed for first downs , putting the Patriots in Dolphins territory and eventually their red zone . However , a holding penalty on Neal pushed the Patriots back 10 yards , forcing a 30 -yard Gostkowski field goal four plays later that gave the Patriots a 3 -0 lead . Following a Dolphins three -and -out , the Patriots ' second drive ended when a Cassel pass to Moss was bobbled by both Moss and cornerback Jason Allen to keep the ball in the air until Renaldo Hill intercepted it ; a 17 -yard return gave the Dolphins the ball at the Patriots ' 42 -yard line . On the next play , a 29 -yard David Martin reception moved the Dolphins into the Patriots ' red zone , where the Dolphins used their " Wildcat " formation on the next two plays ....</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question : Which team scored first ?</head><p>Prediction Patriots</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ground Truth</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dolphins</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Datasets and Prompts</head><p>We evaluate over 20 datasets which fall into 4 categories: SuperGLUE (BoolQ <ref type="bibr" target="#b54">[Clark et al., 2019]</ref>, <ref type="bibr">CB [De Marneffe et al., 2019]</ref>, <ref type="bibr">COPA [Roemmele et al., 2011</ref><ref type="bibr">], MultiRC [Khashabi et al., 2018</ref>, ReCoRD <ref type="bibr">[Zhang et al., 2018]</ref>, RTE , <ref type="bibr">WiC [Pilehvar and Camacho-Collados, 2018]</ref>, <ref type="bibr">WSC [Levesque et al., 2012]</ref>), NLI (ANLI R1, ANLI R2, ANLI R3 <ref type="bibr" target="#b38">[Nie et al., 2020]</ref>, StoryCloze <ref type="bibr" target="#b37">[Mostafazadeh et al., 2017]</ref>), Classification (DBPedia <ref type="bibr" target="#b33">[Zhang et al., 2015]</ref>, AGNews <ref type="bibr" target="#b33">[Zhang et al., 2015]</ref>, SST2 <ref type="bibr" target="#b39">[Socher et al., 2013]</ref>, Amazon <ref type="bibr" target="#b40">[He and McAuley, 2016]</ref>), and Question-Answering (RealTimeQA <ref type="bibr" target="#b41">[Kasai et al., 2022]</ref>, DROP <ref type="bibr" target="#b44">[Dua et al., 2019]</ref>, Natural Questions , WebQuestions <ref type="bibr" target="#b43">[Berant et al., 2013]</ref>). We provide dataset details along with few shot and AMA prompts for the dataset below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1 AGNews</head><p>Description: News article classification dataset with 4 topics. <ref type="bibr" target="#b33">Zhang et al. [2015]</ref> Train Size: 120000, Test Size: 76000</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AGNews Few Shot</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>Pick the correct category for the passage . SPACE . com -TORONTO , Canada --A second team of rocketeers competing for the #36;10 million Ansari X Prize , a contest for privately funded suborbital space flight , has officially announced the first launch date for its manned rocket . Category : SPACE . com -TORONTO , Canada --A second team of rocketeers competing for the #36;10 million Ansari X Prize , a contest for privately funded suborbital space flight , has officially announced the first launch date for its manned rocket . Summarize : the passage " Passage ":</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Categories</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gold Output</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Output</head><p>The passage is about a rocket .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>answer()</head><p>Pick the correct category for the passage . SPACE . com -TORONTO , Canada --A second team of rocketeers competing for the #36;10 million Ansari X Prize , a contest for privately funded suborbital space flight , has officially announced the first launch date for its manned rocket . Summary : The passage is about a rocket . The summary " Summary " fits " Category ": Fragaria x vescana is a hybrid strawberry cultivar that was created in an effort to combine the best traits of the garden strawberry (" Fragaria " x " ananassa ") , which has large berries and vigorous plants , with the woodland strawberry (" Fragaria vesca ") , which has an exquisite flavour , but small berries . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gold</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Output</head><p>Is there information indicating whether Daniel Zolnikov is a good legislator ?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>answer()</head><p>Answer the question . If there is no evidence in the context , return " Unknown ".</p><p>Context : According to Biraben , the plague was present somewhere in Italy and affected 1 ,200 people . Question : Based on the context , Did the plague affect people in Europe ? Answer : yes , people in Italy , Europe Context : Policies aiming at controlling unemployment and in particular at reducing its inequality -associated effects support economic growth . Question : Based on the context , Is confidence a factor in increasing self -esteem ? Answer : unknown Context : The term " matter " is used throughout physics in a bewildering variety of contexts : for example , one refers to " condensed matter physics " , " elementary matter " , " partonic " matter , " dark " matter , " anti " -matter , " strange " matter , and " nuclear " matter . Context : Policies aiming at controlling unemployment and in particular at reducing its inequality -associated effects support economic growth . Question : Based on the context , Is confidence a factor in increasing self -esteem ? Answer : unknown Context : The term " matter " is used throughout physics in a bewildering variety of contexts : for example , one refers to " condensed matter physics " , " elementary matter " , " partonic " matter , " dark " matter , " anti " -matter , " strange " matter , and " nuclear " matter . Question : Based on the context , Is anti -matter made of electrons ? Answer : Unknown</p><p>Context : There is a little Shia community in El Salvador . There is an Islamic Library operated by the Shia community , named " Fatimah Az -Zahra ". They published the first Islamic magazine in Central America : " Revista Biblioteca Islamica ". Additionally , they are credited with providing the first and only Islamic library dedicated to spreading Islamic culture in the country . Question : Based on the context , Is the community south of the United States ? Answer : Statement : This headline leads to more information that is behind a paywall . Question :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Output</head><p>Does this headline lead to more information that is behind a paywall ?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>answer()</head><p>Answer the question . If there is no evidence in the context , return " Unknown ".</p><p>Context : According to Biraben , the plague was present somewhere in Italy and affected 1 ,200 people . Question : Based on the context , Did the plague affect people in Europe ? Answer : yes , people in Italy , Europe Context : Policies aiming at controlling unemployment and in particular at reducing its inequality -associated effects support economic growth . Question : Based on the context , Is confidence a factor in increasing self -esteem ? Answer : unknown Context : The term " matter " is used throughout physics in a bewildering variety of contexts : for example , one refers to " condensed matter physics " , " elementary matter " , " partonic " matter , " dark " matter , " anti " -matter , " strange " matter , and " nuclear " matter . Context : Drinking in public --Drinking in public is legal in England and Wales --one may carry a drink from a public house down the street ( though it is preferred that the user requests a plastic glass to avoid danger of breakage and because the taking of the glass could be considered an offence of Theft as only the drink has been purchased ) , and one may purchase alcohol at an off -licence and immediately begin drinking it outside . Separately , one may drink on aeroplanes and on most National Rail train services , either purchasing alcohol onboard or consuming one ' s own . Question : is it legal to drink in public in london Answer : Yes Context : Harry Potter and the Escape from Gringotts --Harry Potter and the Escape from Gringotts is an indoor steel roller coaster at Universal Studios Florida , a theme park located within the Universal Orlando Resort . Similar to dark rides , the roller coaster utilizes special effects in a controlled -lighting environment and also employs motion -based 3 -D projection of both animation and live -action sequences to enhance the experience . The ride , which is themed to the Gringotts Wizarding Bank , became the flagship attraction for the expanded Wizarding World of Harry Potter when it opened on July 8 , 2014. Question : is harry potter and the escape from gringotts a roller coaster ride ? True or False ? Answer : Context : Tonic water --Tonic water ( or Indian tonic water ) is a carbonated soft drink in which quinine is dissolved . Originally used as a prophylactic against malaria , tonic water usually now has a significantly lower quinine content and is consumed for its distinctive bitter flavor . It is often used in mixed drinks , particularly in gin and tonic . Question : does tonic water still have quinine in it ? Answer : yes Context : Northern bobwhite --The northern bobwhite , Virginia quail or ( in its home range ) bobwhite quail ( Colinus virginianus ) is a ground -dwelling bird native to the United States , Mexico , and the Caribbean . It is a member of the group of species known as New World quails ( Odontopho ridae ) . They were initially placed with the Old World quails in the pheasant family ( Phasianidae ) , but are not particularly closely related . The name '' bobwhite ' ' derives from its charac terist ic whistling call . Despite its secretive nature , the northern bobwhite is one of the most familiar quails in eastern North America because it is frequently the only quail in its range . Habitat degradation has likely contributed to the northern bobwhite population in eastern North America declining by roughly 85% from 1966 -2014. This population decline is apparently range -wide and continuing . Question : is a quail the same as a bobwhite ? Answer : yes Context : United States Department of Homeland Security --In fiscal year 2017 , it was allocated a net discretionary budget of $40 .6 billion . With more than 240 ,000 employees , DHS is the third largest Cabinet department , after the Departments of Defense and Veterans Affairs . Homeland security policy is coordinated at the White House by the Homeland Security Council .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gold Output</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other agencies with significant homeland security r e s p o n s i b i l i t i e s include the Departments of</head><p>Health and Human Services , Justice , and Energy Question : is department of homeland security part of dod ? Answer : no Context : Harry Potter and the Escape from Gringotts --Harry Potter and the Escape from Gringotts is an indoor steel roller coaster at Universal Studios Florida , a theme park located within the Universal Orlando Resort . Similar to dark rides , the roller coaster utilizes special effects in a controlled -lighting environment and also employs motion -based 3 -D projection of both animation and live -action sequences to enhance the experience . The ride , which is themed to the Gringotts Wizarding Bank , became the flagship attraction for the expanded Wizarding World of Harry Potter when it opened on July 8 , 2014. Question : is harry potter and the escape from gringotts a roller coaster ride ? Answer :</p><p>Model Output true G.7 CB Description: Three-class textual entailement task.  Train Size: 250, Test Size: 56</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CB Few Shot</head><p>Input B : Now see I . A : I ' m intrigued by it , but I ' m not sure I want to go see it yet . B : Yeah , I don ' t think I want to see that either . Question : she wants to see that True , False , or Neither ? False A : Yeah . The radio doesn ' t really have much news sometimes . The stations I listen to are just mainly music . B : Yeah , I think you pretty much have to listen to all news station to get any news at all . A : Yeah . Do you think that TV is , uh , pretty accurate . Question : TV is pretty accurate True , False , or Neither ? Neither It is part of their religion , a religion I do not scoff at as it holds many elements which match our own even though it lacks the truth of ours . At one of their great festivals they have the ritual of driving out the devils from their bodies . First the drummers come on -I may say that no women are allowed to take part in this ritual and the ladies here will perhaps agree with me that they are fortunate in that omission . Question : no women are allowed to take part in this ritual True , False , or Neither ? True Modify the arachnids , said the researchers . Change their bodies and conditions , and you could get fibres like glass , still monofilament , but with logarithmic progressions of possibilities of strength and flexibility , and the ability to resonate light -particles or sound -waves undistorted , scarcely weakened over thousands of miles . Who said the arachnids had to be totally organic ? Question : arachnids had to be totally organic . True , False , or Neither ? </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gold Output</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Output</head><p>Did arachnids have to be totally organic ?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>answer()</head><p>Provide the answer to the question from the passage .</p><p>Passage : When Judy and Jack went to school , they got in trouble with their teacher for being late . I didn ' t think it was very fair . Question : Did she think it was fair ? Answer : No Passage : If inflation is occurring , leading to higher prices for basic necessities such as gas by 2 dollars . Do you think that inflation is good for society ? Question : Is inflation good for society ? Answer : Maybe Passage : Put yourself out there . The more time you spend dating and socializing , the more likely you will find a boyfriend you like . Question : Does socializing help you find a boyfriend ? Answer : Yes Passage : Modify the arachnids , said the researchers . Change their bodies and conditions , and you could get fibres like glass , still monofilament , but with logarithmic progressions of possibilities of strength and flexibility , and the ability to resonate light -particles or sound -waves undistorted , scarcely weakened over thousands of miles . Who said the arachnids had to be totally organic ? Question : Did arachnids have to be totally organic ? Answer :</p><p>Gold Output false G.8 COPA Description: Casual reasoning dataset where task is to select the alternative that more plausibly has a causal relation with the premise.  Train Size: 400, Test Size: 100</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COPA Few Shot</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>Pick the more likely continuation to the following sentence .</p><p>Context : The truck crashed into the motorcycle on the bridge so The motorcyclist died .</p><p>Context : The customer came into the boutique because The window display caught her eye .</p><p>Context : The print on the brochure was tiny so The man put his glasses on .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context : The</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Choices</head><p>-woman became famous so -photographers followed her Question : ( because ' she took medicine ' , because ' she got expelled ') My roommate was feeling better because ? Answer : ' she took medicine ' Question : ( because ' he does not practice ' , because ' he is fast ') Matt is not good at soccer because ? Answer : ' he does not practice ' Question : ( because ' she was smart ' , because ' she never did her homework ') The girl went to college and graduated with honors because ? Answer : ' she was smart ' Question : ( and so ' her family avoided her . ' , and so ' photographers followed her . ') The woman became famous and so ? Answer :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Choices</head><p>-woman became famous so -photographers followed her  Passage : TY KU -TY KU is an American alcoholic beverage company that specializes in sake and other spirits . The privately -held company was founded in 2004 and is headquartered in New York City New York . While based in New York TY KU ' s beverages are made in Japan through a joint venture with two sake breweries . Since 2011 TY KU ' s growth has extended its products into all 50 states . Summarize : the passage " Passage ":</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Output</head><p>The passage is about a company .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>answer()</head><p>Pick one category for the following text . Description: A reading comprehension benchmark requiring discrete reasoning over paragraphs. <ref type="bibr" target="#b44">Dua et al. [2019]</ref> Train Size: 77409, Test Size: 9536</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DROP Few Shot</head><p>Input Passage : As of the 2010 United States Census , there were 16 ,589 people , 6 ,548 households , and 4 ,643 families residing in the county . The population density was . There were 7 ,849 housing units at an average density of . The racial makeup of the county was 96.8% white , 0.7% black or African American , 0.6% American Indian , 0.2% Asian , 0.2% from other races , and 1.5% from two or more races . Those of Hispanic or Latino origin made up 0.6% of the population . In terms of ancestry , 23.4% were Germans , 22.3% were Americans , 13.6% were Irish people , and 11.0% were English people . Question : How many percent of people were not Asian ? Answer : unknown Passage : The health sector comprises 17 specialized hospitals and centers , 4 regional diagnostic and treatment centers , 9 district and 21 aimag general hospitals , 323 soum hospitals , 18 feldsher posts , 233 family group practices , 536 private hospitals , and 57 drug supply companies / pharmacies . In 2002 , the total number of health workers was 33 ,273 , of whom 6823 were doctors , 788 pharmacists , 7802 nurses , and 14 ,091 mid -level personnel . At present , there are 27.7 physicians and 75.7 hospital beds per 10 ,000 inhabitants . Question : What profession had more health workers , doctors or nurses ? Answer : nurses Passage : The exact number of peasant deaths is unknown , and even the course of events are not clear , because the government , to hide the size of the massacre , ordered the destruction of all documents relating to the uprising . Historian Markus Bauer mentions a greatly underesti mated official figure of 419 deaths , while an unofficial figure , circulated by the press and widely accepted , of about 10 ,000 peasants killed , has never been proven to be true . The same figure of 419 deaths was mentioned by Ion I . C . Bratianu in the Romanian Parliament . The data available to the Prime Minister Dimitrie Sturdza indicated 421 deaths between 28 March and 5 April 1907. Likewise , about 112 were injured and 1 ,751 detained . Newspapers patronized by Constantin Mille , Adevarul and Dimineata , gave a figure of 12 ,000 -13 ,000 victims . In a conversation with the British ambassador in Bucharest , King Carol I mentioned a figure of " several thousand ". According to figures given by Austrian diplomats , between 3 ,000 -5 ,000 peasants were killed , while the French Embassy mentioned a death toll ranging between 10 ,000 -20 ,000. Historians put the figures between 3 ,000 -18 ,000 , the most common being 11 ,000 victims . Question : Which organizations said the death toll to be beyond 10 ,000? Answer : Newspapers patronized by Constantin Mille Passage : Still searching for their first win , the Bengals flew to Texas Stadium for a Week 5</p><p>inter c on f er en c e duel with the Dallas Cowboys . In the first quarter , Cincinnati trailed early as Cowboys kicker Nick Folk got a 30 -yard field goal , along with RB Felix Jones getting a 33yard TD run . In the second quarter , Dallas increased its lead as QB Tony Romo completed a 4yard TD pass to TE Jason Witten . The Bengals would end the half with kicker Shayne Graham getting a 41 -yard and a 31 -yard field goal . In the third quarter , Cincinnati tried to rally as QB Carson Palmer completed an 18 -yard TD pass to WR T . J . Hou shmand zadeh . In the fourth quarter , the Bengals got closer as Graham got a 40 -yard field goal , yet the Cowboys answered with Romo completing a 57 -yard TD pass to WR Terrell Owens . Cincinnati tried to come back as Palmer completed a 10 -yard TD pass to H oushma ndzade h ( with a failed 2 -point conversion ) , but Dallas pulled away with Romo completing a 15 -yard TD pass to WR Patrick Crayton . Question : Which team scored the final TD of the game ? Answer :</p><p>Gold Output dallas DROP AMA prompt()-chain Example answer() Context : According to Biraben , the plague was present somewhere in Europe in every year between 1346 and 1671 Question : Where was the plague present ? Answer : somewhere in Europe Context : Policies aiming at controlling unemployment and in particular at reducing its inequality -associated effects support economic growth . Question : What ' s one factor in increasing self -esteem ? Answer : Unknown Context : The term " matter " is used throughout physics in a bewildering variety of contexts : for example , one refers to " condensed matter physics " , " elementary matter " , " partonic " matter , " dark " matter , " anti " -matter , " strange " matter , and " nuclear " matter . Question : What is another name for anti -matter ? Answer : Unknown Context : Still searching for their first win , the Bengals flew to Texas Stadium for a Week 5</p><p>inter c on f er en c e duel with the Dallas Cowboys . In the first quarter , Cincinnati trailed early as Cowboys kicker Nick Folk got a 30 -yard field goal , along with RB Felix Jones getting a 33yard TD run . In the second quarter , Dallas increased its lead as QB Tony Romo completed a 4yard TD pass to TE Jason Witten . The Bengals would end the half with kicker Shayne Graham getting a 41 -yard and a 31 -yard field goal . In the third quarter , Cincinnati tried to rally as QB Carson Palmer completed an 18 -yard TD pass to WR T . J . Hou shmand zadeh . In the fourth quarter , the Bengals got closer as Graham got a 40 -yard field goal , yet the Cowboys answered with Romo completing a 57 -yard TD pass to WR Terrell Owens . Cincinnati tried to come back as Palmer completed a 10 -yard TD pass to H oushma ndzade h ( with a failed 2 -point conversion ) , but Dallas pulled away with Romo completing a 15 -yard TD pass to WR Patrick Crayton . Question : Which team scored the final TD of the game ? Answer :</p><p>Model Output dallas G.11 MultiRC Description: Multi-sentence reading comprehension dataset.  Train Size: 27243, Test Size: 953</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MultiRC Few Shot</head><p>Input Passage : While this process moved along , diplomacy continued its rounds . Direct pressure on the Taliban had proved unsuccessful . As one NSC staff note put it , " Under the Taliban , Afghanistan is not so much a state sponsor of terrorism as it is a state sponsored by terrorists ." In early 2000 , the United States began a high -level effort to persuade Pakistan to use its influence over the Taliban . In January 2000 , Assistant Secretary of State Karl Inderfurth and the State Department ' s c o u n t e r t e r r o r i s m coordinator , Michael Sheehan , met with General Musharraf in Islamabad , dangling before him the possibility of a presidential visit in March as a reward for Pakistani cooperation . Such a visit was coveted by Musharraf , partly as a sign of his government ' s legitimacy . He told the two envoys that he would meet with Mullah Omar and press him on Bin Laden . They left , however , reporting to Washington that Pakistan was unlikely in fact to do anything ," given what it sees as the benefits of Taliban control of Afghanistan ." President Clinton was scheduled to travel to India . The State Department felt that he should not visit India without also visiting Pakistan .... Question : Based on the previous passage , What did President Clinton ' s visit with Pakistan include ? Is " Discussing Bin Laden " a correct answer ? Answer : Yes Passage : While this process moved along , diplomacy continued its rounds . Direct pressure on the Taliban had proved unsuccessful . As one NSC staff note put it , " Under the Taliban , Afghanistan is not so much a state sponsor of terrorism as it is a state sponsored by terrorists ." In early 2000 , the United States began a high -level effort to persuade Pakistan to use its influence over the <ref type="table">Taliban</ref>  Passage : The Agencies Confer When they learned a second plane had struck the World Trade Center , nearly everyone in the White House told us , they immediately knew it was not an accident . The Secret Service initiated a number of security enhancements around the White House complex . The officials who issued these orders did not know that there were additional hijacked aircraft , or that one such aircraft was en route to Washington . These measures were precautionary steps taken because of the strikes in New York . The FAA and White House Teleco nf e re nc e s . The FAA , the White House , and the Defense Department each initiated a multiagency tele confer ence before 9:30. Because none of these teleconferences -at least before 10:00 -included ... Question : Based on the previous passage , To what did the CIA and FAA begin participating in at 9:40? Is " Coffee hour " a correct answer ? Answer : No Passage : What causes a change in motion ? The application of a force . Any time an object changes motion , a force has been applied . In what ways can this happen ? Force can cause an object at rest to start moving . Forces can cause objects to speed up or slow down . Forces can cause a moving object to stop . Forces can also cause a change in direction . In short , forces cause changes in motion . The moving object may change its speed , its direction , or both . We know that changes in motion require a force . We know that the size of the force determines the change in motion . How much an objects motion changes when a force is applied depends on two things . It depends on the strength of the force . It also depends on the objects mass . Think about some simple tasks you may regularly do . You may pick up a baseball . This requires only a very small force . Question : Based on the previous passage , Would the mass of a baseball affect how much force you have to use to pick it up ? Is " Yes " a correct answer ? Answer :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gold Output yes</head><p>MultiRC AMA prompt()-chain Example Passage : Sara wanted to play on a baseball team . She had never tried to swing a bat and hit a baseball before . Her Dad gave her a bat and together they went to the park to practice . Sara wondered if she could hit a ball . She wasn ' t sure if she would be any good . She really wanted to play on a team and wear a real uniform . She couldn ' t wait to get to the park and test out her bat . When Sara and her Dad reached the park , Sara grabbed the bat and stood a few steps away from her Dad . Sara waited as her Dad pitched the ball to her . Her heart was beating fast . She missed the first few pitches . She felt like quitting but kept trying . Soon she was hitting the ball very far . She was very happy and she couldn ' t wait to sign up for a real team . Her Dad was very proud of her for not giving up . Question : Based on the previous passage , Who pitched the ball to Sara and where did it occur ? Is " Her dad did in the park " a correct answer ? Answer : yes Passage : The Vice President stated that he called the President to discuss the rules of engagement for the CAP . He recalled feeling that it did no good to establish the CAP unless the pilots had instructions on whether they were authorized to shoot if the plane would not divert . He said the President signed off on that concept . The President said he remembered such a conversation , and that it reminded him of when he had been an interceptor pilot . The President emphasized to us that he had authorized the shootdown of hijacked aircraft . The Vice President ' s military aide told us he believed the Vice President spoke to the President just after entering the conference room , but he did not hear what they said . Rice , who entered the room shortly after the Vice President and sat next to him , remembered hearing him inform the President , " Sir , the CAPs are up . Sir , they ' re going to want to know what to do ." Then she recalled hearing him say , " Yes sir ." She believed ... Question : Based on the previous passage , Why was the Secret Service ' s information about United 93 flawed ? Is " The Secret Service Didn ' t have access to FAA information " a correct answer ? Answer : no Passage : Patricia Cross and her boyfriend Larry Osborne , two students in a San Francisco school , become expelled for the publication of an off -campus underground paper . As a result , a philosophy professor , Dr . Jonathon Barnett , resigns his teaching position and decides to become an advocate for the c ounter cultur e youth movement and , specifically , the use of LSD . The hippies of the Haight -Ashbury district first see him as a hero and then as something even more . Dr . Barnett even makes an appearance on the Joe Pyne TV show to voice his support of the hippie community and the use of LSD . One scheming young man sees the opportunity to build Dr . Barnett as the head of a cult centered around the use of LSD . He hopes to earn profit from the users , Dr . Barnett ' s speeches known as '' happenings , '' and their lifestyles . At a massive LSD -fueled dance , Patricia begins to have a bad trip Which leads to an argument between her and Pat , ultimately splitting the couple up ... Question : Based on the previous passage , Why did Dr . Barnett resign from teaching ? Is " Patricia expulsion " a correct answer ? Answer : yes Passage : I wondered if that were my case --if I rode out for honour , and not for the pure pleasure of the riding . And I marvelled more to see the two of us , both lovers of one lady and eager rivals , burying for the nonce our feuds , and with the same hope serving the same cause . We slept the night at Aird ' s store , and early the next morning found Ringan . A new Ringan indeed , as unlike the buccaneer I knew as he was unlike the Quaker . He was now the gentleman of Breadalbane , dressed for the part with all the care of an exquisite . He rode a noble roan , in his Spanish ... Question : Based on the previous passage , Who is described as both buccaneer and cavalier ? Is " Quaker " a correct answer ? Answer : no Passage : What causes a change in motion ? The application of a force . Any time an object changes motion , a force has been applied . In what ways can this happen ? Force can cause an object at rest to start moving . Forces can cause objects to speed up or slow down . Forces can cause a moving object to stop . Forces can also cause a change in direction . In short , forces cause changes in motion . The moving object may change its speed , its direction , or both . We know that changes in motion require a force . We know that the size of the force determines the change in motion . How much an objects motion changes when a force is applied depends on two things . It depends on the strength of the force . It also depends on the objects mass . Think about some simple tasks you may regularly do . You may pick up a baseball . This requires only a very small force . Question : Based on the previous passage , Would the mass of a baseball affect how much force you have to use to pick it up ? Is " Yes " a correct answer ? Answer :  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Output</head><p>Were security forces on high alert after a campaign marred by violence ?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>answer()</head><p>Answer the question . If there is no evidence in the context , return " Unknown ".</p><p>Context : Jenna ' s 10 th birthday was yesterday evening and at least 10 of her friends attended the party . Question : Did 10 friends attend Jenna ' s party ? Answer : Unknown , at least 10 Context : The bullies attacked John when he was walking through the elementary school parking lot and then got sent to the teacher ' s office . Question : Did the bullies attack John in the teacher ' s office ? Answer : No , parking lot Context : WISS discovered a new monkey disease in a remote tribe in the Amazon rainforrest last</p><p>week . It was highly contagious . Question : Did WISS discover a new disease ? Answer : Yes , new monkey disease Context : Security forces were on high alert after an election campaign in which more than 1 ,000 people , including seven election candidates , have been killed . Question : Were security forces on high alert after a campaign marred by violence ? Answer : Context : Garita Palmera , El Salvador ( CNN ) --She talks to the pictures as if they could make her voice travel thousands of miles and reach her son ' s ears . " Oh , my son ," Julia Alvarenga , 59 , says in a tender voice at her home in this coastal town . And then she says , "I ' m going to see him again ." The past two weeks have been an emotional roller coaster for the Salvadoran woman . First , she learned her son had been missing for 13 months . Then she was told he had turned up half a world away . And now she ' s getting news he might be back home soon .. It ' s been an emotional time for the parents of castaway Jose Salvador Alvarenga . His mother , Julia , said her son didn ' t keep up , and they didn ' t even know he was missing . " I would pray to God , and I won ' t lie to you , I was crying ," she says . For the excited residents of his town in El Salvador , Alvarenga is a hero Answer : Even though their son has yet to return home , he ' s already a celebrity in Garita Palmera and neighboring towns .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gold Output</head><p>Context : ( CNN ) --Members of a well -known hacking group --according to a statement and Twitter messages --took credit Sunday for an online attack targeting San Francisco ' s embattled transit system . Anonymous --in a news release attributed to the group , and backed up by related Twitter pages --said it would take down the website of the Bay Area Rapid Transit System , known as BART , between noon and 6 p . m . PT Sunday . This is in response to the system ' s decision to cut off cellphone signals at " select " subway stations in response to a planned protest last week . " By ( cutting cell service ) , you have not only threatened your citizens ' safety , you have also performed an act of censorship ," a seemingly computer -generated voice --speaking over dramatic music and images --said in a video posted online Sunday afternoon .</p><p>" By doing this , you have angered Anonymous .". NEW : A video urges protesters Monday to wear red shirts and record the event . Statements attributed to Anonymous promised an online attack Sunday on BART .</p><p>MyBART . gov appears Sunday to have been hacked . The system said it was prepared for hacks , as well as a planned protest Monday Answer : " We ' re doing what we can to defend against any attack on the BART website ," the system said ..</p><p>Context : Tracy Morgan hasn ' t appeared on stage since the devastating New Jersey crash that nearly ended his life last summer , but all that will change this fall when he returns to host Saturday Night Live . NBC announced on Twitter Monday that Morgan , an SNL alum with seven seasons as a cast member under his belt , will headline the third episode of Season 41 airing October 17. For Morgan , 46 , it will be a second time hosting the long -running variety show , the first since the June 2014 pileup on the New Jersey Turnpike that killed his friend and mentor James ' Jimmy Mack ' McNair .. Morgan , 46 , will host third episode of season 41 of SNL airing October 17. He tweeted to his fans : ' Stoked to be going home ...# SNL '. For the SNL alum who had spent seven years as cast member , it will be a second time hosting the show . Morgan has been sidelined by severe head trauma suffered in deadly June 2014 crash on New Jersey Turnpike that killed his friend . First episode of new SNL season will be hosted by Miley Cyrus , followed by Amy Schumer Answer : ' On October 10 , acclaimed comedian and star of the summer box office hit Trainwreck Amy Schumer will make her SNL debut , followed by cable clutter and waste , European regulators say that Apple and other smartphone makers will be required to support a single common charging standard for all mobile devices as early as the fall of 2024. But Apple hates the idea ( shocker ) because that means about a billion devices will become obsolete . Article : 5 things to know for March 11: Ukraine , Pandemic , MLB , North ... If your day doesn ' t start until you ' re up to speed on the latest headlines , then let us introduce you to your new favorite morning fix . Sign up here for the '5 Things ' newsletter . ( CNN ) America , the " land of the free ," is getting quite costly . Prices for gas , food and housing --which are all necessary expenses --are spiking across the country . Gas prices have risen 38% over the past year , and rising prices in pandemic -related sectors , such as travel and dining , are also expected as the US recovers from the Omicron wave of Covid -19. Here ' s what you need to know to Get Up to Speed and On with Your Day . Article : Wi -Charge / consists of a transmitter and a receiver . Transmitter connects to a standard power outlet and converts electricity into infrared laser beam . Receivers use a miniature photo -voltaic cell to convert transmitted light into electrical power . Receivers can be embedded into a device or connected into an existing charging port . The transmitter automatically identifies chargeable receivers and start charging . Several devices can charge at the same time . According to Wi -Charge it can deliver several watts of power to a device at several meters away . The core technology is based on a " distributed laser resonator " which is formed by the re tr o re fl e ct or s within the Article : Mobile broadband / added in 2005. CDPD , CDMA2000 EV -DO , and MBWA are no longer being actively developed . In 2011 , 90% of the world ' s population lived in areas with 2 G coverage , while 45% lived in areas with 2 G and 3 G coverage , and 5% lived in areas with 4 G coverage . By 2017 more than 90% of the world ' s population is expected to have 2 G coverage , 85% is expected to have 3 G coverage , and 50% will have 4 G coverage . A barrier to mobile broadband use is the coverage provided by the mobile service networks . This may mean no mobile network or that service is limited to Article : Mobile edge computing / Combining elements of information technology and t el e c o m m u n i c a t i o n s networking , MEC also allows cellular operators to open their radio access network ( RAN ) to authorized third -parties , such as application developers and content providers . Technical standards for MEC are being developed by the European T e l e c o m m u n i c a t i o ns Standards Institute , which has produced a technical white paper about the concept . MEC provides a distributed computing environment for application and service hosting . It also has the ability to store and process content in close proximity to cellular subscribers , for faster response time . Applications can also be exposed to real -time radio access network ( RAN ) information . The key element is Question : To help reduce cable clutter and waste , which continent will soon require Apple and other smartphone makers to support a single common charging standard for all mobile devices ? Answer : </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>For each snippet of text , label the sentiment of the text as positive or negative .</p><p>Text : in terms of execution this movie is careless and unfocused . Sentiment : negative Text : ... a pretentious and ultimately empty examination of a sick and evil woman . Sentiment : negative</p><p>Text : the film 's plot may be shallow , but you ' ve never seen the deep like you see it in these harrowing surf shots . Sentiment : positive Text : a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid creme brulee . Sentiment :</p><p>Gold Output negative SST2 AMA prompt()-chain Example answer() For each snippet of text , label the sentiment of the text as positive or negative .</p><p>Text : watching '' ending '' is too often like looking over the outdated clothes and plastic knickknacks at your neighbor 's garage sale . Sentiment : negative Text : naipaul fans may be disappointed . Sentiment : negative Text : scott delivers a terrific performance in this fascinating portrait of a modern lothario . Sentiment : positive Text : you ' ll probably love it . Sentiment : positive Text : a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid creme brulee . Sentiment :</p><p>Model Output negative G.17 Story Cloze Description: Commonsense reasoning task that requires choosing the correct ending to a four-sentence story. <ref type="bibr" target="#b37">Mostafazadeh et al. [2017]</ref> Train Size: 1871, Test Size: 1871</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Story Cloze Few Shot</head><p>Input Given two possible next sentences A ) and B ) , choose the best next sentence to complete the story .</p><p>Answer with A or B .</p><p>Peter was excited to go to the Sanders rally in New Hampshire . As Peter entered the arena it was full of thousands of people . When Peter saw Bernie he cheered as loudly as possible . He felt thrilled to be there . A ) He couldn ' t wait to vote for him . B ) He was a staunch republican . Answer : He couldn ' t wait to vote for him .</p><p>My roommate was sick . She stayed home from work and school . She slept all day long . By the end of the day , she was feeling better . A ) She decided rest has helped . B ) She hoped she would soon be sick again . Answer : She decided rest has helped .</p><p>My aunt is a nurse . She often talks about long hours at work . Last week was especially bad . She didn ' t have a single day where she didn ' t work late . A ) It was easy work . B ) It was hard work . Answer : It was hardwork .</p><p>My friends all love to go to the club to dance . They think it ' s a lot of fun and always invite . I finally decided to tag along last Saturday . I danced terribly and broke a friend ' s toe . A ) My friends decided to keep inviting me out as I am so much fun . B ) The next weekend , I was asked to please stay home . Answer :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Choices</head><p>-My friends decided to keep inviting me out as I am so much fun . -The next weekend , I was asked to please stay home .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gold Output</head><p>The next weekend , I was asked to please stay home . answer() Passage : My aunt is a nurse and she often talks about long hours at work . Last week was especially bad and she was constantly working many hours . Question : Was her work easy ? Answer : No , it was hard work .</p><p>Passage : My roommate was sick . She stayed home from work and school . She slept all day long and by the end of the day , she was feeling better . Question : Did the rest help her ? Answer : Yes , she slept and felt better .</p><p>Passage : Andy had always wanted a big kids bike . When he turned six Year ' s old he asked for a bike for his birthday . He did not know how to ride a bike . On Andy ' s birthday his mother gave him a bike . Question : Did he cry all night ? Answer : No , Andy was happy because he got a bike .</p><p>Passage : My friends all love to go to the club to dance . They think it ' s a lot of fun and always invite . I finally decided to tag along last Saturday . I danced terribly and broke a friend ' s toe . Question : Did I stay home the next weekend ?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Choices</head><p>-My friends decided to keep inviting me out as I am so much fun . -The next weekend , I was asked to please stay home .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gold Output</head><p>The next weekend , I was asked to please stay home .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.18 WSC</head><p>Description: Task that requires readining a sentence with a pronoun and selecting the referent of that pronoun from a list of choices.  Train Size: 554, Test Size: 104</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WSC Few Shot</head><p>Input Passage : Mark was close to Mr . Singer 's heels . He heard him calling for the captain , promising him , in the jargon everyone talked that night , that not one thing should be damaged on the ship except only the ammunition , but the captain and all " his " crew had best stay in the cabin until the work was over . Question : In the passage above , does the pronoun " his " refer to Mark ? Answer : No Passage : Tom gave Ralph a lift to school so " he " wouldn ' t have to walk . Question : In the passage above , does the pronoun " he " refer to Ralph ? Answer : Yes Passage : This book introduced Shakespeare to Ovid ; it was a major influence on " his " writing . Question : In the passage above , does the pronoun " his " refer to Shakespeare ? Answer : Yes Passage : The large ball crashed right through the table because " it " was made of styrofoam . Question : In the passage above , does the pronoun " it " refer to the table ? Answer :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="55">Gold Output</head><p>Yes WSC AMA prompt()-chain Example question() Extract the phrase containing the pronoun .</p><p>Passage : Jane ' s mom went to the shop to buy Jane a backpack for " her " first day of kindergarten . Extract : phrase containing " her ": " her " first day Passage : The musicians performed in the park and the crowd loved " them ". The crowd cheered for them . Extract : phrase containing " them ": crowd loved " them " Passage : Jeff gave his son some money because " he " wanted to buy lunch . Extract : phrase containing " he ": " he " wanted to buy Passage : The large ball crashed right through the table because " it " was made of styrofoam . Extract : phrase containing " it ": Description: Question answering dataset with questions that can be answered using Freebase, a large knowledge graph. <ref type="bibr" target="#b43">Berant et al. [2013]</ref> Train Size: 3778, Test Size: 2032 Question : who plays Carrie Bradshaw in sex and the city ? Answer : Caroline " Carrie " Bradshaw is a fictional character from the HBO franchise Sex and the City , portrayed by Sarah Jessica Parker .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Output</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WebQuestions (WQ) Few Shot</head><p>Question : what are the elements in air ? Answer : By mole fraction ( i . e . , by number of molecules ) , dry air contains 78.08% nitrogen , 20.95% oxygen , 0.93% argon , 0.04% carbon dioxide , and small amounts of other gases Question : what is HP company ? Answer : HP Inc . is an American multinational information technology company headquartered in Palo Alto , California , that develops personal computers ( PCs )</p><p>Question : when was the last season of FRIENDS released ? Answer : The series finale aired on May 6 , 2004 , and was watched by around 52.5 million American viewers , making it the fifth -most -watched series finale in television history Question : who is governor of ohio 2011? Answer :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Output</head><p>John Kasich is the current governor of Ohio .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>answer()</head><p>Answer the question .</p><p>Context : The nearest airport to Palm Springs is Indio / Palm Springs ( PSP ) Airport which is 2.1 miles away . Question : what airport is closest to palm springs ? Answer : Palm Springs International Airport </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.20 WiC</head><p>Description: Word sense disambiguation task cast as binary classification over sentence pairs.  Train Size: 5428, Test Size: 638</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WiC Few Shot</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>These aspects of civilization do not find expression or receive an interp retati on . Find the product of two numbers . Question : Is the word ' find ' used in the same sense in the two sentences above ? No Cut my hair . Cut the engine . Question : Is the word 'cut ' used in the same sense in the two sentences above ? No</p><p>The pit floor showed where a ring of post holes had been . The floor of a cave served the refugees as a home . Question : Is the word ' floor ' used in the same sense in the two sentences above ? Yes An emerging professional class . Apologizing for losing your temper , even though you were badly provoked , showed real class . Question : Is the word ' class ' used in the same sense in the two sentences above ?</p><p>Gold Output no WiC AMA prompt()-chain Example answer() Give synonyms of the word in the sentence .</p><p>In " She heard the sound of voices in the hall ." , synonyms for the word " sound " are : -noise</p><p>In " Enter the secret code ." , synonyms for the word " code " are : -password</p><p>In " She acted in a play on Broadway " , synonyms for the word " play " are : -show</p><p>In " An emerging professional class ." , synonyms for the word " ' class '" are :</p><p>Model Output group</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Example prompt with the in-context demonstrations and placeholder (Left) with two different prompt variations (Right) created by changing demonstrations and question style.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) question(): x ? q generates a question q (such as "Did John go to the park?") from an input x ("John went to the park."). question() prompts simply contain demonstrations of how a statement can be transformed to an open-ended question. (b) answer(): q ? a applies the question generated by (a) to the context of x to produce intermediate answers a (such as "No" or "theater"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Evaluation across model sizes for diagnostics and benchmarks. We report the absolute lift from AMA over few-shot (k = 3) performance, averaged over 7 tasks with 95% confidence intervals (Left). Diagnostic plots are ordered by the amount of lift models of the size-category see on 7 the benchmarks (Right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Technology and Science AGNews AMA prompt()-chain Example question() Passage : China overtakes United States as top destination for foreign investment ( AFP ) . AFP -China overtook the United States as a top global destination for foreign direct investment ( FDI ) in 2003 while the Asia -Pacific region attracted more investment than any other developing region , a UN report said . Summarize : the passage " Passage ": The passage is about foreign direct investment . Passage : Colangelo resigns as CEO of D -Backs . Jerry Colangelo has resigned his position as chief executive officer of the Arizona Diamondbacks , effective immediately , handing the reins of the organization to CEO Elect Jeff Moorad . Summarize : the passage " Passage ": The passage is about the Arizona Diamondbacks . Passage : 3 injured in plant fire in Japan . TOKYO , Aug . 20 ( Xinhuanet ) --Fire broke out Friday at a tire plant belonging to Bridgestone Corp . in Amagi , western Fukuoka Prefecture of Japan , leaving 13 people injured . Summarize : the passage " Passage ": The passage is about a plant fire . Passage : The Race is On : Second Private Team Sets Launch Date for Human Spaceflight ( SPACE . com ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>"</head><label></label><figDesc>overtakes United States as top destination for foreign investment ( AFP ) . AFP -China overtook the United States as a top global destination for foreign direct investment ( FDI ) in 2003 while the Asia -Pacific region attracted more investment than any other developing region , a UN report said . Summary : The passage is about foreign direct investment . The summary " Summary " fits " Category ": Business Passage : Colangelo resigns as CEO of D -Backs . Jerry Colangelo has resigned his position as chief executive officer of the Arizona Diamondbacks , effective immediately , handing the reins of the organization to CEO Elect Jeff Moorad . Summary : The passage is the Arizona Diamondbacks . The summary " Summary " fits " Category ": Sports Passage : 3 injured in plant fire in Japan . TOKYO , Aug . 20 ( Xinhuanet ) --Fire broke out Friday at a tire plant belonging to Bridgestone Corp . in Amagi , western Fukuoka Prefecture of Japan , leaving 13 people injured . Summary : The passage is about a plant fire . The summary " Summary " fits " Category ": World News Passage : The Race is On : Second Private Team Sets Launch Date for Human Spaceflight ( SPACE . com ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>True</head><label></label><figDesc>BoolQ AMA prompt()-chain Example answer() Answer the question using the context .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>False</head><label></label><figDesc>CB AMA prompt()-chain Example question() Rewrite the statement as a yes / no question . Statement : most of the light comes from the sun Question : Does most of the light come from the sun ? Statement : the test was not Question : Was the test hard ? Statement : it is a good idea to buy your parents gifts Question : Is it a good idea to buy your parents gifts ? Statement : the balloon popped Question : Did the balloon pop ? Statement : The father and son went camping to California . Question : Did the father and son go camping ? Statement : arachnids had to be totally organic Question :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>COPA AMA prompt()-chain Example answer() Pick the correct ending for the example .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>and Mental Health -Personality and Mental Health : M u l t i d i s c i p l i n a r y Studies from Personality Dysfunction to Criminal Behaviour is a quarterly peer -reviewed academic journal published by Wiley -Blackwell on behalf of the Centre for Health and Justice . Summarize : the passage " Passage ": The passage is about a journal . Passage : RNLB Mona ( ON 775) -RNLB Mona ( ON 775) was a Watson Class lifeboat based at Broughty Ferry in Scotland that capsized during a rescue attempt with the loss of her entire crew of eight men . The Mona was built in 1935 and in her time saved 118 lives . Summarize : the passage " Passage ": The passage is about a lifeboat . Passage : Sayonara mo Ienakatta Natsu -Sayonara mo Ienakatta Natsu is an album by Mikuni Shimokawa released on July 4 2007 by Pony Canyon . This album consists of eleven songs ; several new songs and some songs which were previously released as singles . Summarize : the passage " Passage ": The passage is about a album .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>"</head><label></label><figDesc>and Mental Health -Personality and Mental Health : M u l t i d i s c i p l i n a r y Studies from Personality Dysfunction to Criminal Behaviour is a quarterly peer -reviewed academic journal published by Wiley -Blackwell on behalf of the Centre for Health and Justice . Summary : The passage is about a journal . The summary " Summary " fits " Category ": written work Passage : RNLB Mona ( ON 775) -RNLB Mona ( ON 775) was a Watson Class lifeboat based at Broughty Ferry in Scotland that capsized during a rescue attempt with the loss of her entire crew of eight men . The Mona was built in 1935 and in her time saved 118 lives . Summary : The passage is about a lifeboat . The summary " Summary " fits " Category ": mean of tra nsport ation Passage : Sayonara mo Ienakatta Natsu -Sayonara mo Ienakatta Natsu is an album by Mikuni Shimokawa released on July 4 2007 by Pony Canyon . This album consists of eleven songs ; several new songs and some songs which were previously released as singles . Summary :The passage is about a album . The summary " Summary " fits " Category ": album Passage : TY KU -TY KU is an American alcoholic beverage company that specializes in sake and other spirits . The privately -held company was founded in 2004 and is headquartered in New York City New York . While based in New York TY KU ' s beverages are made in Japan through a joint venture with two sake breweries . Since 2011 TY KU ' s growth has extended its products into all 50 states . Summary : The passage is about a company . The summary " Summary " fits " Category ":</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>. In January 2000 , Assistant Secretary of State Karl Inderfurth and the State Department ' s c o u n t e r t e r r o r i s m coordinator , Michael Sheehan , met with General Musharraf in Islamabad , dangling before him the possibility of a presidential visit in March as a reward for Pakistani cooperation . Such a visit was coveted by Musharraf , partly as a sign of his government ' s legitimacy .... Question : Based on the previous passage , Where did President Clinton visit on March 25 , 2000? Is " Parkistan " a correct answer ? Answer : Yes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>yes G.12 Natural Questions (NQ) Description: Open-domain question answering that contains questions from real users. Kwiatkowski et al. [2019] Train Size: 307373, Test Size: 7830 Natural Questions (NQ) Few Shot Input Question : who sings does he love me with reba Answer : Linda Davis Question : where do the great lakes meet the ocean Answer : the Saint Lawrence River Question : when does the new my hero academia movie come out Answer : July 5 , 2018 Question : what is the main mineral in lithium batteries Answer : Gold Output lithium Natural Questions (NQ) AMA prompt()-chain Example question() Produce distinct questions .Question : who plays Carrie Bradshaw in sex and the city ? Answer : Caroline " Carrie " Bradshaw is a fictional character from the HBO franchise Sex and the City , portrayed by Sarah Jessica Parker .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Description: Reading comprehension dataset which requires commonsense reasoning. Train Size: 100730, Test Size: 10000ReCoRD Few ShotInputContext : The University of Pennsylvania has been named America ' s top party school by Playboy in the first time the Ivy League institution has made the list . Believe it or not the magazine gave the top spot to the college by declaring that ' UPenn puts other Ivies to shame with its union of brains , brewskies and bros . ' In the magazine ' s ninth annual ranking of universities around the country , the University of Wisconsin -Madison scored the runner up slot . The University of Pennsylvania ( pictured ) has been named America ' s top party school by Playboy in the first time the Ivy League institution has made the list . The University of Wisconsin -Madison scored the runner up slot . Last year ' s winner West Virginia University slipped down to third place . It is the magazine ' s ninth annual ranking of universities around the country Answer : Playboy writes : ' Boasting a notorious underground frat scene that school officials have deemed a nuisance , these renegades pony up thousands of dollars ' worth of liquor for their parties -and competition among the houses means a balls -out war of debauchery .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Story Cloze AMA prompt()-chain Example question() Rewrite the statement as a yes / no question . Statement : Jonathan Samuels was born in the 70 ' s . Question : Was Jonathan Samuels born in the 70 ' s ? Statement : Jerry bullied him and called him names Question : Did Jerry bully him and call him names ? Statement : Sam and jade were going to go to the movies Question : Did did Sam and jade go to the movies ? Statement : Chocolate is tasty , when I am feeling hungry . Question : Does chocolate taste good when you are hungry ? Statement : Mark ran fast . Question : Did mark run fast ? Statement : The next weekend , I was asked to please stay home . Question : home the next weekend ?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Input</head><label></label><figDesc>Question : what character did natalie portman play in star wars ? Answer : Padme Amidala Question : what country is the grand bahama island in ? Answer : Bahamas Question : who does joakim noah play for ? Answer : Chicago Bulls Question : who is governor of ohio 2011? Answer :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>Context : Martin Luther King earned his Bachelor of Divinity degree from Crozer Theological Seminary , followed by a doctorate in Systematic Theology from Boston University . Question : what degree did martin luther king get ? Answer : Bachelor of Divinity Context : The Niger river runs in a crescent through Libya , Mali , Niger , on the border with Benin and then through Nigeria . Question : what countries does the niger river flow through ? Answer : Libya Context : Puerto Rico is a territory of the United States and uses the U . S . dollar . Question : what type of currency is used in puerto rico ? Answer : United States dollar Context : kitt was voice most often by William daniels . Question : who played kitt in knight rider ? Answer : William Daniels Context : John Kasich is the current governor of Ohio . Question : who is governor of ohio 2011</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>AMA results for the GPT-J-6B parameter model<ref type="bibr" target="#b15">[Black et al., 2021]</ref> compared to the few-shot GPT3-175B. The GPT-175B numbers are as reported in,<ref type="bibr" target="#b2">Zhao et al. [2021]</ref>, where the numbers of in-context examples is in parentheses. Note that prompts can abstain from predicting, which can lead to lower average numbers for QA, including on COPA and StoryCloze. For the question-answering tasks and ReCoRD, we report the majority vote aggregation, as using WS is complex with the openended output space. The same results for the BLOOM 7.1B parameter model are in Appendix 3.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>(Appendix B.1).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Performance of T0 as reported in</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of DARPA, NIH, ONR, or the U.S. Government. Melissa Roemmele, Cosmin Adrian Bejan, and Andrew S Gordon. Choice of plausible alternatives: An evaluation of commonsense causal reasoning. In AAAI spring symposium: logical formalizations of commonsense reasoning, pages 90-95, 2011. Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, and Dan Roth. Looking beyond the surface: A challenge set for reading comprehension over multiple sentences. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 252-262, 2018. Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, and Benjamin Van Durme. ReCoRD: Bridging the gap between human and machine commonsense reading comprehension. arXiv preprint 1810.12885, 2018. Mohammad Taher Pilehvar and Jose Camacho-Collados. Wic: the word-in-context dataset for evaluating contextsensitive meaning representations. arXiv preprint arXiv:1808.09121, 2018. Hector Levesque, Ernest Davis, and Leora Morgenstern. The winograd schema challenge. In Thirteenth international conference on the principles of knowledge representation and reasoning, 2012.</figDesc><table><row><cell>Together Computer (https://together.xyz/). We</cell></row><row><cell>are grateful to the Numbers Station (https://numbersstation.ai/), Snorkel (https://snorkel.ai/), Stan-</cell></row><row><cell>ford Center for Research on Foundation Models (https://crfm.stanford.edu/), and Stanford HAI (https:</cell></row><row><cell>//hai.stanford.edu/) organizations for the resources that supported this work. We thank Karan Goel, Maya</cell></row><row><cell>Varma, Joel Johnson, Sabri Eyuboglu, Kawin Ethayarajh, Niladri Chatterji, Neha Gupta, Alex Ratner, and Rishi</cell></row><row><cell>Bommasani for their helpful feedback and discussions. We gratefully acknowledge the support of DARPA under</cell></row><row><cell>Nos. FA86501827865 (SDH) and FA86501827882 (ASED); NIH under No. U54EB020405 (Mobilize), NSF under</cell></row><row><cell>Nos. CCF1763315 (Beyond Sparsity), CCF1563078 (Volume to Velocity), and 1937301 (RTML); ONR under No.</cell></row><row><cell>N000141712266 (Unifying Weak Supervision); the Moore Foundation, NXP, Xilinx, LETI-CEA, Intel, IBM, Mi-</cell></row><row><cell>crosoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Ericsson, Qualcomm, Analog Devices, the Okawa</cell></row><row><cell>Foundation, American Family Insurance, Google Cloud, Swiss Re, Brown Institute for Media Innovation, Department</cell></row><row><cell>of Defense (DoD) through the National Defense Science and Engineering Graduate Fellowship (NDSEG) Program,</cell></row><row><cell>Fannie and John Hertz Foundation, National Science Foundation Graduate Research Fellowship Program, Texas In-</cell></row><row><cell>struments, and members of the Stanford DAWN project: Teradata, Facebook, Google, Ant Financial, NEC, VMWare,</cell></row><row><cell>and Infosys. SA is supported by a Stanford Graduate Fellowship. LO is supported by an Intelligence Community Post-</cell></row><row><cell>doctoral Fellowship. The U.S. Government is authorized to reproduce and distribute reprints for Governmental pur-</cell></row><row><cell>poses notwithstanding any copyright notation thereon.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell cols="2"># Prompts Avg</cell><cell>MV</cell><cell cols="2">WMV Pick Best</cell><cell cols="2">AMA (no dep) AMA (WS)</cell></row><row><cell>No labels:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">Natural Language Understanding</cell><cell></cell><cell></cell></row><row><cell>WSC</cell><cell>3</cell><cell>74.7</cell><cell>77.8</cell><cell>77.8</cell><cell>75.0</cell><cell>77.8?0.0</cell><cell>77.8?0.0</cell></row><row><cell>WiC</cell><cell>5</cell><cell>59.0</cell><cell>61.3</cell><cell>60.9</cell><cell>60.0</cell><cell>60.8?0.0</cell><cell>61.3?0.2</cell></row><row><cell>RTE</cell><cell>5</cell><cell>61.4</cell><cell>66.0</cell><cell>71.4</cell><cell>62.0</cell><cell>65.1?0.5</cell><cell>75.1?0.0</cell></row><row><cell>CB</cell><cell>3</cell><cell>83.3</cell><cell>82.1</cell><cell>82.1</cell><cell>83.9</cell><cell>82.1?0.0</cell><cell>83.9?0.0</cell></row><row><cell>MultiRC</cell><cell>3</cell><cell>58.8</cell><cell>63.8</cell><cell>63.4</cell><cell>63.4</cell><cell>63.7?0.0</cell><cell>63.8?0.0</cell></row><row><cell>BoolQ</cell><cell>5</cell><cell>64.9</cell><cell>65.9</cell><cell>67.2</cell><cell>68.3</cell><cell>65.9?0.0</cell><cell>67.2?0.0</cell></row><row><cell>COPA</cell><cell>4</cell><cell>58.3</cell><cell>85.0</cell><cell>82.0</cell><cell>82.0</cell><cell>84.0?0.0</cell><cell>84.0?0.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Natural Language Inference</cell><cell></cell><cell></cell></row><row><cell>ANLI R1</cell><cell>5</cell><cell>34.6</cell><cell>37.6</cell><cell>36.1</cell><cell>36.8</cell><cell>37.4?1.0</cell><cell>37.8?0.2</cell></row><row><cell>ANLI R2</cell><cell>5</cell><cell>35.4</cell><cell>36.3</cell><cell>36.0</cell><cell>36.0</cell><cell>38.7?0.4</cell><cell>37.9?0.2</cell></row><row><cell>ANLI R3</cell><cell>5</cell><cell>37.0</cell><cell>39.0</cell><cell>38.4</cell><cell>38.4</cell><cell>39.6?0.9</cell><cell>40.9?0.5</cell></row><row><cell>StoryCloze</cell><cell>6</cell><cell>76.3</cell><cell>87.9</cell><cell>81.8</cell><cell>81.8</cell><cell>82.2?0.0</cell><cell>87.8?0.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Classification</cell><cell></cell><cell></cell><cell></cell></row><row><cell>DBPedia</cell><cell>3</cell><cell>81.4</cell><cell>84.1</cell><cell>83.9</cell><cell>82.2</cell><cell>83.9?0.0</cell><cell>83.9?0.0</cell></row><row><cell>SST2</cell><cell>3</cell><cell>94.5</cell><cell>95.7</cell><cell>95.7</cell><cell>95.2</cell><cell>95.7?0.0</cell><cell>95.7?0.0</cell></row><row><cell>Amazon</cell><cell>3</cell><cell>67.0</cell><cell>68.6</cell><cell>68.6</cell><cell>67.3</cell><cell>68.6?0.0</cell><cell>68.6?0.0</cell></row><row><cell>AGNews</cell><cell>3</cell><cell>83.7</cell><cell>86.5</cell><cell>84.2</cell><cell>83.8</cell><cell>86.4?0.0</cell><cell>86.4?0.0</cell></row></table><note>AMA results for the BLOOM-7.1B parameter model compared to the few-shot GPT3-175B. The GPT-175B numbers are as reported in Brown et al. [2020], where the numbers of shots is in parentheses, and the classification task baselines are from from Zhao et al. [2021].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>). For both tasks, we use the Text-F1 score introduced in SQuAD [<ref type="bibr" target="#b53">Rajpurkar et al., 2018]</ref>.InputContext : Caracas , Venezuela ( CNN ) --It ' s been more than 180 years since Venezuelans saw Simon Bolivar ' s face . But the revolutionary leader ' s thick sideburns , bushy eyebrows and steely gaze popped out from behind picture frames Tuesday in new 3 -D images unveiled by President Hugo Chavez . Researchers used several software programs to reconstruct the face of the man who liberated Bolivia , Colombia , Ecuador , Panama , Peru and Venezuela from the Spanish crown . Scans of Bolivar ' s skeletal remains , which investigators exhumed two years ago , factored into their calculations . So did historical paintings , photos of restored uniforms Bolivar wore and images of middle -aged Venezuelans , officials said .</figDesc><table><row><cell>Extraction (Span)</cell></row><row><cell>Input</cell></row><row><cell>Wiki Bio :</cell></row><row><cell>name : robert king</cell></row><row><cell>article_title : robert king ( p h ot oj o ur na l is t )</cell></row><row><cell>birth_place : memphis , tn , usa</cell></row><row><cell>occupation : war correspondent ph o to j ou rn a li st filmmaker creative director art director birthname :</cell></row><row><cell>robert whitfield king</cell></row><row><cell>birth_date : may 25 th</cell></row><row><cell>Question : What is the birthname ?</cell></row><row><cell>Answer :</cell></row><row><cell>Output</cell></row><row><cell>robert whitfield king</cell></row><row><cell>Extraction (Sentence)</cell></row><row><cell>Extract the sentence containing " Simon Bolivar ":</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>InputPick one category for the following text . Monteverdi High Speed -The Monteverdi High Speed was a grand tourer automobile built by Monteverdi in Basel Switzerland from 1967 to 1970. Contemporary rivals included the British Jensen Interceptor ( which was also powered by a Chrysler V8 ) . This car was designed by the Italian design house Frua and was actually built by Fissore of Italy from 1969. They redesigned the car in 1972 and again in 1975. The convertible version of the High Speed 375 was known as the Palm Beach .</figDesc><table><row><cell>" Categories ":</cell></row><row><cell>-company</cell></row><row><cell>-educational institution</cell></row><row><cell>-artist</cell></row><row><cell>-athlete</cell></row><row><cell>-office holder</cell></row><row><cell>-mean of tr anspor tation</cell></row><row><cell>-building</cell></row><row><cell>-natural place</cell></row><row><cell>-village</cell></row><row><cell>-animal</cell></row><row><cell>-plant</cell></row><row><cell>-album</cell></row><row><cell>-film</cell></row><row><cell>-written work</cell></row><row><cell>Passage : Summary : This passage is about a automobile .</cell></row><row><cell>The summary " Summary " fits " Category ":</cell></row><row><cell>Prediction</cell></row><row><cell>automobile</cell></row><row><cell>Ground Truth</cell></row><row><cell>mean of transpo rtatio n</cell></row><row><cell>Instruction Following (2)</cell></row><row><cell>Input</cell></row><row><cell>Pick one category for the following text .</cell></row><row><cell>" Categories ":</cell></row><row><cell>-company</cell></row><row><cell>-educational institution</cell></row><row><cell>-artist</cell></row><row><cell>-athlete</cell></row><row><cell>-office holder</cell></row><row><cell>-mean of tr anspor tation</cell></row><row><cell>-building</cell></row><row><cell>-natural place</cell></row><row><cell>-village</cell></row><row><cell>-animal Instruction Following (1) -plant</cell></row><row><cell>-album</cell></row><row><cell>-film</cell></row><row><cell>-written work</cell></row><row><cell>Passage : Passage : Patricia Bennett -Patricia Bennett ( born 7 April 1947 in The Bronx New York )</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>PredictionWho warned the public on Sunday that the island could feel [ at ] placeholder ' s wrath around noon Wednesday ?</figDesc><table><row><cell>Rewrite the statement as a question about the [ at ] placeholder .</cell></row><row><cell>Statement : Most of the light comes from the [ at ] placeholder</cell></row><row><cell>Question : Where does most of the light come from ?</cell></row><row><cell>Statement : The [ at ] placeholder was not hard</cell></row><row><cell>Question : What was not hard ?</cell></row><row><cell>Statement : [ at ] placeholder went to the mall with her mom to buy a backpack</cell></row><row><cell>Question : Who went to the mall with her mom to buy a backpack ?</cell></row><row><cell>Statement : Rossello warned the public on Sunday that the island could feel [ at ] placeholder ' s</cell></row><row><cell>wrath around noon Wednesday .</cell></row><row><cell>Question :</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>Wedding cad comes clean over invite sale ( Reuters ) . Reuters -A wedding guest who sparked a bidding frenzy when he offered for sale a pair of invitations to a wedding he did not want to attend has admitted that the bride was a former girl friend .</figDesc><table><row><cell>:</cell></row><row><cell>-World News</cell></row><row><cell>-Sports</cell></row><row><cell>-Business</cell></row><row><cell>-Technology and Science</cell></row><row><cell>Passage :</cell></row></table><note>Category : World News Passage : Tennis : Serena Williams Reaches Finals of China Open . Top seed Serena Williams of the United States has powered her way into the finals of the China Open tennis tournament in Beijing with a straight sets (6 -2 , 6 -3) victory over fourth -seeded Vera Zvonareva of Russia . Category : Sports Passage : Abramovich faces rich list challenge . Lakshmi Mittal , the Indian -born steel magnate , yesterday staked a claim to overtake Roman Abramovich as Britain ' s richest man with a 10 bn deal to create the world ' s largest steelmaker . Category : Business Passage : The Race is On : Second Private Team Sets Launch Date for Human Spaceflight ( SPACE . com ) .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>Adversarially mined natural language inference dataset from Wikipedia. Nie et al. [2020] Train Size: 16946, Test Size: 1000 ANLI R1 Few Shot Input Robert L . Hass ( born March 1 , 1941) is an American poet . He served as Poet Laureate of the United States from 1995 to 1997. He won the 2007 National Book Award and shared the 2008 Pulitzer Prize for the collection " Time and Materials : Poems 1997 -2005." In 2014 he was awarded the Wallace Stevens Award from the Academy of American Poets . Question : Robert L . Hass was Poet Laureate of the United States for two years . True , False , or Neither ? True Randall Park ( born March 23 , 1974) is an American actor , comedian , writer , and director . He played Kim Jong -Un in the 2014 film " The Interview " , Minnesota governor Danny Chung in " Veep " , and beginning in 2015 he portrayed Eddie Huang ' s father , American restaurateur Louis Huang , in ABC ' s television show " Fresh Off the Boat ".</figDesc><table><row><cell>G.2 ANLI R1</cell></row><row><cell>Description:</cell></row><row><cell>Output</cell></row><row><cell>technology and science</cell></row></table><note>Question : Randall Park is dead True , False , or Neither ? False</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>Question : Extensive testing went on to produce this berry True , False , or Neither ? Neither Daniel Zolnikov ( born January 29 , 1987) is a Republican member of the Montana Legislature . He was elected to House District 47 which represents Billings , Montana After redistricting , he now represents House District 45. He has made a name for himself pursuing pro -privacy legislation . Question : There is no information indicating whether Daniel Zolnikov is a good legislator or not . True , False , or Neither ?</figDesc><table><row><cell>Gold Output</cell></row><row><cell>sun ?</cell></row><row><cell>Statement : the test was not hard</cell></row><row><cell>Question : Was the test not hard ?</cell></row><row><cell>Statement : it is a good idea to buy your parents gifts</cell></row><row><cell>Question : Is it a good idea to buy your parents gifts ?</cell></row><row><cell>Statement : the balloon popped</cell></row><row><cell>Question : Did the balloon pop ?</cell></row><row><cell>Statement : The father and son went camping to California .</cell></row><row><cell>Question : Did the father and son go camping ?</cell></row><row><cell>Statement : There is no information indicating whether Daniel Zolnikov is a good legislator or not</cell></row><row><cell>.</cell></row><row><cell>Question :</cell></row></table><note>neither ANLI R1 AMA prompt()-chain Example question() Rewrite the statement as a yes / no question .Statement : most of the light comes from the sun Question : Does most of the light come from the</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head></head><label></label><figDesc>Adversarially mined natural language inference dataset from Wikipedia. Nie et al. [2020] Train Size: 45460, Test Size: 1000 ANLI R2 Few Shot Input Matter was a London music venue and nightclub that opened in September 2008 , after three years of planning . A 2 ,600 capacity live music venue and nightclub , it was the second project for owners Cameron Leslie and Keith Reilly , founders of the London club Fabric . Matter is the third venue to open at The O in south -east London . Question : The owners own more than one London club . True , False , or Neither ? True Whitechapel is a British television drama series produced by Carnival Films , in which detectives in London ' s Whitechapel district dealt with murders which replicated historical crimes . The first series was first broadcast in the UK on 2 February 2009 and depicted the search for a modern copycat killer replicating the murders of Jack the Ripper . Question : Some of the victims depicted in Whitechapel were women True , False , or Neither ? Neither Nannina de ' Medici (14 February 1448 -14 May 1493) , born Lucrezia de ' Medici , was the second daughter of Piero di Cosimo de ' Medici and Lucrezia Tornabuoni . She was thus the elder sister of Lorenzo de ' Medici . She married Bernardo Rucellai . Her father ' s name was Piero , so she is sometimes known as Lucrezia di Piero de ' Medici . Question : Nannina de ' Medici is sometimes known as Ivanka Trump True , False , or Neither ? FalseThere is a little Shia community in El Salvador . There is an Islamic Library operated by the Shia community , named " Fatimah Az -Zahra ". They published the first Islamic magazine in Central America : " Revista Biblioteca Islamica ". Additionally , they are credited with providing the first and only Islamic library dedicated to spreading Islamic culture in the country . Question : The community is south of the United States . True , False , or Neither ?Rewrite the statement as a yes / no question .Statement : most of the light comes from the sun Question : Does most of the light come from the sun ?Context : According to Biraben , the plague was present somewhere in Italy and affected 1 ,200 people . Question : Based on the context , Did the plague affect people in Europe ? Answer : yes , people in Italy , Europe</figDesc><table><row><cell>Question : Based on the context , Is anti -matter made of electrons ?</cell><cell></cell></row><row><cell>Answer : Unknown</cell><cell></cell></row><row><cell>legislator ? Answer : Gold Output neither G.3 ANLI R2 true ANLI R2 AMA prompt()-chain Example question() Statement : the test was not hard Description: Gold Output Question : Was the test not hard ?</cell><cell>is a good</cell></row><row><cell>Statement : it is a good idea to buy your parents gifts</cell><cell></cell></row><row><cell>Question : Is it a good idea to buy your parents gifts ?</cell><cell></cell></row><row><cell>Statement : the balloon popped</cell><cell></cell></row><row><cell>Question : Did the balloon pop ?</cell><cell></cell></row><row><cell>Statement : The father and son went camping to California .</cell><cell></cell></row><row><cell>Question : Did the father and son go camping ?</cell><cell></cell></row><row><cell>Statement : The community is south of the United States .</cell><cell></cell></row><row><cell>Question :</cell><cell></cell></row><row><cell>Model Output</cell><cell></cell></row><row><cell>Is the community south of the United States ?</cell><cell></cell></row><row><cell>answer()</cell><cell></cell></row></table><note>Context : Daniel Zolnikov ( born January 29 , 1987) is a Republican member of the Montana Legislature . He was elected to House District 47 which represents Billings , Montana After redistricting , he now represents House District 45. He has made a name for himself pursuing pro -privacy legislation . Question : Based on the context , Is there information indicating whether Daniel Zolnikov</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head></head><label></label><figDesc>Adversarially mined natural language inference dataset from Wikipedia, News and other data sources. Nie et al. [2020] Train Size: 100459, Test Size: 1200 ANLI R3 Few Shot Input And that means that the local law enforcement officials need help at the federal level . Programs like Project Exile where the federal government intensifies arresting people who illegally use guns . And we haven ' t done a very good job of that at the federal level recently . Question : There are only federal enforcement officials . True , False , or Neither ? False Scary Dream &lt; br &gt; Tom woke up in a cold sweat . He was shaking and scared . He realized he had just had a scary dream . Tom was too afraid to fall back asleep . Instead he stayed up all night . Question : Tom experienced a bad nightmare that kept him from sleeping . True , False , or Neither ? True Wayman Lawrence Tisdale ( June 9 , 1964 -May 15 , 2009) was an American professional basketball player in the NBA and a smooth jazz bass guitarist . A three -time All American at the University of Oklahoma , he was elected to the National Collegiate Basketball Hall of Fame in 2009. Question : Wayman Tisdale played smooth jazz bass guitar at the University of Oklahoma True , False , or Neither ? Neither For one night , all of Clinton ' s non -varsity squads achieved perfection sweeping Altus in seventh , eighth and ninth grade basketball at ... PLEASE LOG IN FOR PREMIUM CONTENT . Our website requires visitors to log in to view the best local news from Clinton Daily News .</figDesc><table><row><cell>true</cell></row><row><cell>ANLI R3 AMA prompt()-chain Example</cell></row><row><cell>question()</cell></row><row><cell>Rewrite the statement as a yes / no question .</cell></row><row><cell>Statement : most of the light comes from the sun</cell></row><row><cell>Question : Does most of the light come from the sun ?</cell></row><row><cell>Statement : the test was not hard</cell></row><row><cell>Question : Was the test not hard ?</cell></row><row><cell>Statement : it is a good idea to buy your parents gifts</cell></row><row><cell>Question : Is it a good idea to buy your parents gifts ?</cell></row><row><cell>Statement : the balloon popped</cell></row><row><cell>Question : Did the balloon pop ?</cell></row><row><cell>Gold Output Statement : The father and son went camping to California .</cell></row><row><cell>true</cell></row><row><cell>G.4 ANLI R3</cell></row><row><cell>Description: Not yet a</cell></row><row><cell>subscriber ? Subscribe today ! Thank you !</cell></row><row><cell>Question : This headline leads to more information that is behind a paywall . True , False , or</cell></row><row><cell>Neither ?</cell></row><row><cell>Gold Output</cell></row></table><note>Question : Did the father and son go camping ?</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head></head><label></label><figDesc>For one night , all of Clinton ' s non -varsity squads achieved perfection sweeping Altus in seventh , eighth and ninth grade basketball at ... PLEASE LOG IN FOR PREMIUM CONTENT . Our website requires visitors to log in to view the best local news from Clinton Daily News . Amazon product classification dataset with 9 classes. He and McAuley [2016] Train Size: 9000, Test Size: 9000 G.6 BoolQ Description: Yes/no QA task over small wikipedia passages. Clark et al. [2019] Train Size: 9427, Test Size: 3245 and South Korea have the highest set drinking ages ; however , some of these countries do not have offpremises drinking limits . Austria , Antigua and Barbuda , Belgium , Bermuda , British Virgin Islands , Cuba , Ethiopia , Gibraltar , Luxembourg and Nicaragua have the lowest set drinking ages .</figDesc><table><row><cell>G.5 Amazon</cell></row><row><cell>Description: BoolQ Few Shot</cell></row><row><cell>Input</cell></row><row><cell>Answer the question .</cell></row><row><cell>Context : Red River (1948 film ) --The film ' s supporting cast features Walter Brennan , Joanne Dru ,</cell></row><row><cell>Coleen Gray , Harry Carey , John Ireland , Hank Worden , Noah Beery Jr . , Harry Carey Jr . and</cell></row><row><cell>Paul Fix . Borden Chase and Charles Schnee wrote the screenplay , based on Chase ' s original</cell></row><row><cell>story ( which was first serialized in The Saturday Evening Post in 1946 as '' Blazing Guns on</cell></row><row><cell>the Chisholm Trail ' ') .</cell></row><row><cell>Question : is the movie red river based on a true story</cell></row><row><cell>Answer : No</cell></row><row><cell>Context : Legal drinking age --Kazakhstan , Oman , Pakistan , Qatar , Sri Lanka , Tajikistan , Thailand</cell></row><row><cell>Question : is america the only country with a drinking age of 21</cell></row><row><cell>Answer : No</cell></row><row><cell>Question : Based on the context , Is anti -matter made of electrons ?</cell></row><row><cell>Answer : Unknown</cell></row><row><cell>Context : Not</cell></row><row><cell>yet a subscriber ? Subscribe today ! Thank you !</cell></row><row><cell>Question : Based on the context , Does this headline lead to more information that is behind a</cell></row><row><cell>paywall ?</cell></row><row><cell>Answer :</cell></row><row><cell>Gold Output</cell></row><row><cell>true</cell></row></table><note>, United Arab Emirates , Federated States of Micronesia , Palau , Paraguay , Solomon Islands , India ( certain states ) , the United States ( except U . S . Virgin Islands and Puerto Rico ) , Yemen ( Aden and Sana ' a ) , Japan , Iceland , Canada ( certain Provinces and Territories ) ,</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head></head><label></label><figDesc>Ontology classification dataset with 14 classes.<ref type="bibr" target="#b33">Zhang et al. [2015]</ref> Train Size: 560000, Test Size: 70000 USS Patrol No . 4 ( SP -8) often rendered as USS Patrol #4 was an armed motorboat that served in the United States Navy as a patrol vessel from 1917 to 1919. Patrol No . 4 was built as a private motorboat of the same name in 1915 by Britt Brothers at Lynn Massachusetts . She was one of five motorboats built to the same design for private owners by Britt Brothers as part of the civilian Preparedness Movement program with an understanding that they would enter U . S . Category : Mean Of Transp ortati on Passage : TY KU -TY KU is an American alcoholic beverage company that specializes in sake and other spirits . The privately -held company was founded in 2004 and is headquartered in New York City New York . While based in New York TY KU ' s beverages are made in Japan through a joint venture with two sake breweries . Since 2011 TY KU ' s growth has extended its products into all 50 states . Category :</figDesc><table><row><cell>Pick the correct category for the passage .</cell></row><row><cell>Categories :</cell></row><row><cell>-company</cell></row><row><cell>-educational institution</cell></row><row><cell>-artist</cell></row><row><cell>-athlete</cell></row><row><cell>-office holder</cell></row><row><cell>-mean of tr anspor tation</cell></row><row><cell>-building</cell></row><row><cell>-natural place</cell></row><row><cell>-village</cell></row><row><cell>-animal</cell></row><row><cell>-plant</cell></row><row><cell>-album</cell></row><row><cell>-film</cell></row><row><cell>-written work</cell></row><row><cell>Passage : Garrison Cadet College Kohat -Garrison Cadet College Kohat is Situated in Kohat .</cell></row><row><cell>Foundation stone was laid by the then Prime Minister of Islamic Republic of Pakistan Late</cell></row><row><cell>Mohtarama Benazir Bhutto in 1992. Lieutenant General Arif Bangash Lieutenant General K . K</cell></row><row><cell>Afridi Major General Shirendil Niazi and Colonel Idreesm ( founder Principal ) Dr .</cell></row><row><cell>Category : Educational Institution</cell></row><row><cell>Passage : River Ingrebourne -The River Ingrebourne is a tributary of the River Thames 27 miles Gold Output (43.3 km ) in length . It is considered a strategic waterway in London forming part of the Blue</cell></row><row><cell>Ribbon Network . It flows through the London Borough of Havering roughly from north to south</cell></row><row><cell>photographers followed her joining the Thames at Rainham .</cell></row><row><cell>Category : Natural Place</cell></row><row><cell>G.9 DBPedia Description: DBPedia Few Shot Input Passage : USS Patrol No . 4 ( SP -8) -Gold Output</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head></head><label></label><figDesc>Barack Hussein Obama is an American politician who served as the 44 th president of the United States from 2009 to 2017. A member of the Democratic Party , he was the first African -American president of the United States . Obama previously served as a U . S . senator from Illinois from 2005 to 2008 and as an Illinois state senator from 1997 to 2004. Obama was senator of the state of Illinois prior to becoming a US president . Context : ( CNN ) --Saif al -Islam Gadhafi , 38 , has never lived a day in which his father Moammar didn ' t rule Libya --as its undisputed leader inside the country and an enigmatic , controversial voice for the world . And yet , as the Libyan government faced a stiff popular uprising , it was Moammar Gadhafi ' s second eldest son --and not the Leader of the Revolution himself --who was first to talk to the nation about the unrest and detail a plan to address it . The speech , made early Monday on Libyan state television , does not mean that Saif Gadhafi has usurped power from his father : Senior U . S . officials said there ' s no indication the elder Gadhafi is losing his grip . Saif al -Islam Gadhafi , 38 , gives Libya ' s first public speech acknowledging unrest . There ' s been no public indication why he , and not his father Moammar , talked . Even while some may see the son as more open to change , there ' s little question that his loyalty remains first with Moammar and that his father has given little indication publicly that he ' s ready to let go and calls the shots . Context : The Beatles were an English rock band , formed in Liverpool in 1960 , that comprised John Lennon , Paul McCartney , George Harrison and Ringo Starr . They are regarded as the most influential band of all time and were integral to the development of 1960 s coun tercul ture and popular music ' s recognition as an art form . They were led by primary songwriters Lennon and McCartney . It is without a doubt that the Beatles were influential in rock and roll .Context : Tracy Morgan hasn ' t appeared on stage since the devastating New Jersey crash that nearly ended his life last summer , but all that will change this fall when he returns to host Saturday Night Live . NBC announced on Twitter Monday that Morgan , an SNL alum with seven seasons as a cast member under his belt , will headline the third episode of Season 41 airing October 17. For Morgan , 46 , it will be a second time hosting the long -running variety show , the first since the June 2014 pileup on the New Jersey Turnpike that killed his friend and mentor James ' Jimmy Mack ' McNair .. Morgan , 46 , will host third episode of season 41 of SNL airing October 17. He tweeted to his fans : ' Stoked to be going home ...# SNL '. For the SNL alum who had spent seven years as cast member , it will be a second time hosting the show . Morgan has been sidelined by severe head trauma suffered in deadly June 2014 crash on New Jersey Turnpike that killed his friend . First episode of new SNL season will be hosted by Miley Cyrus , followed by Amy Schumer . ' On October 10 , acclaimed comedian and star of the summer box office hit Trainwreck Amy Schumer will make her SNL debut , followed by things to know for June 13: Gun laws , January 6 , Covid , White ... If your day doesn ' t start until you ' re up to speed on the latest headlines , then let us introduce you to your new favorite morning fix . Sign up here for the '5 Things ' newsletter . ( CNN ) Just imagine what a relief it would be if you could use the same charging cable for all of your devices --your phone , laptop , earbuds , camera , tablet , portable speaker , etc . Well , in a huge step to reduce</figDesc><table><row><cell>-Amy Schumer a week later -Amy Schumer a week later Question : What is the capital city of Japan ?</cell></row><row><cell>-James a week later -James a week later Answer : Tokyo</cell></row><row><cell>-Jimmy Mack a week later -Jimmy Mack a week later</cell></row><row><cell>-McNair a week later -McNair a week later Article : 5</cell></row><row><cell>-Miley Cyrus a week later -Miley Cyrus a week later</cell></row><row><cell>-Morgan a week later -Morgan a week later</cell></row><row><cell>-NBC a week later -NBC a week later</cell></row><row><cell>-New Jersey a week later -New Jersey a week later</cell></row><row><cell>-New Jersey Turnpike a week later -New Jersey Turnpike a week later</cell></row><row><cell>-Night Live a week later -Night Live a week later</cell></row><row><cell>-SNL a week later -SNL a week later</cell></row><row><cell>-Season 41 a week later -Season 41 a week later</cell></row><row><cell>-Tracy Morgan a week later -Tracy Morgan a week later</cell></row><row><cell>-Twitter a week later -Twitter a week later</cell></row><row><cell>Gold Output Model Output</cell></row><row><cell>Morgan , Tracy Morgan Morgan , Tracy Morgan</cell></row><row><cell>ReCoRD AMA prompt()-chain Example G.15 RealTime QA</cell></row><row><cell>answer() Description: Dynamic question answering dataset that asks questions about current world facts. Kasai et al. [2022]</cell></row><row><cell>Train Size: 90, Test Size: 187</cell></row><row><cell>Complete the paragraph .</cell></row><row><cell>Model Choices RealTime QA Few Shot Context : Model Choices Input</cell></row><row><cell>48 49</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head></head><label></label><figDesc>Answer the question given the articles . Article 1: Walmart is slashing prices on clothing and other products -CNN New York ( CNN Business ) Many shoppers have pulled back on buying clothing and other discretionary items as the highest inflation in four decades pinches their pocketbooks . Article 2: Retail slowdown : Target cuts vendor orders , slashes prices as it ... Associated Press NEW YORK . Article 3: Stores have too much stuff . That means discounts are coming | CNN ... New York ( CNN Business ) . Article 4: GM reports strong sales but says it ' s prepared for possible recession ... Oak Fire : California ' s fast -moving wildfire burns 14 ,000 acres and ... ( CNN ) A wildfire raging for a third day Sunday in central California ' s Mariposa County outside Yosemite National Park has burned more than 14 , 000 acres and forced thousands to evacuate from rural communities . Article 2: California Oak Fire : Rapidly -growing fire engulfs homes near ... For more on the fires , " United Shades of America with W . Kamau Bell " heads to California to discover how communities are learning to coexist with the frequent destruction . Article 3: 5 things to know for July 25: Wildfires , Ukraine , Monkeypox , Volcano ... If your day doesn ' t start until you ' re up to speed on the latest headlines , then let us introduce you to your new favorite morning fix . Article 4: Wildfires in US : 2 firefighting helicopter pilots die in Idaho ... Multiple wildfires raged across the U . S . Saturday , causing deaths , destruction and thousands of forced evacuations . Article 5: Boulder wildfires : Hundreds of homes burn evacuations ordered BOULDER , Colo . -A ferocious wind -driven wildfire on Thursday destroyed hundreds of homes and businesses near Denver , forcing tens of thousands to flee and blanketing the area in smoke . Question : A raging wildfire this week forced thousands of people to evacuate communities near which national park ? Answer : " Yosemite National Park " Article 1: 5 things to know for June 13: Gun laws , January 6 , Covid , White ... If your day doesn ' t start until you ' re up to speed on the latest headlines , then let us introduce you to your new favorite morning fix . Sign up here for the '5 Things ' newsletter . ( CNN ) Just imagine what a relief it would be if you could use the same charging cable for all of your devices -your phone , laptop , earbuds , camera , tablet , portable speaker , etc . Well , in a huge step to reduce cable clutter and waste , European regulators say that Apple and other smartphone makers Article 2: 5 things to know for March 11: Ukraine , Pandemic , MLB , North ... If your day doesn ' t start until you ' re up to speed on the latest headlines , then let us introduce you to your new favorite morning fix . Sign up here for the '5 Things ' newsletter . ( CNN ) America , the " land of the free ," is getting quite costly . Prices for gas , food and housing --which are all necessary expenses --are spiking across the country . Gas prices have risen 38% over the past year , and rising prices in pandemic -related sectors , such as travel and dining , are also expected as Article 3: Wi -Charge / consists of a transmitter and a receiver . Transmitter connects to a standard power outlet and converts electricity into infrared laser beam . Receivers use a miniature photo -voltaic cell to convert transmitted light into electrical power . Receivers can be embedded into a device or connected into an existing charging port . The transmitter automatically identifies chargeable receivers and start charging . Several devices can charge at the same time . According to Wi -Charge it can deliver several watts of power to a device at several meters away . The core technology is based on a " distributed laser resonator " which is formed by the Article 4: Mobile broadband / added in 2005. CDPD , CDMA2000 EV -DO , and MBWA are no longer being actively developed . In 2011 , 90% of the world ' s population lived in areas with 2 G coverage , while 45% lived in areas with 2 G and 3 G coverage , and 5% lived in areas with 4 G coverage . By 2017 more than 90% of the world ' s population is expected to have 2 G coverage , 85% is expected Movie review binary sentiment classification dataset.<ref type="bibr" target="#b39">Socher et al. [2013]</ref> Train Size: 6920, Test Size: 1821</figDesc><table><row><cell>Gold Output</cell></row><row><cell>europe</cell></row><row><cell>G.16 SST2</cell></row><row><cell>New York ( Question : Which major US retailer announced this week it is slashing prices on clothing and other CNN Business ) . Article 5: Target is ramping up discounts . Here ' s why -CNN New York ( CNN Business ) . products ? Description: SST2 Few Shot</cell></row><row><cell>Answer : " Walmart "</cell></row><row><cell>Article 1: Article 1: JetBlue announces a deal to buy Spirit Airlines . Fares could surge .</cell></row><row><cell>Article 2: JetBlue -Spirit merger : Airlines have complaints over flights and fees Christopher</cell></row><row><cell>Elliott Special to USA TODAY .</cell></row><row><cell>Article 3: JetBlue announces a deal to buy Spirit Airlines | CNN Business The announcement comes</cell></row><row><cell>a day after Spirit pulled the plug on a deal to merge with Frontier .</cell></row><row><cell>Article 4: Spirit and Frontier pull plug on deal , setting stage for JetBlue to buy ... New York (</cell></row><row><cell>CNN Buiness ) .</cell></row><row><cell>Article 5: Frontier Airlines , Spirit Airlines announce budget airline merger Budget airlines</cell></row><row><cell>Frontier Airlines and Spirit Airlines .</cell></row><row><cell>Question : Which airline announced a deal this week to buy Spirit Airlines ?</cell></row><row><cell>Answer : " JetBlue "</cell></row><row><cell>Gold Output Europe RealTime QA AMA prompt()-chain Example answer() Article 1: 52</cell></row></table><note>to have 3 G coverage , and 50% will have 4 G coverage . A barrier to mobile broadband use is the coverage provided by the mobile service networks . This may mean no mobile network or that Article 5: Mobile edge computing / Combining elements of information technology and t el e c o m m u n i c a t i o n s networking , MEC also allows cellular operators to open their radio access network ( RAN ) to authorized third -parties , such as application developers and content providers . Technical standards for MEC are being developed by the European T e l e c o m m u n i c a t i o ns Standards Institute , which has produced a technical white paper about the concept . MEC</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head></head><label></label><figDesc>Answer the question .Passage : Jane ' s mom went to the shop to buy Jane a backpack for her first day of kindergarten . The large ball crashed right through the table because it was made of styrofoam .</figDesc><table><row><cell>Question : Whose first day ?</cell></row><row><cell>Answer : Jane</cell></row><row><cell>Passage : Mrs . Jenna told Fred she loved him .</cell></row><row><cell>Question : Who loved him ?</cell></row><row><cell>Answer : Mrs . Jenna</cell></row><row><cell>Passage : Joe gave Mark some money so he could buy lunch .</cell></row><row><cell>Question : Who could buy lunch ?</cell></row><row><cell>Answer : Mark</cell></row><row><cell>Passage : Question : What was made of styrofoam ?</cell></row><row><cell>Answer :</cell></row><row><cell>Gold Output</cell></row><row><cell>True</cell></row><row><cell>G.19 WebQuestions (WQ)</cell></row><row><cell>was made of styrofoam</cell></row><row><cell>question()</cell></row><row><cell>Rewrite the input as a question .</cell></row><row><cell>Input : it was made of glass</cell></row><row><cell>Question : What was made of glass ?</cell></row><row><cell>Input : they are funny</cell></row><row><cell>Question : Who or what are funny ?</cell></row><row><cell>Input : he drowned</cell></row><row><cell>Question : Who drowned ?</cell></row><row><cell>Input : wrap around them</cell></row><row><cell>Question : Wrap around who or what ?</cell></row><row><cell>Input : his cat is black</cell></row><row><cell>Question : Whose cat is black ?</cell></row><row><cell>Input : laugh at them</cell></row><row><cell>Question : Laugh at who ?</cell></row><row><cell>Input : her friend jennfier</cell></row><row><cell>Question : Whose friend Jennifer ?</cell></row><row><cell>Input : it was made of styrofoam</cell></row><row><cell>Question :</cell></row><row><cell>Model Output</cell></row><row><cell>What was made of styrofoam ?</cell></row><row><cell>answer()</cell></row><row><cell>56</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We do not use rank-classification scoring, which and use to reduce task complexity, barring the tasks with explicit multiple-choice options (ReCORD, StoryCloze and COPA).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/realtimeqa/realtimeqa_public</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Drew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russ</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simran</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sydney Von Arx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeannette</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brunskill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07258</idno>
		<title level="m">On the opportunities and risks of foundation models</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Calibrate before use: Improving few-shot performance of language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><forename type="middle">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.09690v2</idno>
		<ptr target="https://arxiv.org/pdf/2102.09690.pdf" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08315</idno>
		<title level="m">Surface form competition: Why the highest probability answer isn&apos;t always right</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katarina</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ray</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02155</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multitask prompted training enables zero-shot task generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaid</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Stiegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teven</forename><forename type="middle">Le</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Raja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Tenth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11903</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Can language models learn from explanations in context?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">K</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishita</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Stephanie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kory</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Henry</forename><surname>Mathewson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonia</forename><surname>Tessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">L</forename><surname>Crwswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><forename type="middle">X</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Reframing instructional prompts to gptk&apos;s language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swaroop</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Baral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.07830</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ai chains: Transparent and controllable human-ai interaction by chaining large language model prompts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongshuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carrie</forename><forename type="middle">Jun</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Maieutic prompting: Logically consistent reasoning with recursive explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehun</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianhui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faeze</forename><surname>Brahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Ronan Le Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2205.11822" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">How can we know what language models know? Transactions of the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Araki Araki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">It&apos;s not just size that matters: Small language models are also few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.07118v2</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Snorkel: Rapid training data creation with weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Ehrenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R?</surname></persName>
		</author>
		<idno type="DOI">10.14778/3157794.3157797</idno>
		<ptr target="https://doi.org/10.14778%2F3157794.3157797" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2017-11" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="269" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning dependency structures for weak supervision models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paroma</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Re</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v97/varma19a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>Kamalika Chaudhuri and Ruslan Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Connor</forename><surname>Leahy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.5297715</idno>
		<ptr target="https://doi.org/10.5281/zenodo.5297715" />
		<imprint>
			<date type="published" when="2021-03" />
		</imprint>
	</monogr>
	<note>If you use this software, please cite it using these metadata</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Gpt-j-6b: A 6 billion parameter autoregressive language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aran</forename><surname>Komatsuzaki</surname></persName>
		</author>
		<ptr target="https://www.eleuther.ai/" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Bigscience large open-science open-access multilingual language model</title>
		<ptr target="https://huggingface.co/bigscience/bloom" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Opt: Open pre-trained transformer language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Simig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Punit</forename><surname>Singh Koura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjali</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2205.01068" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Can foundation models wrangle your data?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avanika</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Chami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurel</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.09911</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Can foundation models help us achieve perfect secrecy?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simran</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher R? ; Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Mcclandlish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.08361</idno>
	</analytic>
	<monogr>
		<title level="m">Scaling laws for neural language models</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gehrmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<title level="m">Scaling language modeling with pathways</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Benchmarking generalization via in</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swaroop</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pegah</forename><surname>Alipoormolabashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeganeh</forename><surname>Kordi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>context instructions on 1,600+ language tasks. arXiv</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01652</idno>
		<title level="m">Finetuned language models are zero-shot learners</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Is a question decomposition unit all we need?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pruthvi</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swaroop</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihir</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Baral</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2205.12538" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Selection-inference: Exploiting large language models for interpretable logical reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonia</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.09712</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">What makes good incontext examples for gpt-3?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinghan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">Le</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Data programming: Creating large training sets, quickly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher M De</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Sa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Selsam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R?</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2016/file/6709e8d64a5f47269ed5cea9f625f7ab-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Training complex models with multi-task weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Braden</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Dunnmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreyash</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1810.02840" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fast and three-rious: Speeding up weak supervision with triplet methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayee</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Hooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kayvon</forename><surname>Fatahalian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Re</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v119/fu20a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<editor>Hal Daum? III and Aarti Singh</editor>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Language models in the loop: Incorporating prompting into weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">A</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Braden</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.02318v1</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">SuperGLUE: A stickier benchmark for general-purpose language understanding systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yada</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno>1905.00537</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><forename type="middle">Jake</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelia</forename><surname>Damoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simonyan</surname></persName>
		</author>
		<imprint>
			<pubPlace>Erich Elsen, Jack W</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Training compute-optimal large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sifre</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2203.15556" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Emergent abilities of large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2206.07682" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Lsdsem 2017 shared task: The story cloze test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourselevel Semantics</title>
		<meeting>the 2nd Workshop on Linking Models of Lexical, Sentential and Discourselevel Semantics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="46" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Adversarial nli: A new benchmark for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D13-1170" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 25th international conference on world wide web</title>
		<meeting>the 25th international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="507" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungo</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoichi</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akari</forename><surname>Ronan Le Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyan</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Inui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.13332</idno>
		<title level="m">Realtime qa: What&apos;s the answer right now? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><forename type="middle">N</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D13-1160" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Webgpt: Browser-assisted question-answering with human feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suchir</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shantanu</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyna</forename><surname>Eloundou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Button</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno>abs/2112.09332</idno>
		<ptr target="https://arxiv.org/abs/2112.09332" />
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1910.10683" />
		<imprint>
			<date type="published" when="1910" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Xin</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nihal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abheesht</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taewoon</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>Bari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fevry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.01279</idno>
		<title level="m">An integrated development environment and repository for natural language prompts</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Ethical and social risks of harm from language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Weidinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maribeth</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Conor</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myra</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borja</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atoosa</forename><surname>Kasirzadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.04359</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huggingface</surname></persName>
		</author>
		<ptr target="https://huggingface.co/models" />
		<imprint>
			<date type="published" when="2021-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Openai</surname></persName>
		</author>
		<ptr target="https://openai.com/api/" />
		<imprint>
			<date type="published" when="2021-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Robust principal component analysis?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><forename type="middle">J</forename><surname>Cand?s</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wright</surname></persName>
		</author>
		<idno type="DOI">10.1145/1970392.1970395</idno>
		<ptr target="https://doi.org/10.1145/1970392.1970395" />
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2011-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/W04-1013" />
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: Unanswerable questions for squad</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="784" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Boolq: Exploring the surprising difficulty of natural yes/no questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2924" to="2936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The commitmentbank: Investigating projection in naturally occurring discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine De</forename><surname>Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandy</forename><surname>Simons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Tonhauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of Sinn und Bedeutung</title>
		<meeting>Sinn und Bedeutung</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="107" to="124" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
