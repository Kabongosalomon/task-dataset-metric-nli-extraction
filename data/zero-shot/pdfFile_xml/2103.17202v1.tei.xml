<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GrooMeD-NMS: Grouped Mathematically Differentiable NMS for Monocular 3D Object Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Kumar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrick</forename><surname>Brazil</surname></persName>
							<email>brazilga@msu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GrooMeD-NMS: Grouped Mathematically Differentiable NMS for Monocular 3D Object Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Backbone Score 2D 3D s O IoU Lbefore B Inference NMS Predictions r Training Lbefore (a) Conventional NMS Pipeline Backbone Score 2D 3D s O IoU Lbefore B Inference GrooMeD NMS Predictions r Training Lafter (b) GrooMeD-NMS Pipeline s s O Sort Group G lower p ? ? ? ? ? ? I M P ? ? ? ? ? ? . r &gt; v d Forward Backward (c) GrooMeD-NMS layer Figure 1: Overview of our method. (a) Conventional object detection has a mismatch between training and inference as it uses NMS only in inference. (b)</p><p>To address this, we propose a novel GrooMeD-NMS layer, such that the network is trained end-to-end with NMS applied. s and r denote the score of boxes B before and after the NMS respectively. O denotes the matrix containing IoU2D overlaps of B. L bef ore denotes the losses before the NMS, while L af ter denotes the loss after the NMS. (c) GrooMeD-NMS layer calculates r in a differentiable manner giving gradients from L af ter when the best-localized box corresponding to an object is not selected after NMS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Modern 3D object detectors have immensely benefited from the end-to-end learning idea. However, most of them use a post-processing algorithm called Non-Maximal Suppression (NMS) only during inference. While there were attempts to include NMS in the training pipeline for tasks such as 2D object detection, they have been less widely adopted due to a non-mathematical expression of the NMS. In this paper, we present and integrate GrooMeD-NMSa novel Grouped Mathematically Differentiable NMS for monocular 3D object detection, such that the network is trained end-to-end with a loss on the boxes after NMS. We first formulate NMS as a matrix operation and then group and mask the boxes in an unsupervised manner to obtain a simple closed-form expression of the NMS. GrooMeD-NMS addresses the mismatch between training and inference pipelines and, therefore, forces the network to select the best 3D box in a differentiable manner. As a result, GrooMeD-NMS achieves state-of-the-art monocular 3D object detection results on the KITTI benchmark dataset performing comparably to monocular video-based methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To address this, we propose a novel GrooMeD-NMS layer, such that the network is trained end-to-end with NMS applied. s and r denote the score of boxes B before and after the NMS respectively. O denotes the matrix containing IoU2D overlaps of B. L bef ore denotes the losses before the NMS, while L af ter denotes the loss after the NMS. (c) GrooMeD-NMS layer calculates r in a differentiable manner giving gradients from L af ter when the best-localized box corresponding to an object is not selected after NMS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Modern 3D object detectors have immensely benefited from the end-to-end learning idea. However, most of them use a post-processing algorithm called Non-Maximal Suppression (NMS) only during inference. While there were attempts to include NMS in the training pipeline for tasks such as 2D object detection, they have been less widely adopted due to a non-mathematical expression of the NMS. In this paper, we present and integrate GrooMeD-NMSa novel Grouped Mathematically Differentiable NMS for monocular 3D object detection, such that the network is trained end-to-end with a loss on the boxes after NMS. We first formulate NMS as a matrix operation and then group and mask the boxes in an unsupervised manner to obtain a simple closed-form expression of the NMS. GrooMeD-NMS addresses the mismatch between training and inference pipelines and, therefore, forces the network to select the best 3D box in a differentiable manner. As a result, GrooMeD-NMS achieves state-of-the-art monocular 3D object detection results on the KITTI benchmark dataset performing comparably to monocular video-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>3D object detection is one of the fundamental problems in computer vision, where the task is to infer 3D information of the object. Its applications include augmented reality <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b67">68]</ref>, robotics <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b73">74]</ref>, medical surgery <ref type="bibr" target="#b69">[70]</ref>, and, more recently path planning and scene understanding in autonomous driving <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b76">77]</ref>. Most of the 3D object detectors <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b76">77]</ref> are extensions of the 2D object detector Faster R-CNN <ref type="bibr" target="#b68">[69]</ref>, which relies on the end-to-end learning idea to achieve State-of-the-Art (SoTA) object detection. Some of these methods have proposed changing architectures <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b76">77]</ref> or losses <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b17">18]</ref>. Others have tried incorporating confidence <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b76">77]</ref> or temporal cues <ref type="bibr" target="#b11">[12]</ref>.</p><p>Almost all of them output a massive number of boxes for each object and, thus, rely on post-processing with a greedy <ref type="bibr" target="#b64">[65]</ref> clustering algorithm called Non-Maximal Suppression (NMS) during inference to reduce the number of false positives and increase performance. However, these works have largely overlooked NMS's inclusion in training leading to an apparent mismatch between training and inference pipelines as the losses are applied on all boxes before NMS but not on final boxes after NMS (see <ref type="figure" target="#fig_0">Fig. 1(a)</ref>).</p><p>We also find that 3D object detection suffers a greater mismatch between classification and 3D localization compared to that of 2D localization, as discussed further in Sec. A3.2 of the supplementary and observed in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b75">76]</ref>. Hence, our focus is 3D object detection.</p><p>Earlier attempts to include NMS in the training pipeline <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b64">65]</ref> have been made for 2D object detection where the improvements are less visible. Recent efforts to improve the correlation in 3D object detection involve calculating <ref type="bibr" target="#b76">[77,</ref><ref type="bibr" target="#b78">79]</ref> or predicting <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b75">76]</ref> the scores via likelihood estimation <ref type="bibr" target="#b39">[40]</ref> or enforcing the correlation explicitly <ref type="bibr" target="#b34">[35]</ref>. Although this improves the 3D detection performance, improvements are limited as their training pipeline is not end to end in the absence of a differentiable NMS.</p><p>To address the mismatch between training and inference pipelines as well as the mismatch between classification and 3D localization, we propose including the NMS in the training pipeline, which gives a useful gradient to the network so that it figures out which boxes are the best-localized in 3D and, therefore, should be ranked higher (see <ref type="figure" target="#fig_0">Fig. 1(b)</ref>).</p><p>An ideal NMS for inclusion in the training pipeline should be not only differentiable but also parallelizable. Unfortunately, the inference-based classical NMS and Soft-NMS <ref type="bibr" target="#b7">[8]</ref> are greedy, set-based and, therefore, not parallelizable <ref type="bibr" target="#b64">[65]</ref>. To make the NMS parallelizable, we first formulate the classical NMS as matrix operation and then obtain a closed-form mathematical expression using elementary matrix operations such as matrix multiplication, matrix inversion, and clipping. We then replace the threshold pruning in the classical NMS with its softer version <ref type="bibr" target="#b7">[8]</ref> to get useful gradients. These two changes make the NMS GPU-friendly, and the gradients are backpropagated. We next group and mask the boxes in an unsupervised manner, which removes the matrix inversion and simplifies our proposed differentiable NMS expression further. We call this NMS as Grouped Mathematically Differentiable Non-Maximal Suppression (GrooMeD-NMS).</p><p>In summary, the main contributions of this work include:</p><p>? This is the first work to propose and integrate a closedform mathematically differentiable NMS for object detection, such that the network is trained end-to-end with a loss on the boxes after NMS. ? We propose an unsupervised grouping and masking on the boxes to remove the matrix inversion in the closedform NMS expression. ? We achieve SoTA monocular 3D object detection performance on the KITTI dataset performing comparably to monocular video-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>3D Object Detection. Recent success in 2D object detection <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b68">69]</ref> has inspired people to infer 3D information from a single 2D (monocular) image. How-ever, the monocular problem is ill-posed due to the inherent scale/depth ambiguity <ref type="bibr" target="#b81">[82]</ref>. Hence, approaches use additional sensors such as LiDAR <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b87">88]</ref>, stereo <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b86">87]</ref> or radar <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b83">84]</ref>. Although LiDAR depth estimations are accurate, LiDAR data is sparse <ref type="bibr" target="#b32">[33]</ref> and computationally expensive to process <ref type="bibr" target="#b81">[82]</ref>. Moreover, LiDARs are expensive and do not work well in severe weather <ref type="bibr" target="#b81">[82]</ref>. Hence, there have been several works on monocular 3D object detection. Earlier approaches <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b61">62]</ref> use hand-crafted features, while the recent ones are all based on deep learning. Some of these methods have proposed changing architectures <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b81">82]</ref> or losses <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b17">18]</ref>. Others have tried incorporating confidence <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b76">77]</ref>, augmentation <ref type="bibr" target="#b79">[80]</ref>, depth in convolution <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">22]</ref> or temporal cues <ref type="bibr" target="#b11">[12]</ref>. Our work proposes to incorporate NMS in the training pipeline of monocular 3D object detection. Non-Maximal Suppression. NMS has been used to reduce false positives in edge detection <ref type="bibr" target="#b71">[72]</ref>, feature point detection <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b56">57]</ref>, face detection <ref type="bibr" target="#b84">[85]</ref>, human detection <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b19">20]</ref> as well as SoTA 2D <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b68">69]</ref> and 3D detection <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b81">82]</ref>. Modifications to NMS in 2D detection <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b64">65]</ref>, 2D pedestrian detection <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b72">73]</ref>, 2D salient object detection <ref type="bibr" target="#b90">[91]</ref> and 3D detection <ref type="bibr" target="#b75">[76]</ref> can be classified into three categories -inference NMS <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b75">76]</ref>, optimization-based NMS <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b90">91]</ref> and neural network based NMS <ref type="bibr">[30-32, 51, 65]</ref>.</p><p>The inference NMS <ref type="bibr" target="#b7">[8]</ref> changes the way the boxes are pruned in the final set of predictions. <ref type="bibr" target="#b75">[76]</ref> uses weighted averaging to update the z-coordinate after NMS. <ref type="bibr" target="#b72">[73]</ref> solves quadratic unconstrained binary optimization while <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b80">81]</ref> and <ref type="bibr" target="#b90">[91]</ref> use point processes and MAP based inference respectively. <ref type="bibr" target="#b20">[21]</ref> and <ref type="bibr" target="#b85">[86]</ref> formulate NMS as a structured prediction task for isolated and all object instances respectively. The neural network NMS use a multi-layer network and message-passing to approximate NMS <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b64">65]</ref> or to predict the NMS threshold adaptively <ref type="bibr" target="#b50">[51]</ref>. <ref type="bibr" target="#b29">[30]</ref> approximates the sub-gradients of the network without modelling NMS via a transitive relationship. Our work proposes a grouped closed-form mathematical approximation of the classical NMS and does not require multiple layers or message-passing. We detail these differences in Sec. 4.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Background</head><formula xml:id="formula_0">o i ) = 1 denotes the box b i is suppressed while p(o i ) = 0 denotes b i is kept in D.</formula><p>The NMS threshold N t is the threshold for which two boxes need in order for the non-maximum to be suppressed. The temperature ? controls the shape of the exponential and sigmoidal pruning functions p. v thresholds the rescores in GrooMeD and Soft-NMS <ref type="bibr" target="#b8">[9]</ref> to decide if the box remains valid after NMS.</p><formula xml:id="formula_1">B is partitioned into different groups G = {G k }. B G k denotes the subset of B belonging to group k. Thus, B G k = {b i } ? b i ? G k and B G k ? B G l = ? ? k = l.</formula><p>G k in the subscript of a variable denotes its subset corresponding to B G k . Thus, s G k and r G k denote the scores and the rescores of B G k respectively. ? denotes the maximum group size.</p><p>? denotes the logical OR while x denotes clipping of x in the range [0, 1]. Formally,</p><formula xml:id="formula_2">x = ? ? ? ? ? 1, x &gt; 1 x, 0 ? x ? 1 0, x &lt; 0 (1)</formula><p>|s| denotes the number of elements in s. l l in the subscript denotes the lower triangular version of the matrix without the principal diagonal.</p><p>denotes the element-wise multiplication. I denotes the identity matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Classical and Soft-NMS</head><p>NMS is one of the building blocks in object detection whose high-level goal is to iteratively suppress boxes which have too much IoU with a nearby high-scoring box. We first give an overview of the classical and Soft-NMS <ref type="bibr" target="#b7">[8]</ref>, which are greedy and used in inference. Classical NMS uses the idea that the score of a box having a high IoU 2D overlap with any of the selected boxes should be suppressed to zero. That is, it uses a hard pruning p without any temperature ? . Soft-NMS makes this pruning soft via temperature ? . Thus,  classical and Soft-NMS only differ in the choice of p. We reproduce them in Alg. 1 using our notations.</p><formula xml:id="formula_3">MG k ? zeros (|G k | , |G k |) Prepare mask 10 MG k [:, G k [1]] ? 1 First col of M G k 11 rG k ? (IG k ? MG k PG k ) sG k</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">GrooMeD-NMS</head><p>Classical NMS (Alg. 1) uses argmax and greedily calculates the rescore r i of boxes B and, is thus not parallelizable or differentiable <ref type="bibr" target="#b64">[65]</ref>. We wish to find its smooth approximation in closed-form for including in the training pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Formulation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Sorting</head><p>Classical NMS uses the non-differentiable hard argmax operation (Line 6 of Alg. 1). We remove the argmax by hard sorting the scores s and O in decreasing order (lines 2-3 of Alg. 2). We also try making the sorting soft. Note that we require the permutation of s to sort O. Most soft sorting methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b62">63]</ref> apply the soft permutation to the same vector. Only two other methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b63">64]</ref> can apply the soft permutation to another vector. Both methods use O n 2 computations for soft sorting <ref type="bibr" target="#b6">[7]</ref>. We implement <ref type="bibr" target="#b63">[64]</ref> and find that <ref type="bibr" target="#b63">[64]</ref> is overly dependent on temperature ? to break out the ranks, and its gradients are too unreliable to train our model. Hence, we stick with the hard sorting of s and O.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">NMS as a Matrix Operation</head><p>The rescoring process of the classical NMS is greedy setbased <ref type="bibr" target="#b64">[65]</ref> and only considers overlaps with unsuppressed boxes. We first generalize this rescoring by accounting for the effect of all (suppressed and unsuppressed) boxes as</p><formula xml:id="formula_4">r i ? max ? ? s i ? i?1 j=1 p(o ij )r j , 0 ? ? (2)</formula><p>using the relaxation of logical OR operator as <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b46">47]</ref>. See Sec. A1 of the supplementary material for an alternate explanation of (2). The presence of r j on the RHS of (2) prevents suppressed boxes from influencing other boxes hugely. When p outputs discretely as {0, 1} as in classical NMS, scores s i are guaranteed to be suppressed to r i = 0 or left unchanged r i = s i thereby implying r i ? s i ? i. We write the rescores r in a matrix formulation as</p><formula xml:id="formula_5">? ? ? ? ? ? ? r 1 r 2 r 3 . . . r n ? ? ? ? ? ? ? ? max ? ? ? ? ? ? ? ? ? ? ? ? ? ? c 1 c 2 c 3 . . . c n ? ? ? ? ? ? ? , ? ? ? ? ? ? ? 0 0 0 . . . 0 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,<label>(3)</label></formula><p>with</p><formula xml:id="formula_6">? ? ? ? ? ? ? c 1 c 2 c 3 . . . c n ? ? ? ? ? ? ? = ? ? ? ? ? ? ? s 1 s 2 s 3 . . . s n ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0 0 . . . 0 p(o 21 ) 0 . . . 0 p(o 31 ) p(o 32 ) . . . 0 . . . . . . . . . . . . p(o n1 ) p(o n2 ) . . . 0 ? ? ? ? ? ? ? ? ? ? ? ? ? ? r 1 r 2 r 3 . . . r n ? ? ? ? ? ? ? .<label>(4)</label></formula><p>The above two equations are written compactly as</p><formula xml:id="formula_7">r ? max(s ? Pr, 0),<label>(5)</label></formula><p>where P, called the Prune Matrix, is obtained when the pruning function p operates element-wise on O l l . Maximum operation makes (5) non-linear <ref type="bibr" target="#b40">[41]</ref> and, thus, difficult to solve. However, to avoid recursion, we use</p><formula xml:id="formula_8">r ? (I + P) ?1 s ,<label>(6)</label></formula><p>as the solution to <ref type="bibr" target="#b4">(5)</ref> with I being the identity matrix. Intuitively, if the matrix inversion is considered division in <ref type="bibr" target="#b5">(6)</ref> and the boxes have overlaps, the rescores are the scores divided by a number greater than one and are, therefore, lesser than scores. If the boxes do not overlap, the division is by one and rescores equal scores. Note that the I + P in <ref type="formula" target="#formula_8">(6)</ref> is a lower triangular matrix with ones on the principal diagonal. Hence, I + P is always full rank and, therefore, always invertible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Grouping</head><p>We next observe that the object detectors output multiple boxes for an object, and a good detector outputs boxes wherever it finds objects in the monocular image. Thus, we cluster the boxes in an image in an unsupervised manner based on IoU 2D overlaps to obtain the groups G. Grouping thus mimics the grouping of the classical NMS, but does not rescore the boxes. As clustering limits interactions to intra-group interactions among the boxes, we write <ref type="formula" target="#formula_8">(6)</ref> as</p><formula xml:id="formula_9">r G k ? (I G k + P G k ) ?1 s G k .<label>(7)</label></formula><p>This results in taking smaller matrix inverses in <ref type="formula" target="#formula_9">(7)</ref> than <ref type="formula" target="#formula_8">(6)</ref>.</p><p>We use a simplistic grouping algorithm, i.e., we form a group G k with boxes having high IoU 2D overlap with the top-ranked box, given that we sorted the scores. As the group size is limited by ?, we choose a minimum of ? and the number of boxes in G k . We next delete all the boxes of this group and iterate until we run out of boxes. Also, grouping uses IoU 2D since we can achieve meaningful clustering in 2D. We detail this unsupervised grouping in Alg. 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Masking</head><p>Classical NMS considers the IoU 2D of the top-scored box with other boxes. This consideration is equivalent to only keeping the column of O corresponding to the top box while assigning the rest of the columns to be zero. We implement this through masking of P G k . Let M G k denote the binary mask corresponding to group G k . Then, entries in the binary matrix M G k in the column corresponding to the topscored box are 1 and the rest are 0. Hence, only one of the</p><formula xml:id="formula_10">columns in M G k P G k is non-zero. Now, I G k +M G k P G k</formula><p>is a Frobenius matrix (Gaussian transformation) and we, therefore, invert this matrix by simply subtracting the second term <ref type="bibr" target="#b27">[28]</ref>. In other words,</p><formula xml:id="formula_11">(I G k + M G k P G k ) ?1 = I G k ? M G k P G k .</formula><p>Hence, we simplify <ref type="bibr" target="#b6">(7)</ref> further to get</p><formula xml:id="formula_12">r G k ? (I G k ? M G k P G k ) s G k .<label>(8)</label></formula><p>Thus, masking allows to bypass the computationally expensive matrix inverse operation altogether.</p><p>We call the NMS based on <ref type="bibr" target="#b7">(8)</ref> as Grouped Mathematically Differentiable Non-Maximal Suppression or GrooMeD-NMS. We summarize the complete GrooMeD-NMS in Alg. 2 and show its block-diagram in <ref type="figure" target="#fig_0">Fig. 1</ref>(c). GrooMeD-NMS in <ref type="figure" target="#fig_0">Fig. 1(c)</ref> provides two gradients -one through s and other through O.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.5">Pruning Function</head><p>As explained in Sec. 3.1, the pruning function p decides whether to keep the box in the final set of predictions D or not based on IoU 2D overlaps, i.e., p</p><formula xml:id="formula_13">(o i ) = 1 denotes the box b i is suppressed while p(o i ) = 0 denotes b i is kept in D.</formula><p>Classical NMS uses the threshold as the pruning function, which does not give useful gradients. Therefore, we considered three different functions for p: Linear, a temperature (? )-controlled Exponential, and Sigmoidal function.</p><p>? Linear Linear pruning function <ref type="bibr" target="#b7">[8]</ref> is p(o) = o.</p><p>? Exponential Exponential pruning function <ref type="bibr" target="#b7">[8]</ref> is</p><formula xml:id="formula_14">p(o) = 1 ? exp ? o 2 ? . ? Sigmoidal Sigmoidal pruning function is p(o) = ? o?Nt ?</formula><p>with ? denoting the standard sigmoid. Sigmoidal function appears as the binary cross entropy relaxation of the subset selection problem <ref type="bibr" target="#b59">[60]</ref>. We show these pruning functions in <ref type="figure" target="#fig_3">Fig. 2</ref>. The ablation studies (Sec. 5.4) show that choosing p as Linear yields the simplest and the best GrooMeD-NMS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Differences from Existing NMS</head><p>Although no differentiable NMS has been proposed for the monocular 3D object detection, we compare our GrooMeD-NMS with the NMS proposed for 2D object detection, 2D pedestrian detection, 2D salient object detection, and 3D object detection in Tab. 1. No method described in Tab. 1 has a matrix-based closed-form mathematical expression of the NMS. Classical, Soft <ref type="bibr" target="#b7">[8]</ref> and Distance-NMS <ref type="bibr" target="#b75">[76]</ref> are used at the inference time, while GrooMeD-NMS is used during both training and inference. Distance-NMS <ref type="bibr" target="#b75">[76]</ref> updates the z-coordinate of the box after NMS as the weighted average of the z-coordinates of top-? boxes. QUBO-NMS <ref type="bibr" target="#b72">[73]</ref>, Point-NMS <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b80">81]</ref>, and MAP-NMS <ref type="bibr" target="#b90">[91]</ref> are not used in end-to-end training. <ref type="bibr" target="#b2">[3]</ref> proposes a trainable Point-NMS. The Structured-SVM based NMS <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b85">86]</ref> rely on structured SVM to obtain the rescores. </p><formula xml:id="formula_15">O (|G|) Soft-NMS [8] Soft - O (|G|) Distance-NMS [76] Hard - O (|G|) QUBO-NMS [73]</formula><p>Optimization --Point-NMS <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b80">81]</ref> Point Process --Trainable Point-NMS <ref type="bibr" target="#b2">[3]</ref> Point Process --MAP-NMS <ref type="bibr" target="#b90">[91]</ref> MAP --Structured-NMS <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b85">86]</ref> SSVM --Adaptive-NMS <ref type="bibr" target="#b50">[51]</ref> Hard &gt; 1 O (|G|) NN-NMS <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b64">65]</ref> Neural Network </p><formula xml:id="formula_16">&gt; 1 O (1) GrooMeD-NMS (Ours) Matrix Soft 1 O (|G|)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Target Assignment and Loss Function</head><p>Target Assignment. Our method consists of M3D-RPN <ref type="bibr" target="#b9">[10]</ref> and uses binning and self-balancing confidence <ref type="bibr" target="#b11">[12]</ref>. The boxes' self-balancing confidence are used as scores s, which pass through the GrooMeD-NMS layer to obtain the rescores r. The rescores signal the network if the best box has not been selected for a particular object. We extend the notion of the best 2D box <ref type="bibr" target="#b64">[65]</ref> to 3D. The best box has the highest product of IoU 2D and gIoU 3D <ref type="bibr" target="#b70">[71]</ref> with ground truth g l . If the product is greater than a certain threshold ?, it is assigned a positive label. Mathematically,</p><formula xml:id="formula_17">target(b i ) = ? ? ? 1, if ? g l st i = argmax q(b j , g l ) and q(b i , g l ) ? ? 0, otherwise (9) with q(b j , g l ) = IoU 2D (b j , g l ) 1+gIoU3D(bj ,g l ) 2</formula><p>. gIoU 3D is known to provide signal even for non-intersecting boxes <ref type="bibr" target="#b70">[71]</ref>, where the usual IoU 3D is always zero. Therefore, we use gIoU 3D instead of regular IoU 3D for figuring out the best box in 3D as many 3D boxes have a zero IoU 3D overlap with the ground truth. For calculating gIoU 3D , we first calculate the volume V and hull volume V hull of the 3D boxes. V hull is the product of gIoU 2D in Birds Eye View (BEV), removing the rotations and hull of the Y dimension. gIoU 3D is then given by</p><formula xml:id="formula_18">gIoU 3D (b i , b j ) = V (b i ? b j ) V (b i ? b j ) + V (b i ? b j ) V hull (b i , b j ) ? 1.<label>(10)</label></formula><p>Loss Function. Generally the number of best boxes is less than the number of ground truths in an image, as there could be some ground truth boxes for which no box is predicted. The tiny number of best boxes introduces a far-heavier skew than the foreground-background classification. Thus, we use the modified AP-Loss <ref type="bibr" target="#b13">[14]</ref> as our loss after NMS since AP-Loss does not suffer from class imbalance <ref type="bibr" target="#b13">[14]</ref>. Vanilla AP-Loss treats boxes of all images in a minibatch equally, and the gradients are back-propagated through all the boxes. We remove this condition and rank boxes in an image-wise manner. In other words, if the best boxes are correctly ranked in one image and are not in the second, then the gradients only affect the boxes of the second image. We call this modification of AP-Loss as Imagewise AP-Loss. In other words,</p><formula xml:id="formula_19">L Imagewise = 1 N N m=1 AP(r (m) , target(B (m) )),<label>(11)</label></formula><p>where r (m) and B (m) denote the rescores and the boxes of the m th image in a mini-batch respectively. This is different from previous NMS approaches <ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b64">65]</ref>, which use classification losses. Our ablation studies (Sec. 5.4) show that the Imagewise AP-Loss is better suited to be used after NMS than the classification loss. Our overall loss function is thus given by L = L bef ore + ?L af ter where L bef ore denotes the losses before the NMS including classification, 2D and 3D regression as well as confidence losses, and L af ter denotes the loss term after the NMS, which is the Imagewise AP-Loss with ? being the weight. See Sec. A2 of the supplementary material for more details of the loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>Our experiments use the most widely used KITTI autonomous driving dataset <ref type="bibr" target="#b24">[25]</ref>. We modify the publiclyavailable PyTorch <ref type="bibr" target="#b58">[59]</ref> code of Kinematic-3D <ref type="bibr" target="#b11">[12]</ref>. <ref type="bibr" target="#b11">[12]</ref> uses DenseNet-121 <ref type="bibr" target="#b33">[34]</ref> trained on ImageNet as the backbone and n h = 1,024 using 3D-RPN settings of <ref type="bibr" target="#b9">[10]</ref>. As <ref type="bibr" target="#b11">[12]</ref> is a video-based method while GrooMeD-NMS is an image-based method, we use the best image model of <ref type="bibr" target="#b11">[12]</ref> henceforth called Kinematic (Image) as our baseline for a fair comparison. Kinematic (Image) is built on M3D-RPN <ref type="bibr" target="#b9">[10]</ref> and uses binning and self-balancing confidence. Data Splits. There are three commonly used data splits of the KITTI dataset; we evaluate our method on all three.</p><p>Test Split: Official KITTI 3D benchmark [1] consists of 7,481 training and 7,518 testing images <ref type="bibr" target="#b24">[25]</ref>.</p><p>Val 1 Split: It partitions the 7,481 training images into 3,712 training and 3,769 validation images <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b76">77]</ref>.</p><p>Val 2 Split: It partitions the 7,481 training images into 3,682 training and 3,799 validation images <ref type="bibr" target="#b88">[89]</ref>. Training. Training is done in two phases -warmup and full <ref type="bibr" target="#b11">[12]</ref>. We initialize the model with the confidence prediction branch from warmup weights and finetune using the self-balancing loss <ref type="bibr" target="#b11">[12]</ref> and Imagewise AP-Loss <ref type="bibr" target="#b13">[14]</ref> after our GrooMeD-NMS. See Sec. A3.1 of the supplementary material for more training details. We keep the weight ? at 0.05. Unless otherwise stated, we use p as the Linear function (this does not require ? ) with ? = 100. N t , v and ? are set to 0.4 <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref>, 0.3 and 0.3 respectively. Inference. We multiply the class and predicted confidence to get the box's overall score in inference as in <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b82">83]</ref>. See Sec. 5.2 for training and inference times. Evaluation Metrics. KITTI uses AP 3D|R40 metric to evaluate object detection following <ref type="bibr" target="#b76">[77,</ref><ref type="bibr" target="#b78">79]</ref>. KITTI benchmark evaluates on three object categories: Easy, Moderate and Hard. It assigns each object to a category based on its occlusion, truncation, and height in the image space. The AP 3D|R40 performance on the Moderate category compares different models in the benchmark <ref type="bibr" target="#b24">[25]</ref>. We focus primarily on the Car class following <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">KITTI Test 3D Object Detection</head><p>Tab. 2 summarizes the results of 3D object detection and BEV evaluation on KITTI Test Split. The results in Tab. 2 show that GrooMeD-NMS outperforms the baseline M3D-RPN [10] by a significant margin and several other SoTA methods on both the tasks. GrooMeD-NMS also outperforms augmentation based approach MoVi-3D [80] and depth-convolution based D4LCN <ref type="bibr" target="#b21">[22]</ref>. Despite being an image-based method, GrooMeD-NMS performs competitively to the video-based method Kinematic (Video) <ref type="bibr" target="#b11">[12]</ref>, outperforming it on the most-challenging Hard set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">KITTI Val 1 3D Object Detection</head><p>Results. Tab. 3 summarizes the results of 3D object detection and BEV evaluation on KITTI Val 1 Split at two   IoU 3D thresholds of 0.7 and 0.5 <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18]</ref>. The results in Tab. 3 show that GrooMeD-NMS outperforms the baseline of M3D-RPN <ref type="bibr" target="#b9">[10]</ref> and Kinematic (Image) <ref type="bibr" target="#b11">[12]</ref> by a significant margin. Interestingly, GrooMeD-NMS (an imagebased method) also outperforms the video-based method Kinematic (Video) <ref type="bibr" target="#b11">[12]</ref> on most of the metrics. Thus, GrooMeD-NMS performs best on 6 out of the 12 cases (3 categories ? 2 tasks ? 2 thresholds) while second-best on all other cases. The performance is especially impressive since the biggest improvements are shown on the Moderate and Hard set, where objects are more distant and occluded.</p><p>AP 3D at different depths and IoU 3D thresholds. We next compare the AP 3D performance of GrooMeD-NMS and Kinematic (Image) on linear and log scale for objects at different depths of <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b59">60]</ref> meters and IoU 3D matching criteria of 0.3 ? 0.7 in <ref type="figure" target="#fig_4">Fig. 3</ref> as in <ref type="bibr" target="#b11">[12]</ref>. <ref type="figure" target="#fig_4">Fig. 3</ref> shows that GrooMeD-NMS outperforms the Kinematic (Image) <ref type="bibr" target="#b11">[12]</ref> at all depths and all IoU 3D thresholds.</p><p>Comparisons with other NMS. We compare with the clas- sical NMS, Soft-NMS <ref type="bibr" target="#b7">[8]</ref> and Distance-NMS <ref type="bibr" target="#b75">[76]</ref> in Tab. 4. More detailed results are in Tab. 8 of the supplementary material. The results show that NMS inclusion in the training pipeline benefits the performance, unlike <ref type="bibr" target="#b7">[8]</ref>, which suggests otherwise. Training with GrooMeD-NMS helps because the network gets an additional signal through the GrooMeD-NMS layer whenever the best-localized box corresponding to an object is not selected. Interestingly, Tab. 4 also suggests that replacing GrooMeD-NMS with the classical NMS in inference does not affect the performance. Score-IoU 3D Plot. We further correlate the scores with IoU 3D after NMS of our model with two baselines -M3D-RPN <ref type="bibr" target="#b9">[10]</ref> and Kinematic (Image) <ref type="bibr" target="#b11">[12]</ref> and also the Kinematic (Video) <ref type="bibr" target="#b11">[12]</ref> in <ref type="figure" target="#fig_5">Fig. 4</ref>. We obtain the best correlation of 0.345 exceeding the correlations of M3D-RPN, Kinematic (Image) and, also <ref type="bibr">Kinematic (Video)</ref>. This proves that including NMS in the training pipeline is beneficial.</p><p>Training and Inference Times. We now compare the training and inference times of including GrooMeD-NMS in the pipeline. Warmup training phase takes about 13 hours to train on a single 12 GB GeForce GTX Titan-X GPU. Full training phase of Kinematic (Image) and GrooMeD-NMS takes about 8 and 8.5 hours respectively. The inference time per image using classical and GrooMeD-NMS is 0.12 and 0.15 ms respectively. Tab. 4 suggests that changing the NMS from GrooMeD to classical during inference does not alter the performance. Then, the inference time of our method is the same as 0.12 ms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">KITTI Val 2 3D Object Detection</head><p>Tab. 5 summarizes the results of 3D object detection and BEV evaluation on KITTI Val 2 Split at two IoU 3D thresh-  olds of 0.7 and 0.5 <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18]</ref>. Again, we use M3D-RPN <ref type="bibr" target="#b9">[10]</ref> and Kinematic (Image) <ref type="bibr" target="#b11">[12]</ref> as our baselines. We evaluate the released model of M3D-RPN <ref type="bibr" target="#b9">[10]</ref> using the KITTI metric. <ref type="bibr" target="#b11">[12]</ref> does not report Val 2 results, so we retrain on Val 2 using their public code. The results in Tab. 5 show that GrooMeD-NMS performs best in all cases. This is again impressive because the improvements are shown on Moderate and Hard set, consistent with Tabs. 2 and 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Ablation Studies</head><p>Tab. 6 compares the modifications of our approach on KITTI Val 1 Cars. Unless stated otherwise, we stick with the experimental settings described in Sec. 5. Using a confidence head (Conf+No NMS) proves beneficial compared to the warmup model (No Conf+No NMS), which is consistent with the observations of <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b75">76]</ref>. Further, GrooMeD-NMS on classification scores (denoted by No Conf + NMS) is detrimental as the classification scores are not suited for localization <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b34">35]</ref>. Training the warmup model and then finetuning also works better than training without warmup as in <ref type="bibr" target="#b11">[12]</ref> since the warmup phase allows GrooMeD-NMS to carry meaningful grouping of the boxes.</p><p>As described in Sec. 4.1.5, in addition to Linear, we compare two other functions for pruning function p: Exponential and Sigmoidal. Both of them do not perform as well as the Linear p possibly because they have vanishing gradients close to overlap of zero or one. Grouping and masking both help our model to reach a better minimum. As described in Sec. 4.3, Imagewise AP loss is better than the Vanilla AP loss since it treats boxes of two images differently. Imagewise AP also performs better than the binary cross-entropy (BCE) loss proposed in <ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b64">65]</ref>. Using the product of self-balancing confidence and classification scores instead of using them individually as the scores to the NMS in inference is better, consistent with <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b82">83]</ref>. Class confidence performs worse since it does not have the localization information while the self-balancing confidence (Pred) gives the localization without considering whether the box belongs to foreground or background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this paper, we present and integrate GrooMeD-NMSa novel Grouped Mathematically Differentiable NMS for monocular 3D object detection, such that the network is trained end-to-end with a loss on the boxes after NMS. We first formulate NMS as a matrix operation and then do unsupervised grouping and masking of the boxes to obtain a simple closed-form expression of the NMS. GrooMeD-NMS addresses the mismatch between training and inference pipelines and, therefore, forces the network to select the best 3D box in a differentiable manner. As a result, GrooMeD-NMS achieves state-of-the-art monocular 3D object detection results on the KITTI benchmark dataset. Although our implementation demonstrates monocular 3D object detection, GrooMeD-NMS is fairly generic for other object detection tasks. Future work includes applying this method to tasks such as LiDAR-based 3D object detection and pedestrian detection. 3D Object Detection</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A1. Detailed Explanation of NMS as a Matrix Operation</head><p>The rescoring process of the classical NMS is greedy setbased <ref type="bibr" target="#b64">[65]</ref> and calculates the rescore for a box i (Line 10 of Alg. 1) as</p><formula xml:id="formula_20">r i = s i j?d&lt;i (1 ? p(o ij )) ,<label>(12)</label></formula><p>where d &lt;i is defined as the box indices sampled from d having higher scores than box i. For example, let us consider that d = {1, 5, 7, 9}. Then, for i = 7, d &lt;i = {1, 5} while for i = 1, d &lt;i = ? with ? denoting the empty set. This is possible since we had sorted the scores s and O in decreasing order (Lines 2-3 of Alg. 2) to remove the non-differentiable hard argmax operation of the classical NMS (Line 6 of Alg. 1). Classical NMS only takes the overlap with unsuppressed boxes into account. Therefore, we generalize (12) by accounting for the effect of all (suppressed and unsuppressed) boxes as</p><formula xml:id="formula_21">r i = s i i?1 j=1 (1 ? p(o ij )r j ) .<label>(13)</label></formula><p>The presence of r j on the RHS of (13) prevents suppressed boxes r j ? 0 from influencing other boxes hugely. Let us say we have a box b 2 with a high overlap with an unsuppressed box b 1 . The classical NMS with a threshold pruning function assigns r 2 = 0 while (13) assigns r 2 a small non-zero value with a threshold pruning. Although <ref type="bibr" target="#b12">(13)</ref> keeps r i ? 0, getting a closed-form recursion in r is not easy because of the product operation. To get a closed-form recursion with addition/subtraction in r, we first carry out the polynomial multiplication and then ignore the higher-order terms as</p><formula xml:id="formula_22">r i = s i ? ? 1 ? i?1 j=1 p(o ij )r j + O(n 2 ) ? ? ? s i ? ? 1 ? i?1 j=1 p(o ij )r j ? ? ? s i ? i?1 j=1 p(o ij )r j .<label>(14)</label></formula><p>Dropping the s i in the second term of (14) helps us get a cleaner form of <ref type="bibr" target="#b18">(19)</ref>. Moreover, it does not change the nature of the NMS since the subtraction keeps the relation r i ? s i intact as p(o ij ) and r j are both between [0, 1]. We can also reach <ref type="bibr" target="#b13">(14)</ref> directly as follows. Classical NMS suppresses a box which has a high IoU 2D overlap with any of the unsuppressed boxes (r j ? 1) to zero. We consider any as a logical non-differentiable OR operation and use logical OR operator's differentiable relaxation as <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b46">47]</ref>. We next use this relaxation with the other expression r ? s.</p><p>When a box shows overlap with more than two unsuppressed boxes, the term <ref type="bibr" target="#b13">(14)</ref> or when a box shows high overlap with one unsuppressed box, the term s i &lt; p(o ij )r j . In both of these cases, r i &lt; 0. So, we lower bound <ref type="bibr" target="#b13">(14)</ref> with a max operation to ensure that r i ? 0. Thus,</p><formula xml:id="formula_23">i?1 j=1 p(o ij )r j &gt; 1 in</formula><formula xml:id="formula_24">r i ? max ? ? s i ? i?1 j=1 p(o ij )r j , 0 ? ? .<label>(15)</label></formula><p>We write the rescores r in a matrix formulation as</p><formula xml:id="formula_25">? ? ? ? ? ? ? r 1 r 2 r 3 . . . r n ? ? ? ? ? ? ? ? max ? ? ? ? ? ? ? ? ? ? ? ? ? ? c 1 c 2 c 3 . . . c n ? ? ? ? ? ? ? , ? ? ? ? ? ? ? 0 0 0 . . . 0 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,<label>(16)</label></formula><p>with</p><formula xml:id="formula_26">? ? ? ? ? ? ? c 1 c 2 c 3 . . . c n ? ? ? ? ? ? ? = ? ? ? ? ? ? ? s 1 s 2 s 3 . . . s n ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0 0 . . . 0 p(o 21 ) 0 . . . 0 p(o 31 ) p(o 32 ) . . . 0 . . . . . . . . . . . . p(o n1 ) p(o n2 ) . . . 0 ? ? ? ? ? ? ? ? ? ? ? ? ? ? r 1 r 2 r 3 . . . r n ? ? ? ? ? ? ? .<label>(17)</label></formula><p>We next write the above two equations compactly as</p><formula xml:id="formula_27">r ? max(s ? Pr, 0),<label>(18)</label></formula><p>where P, called the Prune Matrix, is obtained by elementwise operation of the pruning function p on O l l . Maximum operation makes (18) non-linear <ref type="bibr" target="#b40">[41]</ref> and, thus, difficult to solve. However, for a differentiable NMS layer, we need to avoid the recursion. Therefore, we first solve <ref type="bibr" target="#b17">(18)</ref> assuming the max operation is not present which gives us the solution r ? (I + P) ?1 s. In general, this solution is not necessarily bounded between 0 and 1. Hence, we clip it explicitly to obtain the approximation</p><formula xml:id="formula_28">r ? (I + P) ?1 s ,<label>(19)</label></formula><p>which we use as the solution to <ref type="bibr" target="#b17">(18)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2. Loss Functions</head><p>We now detail out the loss functions used for training. The losses on the boxes before NMS, L bef ore , is given by <ref type="bibr" target="#b11">[12]</ref> </p><formula xml:id="formula_29">L bef ore = L class + L 2D + b conf L 3D + ? conf (1 ? b conf ),<label>(20)</label></formula><p>where L class = CE(b class , g class ),</p><formula xml:id="formula_30">L 2D = ? log(IoU(b 2D , g 2D )),<label>(21)</label></formula><formula xml:id="formula_31">L 3D = Smooth-L1(b 3D , g 3D ) + ? a CE([b ?a , b ? h ], [g ?a , g ? h ]).<label>(22)</label></formula><p>b conf is the predicted self-balancing confidence of each box b, while b ?a and b ? h are its orientation bins <ref type="bibr" target="#b11">[12]</ref>. g denotes the ground-truth. ? conf is the rolling mean of most recent L 3D losses per mini-batch <ref type="bibr" target="#b11">[12]</ref>, while ? a denotes the weight of the orientation bins loss. CE and Smoooth-L1 denote the Cross Entropy and Smooth L1 loss respectively. Note that we apply 2D and 3D regression losses as well as the confidence losses only on the foreground boxes. As explained in Sec. 4.3, the loss on the boxes after NMS, L af ter , is the Imagewise AP-Loss, which is given by</p><formula xml:id="formula_33">L af ter = L Imagewise = 1 N N m=1 AP(r (m) , target(B (m) )),<label>(24)</label></formula><p>Let ? be the weight of the L af ter term. Then, our overall loss function is given by L = L bef ore + ?L af ter <ref type="bibr" target="#b24">(25)</ref> </p><formula xml:id="formula_34">= L class + L 2D + b conf L 3D + ? conf (1 ? b conf ) + ?L Imagewise (26) = CE(b class , g class ) ? log(IoU(b 2D , g 2D )) + b conf Smooth-L1(b 3D , g 3D ) + ? a b conf CE([b ?a , b ? h ], [g ?a , g ? h ]) + ? conf (1 ? b conf ) + ?L Imagewise .<label>(27)</label></formula><p>We keep ? a = 0.35 following <ref type="bibr" target="#b11">[12]</ref> and ? = 0.05. Clearly, all our losses and their weights are identical to <ref type="bibr" target="#b11">[12]</ref> except L Imagewise .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3. Additional Experiments and Results</head><p>We now provide additional details and results evaluating our system's performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3.1. Training</head><p>Training images are augmented using random flipping with probability 0.5 <ref type="bibr" target="#b11">[12]</ref>. Adam optimizer <ref type="bibr" target="#b36">[37]</ref> is used with batch size 2, weight-decay 5?10 ?4 and gradient clipping of 1 <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref>. Warmup starts with a learning rate 4 ? 10 ?3 following a poly learning policy with power 0.9 <ref type="bibr" target="#b11">[12]</ref>. Warmup and full training phases take 80k and 50k mini-batches respectively for Val 1 and Val 2 Splits <ref type="bibr" target="#b11">[12]</ref> while take 160k and 100k mini-batches for Test Split.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3.2. KITTI Val 1 Oracle NMS Experiments</head><p>As discussed in Sec. 1, to understand the effects of an inference-only NMS on 2D and 3D object detection, we conduct a series of oracle experiments. We create an oracle NMS by taking the Val Car boxes of KITTI Val 1 Split from the baseline Kinematic (Image) model before NMS and replace their scores with their true IoU 2D or IoU 3D with the ground-truth, respectively. Note that this corresponds to the oracle because we do not know the ground-truth boxes during inference. We then pass the boxes with the oracle scores through the classical NMS and report the results in Tab. 7.</p><p>The results show that the AP 3D increases by a staggering &gt; 60 AP on Mod cars when we use oracle IoU 3D as the NMS score. On the other hand, we only see an increase in AP 2D by ? 11 AP on Mod cars when we use oracle IoU 2D as the NMS score. Thus, the relative effect of using oracle IoU 3D NMS scores on 3D detection is more significant than using oracle IoU 2D NMS scores on 2D detection.</p><p>In other words, the mismatch is greater between classification and 3D localization compared to the mismatch between classification and 2D localization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3.3. KITTI Val 1 3D Object Detection</head><p>Comparisons with other NMS. We compare our method with the other NMS-classical, Soft <ref type="bibr" target="#b7">[8]</ref> and Distance-NMS <ref type="bibr" target="#b75">[76]</ref> and report the detailed results in Tab. 8. We use the publicly released Soft-NMS code and Distance-NMS code from the respective authors. The Distance-NMS model uses the class confidence scores divided by the uncertainty in z (the most erroneous dimension in 3D localization <ref type="bibr" target="#b77">[78]</ref>) of a box as the Distance-NMS <ref type="bibr" target="#b75">[76]</ref> input. Our model does not predict the uncertainty in z of a box but predicts its self-balancing confidence (the 3D localization score). Therefore, we use the class confidence scores multiplied by the self-balancing confidence as the Distance-NMS input.</p><p>The results in Tab. 8 show that NMS inclusion in the training pipeline benefits the performance, unlike <ref type="bibr" target="#b7">[8]</ref>, which suggests otherwise. Training with GrooMeD-NMS helps because the network gets an additional signal through the GrooMeD-NMS layer whenever the best-localized box corresponding to an object is not selected. Moreover, Tab. 8 suggests that we can replace GrooMeD-NMS with the classical NMS in inference as the performance is almost the same even at IoU 3D = 0.5.</p><p>How good is the classical NMS approximation? GrooMeD-NMS uses several approximations to arrive at the matrix solution <ref type="bibr" target="#b18">(19)</ref>. We now compare how good these approximations are with the classical NMS. Interestingly, Tab. 8 shows that GrooMeD-NMS is an excellent approximation to the classical NMS as the performance does not degrade after changing the NMS in inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3.4. KITTI Val 1 Sensitivity Analysis</head><p>There are a few adjustable parameters for the GrooMeD-NMS, such as the NMS threshold N t , valid box threshold v, the maximum group size ?, the weight ? for the L af ter , and ?. We carry out a sensitivity analysis to understand how these parameters affect performance and speed, and   how sensitive the algorithm is to these parameters.</p><p>Sensitivity to NMS Threshold. We show the sensitivity to NMS threshold N t in Tab. 9. The results in Tab. 9 show that the optimal N t = 0.4. This is also the N t in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>Sensitivity to Valid Box Threshold. We next show the sensitivity to valid box threshold v in Tab. 10. Our choice of v = 0.3 performs close to the optimal choice.</p><p>Sensitivity to Maximum Group Size. Grouping has a parameter group size (?). We vary this parameter and report AP 3D|R40 and AP BEV|R40 at two different IoU 3D thresholds on Moderate Cars of KITTI Val 1 Split in <ref type="figure" target="#fig_6">Fig. 5</ref>. We note that the best AP 3D|R40 performance is obtained at ? = 100 and we, therefore, set ? = 100 in our experiments.</p><p>Sensitivity to Loss Weight. We now show the sensitivity to loss weight ? in Tab. 11. Our choice of ? = 0.05 is  the optimal value.</p><p>Sensitivity to Best Box Threshold. We now show the sensitivity to the best box threshold ? in Tab. 12. Our choice of ? = 0.3 is the optimal value.</p><p>Conclusion. Our method has minor sensitivity to N t , ?, ? and ?, which is common in object detection. Our method is not as sensitive to v since it only decides a box's validity. Our parameter choice is either at or close to the optimal. The inference speed is only affected by ?. Other parameters are used in training or do not affect inference speed. <ref type="figure">Figure 6</ref>: Qualitative Results (Best viewed in color). We depict the predictions of GrooMeD-NMS in image view on the left and the predictions of GrooMeD-NMS, Kinematic (Image) <ref type="bibr" target="#b11">[12]</ref>, and Ground Truth in BEV on the right. In general, GrooMeD-NMS predictions are more closer to the ground truth than Kinematic (Image) <ref type="bibr" target="#b11">[12]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Overview of our method. (a) Conventional object detection has a mismatch between training and inference as it uses NMS only in inference. (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>3. 1 . 5 while t = empty do 6 ? 7 d 8 t ? t ? ? Remove from t 9 for i ? 1 : |t| do 10 ri ? ( 1 ?</head><label>1567891101</label><figDesc>NotationsLet B = {b i } n i=1 denote the set of boxes or proposals b i from an image. Let s = {s i } n i=1 and r = {r i } n i=1 denote their scores (before NMS) and rescores (updated scores after NMS) respectively such that r i , s i ? 0 ? i.D denotes the subset of B after the NMS. Let O = [o ij ] denote the n ? n matrix with o ij denoting the 2D Intersection over Union (IoU 2D ) of b i and b j . The pruning function p decides how to rescore a set of boxes B based on IoU 2D overlaps Algorithm 1: Classical/Soft-NMS [8] Input: s: scores, O: IoU2D matrix, Nt: NMS threshold, p: pruning function, ? : temperature Output: d: box index after NMS, r: scores after NMS 1 ? argmax r[t] Top scored box ? d ? ? Add to valid box index p? (O[?, i]))ri its neighbors, sometimes suppressing boxes entirely. In other words, p(</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3 : 7 nG 8 GKeep w indices in t 11 O</head><label>37811</label><figDesc>Grouping of boxes Input: O: sorted IoU2D matrix, Nt: NMS threshold, ?: maximum group size Output: k ? min(|v|, ?) .insert(v[: nG k ]) ? O[w][:, w] Keep w indices in O</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Pruning functions p of the classical and GrooMeD-NMS. We use the Linear and Exponential pruning of the Soft-NMS<ref type="bibr" target="#b7">[8]</ref> while training with the GrooMeD-NMS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Comparison of AP3D at different depths and IoU3D matching thresholds on KITTI Val 1 Split.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Score-IoU3D plot after the NMS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>AP 3D|R 40 and AP BEV|R 40 Variation with ? on Moderate Cars of KITTI Val 1 Split.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 2 :</head><label>2</label><figDesc>GrooMeD-NMS Input: s: scores, O: IoU2D matrix, Nt: NMS threshold, p: pruning function, v: valid box threshold, ?: maximum group size Output: d: box index after NMS, r: scores after NMS</figDesc><table><row><cell cols="2">1 begin</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell cols="5">s, index ? sort(s, descending= True)</cell><cell>Sort s</cell></row><row><cell>3</cell><cell cols="4">O ? O[index][:, index]</cell><cell></cell><cell>Sort O</cell></row><row><cell>4</cell><cell>O</cell><cell>l l</cell><cell cols="2">? lower(O)</cell><cell>Lower</cell><cell>ular matrix</cell></row><row><cell>5</cell><cell cols="3">P ? p(O</cell><cell>l l )</cell><cell cols="2">Prune matrix</cell></row><row><cell>6</cell><cell cols="4">I ? Identity(|s|)</cell><cell cols="2">Identity matrix</cell></row><row><cell>7</cell><cell cols="4">G ? group(O, Nt, ?)</cell><cell cols="2">Group boxes B</cell></row><row><cell>8</cell><cell cols="4">for k ? 1 : |G| do</cell><cell></cell></row><row><cell>9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Overview of different NMS. [Key: Train= End-to-end Trainable, Prune= Pruning function, #Layers= Number of layers, Par= Parallelizable]</figDesc><table><row><cell>NMS</cell><cell>Train</cell><cell>Rescore</cell><cell cols="2">Prune #Layers Par</cell></row><row><cell>Classical</cell><cell></cell><cell></cell><cell>Hard</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Adaptive-NMS<ref type="bibr" target="#b50">[51]</ref> uses a separate neural network to predict the classical NMS threshold N t . The trainable neural network based NMS (NN-NMS)<ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b64">65]</ref> use a separate neural network containing multiple layers and/or messagepassing to approximate the NMS and do not use the pruning function. Unlike these methods, GrooMeD-NMS uses a single layer and does not require multiple layers or message passing. Our NMS is parallel up to group (denoted by G). However, |G| is, in general, &lt;&lt; |B| in the NMS.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>AP 3D|R 40 and AP BEV|R 40 comparisons on the KITTI Test Cars (IoU3D ? 0.7). Previous results are quoted from the official leader-board or from papers.[Key: Best, Second Best]. 16.65 11.72 9.51 22.51 16.02 12.55 Kinematic (Video) [12] 19.07 12.72 9.17 26.69 17.52 13.10 GrooMeD-NMS (Ours) 18.10 12.32 9.65 26.19 18.27 14.05</figDesc><table><row><cell>Method</cell><cell cols="4">AP 3D|R 40 (?) Easy Mod Hard Easy Mod Hard AP BEV|R 40 (?)</cell></row><row><cell>FQNet [49]</cell><cell cols="4">2.77 1.51 1.01 5.40 3.23 2.46</cell></row><row><cell>ROI-10D [56]</cell><cell cols="4">4.32 2.02 1.46 9.78 4.91 3.74</cell></row><row><cell>GS3D [44]</cell><cell cols="4">4.47 2.90 2.47 8.41 6.08 4.94</cell></row><row><cell>MonoGRNet [66]</cell><cell cols="4">9.61 5.74 4.25 18.19 11.17 8.73</cell></row><row><cell>MonoPSR [39]</cell><cell cols="4">10.76 7.25 5.85 18.33 12.58 9.91</cell></row><row><cell>MonoDIS [79]</cell><cell cols="4">10.37 7.94 6.40 17.23 13.19 11.12</cell></row><row><cell>UR3D [76]</cell><cell cols="4">15.58 8.61 6.00 21.85 12.51 9.20</cell></row><row><cell>M3D-RPN [10]</cell><cell cols="4">14.76 9.71 7.42 21.02 13.67 10.23</cell></row><row><cell>SMOKE [52]</cell><cell cols="4">14.03 9.76 7.84 20.83 14.49 12.75</cell></row><row><cell>MonoPair [18]</cell><cell cols="4">13.04 9.99 8.65 19.28 14.83 12.89</cell></row><row><cell>RTM3D [46]</cell><cell cols="4">14.41 10.34 8.77 19.17 14.20 11.99</cell></row><row><cell>AM3D [55]</cell><cell cols="4">16.50 10.74 9.52 25.03 17.32 14.91</cell></row><row><cell>MoVi-3D [80]</cell><cell cols="4">15.19 10.90 9.26 22.76 17.03 10.86</cell></row><row><cell>RAR-Net [50]</cell><cell cols="4">16.37 11.01 9.52 22.45 15.02 12.93</cell></row><row><cell>M3D-SSD [54]</cell><cell cols="4">17.51 11.46 8.98 24.15 15.93 12.11</cell></row><row><cell>DA-3Ddet [90]</cell><cell>16.77 11.50 8.93</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>D4LCN [22]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>AP 3D|R 40 and AP BEV|R 40 comparisons on KITTI Val 1 Cars. [Key: Best, Second Best]. ] in [18] 11.90 7.56 5.76 19.72 12.81 10.15 47.59 32.28 25.50 52.13 35.99 28.72 14.53 11.07 8.65 20.85 15.62 11.88 48.56 35.94 28.59 53.35 39.60 31.77 16.28 12.30 10.42 24.12 18.17 15.76 55.38 42.39 37.99 61.06 47.63 41.92 Kinematic (Image) [12] 18.28 13.55 10.13 25.72 18.82 14.48 54.70 39.33 31.25 60.87 44.36 34.48 Kinematic (Video) [12] 19.76 14.10 10.47 27.83 19.72 15.10 55.44 39.47 31.26 61.79 44.68 34.56 GrooMeD-NMS (Ours) 19.67 14.32 11.27 27.38 19.75 15.92 55.62 41.07 32.89 61.83 44.98 36.29</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">IoU 3D ? 0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">IoU 3D ? 0.5</cell><cell></cell></row><row><cell>Method</cell><cell cols="3">AP 3D|R 40 (?)</cell><cell cols="3">AP BEV|R 40 (?)</cell><cell cols="3">AP 3D|R 40 (?)</cell><cell cols="3">AP BEV|R 40 (?)</cell></row><row><cell></cell><cell>Easy</cell><cell>Mod</cell><cell>Hard</cell><cell>Easy</cell><cell>Mod</cell><cell>Hard</cell><cell>Easy</cell><cell>Mod</cell><cell>Hard</cell><cell>Easy</cell><cell>Mod</cell><cell>Hard</cell></row><row><cell>MonoDR [5]</cell><cell cols="2">12.50 7.34</cell><cell cols="4">4.98 19.49 11.51 8.72</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MonoGRNet [66MonoDIS [79] in [77]</cell><cell cols="2">11.06 7.60</cell><cell cols="4">6.37 18.45 12.58 10.66</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>M3D-RPN [10] in [12]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MoVi-3D [80]</cell><cell cols="6">14.28 11.13 9.68 22.36 17.87 15.73</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MonoPair [18]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>AP 3D|R 40 and AP BEV|R 40 comparisons with other NMS on KITTI Val 1 Cars (IoU3D ? 0.7). Image) C 18.28 13.55 10.13 25.72 18.82 14.48 Kinematic (Image) S 18.29 13.55 10.13 25.71 18.81 14.48 Kinematic (Image) D 18.25 13.53 10.11 25.71 18.82 14.48 Kinematic (Image) G 18.26 13.51 10.10 25.67 18.77 14.44 GrooMeD-NMS C 19.67 14.31 11.27 27.38 19.75 15.93 GrooMeD-NMS S 19.67 14.31 11.27 27.38 19.75 15.93 GrooMeD-NMS D 19.67 14.31 11.27 27.38 19.75 15.93 GrooMeD-NMS G 19.67 14.32 11.27 27.38 19.75 15.92</figDesc><table><row><cell></cell><cell></cell><cell>[Key: C= Classical, S= Soft-</cell></row><row><cell cols="3">NMS [8], D= Distance-NMS [76], G= GrooMeD-NMS]</cell></row><row><cell>Method</cell><cell>Infer NMS</cell><cell>AP 3D|R 40 (?) Easy Mod Hard Easy Mod Hard AP BEV|R 40 (?)</cell></row><row><cell cols="2">Kinematic ((a) Linear Scale</cell><cell>(b) Log Scale</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>AP 3D|R 40 and AP BEV|R 40 comparisons on KITTI Val 2 Cars. [Key: Best, *= Released, ? = Retrained]. RPN [10]* 14.57 10.07 7.51 21.36 15.22 11.28 49.14 34.43 26.39 53.44 37.79 29.36 Kinematic (Image) [12] ? 13.54 10.21 7.24 20.60 15.14 11.30 51.53 36.55 28.26 56.20 40.02 31.25 GrooMeD-NMS (Ours) 14.72 10.87 7.67 22.03 16.05 11.93 51.91 36.78 28.40 56.29 40.31 31.39</figDesc><table><row><cell></cell><cell></cell><cell cols="2">IoU 3D ? 0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">IoU 3D ? 0.5</cell></row><row><cell>Method</cell><cell cols="2">AP 3D|R 40 (?)</cell><cell cols="3">AP BEV|R 40 (?)</cell><cell cols="3">AP 3D|R 40 (?)</cell><cell cols="2">AP BEV|R 40 (?)</cell></row><row><cell></cell><cell>Easy</cell><cell cols="2">Mod Hard Easy</cell><cell>Mod</cell><cell>Hard</cell><cell>Easy</cell><cell>Mod</cell><cell>Hard</cell><cell>Easy</cell><cell>Mod</cell><cell>Hard</cell></row><row><cell>M3D-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Ablation studies of our method on KITTI Val 1 Cars. No Conf+No NMS 16.66 12.10 9.40 23.15 17.43 13.48 51.47 38.58 30.98 56.48 42.53 34.37 Conf+NMS? Conf+No NMS 19.16 13.89 10.96 27.01 19.33 14.84 57.12 41.07 32.79 61.60 44.58 35.97 Conf+NMS? No Conf+NMS 15.02 11.21 8.83 21.07 16.27 12.77 48.01 36.18 29.96 53.82 40.94 33.35 Initialization No Warmup 15.33 11.68 8.78 21.32 16.59 12.93 49.15 37.42 30.11 54.32 41.44 33.48 .26 7.10 17.07 12.17 9.25 29.58 20.42 15.88 32.06 22.16 17.20 Linear? Exponential, ? = 0.5 [8] 18.63 13.85 10.98 27.52 20.14 15.76 56.64 41.01 32.79 61.43 44.73 36.02 Linear? Exponential, ? = 0.1 18.34 13.79 10.88 27.26 19.71 15.90 56.98 41.16 32.96 62.77 45.23 36.56 Linear? Sigmoidal, ? = 0.1 17.40 13.21 9.80 26.77 19.26 14.76 55.15 40.77 32.63 60.56 44.23 35.74 Group+Mask Group+Mask? No Group 18.43 13.91 11.08 26.53 19.46 15.83 55.93 40.98 32.78 61.02 44.77 36.09 Group+Mask? Group+No Mask 18.99 13.74 10.24 26.71 19.21 14.77 55.21 40.69 32.55 61.74 44.67 36.00 Loss Imagewise AP? Vanilla AP 18.23 13.73 10.28 26.42 19.31 14.76 54.47 40.35 32.20 60.90 44.08 35.47 Imagewise AP? BCE 16.34 12.74 9.73 22.40 17.46 13.70 52.46 39.40 31.68 58.22 43.60 35.27 Inference Class*Pred? Class 18.26 13.36 10.49 25.39 18.64 15.12 52.44 38.99 31.3 57.37 42.89 34.68 NMS Scores Class*Pred? Pred 17.51 12.84 9.55 24.55 17.85 13.63 52.78 37.48 29.37 58.30 41.26 32.66 -GrooMeD-NMS (best model) 19.67 14.32 11.27 27.38 19.75 15.92 55.62 41.07 32.89 61.83 44.98 36.29</figDesc><table><row><cell cols="2">Change from GrooMeD-NMS model:</cell><cell>IoU 3D ? 0.7</cell><cell>IoU 3D ? 0.5</cell></row><row><cell>Changed</cell><cell>From ?? To</cell><cell cols="2">AP 3D|R 40 (?) Easy Mod Hard Easy Mod Hard Easy Mod Hard Easy Mod Hard AP BEV|R 40 (?) AP 3D|R 40 (?) AP BEV|R 40 (?)</cell></row><row><cell cols="2">Training Conf+NMS? Pruning Linear? Exponential, ? = 1</cell><cell>12.81 9</cell></row><row><cell>Function</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Results on using Oracle NMS scores on AP 3D|R 40 ,AP BEV|R 40 andAP 2D|R 40 of KITTI Val 1 Cars. [Key: Best] NMS Scores AP 3D|R 40 (?) AP BEV|R 40 (?) AP 2D|R 40 (?) Easy Mod Hard Easy Mod Hard Easy Mod Hard Kinematic (Image) 18.29 13.55 10.13 25.72 18.82 14.48 93.69 84.07 67.14 Oracle IoU 2D 9.36 9.93 6.40 12.27 10.43 8.72 99.18 95.66 85.77 Oracle IoU 3D 87.93 73.10 60.91 93.47 83.61 71.31 80.99 78.38 67.66</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>AP 3D|R 40 and AP BEV|R 40 variation with Nt on KITTI Val 1 Cars. [Key: Best] AP 3D|R 40 (?) AP BEV|R 40 (?) Easy Mod Hard Easy Mod Hard Nt = 0.3 17.49 13.32 10.54 26.07 18.94 14.61 Nt = 0.4 19.67 14.32 11.27 27.38 19.75 15.92 Nt = 0.5 19.65 13.93 11.09 26.15 19.15 14.71</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>AP 3D|R 40 and AP BEV|R 40 variation with v on KITTI Val 1 Cars. [Key: Best] AP 3D|R 40 (?) AP BEV|R 40 (?) Easy Mod Hard Easy Mod Hard v = 0.01 13.71 9.65 7.24 17.73 12.47 9.36 v = 0.1 19.37 13.99 10.92 26.95 19.84 15.40 v = 0.2 19.65 14.31 11.24 27.35 19.73 15.89 v = 0.3 19.67 14.32 11.27 27.38 19.75 15.92 v = 0.4 19.67 14.33 11.28 27.38 19.76 15.93 v = 0.5 19.67 14.33 11.28 27.38 19.76 15.93 v = 0.6 19.67 14.33 11.29 27.39 19.77 15.95</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 :</head><label>11</label><figDesc>AP 3D|R 40 and AP BEV|R 40 variation with ? on KITTI Val 1 Cars. [Key: Best] AP 3D|R 40 (?) AP BEV|R 40 (?) Easy Mod Hard Easy Mod Hard ? = 0 19.16 13.89 10.96 27.01 19.33 14.84 ? = 0.05 19.67 14.32 11.27 27.38 19.75 15.92 ? = 0.1 17.74 13.61 10.81 25.86 19.18 15.57 ? = 1 10.08 7.26 6.00 14.44 10.55 8.41</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12 :</head><label>12</label><figDesc>AP 3D|R 40 and AP BEV|R 40 variation with ? on KITTI Val 1 Cars. [Key: Best] AP 3D|R 40 (?) AP BEV|R 40 (?) Easy Mod Hard Easy Mod Hard ? = 0.1 18.09 13.64 10.21 26.52 19.50 15.74 ? = 0.3 19.67 14.32 11.27 27.38 19.75 15.92 ? = 0.4 18.91 14.02 11.15 27.11 19.64 15.90 ? = 0.5 18.49 13.66 10.96 27.01 19.47 15.79</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was partially sponsored by Ford Motor Company and the Army Research Office under Grant Number W911NF-18-1-0330. This document's views and conclusions are those of the authors and do not represent the official policies, either expressed or implied, of the Army Research Office or the U.S. Government.</p><p>We thank Mathieu Blondel and Quentin Berthet from Google Brain, Paris, for several useful discussions on differentiable ranking and sorting. We also discussed the logical operators' relaxation with Ashim Gupta from the University of Utah. Armin Parchami from Ford Motor Company suggested the learnable NMS paper <ref type="bibr" target="#b31">[32]</ref>. Enrique Corona and Marcos Paul Gerardo Castro from Ford Motor Company provided feedback during the development of this work. Shengjie Zhu from the Computer Vision Lab at Michigan State University proof-read our manuscript and suggested several changes. We also thank Xuepeng Shi from University College London for sharing the Distance-NMS <ref type="bibr" target="#b75">[76]</ref> code for bench-marking. We finally acknowledge anonymous reviewers for their feedback that helped in shaping the final manuscript.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3.5. Qualitative Results</head><p>We next show some qualitative results of models trained on KITTI Val 1 Split in <ref type="figure">Fig. 6</ref>. We depict the predictions of GrooMeD-NMS in image view on the left and the predictions of GrooMeD-NMS, Kinematic (Image) <ref type="bibr" target="#b11">[12]</ref>, and ground truth in BEV on the right. In general, GrooMeD-NMS predictions are more closer to the ground truth than Kinematic (Image) <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3.6. Demo Video of GrooMeD-NMS</head><p>We next include a short demo video of our GrooMeD-NMS model trained on KITTI Val 1 Split. We run our trained model independently on each frame of the three KITTI raw <ref type="bibr" target="#b23">[24]</ref> sequences -2011 10 03 DRIVE 0047, 2011 09 29 DRIVE 0026 and 2011 09 26 DRIVE 0009. None of the frames from these three raw sequences appear in the training set of KITTI Val 1 Split. We use the camera matrices available with the raw sequences but do not use any temporal information. Overlaid on each frame of the raw input videos, we plot the projected 3D boxes of the predictions and also plot these 3D boxes in the BEV. We set the frame rate of this demo at 10 fps. The demo is also available in HD at https://www.youtube.com/watch?v= PWctKkyWrno. In the demo video, notice that the orientation of the boxes are stable despite not using any temporal information.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<ptr target="http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d" />
		<title level="m">The KITTI Vision Benchmark Suite</title>
		<imprint>
			<biblScope unit="page" from="2020" to="2030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Augmented reality meets computer vision: Efficient data generation for urban driving scenes. IJCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Alhaija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Mustikovela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning detection with diverse proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samaneh</forename><surname>Azadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">MonoFENet: Monocular 3D object detection with feature enhancement networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Monocular differentiable rendering for selfsupervised 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deniz</forename><surname>Beker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroharu</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Mihai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takahiro</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toru</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wadim</forename><surname>Matsuoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Kehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gaidon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning with differentiable perturbed optimizers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Berthet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Teboul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Vert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Bach</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast differentiable sorting and ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Teboul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Berthet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josip</forename><surname>Djolonga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Soft-NMS-improving object detection with one line of code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navaneeth</forename><surname>Bodla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharat</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Soft-NMS implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navaneeth</forename><surname>Bodla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharat</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Davis</surname></persName>
		</author>
		<idno>2021- 01-18. 3</idno>
		<ptr target="https://github.com/bharatsingh430/soft-nms/blob/master/lib/nms/cpu_nms.pyx#L98" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">M3D-RPN: Monocular 3D region proposal network for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrick</forename><surname>Brazil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pedestrian detection with autoregressive network phases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrick</forename><surname>Brazil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Kinematic 3D object detection in monocular video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrick</forename><surname>Brazil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Illuminating pedestrians via simultaneous detection &amp; segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrick</forename><surname>Brazil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">AP-Loss for accurate one-stage object detection. TPAMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kean</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junni</forename><surname>Zou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Monocular 3D object detection for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaustav</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huimin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Sanja Fidler, and Raquel Urtasun. 3D object proposals for accurate object class detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaustav</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Berneshawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huimin</forename><surname>Ma</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-view 3D object detection network for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huimin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">MonoPair: Monocular 3D object detection using pairwise spatial relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Differentiable ranks and sorting using optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Teboul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Vert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navneet</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Discriminative models for multi-class object layout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning depth-guided convolutions for monocular 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqi</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">3D object detection and viewpoint estimation with a deformable 3D cuboid model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<title level="m">Vision meets robotics: The KITTI dataset. IJRR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Are we ready for autonomous driving? the KITTI vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Gene Golub and Charles Loan. Matrix computations</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A combined corner and edge detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Stephens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Alvey vision conference</title>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">End-to-end training of object class detectors for mean average precision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A convnet for non-maximum suppression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hosang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GCPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning non-maximum suppression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hosang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">What you see is what you get: Exploiting visibility for 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiyun</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Ziglar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">EP-Net: Enhancing point features with image semantics for 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengteng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiwu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Probabilistic anchor assignment with iou prediction for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hee</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emile</forename><surname>Krieken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erman</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Harmelen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06100</idno>
		<title level="m">Analyzing differentiable fuzzy logic operators</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Monocular 3D object detection leveraging accurate proposals and shape reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Pon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Waslander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">LUVLi face alignment: Estimating landmarks&apos; location, uncertainty, and visibility likelihood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Koike-Akino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Estimation of bandlimited signals from the signs of noisy samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Animesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Prabhakaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Individualness and determinantal point processes for pedestrian detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geonho</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songhwai</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection. IJRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Pastor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Ibarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deirdre</forename><surname>Quillen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">GS3D: An efficient 3D object detection framework for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Stereo R-CNN based 3D object detection for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">RTM3D: Real-time monocular 3D detection from object keypoints for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaici</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feidao</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Augmenting neural networks with first-order logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep fitting degree scoring network for monocular 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Reinforced axial refinement network for monocular 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chufan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Adaptive NMS: Refining pedestrian detection in a crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songtao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">SMOKE: Single-stage monocular 3D object detection via keypoint estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zechen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>T?th</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">M3DSSD: Monocular 3D single stage object detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Accurate monocular 3D object detection via color-embedded 3D reconstruction for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinzhu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haojie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengbo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Roi-10D: Monocular lifting of 2D detection to 6 pose and metric shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Manhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wadim</forename><surname>Kehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Scale &amp; affine invariant interest point detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krystian</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Segmentation of 3D LiDAR data in non-flat urban environments using a local convexity criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Moosmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Pink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Stiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">PyTorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<editor>Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Gradient estimation with stochastic softmax tricks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dami</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Maddison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2020</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">From contours to 3D object detection and pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadia</forename><surname>Payet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinisa</forename><surname>Todorovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Multi-view and 3D deformable part models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bojan</forename><surname>Pepik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Differentiation of blackbox combinatorial solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marin</forename><surname>Pogan?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vit</forename><surname>Musil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Martius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Rolinek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Softsort: A continuous relaxation for the argsort operator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Prillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Eisenschlos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Learning to filter object detections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Prokudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kappler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GCPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">MonoGRNet: A geometric reasoning network for 3D object localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zengyi</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinglu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santosh</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Soccer on your tabletop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Rematas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Automatic detection and segmentation of evolving processes in 3D medical images: Application to multiple sclerosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?rard</forename><surname>Subsol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>Delingette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Generalized intersection over union: A metric and a loss for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Edge and curve detection for visual scene analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azriel</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Thurston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Optimized pedestrian detection for multiple and occluded people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sitapa</forename><surname>Rujikietgumjorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Robotic grasping of novel objects using vision. IJRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Driemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">PointR-CNN: 3D object proposal generation and detection from point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Distancenormalized unified representation for monocular 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuepeng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae-Kyun</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Disentangling monocular 3D object detection: From single to multi-class recognition. TPAMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Simonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Antequera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kontschieder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Demystifying pseudo-LiDAR for monocular 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Simonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kontschieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.05796,2020.14</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Disentangling monocular 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Simonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>L?pez-Antequera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kontschieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Towards generalization across depth for monocular 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Simonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kontschieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Determinantal point process as an alternative to NMS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samik</forename><surname>Some</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinay</forename><surname>Mithun Das Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Namboodiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunlei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Dorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiragkumar</forename><surname>Savani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.13423</idno>
		<title level="m">Center-based monocular 3D object detection with joint depth understanding</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Improving object localization with fitness NMS and bounded IoU loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lachlan</forename><surname>Tychsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Petersson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Pose-independent automatic target detection and recognition using 3D laser radar imagery. Lincoln laboratory journal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandru</forename><surname>Vasile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Marino</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Rapid object detection using a boosted cascade of simple features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">End-to-end integration of a convolution network, deformable parts model and non-maximum suppression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Bharath Hariharan, Mark Campbell, and Kilian Weinberger. Pseudo-LiDAR from visual depth estimation: Bridging the gap in 3D object detection for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Divyansh</forename><surname>Garg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Motion-Net: Joint perception and motion prediction for autonomous driving based on bird&apos;s eye view maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Subcategory-aware convolutional neural networks for object proposals and detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanqing</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Monocular 3D object detection via feature domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifeng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Errui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilei</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Unconstrained salient object detection via proposal subset optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radomir</forename><surname>Mech</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title/>
		<idno>3D|R 40 (?) AP BEV|R 40</idno>
	</analytic>
	<monogr>
		<title level="j">AP</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">AP 3D|R</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
				<idno>12] Classical 18.28 13.55 10.13 25.72 18.82 14.48 54.70 39.33 31.25 60.87 44.36 34.48</idno>
		<title level="m">AP BEV|R 40 (?) Easy Mod Hard Easy Mod Hard Easy Mod Hard Easy Mod Hard Kinematic (Image</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kinematic</surname></persName>
		</author>
		<idno>12] Soft [8] 18.29 13.55 10.13 25.71 18.81 14.48 54.70 39.33 31.26 60.87 44.36 34.48</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kinematic</surname></persName>
		</author>
		<idno>12] Distance [76] 18.25 13.53 10.11 25.71 18.82 14.48 54.70 39.33 31.26 60.87 44.36 34.48</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kinematic</surname></persName>
		</author>
		<idno>12] GrooMeD 18.26 13.51 10.10 25.67 18.77 14.44 54.59 39.25 31.18 60.78 44.28 34.40</idno>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
