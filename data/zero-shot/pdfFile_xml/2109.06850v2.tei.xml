<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BenchIE: A Framework for Multi-Faceted Fact-Based Open Information Extraction Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NEC Laboratories Europe GmbH</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingying</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NEC Laboratories Europe GmbH</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Mannheim</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhushan</forename><surname>Kotnis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NEC Laboratories Europe GmbH</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolin</forename><surname>Lawrence</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NEC Laboratories Europe GmbH</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NEC Laboratories Europe GmbH</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">University of Stuttgart</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goran</forename><surname>Glavas</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Mannheim</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">LMU Munich</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BenchIE: A Framework for Multi-Faceted Fact-Based Open Information Extraction Evaluation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Intrinsic evaluations of OIE systems are carried out either manually-with human evaluators judging the correctness of extractionsor automatically, on standardized benchmarks. The latter, while much more cost-effective, is less reliable, primarily because of the incompleteness of the existing OIE benchmarks: the ground truth extractions do not include all acceptable variants of the same fact, leading to unreliable assessment of the models' performance. Moreover, the existing OIE benchmarks are available for English only. In this work, we introduce BenchIE: a benchmark and evaluation framework for comprehensive evaluation of OIE systems for English, Chinese, and German. In contrast to existing OIE benchmarks, BenchIE is fact-based, i.e., it takes into account informational equivalence of extractions: our gold standard consists of fact synsets, clusters in which we exhaustively list all acceptable surface forms of the same fact. Moreover, having in mind common downstream applications for OIE, we make BenchIE multi-faceted; i.e., we create benchmark variants that focus on different facets of OIE evaluation, e.g., compactness or minimality of extractions. We benchmark several state-of-the-art OIE systems using BenchIE and demonstrate that these systems are significantly less effective than indicated by existing OIE benchmarks. We make BenchIE (data and evaluation code) publicly available. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open Information Extraction (OIE) is the task of extracting relations and their arguments from natural language text in a schema-free manner <ref type="bibr" target="#b4">(Banko et al., 2007)</ref>. Consider the sentence "Sen. Mitchell, who is from Maine, is a lawyer."; an OIE system is expected to extract the triples ("Sen. Mitchell"; "is from"; "Maine") and ("Sen. Mitchell"; "is"; "a lawyer") from the sentence. OIE systems are used 1 https://github.com/gkiril/benchie in many downstream tasks, including knowledge graph (KG) population , open link prediction <ref type="bibr" target="#b7">(Broscheit et al., 2020)</ref>, and question answering <ref type="bibr" target="#b44">(Yan et al., 2018)</ref>. These downstream tasks lend themselves as natural setups for extrinsic OIE evaluation <ref type="bibr" target="#b30">(Mausam, 2016)</ref>. While valuable in concrete applications, such extrinsic evaluations do not measure the intrinsic correctness of the extracted facts: for that purpose, several benchmarks for intrinsic OIE evaluation have been proposed <ref type="bibr" target="#b37">(Stanovsky and Dagan, 2016;</ref><ref type="bibr" target="#b26">Lechelle et al., 2019;</ref><ref type="bibr" target="#b5">Bhardwaj et al., 2019)</ref>.</p><p>Automated benchmark evaluations are more feasible (i.e., faster and cheaper) than manual OIE evaluations <ref type="bibr" target="#b19">(Hohenecker et al., 2020)</ref>. The current benchmarks, however, use scoring functions that are based on approximate (token-level) matching of system extractions against ground truth facts, which seems to be substantially less reliable than human judgments of extraction correctness <ref type="bibr" target="#b45">(Zhan and Zhao, 2020)</ref>. This primarily stems from the incompleteness of existing OIE benchmarks: the gold standard extractions do not include all acceptable surface realizations of the same fact. Consider, for example, a sentence from the recent evaluation framework CaRB <ref type="bibr" target="#b5">(Bhardwaj et al., 2019)</ref>: "Sen. Mitchell is confident he has sufficient votes to block such a measure with procedural actions"; with the gold triple extraction ("Sen. Mitchell"; "is confident he has"; "sufficient votes to . . . procedural actions"). Intuitively, a system extraction with a more concise object-("Sen. Mitchell"; "is confident he has"; "sufficient votes")-could also be accepted, as it still captures the same core piece of knowledge, and would arguably be valuable in most downstream tasks.</p><p>To account for this, existing benchmarks credit system extractions for per-slot lexical overlap with gold extractions. Such scoring is overly lenient and overestimates the systems' ability to extract correct knowledge facts. Consider, e.g., a system extraction ("Sen. Mitchell"; "is confident he has"; "procedural actions") for the above-mentioned sentence. From the factual perspective, this extraction is clearly incorrect (Sen. Mitchell has votes, not actions). However, the popular CaRB benchmark with its token-level metrics would judge the extraction as having (1) perfect precision, since all extracted tokens can be found in corresponding slots of a gold extraction and (2) high recall, as all of the gold subject and predicate tokens as well as two gold object tokens ("procedural" and "actions") are found within corresponding slots of the system extraction <ref type="table">(Table 1)</ref>. Moreover, by providing a single ground truth extraction per fact, existing OIE benchmarks fail to acknowledge that different downstream applications focus on different facets (i.e., aspects) of OIE extractions: e.g., for text summarization, one may prefer minimal extractions <ref type="bibr" target="#b33">(Ponza et al., 2018)</ref>, whereas knowledge base population benefits from strict correctness of entities in subject and object slots <ref type="bibr" target="#b28">(Lin et al., 2020)</ref>.</p><p>In this work, we depart from lenient OIE evaluations based on per-slot token overlaps and propose BenchIE, a novel fact-centric and multi-faceted OIE evaluation framework and benchmark at the core of which is the following question:</p><p>Does the system extraction express the same fact (i.e., the same unit of knowledge) as any of the ground truth extractions (and vice versa) w.r.t. the specific aspect of the OIE extraction that is of interest for one or more downstream applications?</p><p>Contributions. BenchIE advances the state of the art in OIE evaluation in the following: (1) it is the first fact-centered approach to OIE evaluation: to reliably answer the above question, we exhaustively list all correct extractions of the same fact. In contrast to existing benchmarks, BenchIE specifies complete sets of fact-equivalent extractions (dubbed fact synsets), allowing us to avoid error-prone evaluation based on token overlap measures;</p><p>(2) BenchIE is the first multi-faceted OIE benchmark, allowing to test systems for different aspects of OIE extractions that may be relevant in concrete downstream applications; (3) BenchIE is a multilingual benchmark, covering English, Chinese, and German, and to the best of our knowledge the first with manually annotated (i.e., gold standard) extractions in all languages; 2 (4) finally, as a fact-based and multi-faceted benchmark, BenchIE allows us to perform what we believe to be the most comprehensive profiling and comparative evaluation of OIE systems. BenchIE portrays fact extraction abilities of six state-of-the-art OIE models much less favorably and points to their limitations that cannot be detected with existing benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Matching Facts, Not Tokens</head><p>Most OIE systems extract (subject, predicate, object) triples, with concepts as subjects and objects and verb phrases (VPs) as predicates <ref type="bibr" target="#b4">(Banko et al., 2007;</ref><ref type="bibr" target="#b38">Stanovsky et al., 2018;</ref><ref type="bibr" target="#b25">Lauscher et al., 2019;</ref><ref type="bibr" target="#b15">Gashteovski et al., 2017</ref>, though systems producing n-ary <ref type="bibr" target="#b0">(Akbik and L?ser, 2012)</ref>, nested <ref type="bibr" target="#b6">(Bhutani et al., 2016)</ref>, and noun-mediated extractions <ref type="bibr" target="#b43">(Yahya et al., 2014)</ref> also exist. Here we follow the most common practice and focus on VPmediated facts. Our novel fact-based benchmark and evaluation paradigm can, however, equally be applied to other types of extractions (e.g., <ref type="bibr" target="#b13">Friedrich et al. (2022)</ref> used this fact-based concept for OIE to create gold annotations for NE-Centric OIE triples; i.e., triples where each argument is a named entity and the relations could be either verb phrases or noun phrases).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Fact Synsets</head><p>We introduce the general concept of a fact synset: a set of all possible extractions (i.e., different surface forms) for a given fact type (e.g., VP-mediated facts) that are instances of the same fact. E.g., given the input sentence from <ref type="table" target="#tab_3">Table 2</ref>, the extractions ("Sen. Mitchell"; "has sufficient votes to block"; "such a measure") and ("Sen. Mitchell"; "has sufficient votes to block"; "measure") capture the same fact and thus belong to the same fact synset. Existing benchmarks fail to exhaustively list all acceptable extractions for the same fact. This is precisely why, in order to avoid penalizing systems for correct extractions that are not exactly the same as the gold triples, they resort to lenient token-based performance measures prone to two types of errors: (1) they punish correct fact extractions that have limited lexical overlap with the gold extraction of the same fact, e.g., ("Sen. Mitchell"; "is confident he has"; "sufficient votes") vs. ("Sen. Mitchell"; "is confident he has"; "sufficient votes to . . . procedural actions") unreliable for OIE -as shown by , up to 70% of sentence or extraction translations obtained this way were incorrect.</p><p>Input sentence: "Sen. Mitchell is confident he has sufficient votes to block such a measure with procedural actions." CaRB golden extraction: ("Sen. Mitchell"; "is confident he has"; "sufficient votes to block ...procedural actions")</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OIE extraction</head><p>CaRB (P / R) BenchIE t1 ("Sen. Mitchell"; "is confident he has"; "sufficient") 1.00 0.44 0 t2</p><p>("Sen. Mitchell"; "is confident he has"; "sufficient actions") 1.00 0.50 0 t3</p><p>("Sen. Mitchell"; "is confident he has"; "sufficient procedural actions") 1.00 0.56 0 t4 ("Sen. Mitchell"; "is confident he has"; "sufficient votes") 1.00 0.50 1 <ref type="table">Table 1</ref>: Difference in scores between CaRB and BenchIE. For the input sentence, CaRB provides only one extraction which covers all the words in the sentence. Then, for each input OIE extraction (from t 1 to t 4 ) it calculates token-wise precision and recall scores w.r.t. the golden annotation. In contrast, BenchIE provides 46 gold extractions for the same sentence and recognizes OIE extractions as valid if they exactly match any of them.</p><p>Input sentence: "Sen. Mitchell is confident he has sufficient votes to block such a measure with procedural actions."</p><p>f1 ("Sen. Mitchell" | "he"; "is"; "confident [he has sufficient ... actions]") f2 ("Sen. Mitchell" | "he"; "is confident he has"; "sufficient votes") ("Sen. Mitchell" | "he"; "is confident he has"; "suff. votes to block [such] [a] measure") f3 ("Sen. Mitchell" | "he"; "is confident he has sufficient votes to block" "[such] [a] measure") ("Sen. Mitchell" | "he";</p><p>"is confident he has ... to block [such]"; "[a] measure") ("Sen. Mitchell" | "he";</p><p>"is confident he has ... to block [such] [a]"; "measure") f4 ("Sen. Mitchell" | "he"; "is confident he has ... [such] [a] measure with"; "procedural actions") ("Sen. Mitchell" | "he";</p><p>"is confident he has ... [such] [a] measure"; "with procedural actions") <ref type="table" target="#tab_3">Table 2</ref>: An example sentence with four BenchIE fact synsets (f 1 -f 4 ). BenchIE accounts for entity coreference and accepts triples with both "Sen. Mitchell" and "he" as subjects: the delimiter "|" is just a shorthand notation for different extractions. Similarly, the square brackets ([]) represent a shorthand notation for multiple extractions: triples both with and without the expression(s) in the brackets are considered correct. and (2) they reward incorrect extractions that have high lexical overlap with a gold extraction, e.g., ("Sen. Mitchell"; "is confident he has"; "procedural actions") vs. ("Sen. Mitchell"; "is confident he has"; "sufficient votes to block. . . with procedural actions").</p><p>To prevent this, BenchIE relies on exact matching of system extractions against the gold fact synsets. Further, some OIE systems (over)generate extractions of the same fact; e.g., ("Sen. Mitchell"; "has sufficient votes to block"; "such a measure") and ("Sen. Mitchell"; "has sufficient votes to block"; "measure"). Existing evaluation procedures do not acknowledge the fact equivalence of extractions and consequently reward OIE systems for multiply extracting the same fact. Our evaluation based on fact synsets directly remedies these shortcomings of existing OIE benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Annotation Process</head><p>English Benchmark. To make BenchIE comparable to previous benchmarks, we annotate fact synsets on a subset of sentences from CaRB <ref type="bibr" target="#b5">(Bhardwaj et al., 2019)</ref>. Because exhaustive annotation of fact synsets is time consuming, we carried it on 300 (out of 1,200) randomly sampled CaRB sentences. To collect truly exhaustive fact synsets, two expert annotators independently labeled the selected 300 sentences in three rounds. (1) Each annotator first (independently) manually denoted every extraction in which a VP-predicate connects two concepts. The annotator then grouped the fact-equivalent triples into fact synsets. 3 To speed the annotation process up, we developed a dedicated web-based annotation tool AnnIE that facilitates the extraction of VP-mediated triples (e.g., we color-code verbs to indicate possible predicate heads) and their clustering into fact synsets; 4 (2) The annotators then carefully examined all gold extractions from the original CaRB dataset and added those judged to be correct, yet missing from the manually labeled fact synsets from the previous step; (3) Finally, each annotator compared the extractions of all OIE systems in evaluation (see ?4) against the BenchIE's fact synsets (i.e., the result of the first two steps). Any system extraction not found in BenchIE was carefully examined and-if judged to be correctadded to the appropriate fact synset. 5 Finally, the two annotators merged their independently created annotations by discussing and jointly resolving the disagreements. The overall annotation effort for the English dataset amounted to 80 hours per annotator. English BenchIE contains 136,357 unique gold extractions, grouped into 1,350 fact synsets. For comparison, CaRB <ref type="bibr" target="#b5">(Bhardwaj et al., 2019)</ref> lists mere 783 gold triples for the same 300 sentences. <ref type="table" target="#tab_3">Table 2</ref> shows fact synsets for an example sentence.</p><p>Inter-Annotator Agreement (IAA). To validate BenchIE's annotations, we measure the interannotator agreement (IAA) between our two expert annotators. To this end, we quantify the agreement via recall at the fact level (see ?2.3 for further details): for each annotator, we compute their factlevel recall as the percentage of fact synsets of the other annotator they cover with their extractions. <ref type="bibr">6</ref> We average the fact-level recalls of the two annotators as the IAA score. We observed a high IAA score of 0.79. Upon manual inspection, we found that the annotators mostly agree on factsynset level; most of the the disagreements are on extractions level (particularly, from marking the optional tokens within an extraction; see Appendix A.1.3 for details about the optional tokens).</p><p>Chinese and German Benchmarks. Two bilingual expert annotators -native in the target language and fluent in English (EN ) -translated the original 300 English sentences to Chinese (ZH ) and German (DE ), respectively. Then, to collect exhaustive fact synsets in ZH and DE , they followed the same three annotation rounds described for ?2.2. Due to substantial (primarily syntactic) differences compared to EN , we adjusted the annotation guidelines for these languages (see the Appendix A.2 and A.3 for more details). The statistics (number of fact synsets and extractions) of the ZH and DE benchmarks are given in <ref type="table" target="#tab_1">Table 3</ref>. Compared to EN BenchIE, the ZH benchmark contains significantly fewer fact synsets (994 compared to 1,350) and more than two orders of magnitude fewer extractions. The drastically smaller number of extractions is primarily due to the lack of determiners and articles in Chinese. Their frequent occurrence in English combined with their neutrality w.r.t. extractions' correctness results in many mutually different yet fact-equivalent extractions. The numbers for German are, expectedly, much closer to those for English.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Evaluation Measure</head><p>We assume that BenchIE is (1) complete, i.e., that it contains (a) all VP-mediated facts expressed in input sentences and (b) for each fact, its every acceptable extraction as well; and (2) sound, i.e., that it does not contain any incorrect extraction that would capture a fact not stated in the sentence. Such a complete OIE gold standard enables not only a more reliable evaluation of OIE systems by means of exact matching, but also an evaluation at the more meaningful level of knowledge facts, rather than at the level of individual triples. Concretely, we consider a system extraction to be correct if and only if it exactly matches some gold extraction from some fact synset. The number of true positives (TPs) is the number of fact synsets (i.e., different facts) covered by (at least one of the) system extractions. This way, a system that extracts N different triples of the same fact, will be rewarded only once for the correct extraction of the fact. BenchIE's false negatives (FNs) are then, intuitively, fact synsets not covered by any of the system extractions. Finally, each system extraction that does not exactly match any gold triple (from any synset) counts as a false positive (FP). We then compute Precision, Recall, and F 1 score (as the final score) from TP, FP, and FN in standard fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Multi-Faceted OIE Benchmark</head><p>Different downstream applications care about different aspects of OIE extractions. For IE-based text summarization and simplification <ref type="bibr" target="#b33">(Ponza et al., 2018;</ref><ref type="bibr" target="#b36">?tajner and Glava?, 2017)</ref>, e.g., triples should be minimal overall, across all slots (i.e., without unnecessary tokens), but the exact token placement across the slots (e.g., if a preposition is in the predicate or object) does not matter. For entity linking and knowledge base population <ref type="bibr" target="#b28">(Lin et al., 2020)</ref>, in contrast, the token placement between slots is critical: a token that is not part of an entity, should not be placed into subject or object. Acknowledging this, we create three additional variants of the English BenchIE, referred to as facets, each BenchIE-E ("Sen. Mitchell" | "he";</p><p>"is confident he has ... <ref type="bibr">[such]</ref> [a] measure with"; "procedural actions")</p><p>BenchIE-C "(Sen. Mitchell | he) is confident he has sufficient votes to block [such] [a] measure with procedural actions"</p><p>BenchIE-M ("Sen. Mitchell" | "he"; "is confident he has sufficient votes to block measure with"; "procedural actions") ("Sen. Mitchell" | "he";</p><p>"is confident he has sufficient votes to block measure"; "with procedural actions")  <ref type="table" target="#tab_3">Table 2</ref>): all acceptable surface realizations under each facet are shown. "|" and square brackets have the same shorthand notation purpose as in <ref type="table" target="#tab_3">Table 2</ref>.</p><p>corresponding to one aspect that is relevant in common OIE applications. This effort addresses recent calls for multi-dimensional analysis of NLP systems <ref type="bibr" target="#b11">(Ethayarajh and Jurafsky, 2020;</ref><ref type="bibr" target="#b32">Narayan et al., 2021)</ref> and is well-aligned with recent efforts that create multi-faceted benchmarks for other NLP tasks <ref type="bibr" target="#b29">(Liu et al., 2021;</ref><ref type="bibr" target="#b39">V?th et al., 2021)</ref> and datasets <ref type="bibr">(Xiao et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">BenchIE-E</head><p>The default, general-purpose BenchIE facet from the previous section was designed to be somewhat tolerant to token distribution accross slots (see Appendix A.1.2 for details): some tokens may be placed in either the predicate or object (e.g., the preposition with in the synset f 4 in <ref type="table" target="#tab_3">Table 2</ref>). This enables a more flexible comparison of OIE systems that are designed for different purposes (i.e., systems that produce slightly different token placements are not punished) and is in line with prior work on intrinsic OIE evaluation, both automatic <ref type="bibr" target="#b37">(Stanovsky and Dagan, 2016;</ref><ref type="bibr" target="#b5">Bhardwaj et al., 2019)</ref> and manual <ref type="bibr" target="#b12">(Fader et al., 2011;</ref><ref type="bibr" target="#b8">Del Corro and Gemulla, 2013;</ref><ref type="bibr" target="#b15">Gashteovski et al., 2017)</ref>. Such extraction flexibility, however, may not be desirable in tasks like automated KG construction <ref type="bibr" target="#b41">(Wolfe et al., 2017;</ref><ref type="bibr" target="#b21">Jiang et al., 2019)</ref> or entity linking <ref type="bibr" target="#b28">(Lin et al., 2020</ref><ref type="bibr" target="#b27">(Lin et al., , 2021</ref>. <ref type="bibr" target="#b2">Angeli et al. (2015)</ref> show empirically that extractions with wholesome entities and without additional tokens yield benefits in KG construction.</p><p>Since OIE is predominantly used for KG-related tasks <ref type="bibr" target="#b40">(Weikum et al., 2020)</ref>, it is paramount to have an evaluation facet that imposes strict(er) token boundaries on entity slots -subjects and objects. We thus create the entity facet of the benchmark (BenchIE-E) with this additional constraint of wholesomeness of subject and object concepts. BenchIE-E was constructed by one of our annotators (see ?2.2) by removing from EN BenchIE's fact synsets the extractions in which subject and/or object was not a wholesome concept (see <ref type="table" target="#tab_2">Table 4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">BenchIE-C</head><p>The default BenchIE facet ( ?2) compares OIE extractions against gold triples from fact synsets at the slot level: to be judged correct, an extraction must exactly match some gold triple in all slots. This criterion, however, is overly strict if extractions are to be used in applications like summarization or simplification <ref type="bibr" target="#b33">(Ponza et al., 2018;</ref><ref type="bibr" target="#b36">?tajner and Glava?, 2017)</ref>, which commonly concatenate the content of the slots. In this case, it does not matter if a sequence of tokens occurs at the end of the subject or beginning of the predicate (analogously for predicate and object). To reflect this, we introduce the concatenation facet, BenchIE-C: for each gold BenchIE triple, we create the gold BenchIE-C utterance by simply concatenating the content of the triple's slots (see <ref type="table" target="#tab_2">Table 4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">BenchIE-M</head><p>Our third additional evaluation facet addresses the aspect of minimality of OIE extractions <ref type="bibr" target="#b15">(Gashteovski et al., 2017)</ref>. More compact extractions can benefit both text generation <ref type="bibr" target="#b33">(Ponza et al., 2018;</ref><ref type="bibr" target="#b36">?tajner and Glava?, 2017)</ref> and KG-related tasks <ref type="bibr" target="#b28">(Lin et al., 2020</ref><ref type="bibr" target="#b27">(Lin et al., , 2021</ref>. If two triples t 1 and t 2 capture the same fact (i.e., are in the same fact synset), t 1 is considered more compact than t 2 if tokens of each t 1 slot make a (non-strict) subsequence of tokens in the corresponding t 2 slot <ref type="bibr" target="#b14">(Gashteovski, 2020)</ref>. <ref type="bibr">7</ref> To allow for evaluation of minimality, BenchIE-M triples contain only the non-optional tokens (denoted in square brackets in  scoring <ref type="bibr" target="#b5">(Bhardwaj et al., 2019)</ref>. 9 Our quantitative results confirm our intuitions and observations (see <ref type="table">Table 1</ref>  <ref type="bibr" target="#b34">(Ro et al., 2020)</ref>. We additionally implemented the following naive baseline (Naive OIE): each verb (detected using spaCy's POS-tagger <ref type="bibr" target="#b20">(Honnibal and Montani, 2017)</ref>) becomes the predicate, its entire preceding sentence context becomes the subject and succeeding context the object. For ZH and DE , we evaluated a supervised M 2 OIE <ref type="bibr" target="#b34">(Ro et al., 2020)</ref> model based on the multilingual BERT <ref type="bibr" target="#b9">(Devlin et al., 2019)</ref>, trained on a large EN dataset <ref type="bibr" target="#b45">(Zhan and Zhao, 2020)</ref> and transferred (zero-shot) to target languages by means of its multilingual encoder.</p><p>Implicit and N-ary Extractions. Some OIE systems produce implicit extractions containing tokens that do not occur in the sentence. 10 As BenchIE does not contain implicit annotations, we remove such extractions from the OIE systems' output, to avoid penalizing OIE systems for extracting fact types not covered by the benchmark.</p><p>To make CaRB directly comparable, we automati-9 CaRB is an improved version of the widely-adopted OIE2016 benchmark <ref type="bibr" target="#b37">(Stanovsky and Dagan, 2016)</ref>; our findings for CaRB are thus likely to hold for OIE2016 as well. 10 E.g., the triple ("Biden"; "be"; "President") extracted from the phrase "President Biden ..." cally remove all its implicit extractions too. ROIE and M 2 OIE produce N-ary extractions (i.e., more than three slots), whereas BenchIE contains only triples. We follow standard practice (Del Corro and Gemulla, 2013) and convert those extractions into triples by concatenating the third and subsequent slots into a single object. <ref type="table" target="#tab_4">Table 5</ref> summarizes results of OIE systems on BenchIE and CaRB. Across the board, BenchIE's fact-level precision and recall are significantly lower than CaRB's respective precision and recall computed on token level. On average, CaRB scores the OIE systems higher than BenchIE by 14 percentage points for precision, 38 percentage points for recall and 26 percentage points for the F 1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results and Discussion</head><p>Precision. System's precision on BenchIE is lower (albeit not so drastically lower as recall) than on CaRB because BenchIE, as a complete benchmark, punishes incorrect facts, i.e., extractions that cannot be found in BenchIE's fact synsets. CaRB, on the other hand, rewards any token overlap that the incorrectly extracted fact has against its gold triple(s) -in many cases such overlap is substantial and CaRB consequently rewards the incorrect fact with high precision. Consider, for example, the sentence from <ref type="table">Table 1</ref> and an incorrect fact extraction ("Sen. Mitchell"; "is confident he has"; "sufficient actions"); on BenchIE, this extraction is a false positive because it does not exist in any of the four fact synsets it lists for the sentence. CaRB, in contrast, rewards the extraction with perfect precision because all its tokens are accounted for in the corresponding slots of its gold triple ("Sen. Mitchell"; "is confident he has"; "sufficient votes to . . . actions").</p><p>In an attempt to quantify how much CaRB overestimates fact-level precision with its token overlap metric, we evaluated our Naive OIE baseline on both CaRB and BenchIE. While BenchIE reflects the poor quality of naive extractions with the nearzero performance, CaRB estimates its precision to be non-negligible (0.24) and even higher than that of the Stanford's OIE system (0.17). In contrast, BenchIE assigns much lower score to this baseline: precision of 0.03-8 times less than CaRB's score.</p><p>Recall. While CaRB somewhat overestimates factlevel precision of OIE systems, its overestimation of their recall is much more drastic: all tokens of its gold extractions that can be found in respective slots of a factually incorrect extraction of an OIE system contribute to the system's recall. The overestimation of CaRB's recall scores is best illustrated by the fact that our naive baseline (Naive OIE) obtains a score of 0.7, better than any of the six OIE systems under evaluation. In terms of recall, CaRB obviously rewards long extractionsthe longer the system extraction is, the more likely it is to cover more tokens from gold standard extractions. Neural extractors OpenIE6, ROIE, and M 2 OIE on average produce much longer extractions than rule-based systems like MinIE or Stanford (e.g., on average, a ROIE extraction has 16 tokens, whereas Stanford extraction has 7.7 tokens): accordingly, CaRB rewards the neural systems with much higher recall scores. BenchIE, on the other hand, credits only the OIE extractions that cover its fact synsets (and only once per fact synset). Our Naive OIE is, intuitively, highly unlikely to match gold extractions from fact synsets and BenchIE reflects this with a fact-level recall of only 2%. Similarly, BenchIE's recall scores reveal that the long extractions of neural OIE systems very rarely correspond to any acceptable variant of an expressed fact (e.g., ROIE's fact-level recall is only 9%).</p><p>Multilingual OIE. We evaluated M 2 OIE (as the only multilingual model in our evaluation) on the Chinese and German versions of BenchIE. Quite expectedly, the performance for Chinese and German in target languages is below the source English performance. However, the drop due to the zero-shot language transfer is, at first glance -surprisingly, much larger for German than for Chinese: this goes against findings from other tasks, where transfer performance correlates with linguistic proximity between the source and target language <ref type="bibr" target="#b24">(Lauscher et al., 2020)</ref>. M 2 OIE's Chinese (2) the figure does not indicate systems' absolute error rates (for performance comparison, see <ref type="table" target="#tab_4">Table 5</ref>).</p><p>performance is encouraging, as it surpasses the English performance of some of the other OIE models (e.g., its recall score is better than ROIE, and its precision score is better than Stanford's). We believe this is because (a) OIE is a highly syntactic task; and (b) Chinese language is syntactically simple and has the same word order as English (SVO). German language, on the other hand, despite overall linguistic proximity to English, has a different word order (SOV; from generative perspective), with the main verb often appearing at the very end of the sentence -this, we believe, is the main cause of poor OIE transfer between English and German. We believe BenchIE is a good starting point for multilingual OIE evaluation: we subsequently created additional data for Arabic, Galician, and Japanese: see  and <ref type="bibr" target="#b13">Friedrich et al. (2022)</ref> for details and further analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Profiling OIE Systems with BenchIE</head><p>Token-based evaluation of existing OIE benchmarks (with real per-extraction scores in the range [0, 1]) makes pinpointing of extraction error source difficult. This limits their usability in automatic error analysis and system profiling. The fact that previous work performed OIE error analyses manually <ref type="bibr" target="#b12">(Fader et al., 2011;</ref><ref type="bibr" target="#b35">Schneider et al., 2017)</ref> confirms this. BenchIE, in contrast, lists all acceptable extractions and thus naturally lends itself to reliable automatic error analysis and profiling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Slot Errors</head><p>We carry out the analysis of errors per slots on the default BenchIE facet ( ?2), because it is application-agnostic, unlike the additional facets from ?3. We observed that most of the errors in all OIE systems stem from extracting the objects (see <ref type="figure" target="#fig_0">Figure 1</ref>). For an SVO language like English,  correctly extracting subjects and predicates seems substantially easier than correctly extracting objects. MinIE (rule-based) and ROIE (neural) have higher shares of predicate mis-extractions. MinIE post-processes ClausIE's triples by moving words from objects to predicates. Since ClausIE most frequently makes object errors, this effectively redistributes those errors between predicates and objects of MinIE's extractions. <ref type="figure" target="#fig_0">Figure 1</ref>, however, does not tell the whole story, as many extractions are erroneous in multiple slots. For more detailed insights, we assign each incorrect extraction to one of seven error buckets: each error bucket indicates one combination of extraction errors across the three slots. For example, the bucket (1, 1, 0) contains extractions that match their closest gold triple in the subject and predicate, but not object. The closest gold triple is the one that matches the extraction in most slots. <ref type="bibr">11</ref> The error-bucket analysis, summarized in <ref type="figure" target="#fig_1">Figure  2</ref>, reveals that, across all systems, most extractions with object errors actually have correct subjects and predicates (bucket <ref type="figure" target="#fig_0">(1, 1, 0)</ref>). MinIE deviates from this pattern and produces also many extractions with both incorrect object and predicate (bucket (1, 0, 0)) or only bad predicate <ref type="figure" target="#fig_0">(bucket (1, 0, 1)</ref>). Expectedly, most extractions of our naive baseline most often get only the predicate right (bucket (0, 1, 0)) or all three slots wrong (bucket (0, 0, 0)). This further emphasizes how misleading current token-based benchmarks can be -CaRB rewards this baseline with very high recall (see ?4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Bucketized Error Analysis</head><p>To understand where OIE systems fail systematically, we split the input sentences into buckets and measured the performance of OIE systems per <ref type="bibr">11</ref> An incorrect extraction may have several "closest" gold triples that correspond to different error buckets. In this case, we increase the count for all competing buckets. bucket. Based on preliminary qualitative error analysis, we chose bucketization according to some linguistic properties of the sentences that produced erroneous triples. In particular, we examine the performance of OIE systems for sentence length, presence of conjunctions and case markers, since these appeared to be the most common reasons for failure. Note that BenchIE instances can be "bucketized" according to an arbitrary dimension interest, lending itself to diverse future fine-grained evaluations and analyses of OIE systems' behaviour. In general, we found that OIE systems exhibit weakest performance on long sentences (with more than 30 tokens) as well as those that contain conjunctions or have more than two case markers <ref type="figure" target="#fig_2">(Figure 3)</ref>. For a more detailed discussion, see Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Multi-Faceted Evaluation</head><p>Finally, we profile the OIE systems on our three special benchmark facets ( ?3): BenchIE-E, -C and -M. <ref type="figure" target="#fig_3">Figure 4</ref> summarizes the performance of OIE systems on these three facets.</p><p>BenchIE-C. Ignoring slot boundaries, this facet is more lenient to OIE systems than the default facet -BenchIE-C yields higher scores than the regular BenchIE facet for all systems. The gap between the system's performance on BenchIE-C and BenchIE effectively quantifies how often the system misplaces tokens between adjacent slots. This gap is very small for Stanford OIE and MinIE -this means that, for extractions with correct overall token span, they also distribute the tokens between the slots correctly. For downstream tasks like text summarization, BenchIE-C results point to ClausIE as the best choice. Interestingly, we observed that CaRB's Precision for some systems (ClausIE and MinIE) effectively matches their Precision on BenchIE-C (see <ref type="figure" target="#fig_3">Figure 4)</ref>, which is another indication that CaRB scores, in effect, neglect precise token distributions across slots.</p><p>BenchIE-E. This facet is stricter than the default BenchIE facet -it allows fewer token placement variants in subject and object. For all OIE systems the F 1 BenchIE-E score is thus lower than the corresponding BenchIE score. MinIE and Stanford OIE obtain very similar performance on BenchIE-C, BenchIE (default), and BenchIE-E: this means that their extraction (when correct in overall token span) most often have clean concepts in subject and object. All neural systems and ClausIE exhibit huge performance drops on BenchIE-E -this  means that their subject and object concept extractions are not clean, which makes these systems less suitable for tasks like KG population and entity linking. Out of the systems we evaluate, MinIE is the best fit for such downstream tasks.</p><p>BenchIE-M. This facet yields the lowest performance for all systems, as it punishes extractions with any unnecessary tokens. Expectedly, MinIE -a system tailored to produce minimal extractions -yields the best performance on this facet. But even MinIE "loses" half of its performance when minimality is enforced (BenchIE vs. BenchIE-M). This calls for more work on minimizing OIE extractions. Stanford OIE outperforms all systems except MinIE, which renders it a good pick when extraction minimality is beneficial for a downstream task.</p><p>Neural vs. Rule-Based Systems. Neural systems underperform their rule-based counterparts on most facets. This gap is most pronounced on BenchIE-E, whereas it is much smaller on BenchIE-C: these observations strongly indicate that neural systems struggle the most with correct distribution of tokens across the (adjacent) extraction slots. They also do not attempt to remove the optional (i.e., unnecessary) tokens, as indicated by extremely low performance on BenchIE-M. On CaRB, however, these same neural systems yield the best performance. Being trained and validated on datasets with extractions similar to CaRB's, neural extractors seem to overfit to CaRB evaluation. Our factbased multi-faceted evaluation, however, reveals that their extractions are far less likely to be useful down the stream.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We introduced BenchIE: a benchmark for more reliable fact-level evaluation of OIE systems for English, Chinese and German. Unlike existing benchmarks, BenchIE takes into account fact-level equivalence of extractions: it consists of fact synsets that contain all acceptable surface forms of the same fact. Further, EN BenchIE is multi-faceted -it allows to evaluate OIE extractions w.r.t. several aspects relevant in common downstream tasks. Our experiments show that current benchmarks, with incomplete gold standard and approximate tokenlevel matching, drastically overestimate fact extraction abilities of OIE systems. Currently, the limits of BenchIE are its relatively small size (300 sentences v.s. CaRB's 1,200) and its time-consuming annotation process. A promising research direction is the investigation of trade-off between the manual effort and completeness of different OIE annotation strategies. In this scenario, BenchIE is an ideal point of reference: it can precisely quantify the completeness of some larger (non-exhaustive) OIE dataset created with limited or no manual effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix: Annotation Guidelines</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Annotation Guidelines for English</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.1 General Principle</head><p>The annotator should manually extract verbmediated triples from a natural language sentence. Each triple should represent two entities or concepts, and the verb-mediated relation between them. For example, from the input sentence "Michael Jordan, who is a former basketball player, was born in Brooklyn.", there are three entities and concepts-Michael Jordan, former basketball player and Brooklyn-which are related as follows: ("Michael Jordan"; "is"; "former basketball player") and ("Michael Jordan"; "was born in"; "Brooklyn").</p><p>Once the triple is manually extracted, it should be placed into the correct fact synset (see Section A.1.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.2 Fact Synsets</head><p>Once a triple is manually extracted, the annotator should place the triple into its corresponding fact synset (for more details about the concept of fact synsets, refer to Section 2). In case there is no existing fact synset for the manually extracted triple, the annotator should create one and place the triple in that synset.</p><p>Coreference. The annotator should place extractions that refer to the same entity or concept under the same fact synset. Consider the following input sentence: "His son , John Crozie, was an aviation pioneer."; the following triples should be placed in the same fact synset:</p><p>? ("His son"; "was"; "[an] 12 aviation pioneer")</p><p>? ("J. Crozie"; "was"; "[an] aviation pioneer") because "His son" and "John Crozie" refer to the same entity.</p><p>Token placements within the slots. The annotator should consider placing certain tokens in different slots, without damaging the meaning of the fact. Consider the input sentence "Michael Jordan was born in Brooklyn.". There is one fact synset (f 1 ) and its corresponding triples (t 1 , t 2 and t 3 ):</p><p>f 1 t 1 : ("M. J."; "was born in"; "Brooklyn") t 2 : ("M. J."; "was born"; "in Brooklyn") t 3 : ("M. J."; "was"; "born in Brooklyn") 12 words in square brackets indicate optional tokens (see Section <ref type="bibr">A.1.3)</ref> In t 1 , the preposition "in" is in the relation, while in t 2 it is in the object. Likewise, the annotator should allow for some flexibility w.r.t. the verbs. While the verbs and prepositions naturally belong to the relation, some OIE systems were designed with different goal in mind; e.g., to detect head verbs as relations for detecting clauses within the extractions <ref type="bibr" target="#b8">(Del Corro and Gemulla, 2013)</ref> or to fit SRL frames for predicates <ref type="bibr" target="#b38">(Stanovsky et al., 2018)</ref>. We do not want to penalize the OIE systems for such design choices.</p><p>For BenchIE-E 13 , however, this flexibility of token placements is not allowed. In particular, for f 1 the annotator is allowed to only extract t 1 , while t 2 and t 3 should not be listed. Note that this is the only difference in the annotation guidelines between BenchIE-E and the standard BenchIE facet.</p><p>Passive voice. When possible, if an extraction is in passive voice, the annotator should place its active voice equivalent into the appropriate fact synset. For instance, consider the sentence "The ball was kicked by John."; then, the fact synset should contain the following triples:</p><p>? ("[The] ball"; "was kicked by"; "John")</p><p>? ("John"; "kicked"; "[The] ball") Note that the opposite direction is not allowed. If the sentence was "John kicked the ball.", then the annotator is not allowed to manually extract the triple ("[The] ball"; "was kicked by"; "John") because such extraction contains words that are not originally found in the input sentence ("was" and "by"). These are so-called implicit extractions and we do not consider them (for details, see Section A.1.8 of the appendix).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.3 Optional Tokens</head><p>If possible, the annotator should label as optional all tokens that can be omitted in an extraction without damaging its semantics. Such tokens include determiners (e.g., a, the, an), honorifics (e.g., Determiners. Unless a determiner is a part of a named entity (e.g., "The Times"), it is considered as optional. For instance, the following triples are considered to be semantically equivalent: <ref type="bibr">13</ref> For details on BenchIE-E, see Section 3.1.</p><p>? ("Michael Jordan"; "took"; "the ball")</p><p>? ("Michael Jordan"; "took"; "ball")</p><p>The annotator, therefore, should annotate ("Michael Jordan"; "took"; "[the] ball"), where the optional token is in square brackets.</p><p>Titles. Titles of people are considered optional; e.g., ("[Prof.] Michael Jordan"; "lives in"; "USA").</p><p>Adjectives. The annotator should label adjectives as optional if possible. For example, in the following triple, the adjective "smart" can be considered optional: ("Albert Einstein"; "was"; "[a]</p><p>[smart] scientist"). Note that the annotator should be careful not to label adjectives as optional if they are essential to the meaning of the triple. For instance, the adjective "cold" should not be labeled as optional in the triple ("Berlin Wall"; "is [infamous] symbol of"; "[the] cold war").</p><p>Quantities. Certain quantities that modify a noun phrase can be considered as optional; e.g., ("Mitsubishi"; "has control of"; "[some] major projects").</p><p>Words indicating some tenses. The annotator can treat certain verbs that indicate tense as optional. For instance, the word "has" in ("FDA"; "[has] approved"; "Proleukin") can be considered as optional, since both VPs "have approved" and "approved" contain the same core meaning.</p><p>Verb phrases. It is allowed for the annotator to mark verb phrases as optional if possible; e.g. ("John"; "[continues to] reside in"; "Berlin").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.4 Attribution Clauses</head><p>Extractions that indicate attribution of another core piece of information should be placed in separate fact synset, because they indicate a separate piece of information with separate predicate. For example, the core information of the sentence "Conspiracy theorists say that Barack Obama was born in Kenya." is that Barack Obama was born in Kenya. As indicated by <ref type="bibr" target="#b31">Mausam et al. (2012)</ref>, it is important for OIE systems to extract the context about the attribution of such information. Therefore, the annotator should extract the core informationthe triple ("Barack Obama"; "[was] born in"; "Kenya")-in one fact synset, and the triples indicating attribution-("Conspiracy theorists"; "say that"; "Barack Obama was born in Kenya")-in another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.5 Incomplete Clauses</head><p>The annotator should not extract incomplete clauses, i.e., triples that lack crucial piece of information. Suppose there is the input sentence "He was honored by the river being named after him". The following triple should not be manually extracted: ("He"; "was honored by"; "[the] river"), but the following triples should be: ("He"; "was honored by [the] river being named after"; "him") and ("[the] river"; "being named after"; "him").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.6 Overly Complex Extractions</head><p>The annotators should not manually extract overly specific triples, such that their arguments are complex clauses. For instance, for the input sentence "Vaccinations against other viral diseases followed, including the successful rabies vaccination by Louis Pasteur in 1886.", the following triple should not be extracted: ("Vaccinations against other viral diseases"; "followed"; "including the successful rabies vaccination by Louis Pasteur in 1886") because the object is a complex clause which does not describe a single concept precisely, but rather it is composed of several concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.7 Conjunctions</head><p>The annotator should not allow for conjunctive phrases to form an argument (i.e., subject or object). Such arguments should be placed into separate extractions (and in separate fact synsets). Consider the sentence "Michael Jordan and Scottie Pippen played for Chicago Bulls.". The annotator should manually extract the following triples:</p><p>? ("M. Jordan"; "played for"; "Chicago Bulls")</p><p>? ("S. Pippen"; "played for"; "Chicago Bulls")</p><p>The annotator should not, however, extract ("M. J. and S. P."; "played for"; "Chicago Bulls").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.8 Implicit Extractions</head><p>We focus on explicit extractions, which means that every word in the extracted triple must be present in the original input sentence. Therefore, implicit extractions-i.e., extractions that contain inferred information with words not found in the sentenceare not considered. One example implicit extraction is ("Michael Jordan"; "be"; "Prof.") from the input sentence "Prof. Michael Jordan lives in USA.", where the triple infers that Michael Jordan is professor without being explicitly indicated in the sentence (i.e., the word "be" is not present in the input sentence, it is inferred).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Annotation Guidelines (Chinese)</head><p>The annotator should follow the same general principles as with the English annotation guidelines (Section A.1). Due to the language difference, we slightly adapted the annotation guidelines for the Chinese language. In what follows, we list those differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.1 Articles</head><p>Chinese language does not contain articles (i.e., "a", "an", "the"). Therefore, in the manual translation of the sentences, there are no articles in the Chinese counterparts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 Prepositional Phrases within a Noun Phrase</head><p>Certain noun phrases with nested prepositional phrase cannot be translated directly into Chinese the same way as in English. For example, suppose we have the phrase "Prime Minister of Australia". In Chinese, the literal translation of this phrase would be "Australia's Prime Minister". For instance, in the English annotations the sentence "He was the Prime Minister of Australia" would have two fact synsets: This is because the fact synset f 1 relates the concepts "he" and "Australia" with the relation "was [the] Prime Minister of", while the second fact synset relates the concepts "he" and "Prime Minister [of Australia]" with the relation "was".</p><p>In Chinese language, however, the construction of f 1 would not be possible, because the phrase "Prime Minister of Australia" cannot be separated into "Prime Minister" and "Australia". Therefore, the golden annotation for this particular example in Chinese would be only one fact synset: ("He"; "was"; "[Australia's] Prime Minister"), which is equivalent with f 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Annotation Guidelines (German)</head><p>In general, the annotators for German should follow the same guidelines described in Section A.1 for English. In what follows, we describe the differences which are specific for the German annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.1 Separable Verbs</head><p>Separable verbs (e.g., "aufstehen") in German consist of a lexical core (a verb; "stehen") and a separable particle (e.g., a preposition; "auf"). When used in a sentence, separable verbs in German are split in such manner that the separable particle goes to the end of the sentence. Consider the following sentence that contains the separable verb "aufstehen": "Ich stehe um 7 Uhr auf". To accommodate the verb-mediated relations, the annotator should extract the separable particle right after the separable core within the predicate: ("Ich"; "stehe auf um"; "7 Uhr")</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.2 Modal Verbs</head><p>The modal verbs follow similar pattern as the separable verbs. Namely, the modal verb has the main predicate position within the sentence (directly followed by the subject), and the main verb that is modified by the modal verb is at the end of the sentence; e.g. sentence "I must go to work" and its German counterpart "Ich muss zur Arbeit gehen". Following the same guidelines for verb-mediated predicates, the annotator should extract the modal verb together with the main verb: ("Ich"; "muss gehen zur"; "Arbeit").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.3 Passive Voice</head><p>Consider the following English sentence written in passive voice "The letters were sent through the messenger" and its German counterpart "Die Briefe wurden durch den Boten geschickt". Following the spirit of extractions with verb-mediated relations, the annotator should extract the following triple: ("[Die] Briefe"; "wurden geschickt durch"; "[den] Boten").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Annotation Tool</head><p>To facilitate the annotation process, we developed a web-based annotation tool: AnnIE <ref type="bibr" target="#b13">(Friedrich et al., 2022)</ref>. First, the annotator is given the input sentence as a string along with its tokenized form <ref type="figure" target="#fig_6">(Figure 5)</ref>. Then, the tool highlights the tokens of interest that are candidates for the slots. In particular, we highlight the verbs in one color (candidate predicates) and the nouns in another (candidate arguments).</p><p>Then, the annotator can select the tokens with a UI and place them into slots. This forms one annotated triple. Note that the annotator can also annotate for optional tokens and phrases with the  The user selects tokens from the tokenized input sentence and places them into the correct slot: subject (green), predicate (yellow) or object (blue). Then, the user adds the extracted triple either to an active fact cluster (i.e., fact synset) or to a new one. The user can also select which tokens are optional by clicking the "Optional" button on an active token selection. use of the mouse double click. Then, the annotator can place the newly annotated triple in either a new fact synset (cluster) or in an existing one ( <ref type="figure" target="#fig_7">Figure 6</ref>). For more details on the annotation tool, see <ref type="bibr" target="#b13">(Friedrich et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Further Error Analysis</head><p>Based on preliminary qualitative error analysis, we chose bucketization according to some linguistic properties of the sentences that produced erroneous triples. In particular, we examine the performance of OIE systems for sentence length, presence of conjunctions and case markers, since these appeared to be the most common reasons for failure. Note that BenchIE allows for any type of bucketization, which can be used for diverse set of fine-grained evaluation for future research on OIE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Sentence Length</head><p>Sentence length is a feature that can affect the performance of NLP systems for different tasks, including relation extraction <ref type="bibr" target="#b1">(Alt et al., 2020)</ref> and named entity recognition <ref type="bibr" target="#b3">(Arora et al., 2021)</ref>. To evaluate how sentence length afffects performance of OIE systems as well, we split the sentences into three buckets: sentences shorter or equal than 20 tokens, between 21 and 30 tokens, and more than 30 tokens. The distribution of these buckets are 120, 113 and 67 sentences respectively.</p><p>We observed that shorter sentences usually yield the best performance for all OIE systems w.r.t. the F 1 score <ref type="figure" target="#fig_8">(Figure 7a</ref>). An extreme example is MinIE, which loses 26 percentage points from sentences shorter than 20 tokens to sentences longer than 30 tokens. Part of the reason why such sentences are harder to handle is because they contain more complex linguistic structures, such as conjunctions and case markers. Such sentences tend to to produce overly complex extractions that contain very complex structures in their arguments (see example extraction t 3 in <ref type="table" target="#tab_7">Table 6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Conjunctions</head><p>To examine the effect of the conjunctions on the performance of OIE systems, we bucketized the input sentences according to the dependency type conj, which relates two conjunct words in a sentence. In particular, we place the sentences with no conjuncts in one bucket, and the sentences with one or more conjuncts in another bucket. With such bucketization, half of the sentences are in the first bucket, and half in the other. We observed that the F1 score suffers when a sentence contains at least one pair of conjuncts <ref type="figure" target="#fig_8">(Figure 7b</ref>). This observation partially explains the observation from Section 5.1 that OIE systems have troubles identifying the objects correctly. In subsequent experiments, we observed that sentences with more than one conjuncts worsen the scores further compared to the sentences with one or no conjuncts. The triple t 5 in <ref type="table" target="#tab_7">Table 6</ref> is an example of such erroneous extraction.</p><p>Neural models seem to suffer the most due to the conjuncts. For instance, M 2 OIE loses more than half of the F1 score points (from 0.34 down to 0.16) when at least one conjunct is found in the sentence. The exception for the neural systems is OpenIE 6, which is more stable (goes down from 0.29 to 0.23). The reason is because OpenIE 6 was specifically trained to handle conjunctions. Interestingly, ClausIE and MinIE-rule-based systems-lose approximately the same amount of F1 score points as the neural OpenIE 6. This indicates that neu-Extraction ID</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extractions BenchIE</head><p>Sentence s1: "A large gravestone was erected in 1866 , over 100 years after his death." t1 ("A large gravestone"; "was erected"; "in 1866 over 100 y. after his death") 0 t2</p><p>("A large gravestone"; "was erected"; "in 1866") 1</p><p>Sentence s2: "The brightest star in Serpens, Alpha Serpentis, or Unukalhai, is a red giant of spectral type K2III located approximately away which marks the snake's heart ."</p><p>t3 ("The brightest star in Serpens, "is" "a red giant of sp. type K2III loc. app. 0 Alpha Serpentis , or Unukalhai" away which marks the snake 's heart") t4</p><p>("brightest star in Serpens"; "is"; "red giant") 1 Sentence s3: "Lugo and Lozano were released in 1993 and continue to reside in Venezuela.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>t5</head><p>("Lugo and Lozano"; "released"; "in 1993") 0 t6 ("Lugo"; "were released"; "in 1993") 1 t7 ("Lozano"; "were released"; "in 1993") 1 ral models can be trained to handle conjunctions similarly as rule-based systems, though there is still room for improvement. We observed similar behaviors for coordinated conjunctions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Case Markers</head><p>In preliminary qualitative experiments, we found that the objects are often overly specific because they include phrases that should in principle not be part of the expressed concept. Such excessively specific phrases are usually prepositional phrases or case markers. Consider, for example, the triple t 1 in <ref type="table" target="#tab_7">Table 6</ref>. The object in this triple is overly specific and, thus, incorrect.</p><p>To quantify the effect of such case markers, we bucketized the data according to the number of the typed dependencies case that are found in the input sentences. We observed that, as the number of case dependencies increases, the performance of OIE systems decreases <ref type="figure" target="#fig_8">(Figure 7c</ref>). We observed similar behavior for the number of prepositions in a sentence. The rule-based system ClausIE is very sensitive w.r.t. this property, while MinIE is more stable. MinIE was built on top of ClausIE and also focused on restructuring the output of ClausIE, which is the likely reason why MinIE is more robust w.r.t. the case markers. Neural systems (ROIE, OpenIE 6 and M 2 OIE) are very sensitive to this property, since their performance is much lower when we compare the buckets of 0 or 1 case dependency and the buckets with more than 4 case dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D More Detailed Discussion on Related Work D.1 OIE Benchmarks</head><p>The currently existing benchmarks are based on token-based scoring. The first attempt to create an OIE benchmark was OIE2016 <ref type="bibr" target="#b37">(Stanovsky and Dagan, 2016)</ref>. The authors used a dataset from another task-QA-SRL <ref type="bibr" target="#b18">(He et al., 2015)</ref>-and automatically ported it to OIE. For scoring an OIE triple, they follow the original task's guidelines <ref type="bibr" target="#b18">(He et al., 2015)</ref> and match only the grammatical heads of each slot from the OIE triple with the ones from the golden datasets. Such approach has many drawbacks <ref type="bibr" target="#b45">(Zhan and Zhao, 2020)</ref>, because (1) every error in the automatic porting transfers over to the evaluation dataset;</p><p>(2) triples are incorrectly (and over-optimistically) scored because it only considers token-overlaps on grammatical heads, not the whole slots. Being crowdsourced, CaRB <ref type="bibr" target="#b5">(Bhardwaj et al., 2019)</ref> improves over OIE2016 by aggregating per-slot token-level precision and recall scores between system and gold extractions across the three slots (subject, predicate, and object). However, such approach is overly-lenient, as it allows for incorrect extractions to be scored positively (see examples in <ref type="table">Table 1</ref>). Subsequent work followed similar evaluation procedures. For instance, <ref type="bibr" target="#b10">Dong et al. (2021)</ref> propose a dataset that evaluates document-level OIE which uses the same scoring procedures as CaRB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Multi-faceted Evaluation</head><p>While having a reliable single-metric benchmark is crucial for the progress of NLP, recent research indicated that focusing on single metrics is some-what limited, because it does not provide further insights that go beyond the averaged scores (Ethayarajh and Jurafsky, 2020; <ref type="bibr" target="#b32">Narayan et al., 2021)</ref>. In particular, <ref type="bibr" target="#b11">Ethayarajh and Jurafsky (2020)</ref> argue that single-metric scores ignore certain properties of the evaluated NLP models. Such properties, however, could be relevant for practitioners or for certain downstream tasks. As a consequence, the final evaluation score is computed at the expense of other properties of the model. To allow such multi-faceted evaluations, <ref type="bibr" target="#b29">Liu et al. (2021)</ref> proposed ExplainaBoard, which scores NLP systems from several tasks across different facets, and <ref type="bibr" target="#b39">V?th et al. (2021)</ref> propose a multi-faceted benchmark for visual question answering. Due to the incompleteness of current OIE benchmarks-and because of the peculiarity of the task-no such multi-faceted evaluation for OIE has been proposed. For each tested extraction, the state-of-the-art benchmarks provide scores that are in the interval of [0, 1]. Such design is employed because the benchmarks are incomplete, which, in turn, makes it difficult to do proper multi-faceted evaluation. To tackle this issue, we propose a multifaceted evaluation that scores OIE systems across several facets that are important for downstream tasks (see details in Section 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Automatic Error Analysis</head><p>Producing automatic error analysis with current benchmarks is not trivial because they are not exhaustive and do not provide crisp scores. For instance, when there are scores within the interval of [0, 1] for each slot-as in CaRB-, it is hard to say where exactly the error occurred. Previous work on OIE performed error analysis manually <ref type="bibr" target="#b12">(Fader et al., 2011;</ref><ref type="bibr" target="#b35">Schneider et al., 2017)</ref>, which is very time-consuming and inefficient. In contrast to prior work, BenchIE is exhaustive benchmark that provides crisp scores, which allows for automatic per-slot error analysis. We discuss BenchIE's automatic error analysis approach in Section 5.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Relative proportion of errors per slot for OIE systems. Note that (1) fractions do not add up to 1 as extraction can be erroneous in more than one slot; and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Distribution of incorrect extractions of OIE systems across different slot-error combinations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Bucketized experiments: F1 score according to different bucketizations of the input sentences: sentence length (a); number of conjunctions (b); number of case markers (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Multi-faceted evaluation of OIE systems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>[Prof.] Michael Jordan) or certain quantities (e.g., [some] major projects. The optional tokens are marked with square brackets [ ]. In what follows, we show examples of considered optional token(s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>f 1 (</head><label>1</label><figDesc>"He"; "was [the] Pr. Min. of"; "Australia") f 2 ("He"; "was"; "[the] Pr. Min. [of Australia]")</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Highlighting tokens of interest: verbs (potential relations) and nouns (potential arguments).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Manual labeling of OIE triples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Bucketized experiments: F1 score according to different bucketizations of the input sentences: sentence length (a); number of conjunctions (b); number of case markers (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Multilingual BenchIE: Extraction statistics.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 :</head><label>4</label><figDesc>Illustration of BenchIE's facets for one fact synset (f 4 from</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>) from the corresponding BenchIE triple.</figDesc><table><row><cell>Consequently, BenchIE-M fact synsets on average</cell></row><row><cell>contain many fewer extractions than the original</cell></row><row><cell>BenchIE synsets. 8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Comparison of performance of OIE systems on BenchIE and CaRB benchmarks for precision (P), recall (R) and F 1 score (F 1 ). The row ? indicates the difference between CaRB score and BenchIE score (i.e., ? = CaRB?BenchIE). Bold numbers indicate highest score per row (i.e., highest score for P / R / F 1 per benchmark) or highest score difference per row (i.e., highest ? for P / R / F 1 ).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Example extractions along with their score on BenchIE.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2"><ref type="bibr" target="#b34">Ro et al. (2020)</ref> introduce a multilingual version of the CaRB dataset by machine translating both sentences and extractions. However, automated translation seems to be highly</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We provide the annotation guidelines in Appendix A.1.4  We show AnnIE's interface in Appendix B. For further details about the tool, see<ref type="bibr" target="#b13">Friedrich et al. (2022)</ref>.5  Very few extractions were actually added in steps(2)and (3); i.e., there were very few correct extractions (from CaRB gold standard and output of OIE systems) that the annotators missed during manual annotation of fact synsets.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">An extraction covers a fact synset if it exactly matches any of the synset's (fact-equivalent) gold triples.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Fact-Level EvaluationWe first compare BenchIE's fact-level evaluation (i.e., default facet, ?2) against CaRB's token-level 7 At least one t1 slot has to be a strict subsequence of the respective t2 slot; t1 and t2 would be the same otherwise.8  This does not imply that each fact synset in BenchIE-M contains only one (i.e., minimal) triple (seeTable 4).EN ZH DE</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">( 0 , 0 , 0 ) ( 0 , 0 , 1 ) ( 0 , 1 , 0 ) ( 0 , 1 , 1 ) ( 1 , 0 , 0 ) ( 1 , 0 , 1 )( 1 , 1 , 0 )</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">KrakeN: Nary Facts in Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>L?ser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBC-WEKEX@NAACL-HLT)</title>
		<meeting>the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBC-WEKEX@NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="52" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Probing Linguistic Features of Sentence-level Representations in Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Alt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Gabryszak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonhard</forename><surname>Hennig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1534" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Leveraging Linguistic Structure For Open Domain Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin Jose Johnson</forename><surname>Premkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="344" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Identifying Named Entities as they are Typed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravneet</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Preo?iuc-Pietro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>the Conference of the European Chapter of the Association for Computational Linguistics (EACL)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="976" to="988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Open Information Extraction from the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Broadhead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conferences on Artificial Intelligence (IJCAI)</title>
		<meeting>the International Joint Conferences on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2670" to="2676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">CaRB: A Crowdsourced Benchmark for Open IE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangnie</forename><surname>Bhardwaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samarth</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename><surname>Mausam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6263" to="6268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nested Propositions in Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Bhutani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Broscheit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting on Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting on Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2296" to="2308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ClausIE: Clause-Based Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Del Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<idno type="DOI">https:/dl.acm.org/doi/10.1145/2488388.2488420</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International World Wide Web Conferences (WWW)</title>
		<meeting>the International World Wide Web Conferences (WWW)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="355" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">DocOIE: A Document-Level Context-Aware Dataset for OpenIE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuicai</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung-Jae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoli</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2377" to="2389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Utility is in the Eye of the User: A Critique of NLP Leaderboards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kawin</forename><surname>Ethayarajh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4846" to="4853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Identifying Relations for Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the International Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">AnnIE: An Annotation Platform for Constructing Complete Open Information Extraction Benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niklas</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingying</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhushan</forename><surname>Kotnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolin</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goran</forename><surname>Glavas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting on Association for Computational Linguistics (ACL): System Demonstrations</title>
		<meeting>the Annual Meeting on Association for Computational Linguistics (ACL): System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Compact Open Information Extraction: Methods, Corpora, Analysis. PhD thesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MinIE: Minimizing Facts in Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><forename type="middle">Del</forename><surname>Corro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2630" to="2640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On Aligning Openie Extractions with Knowledge Bases: A Case Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhushan</forename><surname>Kotnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Hertling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Meilicke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Evaluation and Comparison of NLP Systems (Eval4NLP@EMNLP)</title>
		<meeting>the Workshop on Evaluation and Comparison of NLP Systems (Eval4NLP@EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="143" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">OPIEC: An Open Information Extraction Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Hertling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Broscheit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Automated Knowledge Base Construction (AKBC)</title>
		<meeting>the Conference on Automated Knowledge Base Construction (AKBC)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Question-Answer Driven Semantic Role Labeling: Using Natural Language to Annotate Natural Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="643" to="653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Systematic Comparison of Neural Architectures and Training Approaches for Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Hohenecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Mtumbuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vid</forename><surname>Kocijan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lukasiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8554" to="8565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Montani</surname></persName>
		</author>
		<title level="m">Natural Language Understanding with Bloom Embeddings, Convolutional Neural Networks and Incremental Parsing. GitHub</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="411" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The Role of &quot;Condition&quot;: A Novel Scientific Knowledge Graph Representation and Construction Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">https:/dl.acm.org/doi/10.1145/3292500.3330942</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
		<meeting>the ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1634" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">OpenIE6: Iterative Grid Labeling and Coordination Analysis for Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keshav</forename><surname>Kolluru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaibhav</forename><surname>Adlakha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samarth</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3748" to="3761" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">MILLIE: Modular &amp; Iterative Multilingual Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhushan</forename><surname>Kotnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">O?oro</forename><surname>Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ammar</forename><surname>Shaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanesa</forename><surname>Rodriguez-Tembras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Takamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolin</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting on Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting on Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">From Zero to Hero: On the Limitations of Zero-Shot Language Transfer with Multilingual Transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Lauscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinit</forename><surname>Ravishankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goran</forename><surname>Glava?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4483" to="4499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">MinScIE: Citation-centered Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Lauscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yide</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 ACM/IEEE Joint Conference on Digital Libraries (JCDL)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="386" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">WiRe57: A Fine-Grained Benchmark for Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lechelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Gotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillippe</forename><surname>Langlais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Linguistic Annotation Workshop (LAW@ACL)</title>
		<meeting>the Linguistic Annotation Workshop (LAW@ACL)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">TENET: Joint Entity and Relation Linking with Coherence Relaxation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueling</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaorui</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">https:/dl.acm.org/doi/abs/10.1145/3448016.3457280</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Management of Data (SIG-MOD)</title>
		<meeting>the International Conference on Management of Data (SIG-MOD)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1142" to="1155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">KBPearl: A Knowledge Base Population System Supported by Joint Entity and Relation Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueling</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Very Large Data Base Endowment (PVLDB)</title>
		<meeting>the Very Large Data Base Endowment (PVLDB)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1035" to="1049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ExplainaBoard: An Explainable Leaderboard for NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuaicheng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqi</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihuiwen</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting on Association for Computational Linguistics (ACL): System Demonstrations</title>
		<meeting>the Annual Meeting on Association for Computational Linguistics (ACL): System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="280" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Open Information Extraction Systems and Downstream Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mausam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4074" to="4077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Open Language Learning for Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting>the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="523" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Personalized Benchmarking with the Ludwig Benchmarking Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avanika</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piero</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Willie</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Re</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Facts that Matter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Ponza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><forename type="middle">Del</forename><surname>Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1043" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi?2OIE: Multilingual open information extraction based on multi-head attention with BERT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngbin</forename><surname>Ro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukyung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pilsung</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1107" to="1117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Analysing Errors of Open Information Extraction Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolf</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Oberhauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Klatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>L?ser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems@EMNLP</title>
		<meeting>the First Workshop on Building Linguistically Generalizable NLP Systems@EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Leveraging Event-based Semantics for Automated Text Simplification. Expert systems with applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>?tajner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goran</forename><surname>Glava?</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="383" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Creating a Large Benchmark for Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the International Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2300" to="2305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Supervised Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="885" to="895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>V?th</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Tilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Thang</forename><surname>Vu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.05159</idno>
		<title level="m">Beyond Accuracy: A Consolidated Tool for Visual Question Answering Benchmarking</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luna</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Razniewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Suchanek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.11564</idno>
		<title level="m">Machine Knowledge: Creation and Curation of Comprehensive Knowledge Bases</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Pocket Knowledge Base Population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Travis</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="305" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Viswanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoumianze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.12875</idno>
		<title level="m">Graham Neubig, and Pengfei Liu. 2022. DataLab: A Platform for Data Analysis and Intervention</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">ReNoun: Fact Extraction for Nominal Attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Halevy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="325" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Assertion-based QA with Question-Aware Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the American Association for Artificial Intelligence (AAAI)</title>
		<meeting>the Conference of the American Association for Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6021" to="6028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Span Model for Open Information Extraction on Accurate Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junlang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9523" to="9530" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
