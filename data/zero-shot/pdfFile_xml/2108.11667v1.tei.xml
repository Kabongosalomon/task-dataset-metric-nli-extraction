<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">StackMix and Blot Augmentations for Handwritten Text Recognition Denis Karachev OCRV Sochi, Russian Federation Mark Potanin SBER AI, MIPT Moscow, Russian Federation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Shonenkov</surname></persName>
							<email>shonenkov@phystech.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Russian Federation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sber</forename><forename type="middle">Ai</forename><surname>Sochi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Russian Federation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Karachev@ocrv</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Max Novopoltsev SBER AI Sochi</orgName>
								<address>
									<country key="RU">Russian Federation</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ru</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Max Novopoltsev SBER AI Sochi</orgName>
								<address>
									<country key="RU">Russian Federation</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Dimitrov</surname></persName>
							<email>denis.dimitrov@math.msu.su</email>
							<affiliation key="aff2">
								<orgName type="department">Russian Federation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sber</forename><surname>Ai</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Russian Federation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Msu</forename><surname>Lomonosov</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Russian Federation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moscow</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Russian Federation</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">StackMix and Blot Augmentations for Handwritten Text Recognition Denis Karachev OCRV Sochi, Russian Federation Mark Potanin SBER AI, MIPT Moscow, Russian Federation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes a handwritten text recognition (HTR) system that outperforms current state-of-the-art methods. The comparison was carried out on three of the most frequently used in HTR task datasets, namely Bentham, IAM, and Saint Gall. In addition, the results on two recently presented datasets, Peter the Great's manuscripts and HKR Dataset, are provided.</p><p>The paper describes the architecture of the neural network and two ways of increasing the volume of training data: augmentation that simulates strikethrough text (HandWritten Blots) and a "new text" generation method (StackMix), which proved to be very effective in HTR tasks. StackMix can also be applied to the standalone task of generating handwritten text based on printed text.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Handwriting text recognition is an vital task. Automation allows for a dramatical reduction in labor costs for processing correspondence and application forms and deciphering historical manuscripts.</p><p>Handwritten text has several features because of both the inter-and intraclass variability -different instances of the same word written by different people may vary greatly, and the same character written by the same writer may look very different depending on the context when it was written. In addition to the above, historical records may contain flaws like ink drops and paper defects. Another problem with historical documents is the usually small amount of labeled data. Deciphering historical manuscripts is carried out with the help of rare specialists -historians and linguists; this significantly increases the deciphering cost, especially with many documents. Our approach involves having special- ists label a relatively small number of documents, train the model, and apply it to the remaining data.</p><p>We propose a handwritten text recognition system, as well as two ways to increase the volume of training data: augmentation that simulates strikethrough text -HandWritten Blots and a "new text" generation method -StackMix.</p><p>The system was originally designed to decipher Peter the Great manuscripts that were first introduced at <ref type="bibr" target="#b29">[32]</ref> by using marked-up lines of the text as input. One line of text is 2 048 pixels width and 128 pixels height <ref type="figure" target="#fig_0">(Fig. 1)</ref>.</p><p>The remaining paper is organized as follows. Related works are presented in Section 2. Some of them are used for comparison with state-of-the-art models. Section 3 is devoted to describing our method. It includes information about neural network architecture and augmentations, and introduces StackMix. Section 4 describes datasets and metrics used in experiments. Section 5 provides a detailed description of the experiments and results. Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Early works on handwritten recognition problems suggest using a combination of hidden Markov models and RNNs <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> or algorithms based on conditional random fields <ref type="bibr" target="#b22">[23]</ref>. The disadvantage of these approaches is the impossibility of end-to-end loss function optimization. In 2006, a new approach was introduced -Connectionist Tem- porary Classification <ref type="bibr" target="#b16">[17]</ref>. The basic idea was to interpret the network outputs as a probability distribution over all possible label sequences, conditioned on a given input sequence. Given this distribution, an objective function can be derived that directly maximizes the probabilities of the correct labelings. Since the objective function is differentiable, the network can then be trained with standard backpropagation through time. New loss function were also introduced in this article -CTC loss. The ideas proposed in the article found a wide response among researchers, becoming the de-facto standard for handwritten recognition works <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>MDLSTM <ref type="bibr" target="#b33">[36]</ref> networks use 2D-RNN which can deal with both axes of an input image. A simple model consists of several CNN and MDLSTM layers and using CTC loss provides excellent metrics for the IAM <ref type="bibr" target="#b25">[27]</ref> dataset. However, MDLSTM models have some disadvantages like high computational costs and instability. In work <ref type="bibr" target="#b9">[10]</ref>, the authors proposed an "example-packing" method. This eliminates the cost of padding for different-sized images. In works <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b21">[22]</ref>, the authors try to eliminate recurrent layers in CNN-LSTM-CTC to decrease the number of parameters. Their Gated Fully Convolutional Networks shows relatively good results, even without a language model. Another alternative to the RCNN-CTC approach is seq2seq models <ref type="bibr" target="#b26">[29]</ref>. The encoder extracts features from the input, and the decoder with an attention mechanism emits the output sequentially. Common tricks may significantly improve the quality of HTR models. In <ref type="bibr" target="#b1">[2]</ref>, the authors investigated data augmentation and transfer learning for small historical datasets.</p><p>OrigamiNet <ref type="bibr" target="#b35">[38]</ref> is a module that combines segmentation and text recognition tasks. It can be added to any linelevel handwritten text recognition model to make it pagelevel.</p><p>We compared the proposed model with the models described above. The data for comparison is given in section 4.1, and the description of the metrics is given in section 4.2. We also found that different authors used various data partitions for train, test, and validation on the IAM dataset (see section 4.1). This made it difficult to correctly compare the models, so we are presenting our model results for the same data sets that were used in the original papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>Our method comprises three parts. Section 3.1 describes the modified Resnet neural network architecture we used. Sections 3.2 proposes a new augmentation method that simulates strikethrough text -Handwritten Blots. Finally, Section 3.3 describes how to significantly increase the amount of training data generating new text in the style of the current dataset (StackMix approach).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Neural Network Architecture</head><p>The neural network underlying the proposed system consists of three parts: a feature generator, a recurrent network to account for the order of the features, and the classifier that outputs the probability of each character.</p><p>As a function generator, various network architectures were tested, and the final choice fell on Resnet <ref type="figure" target="#fig_1">(Fig. 2</ref>). We took only three first blocks from Resnet-34 and replaced the stride parameter in the first layer with 1 to increase the "width" of the objects. One Resnet block ( <ref type="figure" target="#fig_2">Figure 3</ref>) consisted of 3, 4, and 6 residual blocks with 64, 128, and 256 output layers, respectively.</p><p>After the features were extracted, they were averaged through the AdaptiveAvgPool2d layer and fed into the three BiLSTM layers to deal with feature sequences. As a final classifier, we use two fully connected layers with GELU and dropout between them.</p><p>The results achieved using the described architecture without any additional modifications are shown in the "base" row of <ref type="table">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Blot Augmentation</head><p>The idea of augmentation appeared during the analysis of the Digital Peter dataset <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b29">32]</ref>. In the process of examining the dataset, we found examples of images in which some characters were crossed out and almost indistinguishable, but they were still present in the markup. Hense, the idea of using the Cutout augmentation <ref type="bibr" target="#b11">[12]</ref> emerged, since it allows for overlaping of some elements of symbols or entire symbols, which makes the augmentation a bit like crossed-out symbols.</p><p>However, in the process of training the models, we got the idea of implementing such an algorithm that would allow for simulating the strikethrough characters as close as possible to the originals. Since we did not find the implementation of such algorithms in open sources, we created it ourselves.</p><p>To implement the strikethrough effect, we decided to use the Bezier curve construction algorithm, which in our case smoothed the curve transition between points.</p><p>The Bezier curve is a parametric curve and is a special case of the Bernstein polynomial. Finding basic polynomials of degree n are found by the formula:</p><formula xml:id="formula_0">b j,n = n j s j (1 ? s) n?j<label>(1)</label></formula><p>Where j = 0, . . . , n. The definition of a curve as a linear combination is found as:</p><formula xml:id="formula_1">B(s) = n j=0 b j,n ? v j<label>(2)</label></formula><p>Where v j is the point in the space, and b j,n define above. Since the sum of all polynomials must be equal to one, then.</p><formula xml:id="formula_2">b 0,n + b 0,1 + ... + b n,n = (s + (1 ? s)) n = 1 (3)</formula><p>Where S is non-negative weights that sum to one. We found the implementation of the algorithm for constructing the Bezier curve in <ref type="bibr" target="#b18">[19]</ref>.</p><p>Next, we implemented our own algorithm that simulates strikethrough. The main steps were as follows:</p><p>1. Determine the coordinates of the strikethrough area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Define areas for generating points to be used for draw-</head><p>ing a Bezier curve.</p><p>3. Generate points for the Bezier curve with the parameters of the intensity of the points and their coordinates to simulate the slope. Sometimes, a random point needs to be used several times for the loop to go a slightly further from the curve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Draw a</head><p>Bezier curve with a specified transparency. A graphical description of the algorithm is shown in <ref type="figure">Fig. 4</ref>. An example of a picture from a dataset using our strikethrough is provided in <ref type="figure">Fig. 5</ref> The implementation of this algorithm can be found here <ref type="bibr">[28]</ref>. We empirically selected the parameters for strikethrough (minh = 50, maxh = 100, minw = 10, maxw = 50, incline = 15, intensity = 0.9, transparency = 0.95, count = 1 . . . 11, proba = 0.5) and tested it on different datasets.</p><p>The effect of the Blot augmentation on quality metrics is shown in the "blots" row of <ref type="table">Table 4</ref>, and in <ref type="figure" target="#fig_8">Figure 9</ref>. The obtained data suggests that handwritten blot augmentation makes a significant contribution to the quality of training models. Therefore, we recommend using it to train models in handwriting recognition problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">StackMix</head><p>Improving the quality and stability of neural networks in image recognition tasks uses approaches that combine information from various objects of the training dataset, demonstrating effective performance and making the neural network more generalizable and resistant to new samples, despite not being previously presented to the neural network. For example, the CutMix approach <ref type="bibr" target="#b37">[40]</ref> is an augmentation, in which parts of the images are cut from different samples and inserted into a new one, while the targets are mixed according to the proportions of the original parts of the images. A similar approach is used in SnapMix <ref type="bibr" target="#b20">[21]</ref>, but the cutting of images is regulated by the neural network model using Class Activation Map. This approach allows for reducing the noise of the cut objects and selecting the most significant parts from the point of view of the neural network. Additionally, an interesting approach with mixing objects is presented in MixUp <ref type="bibr" target="#b38">[41]</ref> and MWH <ref type="bibr" target="#b36">[39]</ref>, where images are overlapped on each other with a transparency coefficient and also mixes the targets with the proportion. Unfortunately, these methods cannot be applied to the optical character recognition and handwritten text recognition tasks, because mixing recursively dependent targets makes it very difficult to obtain a correct mapping of image and text. Therefore, we would like to introduce the StackMix approach, which allows for the improvement of the quality and stability of our neural network.</p><p>Weakly Supervised Symbol Segmentation. First, to apply the proposed StackMix approach to the OCR task additional data markup that exactly marks the symbols boundaries is required. To achieve this an approach with automatic segmentation of training images into symbols using post-processing of a supervised pretrained neural network via CTC loss was used. The main idea was to connect the last layer of RNN (after applying SoftMax activation for every symbol from image features) and image width to get symbols' boundaries using only weakly supervised training without any manual markup <ref type="figure" target="#fig_5">(Fig. 7)</ref>. For training neural network can be used base scheme without any augmentations and tricks. To get high quality marking of symbols' boundaries a sample from the training stage should be used.</p><p>Corpus. The StackMix approach also requires an external text corpus that has the same alphabet as the main dataset. Corpus does not require special marking and only contains allowed symbols. For the Digital Peter dataset, we used the texts of the XVII-XVIII centuries (? 3M lines). For the IAM and BenthamR0 datasets, we used cleaned texts from the Kaggle Competition "Jigsaw Unintended Bias in Toxicity Classification" <ref type="bibr" target="#b32">[35]</ref> (? 560k lines). For the HKR dataset, we used small portion of Russian texts from Wikimedia <ref type="bibr" target="#b31">[34]</ref> (? 2.2M lines), and for the Saint Gall dataset, we used cleaned Latin corpus from Kaggle [24] (? 180k lines) that used "The Latin Library" <ref type="bibr" target="#b8">[9]</ref>.</p><p>StackMix Algorithm. The input for the algorithm is expected to be text from the external corpus, which creates a new image with this text using parts of images of the training dataset. The algorithm from nltk MWETokenizer <ref type="bibr" target="#b24">[26]</ref> is used for tokenization. It processes tokenized text and merges multi-word expressions into single tokens. Col- lections of multi-word expressions are obtained from the training dataset, using symbol borders to connect parts of images and MWE tokens including spaces and punctuation marks. In this study, we used one random MWE tokenizer from six with a token dimension of no more than 3, 4, 5, 6, 7 and 8 with proba 0.05, 0.15, 0.2, 0.2, 0.2 and 0.2 respectively. After this each token wss matched with part of an image from the training data, and the pieces were stacked (hence the name "StackMix") together into a complete image, maintaining the correct order of the tokens.</p><p>Examples of the StackMix algorithm for various datasets are given in <ref type="figure" target="#fig_6">Figure 8</ref> and the supplementary materials. Despite the visible places where tokens were glued together, the algorithm significantly increased the quality of recognition. The alignment and selection of samples to increase the realism of the generated string did not lead to an increase in metrics in our experiments.</p><p>Nevertheless, after certain improvements, this algorithm may be used for the realistic generation of new documents. As an example in supplementary materials, we generated pages of texts from different sources. For all models, some paragraphs from the first chapter of a Harry Potter book was used. The results suggest that it is possible to generate different texts with different styles and fonts. For models of English language, we used the original Harry Potter book and for models that had Cyrillic symbols, the Russian version of the Harry Potter book was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Benchmarks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>Four different datasets were used in the experiments to prove state-of-the-art quality of our model. that were written by the renowned English philosopher and reformer <ref type="figure" target="#fig_0">Jeremy Bentham (1748-1832)</ref>. Volunteers of the Transcribe Bentham 1 initiative transcribed this collection. Currently, &gt; 6 000 documents or &gt; 25 000 pages have been transcribed using this public web platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bentham manuscripts refers to a large set of documents</head><p>For our experiments, we used the BenthamR0 dataset <ref type="bibr" target="#b13">[14]</ref> a part of the Bentham manuscripts.</p><p>The IAM handwriting dataset contains forms of handwritten English text. It consists of 1 539 pages of scanned text from 657 different writers. This dataset is widely used for experiments in many papers. However, there is a big problem with uncertainty in data splitting for model training and evaluation. This issue was described in <ref type="bibr" target="#b26">[29]</ref>. The IAM dataset has different train/val/test splits that are shown in <ref type="table">Table 4</ref>.1. The problem is that none of them are labeled as a standard, so the IAM dataset split differs from paper to paper. However, results should be compared on the same split.</p><p>In our experiments, we use the IAM-B 2 and IAM-D partitions. IAM-B was used to compare our model with others. IAM-D was a new partition inspired by the official page of project <ref type="bibr" target="#b2">3</ref> . This page contained "unknown","val1" and "val2" split labels. We added "unknown" samples to the train set, and combined "val1" and "val2" together.</p><p>IAM-B was chosen because many recently published papers used this partition. We used IAM-D because it provides more training samples.</p><p>We create a github repository <ref type="bibr" target="#b14">[15]</ref> with information and indexes corresponding to each IAM split in <ref type="table">Table 4</ref>.1. It also contains links to papers that use these splits. We hope this helps researchers choose appropriate IAM partitions and make valid comparisons with other papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Digital Peter is a completely new dataset of Peter the</head><p>Great's manuscripts <ref type="bibr" target="#b29">[32]</ref>. It consists of 9 694 images and text files corresponding to lines in historical documents. The open machine learning competition Digital Peter was held based on the considered dataset <ref type="bibr" target="#b5">[6]</ref>. There are 6 237 lines in the training set, 1 527 lines in the validation set, and 1 930 lines in the testing set. <ref type="bibr" target="#b28">[31]</ref> is a recently published dataset of modern Russian and Kazakh language. This database consists of &gt; 1 400 filled forms. It contains 64 943 lines and &gt; 715 699 symbols produced by about 200 different writers. Data are split in the following manner: 45 559 lines for a train set, 10 009 lines for validation, and 9 375 lines for test. This data splitting was found in github <ref type="bibr" target="#b15">[16]</ref> of the authors of the HKR Dataset, but these proportions of train/valid/test were slightly different that those of the original paper <ref type="bibr" target="#b28">[31]</ref>. We assumed that the seed was not fixed in a script to get split, which was not a big problem for comparing results. Also, authors of the HKR Dataset used a good idea for splitting on Test1 and Test2 and demonstrated the problem of recognition text for new owners of the handwriting styles. The behavior of our approaches, separately in Test1 and Test2, can be found in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HKR Dataset</head><p>Saint Gall dataset contains handwritten historical manuscripts written in Latin that date back to the 9th century. It consists of 60 pages, 1 410 text lines and 11 597 words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Metrics</head><p>We used character error rate (CER, %), word error rate (WER, %), string accuracy (ACC, %) to measure the quality of the HTR models:</p><formula xml:id="formula_3">CER = n i=1 dist c (pred i , true i ) n i=1 len c (true i ) ,<label>(4)</label></formula><formula xml:id="formula_4">WER = n i=1 dist w (pred i , true i ) n i=1 len w (true i ) ,<label>(5)</label></formula><p>where dist c and dist w are the Levenshtein distances calculated in characters (including spaces) and words, respectively, and len c and len w are the length of the string in characters and words respectively.</p><formula xml:id="formula_5">ACC = n i=1 [pred i = true i ] n .<label>(6)</label></formula><p>In the formulas (4), <ref type="bibr" target="#b4">(5)</ref>, and <ref type="formula" target="#formula_5">(6)</ref>, n is the size of the test sample, pred i is the string of characters that the model recognized in the i-th image, and true i is the true translation of the i-th image made by the expert.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Setup</head><p>Each experiment was repeated five times. AdamW was used as an optimizer <ref type="bibr" target="#b17">[18]</ref> with OneCycleLR scheduler, starting at a learning rate of 0.001 down to 1e-08. The mean and standard deviation of each metric are given as the result. The use of augmentations allows for further metric improvements. In our experiments, we used StackMix "on the fly" during training with a probability of 0.8. We added traditional augmentations of CLAHE <ref type="bibr" target="#b30">[33]</ref>, JpegCompression, Rotate, and our augmentation (simulation of crossedout letters) -"HandWritten Blots". Different combinations of augmentations were grouped in our experiments:</p><p>? Models with StackMix were trained during 1 000 epoch, but were not overfitted. We believe they should be trained more with bigger external text corpora. A comparison of our results for various datasets (IAM <ref type="bibr" target="#b25">[27]</ref>, BenthamR0 <ref type="bibr" target="#b13">[14]</ref>, Digital Peter <ref type="bibr" target="#b29">[32]</ref>, HKR Dataset <ref type="bibr" target="#b28">[31]</ref>, Saint Gall <ref type="bibr" target="#b12">[13]</ref>) is presented in <ref type="table">Table 4</ref> and in <ref type="figure" target="#fig_8">Figure 9</ref>.</p><p>Inference speed was measured as the average recognition speed for one line of text with batch size 16 and an image size of 128 * 2048 pixels, using one Tesla-V100 GPU. The inference speed of different datasets are shown in <ref type="table" target="#tab_1">Table 2</ref> and inference speed of models with different augmentations is shown in <ref type="table">Table 3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparison with State-of-the-art</head><p>In this section, we present the comparison with other models ( <ref type="table" target="#tab_2">Table 5</ref>).</p><p>Our model outperforms other approaches on the Ben-thamR0, HKR, and IAM-D datasets. It reached 3.77% of CER on the IAM-B dataset, which is very close to the best model published in 2016 that achieved 3.5% CER. On the Saint Gall dataset, we achieved 5.56% CER, which is very close to the current best solution of 5.26% CER.</p><p>The IAM dataset has two versions because papers use various data splits. We included IAM-B and IAM-D partitions in <ref type="table" target="#tab_2">Table 5</ref> to compare them with other models of the same split.</p><p>Authors of the paper <ref type="bibr" target="#b10">[11]</ref> provided open code for their model here <ref type="bibr" target="#b19">[20]</ref>. We noticed that when evaluating the model, they lowered the characters in predicted and true strings. However, in our experiments, we did not convert the characters to lowercase. For real HTR tasks, it is not important to track the case of characters. In the supplementary materials, we provide the metrics of the models trained and evaluated on lowercase characters, and a comparison similar to the <ref type="table" target="#tab_2">Table 5</ref> on less widespread datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>The neural network architecture presented in this article allows the problem of handwriting recognition of both modern and historical documents for various languages to be solved. The described augmentations -HandWritten Blots and StackMix -further improve the quality of recognition, demonstrating the best result among the currently known handwriting recognition systems.</p><p>The presented system can significantly increase the speed of deciphering historical documents. For example, it took a team of 10-15 historians about 3 months to decipher 662 pages of manuscripts from the Digital Peter dataset, what the organizers of the competition <ref type="bibr" target="#b5">[6]</ref> wrote about. When working on the same dataset on a single Tesla V100, the average decryption speed was 95 lines/s or 380 pages/min, which is unattainable by historical scientists. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>One line of text.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Neural network architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Resnet block architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .Figure 5 .</head><label>45</label><figDesc>Graphic description of the algorithm. a) define the strikethrough area; b) define areas for generating points; c) generate random points; d) draw a Bezier curve from the generated points Sample image using faux strikethrough</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Example images of symbol segmentation using semi supervised methods. Images have ids: IAM-a02-082-05, BenthamR0-072 105 002 04 05 and SaintGall-csg562-004-13 respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Post-processing scheme to get the boundaries of the symbols.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Example images created using StackMix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>"base" -experiments without augmentations, 300 epoch (HKR 100 epoch) ? "augs" -standart augmentations (CLAHE [33], Jpeg-Compression, Rotate), 300 epoch (HKR 100 epoch) ? "blots" -using only our HandWrittenBlot augmentation, 500 epoch (HKR 150 epoch) ? "stackmix" -using only our Stackmix approach, 1 000 epoch (HKR 300 epoch) ? "all" -using all previous augmentations (augs + blots + stackmix), 1 000 epoch (HKR 300 epoch)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>This graph compares the relative train time and CER results of experiments for different datasets and approaches. Arb. units for train time were obtained by the formula T arb = log2(T /Tmin), where Tmin = 33.6 ms is the minimum value of train time per one image. The colored lines represent obtained experiment points. Since the quality of approaches grows with increasing train time, some points have no line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>IAM splits.</figDesc><table><row><cell>Split</cell><cell cols="2">Train Val</cell><cell>Test</cell></row><row><cell cols="2">IAM-A 6161</cell><cell cols="2">966 2915</cell></row><row><cell cols="2">IAM-B 6482</cell><cell cols="2">976 2915</cell></row><row><cell cols="2">IAM-C 6161</cell><cell cols="2">940 1861</cell></row><row><cell cols="4">IAM-D 9652 1840 1861</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Inference speed for 1xV100 GPU, image size 128x2048.</figDesc><table><row><cell>Dataset</cell><cell>Speed, img / sec</cell></row><row><cell>BenthamR0</cell><cell>86.2 ? 1.3</cell></row><row><cell>IAM</cell><cell>94.9 ? 1.2</cell></row><row><cell>Digital Peter</cell><cell>92.6 ? 2.7</cell></row><row><cell>HKR</cell><cell>98.4 ? 1.3</cell></row><row><cell>Saint Gall</cell><cell>86.3 ? 0.6</cell></row><row><cell cols="2">Experiment Speed, img / sec</cell></row><row><cell>base</cell><cell>28.4 ? 0.9</cell></row><row><cell>augs</cell><cell>28.5 ? 0.6</cell></row><row><cell>blots</cell><cell>28.2 ? 1.4</cell></row><row><cell>stackmix</cell><cell>21.0 ? 5.0</cell></row><row><cell>all</cell><cell>17.7 ? 5.8</cell></row><row><cell cols="2">Table 3. Training speed for 1xV100 GPU, image size 128x2048.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5 .</head><label>5</label><figDesc>? 0.06 11.8 ? 0.3 52.1 ? 0.8 5.80 ? 0.08 18.9 ? 0.2 29.3 ? 0.4 augs 2.85 ? 0.05 11.3 ? 0.1 52.8 ? 1.0 5.43 ? 0.04 17.8 ? 0.1 30.7 ? 0.5 blots 2.27 ? 0.04 9.5 ? 0.2 57.0 ? 0.4 4.59 ? 0.03 15.0 ? 0.1 36.4 ? 0.5 stackmix 2.08 ? 0.03 9.0 ? 0.1 58.2 ? 0.8 4.90 ? 0.07 16.4 ? 0.2 35.2 ? 0.5 all 1.73 ? 0.02 7.9 ? 0.1 61.9 ? 1.1 3.77 ? 0.06 12.8 ? 0.2 43.6 ? 0.6 .69 ? 0.13 14.4 ? 0.4 80.0 ? 0.3 4.06 ? 0.12 28.8 ? 0.8 6.1 ? 0.8 all 3.49 ? 0.08 13.0 ? 0.3 82.0 ? 0.5 3.65 ? 0.11 26.2 ? 0.6 11.8 ? 2.0 Comparison to other models, test set</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Datasets</cell><cell></cell></row><row><cell></cell><cell></cell><cell>BenthamR0</cell><cell></cell><cell></cell><cell>IAM-B</cell></row><row><cell></cell><cell>CER, %</cell><cell>WER, %</cell><cell>ACC, %</cell><cell>CER, %</cell><cell>WER, %</cell><cell>ACC, %</cell></row><row><cell>base</cell><cell cols="2">2.99 Digital Peter</cell><cell></cell><cell></cell><cell>IAM-D</cell></row><row><cell></cell><cell>CER, %</cell><cell>WER, %</cell><cell>ACC, %</cell><cell>CER, %</cell><cell>WER, %</cell><cell>ACC, %</cell></row><row><cell>base</cell><cell cols="6">4.44 ? 0.02 24.3 ? 0.2 43.7 ? 0.5 4.55 ? 0.06 14.5 ? 0.2 35.5 ? 0.7</cell></row><row><cell>augs</cell><cell cols="6">4.15 ? 0.04 23.0 ? 0.2 45.7 ? 0.4 4.38 ? 0.04 14.0 ? 0.2 36.3 ? 0.6</cell></row><row><cell>blots</cell><cell cols="6">3.39 ? 0.04 19.3 ? 0.4 51.9 ? 0.4 3.70 ? 0.03 11.8 ? 0.1 42.3 ? 0.6</cell></row><row><cell cols="7">stackmix 3.40 ? 0.05 19.2 ? 0.3 51.6 ? 0.7 3.77 ? 0.04 12.3 ? 0.1 42.4 ? 0.8</cell></row><row><cell>all</cell><cell cols="6">2.50 ? 0.03 14.6 ? 0.2 60.8 ? 0.8 3.01 ? 0.02 9.8 ? 0.1 50.7 ? 0.3</cell></row><row><cell></cell><cell></cell><cell>HKR</cell><cell></cell><cell></cell><cell>Saint Gall</cell></row><row><cell></cell><cell>CER, %</cell><cell>WER, %</cell><cell>ACC, %</cell><cell>CER, %</cell><cell>WER, %</cell><cell>ACC, %</cell></row><row><cell>base</cell><cell cols="6">6.71 ? 0.18 22.5 ? 0.3 71.1 ? 0.5 4.71 ? 0.05 32.5 ? 0.3 2.2 ? 0.5</cell></row><row><cell>augs</cell><cell cols="6">6.67 ? 0.24 21.5 ? 0.3 72.2 ? 0.2 4.49 ? 0.11 31.3 ? 0.5 3.4 ? 0.7</cell></row><row><cell>blots</cell><cell cols="6">7.40 ? 0.26 23.0 ? 0.5 72.6 ? 0.4 4.08 ? 0.03 28.1 ? 0.2 4.6 ? 1.1</cell></row><row><cell cols="2">stackmix 3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://transcribe-bentham.ucl.ac.uk/td/Transcribe Bentham 2 http://www.tbluche.com/resources.html 3 https://fki.tic.heia-fr.ch/databases/iam-handwriting-database</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Attention-based fully gated CNN-BGRU for Russian handwritten text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelrahman</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Hamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniyar</forename><surname>Nurseitov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Imaging</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">141</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Boosting offline handwritten text recoglines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jos?</forename><surname>Carlos Aradillas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan Jos?</forename><surname>Murillo-Fuentes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><forename type="middle">M</forename><surname>Olmos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>IEEE Access</publisher>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="76674" to="76688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Markovian models for sequential data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="129" to="162" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Connnectionist speech recognition: A hybrid approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herv?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Morgan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Handwriting recognition of historical documents with few labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgard</forename><surname>Chammas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chafic</forename><surname>Mokbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurence</forename><surname>Likforman-Sulem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th IAPR International Workshop on Document Analysis Systems (DAS)</title>
		<imprint>
			<date type="published" when="2018-04" />
			<biblScope unit="page" from="43" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Competition Digital</forename><surname>Peter</surname></persName>
		</author>
		<ptr target="https://github.com/sberbank-ai/digital\underline{\hspace{0.1cm}}peter/\underline{\hspace{0" />
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">End-to-end handwritten paragraph text recognition using a vertical attention network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Coquenet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cl?ment</forename><surname>Chatelain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Paquet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.03868</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recurrence-free unconstrained handwritten text recognition using gated fully convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Coquenet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cl?ment</forename><surname>Chatelain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Paquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 17th International Conference on Frontiers in Handwriting Recognition (ICFHR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="19" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Credits for the Latin library</title>
		<ptr target="https://www.thelatinlibrary.com/cred.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">No padding please: Efficient neural handwriting recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gideon</forename><surname>Maillette De Buy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lambert</forename><surname>Wenniger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Schomaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="355" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Alejandro H?ctor Toselli, and Estanislau Baptista Lima. HTR-Flor: A deep learning system for offline handwritten text recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur Flor De Sousa</forename><surname>Neto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="54" to="61" />
		</imprint>
	</monogr>
	<note>Byron Leite Dantas Bezerra</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Transcription alignment of Latin manuscripts using Hidden Markov Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volkmar</forename><surname>Frinken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alicia</forename><surname>Forn?s</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Workshop on Historical Document Imaging and Processing</title>
		<meeting>the 2011 Workshop on Historical Document Imaging and Processing</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Ground-truth production in the transcriptorium project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gatos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Louloudis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Causer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronica</forename><surname>Grint</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan-Andreu</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Toselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="page" from="237" to="241" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Github repository with various IAM splits</title>
		<ptr target="https://github.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Github with HKR dataset splitting</title>
		<ptr target="https://github.com/bosskairat/Dataset" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Connectionist Temporal Classification : Labelling unsegmented sequence data with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faustino</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine Learning, ICML&apos;06</title>
		<meeting>the 23rd international conference on Machine Learning, ICML&apos;06</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="369" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">AdamW and superconvergence is now the fastest way to train neural nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<ptr target="https://www.fast.ai/2018/07/02/adam-weight-decay/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Helper for b?zier curves, triangles, and higher order objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danny</forename><surname>Hermes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page">267</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Htr-Flor</surname></persName>
		</author>
		<ptr target="https://github.com/arthurflor23/handwritten-text-recognition" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Snap-Mix: Semantically proportional mixing for augmenting finegrained data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoli</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence, number 2 in 35</title>
		<meeting>the AAAI Conference on Artificial Intelligence, number 2 in 35</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1628" to="1636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A scalable handwritten text recognition system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Reeve</forename><surname>Ingle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuhisa</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Baccash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashok</forename><forename type="middle">C</forename><surname>Popat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML&apos;01</title>
		<meeting>the Eighteenth International Conference on Machine Learning, ICML&apos;01</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gram-CTC: Automatic unit selection and target decomposition for sequence labelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hairong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2188" to="2197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Multi-word expression tokenizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Malouf</surname></persName>
		</author>
		<ptr target="https://www.nltk.org/l\underline{\hspace{0.1cm}}modules/nltk/tokenize/mwe.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The IAM-database: an English sentence database for offline handwriting recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U.-V</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Document Analysis and Recognition</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="46" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Evaluating sequence-to-sequence models for handwritten text recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Labahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Gr?ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jochen</forename><surname>Z?llner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1286" to="1293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Are 2D-LSTM really dead for offline text recognition?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastien</forename><surname>Moysset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronaldo</forename><surname>Messina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Document Analysis and Recognition (IJDAR)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="193" to="208" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniyar</forename><surname>Nurseitov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kairat</forename><surname>Bostanbekov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.03579</idno>
		<title level="m">Daniyar Kurmankhojayev, Anel Alimova, and Abdelrahman Abdallah. HKR for Handwritten Kazakh and Russian database</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Digital peter: Dataset, competition and handwriting recognition methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Potanin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Dimitrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Shonenkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Bataev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Karachev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Novopoltsev</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.09354</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Realization of the contrast limited adaptive histogram equalization (CLAHE) for real-time image enhancement. The Journal of VLSI Signal Processing-Systems for Signal, Image, and Video Technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><forename type="middle">M</forename><surname>Reza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Downloads</forename><surname>Russian Wikimedia</surname></persName>
		</author>
		<ptr target="https://dumps.wikimedia.org/ruwiki/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Jigsaw unintended bias in toxicity classification</title>
		<ptr target="https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>The Conversation AI team</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Handwriting recognition with large multidimensional long short-term memory recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Voigtlaender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Doetsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="228" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Decoupled attention network for text recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianwen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxue</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaqiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxiang</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="12216" to="12224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">OrigamiNet: Weaklysupervised, segmentation-free, one-step, full page text recognition by learning to unfold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yousef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">E</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14710" to="14719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.04342</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">Mixup without hesitation. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">CutMix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
