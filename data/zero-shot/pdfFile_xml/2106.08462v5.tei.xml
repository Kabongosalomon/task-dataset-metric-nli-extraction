<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Resolution Continuous Normalizing Flows</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikram</forename><surname>Voleti</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Oberman</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Pal</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Polytechnique</forename><surname>Montr?al</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mila</forename><forename type="middle">Canada</forename><surname>Cifar</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Chair</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Universit? de Montr?al Chris Finlay McGill University</orgName>
								<address>
									<settlement>Mila</settlement>
									<country>Deep Render</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">McGill University</orgName>
								<address>
									<settlement>Mila</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Resolution Continuous Normalizing Flows</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent work has shown that Neural Ordinary Differential Equations (ODEs) can serve as generative models of images using the perspective of Continuous Normalizing Flows (CNFs). Such models offer exact likelihood calculation, and invertible generation/density estimation. In this work we introduce a Multi-Resolution variant of such models (MRCNF), by characterizing the conditional distribution over the additional information required to generate a fine image that is consistent with the coarse image. We introduce a transformation between resolutions that allows for no change in the log likelihood. We show that this approach yields comparable likelihood values for various image datasets, with improved performance at higher resolutions, with fewer parameters, using only 1 GPU. Further, we examine the out-of-distribution properties of MRCNFs, and find that they are similar to those of other likelihood-based generative models.</p><p>Preprint. Under review.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Reversible generative models derived through the use of the change of variables technique <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b82">83]</ref> are growing in interest as alternatives to generative models based on Generative Adversarial Networks (GANs) <ref type="bibr" target="#b19">[20]</ref> and Variational Autoencoders (VAEs) <ref type="bibr" target="#b39">[40]</ref>. While GANs and VAEs have been able to produce visually impressive samples of images, they have a number of limitations. A change of variables approach facilitates the transformation of a simple base probability distribution into a more complex model distribution. Reversible generative models using this technique are attractive because they enable efficient density estimation, efficient sampling, and computation of exact likelihoods.</p><p>A promising variation of the change-of-variable approach is based on the use of a continuous time variant of normalizing flows <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b17">18]</ref>, which uses an integral over continuous time dynamics to transform a base distribution into the model distribution, called Continuous Normalizing Flows (CNF). This approach uses ordinary differential equations (ODEs) specified by a neural network, or Neural ODEs. CNFs have been shown to be capable of modelling complex distributions such as those associated with images.</p><p>While this new paradigm for the generative modelling of images is not as mature as GANs or VAEs in terms of the generated image quality, it is a promising direction of research as it does not have some key shortcomings associated with GANs and VAEs. Specifically, GANs are known to suffer from mode-collapse <ref type="bibr" target="#b48">[49]</ref>, and are notoriously difficult to train <ref type="bibr" target="#b1">[2]</ref> compared to feed forward networks because their adversarial loss seeks a saddle point instead of a local minimum <ref type="bibr" target="#b3">[4]</ref>. CNFs are trained by mapping images to noise, and their reversible architecture allows images to be generated by going in reverse, from noise to images. This leads to fewer issues related to mode collapse, since any input example in the dataset can be recovered from the flow using the reverse of the transformation learned during training. VAEs only provide a lower bound on the marginal likelihood whereas CNFs provide <ref type="figure">Figure 1</ref>: The architecture of our Multi-Resolution Continuous Normalizing Flow (MRCNF) method (best viewed in color). Continuous normalizing flows (CNFs) g s are used to generate images x s from noise z s at each resolution, with those at finer resolutions conditioned (dashed lines) on the coarser image one level above x s+1 , except at the coarsest level where it is unconditional. Every finer CNF produces an intermediate image y s , which is then combined with the immediate coarser image x s+1 using a linear map M from eq. <ref type="bibr" target="#b7">(8)</ref> to form x s . The multiscale maps are defined by eq. <ref type="bibr" target="#b14">(15)</ref>. exact likelihoods. Despite the many advantages of reversible generative models built with CNFs, quantitatively such methods still do not match the widely used Fr?chet Inception Distance (FID) scores of GANs or VAEs. However their other advantages motivate us to explore them further.</p><p>Furthermore, state-of-the art GANs and VAEs exploit the multi-resolution properties of images, and recent top-performing methods also inject noise at each resolution <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b76">77]</ref>. While shaping noise is fundamental to normalizing flows, only recently have normalizing flows exploited the multi-resolution properties of images. For example, WaveletFlow <ref type="bibr" target="#b82">[83]</ref> splits an image into multiple resolutions using the Discrete Wavelet Transform, and models the average image at each resolution using a normalizing flow. While this method has advantages, it suffers from many issues such as high parameter count and long training time.</p><p>In this work, we consider a non-trivial multi-resolution approach to continuous normalizing flows, which fixes many of these issues. A high-level view of our approach is shown in <ref type="figure">Figure 1</ref>. Our main contributions are:</p><p>1. We propose a multi-resolution transformation that does not add cost in terms of likelihood.</p><p>2. We introduce Multi-Resolution Continuous Normalizing Flows (MRCNF).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">We achieve comparable Bits-per-dimension (BPD) (negative log likelihood per pixel) on</head><p>image datasets using fewer model parameters and significantly less training time with only one GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>We explore the out-of-distribution properties of (MR)CNF, and find that they are similar to non-continuous normalizing flows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Normalizing Flows</head><p>Normalizing flows <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b43">44]</ref> are generative models that map a complex data distribution, such as real images, to a known noise distribution. They are trained by maximizing the log likelihood of their input images. Suppose a normalizing flow g produces output z from an input x i.e. z = g(x).</p><p>The change-of-variables formula provides the likelihood of the image under this transformation as:</p><formula xml:id="formula_0">log p(x) = log det dg dx + log p(z)<label>(1)</label></formula><p>The first term on the right (log determinant of the Jacobian) is often intractable, however, previous works on normalizing flows have found ways to estimate this efficiently. The second term, log p(z), is computed as the log probability of z under a known noise distribution, typically the standard Gaussian N (0, I).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Wavelet Flow [83]</head><p>WaveletFlow splits an image using the Discrete Wavelet Transformation, and maps the average image at each resolution to noise using a normalizing flow. WaveletFlow builds on the Glow <ref type="bibr" target="#b41">[42]</ref> architecture. It uses an orthogonal transformation, which does not preserve range, and adds a constant term to the log likelihood at each resolution. Best results are obtained when WaveletFlow models with a high parameter count are trained for a long period of time. We aim to fix these issues using our MRCNF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Continuous Normalizing Flows</head><p>Continuous Normalizing Flows (CNF) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b17">18]</ref> are a variant of normalizing flows that operate in the continuous domain. A CNF creates a geometric flow between the input and target (noise) distributions, by assuming that the state transition is governed by an Ordinary Differential Equation (ODE). It further assumes that the differential function is parameterized by a neural network, this model is called a Neural ODE <ref type="bibr" target="#b8">[9]</ref>. Suppose CNF g transforms its state v(t) using a Neural ODE, with neural network f defining the differential. Here, v(t 0 ) = x is, say, an image, and at the final time step v(t 1 ) = z is a sample from a known noise distribution.</p><formula xml:id="formula_1">dv(t) dt = f (v(t), t) =? v(t 1 ) = g(v(t 0 )) = v(t 0 ) + t1 t0 f (v(t), t) dt<label>(2)</label></formula><p>This integration is typically performed by an ODE solver. Since this integration can be run backwards as well to obtain the same v(t 0 ) from v(t 1 ), a CNF is a reversible model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Equation 1</head><p>can be used to compute the change in log-probability induced by the CNF. However, Chen et al. <ref type="bibr" target="#b8">[9]</ref> and Grathwohl et al. <ref type="bibr" target="#b20">[21]</ref> proposed a more efficient variant in the context of CNFs, called the instantaneous change-of-variables formula:</p><formula xml:id="formula_2">? log p(v(t)) ?t = ?Tr ?f ?v(t) =? ? log p v(t0)?v(t1) = ? t1 t0 Tr ?f ?v(t) dt<label>(3)</label></formula><p>Hence, the change in log-probability of the state of the Neural ODE i.e. ? log p v is expressed as another differential equation. The ODE solver now solves both differential equations eq. (2) and eq. (3) by augmenting the original state with the above. Thus, a CNF provides both the final state v(t 1 ) as well as the change in log probability ? log p v(t0)?v(t1) together.</p><p>Prior works <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b31">32]</ref> have trained CNFs as reversible generative models of images, by maximizing the likelihood of the images under the model:</p><formula xml:id="formula_3">z = g(x) ; log p(x) = ? log p x?z + log p(z)<label>(4)</label></formula><p>where x is an image, z and ? log p x?z are computed by the CNF using eq. (2) and eq. (3), and log p(z) is the likelihood of the computed z under a known noise distribution, typically the standard Gaussian N (0, I). Novel images are generated by sampling z from the known noise distribution, and running it through the CNF in reverse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our method</head><p>Our method is a reversible generative model of images that builds on top of CNFs. We introduce the notion of multiple resolutions in images, and connect the different resolutions in an autoregressive fashion. This helps generate images faster, with better likelihood values at higher resolutions, using only one GPU in all our experiments. We call this model Multi-Resolution Continuous Normalizing Flow (MRCNF).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multi-Resolution image representation</head><p>Multi-resolution representations of images have been explored in computer vision for decades <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b49">50]</ref>. This implies that much of the content of an image at a resolution is a composition of low-level information captured at coarser resolutions, and some high-level information not present in the coarser images. We take advantage of this property by first decomposing an image in resolution space i.e. by expressing it as a series of S images at decreasing resolutions: x ? (x 1 , x 2 , . . . , x S ), where x 1 = x is the finest image, x S is the coarsest, and every x s+1 is the average image of x s . This called an image pyramid, or a Gaussian Pyramid if the upsampling-downsampling operations include a Gaussian filter <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b49">50]</ref>. In this work, we obtain a coarser image simply by averaging pixels in every 2?2 patch, thereby halving the width and height.</p><p>However, this representation is redundant since much of the information in x 1 is contained in x s&gt;1 . Instead, we express x as a series of high-level information y s not present in the immediate coarser images x s+1 , and a final coarse image x S :</p><formula xml:id="formula_4">x ? (y 1 , x 2 ) ? (y 1 , y 2 , x 3 ) ? ? ? ? ? (y 1 , y 2 , . . . , y S?1 , x S )<label>(5)</label></formula><p>Our overall method is to map these S terms to S noise samples using S CNFs. We choose to design a linear transformation with the following properties: 1) invertible i.e. it should be possible to deterministically obtain x s from y s and x s+1 , and vice versa ; 2) volume preserving i.e. determinant is 1, change in log-likelihood is 0 ; 3) angle preserving ; and 4) range preserving (under the notion of the maximum principle <ref type="bibr" target="#b78">[79]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Defining the high-level information y s</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consider the simplest case of 2 resolutions</head><formula xml:id="formula_5">where x 1 is a 2?2 image with pixel values x 1 , x 2 , x 3 , x 4 , and x 2 is a 1?1 image with pixel valuex = 1 4 (x 1 + x 2 + x 3 + x 4 )</formula><p>. We require three values (y 1 , y 2 , y 3 ) = y 1 that contain information not present in x 2 , such that x 1 is obtained when y 1 and x 2 are combined.</p><p>This could be viewed as a problem of finding a matrix M such that:</p><formula xml:id="formula_6">[x 1 , x 2 , x 3 , x 4 ] = M [y 1 , y 2 , y 3 ,x]</formula><p>. We fix the last column of M as [1, 1, 1, 1] , since every pixel value in x 1 depends onx. Finding the rest of the parameters can be viewed as requiring four 3D vectors that are spaced such that they do not degenerate the number of dimensions of their span. These can be considered as the four corners of a tetrahedron in 3D space, under any configuration (rotated in 3D space), and any scaling of the vectors (see <ref type="figure" target="#fig_0">Figure 2</ref>).</p><p>Out of the many possibilities for this tetrahedron, we could choose the matrix that performs the Discrete Haar Wavelet Transform <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref>:</p><formula xml:id="formula_7">? ? ? x 1 x 2 x 3 x 4 ? ? ? = ? ? ? ? 1 2 1 2 1 2 1 1 2 ? 1 2 ? 1 2 1 ? 1 2 1 2 ? 1 2 1 ? 1 2 ? 1 2 1 2 1 ? ? ? ? ? ? ? y 1 y 2 y 3 x ? ? ? ?? ? ? ? y 1 y 2 y 3 x ? ? ? = ? ? ? ? 1 2 1 2 ? 1 2 ? 1 2 1 2 ? 1 2 1 2 ? 1 2 1 2 ? 1 2 ? 1 2 1 2 1 4 1 4 1 4 1 4 ? ? ? ? ? ? ? x 1 x 2 x 3 x 4 ? ? ?<label>(6)</label></formula><p>However, this has log det(M ?1 ) = log(1/2) (eq. (6)), and is therefore not volume preserving.</p><p>Other simple scaling of eq. (6) has been used in the past, for example multiplying the last row of eq. (6) by 2, yielding an orthogonal transformation, such as in WaveletFlow <ref type="bibr" target="#b82">[83]</ref>. However, this transformation neither preserves the volume i.e. the log determinant is not 0, nor the maximum i.e. the range of x s changes.</p><p>We wish to find a transformation M where: one of the results is the average of the inputs,x; it is unit determinant; the columns are orthogonal; and it preserves the range ofx. Fortunately such a matrix exists -although we have not seen it discussed in prior literature. It can be seen as a variant of the Discrete Haar Wavelet Transformation matrix that is unimodular, i.e. has a determinant of 1 (and is therefore volume preserving), while also preserving the range of the images for the input and its average:</p><formula xml:id="formula_8">? ? ? x 1 x 2 x 3 x 4 ? ? ? = 1 a ? ? ? c c c a c ?c ?c a ?c c ?c a ?c ?c c a ? ? ? ? ? ? y 1 y 2 y 3 x ? ? ??? ? ? ? y 1 y 2 y 3 x ? ? ? = ? ? ? c ?1 c ?1 ?c ?1 ?c ?1 c ?1 ?c ?1 c ?1 ?c ?1 c ?1 ?c ?1 ?c ?1 c ?1 a ?1 a ?1 a ?1 a ?1 ? ? ? ? ? ? x 1 x 2 x 3 x 4 ? ? ?<label>(7)</label></formula><p>where c = 2 2/3 , a = 4. Hence, log det(M ?1 ) = log(1) = 0. This can be scaled up to larger spatial regions by performing the same calculation for each 2?2 patch. Let M be the function that uses matrix M from above and combines every pixel in x s+1 with the three corresponding pixels in y s to make the 2?2 patch at that location in x s using eq. <ref type="formula" target="#formula_8">(7)</ref>:</p><formula xml:id="formula_9">x s = M (y s , x s+1 ) ?? y s , x s+1 = M ?1 (x s )<label>(8)</label></formula><p>Equation <ref type="formula" target="#formula_0">1</ref> can be used to compute the change in log likelihood from this transformation</p><formula xml:id="formula_10">x s ? (y s , x s+1 ): log p(x s ) = ? log p xs?(ys,xs+1) + log p(y s , x s+1 ) = log det(M ?1 ) + log p(y s , x s+1 ) (9)</formula><p>where log det(M ?1 ) = dims(x s+1 ) log(1/2) in the case of eq. (6), where "dims" is the number of pixels times the number of channels (typically 3) in the image, and log det(M ?1 ) = 0 for eq. (7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multi-Resolution Continuous Normalizing Flows</head><p>Using the multi-resolution image representation in eq. (5), we characterize the conditional distribution over the additional degrees of freedom (y s ) required to generate a higher resolution image (x s ) that is consistent with the average (x s+1 ) over the equivalent pixel space. At each resolution s, we use a CNF to reversibly map between y s (or x S when s=S) and a sample z s from a known noise distribution. For generation, y s only adds 3 degrees of freedom to x s+1 , which contain information missing in x s+1 , but conditional on it.</p><p>This framework ensures that one coarse image could generate several potential fine images, but these fine images have the same coarse image as their average. This fact is preserved across resolutions. Note that the 3 additional pixels in y s per pixel in x s+1 are generated conditioned on the entire coarser image x s+1 , thus maintaining consistency using the full context.</p><p>In principle, any generative model could be used to map between the multi-resolution image and noise. Normalizing flows are good candidates for this as they are probabilistic generative models that perform exact likelihood estimates, and can be run in reverse to generate novel data from the model's distribution. This allows model comparison and measurement of generalization to unseen data. We choose to use the CNF variant of normalizing flows at each resolution. CNFs have recently been shown to be effective in modeling image distributions using a fraction of the number of parameters typically used in normalizing flows (and non flow-based approaches), and their underlying framework of Neural ODEs have been shown to be more robust than convolutional layers <ref type="bibr" target="#b81">[82]</ref>.</p><p>Training: We train an MRCNF by maximizing the average log-likelihood of the images in the training dataset under the model. The log probability of each image log p(x) can be estimated recursively from eq. (9) as:</p><formula xml:id="formula_11">log p(x) = ? log p x1?(y1,x2) + log p(y 1 , x 2 ) = ? log p x1?(y1,x2) + log p(y 1 | x 2 ) + log p(x 2 ) = S?1 s=1 ? log p xs?(ys,xs+1) + log p(y s | x s+1 ) + log p(x S )<label>(10)</label></formula><p>where ? log p xs?(ys,xs+1) is given by eq. (9), log p(y s | x s+1 ) and log p(x S ) are given by eq. <ref type="formula" target="#formula_3">(4)</ref>:</p><formula xml:id="formula_12">z s = g s (y s | x s+1 ) ; log p(y s | x s+1 ) = ? log p (ys?zs)|xs+1 + log p(z s ) (11) z S = g S (x S ) ; log p(x S ) = ? log p x S ?z S + log p(z S )<label>(12)</label></formula><p>The coarsest resolution S can be chosen such that the last CNF operates on the image distribution at a small enough resolution that is easy to model unconditionally. All other CNFs are conditioned on the immediate coarser image. The conditioning itself is achieved by concatenating the input image of the CNF with the coarser image. This model could be seen as a stack of CNFs connected in an autoregressive fashion.</p><p>Typically, likelihood-based generative models are compared using the metric of bits-per-dimension (BPD), i.e. the negative log likelihood per pixel in the image. Hence, we train our MRCNF to minimize the average BPD of the images in the training dataset, computed using eq. (13):</p><formula xml:id="formula_13">BPD(x) = ? log p(x)/dims(x)<label>(13)</label></formula><p>We use FFJORD <ref type="bibr" target="#b20">[21]</ref> as the baseline model for our CNFs. In addition, we use to two regularization terms introduced by RNODE [18] to speed up the training of FFJORD models by stabilizing the learnt dynamics: the kinetic energy of the flow K(?), and the Jacobian norm B(?):</p><formula xml:id="formula_14">K(?) = t1 t0 f (v(t), t, ?) 2 2 dt; B(?) = t1 t0 ? z f (v(t), t, ?) 2 2 dt, ? N (0, I) (14)</formula><p>Parallel training: Note that although the final log likelihood log p(x) involves sequentially summing over values returned by all S CNFs, the log likelihood term of each CNF is independent of the others.</p><p>Conditioning is done using ground truth images. Hence, each CNF can be trained independently, in parallel.</p><p>Generation: Given an S-resolution model, we first sample z s , s = 1, . . . , S from the latent noise distributions. The CNF g s at resolution s transforms the noise sample z s to high-level information y s conditioned on the immediate coarse image x s+1 (except g S which is unconditioned). y s and x s+1 are then combined to form x s using M from eq. <ref type="formula" target="#formula_8">(7)</ref>. This process is repeated progressively from coarser to finer resolutions, until the finest resolution image x 1 is computed (see <ref type="figure">Figure 1</ref>). It is to be noted that the generated image at one resolution is used to condition the CNF at the finer resolution.</p><formula xml:id="formula_15">x S = g ?1 S (z S ) s = S y s = g ?1 s (z s | x s+1 ); x s = M (y s , x s+1 ) s = S-1 ? 1<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Multi-Resolution Noise</head><p>We further decompose the noise image as well into its respective coarser components. This means that ultimately we use only one noise image at the finest level, but it is decomposed into multiple resolutions using eq. (7). x s+1 is mapped to noise of a quarter variance, while y s is mapped to noise of c-factored variance (see <ref type="figure">fig. 1</ref>). Although this is optional, it preserves interpretation between the single-and multi-resolution models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related work</head><p>Multi-resolution approaches already serve as a key component of state-of-the-art GAN <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b35">36]</ref> and VAE <ref type="bibr" target="#b67">[68,</ref><ref type="bibr" target="#b76">77]</ref> based deep generative models. Deconvolutional CNNs <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b66">67]</ref> use upsampling layers to generate images more effectively. Modern state-of-the-art generative models have also injected noise at different levels to improve sample quality <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b76">77]</ref>.</p><p>Several prior works on normalizing flows <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b82">83</ref>] build on RealNVP <ref type="bibr" target="#b15">[16]</ref>. Although they achieve great results in terms of BPD and image quality, they nonetheless report results from significantly higher number of parameters (some with 100x!), and several times GPU hours of training.</p><p>STEER <ref type="bibr" target="#b18">[19]</ref> introduced temporal regularization to CNFs by making the final time of integration stochastic. However, we found that this increased training time without significant BPD improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison to WaveletFlow:</head><p>We emphasize that there are important and crucial differences between our MRCNF and WaveletFlow. We generalize the notion of a multi-resolution image representation (section 3.2), and show that Wavelets are one case of this general formulation. WaveletFlow builds on the Glow <ref type="bibr" target="#b41">[42]</ref> architecture, while ours builds on CNFs <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b17">18]</ref>. We also make use of the notion of multi-resolution decomposition of the noise, which is optional, but is not taken into account by WaveletFlow. WaveletFlow uses an orthogonal transformation which does not preserve range ; our MRCNF uses eq. (7) which is volume-preserving and range-preserving. Finally, WaveletFlow applies special sampling techniques to obtain better samples from its model. We have so far not used such techniques for generation, but we believe they can potentially help our models as well. By making these important changes, we fix many of the previously discussed issues with WaveletFlow. For a more detailed ablation study, please check subsection 5.1.</p><p>"Multiple scales" in prior normalizing flows: Normalizing flows <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b20">21]</ref> try to be "multi-scale" by transforming the input in a smart way (squeezing operation) such that the width of the features progressively reduces in the direction of image to noise, while maintaining the total dimensions. This happens while operating at a single resolution. In contrast, our model stacks normalizing flows at multiple resolutions in an autoregressive fashion by conditioning on the images at coarser resolutions. <ref type="table">Table 1</ref>: Bits-per-dimension (lower is better) of images in the corresponding evaluation sets for CIFAR10, ImageNet 32?32, and ImageNet 64?64. We also report the number of parameters in the models, and the time taken to train (in GPU hours). All our models were trained on only one GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental results</head><p>Blank spaces indicate unreported values. ? As reported in <ref type="bibr" target="#b18">[19]</ref>. ? Re-implemented by us. ' We train MRCNF models on the CIFAR10 <ref type="bibr" target="#b44">[45]</ref> dataset at finest resolution of 32x32, and the ImageNet <ref type="bibr" target="#b13">[14]</ref> dataset at 32x32, 64x64, 128x128. We build on top of the code provided in Finlay et al. <ref type="bibr" target="#b17">[18]</ref> 1 . In all cases, we train using only one NVIDIA RTX 20280 Ti GPU with 11GB.</p><p>In <ref type="table" target="#tab_4">Table 5</ref>, we compare our results with prior work in terms of (lower is better in all cases) the BPD of the images of the test datasets under the trained models, the number of parameters used by the model, and the number of GPU hours taken to train. The most relevant models for comparison are the 1-resolution FFJORD <ref type="bibr" target="#b20">[21]</ref> models, and their regularized version RNODE <ref type="bibr" target="#b17">[18]</ref>, since our model directly converts their architecture into multi-resolution. Other relevant comparisons are previous flow-based methods <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b82">83]</ref>, however their core architecture (RealNVP <ref type="bibr" target="#b15">[16]</ref>) is quite different from FFJORD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BPD:</head><p>At lower resolution spaces, we achieve comparable BPDs in lesser time with far fewer parameters than previous normalizing flows (and non flow-based approaches). However, the power of the multi-resolution formulation is more evident at higher resolutions: we achieve better BPD for ImageNet64 with significantly fewer parameters and lower time using only one GPU.</p><p>It is to be noted that we were not able to reproduce the same BPD as provided by STEER <ref type="bibr" target="#b18">[19]</ref>, we report the results of our re-implementation. A more complete table can be found in the appendix.</p><p>Train time: All our experiments used only one GPU, and took significantly less time to train than 1-resolution CNFs, and all prior works including flow-based and non-flow-based models. Since all the CNFs can be trained in parallel, the actual training time in practice could be much lower than reported.  Super-resolution: Our formulation also allows for super-resolution of images <ref type="figure" target="#fig_1">(Figure 3</ref>) free of cost since our framework is autoregressive in resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Progressive training:</head><p>We trained an MRCNF model on ImageNet128 by training only the finest resolution (128?128) conditioned on the immediate coarser (64?64) images, and attached it to a 3-resolution model trained on ImageNet64. The resultant 4-resolution ImageNet128 model gives a BPD of 3.31 ( <ref type="table" target="#tab_1">Table 2</ref>) with just 2.74M parameters in ?60 GPU hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Ablation study</head><p>Our MRCNF method differs from WaveletFlow in three respects: 1. we use CNFs, 2. we use eq. (7) instead of eq. (6) as used by WaveletFlow, 3. we use multi-resolution noise. We check the individual effects of these changes in an ablation study in <ref type="table">Table 3</ref>, and conclude that: <ref type="table">Table 3</ref>: Ablation study across using Wavelet in eq. (6), and multi-resolution noise formulation in 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR10</head><p>IMAGENET64 BPD PARAM TIME BPD PARAM TIME WaveletFlow <ref type="bibr" target="#b82">[83]</ref> 3.78 98.0M 822.00 1-resolution CNF (RNODE) <ref type="bibr" target="#b17">[18]</ref> 3 1. Simply replacing the normalizing flows in WaveletFlow with CNFs does not produce the best results. It does improve the BPD and training time compared to WaveletFlow. 2. Using our unimodular transformation in eq. (7) instead of the original Wavelet Transformation of eq. (6) not only improves the BPD, it also consistently decreases training time. 3. As expected, the use of multi-resolution noise does not have a critical impact on either BPD or training time. We use it anyway so as to retain interpretation with 1-resolution models.</p><p>Thus, our MRCNF model is not a trivial replacement of normalizing flows with CNFs in WaveletFlow. We generalize the notion of multi-resolution image representation, in which the Discrete Wavelet Transform is one of many possibilities. We then derived a unimodular transformation that adds no change in likelihood. The derivation of likelihood-based models suggests that the density of an image under the model is an effective measure of its likelihood of being in distribution. However, recent works <ref type="bibr" target="#b75">[76,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b58">59]</ref> have pointed out that it is possible that images drawn from other distributions have higher model likelihood. Examples have been shown where normalizing flow models (such as Glow) trained on CIFAR10 images assign higher likelihood to SVHN <ref type="bibr" target="#b59">[60]</ref> images. This could have serious implications on the practical applicability of these models. Some also note that likelihoodbased models do not generate images with good sample quality as they avoid assigning small probability to out-of-distribution (OoD) data points, hence using model likelihood (-BPD) for detecting OoD data is not effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Examining Out-of-Distribution behaviour</head><p>We conduct the same experiments with (MR)CNFs, and find that similar conclusions can be drawn. <ref type="figure" target="#fig_2">Figure 4</ref> plots the histogram of log likelihood per dimension (-BPD) of OoD images (SVHN, TinyImageNet) under MRCNF models trained on CIFAR10. It can be observed that the likelihood of the OoD SVHN is higher than CIFAR10 for MRCNF, similar to the findings for Glow, PixelCNN, VAE in earlier works <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b42">43]</ref>.</p><p>One possible explanation put forward by Nalisnick et al. <ref type="bibr" target="#b58">[59]</ref> is that "typical" images are less "likely" than constant images, which is a consequence of the distribution of a Gaussian in high dimensions.</p><p>Indeed, as our <ref type="figure" target="#fig_2">Figure 4</ref> shows, constant images have the highest likelihood under MRCNFs, while randomly generated (uniformly distributed) pixels have the least likelihood (not shown in figure due to space constraints).</p><p>Choi et al. <ref type="bibr" target="#b12">[13]</ref>, Nalisnick et al. <ref type="bibr" target="#b58">[59]</ref> suggest using "typicality" as a better measure of OoD. However, Serr? et al. <ref type="bibr" target="#b70">[71]</ref> observe that the complexity of an image plays a significant role in the training of likelihood-based generative models. They propose a new metric S as an out-of-distribution detector:</p><formula xml:id="formula_16">S(x) = bpd(x) ? L(x)<label>(16)</label></formula><p>where L(x) is the complexity of an image x measured as the length of the best compressed version of x (we use FLIF <ref type="bibr" target="#b72">[73]</ref> following Serr? et al. <ref type="bibr" target="#b70">[71]</ref>) normalized by the number of dimensions. We perform a similar analysis as Serr? et al. <ref type="bibr" target="#b70">[71]</ref> to test how S compares with -bpd for OoD detection. For different MRCNF models trained on CIFAR10, we compute the area under the receiver operating characteristic curve (auROC) using -bpd and S as standard evaluation for the OoD detection task <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b70">71]</ref>. <ref type="table" target="#tab_3">Table 4</ref> shows that S does perform better than -bpd in the case of (MR)CNFs, similar to the findings in Serr? et al. <ref type="bibr" target="#b70">[71]</ref> for Glow and PixelCNN++. It seems that SVHN is easier to detect as OoD for Glow than MRCNFs. However, OoD detection performance is about the same for TinyImageNet. We also observe that MRCNFs are better at OoD than CNFs.</p><p>Other OoD methods <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b23">24]</ref> are not suitable in our case, as identified in Serr? et al. <ref type="bibr" target="#b70">[71]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Shuffled in-distribution images</head><p>Kirichenko et al. <ref type="bibr" target="#b42">[43]</ref> conclude that normalizing flows do not represent images based on their semantic contents, but rather directly encode their visual appearance. We verify this for continuous normalizing flows by estimating the density of in-distribution test images, but with patches of pixels randomly shuffled. <ref type="figure" target="#fig_3">Figure 5 (a)</ref> shows an example of images of shuffled patches of varying size, <ref type="figure" target="#fig_3">Figure 5</ref> (b) shows the graph of the their log-likelihoods.</p><p>That shuffling pixel patches would render the image semantically meaningless is reflected in the Fr?chet Inception Distance (FID) between CIFAR10-Train and these sets of shuffled images -1x1: 340.42, 2x2: 299.99, 4x4: 235.22, 8x8: 101.36, 16x16: 33.06, 32x32 (i.e. CIFAR10-Test): 3.15. However, we see that images with large pixel patches shuffled are quite close in likelihood to the unshuffled images, suggesting that since their visual content has not changed much they are almost as likely as unshuffled images under MRCNFs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have presented a Multi-Resolution approach to Continuous Normalizing Flows (MRCNF). MRCNF models achieve comparable or better performance in significantly less training time, training on a single GPU, with a fraction of the number of parameters of other competitive models. Although the likelihood values for 32?32 resolution datasets such as CIFAR10 and ImageNet32 do not improve over the baseline, ImageNet64 and above see a marked improvement. The performance is better for higher resolutions, as seen in the case of ImageNet128. We also conducted an ablation study to note the effects of each change we introduced in the formulation.</p><p>In addition, we show that (Multi-Resolution) Continuous Normalizing Flows have similar out-ofdistribution properties as other Normalizing Flows.</p><p>In terms of broader social impacts of this work, generative models of images can be used to generate so-called fake images, and this issue has been discussed at length in other works. We emphasize lower computational budgets, and show comparable performance with far fewer parameters and less training time.  (a) Generated samples at 8?8 (b) Generated samples at 16?16 (c) Generated samples at 32?32 <ref type="figure">Figure 7</ref>: Generated samples from CIFAR10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Simple example of density estimation</head><p>For example, if we use Euler method as our ODE solver, for density estimation Equation 2 reduces to:</p><formula xml:id="formula_17">v(t 1 ) = v(t 0 ) + (t 1 ? t 0 )f s (v(t 0 ), t 0 | c)<label>(17)</label></formula><p>where f s is a neural network, t 0 represents the "time" at which the state is image x, and t 1 is when the state is noise z. We start at scale S with an image sample x S , and assume t 0 and t 1 are 0 and 1 respectively:</p><formula xml:id="formula_18">? ? ? ? ? ? ? ? ? ? ? ? ? ? ? z S = x S + f S (x S , t 0 | x S?1 ) z S?1 = x S?1 + f S?1 (x S?1 , t 0 | x S?2 )</formula><p>. . .</p><formula xml:id="formula_19">z 1 = x 1 + f 1 (x 1 , t 0 | x 0 ) z 0 = x 0 + f 0 (x 0 , t 0 )<label>(18)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Simple example of generation</head><p>For example, if we use Euler method as our ODE solver, for generation Equation 2 reduces to:</p><p>v(t 0 ) = v(t 1 ) + (t 0 ? t 1 )f s (v(t 1 ), t 1 | c)</p><p>i.e. the state is integrated backwards from t 1 (i.e. z s ) to t 0 (i.e. x s ). We start at scale 0 with a noise sample z 0 , and assume t 0 and t 1 are 0 and 1 respectively:</p><formula xml:id="formula_21">? ? ? ? ? ? ? ? ? ? ? ? ? ? ? x 0 = z 0 ? f 0 (z 0 , t 1 ) x 1 = z 1 ? f 1 (z 1 , t 1 | x 0 ) . . . x S?1 = z S?1 ? f S?1 (z S?1 , t 1 | x S?2 ) x S = z S ? f S (z S , t 1 | x S?1 )<label>(20)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Models</head><p>We used the same neural network architecture as in RNODE <ref type="bibr" target="#b17">[18]</ref>. The CNF at each resolution consists of a stack of bl blocks of a 4-layer deep convolutional network comprised of 3x3 kernels and softplus activation functions, with 64 hidden dimensions, and time t concatenated to the spatial input. In addition, except at the coarsest resolution, the immediate coarser image is also concatenated with the state. The integration time of each piece is [0, 1]. The number of blocks bl and the corresponding total number of parameters are given in <ref type="table" target="#tab_5">Table 6</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Gradient norm</head><p>In order to avoid exploding gradients, We clipped the norm of the gradients <ref type="bibr" target="#b65">[66]</ref> by a maximum value of 100.0. In case of using adversarial loss, we first clip the gradients provided by the adversarial loss by 50.0, sum up the gradients provided by the log-likelihood loss, and then clip the summed gradients by 100.0.  <ref type="table">Table 7</ref> lists the FID values of generated images from MRCNF models trained on CIFAR10, with different temperature settings on the Gaussian.  <ref type="table">Table 7</ref>: FID v/s temperature for MRCNF models trained on CIFAR10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H FID v/s Temperature</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Tetrahedron in 3D space with 4 corners</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>ImageNet: Example of super-resolving from ground truth 16?16 to 64?64. Top: ground truth, middle: generated, bottom: ground truth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Histogram of log likelihood per dimension of out-of-distribution datasets (TinyImageNet, SVHN, Constant) under (MR)CNF models trained on CIFAR10. As with other likelihood-based generative models such as Glow &amp; Pixel-CNN, OoD datasets have higher likelihood under (MR)CNFs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>(a) Example of shuffling different-sized patches of a 32?32 image: (left to right, top to bottom) 1?1, 2?2, 4?4, 8?8, 16?16, 32?32 (unshuffled) (b) Bits-per-dim vs Epoch at each resolution for different MRCNF models trained on CIFAR10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Generated samples from MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>S log 2 =</head><label>2</label><figDesc>=? log p(a S ) = log p(b S ) ? D S log 256 =? bpd(a S ) = ? log p(a S ) D S log 2 = ?(log p(b S ) ? D S log 256) D ? log p(b S ) D S log 2 + log 256 log 2 = bpd(x) + 8where bpd(x) is given from Equation 13.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>GPUs to train on ImageNet64. FFJORD + STEER [19] 3.40 1.4M 86.3 3.84 2.0M &gt;5days RNODE + STEER [19] 3.397 1.4M 22.2 2.35 2.0M 24.9</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x':</cell></row><row><cell cols="3">Fails to train.  CIFAR10</cell><cell cols="2">IMAGENET32</cell><cell cols="2">IMAGENET64</cell></row><row><cell></cell><cell cols="6">BPD PARAM TIME BPD PARAM TIME BPD PARAM TIME</cell></row><row><cell cols="2">Non Flow-based Prior Work</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Gated PixelCNN [78]</cell><cell>3.03</cell><cell></cell><cell>3.83</cell><cell>60</cell><cell>3.57</cell><cell>60</cell></row><row><cell>SPN [57]</cell><cell></cell><cell></cell><cell>3.85 150.0M</cell><cell></cell><cell cols="2">3.53 150.0M</cell></row><row><cell cols="2">Sparse Transformer [12] 2.80 59.0M</cell><cell></cell><cell></cell><cell></cell><cell cols="2">3.44 152.0M 7days</cell></row><row><cell>NVAE [77]</cell><cell>2.91</cell><cell>55</cell><cell>3.92</cell><cell>70</cell><cell></cell><cell></cell></row><row><cell>DistAug [34]</cell><cell>2.56 152.0M</cell><cell></cell><cell></cell><cell></cell><cell cols="2">3.42 152.0M</cell></row><row><cell>Flow-based Prior Work</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RealNVP [16]</cell><cell>3.49</cell><cell></cell><cell>4.28 46.0M</cell><cell></cell><cell cols="2">3.98 96.0M</cell></row><row><cell>Glow [42]</cell><cell>3.35 44.0M</cell><cell></cell><cell>4.09 66.1M</cell><cell></cell><cell cols="2">3.81 111.1M</cell></row><row><cell>MaCow [53]</cell><cell>3.16 43.5M</cell><cell></cell><cell></cell><cell></cell><cell cols="2">3.69 122.5M</cell></row><row><cell>Flow++ [25]</cell><cell>3.08 31.4M</cell><cell></cell><cell>3.86 169.0M</cell><cell></cell><cell cols="2">3.69 73.5M</cell></row><row><cell>Wavelet Flow [83]</cell><cell></cell><cell></cell><cell>4.08 64.0M</cell><cell></cell><cell cols="2">3.78 96.0M 822</cell></row><row><cell>DenseFlow [22]</cell><cell>2.98</cell><cell>250</cell><cell>3.63</cell><cell>310</cell><cell>3.35</cell><cell>224</cell></row><row><cell cols="3">1-Resolution Continuous Normalizing Flow</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>FFJORD [21]</cell><cell cols="5">3.40 0.9M ?5days  ? 3.96  ? 2.0M  ? &gt;5days x</cell><cell>x</cell></row><row><cell>RNODE [18]</cell><cell cols="4">3.38 1.4M 31.8  MRCNF)</cell><cell></cell><cell></cell></row><row><cell>2-resolution MRCNF</cell><cell cols="6">3.65 1.3M 19.8 3.77 1.3M 18.2 3.44 2.0M 42.3</cell></row><row><cell>2-resolution MRCNF</cell><cell cols="4">3.54 3.3M 36.5 3.78 6.7M 18.0</cell><cell>x</cell><cell>6.7M x</cell></row><row><cell>3-resolution MRCNF</cell><cell cols="6">3.79 1.5M 17.4 3.97 1.5M 13.8 3.55 2.0M 35.4</cell></row><row><cell>3-resolution MRCNF</cell><cell cols="4">3.60 5.1M 38.3 3.93 10.2M 41.2</cell><cell>x</cell><cell>7.6M x</cell></row></table><note>* RNODE [18] used 4? 2.36 2.0M ? 30.1* 3.83 2.0M* 256.4? 3.49 ? 1.6M ? 40.4? 3.49 ? 1.6M ? 30.1 (OURS) Multi-Resolution Continuous Normalizing Flow (</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Metrics for unconditional ImageNet128 generation. -resolution MRCNF 3.31 ?0.69 2.74M 58.59</figDesc><table><row><cell>IMAGENET128</cell><cell>BPD</cell><cell>PARAM TIME</cell></row><row><cell>Parallel Multiscale [69]</cell><cell>3.55</cell><cell></cell></row><row><cell>SPN [57]</cell><cell>3.08</cell><cell>250M</cell></row><row><cell>(OURS) 4</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell cols="3">auROC for OoD detection using</cell></row><row><cell cols="3">-bpd and S[71], for models trained on CI-</cell></row><row><cell>FAR10.</cell><cell></cell><cell></cell></row><row><cell>CIFAR10</cell><cell>SVHN</cell><cell>TIN</cell></row><row><cell>(trained)</cell><cell cols="2">-bpd S -bpd S</cell></row><row><cell>Glow</cell><cell cols="2">0.08 0.95 0.66 0.72</cell></row><row><cell>1-res CNF</cell><cell cols="2">0.07 0.16 0.48 0.60</cell></row><row><cell cols="3">2-res MRCNF 0.06 0.25 0.46 0.66</cell></row><row><cell cols="3">3-res MRCNF 0.05 0.25 0.46 0.66</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Unconditional image generation metrics (lower is better in all cases): number of parameters in the model, bits-per-dimension, time (in hours). Most previous models use multiple GPUs for training, all our models were trained on only one NVIDIA V100 GPU. ? As reported in<ref type="bibr" target="#b18">[19]</ref>. * FFJORD RNODE<ref type="bibr" target="#b17">[18]</ref> used 4 GPUs to train on ImageNet64. 'x': Fails to train.4M  31.84 ? 2.36 2.0M ? 30.1 * 3.83 2.0M * 256.4 ? 3.49 ? 1.6M ? 40.39</figDesc><table><row><cell></cell><cell></cell><cell>CIFAR10</cell><cell cols="2">IMAGENET32</cell><cell cols="2">IMAGENET64</cell></row><row><cell></cell><cell cols="3">BPD PARAM TIME BPD PARAM</cell><cell cols="3">TIME BPD PARAM TIME</cell></row><row><cell>Non Flow-based Prior Work</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>PixelRNN [63]</cell><cell>3.00</cell><cell></cell><cell>3.86</cell><cell cols="2">3.63</cell></row><row><cell>Gated PixelCNN [78]</cell><cell>3.03</cell><cell></cell><cell>3.83</cell><cell cols="2">60 3.57</cell><cell>60</cell></row><row><cell>Parallel Multiscale [69]</cell><cell></cell><cell></cell><cell>3.95</cell><cell cols="2">3.70</cell></row><row><cell>Image Transformer [65]</cell><cell>2.90</cell><cell></cell><cell>3.77</cell><cell></cell><cell></cell></row><row><cell>PixelSNAIL [11]</cell><cell>2.85</cell><cell></cell><cell>3.80</cell><cell></cell><cell></cell></row><row><cell>SPN [57]</cell><cell></cell><cell></cell><cell>3.85 150.0M</cell><cell cols="3">3.53 150.0M</cell></row><row><cell>Sparse Transformer [12]</cell><cell cols="2">2.80 59.0M</cell><cell></cell><cell cols="3">3.44 152.0M 7days</cell></row><row><cell>Axial Transformer [26]</cell><cell></cell><cell></cell><cell>3.76</cell><cell cols="2">3.44</cell></row><row><cell>PixelFlow++ [61]</cell><cell>2.92</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>NVAE [77]</cell><cell>2.91</cell><cell>55</cell><cell>3.92</cell><cell>70</cell><cell></cell></row><row><cell cols="3">Dist-Aug Sparse Transformer [34] 2.56 152.0M</cell><cell></cell><cell cols="3">3.42 152.0M</cell></row><row><cell>Flow-based Prior Work</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>IAF [41]</cell><cell></cell><cell></cell><cell>3.11</cell><cell></cell><cell></cell></row><row><cell>RealNVP [16]</cell><cell>3.49</cell><cell></cell><cell>4.28 46.0M</cell><cell cols="3">3.98 96.0M</cell></row><row><cell>Glow [42]</cell><cell cols="2">3.35 44.0M</cell><cell>4.09 66.1M</cell><cell cols="3">3.81 111.1M</cell></row><row><cell>i-ResNets [3]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Emerging [27]</cell><cell cols="2">3.34 44.7M</cell><cell>4.09 67.1M</cell><cell cols="3">3.81 67.1M</cell></row><row><cell>IDF [28]</cell><cell>3.34</cell><cell></cell><cell>4.18</cell><cell cols="2">3.90</cell></row><row><cell>S-CONF [35] MintNet [74]</cell><cell cols="3">3.34 3.32 17.9M ?5days 4.06 17.4M</cell><cell></cell><cell></cell></row><row><cell>Residual Flow [10]</cell><cell>3.28</cell><cell></cell><cell>4.01</cell><cell cols="2">3.76</cell></row><row><cell>MaCow [53]</cell><cell cols="2">3.16 43.5M</cell><cell></cell><cell cols="3">3.69 122.5M</cell></row><row><cell>Neural Spline Flows [17]</cell><cell cols="2">3.38 11.8M</cell><cell></cell><cell cols="3">3.82 15.6M</cell></row><row><cell>Flow++ [25]</cell><cell cols="2">3.08 31.4M</cell><cell>3.86 169.0M</cell><cell cols="3">3.69 73.5M</cell></row><row><cell>ANF [31]</cell><cell>3.05</cell><cell></cell><cell>3.92</cell><cell cols="2">3.66</cell></row><row><cell>MEF [81]</cell><cell cols="2">3.32 37.7M</cell><cell>4.05 37.7M</cell><cell cols="3">3.73 46.6M</cell></row><row><cell>VFlow [8]</cell><cell>2.98</cell><cell></cell><cell>3.83</cell><cell></cell><cell></cell></row><row><cell>Woodbury NF [52]</cell><cell>3.47</cell><cell></cell><cell>4.20</cell><cell cols="2">3.87</cell></row><row><cell>NanoFlow [47]</cell><cell>3.25</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ConvExp [29]</cell><cell>3.218</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wavelet Flow [83]</cell><cell></cell><cell></cell><cell>4.08 64.0M</cell><cell cols="3">3.78 96.0M 822</cell></row><row><cell>TayNODE [39]</cell><cell>1.039</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">1-resolution Continuous Normalizing Flow</cell><cell></cell><cell></cell><cell></cell></row><row><cell>FFJORD [21]</cell><cell>3.40</cell><cell cols="3">0.9M ?5days  ? 3.96  ? 2.0M  ? &gt;5days x</cell><cell></cell><cell>x</cell></row><row><cell cols="5">RNODE [18] 1.FFJORD + STEER [19] 3.38 3.40 1.4M 86.34 3.84 2.0M &gt;5days</cell><cell></cell></row><row><cell>RNODE + STEER [19]</cell><cell cols="4">3.397 1.4M 22.24 2.35 2.0M  ? 3.49  ? 1.6M  ? 30.07 24.90</cell><cell></cell></row><row><cell cols="4">(OURS) Multi-Resolution Continuous Normalizing Flow (MRCNF)</cell><cell></cell><cell></cell></row><row><cell>2-resolution MRCNF</cell><cell>3.65</cell><cell cols="2">1.3M 19.79 3.77 1.3M</cell><cell cols="2">18.18 3.44</cell><cell>2.0M 42.30</cell></row><row><cell>2-resolution MRCNF</cell><cell>3.54</cell><cell cols="2">3.3M 36.47 3.78 6.7M</cell><cell>17.98 x</cell><cell></cell><cell>6.7M</cell><cell>x</cell></row><row><cell>3-resolution MRCNF</cell><cell>3.79</cell><cell cols="2">1.5M 17.44 3.97 1.5M</cell><cell cols="2">13.78 3.55</cell><cell>2.0M 35.39</cell></row><row><cell>3-resolution MRCNF</cell><cell>3.60</cell><cell cols="2">5.1M 38.27 3.93 10.2M</cell><cell>41.20 x</cell><cell></cell><cell>7.6M</cell><cell>x</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Number of parameters for different models with different total number of resolutions (res), and the number of channels (ch) and number of blocks (bl) per resolution.</figDesc><table><row><cell></cell><cell>MRCNF</cell></row><row><cell cols="2">resolutions ch bl Param</cell></row><row><cell></cell><cell>64 2 0.16M</cell></row><row><cell>1</cell><cell>64 4 0.32M</cell></row><row><cell></cell><cell>64 14 1.10M</cell></row><row><cell></cell><cell>64 8 1.33M</cell></row><row><cell>2</cell><cell>64 20 3.34M</cell></row><row><cell></cell><cell>64 40 6.68M</cell></row><row><cell></cell><cell>64 6 1.53M</cell></row><row><cell>3</cell><cell>64 8 2.04M</cell></row><row><cell></cell><cell>64 20 5.10M</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>147.62 175.93 284.75 405.34 466.16 2-resolution MRCNF 89.55 106.21 171.53 261.64 370.38 435.17 3-resolution MRCNF 88.51 104.39 152.82 232.53 301.89 329.12 4-resolution MRCNF 92.19 104.35 135.58 186.71 250.39 313.39</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Temperature</cell><cell></cell></row><row><cell></cell><cell>1.0</cell><cell>0.9</cell><cell>0.8</cell><cell>0.7</cell><cell>0.6</cell><cell>0.5</cell></row><row><cell>1-resolution CNF</cell><cell>138.82</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/cfinlay/ffjord-rnode</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments and Disclosure of Funding</head><p>Chris Finlay contributed to this paper while a postdoc at McGill University; he is now affiliated with Deep Render. His postdoc was funded in part by a Healthy Brains Healthy Lives Fellowship. Adam Oberman was supported by the Air Force Office of Scientific Research under award number FA9550-18-1-0167 and by IVADO. Christopher Pal is funded in part by CIFAR. We thank CIFAR for their support through the CIFAR AI Chairs program. We also thank Samsung for partially supporting Vikram Voleti for this work. We thank Adam Ibrahim, Etienne Denis, Gauthier Gidel, Ioannis Mitliagkas, and Roger Girgis for their valuable feedback.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G 8-bit to uniform</head><p>The change-of-variables formula gives the change in probability due to the transformation of u to v: </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pyramid methods in image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Ogden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RCA engineer</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="33" to="41" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Towards principled methods for training generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.04862</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Invertible residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Jacobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="573" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A closer look at the optimization landscapes of generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Berard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large scale GAN training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The laplacian pyramid as a compact image code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on communications</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="532" to="540" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast filter transform for image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Burt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer graphics and image processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="51" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Vflow: More expressive generative flows with variational data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chenli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural ordinary differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Residual flows for invertible generative modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Jacobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9916" to="9926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pixelsnail: An improved autoregressive generative model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. PMLR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="864" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Generating long sequences with sparse transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.10509</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Waic, but why? generative ensembles for robust anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.01392</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep generative image models using a laplacian pyramid of adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1486" to="1494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Density estimation using real nvp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learned Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural spline flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Durkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bekasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papamakarios</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/7ac71d433f282034e088473244df8c02-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="7511" to="7522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">How to train your neural ode: the world of jacobian and kinetic regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nurbekyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Steer: Simple temporal regularization for neural odes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Behl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Namboodiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT Press</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ffjord: Free-form continuous dynamics for scalable reversible generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Densely connected normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grci?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Grubi?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>?egvi?</surname></persName>
		</author>
		<idno>Available: 2010.02502</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A baseline for detecting misclassified and out-of-distribution examples in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep anomaly detection with outlier exposure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Flow++: Improving flow-based generative models with variational dequantization and architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Axial attention in multidimensional transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.12180</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Emerging convolutions for generative normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V D</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Integer discrete flows and lossless compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="12" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The convolution exponential and generalized sylvester flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Satorras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Data discovery and anomaly detection using atypicality: Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>H?st-Madsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sabeti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Walton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="5302" to="5322" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Augmented normalizing flows: Bridging the gap between generative flows and latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.07101</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Accelerating continuous normalizing flow with trajectory polynomial regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Yeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1530" to="1538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Distribution augmentation for generative modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10" to="563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Invertible convolutional flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duckworth</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/b1f62fa99de9f27a048344d55c5ef7a6-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="5635" to="5645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Msg-gan: Multi-scale gradients for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karnewar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7799" to="7808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learned Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Analyzing and improving the image quality of stylegan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8110" to="8119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning differential equations that are easy to solve</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Improving variational inference with inverse autoregressive flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno>arxiv:1606.04934</idno>
		<ptr target="http://arxiv.org/abs/1606.04934" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Glow: Generative flow with invertible 1x1 convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="215" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Why normalizing flows fail to detect out-of-distribution data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kirichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Normalizing flows: An introduction and review of current methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kobyzev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brubaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="https://www.cs.toronto.edu/~kriz/cifar.html" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A simple unified framework for detecting out-of-distribution samples and adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7167" to="7177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Nanoflow: Scalable normalizing flows with sublinear parameter complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Enhancing the reliability of out-of-distribution image detection in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Pacgan: The power of two samples in generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khetan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1498" to="1507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scale-space for discrete signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lindeberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="234" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Woodbury transformations for deep generative flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5893" to="5902" />
		</imprint>
	</monogr>
	<note>Macow: Masked convolutional generative flow</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A theory for multiresolution signal decomposition: the wavelet representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="674" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">A wavelet tour of signal processing: the sparse way</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Peyr?</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Vision: A computational investigation into the human representation and processing of visual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Generating high fidelity images with subscale pixel networks and multidimensional upscaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Do deep generative models know what they don&apos;t know</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matsukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gorur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Detecting out-of-distribution inputs to deep generative models using a test for typicality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matsukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02994</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Closing the dequantization gap: Pixelcnn as a single-layer flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Ot-flow: Fast and accurate continuous normalizing flows via optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Onken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruthotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Pixel recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Normalizing flows for probabilistic modeling and inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.02762</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Image transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Generating diverse high-fidelity images with vq-vae-2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14" to="866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Parallel multiscale autoregressive density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Belov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N. De</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Data discovery and anomaly detection using atypicality for real-valued data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sabeti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>H?st-Madsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">219</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Input complexity and out-ofdistribution detection with likelihood-based generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Serr?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>?lvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>G?mez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Slizovskaia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>N??ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Singan: Learning a generative model from a single natural image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Michaeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4570" to="4580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Flif: Free lossless image format based on maniac compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sneyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="66" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Mintnet: Building invertible neural networks with masked convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A family of nonparametric density estimation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Tabak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="164" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A note on the evaluation of generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Nvae: A deep hierarchical variational autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Conditional image generation with pixelcnn decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4790" to="4798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">On a discrete maximum principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Varga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Numerical Analysis</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="355" to="359" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Scale-space filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Witkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Readings in Computer Vision</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="329" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Generative flows with matrix exponential</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">On robustness of neural ordinary differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">Y F</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Wavelet flow: Fast training of high resolution normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brubaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
