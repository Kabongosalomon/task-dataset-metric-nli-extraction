<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Faster AutoAugment: Learning Augmentation Strategies using Backpropagation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichiro</forename><surname>Hataya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Information Science and Technology</orgName>
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">RIKEN Center for Advanced Intelligence Project</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Zdenek</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Information Science and Technology</orgName>
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuki</forename><surname>Yoshizoe</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">RIKEN Center for Advanced Intelligence Project</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Nakayama</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Information Science and Technology</orgName>
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Faster AutoAugment: Learning Augmentation Strategies using Backpropagation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data augmentation methods are indispensable heuristics to boost the performance of deep neural networks, especially in image recognition tasks. Recently, several studies have shown that augmentation strategies found by search algorithms outperform hand-made strategies. Such methods employ black-box search algorithms over image transformations with continuous or discrete parameters and require a long time to obtain better strategies. In this paper, we propose a differentiable policy search pipeline for data augmentation, which is much faster than previous methods. We introduce approximate gradients for several transformation operations with discrete parameters as well as the differentiable mechanism for selecting operations. As the objective of training, we minimize the distance between the distributions of augmented data and the original data, which can be differentiated. We show that our method, Faster AutoAugment, achieves significantly faster searching than prior work without a performance drop.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Data augmentation is a powerful technique for machine learning to virtually increase the amount and diversity of data, which improves the performance especially in image recognition tasks. Conventional data augmentation methods include geometric transformations such as rotation and color enhancing such as auto-contrast. Similarly to other hyper-parameters, the designers of data augmentation strategies usually select transformation operations based on their prior knowledge (e.g., required invariance). For example, horizontal flipping is expected to be effective for general object recognition but probably not for digit recognition. In addition to the selection, the designers need to combine several operations and set their magnitudes (e.g., degree of rotation). Therefore, designing of data augmentation strategies is a complex combinatorial problem.</p><p>When designing data augmentation strategies in a datadriven manner, one can regard the problem as searching for  Overview of our proposed model. We propose to use a differentiable data augmentation pipeline to achieve faster policy search by using adversarial learning. <ref type="bibr">Dataset</ref> AA PBA Fast AA Faster AA (ours) CIFAR-10 5,000 5.0 3.5 0.23 SVHN 1,000 1.0 1.5 0.061 ImageNet 15,000 -450 2.3 <ref type="table">Table 1</ref>. Faster AutoAugment is faster than others, without a significant performance drop (see <ref type="bibr">section 5)</ref>. GPU hours comparison of Faster AutoAugment (Faster AA), AutoAugment (AA) <ref type="bibr" target="#b4">[5]</ref>, PBA <ref type="bibr" target="#b11">[12]</ref> and Fast AutoAugment (Fast AA) <ref type="bibr" target="#b17">[18]</ref>.</p><p>optimal hyper-parameters in a search space, which becomes prohibitively large as the combinations get complex. Therefore, efficient methods are required to find optimal strategies. If gradient information of these hyper-parameters is available, they can be efficiently optimized by gradient descent <ref type="bibr" target="#b19">[20]</ref>. However, the gradient information is usually difficult to obtain because some magnitude parameters are discrete, and the selection process of operations is nondifferentiable. Therefore, previous research to automati-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original images</head><p>Augmented images <ref type="figure" target="#fig_7">Figure 2</ref>. We regard data augmentation as a process that fills missing data points of the original training data; therefore, our objective is to minimize the distance between the distributions of augmented data and the original data using adversarial learning.</p><p>cally design data augmentation policies has used black-box optimization methods that require no gradient information.</p><p>For example, AutoAugment <ref type="bibr" target="#b4">[5]</ref> used reinforcement learning.</p><p>In this paper, we propose to solve the problem by approximating gradient information and thus enabling gradientbased optimization for data augmentation policies. To this end, we approximate the gradients of discrete image operations using straight-through estimator <ref type="bibr" target="#b2">[3]</ref> and make the selection process of operations differentiable by incorporating a recent differentiable neural architecture search method <ref type="bibr" target="#b18">[19]</ref>. As the objective, we minimize the distance between the distributions of the original images and augmented images, because we want the data augmentation pipeline to transform images so that it fills missing points in the training data <ref type="bibr" target="#b17">[18]</ref> (see <ref type="figure" target="#fig_7">Figure 2</ref>). To make the transformed images match the distribution of original images, we use adversarial learning (see <ref type="figure" target="#fig_1">Figure 1</ref>). As a result, the searching process becomes end-to-end differentiable and significantly faster than prior work such as AutoAugment, PBA and Fast AutoAugment (see <ref type="table">Table 1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">).</head><p>We empirically show that our method, which we call Faster AutoAugment, enables much faster policy search while achieving comparable performance with that of prior work on standard benchmarks: CIFAR-10, CIFAR-100 <ref type="bibr" target="#b15">[16]</ref>, SVHN <ref type="bibr" target="#b20">[21]</ref> and ImageNet <ref type="bibr" target="#b25">[26]</ref>.</p><p>In summary, our contributions are following three points:</p><p>1. We introduce gradient approximations for several nondifferentiable data augmentation operations.</p><p>2. We make the searching of data augmentation policies end-to-end differentiable by gradient approximations, differentiable selection of operations and a differentiable objective that measures the distance between the original and augmented image distributions.</p><p>3. We show that our proposed method, Faster AutoAugment, significantly reduces the searching time compared to prior methods without a performance drop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Neural Architecture Search Neural Architecture Search (NAS) aims to automatically design architectures of neural networks to achieve higher performance than manually designed ones. To this end, NAS algorithms are required to select better combinations of components (e.g., convolution with a 3x3 kernel) from discrete search spaces using searching algorithms such as reinforcement learning <ref type="bibr" target="#b37">[38]</ref> and evolution strategy <ref type="bibr" target="#b23">[24]</ref>. Recently, DARTS <ref type="bibr" target="#b18">[19]</ref> achieved faster search by relaxing the discrete search space to a continuous one which allowed them to use gradient-based optimization. While AutoAugment <ref type="bibr" target="#b4">[5]</ref> was inspired by <ref type="bibr" target="#b37">[38]</ref>, our method is influenced by DARTS <ref type="bibr" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Augmentation</head><p>Data augmentation methods improve the performance of learnable models by increasing the virtual size and diversity of training data without collecting additional data samples. Traditionally, geometric transformations and color enhancing transformations have been used in image recognition tasks. For example, <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b10">11]</ref> randomly apply horizontal flipping and cropping as well as alternation of image hues. In recent years, other image manipulation methods have been shown to be effective. <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b5">6]</ref> cut out a random patch from the image and replace it with random noise or a constant value. Another strategy is to mix multiple images of different classes either by convex combinations <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b28">29]</ref> or by creating a patchwork from them <ref type="bibr" target="#b33">[34]</ref>. In these studies, the selection of operations, their magnitudes and the probabilities to be applied are carefully hand-designed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automating Data Augmentation</head><p>Similar to NAS, it is a natural direction to aim to automate data augmentation. One direction is to search for better combinations of symbolic operations using black-box optimization techniques: reinforcement learning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b22">23]</ref>, evolution strategy <ref type="bibr" target="#b31">[32]</ref>, Bayesian optimization <ref type="bibr" target="#b17">[18]</ref> and Population Based Training <ref type="bibr" target="#b11">[12]</ref>. As the objective, <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b11">12]</ref> directly aim to minimize error rate, or equivalently to maximize accuracy, while <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b17">18]</ref> try to match the densities of augmented and original images.</p><p>Another direction is to use generative adversarial networks (GANs) <ref type="bibr" target="#b8">[9]</ref>. <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b0">1]</ref>   erate images that promote the performance of image classifiers. <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref> use GANs to modify the outputs of simulators to look like real objects.</p><p>Automating data augmentation can also be applied to representation learning such as semi-supervised learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b32">33]</ref> and domain generalization <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries</head><p>In this section, we describe the common basis of Au-toAugment <ref type="bibr" target="#b4">[5]</ref>, PBA <ref type="bibr" target="#b11">[12]</ref> and Fast AutoAugment <ref type="bibr" target="#b17">[18]</ref> (see also <ref type="figure" target="#fig_3">Figure 3</ref>). Faster AutoAugment also follows this problem setting.</p><p>In these works, input images are augmented by a policy which consists of L different sub-policies S (l) (l = 1, 2, . . . , L). A randomly selected sub-policy transforms each image X. A single sub-policy consists of K consecutive image processing operations O</p><formula xml:id="formula_0">(l) 1 , . . . , O (l)</formula><p>K which are applied to the image one by one. We refer to the number of consecutive operations K as operation count. In the rest of this paper, we focus on sub-policies; therefore, we omit the superscripts l.</p><p>Each method first searches for better policies. After the searching phase, the obtained policy is used as a data augmentation pipeline to train neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Operation</head><p>Magnitude ?  <ref type="table">Table 2</ref>. Operations used in AutoAugment, PBA, Fast AutoAugment and Faster AutoAugment. Some operations have discrete magnitude parameters ?, while others have no or continuous magnitude parameters. Different from previous works, we approximate gradients of operations w.r.t. discrete magnitude ?, which we describe in section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Operations</head><p>Operations used in each sub-policy include affine transformations such as shear x and color enhancing operations such as solarize. In addition, we use cutout <ref type="bibr" target="#b5">[6]</ref> and sample pairing <ref type="bibr" target="#b12">[13]</ref> following <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18]</ref>. We show all 16 operations used in these works in <ref type="table">Table 2</ref>.</p><p>We denote the set of operations as O = {shear x, solarize, . . .}.</p><p>Some operations have magnitude parameters that are free variables, e.g., the angle in rotate. On the other hand, some operations, such as invert, have no magnitude parameter. For simplicity, we use the following expressions as if every operation had its magnitude parameter </p><formula xml:id="formula_1">? O (? [0, 1]). Each operation is applied with probability of p O (? [0, 1]). Therefore, each image X is augmented as X ? O(X; ? O ) (with probability of p O ) X (with probability of 1 ? p O ).<label>(1)</label></formula><formula xml:id="formula_2">S(X; ? S , p S ) = (O K ? ? ? ? ? O 1 )(X; ? S , p S ),<label>(2)</label></formula><p>where ? S = (? O1 , . . . , ? O K ) and p S = (p O1 , . . . , p O K ).</p><p>In the rest of this paper, we represent an image operation O, O(?; ?) and O(?; ?, p) interchangeably according to the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Search Space</head><p>The goal of searching is to find the best operation combination O 1 , . . . , O K and parameter sets (? S , p S ) for L sub-policies. Therefore, the size of the total search space is roughly (#O ? [0, 1] ? [0, 1]) KL . Using multiple subpolicies results in a prohibitively large search space for brute-force searching. <ref type="bibr" target="#b17">[18]</ref> uses Bayesian optimization in this search space. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12]</ref> discretize the continuous part [0, 1] into 10 or 11 values and search the space using reinforcement learning and population based training. Nevertheless, the problem is still difficult to solve naively even after discretizing the search space. For instance, if the number of sub-policies L is 10 with K = 2 consecutive operations, the discretized space size becomes (16 ? 10 ? 11) 2?10 ? 8.1 ? 10 64 .</p><p>Previous methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18]</ref> use black-box optimization. Therefore, they need to train CNNs with candidate policies and obtain their validation accuracy. The repetition of this process requires a lot of time. In contrast, Faster Au-toAugment achieves faster searching with gradient-based optimization to avoid repetitive evaluations, even though the search space is the same as in Fast AutoAugment. We describe the details in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Faster AutoAugment</head><p>Faster AutoAugment explores the search space to find better policies in a gradient-based manner, which distinguishes our method. In section 4.1, we describe the details of gradient approximation for policy searching. To accomplish gradient-based training, we adopt distance minimization between the distributions of the augmented and the original images as the learning objective, which we present in section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Differentiable Data Augmentation Pipeline</head><p>Previous searching methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18]</ref> have used image processing libraries (e.g., Pillow) which do not support backpropagation through the operations in <ref type="table">Table 2</ref>. Contrary to previous work, we modify these operations to be differentiable -each of which can be differentiated with respect to the probability p and the magnitude ?. Thanks to this modification, the searching problem becomes an optimization problem. The sequence of operations in each subpolicy also needs to be optimized in the same fashion.</p><p>On the probability parameter p First, we regard equation 1 as</p><formula xml:id="formula_3">bO(X; ?) + (1 ? b)X,<label>(3)</label></formula><p>where b ? {0, 1} is sampled from Bernoulli distribution Bern(b; p), i.e. b = 1 with probability of p. Since this distribution is non-differentiable, we instead use Relaxed Bernoulli distribution <ref type="bibr" target="#b13">[14]</ref> ReBern</p><formula xml:id="formula_4">(b; p, ?) = ?( 1 ? {log p 1 ? p + log u 1 ? u }). (4) Here, ?(x) = 1 1 + exp(?x)</formula><p>is a sigmoid function that keeps the range of function in (0, 1) and u is a value sampled from a uniform distribution on In such cases, gradients w.r.t. ? cannot backpropagate through these operations. Thus, we approximate their gradient in a similar manner to the straight-through estimator <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b30">31]</ref>. More precisely, we approximate the (i, j)th element of an augmented image by an operator O as</p><formula xml:id="formula_5">O(X; ?) i,j = StopGrad(O(X; ?) i,j ? ?) + ?,<label>(5)</label></formula><p>where StopGrad is a stop gradient operation which treats its operand as a constant. During the forward computation, the augmentation is exactly operated:?(X; ?) i,j = O(X; ?) i,j . However, during the backward computation, the first term of the right-hand side of equation 5 is ignored because it is constant, and then we obtain an approximated gradient:</p><formula xml:id="formula_6">?O(X) i,j ?? ? ??(X) i,j ?? = 1.<label>(6)</label></formula><p>Despite its simplicity, we find that this method works well in our experiments. Using this approximation, each operation O(?; ? O , p O ) can be differentiable w.r.t. its magnitude parameter ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Searching for operations in sub-policies</head><p>Each sub-policy S consists of K operations. To select the appropriate operation O k where k ? {1, 2, . . . , K}, we use a strategy similar to the one used in neural architecture search <ref type="bibr" target="#b18">[19]</ref> (see also Algorithm 1 and <ref type="figure" target="#fig_5">Figure 4</ref> for details).  To be specific, we approximate the output of a single selected kth operation O k (X) by weighted sum of the outputs of all operations as</p><formula xml:id="formula_7">#O n [? ? (w k )] n O (n) k (X; ? (n) k , p (n) k ),<label>(7)</label></formula><p>where, O </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Data Augmentation as Density Matching</head><p>Using the techniques described above, we can backpropagate through the data augmentation process. In this section, we describe the objective of policy learning.</p><p>One possible candidate for the objective is the minimization of the validation loss as in DARTS <ref type="bibr" target="#b18">[19]</ref>. However, this bi-level formulation takes a lot of time and costs a large memory footprint <ref type="bibr" target="#b6">[7]</ref>. To avoid this problem, we adopt a different approach.</p><p>Algorithm 1 Selection of operations in a single sub-policy during searching. Refer to <ref type="figure" target="#fig_5">Figure 4</ref> for the K = 2 case. X: input image, {w 1 , . . . , w K }: learnable weights, ? ? : softmax function with temperature ? for k in {1, 2, . . . , K} : Augment X by the kth stage operations:</p><formula xml:id="formula_8">X ? #O n=1 [? ? (w k )] n O (n) k (X; ? (n) k , p (n) k ) return X</formula><p>Data augmentation can be seen as a process that fills missing data points in training data <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b29">30]</ref>. Therefore, we minimize the distance between distributions of the original images and the augmented images. This goal can be achieved by minimizing the Wasserstein distance between these distributions d ? using Wasserstein GAN <ref type="bibr" target="#b1">[2]</ref> with gradient penalty <ref type="bibr" target="#b9">[10]</ref>. Here, ? is the parameters of its critic, or almost equivalently, discriminator. Unlike usual GANs for image modification, our model does not have a typical generator that learns to transform images using conventional neural network layers. Instead, a policy -explained in previous sections -is trained, and it transforms images using predefined operations. Following prior work <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18]</ref>, we use WideResNet-40-2 <ref type="bibr" target="#b34">[35]</ref> (for CIFAR-10, CIFAR-100 and SVHN) or ResNet-50 <ref type="bibr" target="#b10">[11]</ref> (for ImageNet) and replace their classifier heads with a two-layer perceptron that serves as a critic. Besides, we add a classification loss to prevent images of a certain class to be transformed into images of another class (see Algorithm 2). Update parameters M , P , W , ? to minimize d + l using stochastic gradient descent (e.g., Adam)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments and Results</head><p>In this section, we show the empirical results of our approach on CIFAR-10, CIFAR-100 <ref type="bibr" target="#b15">[16]</ref>, SVHN <ref type="bibr" target="#b20">[21]</ref> and ImageNet <ref type="bibr" target="#b25">[26]</ref> datasets and compare the results with Au-toAugment <ref type="bibr" target="#b4">[5]</ref>, PBA <ref type="bibr" target="#b11">[12]</ref> and Fast AutoAugment <ref type="bibr" target="#b17">[18]</ref>. Except for ImageNet, we run all experiments three times and report the average results. The details of datasets are presented in <ref type="table">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Implementation Details</head><p>Prior methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18]</ref> employed Python's Pillow 2 as the image processing library. We transplanted the operations described in section 3.1 to PyTorch <ref type="bibr" target="#b21">[22]</ref>, a tensor computation library with automatic differentiation. For geometric operations, we extend functions in kornia <ref type="bibr" target="#b24">[25]</ref>. For color-enhancing operations, sample pairing <ref type="bibr" target="#b12">[13]</ref> and cutout <ref type="bibr" target="#b5">[6]</ref>, we implement them using PyTorch. Operations with discrete magnitude parameters are implemented as described in section 4.1 with additional CUDA kernels.</p><p>We use CNN models and baseline preprocessing procedures available from the Fast AutoAugment's repository <ref type="bibr" target="#b2">3</ref> and follow their settings and hyper-parameters for CNN training such as the initial learning rate and learning rate scheduling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experimental Settings</head><p>To compare our results with previous studies <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b11">12]</ref>, we follow their experimental settings on each dataset. We train the policy on randomly selected subsets of each dataset presented in <ref type="table">Table 3</ref>. In the evaluation phase, we train CNN models from scratch on each dataset with learned Faster Au-toAugment policies. For SVHN, we use both training and additional datasets.</p><p>Similar to Fast AutoAugment <ref type="bibr" target="#b17">[18]</ref>, our policies are composed of 10 sub-policies each of which has operation count K = 2 as described in section 3.2. We train the policies for 20 epochs using ResNet-50 for ImageNet and WideResNet-40-2 for other datasets. In all experiments, we set temperature parameters ? and ? to 0.05. We use Adam optimizer <ref type="bibr" target="#b14">[15]</ref> with a learning rate of 1.0 ?3 , coefficients for running averages (betas) of (0, 0.999), the coefficient for the classification loss of 0.1, and the coefficient for gradient penalty of 10. Because GPUs are optimized for batched tensor computation, we apply sub-policies to chunks of images. The number of chunks determines the balance between speed and diversity. We set the chunk size to 16 for ImageNet and 8 for other datasets during searching. For evaluation, we use the chunk size of 32 for ImageNet and 16 for other datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Training set size Subset size for policy training CIFAR-10 <ref type="bibr" target="#b15">[16]</ref> 50,000 4,000 CIFAR-100 <ref type="bibr" target="#b15">[16]</ref> 50,000 4,000 SVHN <ref type="bibr" target="#b20">[21]</ref> 603,000 1,000 ImageNet <ref type="bibr" target="#b25">[26]</ref> 1,200,000 6,000 <ref type="table">Table 3</ref>. Summary of datasets used in the experiments. For the policy training on ImageNet, we use only 6000 images from the 120 selected classes following <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-10 and CIFAR-100</head><p>In <ref type="table">Table 4</ref>, we show test error rates on CIFAR-10 and CIFAR-100 with various CNN models: WideResNet-40-2, WideResNet-28-10 <ref type="bibr" target="#b34">[35]</ref>, Shake-Shake (26 2 ? {32, 96, 112}d) <ref type="bibr" target="#b7">[8]</ref>. We train WideResNets for 200 epochs and Shake-Shakes for 1,800 epochs as <ref type="bibr" target="#b4">[5]</ref> and report averaged values over three runs for Faster AutoAugment. The results of baseline and Cutout are from <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18]</ref>. Faster Au-toAugment not only shows competitive results with prior work, but this method is significantly faster to train than others (See <ref type="table">Table 1</ref>). For CIFAR-100, we report results with policies trained on reduced CIFAR-10 following <ref type="bibr" target="#b4">[5]</ref> as well as policies trained on reduced CIFAR-100. The latter results are better than the former ones, which suggests the importance of training policy on the target dataset. We also show several examples of augmented images in <ref type="figure">Figure 5</ref>. The policy seems to prefer color enhancing operations as reported in AutoAugment <ref type="bibr" target="#b4">[5]</ref>.</p><p>In <ref type="table">Table 5</ref>  <ref type="bibr" target="#b3">4</ref> , we report error rates on Reduced CIFAR-10 to show the effect of Faster AutoAugment in the lowresource scenario. In this experiment, we randomly sample 4,000 images from the training dataset. We train the policy using the subset and evaluate the policy with WideResNet-28-10 on the same subset for 200 epochs. As can be seen, Faster AutoAugment improves the performance 7.7 % over Cutout and achieves a close error rate to AutoAugment. This result implies that data augmentation can moderately unburden the difficulty of learning from small data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SVHN</head><p>In <ref type="table">Table 4</ref>, we show test error rates on SVHN with WideResNet-28-10 trained for 200 epochs. For Faster Au-toAugment, we report the average value of three runs. Faster AutoAugment achieves the error rate of 1.2%, which is 0.1% improvement over Cutout and on par with PBA. The augmented images are seen in <ref type="figure">Figure 5</ref>. Besides, we show the augmented images in <ref type="figure">Figure 5</ref> with used sub-policies, which seem to select more geometric transformations than CIFAR-10's policy as reported in AutoAugment <ref type="bibr" target="#b4">[5]</ref>.  <ref type="table">Table 4</ref>. Faster AutoAugment yields comparable performance with prior work. Test error rates on CIFAR-10, CIFAR-100 and SVHN. We report average rates over three runs. For CIFAR-100, we report results obtained with policies trained on CIFAR-10 / CIFAR-100.</p><p>Baseline Cutout <ref type="bibr" target="#b5">[6]</ref> AA <ref type="bibr" target="#b4">[5]</ref> Faster AA (ours) 24.3 22.5 14.1 14.8 <ref type="table">Table 5</ref>. Test error rates with models trained on Reduced CIFAR-10, which consists of 4,000 images randomly sampled from the training set. We show that the obtained policy by Faster AutoAugment is useful for the low-resource scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ImageNet</head><p>In <ref type="table">Table 6</ref>, we compare the top-1 and top-5 validation error rates on ImageNet with <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18]</ref>. To align our results with <ref type="bibr" target="#b4">[5]</ref>, we also train ResNet-50 for 200 epochs. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18]</ref>   <ref type="table">Table 6</ref>. Top-1/Top-5 validation error rates on ImageNet <ref type="bibr" target="#b25">[26]</ref> with ResNet-50 <ref type="bibr" target="#b10">[11]</ref>. Faster AutoAugment achieves comparable performance gain to AA and Fast AA.</p><p>6. Analysis</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Changing the Number of Sub-policies</head><p>The number of sub-policies L is arbitrary. <ref type="figure">Figure 6</ref> shows the relationship between the number of subpolicies and the final test error on CIFAR-10 dataset with WideResNet-40-2. As can be seen, the more sub-policies we have, the lower the error rate is. This phenomenon is straight-forward because the number of sub-policies determines the diversity of augmented images; however, an increase in the number of sub-policies results in exponential growth of the search space, which is prohibitive for standard searching methods. <ref type="figure">Figure 6</ref>. As the number of sub-policies grows, performance increases. The relationship between the number of sub-policies and the test error rate (CIFAR-10 with WideResNet-40-2). We plot test error rates and their standard deviations averaged over three runs. <ref type="figure">Figure 7</ref>. As the operation count grows, performance increases. The relationship between the operation count of each sub-policy and the average test error rate of three runs (CIFAR-10 with WideResNet-40-2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Changing Operation Count</head><p>The operation count K of each sub-policy is also arbitrary. Like the number of sub-policies L, the operation count of a sub-policy K also exponentially increases the search space. We change K from 1 to 4 on CIFAR-10 dataset with WideResNet-40-2. We present the resulted error rates in <ref type="figure">Figure 7</ref>. As can be seen, as the operation count in each sub-policy grows, the performance increases, i.e., the error rates decrease. Results of section 6.1 and section 6.2 show that Faster AutoAugment is scalable to a large search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Changing Data Size</head><p>In the main experiments in section 5, we use a subset of CIFAR-10 of 4,000 images for policy training. To validate the effect of this sampling, we train a policy on the full CIFAR-10 of 50,000 images as <ref type="bibr" target="#b17">[18]</ref> and evaluate the obtained policy with WideResNet-40-2. We find that the increase of data size causes a significant performance drop (from 3.7% to 4.1%) with the number of sub-policies L = 10. We hypothesize that this drop is because of lower capability of the policy when L = 10. Therefore, we train a policy with L = 80 sub-policies and randomly sample 10 sub-policies to evaluate the policy, which results in comparable error rates (3.8%). We present the results in <ref type="table">Table 7</ref>, comparing with Fast AutoAugment <ref type="bibr" target="#b17">[18]</ref>, which shows the effectiveness of using subsets for Fast AutoAugment and Faster AutoAugment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">The Effect of Policy Training</head><p>To confirm that trained policies are more effective than randomly initialized policies, we compare test error rates on CIFAR-10 with and without policy training, as performed in AutoAugment <ref type="bibr" target="#b4">[5]</ref>. Using WideResNet-28-10, trained poli-Data size Fast AA <ref type="bibr" target="#b17">[18]</ref> Faster AA (ours) 4,000 3.6 3.7 50,000 3.7 3.8 <ref type="table">Table 7</ref>. Test error rates on CIFAR-10 using policies trained on the reduced CIFAR-10 (4,000 images) and the full CIFAR-10 (50,000 images) with WideResNet-40-2.</p><p>cies achieve error rate of 2.6% while randomly initialized policies have a slightly worse error rate of 2.7% (both error rates are an average of three runs). These results imply that data augmentation policy searching is a meaningful research direction, but still has much room to improve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this paper, we have proposed Faster AutoAugment, which achieves faster policy searching for data augmentation than previous methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18]</ref>. To achieve this, we have introduced gradient approximation for several nondifferentiable image operations and made the policy searching process end-to-end differentiable. We have verified our method on several standard benchmarks and showed that Faster AutoAugment could achieve competitive performance with other methods for automatic data augmentation. Besides, our additional experiments suggest that gradientbased policy optimization can scale to more complex scenarios.</p><p>We believe that faster policy searching will be beneficial for research on representation learning such as semisupervised learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b32">33]</ref> and domain generalization <ref type="bibr" target="#b31">[32]</ref>. Additionally, learning from small data using learnable policies might be an interesting future direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Overview of our proposed model. We propose to use a differentiable data augmentation pipeline to achieve faster policy search by using adversarial learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>use conditional GANs to gen-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Schematic view of the problem setting. Each image is augmented by a sub-policy randomly selected from the policy. A single sub-policy is composed of K consecutive operations (O1, . . . , OK ), such as shear x and solarize. An operation O k operates a given image with probability p k and magnitude ? k .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Schematic view of the selection of operations in a single sub-policy when K = 2. During searching, we apply all operations to an image and take weighted sum of the results as an augmented image. The weights, w1 and w2, are also updated as other parameters. After searching, we sample operations according to the trained weights.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>n = m. w k is a learnable parameter and ? ? is a softmax function ? ? (z) = exp(z/?)j exp(z i /?)with a temperature parameter ? &gt; 0. With a low temperature ?, ? ? (w k ) becomes a onehot-like vector. During inference, we sample the kth operation according to categorical distribution Cat(? k (w k )).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Algorithm 2</head><label>2</label><figDesc>Training of Faster AutoAugment M , P , W : learnable parameters of a sub-policy d ? (?, ?): distance between two densities with learnable parameters ? f : image classifier L: cross entropy loss : coefficient of classification loss D: training set while not converge : Sample a pair of batches B, B from D Augment data A = {S(X; M , P , W ); (X, ?) ? B} Measure distance d = d ? (A, B ) Classification loss l = E (X,y)?A L(f (X), y) + E (X ,y )?B L(f (X ), y )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Rewriting this mapping as O(?; ? O , p O ), each sub-policy S consisting of operations O 1 , O 2 , . . . , O K can be written as</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>report top-1 / top-5 error rates of 23.7% / 6.9%; however, despite efforts to reproduce the results, we could not reach the same baseline performance. Faster AutoAugment achieves a 1.0% improvement over the baseline on top-1 error rate. This gain is close to that of AutoAugment and Fast AutoAugment, which verifies that Faster AutoAugment has an effect comparable to prior work on a large and complex dataset.</figDesc><table><row><cell></cell><cell cols="2">Baseline with Policy</cell><cell>Gain</cell></row><row><cell>AA [5]</cell><cell>23.7/6.9</cell><cell>22.4/6.2</cell><cell>1.3/0.7</cell></row><row><cell>Fast AA [18]</cell><cell></cell><cell>22.4/6.3</cell><cell>1.3/0.6</cell></row><row><cell cols="2">Faster AA (ours) 24.1/7.2</cell><cell>23.5/6.8</cell><cell>0.6/0.4</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that<ref type="bibr" target="#b17">[18]</ref> and we estimate the GPU hours with an NVIDIA V100 GPU while<ref type="bibr" target="#b4">[5]</ref> did with an NVIDIA P100 GPU.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://python-pillow.org/ 3 https://github.com/kakaobrain/ fast-autoaugment/tree/master/FastAutoAugment/ networks</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4"><ref type="bibr" target="#b4">[5]</ref> reports better baseline and Cutout performance than us (18.8 % and 16.5 % respectively), but we could not reproduce the results.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Data Augmentation Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gan</forename><surname>Wasserstein</surname></persName>
		</author>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>L?onard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">MixMatch: A Holistic Approach to Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">AutoAugment: Learning Augmentation Policies from Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<title level="m">Improved Regularization of Convolutional Neural Networks with Cutout. arXiv</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Shake-Shake regularization of 3-branch residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gastaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improved Training of Wasserstein GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Population Based Augmentation: Efficient Learning of Augmentation Policy Schedules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Inoue</surname></persName>
		</author>
		<title level="m">Data Augmentation by Pairing Samples for Images Classification. arXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Categorical Reparameterization with Gumbel-Softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adam: a Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning Multiple Layers of Features from Tiny Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ImageNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast AutoAugment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Gradient-based hyperparameter optimization through reversible learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
		<editor>F. Bach and D. Blei</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Reading Digits in Natural Images with Unsupervised Feature LearningNo Title</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning to compose domain-specific transformations for data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Ehrenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dunnmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>R?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Regularized Evolution for Image Classifier Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Kornia: an Open Source Differentiable Computer Vision Library for PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ponsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rublee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bradski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ImageNet Large Scale Visual Recognition Challenge. IJCV</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning from simulated and unsupervised images through adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Susskind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">RenderGAN: Generating realistic labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sixt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wild</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Landgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Frontiers Robotics AI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Between-class Learning for Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tokozume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Bayesian Data Augmentation Approach for Learning Deep Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Neural Discrete Representation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<title level="m">Unsupervised Data Augmentation. arXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Wide Residual Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">mixup: Beyond Empirical Risk Minimization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Random erasing data augmentation. arXiv</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Neural Architecture Search with Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
