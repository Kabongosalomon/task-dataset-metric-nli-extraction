<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Simple Training Strategies and Model Scaling for Object Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Du</surname></persName>
							<email>xianzhi@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
							<email>barretzoph@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Google</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waymo</forename></persName>
						</author>
						<title level="a" type="main">Simple Training Strategies and Model Scaling for Object Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T02:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The speed-accuracy Pareto curve of object detection systems have advanced through a combination of better model architectures, training and inference methods. In this paper, we methodically evaluate a variety of these techniques to understand where most of the improvements in modern detection systems come from. We benchmark these improvements on the vanilla ResNet-FPN backbone with RetinaNet and RCNN detectors. The vanilla detectors are improved by 7.7% in accuracy while being 30% faster in speed. We further provide simple scaling strategies to generate family of models that form two Pareto curves, named RetinaNet-RS and Cascade RCNN-RS. These simple rescaled detectors explore the speed-accuracy trade-off between the one-stage RetinaNet detectors and two-stage RCNN detectors. Our largest Cascade RCNN-RS models achieve 52.9% AP with a ResNet152-FPN backbone and 53.6% with a SpineNet143L backbone. Finally, we show the ResNet architecture, with three minor architectural changes, outperforms EfficientNet as the backbone for object detection and instance segmentation systems. Code and checkpoints will be released 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>State-of-the-art object detection performance on the COCO benchmark <ref type="bibr" target="#b24">[25]</ref> has been pushed from 30% AP to 58% since the development of popular object detectors <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b27">28]</ref>. In addition to pursuing high accuracies, the research community also cares about the speedaccuracy Pareto curve of object detection systems <ref type="bibr" target="#b20">[21]</ref>. The performance improvements not only come from the novel * Authors contributed equally. <ref type="bibr" target="#b0">1</ref> Code and checkpoints will be available in TensorFlow: https://github.com/tensorflow/models/tree/master/ official/vision/beta https : / / github . com / tensorflow / tpu / tree / master / models/official/detection  model architectures proposed in the literature but also from improved scaling, and modern training and inference methods <ref type="bibr" target="#b1">2</ref> . Many techniques that contribute to a large portion of performance improvements are not emphasized enough or are overlooked in the literature. Some of these details can conflate the performance of current state-of-the-art detection systems.</p><p>Our work aims to carefully study these techniques and tease apart where most of the improvements are coming from in modern detection systems. We carefully ablate the impact of the commonly used techniques in current state-of-the-art object detection and instance segmentation systems from two angles: 1) minor architectural improvements, including Squeeze-and-Excitation modules <ref type="bibr" target="#b18">[19]</ref>, activation functions <ref type="bibr" target="#b17">[18]</ref> and model stem <ref type="bibr" target="#b15">[16]</ref>; 2) training and inference methods, including stronger data augmentation, better model regularization <ref type="bibr" target="#b19">[20]</ref>, longer training schedules and float16 benchmarking.</p><p>Lastly, we propose a simple yet effective model scaling method for object detection and instance segmentation. Based on our empirical results, we find that only scaling the input image resolution and backbone depth is already quite effective. We apply this strategy to RetinaNet <ref type="bibr" target="#b23">[24]</ref> and RCNN <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b12">13]</ref> models and name them RetinaNet-RS and RCNN-RS.</p><p>We evaluate our RetinaNet-RS and Cascade RCNN-RS models on the COCO dataset <ref type="bibr" target="#b24">[25]</ref> and the Waymo Open dataset <ref type="bibr" target="#b32">[33]</ref> (WOD). Our results reveal that the above mentioned architectural changes and training/inference methods improve detection baselines by 7.7% AP while reducing inference time by 30%. By further adopting the proposed scaling strategy, we present two families of detectors. In particular, our Cascade RCNN-RS model adopting a ResNet152-FPN backbone achieves 52.9% AP on COCO at 119ms per image on a V100 GPU. Our Cascade RCNN-RS adopting a SpineNet143L backbone achieves 53.6% AP on COCO and 71.2 AP/L1 on WOD.</p><p>Our contributions are:</p><p>? We identify the key architectural changes, training methods and inference methods that significantly improve object detection and instance segmentation systems in speed and accuracy.</p><p>? We highlight the key implementation details and establish new baselines for RetinaNet and Cascade RCNN models.</p><p>? We provide two object detection model families as strong new baselines for future research, RetineNet-RS and Cascade RCNN-RS.</p><p>? We explore speed-accuracy trade-off between onestage RetinaNet and two-stage RCNN models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Modified ResNet Backbone</head><p>We modify the standard ResNet <ref type="bibr" target="#b13">[14]</ref> architecture in three ways to improve its performance with small computational costs. Bello et al. <ref type="bibr" target="#b0">[1]</ref> has demonstrated Squeezeand-Excitation module <ref type="bibr" target="#b18">[19]</ref> and ResNet-D stem <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b14">15]</ref> are both effective for classification model. Recent detection systems, e.g., <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b1">2]</ref>, show the above two changes and a non-linear activation function like Sigmoid Linear Unit activation are effective on improving detection performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Squeeze-and-Excitation:</head><p>We apply the Squeeze-and-Excitation module to all all residual blocks in the ResNet architecture. Following <ref type="bibr" target="#b18">[19]</ref>, one attention module is placed  after the final 1?1 convolutional layer, but before merging the residual with the shortcut connection. A squeeze ratio of 0.25 is used for all experiments.</p><p>ResNet-D stem: We follow <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b14">15]</ref> and modify the original ResNet stem to the ResNet-D stem. In summary, we replace the first 7 ? 7 convolutional layer at feature dimension 64 with three 3 ? 3 convolutional layers at feature dimension 32, 32, 64, respectively. The first 3 ? 3 convolution has a stride of 2. Batch normalization and activation layers are applied after each convolutional layer.</p><p>Sigmoid Linear Unit activation: The Sigmoid Linear Unit (SiLU) <ref type="bibr" target="#b16">[17]</ref>, computed as f (x) = x ? ?(x), has shown promising results as a replacement of the ReLU activation.</p><p>In this work, we replace all ReLU activations in the model architecture (backbone, FPN and detection heads) with the SiLU activation.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Scale Resolution Backbone</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Training and Inference Methods</head><p>Strong data augmentation: We apply horizontal flipping and image scale jittering with a random scale between [0.1, 2.0] is used as our main data augmentation strategy. The same scale jittering strategy is used and studied in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b8">9]</ref>. For example, if the output image size is 640 ? 640, we first resize the image to randomly between 64 ? 64 and 1280 ? 1280 and then pad or crop the resized image to 640 ? 640.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strong regularization:</head><p>We apply 4e-5 weight decay and stochastic depth <ref type="bibr" target="#b19">[20]</ref> with 0.2 initial drop rate for model regularization. We set the drop rate for a network block based on its depth in the network. The final drop rate of one block is calculated by multiplying the initial drop rate with the block order divided by the total number of blocks.</p><p>Longer training schedule: The strong data augmentation and regularization methods are combined with a longer training schedule to fully train a model to convergence. On different datasets, we keep increasing the training epochs until we find the best schedule.</p><p>Inference methods: For inference we use the same square image size as training. We resize the longer side of an image to the target size and pad zeros to keep aspect ratio. We measure inference speed on a Tesla V100 GPU with batch size 1 under settings that only includes the model forward pass time and forward pass plus post-processing (e.g., non-maximum suppression) time. We report both latency measured with float16 precision and float32 precision. Further inference time speedup can be achieved by TensorRT optimization, which is not used in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Model Scaling Method</head><p>We present a simple yet effective scaling method for the one-stage RetinaNet detectors and the two-satge RCNN detectors. The compounding scaling rule in Efficient-Det <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref> scales up input resolution together with model depth and feature dimensions for all model components including the backbone, FPN and detection heads. We find that only scaling up the model in input resolution and backbone depth is quite effective for most stages of the speedaccuracy Pareto curve, while being significantly simpler. We empirically control the image resolution and backbone model, then perform a grid search as shown in <ref type="table" target="#tab_0">Table 1</ref> to determine the Pareto curve.</p><p>For RetinaNet, we scale up input resolution from 512 to 768 and the ResNet backbone depth from 50 to 152. As RetinaNet performs dense one-stage object detection, we find scaling up input resolution leads to large resolution feature maps hence more anchors to process. This results in a higher capacity dense prediction heads and expensive NMS. We stop at input resolution 768 ? 768 for RetinaNet. The scaling method is presented in <ref type="table" target="#tab_2">Table 2</ref>. We name the rescaled RetinaNet models RetinaNet-RS.</p><p>Scaling up input resolution for RCNN models is more effective than one-stage detectors. RCNN uses a two-stage object detection mechanism. The first region proposal stage is typically lightweight and class-agnostic, thus the input resolution does not place too much overhead at the first stage. The second stage always processes a fixed number of proposals generated from the first stage. We design the scaling method to scale up input resolution from 512 to 1280 and the ResNet backbone depth from 50 to 200. The scaling method for RCNN models is presented in <ref type="table" target="#tab_3">Table 3</ref> and the re-scaled model family is named as RCNN-RS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Detection Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">RetinaNet-RS</head><p>Detection head: We follow the standard RetinaNet <ref type="bibr" target="#b23">[24]</ref> head design. In brief, we use 4 3 ? 3 convolutional layers at feature dimension 256 in the box and classification subnets before the final prediction layers. Each convolutional layer is followed by a batch norm layer and a SiLU activation. The convolutional layers are shared across all feature levels in the detection head while the batch norm layers are not shared. We place 3 anchors at aspect ratios [1.0, 2.0, 0.5] at each pixel location and set the base anchor size to 3.0. The focal loss parameters ? and ? are set to 0.25 and 1.5, respectively.</p><p>Feature extractor: RetinaNet-RS uses the backbone, e.g., modified ResNet-50/101/152 described in Section 2.1.  . We report end-to-end latency including post-processing (e.g. NMS) on a Tesla V100 GPU with float16 precision (FP16) and float32 precision (FP32). FP16 ? represents model latency in float16 without measuring post-processinig ops (NMS).</p><p>A standard FPN <ref type="bibr" target="#b22">[23]</ref> at feature dimension 256 is applied after the backbone to extract multi-scale features from level P 3 to P 7 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Cascade RCNN-RS</head><p>We use Cascade RCNN, one of the strongest RCNN detectors, as our two-stage detection framework in this work.</p><p>RPN head: For our Cascade RCNN-RS experiments we generally follow the implementation from <ref type="bibr" target="#b2">[3]</ref>. For the RPN head, we use two 3?3 convolutional layers at feature dimension 256 and the same anchor settings as RetinaNet mentioned in Section 2.4.1. We use 500 proposals for training and 1000 proposals for inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Box regression head:</head><p>We use two settings for the box regression heads, one for regular-size models and one for large-size models. For regular-size models, we implement two cascaded heads with increasing IoU thresholds 0.6 and 0.7. Each head has 4 3?3 convolutional layers at feature dimensions 256 and one fully connected layer at feature dimension 1024 before the final prediction layer. We importantly note for getting good performance improvements class agnostic bounding box regression must be used. This is where for the box regression heads only 4 bounding box coordinates are predicted instead of 4?(number of classes).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instance segmentation head:</head><p>We use four 3?3 convolutional layers and one 3?3 stride-2 deconvolutional layer at feature dimension 256 before the final prediction layer in the instance segmentation head.</p><p>Feature extractor: We first study the performance of the ResNet-50/101/152/200 model family and the Efficient-Net B1 to B7 model family with the regular-size Cascade RCNN framework. To scale up ResNet based models, we use the scaling method described in <ref type="table" target="#tab_3">Table 3</ref>. To scale up EfficientNet based models, we follow the compound scaling rule introduced in <ref type="bibr" target="#b35">[36]</ref>. A standard FPN is attached to ResNet and EfficientNet backbones to extract P 3 to P 7 multi-scale features. To obtain the best performance, we adopt the SpineNet-143/143L backbones. The SpineNet-143L backbone uniformly scales up feature dimension of all convolutional layers in SpineNet-143 by 1.5?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Experimental settings COCO dataset:</head><p>We first evaluate our models on the popular COCO benchmark <ref type="bibr" target="#b24">[25]</ref>. All models are trained on the train2017 split and evaluated on the val2017 split. Besides the settings described in Section 2.2, we generally follow <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b35">36]</ref> to train models from scratch on COCO train2017 with synchronized batch normalization and SGD with a 0.9 momentum rate. Unless noted, all models are trained with a batch size of 256 for 600 epochs on TPUv3 devices <ref type="bibr" target="#b21">[22]</ref>. We apply a step-wise decay learning rate schedule with an initial learning rate 0.28 that decays to 0.1? and 0.01? at the last 25 epoch and the last 10 epoch.   A linear learning rate warm-up is applied over the first 5 epochs. Our main results for bounding box detection and instance segmentation are reported on COCO val2017.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">COCO Bounding Box Detection</head><p>Our results of RetinaNet-RS and Cascade Faster RCNN-RS (Cascade FRCNN-RS) on the COCO bounding box detection task are presented in <ref type="table" target="#tab_5">Table 4</ref> and <ref type="figure" target="#fig_1">Figure 1</ref>.</p><p>From <ref type="figure" target="#fig_1">Figure 1</ref> we can see that the new training meth-ods improve COCO AP by 4.5% with no inference cost and the architectural changes improve COCO AP by another 3.2% with insignificant computational cost. <ref type="figure" target="#fig_1">Figure 1</ref> further shows that at high-computation regime (e.g. when using large model scale and large input size), the twostage Cascade RCNN-RS models outperform the one-stage RetinaNet-RS models on the speed-accuracy pareto curve. At low-computation regime, RetinaNet-RS is more efficient than Cascade FRCNN-RS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">COCO Instance Segmentation</head><p>Cascade Mask RCNN-RS (Cascade MRCNN-RS) is used as our two-stage instance segmentation framework. We compare three backbones: ResNet-FPN, EfficeintNet-FPN and SpineNet. All models are trained and evaluated in the same codebase and benchmarked on a Tesla V100 GPU under the same settings. Results are presented in <ref type="table" target="#tab_7">Table 5</ref> and <ref type="figure" target="#fig_4">Figure 2</ref>.</p><p>Adopting the same Cascade MRCNN-RS framework and trained under the same settings, ResNet-FPN backbones are able to achieve a better speed-accuracy Pareto curve than the EfficientNet-FPN backbones at all model scales. The Cascade MRCNN-RS model adopts a ResNet200-FPN backbone at input resolution 1280 achieves 53.1% AP. By replacing the backbone with SpineNet-143L, we further improve the AP to 53.6% with a slightly faster speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Understanding Performance Improvements</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Effectiveness of Modern Techniques</head><p>We conduct ablation studies for the modern training methods and architectural modifications with a RetinaNet-RS model that adopts a ResNet50-FPN backbone at 640 input resolution. As shown in <ref type="table" target="#tab_0">Table 1</ref>, training with large scale jittering for 350 epochs improves AP by 3.5%. Stronger model regularization and a longer 600-epoch training schedule improves AP by 1.0%. The modern training methods improve AP by 4.5% without introducing any computational costs. For architectural modifications, replacing ReLU with SiLU activation improves AP by 1.0%, Plugging in Squeeze-and-Excitation modules improve AP by 1.5% and adopting the ResNet-D stem improves AP by another 0.7%. The three modifications improve AP by 3.2% while introducing insignificant computational costs. The results are also presented in <ref type="figure" target="#fig_1">Figure 1</ref>    images from float32 to float16 precision, the speed of model forward pass can be boosted to 1.5? to 1.7?. Inference latency and speed improvements of all models are presented in <ref type="figure" target="#fig_5">Figure 3</ref> and <ref type="table" target="#tab_5">Table 4</ref>, 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Latency benchmarking settings</head><p>Post-processing: Post-processing ops such as NMS takes a non-negligible portion of latency. We show the speed of our RetinaNet-RS and Cascade FRCNN-RS models with and without measuring post-processing ops in <ref type="table" target="#tab_5">Table 4</ref> and the pareto curve comparisons in <ref type="figure" target="#fig_8">Fig. 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">ResNet Depth vs Input Resolution</head><p>This section analyzes the efficiency of the proposed scaling method that scales model depth and input resolution at the same time. We present the performance of Cascade MRCNN-RS models that adopt ResNet-50/101/152/200 backbones and trained at input resolution 512, 640, 768, 896, 1024 and 1280. We show that a better scaling efficiency can be achieved when scaling model depth and input resolution together. At low input resolutions (i.e. 512 or 640), the ResNet-50 backbone is more effective than deeper ResNet variants. At slight larger input resolutions (i.e., 768 or 896), the ResNet-101 backbone is more ef-    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Impact of Non-maximum Suppression</head><p>In this paper, the detection frameworks (RetinaNet and R-CNN) employ non-maximum suppression (NMS) to remove duplicate detection. It becomes a bottleneck as we keep improving train the training technologies and model architecture. <ref type="figure" target="#fig_1">Figure 1 and 4</ref> compares the inference time with and without the NMS operation. The non-maximum suppression takes about 40% of inference time in RetinaNet and 15-30% of inference time in Cascade Faster R-CNN. A well optimized software library, e.g., TensorRT, or the detectors without NMS, e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b39">40]</ref>, can save the computation overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we dissects the performance improvements coming from minor architecture modifications and training/inference methods. We design a family of models using a simple scaling strategy that only changes the backbone capacity and image resolution. We find the speed-accuracy Pareto curve is already a strong baseline to recent object detection systems. We hope this study will help the research community understand the bottleneck and performance improvements of modern object detection systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Waymo Open Dataset</head><p>Experment setup: We conduct experiments on the Waymo Open Dataset <ref type="bibr" target="#b31">[32]</ref>, which is a large-scale dataset for autonomous driving. The dataset comprises 798 training sequences and 202 validation sequences. Each sequence spans 20 seconds and is densely labeled at 10 frames per second with camera object detection and tracks. We evaluate our models on the 2D Detection Task.</p><p>We train all models on the train set and report the metrics on the test set. The models are pre-trained on the JFT and COCO datasets and finetuned on the Waymo Open Dataset for 6 epochs with using a cosine decay learning rate with an initial learning rate of 0.08. All other hyperparameters are the same as the models trained on the COCO dataset.</p><p>Results: We evaluate our improved baselines with SpineNet143L as the backbone on the Waymo Open Dataset (WOD) 2D detection task <ref type="bibr" target="#b31">[32]</ref>. Compared to the COCO dataset, WOD includes more small objects with heavy occlusions in the urban driving scene. We show the results in <ref type="table" target="#tab_12">Table 8</ref>. FRCNN performs better than RetinaNet with 3.6% AP/L1 and 3.9% AP/L2 difference. The reason might be that there are many frames with little or no instance, and single stage detectors could suffer more from the data imbalance even with the help of the focal loss. To obtain the best performance, we adopt Cascade FRCNN and apply 7  convolutional layers instead of 4 in each head and attach one more cascaded head with an IoU threshold 0.8. The performance is improved with 0.5%-1.2% AP on different resolutions compared to the 2-stage FRCNN. This demonstrates that the improved baselines could also generalize to data of different domains (e.g. self-driving cars).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Performance comparisons of Vanilla RetinaNet, RetinaNet-RS and Cascade FRCNN-RS on COCO Object Detection. Latencies are measured in float16. Experimental details are in Section 3.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Performance comparison of Cascade MRCNN-RS models adopting ResNet-FPN, EfficientNet-FPN and SpineNet backbones. Results for all models are generated under the same settings described in Section 3.3. We show ResNet-FPN and SpineNet backbones outperform EfficientNet-FPN backbones at all model scales. Pareto Curve Cascade FRCNN-RS (FP16) Cascade FRCNN-RS (FP32) RetinaNet-RS (FP16) RetinaNet-RS (FP32)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Speed improvements with float16 precision. Inference with float16 leads to a 1.5? to 1.7? speed boost for RetinaNet-RS and Cascade FRCNN-RS models. Latency numbers are reported on a V100 GPU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Pareto Curve Cascade FRCNN-RS (w/ NMS) Cascade FRCNN-RS (w/o NMS) RetinaNet-RS (w/ NMS) RetinaNet-RS (w/o NMS)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 :</head><label>4</label><figDesc>Speed comparisons with or without measuring postprocessing ops for RetinaNet-RS and Cascade FRCNN-RS. Latency numbers are reported on a V100 GPU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Ablation</figDesc><table><row><cell>study of the modern techniques discussed in</cell></row><row><cell>this paper. Results are reported using a RetinaNet detector with</cell></row><row><cell>a ResNet-50 backbone at 640 ? 640 input resolution on COCO</cell></row><row><cell>val2017. SJ: scale jittering. SD: stochastic depth. SE: Squeeze-</cell></row><row><cell>and-Excitation. ResNet-D: ResNet-D style stem. We show that</cell></row><row><cell>there is a 7.7% AP improvement by adopting all the techniques</cell></row><row><cell>while reducing inference latency by 30%.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>RetinaNet-RS scaling method. A simple scaling method to scale up RetinaNet detection systems by changing only the input resolution and ResNet backbone depth.</figDesc><table><row><cell cols="2">Model Scale Resolution</cell><cell>Backbone</cell></row><row><cell>Scale 1</cell><cell>512 ? 512</cell><cell>ResNet-50</cell></row><row><cell>Scale 2</cell><cell>640 ? 640</cell><cell>ResNet-50</cell></row><row><cell>Scale 3</cell><cell>768 ? 768</cell><cell>ResNet-50</cell></row><row><cell>Scale 4</cell><cell cols="2">768 ? 768 ResNet-101</cell></row><row><cell>Scale 5</cell><cell cols="2">896 ? 896 ResNet-101</cell></row><row><cell>Scale 6</cell><cell cols="2">896 ? 896 ResNet-152</cell></row><row><cell>Scale 7</cell><cell cols="2">1024 ? 1024 ResNet-152</cell></row><row><cell>Scale 8</cell><cell cols="2">1280 ? 1280 ResNet-152</cell></row><row><cell>Scale 9</cell><cell cols="2">1280 ? 1280 ResNet-200</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>RCNN-RS scaling method.</figDesc><table><row><cell>A simple scaling method to</cell></row><row><cell>scale up RCNN models by changing only the input resolution and</cell></row><row><cell>ResNet backbone depth.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Result comparisons on COCO val2017 of RetinaNet-RS (first group) and Cascade FRCNN-RS (second group)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Precision float16 :</head><label>float16</label><figDesc>Inference in 16-bit floating-point types make model run faster and use less memory. This subsection compares RetinaNet-RS and Cascade FRCNN-RS models using float32 precision and float16 precision for model inference. By casting model weights and input</figDesc><table><row><cell>Backbone</cell><cell>Resolution</cell><cell cols="2">Latency (ms) FP16 FP32</cell><cell>AP</cell><cell>APS APM APL</cell></row><row><cell cols="2">EfficientNetB1-FPN 640?640</cell><cell>42</cell><cell>71</cell><cell>45.5</cell><cell>24.3 48.8 65.0</cell></row><row><cell cols="2">EfficientNetB2-FPN 768?768</cell><cell>48</cell><cell>78</cell><cell>46.9</cell><cell>26.4 49.8 66.5</cell></row><row><cell cols="2">EfficientNetB3-FPN 896?896</cell><cell>54</cell><cell>90</cell><cell>48.9</cell><cell>29.2 52.0 67.2</cell></row><row><cell cols="3">EfficientNetB4-FPN 1024?1024 67</cell><cell>109</cell><cell>50.5</cell><cell>30.5 53.1 69.2</cell></row><row><cell cols="3">EfficientNetB5-FPN 1280?1280 90</cell><cell>158</cell><cell>52.0</cell><cell>32.3 55.3 69.7</cell></row><row><cell cols="3">EfficientNetB6-FPN 1280?1280 101</cell><cell>179</cell><cell>52.5</cell><cell>33.0 55.4 69.9</cell></row><row><cell cols="3">EfficientNetB7-FPN 1536?1536 149</cell><cell>263</cell><cell>52.6</cell><cell>32.2 55.8 70.2</cell></row><row><cell>ResNet50-FPN</cell><cell>512?512</cell><cell>41</cell><cell>69</cell><cell>46.1</cell><cell>23.7 50.1 67.1</cell></row><row><cell>ResNet50-FPN</cell><cell>640?640</cell><cell>45</cell><cell>77</cell><cell>48.4</cell><cell>27.4 51.5 67.9</cell></row><row><cell>ResNet50-FPN</cell><cell>768?768</cell><cell>50</cell><cell>85</cell><cell>49.4</cell><cell>29.4 52.6 68.3</cell></row><row><cell>ResNet101-FPN</cell><cell>768?768</cell><cell>60</cell><cell>97</cell><cell>50.3</cell><cell>29.7 53.9 69.7</cell></row><row><cell>ResNet101-FPN</cell><cell>896?896</cell><cell>68</cell><cell>109</cell><cell>51.1</cell><cell>31.4 54.3 69.8</cell></row><row><cell>ResNet152-FPN</cell><cell>896?896</cell><cell>79</cell><cell>125</cell><cell>51.8</cell><cell>32.0 55.1 70.0</cell></row><row><cell>ResNet152-FPN</cell><cell cols="2">1024?1024 90</cell><cell>148</cell><cell>52.4</cell><cell>32.9 55.3 70.0</cell></row><row><cell>ResNet152-FPN</cell><cell cols="2">1280?1280 119</cell><cell>191</cell><cell>52.9</cell><cell>33.5 56.7 70.3</cell></row><row><cell>ResNet200-FPN</cell><cell cols="2">1280?1280 149</cell><cell>232</cell><cell>53.1</cell><cell>33.9 56.2 70.3</cell></row><row><cell>SpineNet143</cell><cell cols="2">1280?1280 109</cell><cell>175</cell><cell>53.0</cell><cell>33.8 55.8 70.5</cell></row><row><cell>SpineNet143L</cell><cell cols="2">1280?1280 144</cell><cell>234</cell><cell>53.6</cell><cell>34.5 56.7 70.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Result comparisons on COCO val2017 among Cascade MRCNN-RS models adopting ResNet-FPN, SpineNet and EfficientNet-FPN backbones. All results are generated in the same codebase. We report end-to-end latency including NMS on a Tesla V100 GPU with float16 precision (FP16) and float32 precision (FP32).</figDesc><table><row><cell>Backbone \Resolution</cell><cell>512</cell><cell>640</cell><cell>768</cell><cell>896</cell><cell>1024</cell><cell>1280</cell></row><row><cell>R50-FPN</cell><cell cols="6">46.1 (69) 48.4 (77) 49.4 (85) 50.0 (94) 50.2 (106) 50.8 (132)</cell></row><row><cell>R101-FPN</cell><cell cols="6">47.5 (75) 49.3 (86) 50.3 (97) 51.1 (109) 51.6 (123) 51.9 (160)</cell></row><row><cell>R152-FPN</cell><cell cols="6">47.8 (83) 49.7 (96) 50.6 (109) 51.8 (125) 52.3 (148) 52.9 (193)</cell></row><row><cell>R200-FPN</cell><cell cols="6">48.3 (92) 50.4 (109) 51.5 (127) 52.2 (148) 52.6 (174) 53.1 (232)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>ResNet depth vs input resolution. We report COCO val2017 AP of different ResNet backbones and the corresponding inference latency on V100 GPU (numbers in parentheses) with float32 precision. All models adopt the Cascade MRCNN-RS detector.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>fective. At high input resolutions (i.e., 1024 or 1280) the ResNet-152 backbone is the most effective choice. Further scaling model depth to ResNet-200 does not improve the speed-accuracy Pareto curve. The results are shown in Table 6.</figDesc><table><row><cell cols="4">Jitter Scale 90-ep 200-ep 400-ep 600-ep</cell></row><row><cell>[1.0, 1.0] 41.9</cell><cell>39.3</cell><cell>38.4</cell><cell>35.7</cell></row><row><cell>[0.8, 1.2] 43.8</cell><cell>45.0</cell><cell>44.6</cell><cell>44.3</cell></row><row><cell>[0.1, 2.0] 43.9</cell><cell>47.0</cell><cell>47.6</cell><cell>47.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Jitter scales vs training epochs. We show that model performance significantly benefits from using aggressive scale jittering with longer training schedules.4.4. Scale Jittering vs Training ScheduleApplying large scale jittering augmentation potentially results in more unique training samples during the training procedure, which allows the model to benefit from a longer training schedule. We empirically show that the best modelperformance can be achieved by enabling large scale jittering to train models for an up to 600 epoch schedule. To study the effectiveness, we compare three scale jittering setups, [0.1, 2.0], [0.8, 1.2], and [1.0. 1.0], on 90-epoch, 200epoch, 400-epoch, and 600-epoch model training schedules. The results are shown inTable 7.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>ModelTrain Resolution Eval Resolution AP/L1 AP/L2</figDesc><table><row><cell>RetinaNet-RS</cell><cell>896?1664</cell><cell>896?1664</cell><cell>64.5</cell><cell>56.1</cell></row><row><cell>FRCNN-RS</cell><cell>896?1664</cell><cell>896?1664</cell><cell>68.1</cell><cell>60.0</cell></row><row><cell>FRCNN-RS</cell><cell>896?1664</cell><cell>1024?1920</cell><cell>69.5</cell><cell>61.2</cell></row><row><cell>FRCNN-RS</cell><cell>896?1664</cell><cell>1280?2400</cell><cell>70.0</cell><cell>63.4</cell></row><row><cell>Cascade FRCNN-RS</cell><cell>896?1664</cell><cell>896?1664</cell><cell>68.6</cell><cell>60.7</cell></row><row><cell>Cascade FRCNN-RS</cell><cell>896?1664</cell><cell>1024?1920</cell><cell>70.5</cell><cell>61.8</cell></row><row><cell>Cascade FRCNN-RS</cell><cell>896?1664</cell><cell>1280?2400</cell><cell>71.2</cell><cell>62.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Results on Waymo Open Dataset. We evaluate different detectors adopting the SpineNet143L backbone.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https : / / ai . facebook . com / blog / advancingcomputer -vision -research -with -new -detectron2mask-r-cnn-baselines/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwan</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<title level="m">Jonathon Shlens, and Barret Zoph. Revisiting resnets: Improved training and scaling strategies</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Yolov4: Optimal speed and accuracy of object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Bochkovskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Yao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Yuan Mark</forename><surname>Liao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cascade r-cnn: Delving into high quality object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">End-toend object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">End-toend object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hybrid task cascade for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4969" to="4978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Efficient scale-permuted backbone with learned resource distribution. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengchong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spinenet: Learning scale-permuted backbone for recognition and localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengchong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simple copypaste is a strong data augmentation method for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<idno>abs/2012.07177</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Nas-fpn: Learning scalable feature pyramid architecture for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Piotr Doll?r, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Bag of tricks for image classification with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tong He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<idno>abs/1812.01187</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bag of tricks for image classification with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tong He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<title level="m">Gaussian error linear units (gelus). arXiv: Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Gaussian error linear units (gelus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep networks with stochastic depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sedra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Speed/accuracy trade-offs for modern convolutional object detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Korattikara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raminder</forename><surname>Bajwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Boden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al</forename><surname>Borchers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rick</forename><surname>Boyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierreluc</forename><surname>Cantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clifford</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Coriell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Daley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Dau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Gelb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><surname>Vazir Ghaemmaghami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajendra</forename><surname>Gottipati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Gulland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Hagmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">C</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Hogberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Hundt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hurt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Ibarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Jaffey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alek</forename><surname>Jaworski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harshit</forename><surname>Khaitan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveen</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Lacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Laudon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diemthu</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Lucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lundin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Mackean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Maggiore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maire</forename><surname>Mahony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kieran</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Nagarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Narayanaswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathy</forename><surname>Nix ; Vijay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doe</forename><forename type="middle">Hyun</forename><surname>Wilcox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jed Souter</title>
		<imprint/>
	</monogr>
	<note>In-datacenter performance analysis of a tensor processing unit. CoRR, abs/1704.04760, 2017. 4</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Path aggregation network for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8759" to="8768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="37" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.02767</idno>
		<title level="m">Yolov3: An incremental improvement</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Scalability in perception for autonomous driving: Waymo open dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Kretzschmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xerxes</forename><surname>Dotiwalla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Chouard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijaysai</forename><surname>Patnaik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tsui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Caine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2446" to="2454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Kretzschmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xerxes</forename><surname>Dotiwalla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Chouard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijaysai</forename><surname>Patnaik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tsui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Caine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiquan</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksei</forename><surname>Timofeev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krivokon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Jonathon Shlens, Zhifeng Chen, and Dragomir Anguelov. Scalability in perception for autonomous driving: Waymo open dataset</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
		<idno>abs/1512.00567</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Efficientdet: Scalable and efficient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Scaled-yolov4: Scaling cross stage partial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Yao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Bochkovskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Yuan Mark</forename><surname>Liao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Deep high-resolution representation learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaorui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Resnest: Splitattention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongruo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Objects as points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
