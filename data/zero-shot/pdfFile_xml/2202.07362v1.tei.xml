<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MuLD: The Multitask Long Document Benchmark</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">Thomas</forename><surname>Hudson</surname></persName>
							<email>g.t.hudson@durham.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Durham University</orgName>
								<orgName type="institution" key="instit2">Durham University</orgName>
								<address>
									<settlement>Durham</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Al Moubayed</surname></persName>
							<email>noura.al-moubayed@durham.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Durham University</orgName>
								<orgName type="institution" key="instit2">Durham University</orgName>
								<address>
									<settlement>Durham</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MuLD: The Multitask Long Document Benchmark</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Long Documents</term>
					<term>Benchmark</term>
					<term>Multitask learning</term>
					<term>NLP</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The impressive progress in NLP techniques has been driven by the development of multi-task benchmarks such as GLUE and SuperGLUE. While these benchmarks focus on tasks for one or two input sentences, there has been exciting work in designing efficient techniques for processing much longer inputs. In this paper, we present MuLD: a new long document benchmark consisting of only documents over 10,000 tokens. By modifying existing NLP tasks, we create a diverse benchmark which requires models to successfully model long-term dependencies in the text. We evaluate how existing models perform, and find that our benchmark is much more challenging than their 'short document' equivalents. Furthermore, by evaluating both regular and efficient transformers, we show that models with increased context length are better able to solve the tasks presented, suggesting that future improvements in these models are vital for solving similar long document problems. We release the data and code for baselines to encourage further research on efficient NLP models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Pretrained language models have been highly influential in Natural Language Processing (NLP), leading to state-of-the-art results across a wide range of tasks. Based on the transformer architecture, these language models have shown capable at text classification, question answering, and translation among many other NLP problems. The rise of pretrained language models in NLP has been driven by influential benchmarks such GLUE <ref type="bibr" target="#b21">(Wang et al., 2018)</ref>, and SuperGLUE <ref type="bibr" target="#b22">(Wang et al., 2019)</ref>, which combine multiple existing datasets to provide a standardised evaluation of general-purpose Natural Language Understanding (NLU) approaches. Similar benchmarks have been created to evaluate multilingual approaches <ref type="bibr" target="#b24">(Yao et al., 2021)</ref>, and other types of NLP task such as Natural Language Generation (NLG) . However, a key component of the success of the transformer model -self-attention -is also a major limitation when it comes to processing longer sequences. Comparing each token to all other tokens in the previous layer yields a O(n 2 ) complexity, limiting the ability of standard transformers only a few hundred or thousand tokens on standard hardware. With many real world tasks involving the need to process documents in the range of tens of thousands of tokens, this is an important problem to solve. Recently, approaches such as Longformer <ref type="bibr" target="#b0">(Beltagy et al., 2020)</ref>, Reformer <ref type="bibr" target="#b6">(Kitaev et al., 2020)</ref>, and Linformer  have explored techniques for improving the efficiency of transformers, allowing them to operate on much longer sequences. However, these have mainly been evaluated on artificial datasets, with limited evaluation on real-world data. There has been some work on creating long-text 0 10,000 20,000 30,000 40,000 50,000 60,000</p><p>Words per Input datasets. A notable example is NarrativeQA <ref type="bibr" target="#b7">(Ko?isk? et al., 2018)</ref> which challenges models to answer questions about the plot of entire novels and movie scripts which have an average length of around 60,000 tokens -well beyond the input size of current typical efficient transformer models. There has however been little work in developing benchmarks of this length across a wide variety of NLP tasks.</p><p>Many 'long document' benchmarks use datasets consisting of at most a few thousand tokens ( <ref type="figure" target="#fig_0">Figure 1)</ref>. Notably, the Long-Range Arena <ref type="bibr" target="#b20">(Tay et al., 2021)</ref> uses a maximum length of 8K tokens, and the QuALITY becnhmark <ref type="bibr" target="#b12">(Pang et al., 2021)</ref> uses a maximum of 6K tokens. In this paper, we argue that these lengths are more akin to short essays, and the common usage of the term 'long document' would imply documents in the tens of thousands of tokens -similar in length to novels. It is to this end that we present MuLD: The Multitask Long Document benchmark. This is a set of six long document tasks where each input is at least 10,000 tokens, spanning a range of dataset sizes, genres, and formulations designed specifically to test the ability of different approaches to model long-term dependencies in real world text. The datasets are formed by filtering, extending, or modifying existing NLP datasets. We create baseline results for both standard approaches (T5) and efficient transformer methods (Longformer), finding that Longformer's extended input context allows it to perform better. The MuLD dataset is available at www.github. com/ghomasHudson/muld.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Benchmarks The influence for many NLP benchmarks is the success of GLUE which challenged models to solve 9 language understanding tasks including question answering, coreference resolution, and sentiment analysis. The success of GLUE resulted in advancement to the point where a successor with more challenging tasks was required: SuperGLUE. This approach has been replicated both across other languages <ref type="bibr" target="#b24">(Yao et al., 2021)</ref>, as well as other task domains such as NLG .</p><p>Recently there have been some attempts to design benchmarks which test the ability of models to understand long documents. The Long Range Arena was designed as a benchmark for evaluating the performance of efficient transformers on long input sequences <ref type="bibr" target="#b20">(Tay et al., 2021)</ref>. This benchmark challenges models to perform 6 synthetic and real-world multitmodal tasks on documents with up to 16,000 tokens. Howerver, these tasks are all forms of classification, and as noted by <ref type="bibr" target="#b16">Shaham et al. (2022)</ref> one of the only two NLP tasks: LRA, uses byte tokenization as a way of artificially increasing the token count while having a much smaller number of words. <ref type="bibr" target="#b4">Guan et al. (2021)</ref> introduced a benchmark of long document Chinese tasks based on short stories. Four tasks were set including cloze tests, sentence position prediction, plot completion, and story generation. In contrast to this, we focus on English text, more conventional 'real-world' tasks, and crucially on documents with a minimum length of 10,000 tokens which we consider to be true 'long documents'.</p><p>The QuALITY benchmark <ref type="bibr" target="#b12">(Pang et al., 2021)</ref>, was designed as a multiple-choice question answering dataset which selects questions which can't be answered by briefly skimming the text. Again the maximum document length used: 6,000, is much shorter than the minimum length used in our work of 10,000 tokens. The most notable recent development is SCROLLS: Standardized CompaRison Over Long Language Sequences <ref type="bibr" target="#b16">(Shaham et al., 2022)</ref> which used 7 long document tasks to create a benchmark with a range of input lengths with the median for most tasks (excluding the very long NarrativeQA) falling between 1000 and 10,000 words -which we argue is still too short to be a reliable evaluation of the longer transformer models such as the LED Longformer variant. Additionally, unlike our benchmark which has 5 different types of task, SCROLLS focuses on question answering, summarization and NLI. This limits the type and length of the expected outputs to only short sentences or paragraphs. In contrast, MuLD explores outputs lengths from single words all the way up to outputs that are an equivalent length to the input.</p><p>Long Document Models There have been numerous attempts to improve both the memory footprint and computational cost of transformers, thus allowing the use of longer inputs. One way of tackling the high complexity of full attention is to make the attention sparse. This can be done by chunking the input sequence into fixed blocks <ref type="bibr" target="#b14">(Qiu et al., 2020)</ref>, applying strided windows to the attention matrix, or some method of learning which tokens to attend to <ref type="bibr" target="#b6">(Kitaev et al., 2020)</ref>.</p><p>Other models such as transformer-XL <ref type="bibr" target="#b2">(Dai et al., 2019)</ref> and Infty-former <ref type="bibr" target="#b11">(Martins et al., 2021)</ref> solve this problem by augmenting the model with a memory mechanism <ref type="bibr" target="#b5">(Katharopoulos et al., 2020)</ref>. A form of the kernel trick can be used as well to reduce the complexity. All these techniques are effective in optimising the memory and computation usage of transformer models, but there is little analysis of how these techniques effect the ability of models to solve a wide variety of NLP tasks, which we seek to solve. For a detailed overview of efficient transformers, see <ref type="bibr" target="#b19">Tay et al. (2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The MuLD Benchmark</head><p>The MuLD benchmark is based on six long document NLP tasks, which span a wide range of domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Desiderata</head><p>We pick these tasks based on the following principles:</p><p>(1) Long input size: While many benchmarks use 'long-text' to mean inputs of a few thousand tokens, we consider 'true' long documents to be in the tens of thousands of tokens long. This more closely matches the common usage of this term, where an essay may be a few thousand words long and considered fairly 'short', while common everyday examples of long documents such as novels and reports may be 50,000-100,000 words in length. It is for this reason that we only include documents over 10,000 tokens in our benchmark, with many documents exceeding 100,000 tokens.</p><p>(2) Variety of dependency on the input: Within long document tasks, some may require understanding more of the input than others -either analysing the whole text or just using relevant sections. For example in summarization, a model must have a holistic overview of the document, while in other tasks such as question answering, the answer can be often be given by referencing just a few sections of the document. In reality, most tasks fall sommewhere between these two extremes and we endeavour to capture a variety of input dependency in our benchmark.</p><p>(3) Variety of output length: While the input length should be long, there is a range of different possible output lengths ranging from a single word classification label, a short answer, all the way up to an output of equivalent length to the input.</p><p>(4) Existing Task Formulation We don't seek to invent new types of task, but instead use proven tasks which are already agreed as being challenging for regular 'short' transformer models. Instead, the tasks used are created by either filtering existing datasets, expanding the length of existing datasets with additional text, or replicating the methodology of existing datasets with longer source text.</p><p>(5) Easily Evaluated We pick tasks where the performance can be easily measured with multiple automatic metrics. We also acknowledge that for some tasks, the current metrics used on short documents don't fully capture the challenges that long document evaluation poses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The Tasks</head><p>The six long document tasks are described below and the summarized in <ref type="table">Table 1</ref>.</p><p>NarrativeQA The NarrativeQA Reading Comprehension Challenge Dataset <ref type="bibr" target="#b7">(Ko?isk? et al., 2018)</ref> consists of user-submitted questions regarding the plot of movies or novels. Annotators were only given access to a human-written plot summary to encourage general questions which require a full understanding of the narrative. When these are given to a question-answering system along with the full text of the narrative (either a movie script or the novel text), this is a test of reading comprehension. As each sentence the annotator read can summarise the plot of an entire chapter/scene of a book or movie, models evaluated on the full text must model the dependencies between multiple sections of the narrative. The majority of these documents are longer than our 10,00 token minimum -we simply filter out any documents shorter than this.</p><p>HotpotQA The HotpotQA dataset consists of questions from crowd workers which require information from multiple Wikipedia articles in order to answer, thus testing the ability for models to perform multihop question answering. The data is commonly presented as a list of paragraphs containing relevant information plus a setting where the addition of 'distractor paragraphs' fully test the ability of the model to comprehend which information is relevant to the question asked. To transform this into a long document, we expand each paragraph with its full Wikipedia page as well as adding additional distractor articles from similar topics (randomly chosen from links on the existing pages) in order to meet the 10,000 token minimum  length requirement for this benchmark. These articles are shuffled and concatenated to form the model input. Character Archetype Classification We introduce a character archetype classification dataset based on the methodology of <ref type="bibr" target="#b17">Skowron et al. (2016)</ref>. For this dataset, each example consists of a movie script along with a named character and the task is to classify whether the character is a Hero/Protagonist or Villain/Antagonist based on understanding their role in the narrative. To gather this data we first pick scripts from the web following <ref type="bibr" target="#b7">Ko?isk? et al. (2018)</ref> 1 , these are then matched with summaries of the plot from Wikipedia using a combination of matching names and titles with additional manual verification. We extract character name candidates using a number of methods. Firstly, many of the scripts use the common format where the character name is given before each line of dialogue (e.g. 'HARRY: Where have they gone?'). Secondly, the Wikipedia pages for many films include a list of characters that can be parsed and matched with the script. We then filter these character name candidates to only include those that also appear in the plot summary, eliminating false matches as well as some minor characters who don't impact the plot. Annotators on Amazon Turk were given a description of the task and the character types of <ref type="bibr" target="#b17">Skowron et al. (2016)</ref>. They were then provided with the plot summary and asked to select the character type for each character name candidate extracted previously. Multiple annotators were used on each example to ensure the accuracy of the labels. From this process we eliminated the character types Mentor, Sidekick, and Spouse as there was a lot of disagreement between these classes, perhaps due to our use of movies of all genres rather than the limited set of action movies used by <ref type="bibr" target="#b17">Skowron et al. (2016)</ref>. Open Subtitles The Open Subtitles corpus <ref type="bibr" target="#b9">(Lison et al., 2018</ref>) 2 consists of aligned subtitles from movies and TV shows from the website opensubtitles. org in 60 languages and can be used for machine translation. Importantly rather than individual lines, the data consists of the subtitles for an entire individual movie or tv show, many of these being very long files and we filter to remove any document with less than 10,000 tokens. One of the most common mistakes made by models which don't consider document-level context is the mistranslation of pronouns. For example, in the English phrase "It is cold.", the pronoun "it" should be translated differently depending on if the proceeding context was "The ice formed at night" or "The camera was left outside". For this reason we make use of the English-German pairs used by the ContraPro annotation of open subtitles <ref type="bibr" target="#b12">(M?ller et al., 2018)</ref> which explicitly tests a model's ability to disambiguate these possibilities. This will allow future use of this contrastive evaluation, where models are asked to pick between the two possible translations and must show knowledge of the context. AO3 style change detection Style change detection is the task of identifying the points where the author changes in a document constructed from the work of multiple authors. The PAN 2021 Style Change detection shared task <ref type="bibr" target="#b25">(Zangerle et al., 2021)</ref> introduced this task, forming documents from StackExchange comments to produce a challenging dataset with multiple increasingly difficult subtasks. Task 1 is a binary classification task to identify whether the document contains multiple authors or just a single author. Task 2 is to identify the points where the style changes, and Task 3 is to assign each paragraph uniquely to an author out of the number of authors in the document. As Task 3 is the most challenging (and answers the other two can be constructed from the output of task 3), we only report scores for it in our benchmark. To extend this approach for a long document dataset, we instead use stories contributed to the fanfiction website Archive of Our Own, which contains a large number of different works submitted by fans of popular films, tv, game, and book characters. We use stories written about four of the most popular character relationships: Sherlock Holmes &amp; John Watson, Castiel &amp; Dean Winchester, Steve Rogers &amp; Tony Stark, and Draco Malfoy &amp; Harry Potter. Since we want this task to be a test of style change detection and not topic change detection, each constructed document only contains paragraphs taken from the same relationship to ensure that the difference between sections is the author style not the topic. Additionally, we reserve the "Draco Malfoy &amp; Harry Potter" documents for the test set. After downloading, we clean the data by removing any images and special formatting characters, then split the stories into paragraphs, removing any with less than 100 characters. To construct the style change detection documents, we first randomly choose first randomly choosing a minimum document length (10,000-30,000) and a number of authors (1-4) with 50% of documents having a single author. We then assign authors to the document, randomly partition the lengths for each section, and finally draw, shuffle, and concatenate paragraphs to form the complete text. Very Long Scientific Papers (VLSP) We follow the process of the Scientific papers <ref type="bibr" target="#b1">(Cohan et al., 2018)</ref> summarization dataset, extracting papers from the open-access preprint server Arxiv.org using the both the arxiv short abstract and the one included in the thesis (where available) as the reference summaries. In contrast to <ref type="bibr" target="#b1">Cohan et al. (2018)</ref>, rather than removing very long documents, we explicitly include themremoving any document with less than 10,000 tokens. With this new filtering, the dataset mostly consists of theses which like the scientific papers dataset, have a regular structure consisting of multiple chapters. Due to the long time required to compile these large documents into text files, we only provide a small test set of 482 documents, so we train our models on the original smaller-length scientific papers dataset.</p><p>A box-plot of lengths for all six tasks is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. We can see that NarrativeQA has the longest documents, but all tasks have a median length between 10,000 and 100,000 tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Baselines</head><p>In this section we describe the models we evaluate on the MuLD benchmark. We experiment firstly with a model based on a 'standard' transformer architecture: T5, an encoder-decoder network which was pretrained on multiple text-to-text tasks and can take a maximum input length of 512 tokens <ref type="bibr" target="#b15">(Raffel et al., 2020)</ref>. We compare this to the Longformer model: an 'efficient transformer' which uses sliding window attention (with global attention on some predetermined tokens) to supports up to 4096 tokens (or 16,384 in the encoderdecoder variant) allowing us to see the benefits of using longer contexts for the benchmark <ref type="bibr" target="#b0">(Beltagy et al., 2020)</ref>. As it is not possible to directly feed the entirety of many long documents into models on reasonable hardware (even with longformer), we use chunking techniques to divide, solve, and recombine parts of the input. We use the following methods:</p><p>? NarrativeQA/HotpotQA -We follow the approach of <ref type="bibr" target="#b7">Ko?isk? et al. (2018)</ref> by first dividing the document into chunks of 200 tokens. We then calculate the cosine similarity between the TF-IDF representations of each chunk and the question text in order to score every chunk. Using this metric, we pick the top 10 chunks and concatenate them together to pass into the model along with the question input.</p><p>? Open Subtitles -For a simple baseline, we split the document into regular chunks while respecting line breaks (we never end a chunk in the middle of a line). Each chunk is then passed into the model to be translated, and all the translated chunks are concatenated together to form the translated document.   <ref type="bibr" target="#b26">Zhang et al. (2021)</ref>, by training a classifier on paragraph pairs with the target of predicting whether the two paragraphs are by the same author. For the subtask we report (task 3), we use the methodology of <ref type="bibr" target="#b18">Str?m (2021)</ref>: we assign the first paragraph to the first author, then check if the next paragraph is similar to the previous one. If so we assign this to the author of the most similar paragraph if over some threshold. If not we add a new author. Although we only report the score for task 3, this classifier could also be used to solve all the remaining two subtasks: for task 1, pass consecutive paragraph pairs into the model and output "single-author" if all paragraphs pairs are by the same author, otherwise classify the document as "multi-author". For task 2 simply append all the model outputs together to form a list of style changes.</p><p>? Character Archetype detection -We select chunks containing the first mention, last mention, and most frequent mention of the character in concern. These are concatenated, passed to the model, and used to predict the character type class.</p><p>? VLSP -We split the document into chunks based on the article section headings and summarize the text from the first introduction section of the thesis onwards (ignoring contents, list of tables, list of figures sections).</p><p>Following <ref type="bibr" target="#b7">(Ko?isk? et al., 2018)</ref>, we evaluate tasks which require text-generation (QA, Summarization, Translation) using Bleu-1, Bleu-4 <ref type="bibr" target="#b13">(Papineni et al., 2002)</ref>, Meteor <ref type="bibr" target="#b3">(Denkowski and Lavie, 2011)</ref>, and Rouge-L <ref type="bibr" target="#b8">(Lin, 2004)</ref>, using multiple references where these are available. For the style change detection and character type classification tasks, we simply report the F1-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Discussion</head><p>The results for each of the benchmark tasks are presented in <ref type="table" target="#tab_3">Table 2</ref> for both the T5 and Longformer models. The Longformer model consistently outperforms the T5 model across many of the tasks, suggesting that models which are able to make use of a longer context perform well on our benchmark. Both models find the NarrativeQA dataset more challenging than HotpotQA, which we hypothesise is due to its longer average length, and the higher complexity of narrative understanding involved in NarrativeQA in contrast to the factual Wikipedia data of HotpotQA which typically involves only a limited number of hops. Additionally, each HotpotQA question commonly involves understanding only a small number of sentences (even though these may be widely distributed throughout the document). The T5 model also outperforms Longformer on the OpenSubtitles translation task. We suggest that this is due to the challenge of having to output a much longer sequence (512 vs 4096) tokens is greater than the benefit gained on the few lines where the correct translation depends on context more than 512 tokens away <ref type="bibr" target="#b12">(M?ller et al. (2018)</ref> find that in around half of cases, the antecedent is in the previous sentence, and very few are more than 3 sentences away).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>To enable the evaluation of long document models, we introduce MuLD: a benchmark of varied NLP tasks where each document consists of more than 10,000 tokens. The six tasks in our benchmark are created by filtering, extending, or modifying existing NLP tasks and are designed to require a long context for high performance. We evaluate simple chunking-based baselines, and find that the Longformer model is able to outperform the T5 model suggesting our benchmark is a good test for the ability of models to make use of longer contexts. We believe that the technique explored in this work of augmenting and extending existing 'short document' datasets, can be applied to many other NLP tasks. As the performance of efficient transformers improves, we anticipate the need to update this benchmark with more challenging tasks. While we are focused on creating a benchmark which tests a model's ability to solve real-world long document tasks, we also expect improvements in the efficiencies of the models themselves which may make datasets with more than 100,000 tokens necessary which may require a fundamentally different approach to creating long document datasets. We leave for future work both the development of improved chunking methods, and more efficient transformers which make such methods unnecessary. We hope that the MuLD benchmark will encourage this further research into efficient models for long document NLP. To this end we provide the data, baseline models, and other code at www.github.com/ ghomasHudson/muld.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Comparison of lengths of multitask long document benchmarks. The maximum input length of gpt3 and Longformer (LED) are included for comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Dataset lengths (#tokens)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: T5 and Longformer results on the benchmark</cell></row><row><cell>? Style Change Detection -We use the methodol-</cell></row><row><cell>ogy of</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Primarily from the Internet movie script database: www. imsdb.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">opus.nlpl.eu/OpenSubtitles2016.php</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>We present examples from the MuLD benchmark to give the reader a sense of the tasks included <ref type="bibr">(</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Style Change</head><p>Input:</p><p>John's stomach had a new home again. It now settled into his throat, painfully dry for want of the man before him. "Which story would you like to hear, my dear?" John's fingers looped in and around the curls so delicately, a lesser effort wouldn't have moved the hair at all. He thought of the beautiful mind beneath these curls. Once storing every memory like a computer and now weakened with age-but always beautiful. John gulped down a lump of panic that crawled up his throat. What did he know? "</p><p>Right, but I still reckon I'll keep pretending you don't." "John, when we need to pretend to be a couple, things like spontaneous physical contact are expected to maintain-" "Don't mention it," Sherlock responded with a soft passion he couldn't keep out of his voice. The words came out in a murmur. -" he continued, delighted when John joined in to harmonize flawlessly in the latter half of phrase <ref type="bibr">[...]</ref> Output: <ref type="figure">1,1,1,1,1,1</ref> Barranca looks evilly at Indy's hand upon him. Indy releases him and smiles in a friendly way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INDY</head><p>We don't need them.</p><p>Satipo watches this confrontation with some concern. BARRANCA I do not carry supplies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INDY</head><p>We'll leave them. Once we've got it, we'll be able to reach the plane by dusk <ref type="bibr">[...]</ref> Output:</p><p>Hero VLSP Input:</p><p>## Chapter 1 Basic Definitions and Concepts ### 1.1 Basics of simplicial complexes Let @xmath , and @xmath denote the subsets of @xmath of size @xmath . A collection @xmath of subsets of @xmath is called a (finite abstract) simplicial complex if it is closed under inclusion, i.e. @xmath implies @xmath . Note that if @xmath is not empty (which we will assume from now on) then @xmath . The @xmath -th skeleton of @xmath is @xmath . The elements of @xmath are called faces ; those in @xmath have dimension i . The @xmath -dimensional faces are called vertices , the @xmath -dimensional faces are called edges and the maximal faces with respect to inclusion are called facets . If all the facets have the same dimension, @xmath is pure . The @xmath -vector (face vector) of @xmath is @xmath where @xmath . The dimension of K is @xmath ; e.g. a 1-dimensional simplicial complex is a simple graph. The @xmathpolynomial of @xmath is @xmath <ref type="bibr">[...]</ref> Output:</p><p>This thesis focuses on algebraic shifting and its applications to f-vector theory of simplicial complexes and more general graded posets. In particular, several approaches and partial results concerning the g-conjecture for simplicial spheres are presented here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OpenSubtitles</head><p>Input:</p><p>1957 was a big year. The Russians put that Sputnik into outer space. The Dodgers played their last game at Ebbets Field and said goodbye to Brooklyn. That guy, he shot Frank Costello in the head and missed. The Gallo brothers whacked Albert Anastasia in that barbershop. It was total chaos <ref type="bibr">[...]</ref> Output:</p><p>1957 war ein bedeutendes Jahr. Die Russen schossen ihren Sputnik ins All. Die Dodgers spielten zum letzten Mal in Ebbets Field und sagten Brooklyn Adieu. Dieser Kerl schoss auf Frank Costello und verfehlte ihn. Die Gallo-Bruder legten Albert Anastasia beim Friseur um. Es war totales Chaos <ref type="bibr">[...]</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Longformer: The long-document transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A discourse-aware attention model for abstractive summarization of long documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goharian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="615" to="621" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Transformer-xl: Attentive language models beyond a fixed-length context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.02860</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="85" to="91" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Lot: A benchmark for evaluating chinese long text understanding and generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.12960</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Transformers are rnns: Fast autoregressive transformers with linear attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Katharopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fleuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5156" to="5165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reformer: The efficient transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kitaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The narrativeqa reading comprehension challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ko?isk?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="317" to="328" />
			<date type="published" when="2018-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Opensubtitles2018: Statistical rescoring of sentence alignments in large, noisy parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kouylekov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Glge: A new general language generation evaluation benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FIND-INGS</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Marinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Martins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.00301</idno>
		<title level="m">infty-former: Infinite memory transformer</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A large-scale test set for the evaluation of context-aware pronoun translation in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Voita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Parrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Padmakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.02268</idno>
		<idno>arXiv:2112.08608</idno>
	</analytic>
	<monogr>
		<title level="m">QuAL-ITY: Question answering with long input texts, yes! arXiv preprint</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002-07" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Blockwise self-attention for long document understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<meeting><address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="2555" to="2565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ivgi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Haviv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>Scrolls: Standardized comparison over long language sequences</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic identification of character types from film dialogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Skowron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Trapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Payr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Trappl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="942" to="973" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-label style change detection by solving a binary classification problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Str?m</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Efficient transformers: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<idno>abs/2009.06732</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Long range arena : A benchmark for efficient transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Abnar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP. Association for Computational Linguistics</title>
		<meeting>the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">SuperGLUE: A stickier benchmark for general-purpose language understanding systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno>1905.00537</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Linformer: Self-attention with linear complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.04768</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>Cuge: A chinese language understanding and generation evaluation benchmark. ArXiv, abs/2112.13610</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Overview of the style change detection task at pan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Style change detection based on writing style similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2208" to="2211" />
		</imprint>
	</monogr>
	<note>PAN at CLEF 2021</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
