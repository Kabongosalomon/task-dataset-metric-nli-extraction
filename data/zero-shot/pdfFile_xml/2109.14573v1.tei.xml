<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Flexible Blind JPEG Artifacts Removal</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxi</forename><surname>Jiang</surname></persName>
							<email>jiaxijiang@student.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Vision Lab</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
							<email>kai.zhang@vision.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Vision Lab</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
							<email>timofter@vision.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Vision Lab</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Flexible Blind JPEG Artifacts Removal</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Training a single deep blind model to handle different quality factors for JPEG image artifacts removal has been attracting considerable attention due to its convenience for practical usage. However, existing deep blind methods usually directly reconstruct the image without predicting the quality factor, thus lacking the flexibility to control the output as the non-blind methods. To remedy this problem, in this paper, we propose a flexible blind convolutional neural network, namely FBCNN, that can predict the adjustable quality factor to control the trade-off between artifacts removal and details preservation. Specifically, FBCNN decouples the quality factor from the JPEG image via a decoupler module and then embeds the predicted quality factor into the subsequent reconstructor module through a quality factor attention block for flexible control. Besides, we find existing methods are prone to fail on non-aligned double JPEG images even with only a one-pixel shift, and we thus propose a double JPEG degradation model to augment the training data. Extensive experiments on single JPEG images, more general double JPEG images, and real-world JPEG images demonstrate that our proposed FBCNN achieves favorable performance against state-ofthe-art methods in terms of both quantitative metrics and visual quality.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>JPEG <ref type="bibr" target="#b38">[39]</ref> is one of the most widely-used image compression algorithms and formats due to its simplicity and fast encoding/decoding speeds. JPEG compression splits an image into 8 ? 8 blocks and applies discrete cosine transform (DCT) to each block. The DCT coefficients are then divided by a quantization table and rounded to the nearest integer. The elements in the quantization table control the compression ratio and the rounding operation is the only lossy operation in the whole process. The quantization ta-* Corresponding author. ble is usually represented by an integer called quality factor (QF) ranging from 0 to 100, where a lower quality factor means less storage size but more lost information. Inspired by the success of deep neural networks (DNNs) for image classification <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b36">37]</ref>, researchers began to resort to DNNs for JPEG artifacts removal and have achieved notable academic success.</p><p>However, existing methods for JPEG artifacts removal generally have four limitations in real applications: <ref type="bibr" target="#b0">(1)</ref> Most existing DNNs based methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b53">54]</ref> trained a specific model for each quality factor, lacking the flexibility to learn a single model for different JPEG quality factors. <ref type="bibr" target="#b1">(2)</ref> DCT based methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b52">53]</ref> need to obtain the DCT coefficients or quantization table as input, which is only stored in JPEG format. Besides, when images are compressed multiple times, only the most recent compression information is stored. (3) To solve the first problem, some recent work <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b49">50]</ref> resort to training a single model for a large range of quality factors. However, these blind methods can only provide a deterministic reconstruction result for each input, ignoring the need for user preferences. <ref type="bibr" target="#b3">(4)</ref> Existing methods are all trained with synthetic images which assumes that the low-quality images are compressed only once. However, most images from the Internet are compressed multiple times. Despite some progress for real recompressed images, e.g., from Twitter <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b14">15]</ref>, a detailed and complete study on double JPEG artifacts removal is still missing.</p><p>To tackle the above problems, we design a flexible blind convolutional neural network, namely FBCNN, for real JPEG image restoration. Our FBCNN is a single model that can deal with JPEG images with different quality factors. In addition, FBCNN can work independent of the image formats, as it directly processes images in pixel-domain, without the need to access the metadata of images. By further decoupling the latent quality factor from the input JPEG image, we can use this important parameter to guide the artifacts removal process. As a controllable variable with clear physical meaning, the predicted quality factor can also be adjusted via interactive selection to achieve a balance between artifacts removal and details preservation. To address the problems with real-world JPEG images, we provide a detailed study on the restoration of images with double JPEG compression. We find that existing blind methods are prone to fail when the 8 ? 8 blocks of double JPEG compression are not aligned and QF 1 ? QF 2 . However, our quality factor predictor can help to explain the behavior of current blind methods under unseen scenarios. We provide comprehensive empirical evidence showing that blind methods work are easy to be misled by the unseen compound artifacts, resulting in an unpleasant reconstructed output. By correcting the predicted quality factor, FBCNN instead can boost the performance on complex double JPEG images. To obtain a fully blind model, we further propose two solutions: correcting QF to the smaller one which can be estimated by our dominant QF estimation method or augmenting the training data with non-aligned double JPEG images.</p><p>To summarize, the main contributions of this paper are:</p><p>(1) A flexible blind convolutional neural network for JPEG artifacts removal (FBCNN) is proposed. FBCNN can predict the latent quality factor to guide the image restoration. The predicted quality factor can be adjusted manually to control the preference between artifacts removal and details preservation according to the user's needs.</p><p>(2) We perform a thorough analysis of double JPEG images and provide solutions to take a step towards the restoration of real images. To the best of our knowledge, this is the first attempt to handle double non-aligned JPEG compression. We hope that the community will gradually begin to consider this more challenging and realistic scenario.</p><p>(3) We demonstrate the effectiveness of FBCNN on synthetic and real JPEG images with complex degradation settings. Our proposed FBCNN provides a useful solution for practical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>JPEG Artifacts Removal Networks. Learning-based methods have made notable progress in JPEG artifacts removal in the past few years. Dong et al. <ref type="bibr" target="#b10">[11]</ref> first introduced deep learning to remove JPEG artifacts, inspired by the success of super-resolution network <ref type="bibr" target="#b11">[12]</ref>. Zhang et al. <ref type="bibr" target="#b49">[50]</ref> employed batch normalization <ref type="bibr" target="#b21">[22]</ref> and residual learning <ref type="bibr" target="#b19">[20]</ref> strategies to speed up the training process and boost the performance on general blind image restoration tasks. A wavelet transform based network was presented in <ref type="bibr" target="#b27">[28]</ref> as the generalization of dilated convolution <ref type="bibr" target="#b45">[46]</ref> and subsampling, leading to a large improvement. Fu et al. <ref type="bibr" target="#b14">[15]</ref> proposed a deep convolutional sparse coding network that combines model-based methods with deep learning. Besides, dual-domain convolutional network based methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b54">55]</ref> were proposed to take advantage of redundancies on both pixel and DCT domains. Recently, Ehrlich et al. <ref type="bibr" target="#b12">[13]</ref> trained their networks with the utilization of quantization table as prior information, which allows a single model to correct artifacts at any quality factor and achieved state-of-the-art results.</p><p>Double JPEG Compression. Double JPEG compression has been studied in the area of image forensics for a long time, as detection of double compression can provide important clues for the recovery of image processing history. Fu et al. <ref type="bibr" target="#b13">[14]</ref> showed that if an image has been JPEG compressed only once, then the first digits of the quantized JPEG coefficients follow a Benford-like logarithmic law. In <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b28">29]</ref>, double JPEG compression was classified into two cases: aligned and non-aligned. Chen et al. <ref type="bibr" target="#b7">[8]</ref> formulated the periodic characteristics of JPEG images in both spatial and DCT domains and showed that such periodic characteristics will be changed after recompression. Recently, learning-based methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b39">40]</ref> were proposed to detect double JPEG compression. The estimation of the first quantization table of JPEG images is also a challenging problem and studied in both aligned <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47]</ref> and non-aligned cases <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b44">45]</ref>. However, these methods focus on analyzing the DCT coefficients, which are only stored in JPEG format. Besides, the research on double JPEG compression restoration is still missing.</p><p>Flexible Image Restoration. Flexible image generation based on the conditional variable has drawn much attention in e.g. text-to-image generation <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b42">43]</ref> and facial attribute editing <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27]</ref>. However, these methods can not be directly adopted in image restoration. Zhang et al. <ref type="bibr" target="#b50">[51]</ref> proposed to take a tunable noise level map as the input to handle noise on different levels. In <ref type="bibr" target="#b51">[52]</ref>, a PCA-based dimensionality stretching of the degradation parameters was proposed to take blur kernel and noise level as input for super-resolution. Wang et al. <ref type="bibr" target="#b40">[41]</ref> proposed a novel controllable framework for interactive image restoration. He et al. <ref type="bibr" target="#b18">[19]</ref> focused on the images with multiple degradations and added the multi-dimensional degradation information as input. These methods usually assume that the controllable variable is provided, but such information is almost unknown in real applications. This encourages us to work towards a flexible blind solution for image restoration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>In this section, we first introduce the architecture of our FBCNN, and then present its advantage over other stateof-the-art methods, especially for practical recompressed JPEG images.  <ref type="figure" target="#fig_0">Figure 1</ref>. The architecture of the proposed FBCNN for JPEG artifacts removal. FBCNN consists of four parts, i.e., decoupler, quality factor predictor, flexible controller, and image reconstructor. The decoupler extracts the deep features from the input corrupted JPEG image and then splits them into image features and QF features which are subsequently fed into the reconstructor and predictor, respectively. The controller gets the estimated QF from the predictor and then generates QF embeddings. The QF attention block enables the controller to make the reconstructor produce different results according to different QF embeddings. The predicted quality factor can be changed with interactive selections to have a balance between artifacts removal and details preservation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Flexible Blind Artifacts Removal Network</head><p>JPEG image as input and directly generates the output image. Specifically, FBCNN consists of four components: decoupler, QF predictor, flexible controller, and image reconstructor. The network is fairly straightforward, with each component designed to achieve a specific task.</p><p>Decoupler: The decoupler aims to extract the deep features and decouple the latent quality factor from the input image. It involves four scales, each of which has an identity skip connection to the reconstructor. 4 residual blocks are adopted in each scale, and each residual block is composed of two 3 ? 3 convolution layers with ReLU activation in the middle. 2 ? 2 strided convolutions are adopted for the downscaling operations. The number of output channels in each layer from the first to the fourth scale is set to 64, 128, 256, 512, respectively. The image features from the decoupler are passed into the reconstructor. At the same time, they are also shared by an additional quality factor branch that uses residual blocks to extract higher-level information, followed by a global average pooling layer to get the global quality factor features from the image features.</p><p>Quality Factor Predictor: The QF predictor is a 3-layer MLP (multilayer perceptron) that takes as input the 512dimensional QF features and produces an estimated quality factor QF est of the compressed image. We set the number of nodes in each hidden layer as 512 for a better prediction. During training, patches with small sizes may only include limited information and correspond to multiple quality factors so that the quality factor can not be accurately estimated, which may lead to an unstable training process. Therefore, we use the L1 loss function to avoid too much penalty for such outliers. Let N be the batch size during training, the loss for quality factor estimation in each batch can be written as:</p><formula xml:id="formula_0">L QF = 1 N N i=1 QF i est ? QF i gt 1 .<label>(1)</label></formula><p>Flexible Controller: The flexible controller is a 4-layer MLP and takes as input the quality factor, representing the degree of compression of the targeted image. The controller aims to learn an embedding of the given quality factor that can be fused into the reconstructor for flexible control. Inspired by recent research in spatial feature transform <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b41">42]</ref>, the controller learns a mapping function that outputs a modulation parameter pair (?, ?) which embeds the given quality factor. Specifically, the first three layers of MLP generate shared intermediate conditions, which are then split into three parts corresponding to the three scales in the reconstructor. In the last layer of MLP, we learn dif-ferent parameter pairs for different scales in reconstructor whereas shared (?, ?) are broadcasted to the QF Attention block within the same scale. After obtaining (?, ?) from the controller, the transformation is carried out by scaling and shifting feature maps of a specific layer:</p><formula xml:id="formula_1">F out = ? ? F in ? ?,<label>(2)</label></formula><p>where F in and F out denote the feature maps before and after the affine transformation, and ? is referred to as elementwise multiplication. Given N training samples within a batch, the goal of the image reconstructor is to minimize the following L1 loss function between reconstructed image I rec and the original ground-truth image I gt :</p><formula xml:id="formula_2">L rec = 1 N N i=1 I i rec ? I i gt 1 .<label>(3)</label></formula><p>Overall, the complete training objective can be written as:</p><formula xml:id="formula_3">L total = L rec + ? ? L QF ,<label>(4)</label></formula><p>where ? controls the balance between image reconstruction and QF estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Comparison with Other Design Choices</head><p>In the following, we will clarify the differences between the proposed FBCNN and two alternative design choices.</p><p>A blind model without QF prediction: Existing blind methods only provide a deterministic result, ignoring the need of the user's preference. Besides, as we will discuss in Sec. 3.3, although the pure blind model performs favorably for single JPEG artifacts removal without knowing the quality factor, it does not generalize well to real corrupted images whose artifacts are more complex. FBCNN can be viewed as multiple deblockers and can control the trade-off between JPEG artifacts removal and details preservation.</p><p>Cascaded QF prediction and non-blind model: It is also possible to design a QF predictor cascaded by a nonblind method like CBD-Net <ref type="bibr" target="#b17">[18]</ref>. However, our method enjoys some benefits compared with such a cascaded design: First, for accurate quality factor estimation, a convolutional network starting from the same scale as the input image is needed, which would increase the total model size and cost more training and inference time. Instead, we only add a relatively small prediction branch. Second, our decoupler shared parameters for QF estimation and image reconstruction, accelerating the convergence of predicting QF. On the contrary, in cascaded design, inaccurate QF estimation would lead to an unstable training process. It might be a solution to train a QF predictor and then freeze it to train the second part for reconstruction. Nevertheless, it would cost more training time than our joint training schedule. Fourth, in cascaded networks, the predicted parameter is treated as the input of the second part and propagates through the whole encoder-decoder architecture. Instead, our predicted parameter QF is the only input to the decoder part. We can change the QF to adjust different outputs during inference without the need to change the encoded image features, which saves half of the inference time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Restoration of Double JPEG Images</head><p>Limitations of existing methods: Although some existing work claimed to work on recompressed JPEG images, a detailed study on the restoration of double JPEG compression is still missing. We find that the current blind methods always fail when the blocks of two JPEG compression are not aligned and QF 1 ? QF 2 , even if there is an only onepixel shift between two compression.</p><p>Let us look at an example in <ref type="figure" target="#fig_1">Fig. 2</ref>, where the appearances of JPEG images with different compression settings can be observed. To get non-aligned double JPEG images, we remove the first row and the first column of the image between the first compression with QF 1 and the second one with QF 2 . For aligned double JPEG with QF = (90, 10), <ref type="bibr" target="#b9">(10,</ref><ref type="bibr">90)</ref>, and non-aligned double JPEG with QF = (90, 10)*, the blocking effects are similar to single compression with QF = 10: the edges of 8 ? 8 blocks are apparent. However, in the case of non-aligned double JPEG with QF = (10, 90)*, the blocking edges are not clear anymore. We test representative blind methods DnCNN <ref type="bibr" target="#b49">[50]</ref> and QGAC <ref type="bibr" target="#b12">[13]</ref> on these images.</p><p>As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, in cases of QF = 90, 10, (90, 10), the blocking effects are well removed by both methods. DnCNN also works well on QF = (10, 90), while QGAC fails in this case because QGAC extracts the quantization table from the JPEG image, but JPEG images only keep the most recent compression information. Therefore, we conclude that existing quantization table-based methods are not suitable for real application. However, in the case of non-aligned double JPEG compression when QF 1 = 10 and QF 2 = 90, both methods do not work. Since our FBCNN is also a pixel-based blind method like DnCNN but can predict the quality factor, it can be used to explain the behavior behind a blind method. We test FBCNN using the same images. Not surprisingly, we get a similar, almost unchanged reconstructed result, but we find the predicted quality factor is 90. We continue to test other images with non-aligned double JPEG compression and QF 1 &lt; QF 2 , finding that the predicted quality factor is always close to QF 2 . This is to say, blind methods trained with single JPEG compression image pairs are always misled by the appearance of non-aligned double JPEG images with QF 1 &lt; QF 2 . They also do not work when QF 1 = QF 2 .</p><p>In summary, we classify double JPEG compression into two categories: simple and complex compression. Simple compression corresponds to non-aligned double JPEG with QF 1 &gt; QF 2 and all aligned double JPEG compression, which is actually equivalent to single JPEG compression. Complex compression corresponds to non-aligned double JPEG with QF 1 ? QF 2 , where composite artifacts occur. We test images with these degradation settings by a recent double JPEG compression algorithm <ref type="bibr" target="#b30">[31]</ref>, finding that only images with non-aligned double JPEG with QF 1 ? QF 2 can be identified as double JPEG compression, which further support our arguments.</p><p>To overcome the problem with non-aligned double JPEG compression, we propose two solutions, from the perspectives of adjusting the QF to utilize our flexible network and augmenting the training data.</p><p>FBCNN trained with a single JPEG degradation model with dominant QF correction: Since our FBCNN can provide different outputs by setting different quality factors, correcting the predicted QF to the smaller one, which actually dominates the main compression, is expected to improve the restoration results. However, to get a fully blind model, it is crucial to infer the smaller quality factor automatically. By utilizing the property of JPEG compression, we find that the quality factor of a JPEG image with single compression can be obtained by doing another JPEG compression with all possible QFs. The image's QF corresponds to the global minimum of the MSE (mean squared error) between two JPEG images. We further extend this method to challenging non-aligned double JPEG images with QF 1 &lt; QF 2 . We apply another JPEG compression with all possible QFs after a shift in the range of 0 to 7 in two directions. We also calculate the MSE curves for each shift possibility between the two JPEG images. For each MSE curve, we search for the first minimum. It can be found that among all the first minimums, the QF at the smallest first minimum is always close to QF 1 , while the QF at the global minimum is approximate to QF 2 . Besides, we constrain the MSE of the smallest first minimum to be smaller than a threshold T to have more robust results. We empirically set T to 30 in our experiment. We name the FBCNN model with dominant QF correction as FBCNN-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FBCNN trained with double JPEG degradation model:</head><p>We can also solve this problem by augmenting the training data using images with double JPEG compression. We pro- <ref type="table">Table 1</ref>. PSNR|SSIM|PSNRB results of different methods on grayscale JPEG images with single compression. Please note that the methods marked with * train a specific model for each quality factor. The best two results are highlighted in red and blue colors, respectively. pose a new degradation model to synthesize the non-aligned double JPEG image y from the uncompressed image x via y = JPEG(shift(JPEG(x, QF 1 )), QF 2 ).</p><p>For shift operation, we randomly remove the first i rows and j columns of the image after the first compression, where 0 ? i, j ? 7. When trained with double JPEG compressed images, the weight of quality factor loss is set to zero. Then the dominant quality factor can be trained in an unsupervised way. We name the FBCNN model with augmented training data as FBCNN-A. Note that our double JPEG degradation model can also be applied to other tasks such as blind single image super-resolution <ref type="bibr" target="#b48">[49]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Preparation and Network Training</head><p>For fair comparisons, JPEG images used during training and evaluation are all generated by the MATLAB JPEG encoder. We use the Y channel of YCbCr space for grayscale image comparison, and the RGB channels for color image comparison. Following <ref type="bibr" target="#b12">[13]</ref>, we employ DIV2K <ref type="bibr" target="#b0">[1]</ref> and Flickr2K <ref type="bibr" target="#b37">[38]</ref> as our training data. During training, we randomly extract patch pairs with the size 128 ? 128, and the quality factor is randomly sampled from 10 to 95. We set ? to 0.1. To optimize the parameters of FBCNN, we adopt the Adam solver <ref type="bibr" target="#b23">[24]</ref> with batch size 256. The learning rate starts from 1 ? 10 ?4 and decays by a factor of 0.5 every 4?10 4 iterations and finally ends with 1.25?10 ?5 . We train our model with PyTorch on eight NVIDIA GeForce GTX 2080Ti GPUs. It takes about two days to obtain FBCNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Single JPEG Image Restoration</head><p>Grayscale JPEG image restoration We first evaluate the performance of the proposed FBCNN on images with single JPEG compression. We test on the commonly used benchmarks: Classic5 <ref type="bibr" target="#b47">[48]</ref>, LIVE1 <ref type="bibr" target="#b35">[36]</ref> and the test set of BSDS500 <ref type="bibr" target="#b29">[30]</ref>. We compare our proposed FBCNN with ARCNN <ref type="bibr" target="#b10">[11]</ref>, MWCNN <ref type="bibr" target="#b27">[28]</ref>, DnCNN <ref type="bibr" target="#b49">[50]</ref>, DCSC <ref type="bibr" target="#b14">[15]</ref>, QGAC <ref type="bibr" target="#b12">[13]</ref>. It should be pointed out that ARCNN and MWCNN train a single network for each specific value of quality factor, and DCSC is trained with quality factors from 10 to 40. Only DnCNN, QGAC, and our FBCNN cover a full range of quality factors. We calculate the PSNR, SSIM, and PSNR-B for quantitative assessment. The quantitative results are shown in <ref type="table">Table 1</ref>. Our method has significantly better results than other blind methods and moderately better results than MWCNN, which trains each model for a specific quality factor. For subjective comparisons, some restored images of different approaches on the LIVE1 dataset have been presented. As can be seen in <ref type="figure">Fig. 3</ref>, the results of our FBCNN are more visually pleasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Color JPEG image restoration</head><p>We also train our model on RGB channels, referred to as FBCNN-C. We compare FBCNN-C with QGAC, which is a state-of-the-art method, especially for color JPEG image restoration. The evaluation is made on LIVE1 <ref type="bibr" target="#b35">[36]</ref>, testset of BSDS500 <ref type="bibr" target="#b29">[30]</ref>, and ICB <ref type="bibr" target="#b33">[34]</ref> dataset. Although QGAC is specially designed for color JPEG image artifacts removal, we still get better performance by setting the input/output channels as 3. The result is shown in <ref type="table" target="#tab_2">Table 2</ref>.   Flexible JPEG image restoration To demonstrate the flexibility of FBCNN, we show an example in <ref type="figure">Fig. 4</ref>. By setting different quality factors, we can get results with different perception qualities. Users can make an interactive selection according to their preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Double JPEG Image Restoration</head><p>The focus of our paper is to remove the complex double JPEG compression artifacts, which is an important step towards real image restoration. So we also evaluate the performance of current state-of-the-art methods and our pro-posed methods on images with double JPEG compression. We compare our methods with blind methods: DnCNN, DCSC, QGAC. The comparison is conducted using different combinations of quality factors (QF 1 , QF 2 ) on the LIVE1 dataset. Each original image is JPEG compressed with QF 1 , cropped by a random shift <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b3">4)</ref> to the upper left corner, and JPEG compressed with QF 2 .</p><p>The numerical and visual results are reported in <ref type="table" target="#tab_3">Table 3</ref> and <ref type="figure">Fig. 5</ref>. As shown in <ref type="table" target="#tab_3">Table 3</ref>, when changing the order of QF 1 and QF 2 , although the differences between the PSNR values of JPEG images are generally smaller than 0.05 dB, a significant drop in performance can be seen on other methods and our FBCNN. Since DCSC is only trained with small quality factors from 10 to 40, it generally performs better than DnCNN, QGAC, and FBCNN when QF 1 &lt; QF 2 . Despite some benefits for double JPEG compression, it should be pointed out that it is not reasonable to use a model trained with low quality factors to tackle all kinds of JPEG images. When dealing with relatively high-quality images, it tends to give more blurry results. We also examine the effectiveness of our proposed two solutions to non-aligned double JPEG restoration. FBCNN-D is obtained based on FBCNN by correcting the quality factor by dominant QF estimation during inference. FBCNN-A is obtained by augmenting the training data with our proposed double JPEG degradation model. <ref type="table" target="#tab_3">Table 3</ref> shows that by correcting the predicted quality factor, FBCNN-D largely improves the PSNR when QF 1 &lt; QF 2 . FBCNN-A further improves performance when QF 1 &lt; QF 2 . The difficult case when QF 1 = QF 2 also sees an improvement on FBCNN-A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Real-World JPEG Image Restoration</head><p>Besides the above experiments on synthetic test images, we also conduct experiments on real images to demonstrate the effectiveness of the proposed FBCNN. We collect 400 meme images from the Internet, as this kind of image is of-ten compressed many times. <ref type="figure">Fig. 6</ref> shows a test example on our collected Meme dataset. Since there are no groundtruth high-quality images and no reliable no-reference image quality assessment (IQA) metrics, we do not report the quantitative results. We leave the study of no-reference IQA for JPEG compression artifacts removal for future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, we proposed a flexible blind JPEG artifacts removal network (FBCNN) for real JPEG image restoration. FBCNN decouples the quality factor from the input image via a decoupler and then embeds the predicted quality factor into the subsequent reconstructor through a quality factor attention block for flexible control. The predicted quality factor can also be adjusted to achieve a balance between artifacts removal and details preservation. Besides, we address non-aligned double JPEG restoration tasks to take steps towards real JPEG images with severe degradations. Extensive experiments on single JPEG images, the more general double JPEG images, and real-world JPEG images demonstrate the flexibility, effectiveness, and generalizability of our proposed FBCNN for restoring different kinds of degraded JPEG images.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>illustrates the overall architecture of our proposed FBCNN. FBCNN is an end-to-end model which takes a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Visual comparisons of a JPEG image with different degradation settings and their restored results by DnCNN and QGAC. QF = (QF 1 , QF 2 ) denotes that the image is firstly compressed with QF 1 and then compressed with QF 2 . '*' means there is a pixel shift (1,1) between blocks of two compression. Even only a shift of one pixel between two compression can lead to failures of existing methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .Figure 4 .</head><label>34</label><figDesc>Visual comparisons of different methods on a single JPEG image 'BSDS500: 140088' with QF = 10.(a) JPEG (27.45dB) (b) QF = 10 (28.13dB) (c) QF = 30 (29.34dB) (d) QF = 90 (28.05dB) An example to show the flexibility of FBCNN by setting different QFs into the network. The JEPG image is 'LIVE1: cemetry' compressed with quality factor 30. Although the artifacts around the words can be effectively removed when the set QF is small, the texture on the bricks becomes blurred. Users can get the desired results according to their preference through interactive selection by FBCNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>Visual comparisons of image 'LIVE1: caps' with non-aligned double JPEG compression. This image is degraded by the first JPEG with QF 1 =10, pixel shift = (4, 4), the second JPEG with QF 2 = 30 successively. Visual comparisons of an example from our Meme dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Image Reconstructor: The image reconstructor includes three scales and receives image features from decoupler and quality factor embedding parameters (?, ?) to generate the restored clean image. The QF attention block is an important component of the reconstructor. The number of QF attention blocks in each scale is set to 4. The learned parameter pair (?, ?) adaptively influences the outputs by applying an affine transformation spatially to each intermediate feature map inside the QF attention block of each scale.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>82|0.760|25.21 29.03 |0.793|28.76 30.01|0.820|29.59 29.40|0.803|29.13 29.62|0.810|29.30 29.84|0.812|29.43 30.12|0.822|29.80 20 30.12|0.834|27.50 31.15|0.852|30.59 32.16|0.870|31.52 31.63|0.861|31.19 31.81|0.864|31.34 31.98|0.869|31.37 32.31|0.872|31.74 30 31.48|0.867|28.94 32.51|0.881|31.98 33.43|0.893|32.62 32.91|0.886|32.38 33.06|0.888|32.49 33.22|0.892|32.42 33.54|0.894|32.78 40 32.43|0.885|29.92 33.32|0.895|32.79 34.27|0.906|33.35 33.77|0.900|33.23 33.87|0.902|33.30 34.05|0.905|33.12 34.35|0.907|33.48 LIVE1 10 27.77|0.773|25.33 28.96|0.808|28.68 29.69|0.825|29.32 29.19|0.812|28.90 29.34|0.818|29.01 29.51|0.825|29.13 29.75|0.827|29.40 20 30.07|0.851|27.57 31.29|0.873|30.76 32.04|0.889|31.51 31.59|0.880|31.07 31.70|0.883|31.18 31.83|0.888|31.25 32.13|0.889|31.57 30 31.41|0.885|28.92 32.67|0.904|32.14 33.45|0.915|32.80 32.98|0.909|32.34 33.07|0.911|32.43 33.20|0.914|32.47 33.54|0.916|32.83 40 32.35|0.904|29.96 33.61|0.920|33.11 34.45|0.930|33.78 33.96|0.925|33.28 34.02|0.926|33.36 34.16|0.929|33.36 34.53|0.931|33.74 BSDS500 10 27.80|0.768|25.10 29.10|0.804|28.73 29.61|0.820|29.14 29.21|0.809|28.80 29.32|0.813|28.91 29.46|0.821|28.97 29.67|0.821|29.22 20 30.05|0.849|27.22 31.28|0.870|30.55 31.92|0.885|31.15 31.53|0.878|30.79 31.63|0.880|30.92 31.73|0.884|30.93 32.00|0.885|31.19 30 31.37|0.884|28.53 32.67|0.902|31.94 33.30|0.912|32.34 32.90|0.907|31.97 32.99|0.908|32.08 33.07|0.912|32.04 33.37|0.913|32.32 40 32.30|0.903|29.49 33.55|0.918|32.78 34.27|0.928|33.19 33.85|0.923|32.80 33.92|0.924|32.92 34.01|0.927|32.81 34.33|0.928|33.10</figDesc><table><row><cell>Dataset</cell><cell>Quality</cell><cell>JPEG</cell><cell>ARCNN*</cell><cell>MWCNN*</cell><cell>DnCNN</cell><cell>DCSC</cell><cell>QGAC</cell><cell>FBCNN (Ours)</cell></row><row><cell></cell><cell>10</cell><cell>27.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Classic5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>PSNR|SSIM|PSNRB results of QGAC and FBCNN-C on color JPEG images with single compression. 69|0.743|24.20 27.62|0.804|27.43 27.77|0.803|27.51 20 28.06|0.826|26.49 29.88|0.868|29.56 30.11|0.868|29.70 30 29.37|0.861|27.84 31.17|0.896|30.77 31.43|0.897|30.92 40 30.28|0.882|28.84 32.05|0.912|31.61 32.34|0.913|31.80 BSDS500 10 25.84|0.741|24.13 27.74|0.802|27.47 27.85|0.799|27.52 20 28.21|0.827|26.37 30.01|0.869|29.53 30.14|0.867|29.56 30 29.57|0.865|27.72 31.33|0.898|30.70 31.45|0.897|30.72 40 30.52|0.887|28.69 32.25|0.915|31.50 32.36|0.913|31.52 ICB 10 29.44|0.757|28.53 32.06|0.816|32.04 32.18|0.815|32.15 20 32.01|0.806|31.11 34.13|0.843|34.10 34.38|0.844|34.34 30 33.20|0.831|32.35 35.07|0.857|35.02 35.41|0.857|35.35 40 33.95|0.840|33.14 32.25|0.915|31.50 36.02|0.866|35.95</figDesc><table><row><cell>Dataset</cell><cell>QF</cell><cell>JPEG</cell><cell>QGAC</cell><cell>FBCNN-C (Ours)</cell></row><row><cell></cell><cell>10 25.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>LIVE1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>PSNR|SSIM|PSNRB results of different methods on grayscale JPEG images with non-aligned double compression. The testing images are synthesized from the LIVE1 dataset. The best two results are highlighted in red and blue colors, respectively.<ref type="bibr" target="#b29">(30,</ref><ref type="bibr" target="#b9">10)</ref> 27.49|0.762|25.62 28.95|0.805|28.61 29.08|0.810|28.81 29.24|0.818|28.94 29.46|0.820|29.11 29.46|0.820|29.10 29.44|0.818|29.12 (50,10) 27.65|0.769|25.69 29.13|0.810|28.76 29.25|0.815|28.96 29.42|0.823|29.08 29.64|0.825|29.23 29.65|0.825|29.22 29.61|0.823|29.20 (50,30) 30.62|0.866|28.85 32.20|0.895|31.50 32.30|0.897|31.78 32.32|0.899|31.72 32.61|0.902|31.88 32.61|0.902|31.89 32.69|0.901|32.24 QF 1 =QF 2 (10,10) 26.48|0.715|25.08 27.73|0.765|27.49 27.76|0.768|27.59 27.78|0.771|27.59 27.96|0.774|27.75 27.95|0.774|27.74 28.25|0.777|28.14 (30,30) 29.98|0.847|28.53 31.40|0.878|30.86 31.48|0.880|31.10 31.43|0.881|30.99 31.64|0.884|31.14 31.65|0.884|31.14 31.94|0.886|31.73 (50,50) 31.58|0.888|30.18 33.12|0.912|32.44 33.28|0.914|32.80 33.12|0.914|32.50 33.38|0.917|32.61 33.45|0.914|32.85 33.70|0.919|33.34 QF 1 &lt;QF 2 (10,30) 27.55|0.760|26.94 28.33|0.790|28.17 28.31|0.789|28.19 28.30|0.791|28.18 28.29|0.791|28.15 28.94|0.802|28.82 29.38|0.816|29.30 (10,50) 27.69|0.768|27.41 28.30|0.791|28.24 28.40|0.794|28.35 28.23|0.791|28.18 28.20|0.789|28.14 28.96|0.801|28.88 29.52|0.820|29.45 (30,50) 30.61|0.865|29.60 31.89|0.890|31.46 32.08|0.893|31.78 31.81|0.891|31.43 31.96|0.893|31.50 32.31|0.895|31.94 32.64|0.900|32.49</figDesc><table><row><cell>Type</cell><cell>QF</cell><cell>JPEG</cell><cell>DnCNN</cell><cell>DCSC</cell><cell>QGAC</cell><cell>FBCNN (Ours)</cell><cell>FBCNN-D (Ours) FBCNN-A (Ours)</cell></row><row><cell>QF 1 &gt;QF 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments: This work was partly supported by the ETH Z?rich Fund (OK) and a Huawei Technologies Oy (Finland) project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ntire 2017 challenge on single image super-resolution: Dataset and study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirikur</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="126" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Aligned and non-aligned double jpeg detection using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Barni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bondi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicol?</forename><surname>Bonettini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Bestagini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Costanzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Maggini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benedetta</forename><surname>Tondi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Tubaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Visual Communication and Image Representation</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Identification of cut &amp; paste tampering by means of double-jpeg detection and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Barni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Costanzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lara</forename><surname>Sabatini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Circuits and Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1687" to="1690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Analysis of nonaligned double jpeg artifacts for the localization of image forgeries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiziano</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Piva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Information Forensics and Security</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image forgery localization via block-grained analysis of jpeg artifacts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiziano</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Piva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1003" to="1017" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cas-cnn: A deep convolutional neural network for image compression artifact suppression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Cavigelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="752" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1256" to="1272" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Detecting recompression of jpeg images via periodicity analysis of compression artifacts for tampering detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiou-Ting</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="396" to="406" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stargan: Unified generative adversarial networks for multi-domain image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjey</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minje</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8789" to="8797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust first quantization matrix estimation based on filtering of recompression artifacts for non-aligned double compressed jpeg images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nandita</forename><surname>Dalmia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Okade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing: Image Communication</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="9" to="20" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Compression artifacts reduction by a deep convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubin</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="576" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning a deep convolutional network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="184" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Quantization guided jpeg artifact correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Ehrlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A generalized benford&apos;s law for jpeg coefficients and its applications in image forensics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Security, Steganography, and Watermarking of Multimedia Contents IX</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">6505</biblScope>
			<biblScope unit="page">65051</biblScope>
		</imprint>
	</monogr>
	<note>International Society for Optics and Photonics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Jpeg artifacts reduction via deep convolutional sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Jun</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="2501" to="2510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">First quantization matrix estimation from double compressed jpeg images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fausto</forename><surname>Galvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Puglisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arcangelo</forename><surname>Ranieri Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastiano</forename><surname>Battiato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1299" to="1310" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Building dual-domain representations for compression artifacts reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="628" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Toward convolutional blind denoising of real photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifei</forename><surname>Shi Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1712" to="1722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Interactive multidimension modulation with dynamic controllable residual learning for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwen</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Attgan: Facial attribute editing by only changing what you want</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenliang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meina</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="5464" to="5478" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Agarnet: Adaptively gated jpeg compression artifacts removal network for a wide range quality factor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonsik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><forename type="middle">Woong</forename><surname>Soh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">Ik</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Controllable text-to-image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Stgan: A unified selective transfer network for arbitrary image attribute editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Errui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilei</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3673" to="3682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-level wavelet-cnn for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengju</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongzhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A novel method for detecting cropped and recompressed image block</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiqi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoping</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">217</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doron</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Double jpeg detection in mixed jpeg quality factors using deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinseok</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyeon</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonhyuk</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heung-Kyu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Semantic image synthesis with spatially-adaptive normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Chun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2337" to="2346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multiple jpeg compression detection by means of benford-fourier coefficients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cecilia</forename><surname>Pasquini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giulia</forename><surname>Boato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>P?rez-Gonz?lez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Information Forensics and Security</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="113" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Image compression benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rawzor</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Generative adversarial text to image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeynep</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lajanugen</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1060" to="1069" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheikh</surname></persName>
		</author>
		<ptr target="http://live.ece.utexas.edu/research/quality" />
		<title level="m">Live image quality assessment database release 2</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ntire 2017 challenge on single image super-resolution: Methods and results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirikur</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="114" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The jpeg still picture compression standard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wallace</surname></persName>
		</author>
		<idno>xviii-xxxiv, 1992. 1</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Consumer Electronics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Double jpeg compression forensics based on a convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Information Security</title>
		<imprint>
			<biblScope unit="volume">2016</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Cfsnet: Toward a controllable feature space for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiming</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yapeng</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4140" to="4149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Recovering realistic texture in image super-resolution by deep spatial feature transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="606" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Attngan: Finegrained text to image generation with attentional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengchuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuyuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1316" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Mse period based estimation of first quantization step in double compressed jpeg images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyi</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongmei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing: Image Communication</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="76" to="83" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">An improved first quantization matrix estimation for nonaligned double compressed jpeg images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinpeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">107430</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">An improved parameter estimation scheme for image modification detection based on dct coefficient analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiamu</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbin</forename><surname>Sm Yiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Forensic Science International</title>
		<imprint>
			<biblScope unit="volume">259</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="200" to="209" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">On single image scale-up using sparse-representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Zeyde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matan</forename><surname>Protter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Curves and Surfaces</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="711" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Designing a practical degradation model for deep blind image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyun</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3142" to="3155" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Ffdnet: Toward a fast and flexible solution for cnn-based image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4608" to="4622" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning a single convolutional super-resolution network for multiple degradations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3262" to="3271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Dmcnn: Dual-domain multi-scale convolutional neural network for compression artifacts removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoshuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueyu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="390" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Residual non-local attention networks for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Implicit dual-domain convolutional network for robust color image compression artifact reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolun</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaowu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuesong</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technology</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
