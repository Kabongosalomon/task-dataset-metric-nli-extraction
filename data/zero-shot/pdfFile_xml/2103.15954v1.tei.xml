<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DiNTS: Differentiable Neural Network Topology Search for 3D Medical Image Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufan</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Roth</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Zhao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daguang</forename><surname>Xu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DiNTS: Differentiable Neural Network Topology Search for 3D Medical Image Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, neural architecture search (NAS) has been applied to automatically search high-performance networks for medical image segmentation. The NAS search space usually contains a network topology level (controlling connections among cells with different spatial scales) and a cell level (operations within each cell). Existing methods either require long searching time for large-scale 3D image datasets, or are limited to pre-defined topologies (such as U-shaped or single-path) . In this work, we focus on three important aspects of NAS in 3D medical image segmentation: flexible multi-path network topology, high search efficiency, and budgeted GPU memory usage. A novel differentiable search framework is proposed to support fast gradient-based search within a highly flexible network topology search space. The discretization of the searched optimal continuous model in differentiable scheme may produce a sub-optimal final discrete model (discretization gap). Therefore, we propose a topology loss to alleviate this problem. In addition, the GPU memory usage for the searched 3D model is limited with budget constraints during search. Our Differentiable Network Topology Search scheme (DiNTS) is evaluated on the Medical Segmentation Decathlon (MSD) challenge, which contains ten challenging segmentation tasks. Our method achieves the state-ofthe-art performance and the top ranking on the MSD challenge leaderboard.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Automated medical image segmentation is essential for many clinical applications like finding new biomarkers and monitoring disease progression. The recent developments in deep neural network architectures have achieved great performance improvements in image segmentation. Manually designed networks, like U-Net <ref type="bibr" target="#b33">[34]</ref>, have been widely used in different tasks. However, the diversity of medical image segmentation tasks could be extremely high since the image characteristics &amp; appearances can be completely distinct for different modalities and the presentation of diseases in Auto-DeepLab <ref type="bibr" target="#b20">[21]</ref>, each edge in the topology search space is given a probability ?. The probabilities of input edges to a node sum to one, which means only one input edge for each node would be selected. A single-path discrete model (red path) is extracted from the continuous searched model. This can result in a large "discretization gap" between the feature flow of the searched continuous model and the final discrete model.</p><p>can vary considerably. This makes the direct application of even a successful network like U-Net <ref type="bibr" target="#b33">[34]</ref> to a new task less likely to be optimal. The neural architecture search (NAS) algorithms <ref type="bibr" target="#b48">[49]</ref> have been proposed to automatically discover the optimal architectures within a search space. The NAS search space for segmentation usually contains two levels: network topology level and cell level. The network topology controls the connections among cells and decides the flow of the feature maps across different spatial scales. The cell level decides the specific operations on the feature maps. A more flexible search space has more potential to contain better performing architectures.</p><p>In terms of the search methods in finding the optimal architecture from the search space, evolutionary or reinforcement learning-based <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b32">33]</ref> algorithms are usually time consuming. C2FNAS <ref type="bibr" target="#b44">[45]</ref> takes 333 GPU days to search one 3D segmentation network using the evolutionary-based methods, which is too computationally expensive for common use cases. Differentiable architecture search <ref type="bibr" target="#b22">[23]</ref> is much more efficient and Auto-DeepLab <ref type="bibr" target="#b20">[21]</ref> is the first work to apply differentiable search for segmentation network topology. However, Auto-DeepLab's differentiable formulation limits the searched network topology. As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, this formulation assumes that only one in-put edge would be kept for each node. Its final searched model only has a single path from input to output which limits its complexity. Our first goal is to propose a new differentiable scheme to support more complex topologies in order to find novel architectures with better performance.</p><p>Meanwhile, the differentiable architecture search suffers from the "discretization gap" problem <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b37">38]</ref>. The discretization of the searched optimal continuous model may produce a sub-optimal discrete final architecture and cause a large performance gap. As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, the gap comes from two sides: 1) the searched continuous model is not binary, thus some operations/edges with small but non-zero probabilities are discarded during the discretization step; 2) the discretization algorithm has topology constraints (e.g. single-path), thus edges causing infeasible topology are not allowed even if they have large probabilities in the continuous model. Alleviating the first problem by encouraging a binarized model during search has been explored <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b26">27]</ref>. However, alleviating the second problem requires the search to be aware of the discretization algorithm and topology constraints. In this paper, we propose a topology loss in search stage and a topology guaranteed discretization algorithm to mitigate this problem.</p><p>In medical image analysis, especially for some longitudinal analysis tasks, high input image resolution and large patch size are usually desired to capture miniscule longitudinal changes. Thus, large GPU memory usage is a major challenge for training with large high resolution 3D images. Most NAS algorithms with computational constraints focus on latency <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b35">36]</ref> for real-time applications. However, real-time inference often is not a major concern compared to the problem caused by huge GPU memory usage in 3D medical image analysis. In this paper, we propose additional GPU memory constraints in the search stage to limit the GPU usage needed for retraining the searched model.</p><p>We validate our method on the Medical Segmentation Decathlon (MSD) dataset <ref type="bibr" target="#b36">[37]</ref> which contains 10 representative 3D medical segmentation tasks covering different anatomies and imaging modalities. We achieve stateof-the-art results while only takes 5.8 GPU days (recent C2FNAS <ref type="bibr" target="#b44">[45]</ref> takes 333 GPU days on the same dataset). Our contributions can be summarized as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? We propose a novel Differentiable Network Topology</head><p>Search scheme DiNTS, which supports more flexible topologies and joint two-level search.</p><p>? We propose a topology guaranteed discretization algorithm and a discretization aware topology loss for the search stage to minimize the discretization gap.</p><p>? We develop a memory usage aware search method which is able to search 3D networks with different GPU memory requirements.</p><p>? We achieve the new state-of-the-art results and top ranking in the MSD challenge leaderboard while only taking 1.7% of the search time compared to the NASbased C2FNAS <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Medical Image Segmentation</head><p>Medical image segmentation faces some unique challenges like lacking manual labels and vast memory usage for processing 3D high resolution images. Compared to networks used in natural images like DeepLab <ref type="bibr" target="#b1">[2]</ref> and PSPNet <ref type="bibr" target="#b45">[46]</ref>, 2D/3D UNet <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b5">6]</ref> is better at preserving fine details and memory friendly when applied to 3D images. VNet <ref type="bibr" target="#b25">[26]</ref> improves 3D UNet with residual blocks. UNet++ <ref type="bibr" target="#b46">[47]</ref> uses dense blocks <ref type="bibr" target="#b12">[13]</ref> to redesign skip connections. H-DenseUNet <ref type="bibr" target="#b16">[17]</ref> combines 2D and 3D UNet to save memory. nnUNet <ref type="bibr" target="#b13">[14]</ref> ensembles 2D, 3D, and cascaded 3D UNet and achieves state-of-the-art results on a variety of medical image segmentation benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Neural Architecture Search</head><p>Neural architecture search (NAS) focuses on designing network automatically. The work in NAS can be categorized into three dimensions: search space, search method and performance estimation <ref type="bibr" target="#b7">[8]</ref>. The search space defines what architecture can be searched, which can be further divided into network topology level and cell level. For image classification, <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b10">11]</ref> focus on searching optimal cells and apply a pre-defined network topology while <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b41">42]</ref> perform search on the network topology. In segmentation, Auto-DeepLab <ref type="bibr" target="#b20">[21]</ref> uses a highly flexible search space while FasterSeg <ref type="bibr" target="#b2">[3]</ref> proposes a low latency two level search space. Both perform a joint two-level search. In medical image segmentation, NAS-UNet <ref type="bibr" target="#b39">[40]</ref>, V-NAS <ref type="bibr" target="#b47">[48]</ref> and Kim et al <ref type="bibr" target="#b14">[15]</ref> search cells and apply it to a U-Netlike topology. C2FNAS <ref type="bibr" target="#b44">[45]</ref> searches 3D network topology in a U-shaped space and then searches the operation for each cell. MS-NAS <ref type="bibr" target="#b43">[44]</ref> applies PC-Darts <ref type="bibr" target="#b42">[43]</ref> and Auto-DeepLab's formulation to 2D medical images.</p><p>Search method and performance estimation focus on finding the optimal architecture from the search space. Evolutionary and reinforcement learning has been used in <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b32">33]</ref> but those methods require extremely long search time. Differentiable methods <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b20">21]</ref> relax the discrete architecture into continuous representations and allow direct gradient based search. This is magnitudes faster and has been applied in various NAS works <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b43">44]</ref>. However, converting the continuous representation back to the discrete architecture causes the "discretization gap". To solve this problem, FairDARTS <ref type="bibr" target="#b4">[5]</ref> and Tian et al <ref type="bibr" target="#b37">[38]</ref> proposed zero-one loss and entropy loss respectively to push the continuous representation close to binary. Some works <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b11">12]</ref>  use temperature annealing to achieve the same goal. Another problem of the differentiable method is the large memory usage during search stage. PC-DARTS <ref type="bibr" target="#b42">[43]</ref> uses partial channel connections to reduce memory, while Auto-DeepLab <ref type="bibr" target="#b20">[21]</ref> reduces the filter number at search stage. It's a common practice to retrain the searched model while increasing the filter number, batch size, or patch size to gain better performance. But for 3D medical image segmentation, the change of retraining scheme (e.g. transferring to a new task which requires larger input size) can still cause out-of-memory problem. Most NAS work has been focused on searching architecture with latency constraints <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b35">36]</ref>, while only a few considered memory as a constraint. Mem-NAS <ref type="bibr" target="#b23">[24]</ref> uses a growing and trimming framework to constrain the inference GPU memory but does not allow integration in a differentiable scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Network Topology Search Space</head><p>Inspired by Auto-Deeplab <ref type="bibr" target="#b20">[21]</ref> and <ref type="bibr" target="#b18">[19]</ref>, we propose a search space with fully connected edges between adjacent resolutions (2? higher, 2? lower or the same) from adjacent layers as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. A stack of multi-resolution images are generated by down-sampling the input image by 1/2, 1/4, 1/8 along each axis. Together with the original image, we use four 3 ? 3 ? 3 3D convolutions with stride 2 to generate multi-resolution features (layer 0 in <ref type="figure" target="#fig_1">Fig. 2</ref>) to the following search space. The search space has L layers and each layer consists of feature nodes (green nodes) from D=4 resolutions and E=3D-2 candidate input edges (dashed green edges). Each edge contains a cell operation, and a upsample/downsample operation (factor 2) is used before the cell if the edge is an upsample/downsample edge. A feature node is the summation of the output features from each input edge. Compared to Auto-DeepLab <ref type="bibr" target="#b20">[21]</ref>, our search space supports searching for input image scales (c) Multi-resolution input <ref type="bibr" target="#b19">[20]</ref> and Input selection and complex multi-path topologies, as shown in <ref type="figure" target="#fig_3">Fig. 3</ref>. As for multi-path topology, MS-NAS <ref type="bibr" target="#b43">[44]</ref> discretizes and combines multiple single-path models searched from Auto-DeepLab's framework, but the search is still unaware of the discretization thus causing the gap. <ref type="bibr" target="#b18">[19]</ref> also supports multi-path topology, but <ref type="bibr" target="#b18">[19]</ref> is more about feature routing in a "fully connected" network, not a NAS method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Cell Level Search Space</head><p>We define a cell search space to be a set of basic operations where the input and output feature maps have the same spatial resolution. The cell search space in DARTS <ref type="bibr" target="#b22">[23]</ref> and Auto-Deeplab <ref type="bibr" target="#b20">[21]</ref> contains multiple blocks and the connections among those blocks can also be searched. However, the searched cells are repeated over all the cells in the network topology level. Similar to C2FNAS <ref type="bibr" target="#b44">[45]</ref>, our algorithm searches the operation of each cell independently, with one operation selected from the following:</p><p>(1) skip connection (2) 3x3x3 3D convolution (3) P3D 3x3x1: 3x3x1 followed by 1x1x3 convolution (4) P3D 3x1x3: 3x1x3 followed by 1x3x1 convolution (5) P3D 1x3x3: 1x3x3 followed by 3x1x1 convolution P3D represents pseudo 3D <ref type="bibr" target="#b31">[32]</ref> and has been used in V-NAS <ref type="bibr" target="#b47">[48]</ref>. A cell also includes ReLU activation and Instance Normalization <ref type="bibr" target="#b38">[39]</ref> which are used before and after those operations respectively (except for skip connection). The cell operations do not include multi-scale feature aggregation operations like atrous convolution and pooling. The feature spatial changes are performed by the upsample/downsample operations in the edges searched from the topology level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Continuous Relaxation and Discretization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Preliminaries</head><p>We briefly recap the relaxation in DARTS <ref type="bibr" target="#b22">[23]</ref>. NAS tries to select one from N candidate operations</p><formula xml:id="formula_0">O 1 , O 2 , ? ? ? , O N for each computational node. Each operation O i is paired with a trainable parameter ? i where N i=1 ? i = 1, ? i ? 0, and the output feature x out = N i=1 ? i O i (x in )</formula><p>, where x in is the input feature. Thus, the discrete operation is relaxed by the continuous representation ? which can be optimized using gradient descent. After optimization, O i with larger ? i is more important and will be selected. However, a small ? j (as long as ? j = 0) can still make a significant difference on x out and following layers. Therefore, directly discarding non-zero operations will lead to the discretization gap.</p><p>Auto-DeepLab <ref type="bibr" target="#b20">[21]</ref> extends this idea to edge selection in network topology level. As illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>, every edge is paired with a trainable parameter ? (0 ? ? ? 1), and parameters paired with edges that pointed to the same feature node sum to one. This is based on an assumption that "one input edge for each node" because the input edges to a node are competing with each other. After discretization, a single path is kept while other edges, even with a large ?, are discarded. This means the feature flow in the searched continuous model has a significant gap with the feature flow in the final discrete model. The single-path topology limitation comes from the previous assumption for topology level relaxation while the gap comes from the unawareness of the discretization in the search stage, such that edges with large probabilities can be discarded due to topology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Sequential Model with Super Feature Node</head><p>We propose a network topology relaxation framework which converts the multi-scale search space into a sequential space using "Super Feature Node". For a search space with L layers and D resolution levels, these D feature nodes in the same layer i are combined as a super feature node s i and features flow sequentially from these L super nodes as shown in <ref type="figure" target="#fig_4">Fig. 4</ref>. There are E=3D-2 candidate input edges to each super node and the topology search is to select an optimal set of input edges for each super node. We define a connection pattern as a set of selected edges and there are M = 2 E ? 1 feasible candidate connection patterns. The j-th connection pattern cp j is an indication vector of length E, where cp j (e) = 1, if e-th edge is selected in j-th pattern. We define the input connection operation to s i with connection pattern cp j as c i j . cp j defines c i j 's topology while c i j also includes cell operations on the selected edges in cp j . c i j , c i+1 k means the input/output connection patterns for s i are cp j , cp k respectively. Under this formulation, the topology search becomes selecting an input connection pattern for each super node and the competition is among all M connection patterns, not among edges. We associate a variable ? i j to the connection operation c i j for every s i and every pattern j. Denote the input features at layer 0 as s 0 , we have a sequential feature flow equation:</p><formula xml:id="formula_1">s i = M j=1 (? i j * c i j (s i?1 )) i = 1 ? ? ? , L<label>(1)</label></formula><formula xml:id="formula_2">M j=1 ? i j = 1, ? j ? 0 ?i, j ? i j = E e=1 (1 ? p i e ) 1?cpj (e) (p i e ) cpj (e) M j=1 E e=1 (1 ? p i e ) 1?cpj (e) (p i e ) cpj (e)<label>(2)</label></formula><formula xml:id="formula_3">0 ? p i e ? 1 ?i, e</formula><p>However, M is growing exponentially with D. To reduce the architecture parameters, we parameterize ? i j with a set of edge probability parameters p i e , e=1, ? ? ? , E in Eq. 2.</p><p>For a search space with L=12 layers and D=4, the network topology parameter number is reduced from M ?L = 1023 ? 12 to E ? L = 10 ? 12. Under this formulation, the probability ? of connections are highly correlated. If an input edge e to s i has low probability, all the candidate patterns to s i with e selected will have lower probabilities. For cell operation relaxation, we use the method in Sec. 3.3.1. Each cell on the input edge e to s i has its own cell architecture parameters ? i,e 1 , ? i,e 2 , ? ? ? , ? i,e N and will be optimized. Notice the c i j in Eq. 1. contains the cell operations defined on the selected edges, and it contains relaxed cell architecture parameters ?. Thus we can perform gradient based search for topology and cell levels jointly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Discretization with Topology Constraints</head><p>After training, the final discrete architecture is derived from the optimized continuous architecture representation ? (derived from p i e ) and ?. ? j i represents the probability of using input connection pattern cp i j for super node s i . Since the network topology search space is converted into a sequential space, the easiest way for topology discretization is to select cp j with the maximum ? i j . However, the topology may not be feasible. We define topology infeasibility as:</p><p>"a feature node has an input edge but no output edge or has an output edge but no input edge".</p><p>The gray feature nodes in <ref type="figure" target="#fig_5">Fig. 5</ref> indicate infeasible topology. Therefore, we cannot select cp j and cp k as s i 's input/output connection patterns even if they have the largest probabilities. For every connection pattern cp j , we generate a feasible set F(j). If a super node with input pattern j and output pattern k is feasible (all feature nodes of the super node are topologically feasible), then k ? F(j). Denote the array of selected input connection pattern indexes for these L super nodes as I, and the topology discretization can be performed by sampling I from its distribution p(I) using maximum likelihood (minimize negative log likelihood):</p><formula xml:id="formula_4">p(I) = L i=1 ? I(i) i , ?i : I(i + 1) ? F(I(i)) 0, else.<label>(3)</label></formula><formula xml:id="formula_5">I = argmin I L i=1 -log(? I(i) i ), ?i : I(i + 1) ? F(I(i)) (4)</formula><p>We build a directed graph G using ? and F as illustrated in <ref type="figure" target="#fig_5">Fig. 5</ref>. The nodes (yellow blocks) of G are connection operations and the input edge cost to a node c i j in G is ?log(? i j ). The path with minimum cost from the source to the sink nodes (green nodes with gray contour) corresponds to Eq. 4, and we obtained the optimal I using Dijkstra algorithm <ref type="bibr" target="#b6">[7]</ref>. For cell operations on the selected edges from I, we simply use the operation with the largest ?. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Bridging the Discretization Gap</head><p>To minimize the gap between the continuous representation and the final discretized architecture, we add entropy losses to encourage binarization of ? and ?:</p><formula xml:id="formula_6">L ? = ?1 L * E * N L i=1 E e=1 N n=1 ? i,e n * log(? i,e n ) L ? = ?1 L * M L i=1 M j=1 ? i j * log(? i j )<label>(5)</label></formula><p>However, even if the architecture parameters ? and ? are almost binarized, there may still be a large gap due to the topology constraints in the discretization algorithm. Recall the definition of topology feasibility in Sec. 3.3.3: an activated feature node (node with at least one input edge) must have an output edge while an in-activated feature node cannot have an output edge. Each super node has D feature nodes, thus there are 2 D ? 1 node activation pattern. We define A as the set of all node activation patterns. Each element a ? A is a indication function of length D, where a(i) = 1 if the i-th node of the super-node is activated. We further define two sets F in (a) and F out (a) representing all feasible input and output connection pattern indexes for a super node with node activation a as shown in <ref type="figure" target="#fig_6">Fig. 6</ref>. We propose the following topology loss:</p><formula xml:id="formula_7">p i in (a) = j?Fin(a) ? i j , p i out (a) = j?Fout(a) ? i+1 j (6) L tp = ? L?1 i=1 a?A ( p i in (a)log(p i out (a)) + (1 ? p i in (a))log(1 ? p i out (a)) )<label>(7)</label></formula><p>p i in (a) is the probability that the activation pattern for s i is a, and p i out (a) is the probability that s i with pattern a is feasible. By minimizing L tp , the search stage is aware of the topology constraints and encourages all super nodes to be topologically feasible, thus reduce the gap caused by topology constraints in the discretization step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Memory Budget Constraints</head><p>The searched model is usually retrained under different training settings like patch size, filter number, or tasks. Auto-DeepLab <ref type="bibr" target="#b20">[21]</ref> used 4? larger image patch and 6? more filters in retraining compared to the search stage. But this can cause out of memory problem for 3D images in retraining, thus we consider memory budget in architecture search. A cell's expected memory usage is estimated by M i,e = N n=1 ? i,e n M n . M n is the memory usage of operation O n (estimated by tensor size <ref type="bibr" target="#b9">[10]</ref>) defined in Sec. 3.2. The expected memory usage M e of the searched model is:</p><formula xml:id="formula_8">M e = L i=1 M j=1 ? i j * ( E e=1 M i,e * cp j (e))<label>(8)</label></formula><p>Similar to <ref type="bibr" target="#b18">[19]</ref>, we consider the budget as the percentage ? of the maximum memory usage M a , of which all ? and ? equal to one.</p><formula xml:id="formula_9">M a = L i=1 M j=1 * ( E e=1 ( N n=1 M n ) * cp j (e))<label>(9)</label></formula><p>L m = |M e /M a ? ?| 1 (10)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Optimization</head><p>We adopt the same optimization strategy as in DARTS <ref type="bibr" target="#b22">[23]</ref> and Auto-DeepLab <ref type="bibr" target="#b20">[21]</ref>. We partition the training set into train1 and train2, and optimize the network weights w (e.g. convolution kernels) using L seg on train1 and network architecture weights ? and p e using L arch on train2 alternately. The loss L seg for w is the evenly sum of dice and cross-entropy loss <ref type="bibr" target="#b44">[45]</ref> in segmentation, while</p><formula xml:id="formula_10">L arch = L seg + t/t all * (L ? + L ? + ? * L tp + L m ) (11)</formula><p>t and t all are the current and total iterations for architecture optimization such that the searching is focusing more on L seg at the starting point. We empirically scale L tp to the same range with other losses by setting ?=0.001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We conduct experiments on the MSD dataset <ref type="bibr" target="#b36">[37]</ref> which is a comprehensive benchmark for medical image segmentation. It contains ten segmentation tasks covering different anatomies of interest, modalities and imaging sources (institutions) and is representative for real clinical problems. Recent C2FNAS <ref type="bibr" target="#b44">[45]</ref> reaches state-of-the-art results on MSD dataset using NAS based methods. We follow its experiment settings by searching on the MSD Pancreas dataset and deploying the searched model on all 10 MSD tasks for better comparison. All images are resampled to have a 1.0 ? 1.0 ? 1.0 mm 3 voxel resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Details</head><p>Our search space has L=12 layers and D=4 resolution levels as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. The stem cell at scale 1 has 16 filters and we double the filter number when decreasing the spatial size by half in each axis. The search is conducted on Pancreas dataset following the same 5 fold data split (4 for training and last 1 for validation) as C2FNAS <ref type="bibr" target="#b44">[45]</ref>. We use SGD optimizer with momentum 0.9, weight decay of 4e-5 for network weights w. We train w for the first one thousand (1k) warm-up and following 10k iterations without updating architecture. The architecture weights ?, p e are initialized with Gaussian N (1, 0.01), N (0, 0.01) respectively before softmax and sigmoid. In the following 10k iterations, we jointly optimize w with SGD and ?, p e with Adam optimizer <ref type="bibr" target="#b15">[16]</ref> (learning rate 0.008, weight decay 0). The learning rate of SGD linearly increases from 0.025 to 0.2 in the first 1k warm-up iterations, and decays with factor 0.5 at the following [8k, 16k] iterations. The search is conducted on 8 GPUs with batch size 8 (each GPU with one 96?96?96 patch). The patches are randomly augmented with 2D rotation by <ref type="bibr">[90,</ref><ref type="bibr">180,</ref><ref type="bibr">270]</ref> degrees in the x-y plane and flip in all three axis. The total training iterations, SGD learning rate scheduler and data pre-processing and augmentation are the same with C2FNAS <ref type="bibr" target="#b44">[45]</ref>. After searching, the discretized model is randomly initialized and retrained with doubled filter number and doubled batch size to match C2FNAS <ref type="bibr" target="#b44">[45]</ref>'s setting. We use the SGD optimizer with 1k warm-up and 40k training iterations and decay the learning rate by a factor of 0.5 at [8k, 16k, 24k, 32k] iterations after warm-up. The learning rate scheduler is the same with search stage in the warm-up and the first 20k iterations. The latter 20k iterations are for better convergence and match the 40k total retraining iterations used in C2FNAS <ref type="bibr" target="#b44">[45]</ref>. The same data augmentation as C2FNAS (also the same as the search stage) is used for the Pancreas dataset for better comparison. To test the generalizability of the searched model, we retrain the model on all of the rest nine tasks. Some tasks in the MSD dataset contain very few training data so we use additional basic 2D data augmentations of random rotation, scaling and gamma correction for all nine tasks. We use </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Pancreas Dataset Search Results</head><p>The search takes 5.8 GPU days while C2FNAS takes 333 GPU days on the same dataset (both using 8 16GB V100 GPU). We vary the memory constraints ? = [0.2, 0.5, 0.8] and show the search results in <ref type="figure">Fig. 7</ref>. The searched models have highly flexible topology which are searched jointly with the cell level. The 5-fold cross-validation results on Pancreas are shown in <ref type="table" target="#tab_0">Table 1</ref>. By increasing ?, the searched model is more "dense in connection" and can achieve better performance while requiring more GPU memory (estimated using PyTorch <ref type="bibr" target="#b28">[29]</ref> functions in training described in Sec. 4.1). The marginal performance drop by decreasing ? = 0.8 to ? = 0.5 shows that we can reduce memory usage without losing too much accuracy. Although techniques like mixed-precision training <ref type="bibr" target="#b24">[25]</ref> can be used to further reduce memory usage, our memory aware search tries to solve this problem from NAS perspective. Compared to nnUNet <ref type="bibr" target="#b13">[14]</ref> (represented by 3D UNet because it ensembles 2D/3D/cascaded-3D U-Net differently for each task) and C2FNAS in <ref type="table" target="#tab_0">Table 1</ref>, our searched models have no advantage in FLOPs and Parameters which are important in mobile settings. We argue that for medical image analysis, light model and low latency are less a focus than better GPU memory usage and accuracy. Our DiNTS can optimize the usage of the available GPU and achieve better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Segmentation Results on MSD</head><p>The searched model with ? = 0.8 from Pancreas is used for retraining and testing on all ten tasks of MSD dataset. Similar to the model ensemble used in nnUNet <ref type="bibr" target="#b13">[14]</ref> and C2FNAS <ref type="bibr" target="#b44">[45]</ref>, we use a 5 fold cross validation for each task and ensemble the results using majority voting. The largest connected component post-processing in nnUNet <ref type="bibr" target="#b13">[14]</ref> is also applied. The Dice-S?rensen (DSC) and Normalised Surface Distance (NSD) as used in the MSD challenge are reported for the test set in <ref type="table">Table 2</ref>. nnUNet <ref type="bibr" target="#b13">[14]</ref> uses extensive data augmentation, different hyper-parameters like patch size, batch size for each task and ensembles networks with different architectures. It focuses on hyperparameter selection based on hand-crafted rules and is the champion of multiple medical segmentation challenges including MSD. Our method and C2FNAS <ref type="bibr" target="#b44">[45]</ref> focus on architecture search and use consistent hyper-parameters and basic augmentations for all ten tasks. We achieved better results than C2FNAS <ref type="bibr" target="#b44">[45]</ref> in all tasks with similar hyperparameters while only takes 1.7% searching time. Comparing to nn-UNet <ref type="bibr" target="#b13">[14]</ref>, we achieve much better performance on challenging datasets like Pancrease, Brain and Colon, while worse on smaller datasets like Heart (10 test cases), Prostate (16 test cases) and Spleen (20 test cases). Task-specific hyper-parameters, test-time augmentation, extensive data augmentation and ensemble more models as used in nn-UNet <ref type="bibr" target="#b13">[14]</ref> might be more effective on those small datasets than our unified DiNTS searched architecture. Overall, we achieved the best average results and top ranking in the MSD challenge leaderboard, showing that a non-UNet based topology can achieve superior performance in medical imaging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Search on Different Datasets</head><p>The models in Sec. <ref type="bibr" target="#b3">4</ref>  <ref type="table">Table 3</ref>. Dice-S?rensen score (DSC) of 5-fold cross validation on Brain, Liver and Lung datasets of architectures searched from Pancreas, Brain, Liver and Lung datasets with ? = 0.8.</p><p>and Lung (64 CT data) covering big, medium and small datasets. The results are shown in <ref type="table">Table.</ref> 3 and demonstrate the good generalizability of our DiNTS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Necessity of Topology Loss</head><p>As illustrated in Sec. 1, the discretization algorithm discards topologically infeasible edges (even with large probabili- ties), which causes a gap between feature flow in the optimized continuous model (Eq. 1) and the discrete model. Our topology loss encourages connections with large probabilities to be feasible, thus will not be discarded and causing the gap. We denote C max as the topology decoded by selecting connection j with largest ? i j for each layer i (can be infeasible). C top is the topology decoded by our discretization algorithm. C max , C top are the indication matrices of size [L, E] representing whether an edge is selected, and G = L i=1 E e=1 |C max (i, e) ? C top (i, e)|. Larger G represents larger gap between the feature flow before and after discretization. <ref type="figure">Fig. 8</ref> shows the change of G during search with/without topology loss under different memory constraints. With topology loss, the gap between C max and C top is reduced, and it's more crucial for smaller ? where the searched architecture is more sparse and more likely to have topology infeasibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, we present a novel differentiable network topology search framework (DiNTS) for 3D medical image segmentation. By converting the feature nodes with varying spatial resolution into super nodes, we are able to focus on connection patterns rather than individual edges, which enables more flexible network topologies and a discretization aware search framework. Medical image segmentation challenges have been dominated by U-Net based architectures <ref type="bibr" target="#b13">[14]</ref>, even NAS-based C2FNAS is searched within a U-shaped space. DiNTS's topology search space is highly flexible and achieves the best performance on the benchmark MSD challenge using non-UNet architectures, while only taking 1.7% search time compared to C2FNAS. Since directly converting Auto-DeepLab <ref type="bibr" target="#b20">[21]</ref> to the 3D version will have memory issues, we cannot fairly compare with it. For future work, we will test our proposed algorithm on 2D natural image segmentation benchmarks and explore more complex cells.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Limitations of existing differentiable topology search formulation. E.g.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Our search space contains L=12 layers. The blue edges are the stem containing pre-defined operations. The cell operations are defined on the edges while the nodes are feature maps. Edges in the topology search space that are selected for features to flow from input to output form a candidate network topology. Each edge in the search space includes a cell which contains O=5 operations to select from. A downsample/upsample edge also contains a 2? downsample/upsample operation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Our search space covers a variety of topologies (singlepath, multi-path) and can select input resolutions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>??Figure 4 .</head><label>4</label><figDesc>select one from , , ? , with probability , , ? ,Original SequentialThe feature nodes at the same layer i are combined as a super node si. A set of selected edges (e.g. red edges in a dashed yellow block) that connects si?1 and si is a "connection". For E edges, there are M = 2 E ? 1 connection patterns. Topology search becomes selecting one connection pattern to connect adjacent super nodes sequentially.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Left: The gray feature nodes are topologically infeasible, thus connection pattern index k is not in j's feasible set, k / ? F(j).Right: A directed graph G which contains L?M +2 nodes. A node c i j (yellow block) is connected with c i+1 k and c i?1 m if j ? F(m) and k ? F(j).The cost of edges directed to c i j is -log? i j . The source connects to all first layer nodes and all L-th layer nodes connect to the sink (edge cost is a constant value). Those L nodes on the shortest path from source to sink (red path) in G represent the optimal feasible connection operations (final architecture).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>The connection patterns in Fin(a) activates pattern a, and all feasible output connection patterns are in Fout(a). a = [0, 1, 1] means the last two nodes of the super-node are activated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>8 Figure 8 .</head><label>88</label><figDesc>The indication G of discretization gap during architecture search with different memory constraints ?. With topology loss (dashed line), G is decreased compared to no topology loss (solid line), showing the importance of topology loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of FLOPs, Parameters and Retraining GPU memory usage and the 5-Fold cross validation Dice-S?rensen score of our searched architectures on Pancreas dataset Figure 7. Searched architectures (not including the stem in Fig. 2) on Pancreas dataset with varying memory constraints.patch size 96 ? 96 ? 96 and stride 16 ? 16 ? 16 for all ten tasks except Prostate and Hippocampus. Prostate data has very few slices (less than 40) in the z-axis, so we use patch size 96 ? 96 ? 32 and stride 16 ? 16 ? 4. Hippocampus data size is too small (around 36 ? 50 ? 35) and we use patch size 32 ? 32 ? 32 and stride 4 ? 4 ? 4. Post-processing with largest connected component is also applied.</figDesc><table><row><cell cols="2">Model</cell><cell></cell><cell cols="3">FLOPs (G)</cell><cell>Params. (M)</cell><cell cols="2">Memory (MB)</cell><cell cols="4">DSC1 DSC2 Avg.</cell></row><row><cell cols="4">3D UNet [6] (nn-UNet)</cell><cell>658</cell><cell></cell><cell>18</cell><cell>9176</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell></row><row><cell cols="4">Attention UNet [28]</cell><cell>1163</cell><cell></cell><cell>104</cell><cell cols="2">13465</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell></row><row><cell cols="3">C2FNAS [45]</cell><cell></cell><cell>151</cell><cell></cell><cell>17</cell><cell>5730</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell></row><row><cell cols="3">DiNTS (?=0.2)</cell><cell></cell><cell>146</cell><cell></cell><cell>163</cell><cell>5787</cell><cell></cell><cell cols="4">77.94 48.07 63.00</cell></row><row><cell cols="3">DiNTS (?=0.5)</cell><cell></cell><cell>308</cell><cell></cell><cell>147</cell><cell cols="2">10110</cell><cell cols="4">80.20 52.25 66.23</cell></row><row><cell cols="3">DiNTS (?=0.8)</cell><cell></cell><cell>334</cell><cell></cell><cell>152</cell><cell cols="2">13018</cell><cell cols="4">80.06 52.53 66.29</cell></row><row><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell><cell>12</cell></row><row><cell></cell><cell></cell><cell>Skip</cell><cell>3x3x3</cell><cell></cell><cell cols="2">P3D 3x3x1</cell><cell cols="2">P3D 3x1x3</cell><cell></cell><cell cols="2">P3D 1x3x3</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="9">(a) Searched architecture with ? = 0.8</cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell><cell>12</cell></row><row><cell></cell><cell></cell><cell>Skip</cell><cell>3x3x3</cell><cell></cell><cell cols="2">P3D 3x3x1</cell><cell cols="2">P3D 3x1x3</cell><cell></cell><cell cols="2">P3D 1x3x3</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="9">(b) Searched architecture with ? = 0.5</cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell><cell>12</cell></row><row><cell></cell><cell></cell><cell>Skip</cell><cell>3x3x3</cell><cell></cell><cell cols="2">P3D 3x3x1</cell><cell cols="2">P3D 3x1x3</cell><cell></cell><cell cols="2">P3D 1x3x3</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="9">(c) Searched architecture with ? = 0.2</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>.2 and Sec. 4.3 are searched from the Pancreas dataset (282 CT 3D training images). To test the generalizability of DiNTS, we perform the same search as in Sec. 4.1 on Brain (484 MRI data), Liver (131 CT data) Brain Metric DSC1 DSC2 DSC3 Avg. NSD1 NSD2 NSD3 Avg. CerebriuDIKU [30] 69.52 43.11 66.74 59.79 88.25 68.98 88.90 82.04 NVDLMED [41] 67.52 45.00 68.01 60.18 86.99 69.77 89.82 82.19 Kim et al [15] 67.40 45.75 68.26 60.47 86.65 72.03 90.28 82.99 nnUNet [14] 68.04 46.81 68.46 61.10 87.51 72.47 90.78 83.59 C2FNAS [45] 67.62 48.60 69.72 61.98 87.61 72.87 91.16 83.88 DiNTS 69.28 48.65 69.75 62.56 89.33 73.16 91.69 84.73 ] 71.23 24.98 48.11 91.57 46.43 69.00 67.01 77.86 NVDLMED [41] 77.97 44.49 61.23 94.43 63.45 78.94 72.78 83.26 Kim et al [15] 80.61 51.75 66.18 95.83 73.09 84.46 74.34 85.12 nnUNet [14] 81.64 52.78 67.21 96.14 71.47 83.81 77.89 88.09 C2FNAS [45] 80.76 54.41 67.59 96.16 75.58 85.87 76.97 87.83 DiNTS 81.02 55.35 68.19 96.26 75.90 86.08 77.93 88.68 Table 2. Dice-S?rensen score (DSC) and Normalised Surface Distance (NSD) results on the MSD test dataset (numbers from MSD challenge live leaderboard).</figDesc><table><row><cell></cell><cell>Heart</cell><cell></cell><cell></cell><cell cols="2">Liver</cell><cell></cell></row><row><cell>Metric</cell><cell cols="3">DSC1 NSD1 DSC1 DSC2</cell><cell>Avg.</cell><cell cols="3">NSD1 NSD2 Avg.</cell></row><row><cell cols="4">CerebriuDIKU [30] 89.47 90.63 94.27 57.25</cell><cell>75.76</cell><cell cols="3">96.68 72.60 84.64</cell></row><row><cell>NVDLMED [41]</cell><cell cols="3">92.46 95.57 95.06 71.40</cell><cell>83.23</cell><cell cols="3">98.26 87.16 92.71</cell></row><row><cell>Kim et al [15]</cell><cell cols="7">93.11 96.44 94.25 72.96 83.605 96.76 88.58 92.67</cell></row><row><cell>nnUNet [14]</cell><cell cols="3">93.30 96.74 95.75 75.97</cell><cell>85.86</cell><cell cols="3">98.55 90.65 94.60</cell></row><row><cell>C2FNAS [45]</cell><cell cols="3">92.49 95.81 94.98 72.89</cell><cell>83.94</cell><cell cols="3">98.38 89.15 93.77</cell></row><row><cell>DiNTS</cell><cell cols="3">92.99 96.35 95.35 74.62</cell><cell>84.99</cell><cell cols="3">98.69 91.02 94.86</cell></row><row><cell></cell><cell>Lung</cell><cell></cell><cell></cell><cell cols="2">Hippocampus</cell><cell></cell></row><row><cell>Metric</cell><cell cols="7">DSC1 NSD1 DSC1 DSC2 Avg. NSD1 NSD2 Avg.</cell></row><row><cell cols="8">CerebriuDIKU [30] 58.71 56.10 89.68 88.31 89.00 97.42 97.42 97.42</cell></row><row><cell>NVDLMED [41]</cell><cell cols="7">52.15 50.23 87.97 86.71 87.34 96.07 96.59 96.33</cell></row><row><cell>Kim et al [15]</cell><cell cols="7">63.10 62.51 90.11 88.72 89.42 97.77 97.73 97.75</cell></row><row><cell>nnUNet [14]</cell><cell cols="7">73.97 76.02 90.23 88.69 89.46 97.79 97.53 97.66</cell></row><row><cell>C2FNAS [45]</cell><cell cols="7">70.44 72.22 89.37 87.96 88.67 97.27 97.35 97.31</cell></row><row><cell>DiNTS</cell><cell cols="7">74.75 77.02 89.91 88.41 89.16 97.76 97.56 97.66</cell></row><row><cell></cell><cell>Spleen</cell><cell></cell><cell></cell><cell cols="2">Prostate</cell><cell></cell></row><row><cell>Metric</cell><cell cols="7">DSC1 NSD1 DSC1 DSC2 Avg. NSD1 NSD2 Avg.</cell></row><row><cell cols="8">CerebriuDIKU [30] 95.00 98.00 69.11 86.34 77.73 94.72 97.90 96.31</cell></row><row><cell>NVDLMED [41]</cell><cell cols="7">96.01 99.72 69.36 86.66 78.01 92.96 97.45 95.21</cell></row><row><cell>Kim et al [15]</cell><cell cols="7">91.92 94.83 72.64 89.02 80.83 95.05 98.03 96.54</cell></row><row><cell>nnUNet [14]</cell><cell cols="7">97.43 99.89 76.59 89.62 83.11 96.27 98.85 97.56</cell></row><row><cell>C2FNAS [45]</cell><cell cols="7">96.28 97.66 74.88 88.75 81.82 98.79 95.12 96.96</cell></row><row><cell>DiNTS</cell><cell cols="7">96.98 99.83 75.37 89.25 82.31 95.96 98.82 97.39</cell></row><row><cell></cell><cell>Colon</cell><cell></cell><cell></cell><cell cols="2">Hepatic Vessels</cell><cell></cell></row><row><cell>Metric</cell><cell cols="3">DSC1 NSD1 DSC1 DSC2</cell><cell>Avg.</cell><cell cols="2">NSD1 NSD2</cell><cell>Avg.</cell></row><row><cell cols="4">CerebriuDIKU [30] 28.00 43.00 59.00 38.00</cell><cell>48.50</cell><cell cols="2">79.00 44.00</cell><cell>61.50</cell></row><row><cell>NVDLMED [41]</cell><cell cols="3">55.63 66.47 61.74 61.37</cell><cell>61.56</cell><cell cols="2">81.61 68.82</cell><cell>75.22</cell></row><row><cell>Kim et al [15]</cell><cell cols="7">49.32 62.21 62.34 68.63 65.485 83.22 78.43 80.825</cell></row><row><cell>nnUNet [14]</cell><cell cols="3">58.33 68.43 66.46 71.78</cell><cell>69.12</cell><cell cols="2">84.43 80.72</cell><cell>82.58</cell></row><row><cell>C2FNAS [45]</cell><cell cols="3">58.90 72.56 64.30 71.00</cell><cell>67.65</cell><cell cols="2">83.78 80.66</cell><cell>82.22</cell></row><row><cell>DiNTS</cell><cell cols="3">59.21 70.34 64.50 71.76</cell><cell>68.13</cell><cell cols="2">83.98 81.03</cell><cell>82.51</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Pancreas</cell><cell></cell><cell></cell><cell cols="2">Overall</cell></row><row><cell>Metric</cell><cell cols="5">DSC1 DSC2 Avg. NSD1 NSD2 Avg.</cell><cell cols="2">DSC NSD</cell></row><row><cell>CerebriuDIKU [30Test Dataset</cell><cell cols="2">Brain</cell><cell cols="2">Liver</cell><cell></cell><cell>Lung</cell></row><row><cell cols="8">Search Dataset Brain Pancreas Liver Pancreas Lung Pancreas</cell></row><row><cell>DSC1</cell><cell>80.20</cell><cell>79.68</cell><cell>94.15</cell><cell>94.12</cell><cell>69.30</cell><cell cols="2">68.90</cell></row><row><cell>DSC2</cell><cell>61.09</cell><cell>60.67</cell><cell>58.74</cell><cell>57.86</cell><cell>-</cell><cell></cell><cell>-</cell></row><row><cell>DSC3</cell><cell>77.63</cell><cell>77.48</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell></row><row><cell>Avg.</cell><cell>72.97</cell><cell>72.61</cell><cell>76.44</cell><cell>75.99</cell><cell>69.30</cell><cell cols="2">68.90</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<title level="m">Proxylessnas: Direct neural architecture search on target task and hardware. ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Fasterseg: Searching for faster real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1294" to="1303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Fair darts: Eliminating unfair advantages in differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.12126</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>?zg?n ? I?ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soeren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ronneberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="424" to="432" />
		</imprint>
	</monogr>
	<note>3d u-</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A note on two problems in connexion with graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Edsger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dijkstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numerische mathematik</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="269" to="271" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Neural architecture search: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Hendrik</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Densely connected search space for more flexible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiemin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10628" to="10637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Estimating gpu memory consumption of deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjie</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengxian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mao</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-05" />
			<pubPlace>Microsoft</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Huan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shao-Ping</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.00969</idno>
		<title level="m">Dots: Decoupling operation and topology in differentiable architecture search</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dsnas: Direct neural architecture search without parameter retraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoukang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xunying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12084" to="12092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Automated design of deep learning methods for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>J?ger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><forename type="middle">H</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08128</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scalable neural architecture search for 3d medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwoong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ildoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungbin</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woonhyuk</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiheon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyungjoo</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boogeon</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="220" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">H-denseunet: hybrid densely connected unet for liver and tumor segmentation from ct volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaomeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>TMI</publisher>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="2663" to="2674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Partial order pruning: for best speed/accuracy trade-off in neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9145" to="9153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning dynamic routing for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8553" to="8562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Refinenet: Multi-path refinement networks for highresolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Autodeeplab: Hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="82" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Progressive neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="19" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Darts: Differentiable architecture search. ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Memnas: Memory-efficient neural architecture search with growtrim learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiye</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huadong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingoo</forename><surname>Seok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2108" to="2116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paulius</forename><surname>Micikevicius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonah</forename><surname>Alben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Venkatesh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>et al. Mixed precision training. ICLR</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">V-net: Fully convolutional neural networks for volumetric medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fausto</forename><surname>Milletari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seyed-Ahmad</forename><surname>Ahmadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>IEEE</publisher>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="565" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Xnas: Neural architecture search with expert advice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Nayman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asaf</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Ridnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itamar</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihi</forename><surname>Zelnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Oktay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo</forename><surname>Schlemper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><forename type="middle">Le</forename><surname>Folgoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mattias</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazunari</forename><surname>Misawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kensaku</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Mcdonagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nils</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Hammerla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kainz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>et al. Attention u-net: Learning where to look for the pancreas. MIDL</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8026" to="8037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">One network to segment them all: A general, lightweight system for accurate 3d medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Perslev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Bj?rnager Dam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="30" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Efficient neural architecture search via parameter sharing. ICML</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Melody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning spatiotemporal representation with pseudo-3d residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaofan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5533" to="5541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the aaai conference on artificial intelligence</title>
		<meeting>the aaai conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4780" to="4789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Squeezenas: Fast neural architecture search for faster semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Forrest</forename><surname>Landola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sammy</forename><surname>Sidhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV Workshops</title>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">A large annotated medical image dataset for the development and evaluation of segmentation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Amber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michela</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyridon</forename><surname>Antonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Bakas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyvan</forename><surname>Bilello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bram</forename><surname>Farahani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annette</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kopp-Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geert</forename><surname>Bennett A Landman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Menze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09063</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjie</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.03154</idno>
		<title level="m">Discretization-aware architecture search</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.08022</idno>
		<title level="m">stance normalization: The missing ingredient for fast stylization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Nasunet: Neural architecture search for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="44247" to="44257" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Alan Yuille, and Holger Roth. 3d semi-supervised learning with uncertainty-aware multi-view co-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingda</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinzheng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lequan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daguang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3646" to="3655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Exploring randomly wired neural networks for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1284" to="1293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Pc-darts: Partial channel connections for memory-efficient differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Ms-nas: Multi-scale neural architecture search for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiyu</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Zhuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="388" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">C2FNAS: Coarseto-Fine Neural Architecture Search for 3D Medical Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qihang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daguang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4126" to="4135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Unet++: Redesigning skip connections to exploit multiscale features in image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md</forename><surname>Mahfuzur Rahman Siddiquee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianming</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMI</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1856" to="1867" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">V-nas: Neural architecture search for volumetric medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daguang</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IEEE</publisher>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="240" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8697" to="8710" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
