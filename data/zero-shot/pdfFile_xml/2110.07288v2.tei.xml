<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">View Vertically: A Hierarchical Network for Trajectory Prediction via Fourier Spectrums</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Conghao</forename><surname>Wong</surname></persName>
							<email>conghaowong@hust.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beihao</forename><surname>Xia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziming</forename><surname>Hong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinmu</forename><surname>Peng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiong</forename><surname>Cao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">JD Explore Academy</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibo</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">JD Explore Academy</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinge</forename><surname>You</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">View Vertically: A Hierarchical Network for Trajectory Prediction via Fourier Spectrums</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T07:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Hierarchical Trajectory Prediction, Fourier Spectrums</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Understanding and forecasting future trajectories of agents are critical for behavior analysis, robot navigation, autonomous cars, and other related applications. Previous methods mostly treat trajectory prediction as time sequence generation. Different from them, this work studies agents' trajectories in a "vertical" view, i.e., modeling and forecasting trajectories from the spectral domain. Different frequency bands in the trajectory spectrums could hierarchically reflect agents' motion preferences at different scales. The low-frequency and high-frequency portions could represent their coarse motion trends and fine motion variations, respectively. Accordingly, we propose a hierarchical network V 2 -Net, which contains two sub-networks, to hierarchically model and predict agents' trajectories with trajectory spectrums. The coarse-level keypoints estimation sub-network first predicts the "minimal" spectrums of agents' trajectories on several "key" frequency portions. Then the finelevel spectrum interpolation sub-network interpolates the spectrums to reconstruct the final predictions. Experimental results display the competitiveness and superiority of V 2 -Net on both ETH-UCY benchmark and the Stanford Drone Dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Trajectory prediction aims at inferring agents' possible future trajectories considering potential influencing factors. It has been an essential but challenging task, which can be widely applied to behavior analysis <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b39">40]</ref>, robot navigation <ref type="bibr" target="#b48">[49]</ref>, autonomous driving <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b22">23]</ref>, tracking <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b43">44]</ref>, detection <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b34">35]</ref>, and many other computer vision tasks <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b53">54]</ref>. Researchers have widely studied interactive factors, including the agent-agent interaction <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14]</ref> and the agent-scene interaction <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b42">43]</ref>. Another line of researchers have explored creative ways to model trajectories. Neural networks like Long-Short Term Memory Networks (LSTMs) <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b55">56]</ref>, Graph Convolution Networks (GCNs) <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b56">57]</ref>, and Transformers (a) (b) <ref type="figure">Fig. 1</ref>. V 2 -Net Motivation. (a) We show the trajectory in two views, the time sequences view and the Fourier spectrums view. The x-axis trajectory (green dots) and the y-axis trajectory (yellow dots) have similar "shapes", while they are quite different in the spectrum views (shown with amplitudes and phases), which motivates us to view trajectories "vertically" with spectrums rather than time sequences. (b) shows a trajectory with interactions. We utilize the first n/N low-frequency portions to reconstruct the trajectory, and the results show that different frequency portions have different contributions to their global plannings and interactive preferences. <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b57">58]</ref> are employed to encode agents' trajectories. Some researchers have also studied agents' multi-modal characteristics <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17]</ref> and the distributions of their goals <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b40">41]</ref>, thus forecasting multiple future choices. However, most previous methods treat trajectory prediction as time sequence generation and predict trajectories recurrently, which could be challenging to reflect agents' motion preferences at different scales hierarchically. In other words, researchers usually tend to explore agents' behaviors and their changing trends dynamically but lack the overall analyses at different temporal scales. In fact, pedestrians always plan their activities at different levels simultaneously. For example, they may first determine their coarse motion trends and then make fine decisions to interactive variations. Although some methods <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b58">59]</ref> employ neural networks with attention mechanisms (like Transformers) as the backbone to model agents' status, they may still be difficult to directly represent agents' detailed motion differences at different temporal scales.</p><p>The Fourier transform (FT) and its variations have significantly succeeded in the signal processing community. Recently, researchers have also introduced FTs to some computer vision tasks, such as image de-noising <ref type="bibr" target="#b20">[21]</ref>, edge extraction <ref type="bibr" target="#b18">[19]</ref>, and image super-resolution <ref type="bibr" target="#b5">[6]</ref>. FTs decompose sequential inputs into a series of sinusoids with different amplitudes and phases on different frequencies. Furthermore, these sinusoids could reflect the differentiated frequency response characteristics at different frequency scales, which could be difficult to obtain directly in the original signal. They provide a "vertical" view for processing and analyzing sequences, thus presenting elusive features in the original signals.</p><p>Some researchers have applied FTs in tasks similar to trajectory prediction. For example, Mao et al. <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b31">32]</ref> employ the discrete cosine transform (DCT) to help predict human motions. Cao et al. <ref type="bibr" target="#b2">[3]</ref> use the graph Fourier transform to attempt to model interaction series in trajectory prediction. Unfortunately, FTs have not been employed to model trajectories in the trajectory prediction task directly. Inspired by the successful use of FTs, we try to employ the Discrete Fourier Transform (DFT) to obtain trajectory spectrums to capture agents' detailed motion preferences at different frequency scales. <ref type="figure">Fig.1(a)</ref> demonstrates an agent's two-dimensional trajectory in the time series and spectrum view, respectively. Although the two projection trajectories have similar shapes, they show considerable differences in the spectrum view. It means that the trajectory spectrums (including amplitudes and phases) obtained through FTs could reflect subtle differences that are difficult to discern within the time series.</p><p>Furthermore, some works have divided trajectory prediction into a two-stage pipeline, which we call the hierarchical prediction strategy. <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b29">30]</ref> divide this two-stage process into destination prediction and destination-controlled prediction. <ref type="bibr" target="#b28">[29]</ref> introduces several "waypoints" to help predict agents' potential intentions rather than the only destination point. FTs decompose time series into the combination of different frequency portions. Inspired by these hierarchical approaches, a natural thought is to hierarchically predict agents' trajectories on different frequency scales, including: (a) Global Plannings, i.e., agents' coarse motion trends. The low-frequency portions (slow-changing portions) in the trajectory spectrums could reflect their plannings globally. (b) Interactive Preferences, i.e., agents' detailed interactions. The high-frequency portions (fast-changing portions) in the spectrums will directly show the rapidly changing movement rules, thus further describing their personalized interactive preferences. <ref type="figure">Fig.1</ref>(b) demonstrates the trajectory reconstructed by different number of frequency portions. Agent's overall plannings could be reconstructed through a few low-frequency portions of the trajectory spectrum. By continually adding new high-frequency portions, the reconstructed trajectory would be able to reflect finer motion details and interactive preferences. Accordingly, we introduce a "coarse-fine" strategy to hierarchically model global plannings and interactive preferences by trajectory spectrums at different levels correspondingly.</p><p>In this paper, we propose the V 2 -Net to hierarchically forecast trajectories in the spectrum view. It contains two sub-networks. The coarse-level keypoints estimation sub-network first predicts the "minimal" spectrums of agents' trajectories on several "key" frequency portions, and then the fine-level spectrum interpolation sub-network interpolates the spectrums to reconstruct the final predictions. Meanwhile, agents' social and scene interactions will also be concerned to make the network available to give predictions that conform to social rules and physical constraints. Our contributions are list as follows:</p><p>-We introduce the Fourier Transform to model and predict trajectories with spectrums to better capture agents' behaviors from a different perspective. -A Transformer-based V 2 -Net containing coarse-level keypoints estimation and fine-level spectrum interpolation sub-networks is proposed to model and predict trajectories "coarse-to-fine" hierarchically.</p><p>-Experiments demonstrate that V 2 -Net achieves competitive performance on both ETH-UCY benchmark and the Stanford Drone Dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Trajectory Prediction. Recently, researchers have studied how interactive factors affect agents' trajectory plans, like social interaction <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b59">60]</ref> and scene interaction <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b55">56]</ref>. The modeling of agents' trajectories also matters how the trajectory prediction networks perform. Alahi et al. <ref type="bibr" target="#b0">[1]</ref> treat this task as a sequence generation problem, and they employ LSTMs to model and predict pedestrians' positions in the next time step recurrently. A series of works have also introduced Graph Neural Networks (GNNs), e.g. Graph Attention Networks (GATs) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b26">27]</ref> and GCNs <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b35">36]</ref>, to handle interactive factors when forecasting. Moreover, the attention mechanism has been employed <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b59">60]</ref> to focus on the most valuable interactive targets to give reasonable predictions. With the success of Transformers <ref type="bibr" target="#b49">[50]</ref> in sequence processing such as natural language processing, researchers <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b57">58]</ref> have employed Transformers to obtain better feature representations. Some researchers address agents' uncertainty and randomness by introducing generative models. Generative Adversarial Networks (GANs) are employed in <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b21">22]</ref> to generate multiple stochastic trajectories to suit agents' various future choices. Some works like <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b44">45]</ref> use the Conditional Variation AutoEncoder (CVAE) to achieve the similar goal.</p><p>Applications of Fourier Transforms. Many approaches achieve better performance in different computer vision tasks by introducing FTs. Cheng et al. <ref type="bibr" target="#b5">[6]</ref> present a Fast Fourier Transform-based algorithm, which brings high computational efficiency and reliability for the multichannel interpolation in image superresolution. Kaur et al. <ref type="bibr" target="#b18">[19]</ref> propose a Fractional Fourier Transform based Riesz fractional derivative approach for edge detection and apply it to enhance images. Komatsu et al. <ref type="bibr" target="#b20">[21]</ref> construct the 3-D mean-separation-type short-time DFT and apply it to denoise moving images. It is worth noting that FTs have been widely applied in handling time-series forecasting problems. Mao et al. <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref> employ DCT to help predict human skeleton-graphs in motion forecasting. Cao et al. <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b2">3]</ref> propose spectral temporal graph to model interaction series (not trajectories) in trajectory forecasting. Forecasting trajectories could also be regarded as one of the time-series forecasting tasks <ref type="bibr" target="#b0">[1]</ref>. The successful use of FTs motivates us to model agents' trajectories in the Fourier domain, therefore trying to obtain better representations. Unfortunately, there seems to be no method that directly uses FTs to describe agents' trajectories in the field of trajectory prediction. This paper attempts to model and forecast agents' trajectories in the spectrum view for the first time.</p><p>Hierarchical Trajectory Prediction. More and more researchers <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b40">41]</ref> have treated trajectory prediction as a "two-stage" problem and predict trajectories hierarchically. Some researchers divide this process into "destination prediction" and "destination-controlled prediction". Mangalam et al. <ref type="bibr" target="#b29">[30]</ref> infer trajectory endpoints to assist in long-range multi-modal trajectory prediction.</p><p>Tran et al. <ref type="bibr" target="#b47">[48]</ref> attempt to obtain multi-modal goal proposals from the additional goal channel to generate multiple predictions. Wong et al. <ref type="bibr" target="#b51">[52]</ref> use a set of generators to give destination proposals with different styles, and then interpolate to forecast multiple future predictions. Others like <ref type="bibr" target="#b28">[29]</ref> also introduce several "waypoints" to help better predict agents' potential future intentions rather than the only destination points. These hierarchical approaches concern more on factor "destination" (or "waypoints") and "predictions". Considering the Fourier transforms could decompose time series into the combination of different frequency portions, a natural thought is to predict agents' future trajectories hierarchically on different frequency scales. Therefore, these two-stage factors may become the "low-frequency-portions" and "high-frequency-portions" for trajectory spectrums. It motivates us to forecast trajectories from coarse global plannings to fine interactive preferences with trajectory spectrums hierarchically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>As shown in <ref type="figure" target="#fig_0">Fig.2</ref>, V 2 -Net has two main sub-networks, the coarse-level keypoints estimation sub-network and the fine-level spectrum interpolation sub-network.</p><p>Formulations. Let p t = (x t , y t ) ? R 2 denote the two-dimensional coordinates of one agent at step t. Given a video clip {I} that contains M agents' observed</p><formula xml:id="formula_0">trajectories {X i } M i=1 (X i = (p 1 , p 2 , .</formula><p>.., p t h ) T represents i-th agent's observed trajectory) during the observation period, trajectory prediction aims to forecast their possible future coordinates</p><formula xml:id="formula_1">{? i } M i=1 (? i = (p t h +1 ,p t h +2 , .</formula><p>..,p t h +t f ) T denotes one of the prediction) during the corresponding future t f steps considering their observations and the interactive context. <ref type="table">Table 1</ref>. Architecture details of the proposed V 2 -Net.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Layers</head><p>Network Architecture MLPt (ax, ay, ?x, ?y) ? fc(64, ReLU) ? fc(64, tanh) ? ft</p><formula xml:id="formula_2">MLPc C ? MaxPool(5 ? 5) ? Flatten ? fc(64t h , tanh) ? Reshape(t h , 64) ? fc T k fe ? TransformerEncoder (128) ? f ? k ; f ? k , (ax, ay, ?x, ?y) ? TransformerDecoder (128) ? f ?? k MLPe f ?? k ? fc(128, tanh) ? fc(128) ? f MLP d f ? fc(128, ReLU) ? fc(128, ReLU) ? fc(4N key ) ? Reshape (N key , 4) ? (a key x , a key y , ? key x , ? key y ) Ti [f key t , fc] ? TransformerEncoder (128) ? f ? i ; f ? i , (a key x , a key y , ? key x , ? key y ) ? TransformerDecoder (4) ? (?x,?y,?x,?y)</formula><p>Keypoints Estimation Sub-network. The coarse-level keypoints estimation sub-network aims to forecast agents' keypoint spectrums with a lower spatiotemporal resolution. An encoder-decoder structure is designed to generate multiple random predictions to adapt to agents' uncertainty and randomness. We first use Discrete Fourier Transform (DFT) on agents' observed trajectories to obtain the t h -point trajectory spectrums. We apply 1D-DFT on each dimension in the observed trajectory</p><formula xml:id="formula_3">X = {(x t , y t )} X = DFT[(x 1 , x 2 , ..., x t h )] ? C t h , Y = DFT[(y 1 , y 2 , ..., y t h )] ? C t h , A = {a x , a y } = {?X ?, ?Y?}, ? = {? x , ? y } = {arg X , arg Y}.<label>(1)</label></formula><p>We employ an embedding MLP (the MLP t in <ref type="table">Table 1</ref>) to embed agents' observed trajectory spectrums (a x , a y , ? x , ? y ) ? R t h ?4 into the high-dimensional f t . Similar to previous works like S-GAN <ref type="bibr" target="#b13">[14]</ref>, we model agents' multimodality by sampling the random noise vector z ? N (0, I) and then concatenating the corresponding random representations f i to the f t . The encoder for these noise vectors (we call the MLP i ) has the same structure like the MLP t . We combine the above representations to obtain the embedded vector f e . Formally,</p><formula xml:id="formula_4">f t = MLP t ((a x , a y , ? x , ? y )) ? R t h ?64 , f i = MLP i (z) ? R t h ?64 , f e = [f t , f i ] ? R t h ?128 .<label>(2)</label></formula><p>Here, [a, b] represents the concatenation for vectors {a, b} on the last dimension.</p><p>Then, we use a Transformer[50] 3 named T k to encode agents' behavior representations. The embedded vector f e is passed to the Transformer encoder, and the spectrums (a x , a y , ? x , ? y ) are input to the Transformer decoder. The Transformer here is used as the feature extractor, and it does not contain the final output layer. We employ another MLP encoder (MLP e ) to aggregate features at different frequency nodes <ref type="bibr" target="#b51">[52]</ref>, thus inferring the behavior feature f :</p><formula xml:id="formula_5">f = MLP e (T k (f e , (a x , a y , ? x , ? y ))) ? R t h ?128 .<label>(3)</label></formula><p>The sub-network finally utilizes a decoder MLP (MLP d ) to predict agents'</p><formula xml:id="formula_6">N key -point (N key &lt; t f ) keypoint spectrums [A key , ? key ]. Formally, [A key , ? key ] = (a key x , a key y , ? key x , ? key y ) = MLP d (f ) ? R N key ?4 .<label>(4)</label></formula><p>We call N key the number of spectrum keypoints.</p><p>When training the sub-network, agents' key spatial coordinates y key (which are gathered from their entire ground-truth future trajectories) will be used as the supervision. Meanwhile, the Inverse DFT (IDFT) will be applied to obtain the predicted spatial keypoints? key . The network variables will be tuned by minimizing the average Euclidean distance between y key and the predicted? key , therefore learning to predict the corresponding keypoint spectrums. We define the Average Keypoints Loss (L AKL ) as:</p><formula xml:id="formula_7">L AKL = ?? key ? y key ? 2 = 1 N key N key n=1 ?p t key n ? p t key n ? 2 ,<label>(5)</label></formula><p>where?</p><formula xml:id="formula_8">key = IDFT[a key x exp(j? key x )], IDFT[a key y exp(j? key y )] ? R N key ?2 , y key = p t key 1 , p t key 2 , ..., p t key N key T ? R N key ?2 .<label>(6)</label></formula><p>Spectrum Interpolation Sub-network. The fine-level spectrum interpolation sub-network reconstructs the complete trajectory spectrums from the keypoint spectrums with a higher spatio-temporal resolution. It aims to learn the spectrum biases between the complete spectrums and the keypoint spectrums. The sub-network takes the N key -point keypoint spectrums [A key , ? key ] as the input. Similar to Equation 2, we have the representation f key t :</p><p>f key t = MLP t ((a key x , a key y , ? key x , ? key y )) ? R N key ?64 .</p><p>Note that MLP t in Equation 2 and Equation 7 do not share weights. Besides, agents' social and scene interactions will be concerned in this subnetwork. In detail, we use a context embedding MLP (MLP c ) to encode the transferred images C <ref type="bibr" target="#b52">[53]</ref> (which encodes both social interactions and scene constraints together in an energy map form by the scene visual image I and trajectories T via a CNN) into the context feature f c = MLP c (C).</p><p>We employ a similar Transformer (called the Interpolation Transformer, T i ) to learn the spectrum biases. We pass the concatenated feature f key e = [f key t , f c ] to the transformer encoder, and keypoint spectrums [A key , ? key ] = (a key x , a key y , ? key x , ? key y ) to the transformer decoder. The transformer here is used to forecast the complete spectrums [?,?] = (? x ,? y ,? x ,? y ). Then, we use the IDFT to obtain the reconstructed trajectory? o . Formally,</p><formula xml:id="formula_10">(? x ,? y ,? x ,? y ) = T i (f key e , (a key x , a key y , ? key x , ? key y )) ? R (t h +t f )?4 , y o = IDFT[? x exp(j? x )], IDFT[? y exp(j? y )] ? R (t h +t f )?2 .<label>(8)</label></formula><p>Finally, we have one of the V 2 -Net predictions:</p><formula xml:id="formula_11">y =? o [t h :, :] ? R t f ?2 ,<label>(9)</label></formula><p>where the [t h :, :] indicates the slicing operation on tensors.</p><p>The spectrum interpolation sub-network learns to interpolate the "key" trajectory spectrums into the complete trajectory spectrums, thus reflecting agents' fine interactive details by predicting the remaining spectrum portions. Its variables will be tuned through the Average Point-wise Loss (L APL ):</p><formula xml:id="formula_12">L APL = ?? ? y? 2 = 1 t f t h +t f t=t h +1 ?p t ? p t ? 2 .<label>(10)</label></formula><p>Loss Functions. We use the joint loss function to tain V 2 -Net:</p><formula xml:id="formula_13">L = L AKL + L APL .<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Datasets. (a) ETH-UCY Benchmark: Many previous methods like <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b42">43]</ref> take several sub-datasets from ETH <ref type="bibr" target="#b38">[39]</ref> and UCY <ref type="bibr" target="#b23">[24]</ref> to train and evaluate their models with the "leave-one-out" strategy <ref type="bibr" target="#b0">[1]</ref>, which is called the ETH-UCY benchmark. It contains 1536 pedestrians with thousands of non-linear trajectories. The annotations are pedestrians' coordinates in meters. (b) Stanford Drone Dataset: The Stanford Drone Dataset <ref type="bibr" target="#b41">[42]</ref> (SDD) has 60 bird-view videos captured by drones. More than 11,000 different agents are annotated with bounding boxes in pixels. It contains over 185,000 social interactions and 40,000 scene interactions, which is more complex and challenging. 4</p><p>Metrics. We employ two metrics to evaluate the prediction accuracy, including the Average Displacement Error (ADE) and the Final Displacement Error (FDE) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b38">39]</ref>. ADE is the average point-wise Euclidean distance between groundtruth and predictions of all steps, and FDE is the Euclidean distance between the last point's prediction and groundtruth. Following <ref type="bibr" target="#b13">[14]</ref>, the reported metrics are the minimum value in 20 generations ("best-of-20"). For one prediction, we have:</p><formula xml:id="formula_14">ADE = 1 t f t h +t f t=t h +1 ?p t ?p t ? 2 , FDE = ?p t h +t f ?p t h +t f ? 2 .<label>(12)</label></formula><p>Baselines. We choose several methods as our baselines, including S-GAN <ref type="bibr" target="#b13">[14]</ref>, SoPhie <ref type="bibr" target="#b42">[43]</ref>, Social-BiGAT <ref type="bibr" target="#b21">[22]</ref>, E-SR-LSTM <ref type="bibr" target="#b60">[61]</ref>, MANTRA <ref type="bibr" target="#b33">[34]</ref>, Multiverse <ref type="bibr" target="#b26">[27]</ref>, SimAug <ref type="bibr" target="#b25">[26]</ref>, PECNet <ref type="bibr" target="#b29">[30]</ref>, STAR <ref type="bibr" target="#b57">[58]</ref> TPNMS <ref type="bibr" target="#b27">[28]</ref>, TF <ref type="bibr" target="#b12">[13]</ref>, Trajectron++ <ref type="bibr" target="#b44">[45]</ref>, Introvert <ref type="bibr" target="#b45">[46]</ref>, LB-EBM <ref type="bibr" target="#b37">[38]</ref>, Agentformer <ref type="bibr" target="#b58">[59]</ref>, Y-net <ref type="bibr" target="#b28">[29]</ref>, and SpecTGNN <ref type="bibr" target="#b2">[3]</ref>.</p><p>Implementation Details. We predict agents' trajectories in future t f = 12 frames according to their t h = 8 frames' observations. The frame rate is set to 2.5 frames per second when sampling trajectories. We train the entire V 2 -Net with the Adam optimizer (learning rate lr = 0.0003) on one NVIDIA Tesla P4 graphic processor. V 2 -Net is trained with the batch size bs = 2500 for 800 epochs on ETH-UCY and 150 epochs on SDD. Detailed layer connections, output units, and activations are listed in <ref type="table">Table 1</ref>. We employ L = 4 layers of encoder-decoder structure with H = 8 attention heads in each Transformer-based sub-network. The output dimension of fully connected layers used in multi-head attention layers is set to 128. The default number of spectrum keypoints is set to N key = 3.</p><p>When training the network, we set {t key 1 , t key 2 , t key SDD. As shown in <ref type="table">Table 3</ref>, V 2 -Net has better performance than the previous state-of-the-art methods on SDD. Compared to SpecTGNN, V 2 -Net has significantly gained by 13.3% and 8.2% in ADE and FDE, respectively. V 2 -Net also outperforms the state-of-the-art Y-net by 9.3% and 3.9%. In general, V 2 -Net has a better prediction accuracy than other baselines on SDD. It is worth noting that SDD is more complex than ETH-UCY, which demonstrates V 2 -Net's robustness and adaptability to larger and more challenging scenarios.</p><formula xml:id="formula_15">3 } = {t h + 4, t h + 8, t h + 12}.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Comparision to State-of-the-Art Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ETH-UCY. As shown in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Quantitative Analysis</head><p>We design several model variations and run ablation studies to verify each design in the proposed V 2 -Net. Quantitative results are shown in <ref type="table">Table 4</ref> and <ref type="table" target="#tab_2">Table 5</ref>.  <ref type="table">Table 4</ref>. Ablation Studies. S1 and S2 represent the keypoints estimation stage and the spectrum interpolation stage, correspondingly. "D" indicates whether different variations model trajectories with spectrums. "N" indicates the number of spectrum keypoints. Results in "?" are the percentage metric improvements compared to a1.</p><p>No. S1 S2 D  DFT on Trajectories. V 2 -Net implements on the trajectory spectrums to focus on different frequency portions in different prediction stages. Variations a1 and a2 are trained with the same number of spectrum keypoints N key = 1, while a1 does not use DFT/IDFT when predicting. It means that variation a2 obtains behavior features and interaction features from the spectrums, while a1 obtains them from the time series. Experiments show that a2 outperforms a1 by about 10% average ADE and FDE on ETH-UCY. In addition, we remove all other components from the model and design two minimal model variations min1 and min2 to demonstrate more directly the usefulness of introducing DFT for trajectory prediction. These two variations DO NOT take into account agents' interactions and multimodal properties, but only retain the Transformer backbone to achieve the "simple" trajectory prediction goal. We train both the two variations under the same conditions. Results in <ref type="table" target="#tab_2">Table 5</ref> favorably demonstrate the performance gains (12.9% on ADE and 11.1% on FDE) by using trajectory spectrums, independent of the rest of the designs in the proposed network. It proves the effectiveness of DFT in this task, and further demonstrates the considerable performance gain by implementing on the trajectory spectrums.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Spectrum</head><p>Keypoints N key . The number of spectrum keypoints to be predicted matters how the keypoints estimation sub-network determines agents' overall motion trends. A smaller N key might cause a looser planning division, making it challenging to reflect the differences between agents' similar future choices. On the contrary, a larger value may lead to a strict trends division, which could be difficult for the subsequent network to reflect agents' multiple uncertain future choices and motion preferences. Ablation experiments on variations a2, b1, b2, and b3 show the quantitative comparisons with different N key configurations. The temporal keypoints are set to the equivalence point among the predicted period (t f = 12). For example, when N key = 1, we set {t key 1 } = {t h + 12}, and when N key = 4, we set {t key 1 , t key 2 , t key 3 , t key 4 } = {t h + 3, t h + 6, t h + 9, t h + 12}. It shows that variation b1 (N key = 3) outperforms variation a2 (N key = 1) with additional improvements by about 5% ADE and 6% FDE. However, The performance of variation b3 (N key = 6) reduces by about 5% and 1% compared to variation a1. Please refer to visualized trajectories of different N key variations in section "Qualitative Analysis" to see how they affect the prediction performance qualitatively.</p><p>Hierarchical Prediction. Similar to some goal-driven methods, V 2 -Net splits trajectory prediction into a two-stage "keypoints-interpolation" process. However, the most significant difference from these methods is that our model implements the entire process with trajectory spectrums rather than spatial coordinates. Correspondingly, the second stage "goal-conditioned prediction" has turned into the "spectrum interpolation". Although the first stage sub-network has already given a low-resolution prediction composed of a few keypoint spectrums, it is not easy to reflect agents' subtle interactions and activity differences. The spectrum interpolation sub-network aims to interpolate these "key" spectrums into the complete trajectory spectrums, thus reflecting agents' fine-level interactive preferences. Variation c only implements the S1 sub-network but utilizes linear interpolation to finish forecasting. Variations b1 and c could show the improvements brought by the interpolation sub-network. Results point out that b1 improves about 7% in ADE compared with variation c. It effectively reflects the superiority of the "coarse-to-fine" hierarchical prediction with spectrums.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Qualitative Analysis</head><p>Coarse-Fine Prediction. V 2 -Net predicts agents' multiple random keypoint spectrums at the first stage, and then uses a spectrum interpolation method to forecast the complete spectrums by considering interactions and fine activities. <ref type="figure" target="#fig_2">Fig.3</ref> shows two visualized results at keypoints estimation and spectrum interpolation stages correspondingly. At the first stage, V 2 -Net aims to predict keypoint spectrums with a low spatio-temporal resolution. We apply IDFT on these keypoint spectrums to show the corresponding spatial keypoints in <ref type="figure" target="#fig_2">Fig.3</ref>. As shown in <ref type="figure" target="#fig_2">Fig.3(a)</ref> and (b), these spatial keypoints could only represent the general trend of agents' future activities rather than the specific and precise coordinates. Then, the interpolation sub-network considers both physical constraints and social interactions to "fine-tune" these keypoints. For example, the marked keypoints in <ref type="figure" target="#fig_2">Fig.3(b)</ref> indicate that the pedestrian could go toward the road. However, the corresponding final prediction shows that he might slow down and stay on the side of the road considering the scene's physical constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Spectrum Keypoints and Prediction</head><p>Styles. The keypoint sub-network estimate agents' keypoint spectrums to determine their coarse future routes. Meanwhile, it contains a generative module to give agents multiple predictions by randomly sampling z ? N (0, I), therefore adapting to agents' uncertain future decisions. The number of spectrum keypoints N key matters directly V 2 -Net's stochastic performance, which can be seen in <ref type="figure">Fig.4</ref>. It shows that <ref type="figure">Fig.4(a)</ref> exhibits a looser restraint when generating trajectories. Obviously, it is caused by the insufficient trends constraints from the little N key . Although (a) gives a large number of future predictions, most of them may be invalid or do <ref type="figure">Fig. 4</ref>. Number of Spectrum Keypoints and Prediction Styles. We show the visualized predictions with different N key configurations. Each sample has 20 random predictions. not meet the scene constraints. Visualized results indicate that V 2 -Net will give more rigorous predictions when N key increases. It will forecast more acceptable predictions when increasing the N key to 3 ( <ref type="figure">Fig.4(b)</ref>). However, its predictions will be limited to a small area when N key is set to 6 ( <ref type="figure">Fig.4(c)</ref>). At this time, V 2 -Net could hardly reflect agents' multiple stochastic plannings under the constraints of such excessive keypoints. In short, with a low number of keypoints a wider spectrum of possibilities is covered (higher multimodality) and vice versa by increasing the number the trajectories become more plausible (collisions with static elements are avoided). It also explains the drop of quantitative performance when N key = 6 in the above ablation studies. Furthermore, we can set different N key in different prediction scenarios to achieve controllable predictions.</p><formula xml:id="formula_16">(a) !"# = 1 (b) !"# = 3 (c) !"# = 6</formula><formula xml:id="formula_17">(a) (b) (c) (d) (e) (f) (g) (h) (i) (j) (k) (l)</formula><p>Visualization. As shown in <ref type="figure" target="#fig_3">Fig.5</ref>, V 2 -Net could predict multiple trajectories considering both scene constraints and social interactions. For example, V 2 -Net gives a variety of different future options for bikers crossing the intersection (illustrated in <ref type="figure" target="#fig_3">Fig.5(a)(e)(k)</ref>). In the prediction case (e) and (k), it considers the physical constraints of the environment and forecast to bypasses the grass. Additionally, it also shows strong adaptability in some unique prediction scenarios. For instance, it gives three kinds of predictions to the biker in case (h) to pass through the traffic circle: turning right, going ahead, and turning left. When turning left, the given predictions are not to turn left directly (just like turning right) but to go left after going around the traffic circle, which is consistent with the traffic rules around the circle. Case (i) presents similar results for the man passing the crossroads. It shows V 2 -Net could accurately describe the scene's physical constraints and agents' motion rules in various scenes. Surprisingly, V 2 -Net could give "smoother" predictions due to the usage of DFT, like turning left in case (h). The spatio-temporal continuity between adjacent points in the predicted time series will be ensured with the superposition of a series of sinusoids. Therefore, the predictions could reflect the real physical characteristics of the target agent while keeping their interactive preferences.</p><p>Limitations. As shown in <ref type="figure" target="#fig_4">Fig.6</ref>, V 2 -Net has failed predictions for stationary agents and few interactive cases. Although not all predictions are regarded as failed predictions, some of them show not-so-reasonable movement trends for these standing still agents. Additionally, it may provide predictions not that suitable for the interactive context. We will fix this problem in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we focus on giving predictions by modeling their trajectories with spectrums from the global plannings and the interactive preferences two hierarchical steps. A Transformer-based V 2 -Net, which consists of the coarse-level keypoints estimation sub-network and the fine-level spectrum interpolation subnetwork, is proposed to predict agents' trajectories hierarchically. Experimental results show that V 2 -Net achieves the competitive performance on both ETH-UCY benchmark and the Stanford Drone Dataset. Although the proposed method shows higher prediction accuracy and provides better visualized results, there are still some failed predictions. We will address this problem and further explore feasible solutions to model and predict agents' possible trajectories.</p><p>Acknowledgements. This work was partially supported by the National Natural Science Foundation of China (Grant No. 62172177), and in part by the Fundamental Research Funds for the Central Universities (Grant No. 2021yjsCXCY040).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Detailed Transformer Structures</head><p>We employ the Transformer <ref type="bibr" target="#b49">[50]</ref> as the backbone to encode trajectory spectrums and the scene context in the two sub-networks. The Transformer used in the V 2 -Net has two main parts, the Transformer Encoder and the Transformer Decoder. Both these two components are made up of several attention layers.</p><p>Attention Layers. Multi-Head Attention operations are applied in each of the attention layers. Following definitions in <ref type="bibr" target="#b49">[50]</ref>, each layer's multi-head dot product attention with H heads is calculated as:</p><formula xml:id="formula_18">Attention(q, k, v) = softmax qk T ? d v, MultiHead(q, k, v) = fc concat({Attention i (q, k, v)} H i=1 ) .<label>(13)</label></formula><p>Here, fc() denotes one fully connected layer that concatenates all heads' outputs. Query matrix q, key matrix k, and value matrix v, are the three layer inputs. Each attention layer also contains an MLP (denoted as MLP a ) to extract the attention features further. It contains two fully connected layers. ReLU activations are applied in the first layer. Formally, we have the layer output f o :</p><formula xml:id="formula_19">f o = ATT(q, k, v) = MLP a (MultiHead(q, k, v)).<label>(14)</label></formula><p>Transformer Encoder. The transformer encoder comprises several encoder layers, and each encoder layer contains an attention layer and an encoder MLP (MLP e ). Residual connections and normalization layers are applied to prevent the network from overfitting. Let h (l+1) denote the output of l-th encoder layer, and h (0) denote the encoder's initial input. For l-th encoder layer, we have</p><formula xml:id="formula_20">a (l) = ATT(h (l) , h (l) , h (l) ) + h (l) , a (l) n = Normalization(a (l) ), c (l) = MLP e (a (l) n ) + a (l) n , h (l+1) = Normalization(c (l) ).<label>(15)</label></formula><p>Transformer Decoder. Like the Transformer encoder, the Transformer decoder comprises several decoder layers, and each is stacked with two different attention layers. The first attention layer in the Transformer decoder focuses on the essential parts in the Transformer encoder's outputs h e queried by the decoder's input X. The second layer is the same self-attention layer as in the encoder. Similar to <ref type="bibr">Equation 15</ref>, we have:</p><formula xml:id="formula_21">a (l) = ATT(h (l) , h (l) , h (l) ) + h (l) , a (l) n = Normalization(a (l) ), a (l) 2 = ATT(h e , h (l) , h (l) ) + h (l) , a (l) 2n = Normalization(a (l) 2 ) c (l) = MLP d (a (l) 2n ) + a (l) 2n , h (l+1) = Normalization(c (l) ).<label>(16)</label></formula><p>Positional Encoding. Before inputting agents' representations or trajectory spectrums into the Transformer, we add the positional coding to inform the relative position of each timestep or frequency portion in the sequential inputs.</p><p>The position coding f t e at step t (1 ? t ? t h ) is obtained by:</p><formula xml:id="formula_22">f t e = f t e 0 , ..., f t e i , ..., f t e d?1 ? R d , where f t e i = ? ? ? ? ? sin t/10000 d/i , i is even; cos t/10000 d/(i?1) , i is odd.<label>(17)</label></formula><p>Then, we have the positional coding matrix f e that describes t h steps of sequences:</p><formula xml:id="formula_23">f e = (f 1 e , f 2 e , ..., f t h e ) T ? R t h ?d .<label>(18)</label></formula><p>The final Transformer input X T is the addition of the original sequential input X and the positional coding matrix f e . Formally,</p><formula xml:id="formula_24">X T = X + f e ? R t h ?d .<label>(19)</label></formula><p>Layer Configurations. We employ L = 4 layers of encoder-decoder structure with H = 8 attention heads in each Transformer-based sub-networks. The MLP e and the MLP d have the same shape. Both of them consist of two fully connected layers. The first layer has 512 output units with the ReLU activation, and the second layer has 128 but does not use any activations. The output dimensions of fully connected layers used in multi-head attention layers are set to d = 128.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Analyses</head><p>Spectrums and Stochastic Performance. Similar to previous multiple outputs approaches, the proposed V 2 -Net could give multiple stochastic predictions to the same target agent. More and more researchers <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b28">29]</ref> have focused on their models' stochastic performance by adding the number of random generations. Following these methods, we design ablation studies to verify V 2 -Net's stochastic performance as well as the performance improvement by using spectrums to  <ref type="table" target="#tab_3">Table 6</ref>.</p><p>Results show that describing and predicting trajectories with trajectory spectrums could bring even more significant performance gains than the original time series when generating more stochastic predictions. The V 2 -Net outperforms the other V 2 -Net variation, which implements trajectories as time-series rather than spectrums, for about 12.3% ADE and 24.8% FDE when generating k = 100 predictions on ETH-UCY. It is worth noting that this performance gain amounts to the astonishing 50% on FDE and 30% ADE when outputting 1000 trajectories. Results in SDD also present the same trends. The performance gain has been improved from 0.5% to 17.5% on ADE and from 12.9% to 51.2% on FDE with the number of predictions raised to 1000. Quantitative metrics illustrate the effectiveness of the V 2 -Net in generating a large number of predictions. On the other hand, it also demonstrates the impressive performance gains achieved by hierarchically predicting agents' trajectory spectrums. Furthermore, it also shows the potential performance advantage of the proposed model in specific scenarios requiring a large number of multimodal predictions, such as trajectory prediction for traffic or autonomous driving.</p><p>In addition, the FDE will drop faster than the ADE as the generation number k increases. Using spectrums to predict trajectories in a hierarchical manner means that agents' overall motion trends (i.e., the keypoint spectrums) may obtain more substantial constraints, resulting in a fast decreasing trend of FDE. Interestingly, the PECNet <ref type="bibr" target="#b29">[30]</ref> that divides the prediction pipeline into the "destination prediction" and the "destination-conditioned prediction" has a similar experimental phenomenon. It also demonstrates the effectiveness of using a hierarchical strategy to predict agents' trajectories, although the two approaches use completely different perspectives to describe and predict trajectories.</p><p>Smoothness. In earlier studies on trajectory prediction, researchers have widely used autoregressive models, such as recurrent neural network (RNN) <ref type="bibr" target="#b17">[18]</ref> and long-short term memory (LSTM) <ref type="bibr" target="#b0">[1]</ref>, to forcast agents' future trajectories recurrently. They model agents' behaviors and interactions in the next time step based on their last observed or predicted states. These models could better describe the state changes between the adjacent moments. Therefore, their predicted trajectories could reflect better smoothness characteristics. However, more and more non-autoregressive models like <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b28">29]</ref> are proposed and show excellent quantitative results. These models predict agents' positions at different future moments "in parallel", which means that the relationship between the adjacent dots might be less concerned. <ref type="figure">Fig.7</ref>(a) (b) and (c) are visualized trajectories from S-GAN <ref type="bibr" target="#b13">[14]</ref>, PECNet <ref type="bibr" target="#b29">[30]</ref>, and MSN <ref type="bibr" target="#b51">[52]</ref>. Although methods (b) and (c) have achieved better qualitative performance, some of their predictions do not seem so "continuous". Specifically, some of these predicted trajectories present large fluctuations on adjacent time steps, while some predictions also exhibit abrupt state changes that may not happen under real-world physical constraints. The proposed V 2 -Net predicts agents' spectrums directly, rather than the time-sequences. With the help of the DFT, V 2 -Net could give "smoother" predictions than these models. It means that in the IDFT process, the correlation between adjacent time steps will be smoothly constrained via sinusoids. <ref type="figure">Fig.7(d)</ref> and (e) show the relatively smooth predicted trajectories given by V 2 -Net. It better reflects agents' real motion laws due to physical movement limitations.</p><p>It is worth noting that the mentioned "smoothness" does not mean that the smoother the network output is always the better. Smoothness reflects the preferences and styles of agents' movements. In current short-time (i.e., recording 3.2s' trajectory to forecast 4.8s' trajectory) trajectory prediction tasks (like the trajectory prediction mentioned in this paper), since the target agents (including pedestrians and bikers, etc.) usually do not move extensively, their observed trajectories tend to exhibit smooth properties as well. In longer time predictions, maintaining their movement style will be a further counterpart of the mentioned smoothness, and it might be made more accessible by reflecting agents' movement preferences through the trajectory spectrums.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>V 2 -Net Overview. The coarse-level keypoints estimation sub-network aims at forecasting the N key -point keypoint spectrums [A key , ? key ] from the observed trajectory spectrums [A, ?]. The other fine-level spectrum interpolation sub-network aims at predicting the complete spectrums [?,?] on each future moment based on the keypoint spectrums and the interaction representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>a1 ? ? ? 1 0.29/0.47 0.12/0.18 0.23/0.38 0.25/0.37 0.17/0.29 -(base) a2 ? ? ? 1 0.23/0.39 0.12/0.17 0.23/0.37 0.22/0.32 0.16/0.26 7.9%/11.3% b1 ? ? ? 3 0.23/0.37 0.11/0.16 0.21/0.35 0.19/0.30 0.14/0.24 16.2%/16.5% b2 ? ? ? 4 0.24/0.38 0.12/0.17 0.22/0.36 0.21/0.32 0.16/0.26 9.5%/12.4% b3 ? ? ? 6 0.29/0.49 0.13/0.17 0.23/0.38 0.26/0.37 0.21/0.31 -6.0%/-1.2% c ? ? ? 3 0.24/0.37 0.12/0.16 0.23/0.35 0.21/0.30 0.15/0.25 9.6%/15.9%</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Keypoints and Interpolation Illustration. We show the predicted spatial keypoints (N key = 3) after IDFT and the corresponding predicted trajectories V 2 -Net finally outputs. Their corresponding time steps are distinguished with different color masks. Dots connected by white arrows belong to the same prediction steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Visualized Predictions. Each sample illustrates 20 random predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Failure Prediction Cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>2 Fig. 7 .</head><label>27</label><figDesc>Smoothness Comparisons. (a), (b) and (c) are visualized predictions from S-GAN[14], PECNet[30], and MSN[52]. (d) and (e) are predictions given by our V 2 -Net. With the help of spectrums, V 2 -Net's predictions show better continuous and smoothness.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc></figDesc><table /><note>, V 2 -Net achieves better performance on most ETH-UCY sub-datasets. It improves the metrics on eth by 23.3% and 28.8% compared with LB-EBM. Meanwhile, V 2 -Net has better performance than Introvert on hotel by about 8.8% FDE. Compared with Introvert, its av- erage ADE and FDE have been improved by 14.2% and 17.6%, respectively. Moreover, V 2 -Net has achieved comparable average performance to the state- of-the-art Agentformer and Y-net. It shows V 2 -Net's strong competitiveness on ETH-UCY. Especially, V 2 -Net dramatically outperforms Agentformer and Y- net about 14.8% ADE on eth, which demonstrates its unique advantages.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .Table 3 .</head><label>23</label><figDesc>Comparisons to baselines with the best-of-20 on ETH-UCY. Metrics are shown in the format of "ADE/FDE" in meters. Lower means better. Comparisons to baselines with the best-of-20 on SDD. Lower means better. FDE 27.25/41.44 16.27/29.38 14.78/27.09 12.03/23.98 9.96/15.88</figDesc><table><row><cell>Models</cell><cell></cell><cell>eth</cell><cell>hotel</cell><cell>univ</cell><cell cols="2">zara1</cell><cell>zara2</cell><cell>Average</cell></row><row><cell cols="8">Social-BiGAT [22] 0.69/1.29 0.49/1.01 0.55/1.32 0.30/0.62 0.36/0.75 0.48/1.00</cell></row><row><cell cols="8">E-SR-LSTM [61] 0.44/0.79 0.19/0.31 0.50/1.05 0.32/0.64 0.27/0.54 0.34/0.67</cell></row><row><cell cols="2">PECNet [30]</cell><cell cols="6">0.54/0.87 0.18/0.24 0.35/0.60 0.22/0.39 0.17/0.30 0.29/0.48</cell></row><row><cell>STAR [58]</cell><cell></cell><cell cols="6">0.56/1.11 0.26/0.50 0.52/1.13 0.40/0.89 0.52/1.13 0.41/0.87</cell></row><row><cell cols="2">TPNMS [28]</cell><cell cols="6">0.52/0.89 0.22/0.39 0.55/0.13 0.35/0.70 0.27/0.56 0.38/0.73</cell></row><row><cell>TF [13]</cell><cell></cell><cell cols="6">0.61/1.12 0.18/0.30 0.35/0.65 0.22/0.38 0.17/0.32 0.31/0.55</cell></row><row><cell cols="8">Trajectron++ [45] 0.43/0.86 0.12/0.19 0.22/0.43 0.17/0.32 0.12/0.25 0.20/0.39</cell></row><row><cell cols="2">Introvert [46]</cell><cell cols="6">0.42/0.70 0.11/0.17 0.20/0.32 0.16/0.27 0.16/0.25 0.21/0.34</cell></row><row><cell cols="2">LB-EBM [38]</cell><cell cols="6">0.30/0.52 0.13/0.20 0.27/0.52 0.20/0.37 0.15/0.29 0.21/0.38</cell></row><row><cell cols="8">Agentformer [59] 0.26/0.39 0.11/0.14 0.26/0.46 0.15/0.23 0.14/0.23 0.18/0.29</cell></row><row><cell>Y-net [29]</cell><cell></cell><cell cols="6">0.28/0.33 0.10/0.14 0.24/0.41 0.17/0.27 0.13/0.22 0.18/0.27</cell></row><row><cell cols="8">V 2 -Net (Ours) 0.23/0.37 0.11/0.16 0.21/0.35 0.19/0.30 0.14/0.24 0.18/0.28</cell></row><row><cell>Models</cell><cell cols="7">S-GAN [14] SoPhie [43] Multiverse [27] SimAug [26]</cell><cell>PECNet</cell></row><row><cell cols="6">ADE/Models MANTRA [34] LB-EBM SpecTGNN [3]</cell><cell>Y-net</cell><cell>V 2 -Net (Ours)</cell></row><row><cell cols="3">ADE/FDE 8.96/17.76</cell><cell>8.87/15.61</cell><cell>8.21/12.41</cell><cell></cell><cell cols="2">7.85/11.85 7.12/11.39</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5 .</head><label>5</label><figDesc>Validation of DFT. We design and run two minimal model variations to show the performance gain brought by DFT. Symbols are the same asTable 4.</figDesc><table><row><cell>No. S1 S2 D N</cell><cell>eth</cell><cell>hotel</cell><cell>univ</cell><cell>zara1</cell><cell>zara2</cell><cell>? Gain (%)</cell></row><row><cell cols="6">min1 ? ? ? -0.83/1.66 0.25/0.44 0.77/1.39 0.48/0.97 0.38/0.74</cell><cell>-(base)</cell></row><row><cell cols="7">min2 ? ? ? -0.79/1.51 0.22/0.38 0.55/1.10 0.46/0.92 0.34/0.71 12.9%/11.1%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 .</head><label>6</label><figDesc>Verifying of Stochastic Performance. k indicates the number of stochastic generations. Metrics are "ADE/FDE" under the best-of-k validation. Lower is better.</figDesc><table><row><cell cols="3">Datasets k</cell><cell>V 2 -Net</cell><cell>V 2 -Net (without DFT)</cell><cell>Absolute Improvements</cell><cell>Percentage Improvements</cell></row><row><cell>ETH-UCY</cell><cell>(Average)</cell><cell cols="2">100 0.14/0.17 200 0.12/0.12 400 0.10/0.09 600 0.10/0.07 1000 0.09/0.06</cell><cell>0.16/0.23 0.15/0.20 0.14/0.17 0.13/0.15 0.13/0.13</cell><cell>0.02/0.06 12.3% / 24.8% 0.03/0.08 20.1% / 34.6% 0.04/0.08 24.5% / 44.1% 0.03/0.08 26.8% / 46.7% 0.04/0.07 31.4% / 51.2%</cell></row><row><cell></cell><cell></cell><cell cols="2">100 5.80/6.90</cell><cell>5.83/7.93</cell><cell>0.03/1.03</cell><cell>0.5% / 12.9%</cell></row><row><cell cols="2">SDD</cell><cell cols="2">200 4.95/4.95 400 4.30/3.52 600 3.98/2.87</cell><cell>5.27/6.49 4.86/5.30 4.68/4.71</cell><cell>0.32/1.54 0.56/1.78 11.5% / 33.6% 6.0% / 23.6% 0.70/1.84 14.8% / 38.9%</cell></row><row><cell></cell><cell></cell><cell cols="2">1000 3.67/2.28</cell><cell>4.46/4.03</cell><cell>0.79/1.75 17.5% / 43.4%</cell></row><row><cell cols="6">model and forecast trajectories when generating a large number of stochastic</cell></row><row><cell cols="6">predictions. Detailed comparisons (best-of-k ) are shown in</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">t h t=1 to obtain their spectrums, including the amplitudes A = {a x , a y } and the phases ? = {? x , ? y }:</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Please see Appendix for the Transformer details.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Dataset splits used to train and validate on SDD are the same as<ref type="bibr" target="#b25">[26]</ref>.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social lstm: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="961" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to predict human behavior in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Group and Crowd Behavior for Computer Vision</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="183" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spectral temporal graph neural network for trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tomizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1839" to="1845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spectral temporal graph neural network for multivariate time-series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="17766" to="17778" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Multipath: Multiple probabilistic anchor trajectory hypotheses for behavior prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.05449</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fft multichannel interpolation and application to image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Kou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="21" to="34" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Malla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.00024</idno>
		<title level="m">Drogon: A trajectory prediction model based on intention-conditioned behavior reasoning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multimodal trajectory predictions for autonomous driving using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Djuric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2090" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Convolutional social pooling for vehicle trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1468" to="1476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Anomaly detection and activity perception using covariance descriptor for trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ergezer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Leblebicioglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="728" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Soft+ hardwired attention: An lstm framework for human trajectory prediction and abnormal event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Denman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="466" to="478" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Loki: Long term and key intentions for trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Malla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanehara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9803" to="9812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Transformer networks for trajectory forecasting pp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Giuliari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Galasso</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10335" to="10342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Stgat: Modeling spatial-temporal interactions for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6272" to="6281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Particle-based pedestrian path prediction using lstm-mdl models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hug</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>H?bner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">21st International Conference on Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2684" to="2691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2375" to="2384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Structural-rnn: Deep learning on spatio-temporal graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ieee conference on computer vision and pattern recognition</title>
		<meeting>the ieee conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5308" to="5317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fractional fourier transform based riesz fractional derivative approach for edge detection and its application in image enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kaur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="page">107852</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Probabilistic vehicle trajectory prediction over occupancy grid map via recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="399" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">3-d mean-separation-type short-time dft with its application to moving-image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Komatsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Saito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Social-bigat: Multimodal trajectory forecasting using bicycle-gan and graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mart?n-Mart?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="137" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="336" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Crowds by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chrysanthou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="655" to="664" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Spatial-temporal consistency network for lowlatency trajectory forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021-10" />
			<biblScope unit="page" from="1940" to="1949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Simaug: Learning robust representations from simulation for trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The garden of forking paths: Towards multi-future trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10508" to="10518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.01884</idno>
		<title level="m">Temporal pyramid network for pedestrian trajectory prediction with multi-supervision</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.01526</idno>
		<title level="m">From goals, waypoints &amp; paths to long term human trajectory forecasting</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">It is not the journey but the destination: Endpoint conditioned trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="759" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Manh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Alaghband</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.04018</idno>
		<title level="m">Scene-lstm: A model for human trajectory prediction</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">History repeats itself: Human motion prediction via motion attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="474" to="489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning trajectory dependencies for human motion prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9489" to="9497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mantra: Memory augmented networks for multiple trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Becattini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seidenari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7143" to="7152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Abnormal crowd behavior detection using social force model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mehran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="935" to="942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Social-stgcnn: A social spatiotemporal graph convolutional neural network for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Claudel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14424" to="14432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Trajectory learning for activity understanding: Unsupervised, multilevel, and long-term adaptive approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2287" to="2301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Trajectory prediction with latent belief energy-based model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="11814" to="11824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">You&apos;ll never walk alone: Modeling social behavior for multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Covernet: Multimodal behavior prediction using trajectory sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Phan-Minh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Grigore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Boulton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Beijbom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Wolff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14074" to="14083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Precog: Prediction conditioned on goals in visual multi-agent settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2821" to="2830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning social etiquette: Human trajectory understanding in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="549" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1349" to="1358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Aliakbarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gould</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.07482</idno>
		<title level="m">Artist: Autoregressive trajectory inpainting and scoring for tracking</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Trajectron++: Dynamically-feasible trajectory forecasting with heterogeneous data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="683" to="700" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XVIII 16</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Introvert: Human trajectory prediction via conditional 3d attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shafiee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Padir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="16815" to="16825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Recursive social behavior graph for trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="660" to="669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Goal-driven long-term trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="796" to="805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Unfreezing the robot: Navigation in dense, interacting crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Trautman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="797" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Social attention: Modeling attention in human crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vemula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muelling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE international Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>You</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.00932</idno>
		<title level="m">Msn: Multi-style network for trajectory prediction</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Cscnet: Contextual semantic consistency network for trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="page">108552</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Learning and inferring &quot;dark matter&quot; and predicting human intents and trajectories in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Todorovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1639" to="1652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Encoding crowd interaction with deep neural network for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Piao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5275" to="5284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Ss-lstm: A hierarchical lstm model for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Q</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1186" to="1194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Scene gated social graph: Pedestrian trajectory prediction based on dynamic social graphs and scene constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Q</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reynolds</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.05507</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph transformer networks for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="507" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Agentformer: Agent-aware transformers for socio-temporal multi-agent forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9813" to="9823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Sr-lstm: State refinement for lstm towards pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12085" to="12094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Social-aware pedestrian trajectory prediction via states refinement lstm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
