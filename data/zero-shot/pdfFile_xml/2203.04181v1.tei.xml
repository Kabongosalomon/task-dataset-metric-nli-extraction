<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Selective-Supervised Contrastive Learning with Noisy Labels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikun</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Trustworthy Machine Learning Lab</orgName>
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiming</forename><surname>Ge</surname></persName>
							<email>geshiming@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
							<email>tongliang.liu@sydney.edu.au</email>
							<affiliation key="aff2">
								<orgName type="department">Trustworthy Machine Learning Lab</orgName>
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Selective-Supervised Contrastive Learning with Noisy Labels</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep networks have strong capacities of embedding data into latent representations and finishing following tasks. However, the capacities largely come from high-quality annotated labels, which are expensive to collect. Noisy labels are more affordable, but result in corrupted representations, leading to poor generalization performance. To learn robust representations and handle noisy labels, we propose selective-supervised contrastive learning (Sel-CL) in this paper. Specifically, Sel-CL extend supervised contrastive learning (Sup-CL), which is powerful in representation learning, but is degraded when there are noisy labels. Sel-CL tackles the direct cause of the problem of Sup-CL. That is, as Sup-CL works in a pair-wise manner, noisy pairs built by noisy labels mislead representation learning. To alleviate the issue, we select confident pairs out of noisy ones for Sup-CL without knowing noise rates. In the selection process, by measuring the agreement between learned representations and given labels, we first identify confident examples that are exploited to build confident pairs. Then, the representation similarity distribution in the built confident pairs is exploited to identify more confident pairs out of noisy pairs. All obtained confident pairs are finally used for Sup-CL to enhance representations. Experiments on multiple noisy datasets demonstrate the robustness of the learned representations by our method, following the state-of-the-art performance. Source codes are available at</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep networks are powerful in various tasks, e.g., image recognition <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b61">62]</ref>, object detection <ref type="bibr" target="#b57">[58]</ref>, visual tracking <ref type="bibr" target="#b10">[11]</ref> and text matching <ref type="bibr" target="#b2">[3]</ref>. The power is largely attributed to the collection of large-scale datasets with highquality annotated labels. In supervised learning, with the * Shiming Ge is the corresponding author. data (i.e., the instance and label pairs) in such datasets, deep networks first learn ideal latent representations of the instances and then complete following tasks with the representations <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b56">57]</ref>. However, it is extremely expensive to obtain large-scale high-quality annotated labels. Alternatively, we can collect labels based on web search and user tags <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b54">55]</ref>. These labels are cheap but inevitably noisy.</p><p>Noisy labels impair the generalization performance of deep networks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b59">60]</ref>. It is because, supervised by the datasets with noisy labels, the mislabeled data provide incorrect signals when inducing latent representations for the instances. The corrupted representations then cause inaccurate decisions for following tasks and hurt generalization <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b51">52]</ref>. For example, as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, the corrupted representations result in an inprecise classification boundary. Therefore, it is crucial to induce robust latent representations of instances for learning with noisy labels, which is also our focus in this paper.</p><p>Recent works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b64">65]</ref> show that, working in a pair-wise manner, contrastive learning (CL) methods can bring good latent representations to help following tasks. Based on whether supervised information is provided, the CL methods can be grouped into supervised contrastive learning (Sup-CL) <ref type="bibr" target="#b26">[27]</ref> and unsupervised contrastive learning (Uns-CL) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b17">18]</ref>. It has been shown that Sup-CL can exploit the supervised information to learn better representations than Uns-CL, but relies on the quality of supervised information <ref type="bibr" target="#b40">[41]</ref>. If the supervised information is corrupted by noisy labels, built pairs by training examples are noisy, following corrupted representations learned by Sup-CL. Motivated by this phenomenon, prior methods use general-purpose techniques in tackling noisy labels for robust representation learning with Sup-CL, e.g., introducing regularization <ref type="bibr" target="#b40">[41]</ref> or generating pseudo-labels <ref type="bibr" target="#b31">[32]</ref>. Although these methods can work fine in some cases, the general-purpose techniques fail to consider the remarkable pair-wise characteristic of Sup-CL in strengthening representation learning. The achieved performance by them is thus argued to be sub-optimal.</p><p>In this paper, we propose selective-supervised contrastive learning (Sel-CL) to address the above issue. Sel-CL can make use of the pair-wise characteristic to learn robust latent representations. The core idea of Sel-CL is <ref type="bibr" target="#b0">(1)</ref> select confident pairs out of noisy pairs; (2) employ the confident pairs to learn robust latent representations. Note that it is hard to identify confident pairs directly for representation learning. The main reason is that we always need to set a threshold with the noise rate for precise identification, e.g., see <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b25">26]</ref>. Nevertheless, it is difficult to estimate the noise rate of noisy pairs. To handle this problem, we propose to first employ confident examples <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b40">41]</ref>, which is much easier to identified, to build a reliable set of confident pairs at each epoch. Then, based on the representation similarity distribution of confident pairs in this set, we set a dynamic threshold to selected more confident pairs out of all noisy pairs. By this pair-wise selection, we can make better use of not only the pairs whose class labels are correct, but also the pairs whose class labels are incorrect, but the examples in them are misclassified to the same class. All selected confident pairs are utilized to enhance representation learning with Sup-CL. As the selected confident pairs are less noisy, the learned representations with this selectivesupervised paradigm will be more robust, naturally following promising generalization.</p><p>The main contributions of this paper are summarized as three aspects: 1) We propose selective-supervised contrastive learning with noisy labels, which can obtain robust pre-trained representations by effectively selecting confident pairs for performing Sup-CL. 2) Without knowing the noise rate of pairs, our approach selects the pairs built by identified confident examples, and the pairs built by the examples with high representation similarities. It fulfils a positive cycle, where better confident pairs result in better representations and better representations will identify better confident pairs. 3) We conduct experiments on synthetic and real-world noisy datasets, which clearly demonstrate our approach achieves better performance compared with the state-of-the-art methods. Comprehensive ablation studies and discussions are also provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>In this section, we review recent methods on learning with noisy labels and contrastive learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Learning with Noisy Labels</head><p>There are a large body of recent works on learning with noisy labels, which include but do not limit to estimating the noise transition matrix <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54]</ref>, reweighting examples <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47]</ref>, selecting confident examples <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b55">56]</ref>, designing robust loss functions <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b63">64]</ref>, introducing regularization <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b60">61]</ref>, generating pseudo labels <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b65">66]</ref>, and etc. In addition, some advanced start-of-the-art methods combine serveral techniques, e.g., DivideMix <ref type="bibr" target="#b29">[30]</ref> and ELR+ <ref type="bibr" target="#b36">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Contrastive Learning</head><p>Recent works in unsupervised contrastive learning (Uns-CL) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b47">48]</ref> have demonstrated the potential of contrastive based similarity learning frameworks for representation learning. These methods maximize (minimize) similarities of positive (negative) pairs at the instance level. That is to say, the positive pair is only built by two correlated views of the same instance. The other data pairs are negative. To make use of supervised information for learning better representations, Uns-CL is extended to the fullysupervised setting, named supervised contrastive learning (Sup-CL) <ref type="bibr" target="#b26">[27]</ref>. Sup-CL aims to make examples belonging to the same class lie closer in the representation space than those of examples from different classes. With clean labels, Sup-CL achieves promising performance.</p><p>In consideration of the strong power of Sup-CL, some works tend to use it to learn latent representations and handle noisy labels. For example, the methods MOIT+ <ref type="bibr" target="#b40">[41]</ref> and MoPro <ref type="bibr" target="#b31">[32]</ref> work in two stages. First, they pre-train the networks with Sup-CL and use general-purpose techniques, e.g., adding regularization, to reduce the side effect of noisy labels. Second, the network is fine-tuned on a reliable dataset. Additionally, the methods ProtoMix <ref type="bibr" target="#b30">[31]</ref> and NGC <ref type="bibr" target="#b50">[51]</ref> work in one stage. They jointly perform the generation of pseudo labels and Sup-CL to combat noisy labels. In this paper, we follow the two-stage learning style. The pair-wise characteristic of contrastive learning is investigated to enhance representation learning and further better handle noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Selective-Supervised Contrastive Learning</head><p>We begin by fixing notations. Scalars are in lowercase letters. Vectors are in lowercase boldface letters. Let I[A] be the indicator of the event A. Let [z] = {1, . . . , z}. Consider a classification task, there are C classes. We are given a noisily-</p><formula xml:id="formula_0">labeled dataset D = {(x i ,? i )} n i=1 ,</formula><p>where n is the sample size, x i is the instance of the i-th example and y i ? [C] is the corresponding noisy label. For? i , the associated but unobservable true label is denoted by y i .</p><p>Overview. Following the two-stage learning style <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b64">65]</ref>, our aim is to induce robust pre-trained representations of instances for learning with noisy labels.</p><p>To achieve it, our approach progressively selects better confident pairs G out of noisy pairs for performing supervised contrastive learning at each epoch. Without the noise rate prior, to help identify the pairs, confident examples T are also obtained in this process. The used pre-training network consists of three components: (1) a deep encoder f (a convolutional neural network backnone) that maps the instance x i to a high-dimensional representation v i ; (2) a classifier head (a fully-connected layer followed by the softmax function) that receives v i as an input and outputs class predictionsp(x i ); (3) a linear or non-linear projection that maps v i into a low-dimensional representation z i . The illustration of the proposed Sel-CL can be seen in <ref type="figure" target="#fig_1">Fig. 2</ref>. After that, with the robust representations, we only keep the pre-trained deep encoder, and apply one new classifier head on the top to output the predictions for fine-tuning stage. In the following, we present our method step by step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Selecting Confident Examples</head><p>To help identify the confident pairs, we first select confident examples base on the representation similarity. In addition, we warm up the training in the first few epochs to ob-tain low-dimensional representations of instances for identifying confident examples later. Specifically, we use Uns-CL <ref type="bibr" target="#b6">[7]</ref> for the warm-up training. Note that our method is robust to the choice of warm-up methods (See Section 4.6).</p><p>The confident examples are identified by measuring agreements between the obtained low-dimensional representations and given labels. For this goal, given two lowdimensional representations z i and z j , we first calculate the representation similarity between them by the cosine distance, i.e.,</p><formula xml:id="formula_1">d (z i , z j ) = z i z j z i z j .<label>(1)</label></formula><p>Then, to quantify the agreement, as did in <ref type="bibr" target="#b40">[41]</ref>, for each example (x i ,? i ), we aggregate the original label from its top-K neighbors based on the representation similarity to create a pseudo-label? i . That is to say, we count the original labels of its top-K neighbors (K=250 in the experiements) and correct? i using the dominant class. In this way, we can better use of representation similarities to improve the detection of mislabeled examples <ref type="bibr" target="#b40">[41]</ref>. We use the pseudo-labels to approximate clean class posterior probabilities, i.e.,</p><formula xml:id="formula_2">q c (x i ) = 1 K K k=1 x k ?N i I[? k = c], c ? [C],<label>(2)</label></formula><p>where N i denotes the neighbor set of K closest instances to x i according to the learned representation. Following <ref type="bibr" target="#b15">[16]</ref>, we exploit the cross-entropy loss to identify confident examples. Denoted the set of confident examples belonging to the c-th class as T c , we have</p><formula xml:id="formula_3">T c = {(x i ,? i ) | (q(x i ),? i )&lt;? c , i ? [n]}, c ? [C],<label>(3)</label></formula><p>where ? c is a threshold for the c-th class, which is dynamically defined to ensure a class-balanced set of identified confident examples. To achieve this goal, we use the ? fractile of per-class agreements between the corrected label? i and the original label? i across all classes to determine how many examples should be selected for each class, i.e.,</p><formula xml:id="formula_4">n i=1 I[? i =? i ][? i = c], c ? [C]</formula><p>. Finally, we can get the confident example set including all classes, i.e., T = ? C c=1 T c . This set is less noisy than original noisy datasets and therefore more reliable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Selecting Confident Pairs</head><p>As it is hard to achieve a precise estimation of the noise rate of noisy pairs, we use identified confident examples to help select confident pairs. Specifically, we transform identified confident examples into a set of associated confident pairs. Denoted this set by G , we have</p><formula xml:id="formula_5">G = {P ij |? i =? j , (x i ,? i ), (x j ,? j ) ? T },<label>(4)</label></formula><p>where P ij is the pair built by the examples (x i ,? i ) and (x j ,? j ). As G is built by T , it is reliable. It should be noted that, even though two examples in one pair have incorrect class labels, the similarity labels are still correct when two examples are misclassified to the same class <ref type="bibr" target="#b49">[50]</ref>. Such pairs are valuable for representation learning. We thus identify more confident pairs from noisy pairs. We define whether two instances x i and x j belong to the same class as their similarity label, i.e.,s ij = I[? i =? j ]. Note that similarity labels are extremely imbalanced, i.e., the positive ones are less than negative ones <ref type="bibr" target="#b49">[50]</ref>. For convenience, we consider the noisy pairs with positive similarity labels. Denoted by the set of confident pairs identified from noisy positive pairs by G . We have</p><formula xml:id="formula_6">G = {P ij |s ij = 1, d (z i , z j ) &gt; ?},<label>(5)</label></formula><p>where ? is a dynamic threshold to control the number of identified confident pairs; i and j are two indices sampled from all training data. To avoid the noise rate estimation of noisy positive pairs, we utilize the reliable information of T to set ?. In more detail, the ? fractile of the representation similarities of the pairs in G is used here. Finally, we can get the confident pair set G = G ? G .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Representation Learning with Selected Pairs</head><p>After selecting confident pairs, we can learn representations by utilizing them with supervised contrastive learning at each epoch. As selected confident pairs can be less noisy, this selective-supervised paradigm can enhance representations to handle noisy labels.</p><p>Contrastive learning. Following the original Sup-CL <ref type="bibr" target="#b26">[27]</ref>, we randomly sample N instances in each mini-batch to apply two random data augmentation operations to each in-stance, thus generating two data views. The resulting train-</p><formula xml:id="formula_7">ing mini-batch data is {(x i ,? i )} 2N i=1 , where i ? I = [2N ]</formula><p>is the index of an arbitrary augmented instance. Given G, we perform supervised contrastive learning with selected confident positive pairs:</p><formula xml:id="formula_8">L = i?I L i (z i ) = i?I ?1 |G(i)| g?G(i) log exp (z i ? z g /? ) a?A(i) exp (z i ? z a /? ) ,<label>(6)</label></formula><p>where A(i) means the set of indices excluding i, i.e.,  </p><formula xml:id="formula_9">A(i) = I\{i}; G(i) = {g | g ? A(i), P i g ? G}</formula><formula xml:id="formula_10">i = ?x a + (1 ? ?)x b , where ? ? [0, 1] ? Beta(? m ,</formula><formula xml:id="formula_11">L MIX i (z i ) = ?L a (z i ) + (1 ? ?)L b (z i ),<label>(7)</label></formula><p>where L a and L b have the same form as L i in Eq. 6. It should be noted that the selection of positive/negative pairs involves considering a unique label for each mixed example <ref type="bibr" target="#b40">[41]</ref>. Nevertheless, the input example always contain two labels, where ? determines the dominant one. We assign this dominant label to every example for positive/negative sampling.</p><p>Classification learning. A classification objective with confident examples is also employed to stabilize the convergence and achieve better representations. Given the confident examples of T , classification learning is conducted by using</p><formula xml:id="formula_12">L CLS = (xi,?i)?T L cls i (x i ) = (xi,?i)?T (p(x i ),? i ),<label>(8)</label></formula><p>where x i can also refer to the augmented image. Moreover, inspired by recent methods <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b49">50]</ref> that learn classifiers with similarity labels, we add a learning objective to directly learn from similarity labels using classfier predictions. Given a multiviewed mini-batch data</p><formula xml:id="formula_13">{(x i ,? i )} 2N i=1</formula><p>, the added similarity loss is:</p><formula xml:id="formula_14">L SIM = i?I j?A(i) (p(x i )p(x j ), I[P i j ? G]).<label>(9)</label></formula><p>Lastly, combining the above analyses, the total objective loss is:</p><formula xml:id="formula_15">L ALL = L MIX + ? c L CLS + ? s L SIM ,<label>(10)</label></formula><p>where ? c and ? s are loss weights, which we set as ? c = 1, ? s = 0.01 in all experiments. Note that, by alternately identifying confident pairs and learning robust representations at each epoch, it fulfils a positive cycle that better confident pairs will result in better learned representations and better representations will identify better confident pairs. The similar idea of the positive cycle is shared by <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Classification Fine-tuning</head><p>With the pre-trained robust representation before, we only keep the pre-trained deep encoder f , and apply one new classifier head on top to form a classifer network f and output the predictions. The existing methods on handling noisy labels can be can be applied to fine-tune the classifier. To avoid the complexity of the method, we fine-tune the deep networks on identified confident examples, with a simple robust loss function <ref type="bibr" target="#b40">[41]</ref>. In order to better distinguish the two stages in our framework, we call the proposed method with fine-tuning as Sel-CL+. Also, we empirically verify that our method is also applicable with complex finetuning algorithms, e.g., DivideMix <ref type="bibr" target="#b29">[30]</ref> and ELR+ <ref type="bibr" target="#b36">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we employ comprehensive experiments to verify the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and Implementation Details</head><p>Simulated noisy datasets. We validate our method on two simulated noisy datasets, i.e., CIFAR-10 <ref type="bibr" target="#b27">[28]</ref> and CIFAR-100 <ref type="bibr" target="#b27">[28]</ref>. Both CIFAR-10 and CIFAR-100 contain 50k training images and 10k test images of the size 32 ? 32 ? 3. Following previous works <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b45">46]</ref>, we consider two settings of simulated noisy labels: symmetric and asymmetric noise. Symmetric noise is generated by randomly replacing the labels for a percentage of the training data with all possible labels. Asymmetric noise uses label flips to incorrect classes: "truck ? automobile, bird ? airplane, deer ? horse, cat ? dog" in CIFAR-10, whereas in CIFAR-100 label flips are done circularly within the super-classes.</p><p>For CIFAR-10/100 datasets , we use a PreAct ResNet-18 network, and train it using SGD with a momentum of 0.9, a weight decay of 10 ?4 , and a batch size of 128. The network is trained for 250 epochs and the warm-up training has 1 epoch. We set the initial learning rate as 0.1, and reduce it by a factor of 10 after 125 and 200 epochs. The fine-tuning stage of Sel-CL+ has 70 epochs, where the learning rate is 0.001. We always use the Mixup parameter ? m = 1, scalar temperature ? = 0.1, and loss weights ? c = 1, ? s = 0.01. The noise detection fractiles on the synthetic datasets are shown in Tab. 1. We apply the strong data augmentations SimAug <ref type="bibr" target="#b6">[7]</ref> in the pre-training stage, and the standard weak data augmentations in the fine-tuning stage. To save computing resources, the MOCO trick <ref type="bibr" target="#b17">[18]</ref> is used, and the size of queue is set to 30k.</p><p>Real-world noisy dataset. We validate our method on a real-world noisy dataset, i.e., WebVision <ref type="bibr" target="#b34">[35]</ref>. WebVision contains 2.4 million images crawled from the web using the 1,000 concepts in ImageNet ILSVRC12. Following previous works <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b40">41]</ref>, we compare baseline methods on the first 50 classes of the Google image subset, called WebVision-50. For WebVision-50, we use a standard ResNet-18, and train it using SGD with a momentum of 0.9, a weight decay of 10 ?4 , and a batch size of 64. The network is trained for 130 epochs and the warm-up training has 5 epochs. We set the initial learning rate as 0.1, and reduce it by a factor of 10 after 80 and 105 epochs. The fine-tuning stage has 50 epochs, where the learning rate is 0.001. We use the Mixup parameter ? m = 1, scalar temperature ? = 0.1, loss weights ? c = 1, ? s = 0.01. The noise detection fractiles are ? = 40% and ? = 0%. The data augmentation techniques are similar to those of the CIFAR-10/100 datasets. The MOCO trick <ref type="bibr" target="#b17">[18]</ref> also is used, and the size of queue is 60k. For all baselines, we use similar configurations for the same datasets for a fair comparison. We acquire the results of some baselines based on published codes. The results with underlines mean that we obtain them based on published codes. Implementation details for baselines are provided in Appendix B. We also borrow other experimental results from the related works <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b64">65</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Representation Learning Evaluations</head><p>We start by analyzing the behaviors of different contrastive learning methods in the presence of noisy labels. We show how the selective module for confident pairs im-  pacts the learned representations. We evaluate the quality of representations using a weighted KNN (K=200) evaluation in unsupervised learning <ref type="bibr" target="#b23">[24]</ref>. The results are shown in Tab. 2. As can be seen, when there is no noise, MOIT greatly improves the quality of learned representations. Benifiting from the application of the similarity loss, Sel-CL achieves 0.46% quality gains. Then, for noisy datasets, Sup-CL is seriously affected by noisy labels. Although MOIT improves its robustness through the Mixup technique and semi-supervised strategy, its performance is still unsatisfactory. For example, in the case with 80% symmetric noise, the weighted KNN accu-racy of MOIT is 55.58%, which is even less than the result of Uns-CL, i.e., 56.23%. In contrast, our Sel-CL significantly alleviates the side effect of noisy labels, by selecting confident pairs for supervised contrastive learning. We can see that Sel-CL consistently outperforms baselines across different cases.</p><p>We </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results on Simulated Noisy Datasets</head><p>We compare the proposed Sel-CL+ with multiple baselines. We report the averaged test accuracy over the last 10 epochs. All baselines use the PreAct ResNet-18 network. Note that for a fair comparison, we report the results of DivideMix <ref type="bibr" target="#b29">[30]</ref> without model ensembles, and equip ELR <ref type="bibr" target="#b36">[37]</ref> with Mixup and weight averaging techniques.</p><p>As shown in Tab. 3, we first observe that the methods pre-trained by Uns-CL <ref type="bibr" target="#b6">[7]</ref> can outperform the original ones, e.g., GCE vs. GCE (Uns-CL init.) and ELR vs. ELR (Uns-CL init.). When the noise level is high, e.g., 80% and 90%, the improvement is clearer, which is consistent with the observations in related works <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b64">65]</ref>. For MOIT+ which exploits Sup-CL by adding regularization, its performance is promising. For symmetric noise, MOIT+ achieves comparable results with other state-of-the-art algorithms, e.g., ELR and DivideMix. For asymmetric noise, MOIT+ can perform better in most cases. As for our Sel-CL+, it achieves competitive performance with symmetric noise. For asymmetric noise, Sel-CL+ consistently achieves the best performance over all baselines. The results verify the effectiveness of our method well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Pair-wise Selection Analysis</head><p>As the results on simulated noisy datasets show that Sel-CL+ work better in the case of asymmetric noise, where label flips happens between semantically similar classes. It is because Sel-CL not only exploits confident pairs associated with T , but also extracts more confident positive pairs based on the representation similarity. To detail this phenomenon, we conduct some analysis about the pair-wise selection in our approach under the asymmetric noise cases.</p><p>There are several observations provided in Tab. 4. The results show that, it is useful to employ the confident examples and associated positive pairs G . However, the imporvement is limited compared with selecting clean examples and clean pairs. Our method further employ G , which is based on the similarity representations. By this procedure, we can make better use of the confident pairs whose class labels are incorrect but similarity labels could be correct, which is much common in the asymmetric cases and real-world scenarios. Besides, an interesting phenomenon is that it is not bad for selecting clean examples and all pairs, since the noise rate of pairs is smaller. This phenomenon may explain why MOIT+ also has advantages with asymmetric noise, which uses all noisy pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Results on the Real-World Noisy Dataset</head><p>We validate our method on the real-world dataset WebVision-50 <ref type="bibr" target="#b34">[35]</ref>, which contains noisily-labeled images collected from Flickr and Google. As shown in Tab. 5, Sel-CL+ achieves the best results on both top-1 and top-5 accuracy on the WebVision validation set and ImageNet ILSVRC12 validation set than the other state-of-the-art methods, including four recent methods that also utilize contrastive learning. The results means that our method is better to handle realistic scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Ablation Study and Discussions</head><p>Influence of each component. To study the impact of each component in our method, we use CIFAR-100 for evaluations. We report test accuracy/weighted KNN evaluations (%) for Sel-CL, and test accuracy (%) for Sel-CL+ in Tab. 6. It shows the contribution of each component into our method.</p><p>Discussions on warm-up methods. We use different warm-up methods, i.e., Uns-CL <ref type="bibr" target="#b6">[7]</ref> and Sup-CL <ref type="bibr" target="#b26">[27]</ref> for Sel-CL+. The experiments are conducted on CIFAR-10 and CIFAR-100 with symmetric and asymmetric noise. The results in Tab. 7 demonstrate that Sel-CL+ is robust to the choice of warm-up methods.</p><p>Discussions on fine-tuning methods. We further test two complex but advanced methods for fine-tuning stage, i.e., DivideMix <ref type="bibr" target="#b29">[30]</ref> (be better with symmetric noise) and ELR+ <ref type="bibr" target="#b36">[37]</ref> (be better with asymmetric noise). As shown in Tab. 8, using more advanced fine-tuning methods can further improve the performance. Both the representations obtained by Uns-CL <ref type="bibr" target="#b6">[7]</ref> and Sel-CL can promote the robustness of two methods, and our Sel-CL brings better results.</p><p>Comparison with one-stage methods for handling noisy labels. We compare our method with two recent one-stage methods, which also employ contrastive learning to handle noisy labels. For a fair comparison, we use AugMix <ref type="bibr" target="#b20">[21]</ref>  as data augmentations of the pre-training stage. As shown in Tab. 9, our approach has advantages in the asymmetric noise cases. In addition, we also try to adopt AugMix augmentation in the fine-tuning stage and find that the weak augmentation is more suitable, which is consistent with the ablation study. The results may reflect the difference between representation learning and classification learning.</p><p>Role of pseudo-labels?. Following <ref type="bibr" target="#b40">[41]</ref>, we use the representation similarity with the weighted KNN to create pseudo labels. In this way, we can make better use of representation similarities. To make it clear, we use CIFAR-100 for evaluations. We report test accuracy/label precsion evaluations (%) for Sel-CL+ with and without pseudo-labels, and here label precsion is the average over all epochs. As Tab. 10 shows, this practice results in better performance due to improved label precision. Besides, we also can just use the pseudo labels to define confident examples rather than to estimate clean class posterior probabilities. By comparing them from empirical observations, our method brings a higher label precision, which is shown in <ref type="figure" target="#fig_5">Fig. 4</ref>. The ablation studies about the hyperparameters are provided in Appendix A, which show that our method is robust to the choices of the hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Limitations</head><p>Our work still has certain limitations, including: 1) This work exploits contrastive learning, and therefore, the performance of our approach relies on adequate data augmentation and large amounts of negative samples. A larger batch size or memory bank is needed, which places higher demands on the storage of computing devices. 2) The use of the KNN algorithm brings greater computational consumption. In this work, we have used some faster KNN algorithms (see source codes) to alleviate the above issue, which facilitates the application of our method to largescale datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper proposes selective-supervised contrastive learning (Sel-CL), a new method to handle noisy labels in training data by learning robust pre-trained representations. We make use of the pair-wise characteristic of contrastive learning to better enhance network robustness. Without the noise rate prior, the confident pairs are selected out of noisy pairs for supervised contrastive learning. We demonstrate the state-of-the-art performance of our method with extensive experiments on multiple noisy datasets. For future work, we are interested in extending our method to other tasks such as object detection and text matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Hyperparameter Sensitivity Analysis</head><p>Analysis of ? s . ? s is the balancing weight of a added similarity loss L SIM . In the paper, we set it as 0.01 for all experiments. As shown in Tab. 1, our approach is robust to selection of ? s . Analysis of ? and ?. Noise detection fractiles ? and ? are used to determine the dynamic thresholds for selecting confident examples and pairs. We use CIFAR-10 datasets for analysis. In the paper, we set ? = 50%, ? = 25% for CIFAR-10 with simulated label noise. As shown in Tab. 2 and Tab. 3, our approach is robust to choices of noise detection fractiles. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation Details For Baselines</head><p>For a fair comparison, except for the results borrowed from related work, we obtain baselines based on published codes with the recommended or well-tuned hyperparameters. The details are as following.</p><p>Uns-CL For CIFAR-10/100 datasets, we train the network for 1000 epochs with SimAug augmentation and cosine learning rate, where the scalar temperature is 0.07, the batch size is 1024 and the initial learning rate is 0.05. For WebVison-50 dataset, we use the pre-trained ResNet-50 model provided by the source code of C2D method 1 , which is trained for 1000 epochs using SimCLR.</p><p>GCE For CIFAR-10 datasets, we train the networks for 120 epochs with q = 0.5 for 20%/50% sym. noise, q = 0.7 for 80%/90% sym. noise, and q = 0.5 for asym. noise. For 1 https://github.com/ContrastToDivide/C2D CIFAR-100 datasets, we train the networks for 150 epochs with q = 0.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GCE (Uns-CL init.)</head><p>For CIFAR-10 datasets, we train the networks for 120 epochs with q = 0.7 for 20% sym. noise, q = 1.0 for 50%/80%/90% sym. noise, and q = 0.5 for asym. noise. For CIFAR-100 datasets, we train the networks for 150 epochs with q = 0.7 for sym. noise and q = 0.5 for asym. noise. ELR We train the networks for 250 epochs with ? = 3 and ? = 0.7 for CIFAR-10 with sym. noise, ? = 1 and ? = 0.9 for CIFAR-10 with asym. noise, and ? = 7 and ? = 0.9 for CIFAR-100.</p><p>ELR (Uns-CL init.) We train the networks for 250 epochs with ? = 5 and ? = 0.7 for CIFAR-10 with 20%/50% sym. noise, ? = 7 and ? = 0.7 for CIFAR-10 with 80%/90% sym. noise, ? = 3 and ? = 0.9 for CIFAR-10 with asym. noise, ? = 7 and ? = 0.9 for CIFAR-100 with 20%/50% sym. noise, ? = 10 and ? = 0.9 for CIFAR-100 with 80%/90% sym. noise and asym. noise.</p><p>MOIT+ For pre-training stage, we train the networks with recommended hyperparameter setting in the original paper, except for CIFAR-100 dataset without label noise, where we do not apply the semi-supervised strategy. For finetuning stage, we refine it with recommended setting.</p><p>DivideMix (Uns-CL init.) We use the implementation of C2D method to train the networks for with its recommended hyperparameter setting. ELR+ (Uns-CL init.) We train the networks for 250 epochs using the same ? and ? with ELR (Uns-CL init.).</p><p>ProtoMix For CIFAR-100 with asymmetric label noise, we train the network for 300 epochs with 0.02 initial learning rate, 128 batch size, 0.4 ? 0 and 0.9 ? 1 .</p><p>Other baselines We obtain other reproduced baselines with their recommended or default hyperparameters, which include Cross-Entropy, Mixup, Forward, P-correction, Mcorrection and DivideMix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Relations with MOIT</head><p>Both MOIT and Sel-CL select confident data in representation learning with noisy labels, but Sel-CL is different from MOIT in two aspects:</p><p>(1) The selected targets are different. MOIT perform point-wise selection, which aims to select confident examples. While, Sel-CL performs pair-wise selection, which aims to select confident pairs. Sel-CL can not only employ the pairs whose class labels are correct, but also use the pairs whose class labels are incorrect.</p><p>( classification head. This operation plays a regularization role in representation learning. However, contrastive learning is performed on all noisy pairs. While, Sel-CL performs contrastive learning on the selected pairs, which improves the robustness of representation learning more directly and effectively. Besides, a series of experiments verify the advantages of Sel-CL compared with MOIT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Visualization Results</head><p>By using t-SNE visualization, we compare the representations achieved by Cross-Entropy and our method. As show in <ref type="figure" target="#fig_0">Fig. 1</ref>, Sel-CL can obtain more robust representations and better combat noisy labels. if t ? Twarm then 3:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Pseudo-code of the Proposed Sel-CL</head><p>Train the deep encoder f with Uns-CL or Sup-CL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>else <ref type="bibr">5:</ref> Selecting confident examples T by measuring the agreement between learned representations and given noisy labels. <ref type="bibr">6:</ref> Selecting confident pairs G by exploiting representation similarity distribution in T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>Train the deep encoder f by performing supervised contrastive learning on G and classfication learning on T with Mixup technique. <ref type="bibr">8:</ref> end if 9: end for 10: return deep encoder f .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Left: learning a classifier with ideal representations induced by clean labels; Right: learning a classifier with corrupted representations caused by noisy labels. Circles represent the representations of positive examples while triangles represent the representations of negative examples. When the representations are corrupted by noisy labels, the decision boundary of the classifier will be largely changed. Therefore, the learned classifier in this case cannot generalize well on test examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>The illustration of the proposed Sel-CL, which progressively selects better confident pairs G for supervised contrastive learning based on the representation similarity. Without the noise rate prior, confident examples T are also obtained to help identify the pairs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>? m ) and x i denotes the training example that combines two mini-batch examples x a and x b . A linear relation in the contrastive loss is imposed as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>The learning process of Sel-CL on CIFAR-100 with 20% symmetric noise. (a) the number of selected examples vs. epochs; (b) the number of selected positive pairs vs. epochs; (c) the label precision of selected examples and pairs (%) vs. epochs; (d) weighted KNN evaluations of Sel-CL (%) vs. epochs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>illustrate the numbers of the selected confident examples and pairs, the label precision of selected confident examples and pairs, and the quality of learned representations during training. The experiments are conducted with 20% symmetric noise. The results are provided in Fig. 3. It can be seen that the selection of confident examples/pairs and representation learning form a positive cycle. Sel-CL can progressively achieve effective selection and improve learned representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Comparison of label precision. The experiments are conducted on CIFAR-100 with 20% asymmetric noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>2 )-Figure 1</head><label>21</label><figDesc>The roles of selection in representation learning are different. In the pre-training stage, MOIT selects confident examples for performing semi-supervised learning at the arXiv:2203.04181v1 [cs.CV] 8 Mar 2022 . t-SNE visualization of representations for CIFAR-10 images. The first two rows denote that the experiments are conducted with 20% symmetric noise. The last two rows denote that the experiments are conducted with 40% asymmetric noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Algorithm 1 Algorithm 1 :</head><label>11</label><figDesc>lists the pseudo-code of Sel-CL. Selective-Supervised Contrastive Learning with Noisy Labels Input: Noisily-labeled dataset D = {(xi,?i)} n i=1 , noise detection fractile ?, ?, mixup parameter ?m, scalar temperature ? , loss weight ?c, ?s, warm-up epochs Twarm , max epochs Tmax. Output: learned deep encoder f . 1: for t = 1, 2, ..., Tmax do 2:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>, and i and g are the original indices of x i and x g in D, respectively. ? ? R + is a temperature parameter. Note that expect for the examples that are involved in selected confident pairs, for the other examples, we perform unsupervised contrastive learning<ref type="bibr" target="#b6">[7]</ref> on them.Additionally, to further make representation learning robust, following MOIT<ref type="bibr" target="#b40">[41]</ref>, a Mixup technique<ref type="bibr" target="#b60">[61]</ref> is added into our framework. Mixup performs convex combination of pairs of examples as x</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Noise detection fractiles on simulated noisy CIFAR-10 and CIFAR-100. Weighted KNN evaluations (%) on CIFAR-100. The best results are in bold.</figDesc><table><row><cell>Fractiles</cell><cell cols="4">CIFAR-10 Sym. Asym. Sym. Asym. CIFAR-100</cell><cell></cell></row><row><cell>?</cell><cell>50%</cell><cell>50%</cell><cell>75%</cell><cell>25%</cell><cell></cell></row><row><cell>?</cell><cell>25%</cell><cell>25%</cell><cell>35%</cell><cell>0%</cell><cell></cell></row><row><cell>Methods</cell><cell>Clean 0%</cell><cell cols="2">Symmetric 20% 80%</cell><cell cols="2">Asymmetric 10% 40%</cell></row><row><cell>Uns-CL [7]</cell><cell>56.23</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="6">Sup-CL [27] 72.66 58.32 41.00 71.11 68.00</cell></row><row><cell>MOIT [41] Sel-CL</cell><cell cols="5">77.48 67.42 55.58 74.86 72.60 77.94 75.36 62.49 76.77 72.71</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Comparison with state-of-the-art methods in the test accuracy (%) on CIFAR-10 and CIFAR-100. The best results are in bold. 57.9 26.1 16.8 88.8 86.1 81.7 76.0 61.8 37.3 8.8 3.5 68.1 63.6 53.3 44.5</figDesc><table><row><cell>Dataset</cell><cell>CIFAR-10</cell><cell>CIFAR-100</cell></row><row><cell>Methods/Noise rate</cell><cell cols="2">Symmetric 20% 50% 80% 90% 10% 20% 30% 40% 20% 50% 80% 90% 10% 20% 30% 40% Asymmetric Symmetric Asymmetric</cell></row><row><cell cols="3">Cross-Entropy 82.7 Mixup [61] 92.3 77.6 46.7 43.9 93.3 88.0 83.3 77.7 66.0 46.6 17.6 8.1 72.4 65.1 57.6 48.1</cell></row><row><cell>Forward [43]</cell><cell cols="2">83.1 59.4 26.2 18.8 90.4 86.7 81.9 76.7 61.4 37.3 9.0 3.4 68.7 63.2 54.4 45.3</cell></row><row><cell>GCE [64]</cell><cell cols="2">86.6 81.9 54.6 21.2 89.5 85.6 80.6 76.0 59.2 47.8 15.8 7.2 68.0 58.6 51.4 42.9</cell></row><row><cell>P-correction [59]</cell><cell cols="2">92.0 88.7 76.5 58.2 93.1 92.9 92.6 91.6 68.1 56.4 20.7 8.8 76.1 68.9 59.3 48.3</cell></row><row><cell>M-correction [1] DivideMix [30] ELR [37]</cell><cell cols="2">93.8 91.9 86.6 68.7 89.6 91.8 92.2 91.2 73.4 65.4 47.6 20.5 67.1 64.5 58.6 47.4 95.0 93.7 92.4 74.2 93.8 93.2 92.5 91.4 74.8 72.1 57.6 29.2 69.5 69.2 68.3 51.0 93.8 92.6 88.0 63.3 94.4 93.3 91.5 85.3 74.5 70.2 45.2 20.5 75.8 74.8 73.6 70.0</cell></row><row><cell cols="3">GCE (Uns-CL init.) [13] 90.0 89.3 73.9 36.5 91.1 87.3 82.2 78.1 68.1 53.3 22.1 8.9 70.2 60.2 52.6 44.1</cell></row><row><cell>ELR (Uns-CL init.) MOIT+ [41]</cell><cell cols="2">94.4 93.0 88.3 86.2 95.0 94.7 94.4 93.3 76.2 71.9 57.9 40.8 77.2 75.5 74.3 70.4 94.1 91.8 81.1 74.7 94.2 94.3 94.3 93.3 75.9 70.6 47.6 41.8 77.4 76.4 75.1 74.0</cell></row><row><cell>Sel-CL+</cell><cell cols="2">95.5 93.9 89.2 81.9 95.6 95.2 94.5 93.4 76.5 72.4 59.6 48.8 78.7 77.5 76.4 74.2</cell></row><row><cell>(a)</cell><cell>(b)</cell><cell></cell></row><row><cell>(c)</cell><cell>(d)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Weighted KNN evaluation (%) of Sel-CL with different selected sets on CIFAR-10/100 with 40% asymmetric noise.</figDesc><table><row><cell>Sel-CL with different selected sets</cell><cell cols="2">CIFAR-10 CIFAR-100</cell></row><row><cell>All examples and all pairs</cell><cell>90.58</cell><cell>68.66</cell></row><row><cell>Confident examples T and pairs G Confident examples T and pairs G ? G Clean examples and associated pairs Clean examples and all pairs Clean examples and clean pairs</cell><cell>90.64 92.97 94.21 94.76 95.52</cell><cell>70.25 72.71 71.45 73.43 76.56</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Accuracy (%) on the WebVision and ILSVRC2012 validation sets. The model is trained on WebVision-50. The best results are in bold.</figDesc><table><row><cell>Methods</cell><cell cols="4">WebVision top-1 top-5 top-1 top-5 ILSVRC12</cell></row><row><cell>Forward [43]</cell><cell cols="4">61.12 82.68 57.36 82.36</cell></row><row><cell>Decoupling [40]</cell><cell cols="4">62.54 84.74 58.26 82.26</cell></row><row><cell>D2L [39]</cell><cell cols="4">62.68 84.00 57.80 81.36</cell></row><row><cell>MentorNet [26]</cell><cell cols="4">63.00 81.40 57.80 79.92</cell></row><row><cell>Co-teaching [16]</cell><cell cols="4">63.58 85.20 61.48 84.70</cell></row><row><cell>Iterative-CV [6]</cell><cell cols="4">65.24 85.34 61.60 84.98</cell></row><row><cell>DivideMix [30]</cell><cell cols="4">77.32 91.64 75.20 90.84</cell></row><row><cell>ELR [37]</cell><cell cols="4">76.26 91.26 68.71 87.84</cell></row><row><cell>ELR+ [37]</cell><cell cols="4">77.78 91.68 70.29 89.76</cell></row><row><cell cols="5">ELR (Uns-CL init.) 79.93 92.00 71.23 88.23</cell></row><row><cell>ProtoMix [31]</cell><cell>76.3</cell><cell>91.5</cell><cell>73.3</cell><cell>91.2</cell></row><row><cell>MoPro [32]</cell><cell>77.59</cell><cell>-</cell><cell>76.31</cell><cell>-</cell></row><row><cell>NGC [51] Sel-CL+</cell><cell cols="4">79.16 91.84 74.44 91.04 79.96 92.64 76.84 93.04</cell></row><row><cell cols="5">Table 6. Ablation study for Sel-CL and Sel-CL+ on CIFAR-100. The best results are in bold.</cell></row><row><cell>Methods</cell><cell></cell><cell cols="3">Sym. 20% Asym. 40%</cell></row><row><cell cols="2">Sel-CL w/o Mixup Data Aug.</cell><cell cols="2">70.3/70.6</cell><cell>64.2/66.2</cell></row><row><cell cols="2">Sel-CL w/o MOCO Trick</cell><cell cols="2">73.3/74.1</cell><cell>69.2/71.5</cell></row><row><cell>Sel-CL w/o Selection</cell><cell></cell><cell cols="2">67.2/68.9</cell><cell>49.9/68.7</cell></row><row><cell cols="2">Sel-CL w/o Classfier Learning</cell><cell cols="2">-/69.9</cell><cell>-/70.2</cell></row><row><cell>Sel-CL w/o L SIM Sel-CL</cell><cell></cell><cell cols="2">74.5/74.9 74.9/75.4</cell><cell>71.8/72.5 72.0/72.7</cell></row><row><cell cols="2">Sel-CL+ w/ Strong Data Aug.</cell><cell>74.5</cell><cell></cell><cell>72.7</cell></row><row><cell cols="2">Sel-CL+ w/o Retraining Cls. Sel-CL+</cell><cell>76.4 76.5</cell><cell></cell><cell>73.4 74.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7 .</head><label>7</label><figDesc>Comparison with different warm-up methods in the test accuracy (%) of Sel-CL+.</figDesc><table><row><cell>Dataset</cell><cell cols="2">CIFAR-10</cell><cell cols="3">CIFAR-100</cell></row><row><cell>Noise type</cell><cell>Sym.</cell><cell>Asym.</cell><cell>Sym.</cell><cell></cell><cell>Asym.</cell></row><row><cell>Noise rate</cell><cell>20% 90%</cell><cell>40%</cell><cell cols="2">20% 90%</cell><cell>40%</cell></row><row><cell>Uns-CL [7]</cell><cell>95.5 81.9</cell><cell>93.4</cell><cell cols="2">76.5 48.8</cell><cell>74.2</cell></row><row><cell cols="2">Sup-CL [27] 95.5 81.6</cell><cell>93.4</cell><cell cols="2">76.8 51.4</cell><cell>74.5</cell></row><row><cell cols="6">Table 8. Comparison with using different fine-tuning methods in the test accuracy (%). The best results are in bold.</cell></row><row><cell>Dataset</cell><cell></cell><cell cols="2">CIFAR-10</cell><cell cols="2">CIFAR-100</cell></row><row><cell>Noise type</cell><cell></cell><cell cols="4">Sym. Asym. Sym. Asym.</cell></row><row><cell>Noise rate</cell><cell></cell><cell>20%</cell><cell>40%</cell><cell>20%</cell><cell>40%</cell></row><row><cell>DivideMix [30]</cell><cell></cell><cell>95.7</cell><cell>92.1</cell><cell>76.9</cell><cell>53.8</cell></row><row><cell>ELR+ [37]</cell><cell></cell><cell>94.6</cell><cell>93.0</cell><cell>77.5</cell><cell>72.2</cell></row><row><cell cols="3">DivideMix (Uns-CL init.) [65] 96.2</cell><cell>90.8</cell><cell>78.3</cell><cell>52.9</cell></row><row><cell cols="2">ELR+ (Uns-CL init.) [65]</cell><cell>94.8</cell><cell>94.3</cell><cell>77.7</cell><cell>72.3</cell></row><row><cell cols="2">DivideMix (Sel-CL init.) ELR+ (Sel-CL init.)</cell><cell>96.3 95.2</cell><cell>91.6 94.6</cell><cell>78.7 77.7</cell><cell>55.2 72.9</cell></row><row><cell cols="6">Table 9. Comparesion with one-stage methods in the test accuracy</cell></row><row><cell cols="6">(%).  ? denotes fine-tuning using AugMix data augmentation. The best results are in bold.</cell></row><row><cell>Dataset</cell><cell cols="2">CIFAR-10</cell><cell cols="3">CIFAR-100</cell></row><row><cell>Noise type</cell><cell>Sym.</cell><cell>Asym.</cell><cell>Sym.</cell><cell></cell><cell>Asym.</cell></row><row><cell>Noise rate</cell><cell>20% 90%</cell><cell>40%</cell><cell cols="2">20% 90%</cell><cell>40%</cell></row><row><cell cols="2">ProtoMix [31] 95.8 75.0 NGC [51] 95.9 80.5 Sel-CL+ 95.4 67.5 Sel-CL+  ? 95.2 67.4</cell><cell>91.9 90.6 92.8 92.5</cell><cell cols="2">79.1 29.3 79.3 29.8 76.4 35.5 76.0 35.4</cell><cell>48.8 -74.2 74.2</cell></row><row><cell cols="6">Table 10. Comparison with different example selection strategies</cell></row><row><cell cols="4">in the test accuracy/label precsion (%) of Sel-CL+.</cell><cell></cell></row><row><cell>Noise type</cell><cell cols="2">Sym.</cell><cell></cell><cell cols="2">Asym.</cell></row><row><cell>Noise rate</cell><cell>20%</cell><cell>90%</cell><cell cols="2">20%</cell><cell>40%</cell></row><row><cell>w pseudo-labels</cell><cell cols="5">76.5/99.1 48.8/62.0 77.5/97.5 74.2/92.2</cell></row><row><cell cols="6">w/o pseudo-labels 76.5/99.1 46.2/55.4 76.8/96.6 69.4/83.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 1 .</head><label>1</label><figDesc>Test accuracy (%) of Sel-CL+ with different ?s on CIFAR-10 with 20% symmetric label noise.</figDesc><table><row><cell>Parameter</cell><cell>0.1</cell><cell cols="4">0.05 0.01 0.005 0.001 0.0001</cell></row><row><cell>?s</cell><cell cols="2">95.3 95.6 95.5</cell><cell>95.5</cell><cell>95.6</cell><cell>95.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 .</head><label>2</label><figDesc>Test accuracy (%) of Sel-CL+ with different ? and ? on CIFAR-10 with 20% symmetric label noise.</figDesc><table><row><cell>Parameter</cell><cell>0%</cell><cell>15% 25% 35% 50% 75%</cell></row><row><cell>?</cell><cell cols="2">94.6 94.7 95.3 95.2 95.5 95.6</cell></row><row><cell>?</cell><cell cols="2">94.9 95.4 95.5 95.5 95.0 95.1</cell></row><row><cell cols="3">Table 3. Test accuracy (%) of Sel-CL+ with different ? and ? on</cell></row><row><cell cols="3">CIFAR-10 with 40% asymmetric label noise.</cell></row><row><cell>Parameter</cell><cell>0%</cell><cell>15% 25% 35% 50% 75%</cell></row><row><cell>?</cell><cell cols="2">92.1 92.5 92.6 93.0 93.4 89.9</cell></row><row><cell>?</cell><cell cols="2">91.4 93.3 93.4 92.6 92.8 92.5</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<editor>Kamalika Chaudhuri and Ruslan Salakhutdinov</editor>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="312" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Me-momentum: Extracting hard confident examples from noisily labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingbin</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">MIX: multi-channel information crossing for text matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haolan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><forename type="middle">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunfeng</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Anomman: Detect anomaly on multi-view attributed networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling-Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhao</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.02822</idno>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Noise against noise: stochastic label noise helps combat inherent label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Understanding and utilizing deep neural networks trained with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benben</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1833" to="1841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Big self-supervised models are strong semi-supervised learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="22243" to="22255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Instance-dependent label-noise learning with manifoldregularized transition matrix estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixiong</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinbo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2022</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning with instance-dependent label noise: A sample sieve approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifei</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cascaded correlation refinement for robust deep tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiming</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TNNLS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1276" to="1288" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robust loss functions under label noise for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aritra</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1919" to="1925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Contrastive Learning Improves Model Robustness Under Label Noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aritra</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sigua: Forgetting may make learning with noisy labels more robust</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingrui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4006" to="4016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Coteaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingrui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep selflearning from noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangfan</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5138" to="5147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="9726" to="9735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using trusted data to train deep networks on labels corrupted by severe noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duncan</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10477" to="10486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Augmix: A simple data processing method to improve robustness and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Ekin Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno>ICLR, 2020. 7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-class classification class labels without multi-class lables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chang</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyang</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Schlosser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Odom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Simple and effective regularization methods for training on noisily labeled data with generalization guarantee</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingli</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unsupervised deep learning by neighbourhood discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2849" to="2858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">O2u-net: A simple noisy label detection approach for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinchi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lie</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongfei</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binqiang</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3326" to="3334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prannay</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Robust inference via generative classifiers for handling noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sukmin</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3763" to="3772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Di-videMix: learning with noisy labels as semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning from noisy data with robust representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">MoPro: Webly supervised learning with momentum prototypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2021</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Coupled-view deep classifier learning from multiple noisy annotators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiming</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiqiang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4667" to="4674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Trustable co-label learning from multiple noisy annotators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyong</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiming</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMM</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirikur</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<title level="m">Webvision database: Visual learning and understanding from web data</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning from noisy labels with distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuncheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yale</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangliang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1928" to="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Early-learning regularization prevents memorization of noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Niles-Weed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narges</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Fernandez-Granda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Classification with noisy labels by importance reweighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="461" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dimensionality-driven learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu-Tao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Sudanthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Wijewickrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3361" to="3370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Decoupling&quot; when to update&quot; from&quot; how to update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eran</forename><surname>Malach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="960" to="970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Multi-objective interpolation training for robustness to label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Towards Robust Learning with Different Label Noise Distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7020" to="7027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Bin Yang, and Raquel Urtasun. Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4331" to="4340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Meta-weight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="1917" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiki</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiki</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihiko</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoharu</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Graph structure estimation neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanpeng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="342" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xunqiang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cris</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.15174</idno>
		<title level="m">Clip-driven referring image segmentation</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Robust long-tailed learning under label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang-Xin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Wei</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Feng</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.11569</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Class2Simi: A New Perspective on Learning with Label Noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songhua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<idno>ICML, 2021. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">NGC: A unified framework for learning with open-world noisy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Fan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaojie</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingqian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Feng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Robust early-learning: Hindering the memorization of noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongyuan</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Part-dependent label noise: Towards instance-dependent label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Are anchor points really indispensable in label-noise learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6835" to="6846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Searching to Exploit Memorization Effect in Learning from Corrupted Labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hansi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hansi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Free lunch for few-shot learning: Distribution calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page" from="2021" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Objects in semantic topology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Probabilistic end-to-end noise correction for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7017" to="7025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Student network learning via evolutionary knowledge distillation. TCSVT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kangkai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiming</forename><surname>Ge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Learning with feature-dependent label noise: A progressive approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yikai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songzhu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mert</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Contrast to divide: Selfsupervised pre-training for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgenii</forename><surname>Zheltonozhskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaim</forename><surname>Baskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avi</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Litany</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Error-bounded correction of noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songzhu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aman</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="11447" to="11457" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
