<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Entity Relation Extraction as Dependency Parsing in Visually Rich Documents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Cao</surname></persName>
							<email>junjie.junjiecao@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuyi</forename><surname>Bao</surname></persName>
							<email>zuyi.bzy@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Entity Relation Extraction as Dependency Parsing in Visually Rich Documents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Previous works on key information extraction from visually rich documents (VRDs) mainly focus on labeling the text within each bounding box (i.e., semantic entity), while the relations in-between are largely unexplored. In this paper, we adapt the popular dependency parsing model, the biaffine parser, to this entity relation extraction task. Being different from the original dependency parsing model which recognizes dependency relations between words, we identify relations between groups of words with layout information instead. We have compared different representations of the semantic entity, different VRD encoders, and different relation decoders. For the model training, we explore multi-task learning to combine entity labeling and relation extraction tasks; and for the evaluation, we conduct experiments on different datasets with filtering and augmentation. The results demonstrate that our proposed model achieves 65.96% F1 score on the FUNSD dataset. As for the realworld application, our model has been applied to the in-house customs data, achieving reliable performance in the production setting. * Corresponding author. The author's contributions were carried out while at Alibaba Group. His current affiliation is Vipshop (China) Co., Ltd.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In real-life scenarios, there are many types of visually rich documents (VRDs), such as invoices, questionnaire forms, declaration materials and so on. These documents contain abundant layout information which helps us to understand the content while texts alone are not enough. In recent years, many works focus on how to extract key information from VRDs based on the results of OCR (Optical Character Recognition), which recognizes bounding boxes and texts within the boxes <ref type="bibr" target="#b14">(Liu et al., 2019a;</ref><ref type="bibr" target="#b24">Yu et al., 2020b)</ref>. Each bounding box contains 1) a group of words that belong together from a semantic and spatial standpoint and 2) visual features such as layout, tabular structure and font size of the boxes in the document. We call such bounding boxes and texts within the boxes semantic entities 1 , and each entity contains the word group and layout coordinates 2 .</p><p>Key information extraction (KIE) is such a task to analyze visually rich documents, which usually contains two steps, entity labeling and entity relation extraction. Similar to named entity recognition (NER) and relation extraction in the traditional natural language processing (NLP), entity labeling aims to assign predefined labels to the semantic entities in VRDs (G. Jaume and Thiran, 2019; <ref type="bibr" target="#b14">Liu et al., 2019a;</ref><ref type="bibr" target="#b24">Yu et al., 2020b)</ref>, and entity relation extraction 3 predicts relations between these semantic entities. Compared with NER and relation extraction in the traditional NLP, KIE from VRDs is a more challenging task. First, a normal (named-) entity in plain text does not contain layout information as those semantic entities in VRDs. Second, normal relation extraction predicts the relation between two given mentions, while relation extraction in VRDs needs to predict the relation between any two semantic entities in the document. As <ref type="bibr">Figure 1 (left)</ref> illustrates, the entity labeling task is to tag "533" with the label "Answer", "Registration No." with label "Question". However, which question can be answered by "533" remains unknown without entity relation extraction. Compared with labeling, the entity relation extraction task is less explored, but its benefits at least include: 1) pro- <ref type="figure">Figure 1</ref>: Left part shows one visually rich document from the FUNSD data. Group of words with one bounding box means one semantic entity and we number each entity as B i . Different colors of boxes mean their different entity labels as legends under the example list. Relation links between semantic entities always point from key entities to value entities. We convert entity relations in the VRD to one tree and add the pseudo root node following the similar setting in dependency tree, and then link zero-head entities to the pseudo node as the pseudo links shown in the right part.</p><p>viding additional structural information closer to human comprehension of the VRDs, and 2) being easier to be transferred to other domains when the predefined label set changes. Therefore, in this paper, we concentrate on the task of semantic entity relation extraction which discovers the relation between two groups of words with layout information, as the yellow links in <ref type="figure">Figure 1</ref> (left) show.</p><p>As another similar task to entity relation extraction in VRDs, dependency parsing aims to find out syntactic relations between words of an input sentence, which has been widely studied for decades. Both of these two tasks capture pairwise relationship between basic units of the input data. We adapt the popular biaffine dependency parser which utilizes the biaffine attention to compute scores between words <ref type="bibr" target="#b3">(Dozat and Manning, 2017)</ref> into the entity relation extraction task due to their similarity. Since visual features play an important role in the VRDs, we introduce abundant layout information into different layers of the model to enhance the original text-only biaffine model:</p><p>? At the entity representation layer, we use the LayoutLM <ref type="bibr" target="#b22">(Xu et al., 2020b)</ref> to encode both the word group and coordinates.</p><p>? At the document encoder layer, we utilize graph convolutional networks (GCN) to combine textual and visual information in VRDs by mapping layout information into graph edge representation between entities <ref type="bibr" target="#b14">(Liu et al., 2019a;</ref><ref type="bibr" target="#b24">Yu et al., 2020b)</ref>.</p><p>? At the relation scorer layer, we extract relative position features between entities according to their coordinates.</p><p>Apart from the above, inspired by the joint POS tagging and dependency parsing model <ref type="bibr" target="#b18">(Nguyen and Verspoor, 2018)</ref>, we propose the multi-task learning for both entity labeling and relation extraction to further improve the performance.</p><p>Abundant detailed experiments are conducted to verify our approach of applying the biaffine dependency parser to semantic entity relation extraction task in VRDs. Our proposed relation extraction model achieves 65.96% F1 score on the FUNSD dataset, demonstrating the effectiveness of our model. As for the real-world application scenario, our model has also been applied to the in-house customs data, achieving reliable performance in the production setting.</p><p>The contributions of this paper are as follows:</p><p>? We adapt the biaffine model used in dependency parsing to the entity relation extraction task and achieve 65.96% F1 score on the FUNSD dataset.</p><p>? We conduct detailed experiments to compare different representations of the semantic entity, different VRD encoders, and different relation decoders to better understand this task.</p><p>? We apply our model to the real-world customs data with different layouts and achieve high performance in the production setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Visually rich document understanding includes many tasks, such as layout recognization <ref type="bibr" target="#b26">(Zhong et al., 2019b;</ref><ref type="bibr" target="#b12">Li et al., 2020)</ref>, table detection and recognition <ref type="bibr" target="#b11">(Li et al., 2019a;</ref><ref type="bibr" target="#b25">Zhong et al., 2019a)</ref> and key information extraction <ref type="bibr" target="#b5">(Grali?ski et al., 2020;</ref><ref type="bibr" target="#b6">Guo et al., 2019;</ref><ref type="bibr" target="#b7">Huang et al., 2019;</ref><ref type="bibr" target="#b4">G. Jaume and Thiran, 2019;</ref><ref type="bibr" target="#b16">Majumder et al., 2020)</ref>. Our paper focuses on the key information extraction task which contains two subtasks, entity labeling and relation extraction. The former subtask tags entities with predefined labels, such as Task 3 on the SROIE data released by <ref type="bibr" target="#b7">Huang et al. (2019)</ref>, while the latter discovers relations between entities, such as Subtask C(3) on the FUNSD data (G. Jaume and Thiran, 2019).</p><p>To encode the semantic entity in VRDs, <ref type="bibr" target="#b24">Yu et al. (2020b)</ref> and  replace BiLSTM (Bi-directional Long Short-Term Memory) used by <ref type="bibr" target="#b14">Liu et al. (2019a)</ref> with BERT <ref type="bibr" target="#b2">(Devlin et al., 2018)</ref> or RoBERTa <ref type="bibr" target="#b15">(Liu et al., 2019b)</ref>. <ref type="bibr" target="#b22">Xu et al. (2020b)</ref> propose LayoutLM, which adds the 2-D position embedding into language model based on BERT and pretrain their language model on large-scale scanned document images with more visually-related loss function. Experiments verify that encoding the word group and layout coordinates at the same time is more effective for VRD understanding. LayoutLMv2 additionally introduces visual embedding into input layer and integrates a spatial-aware self-attention mechanism into the Transformer architecture <ref type="bibr" target="#b21">(Xu et al., 2020a)</ref>. And LayoutLMv2 performs better than LayoutLM in downstream VRD understanding tasks.</p><p>While encoding VRDs, previous works take entity labeling task as sequence labeling and reimplement the named entity recognition (NER) framework <ref type="bibr" target="#b10">(Lample et al., 2016)</ref> but ignore layout information. Then, many works introduce a GCNbased module to encode layout information and combine textual and visual information together <ref type="bibr" target="#b14">(Liu et al., 2019a;</ref><ref type="bibr" target="#b24">Yu et al., 2020b;</ref><ref type="bibr" target="#b0">Carbonell et al., 2021)</ref>. In the GCN module, <ref type="bibr" target="#b14">Liu et al. (2019a)</ref>; <ref type="bibr" target="#b24">Yu et al. (2020b)</ref> take layout features between entity b i and b j as edge embedding to up-date entity representation while  prune irrelevant nodes in graph according to same x-axis or y-axis coordinates to get the adjacency matrix.</p><p>To predict relations between entities, G. Jaume and Thiran (2019) provide one simple approach which concatenates the representations of two entities and use multi-layer perceptron (MLP) to obtain the relation score between entities. <ref type="bibr" target="#b0">Carbonell et al. (2021)</ref> also use the MLP scorer but take GNN as document encoder instead of BERT and perform better. In the field of dependency parsing, <ref type="bibr" target="#b3">Dozat and Manning (2017)</ref> propose the biaffine attention mechanism to compute scores between words, and achieve better performance than the MLP mechanism used by <ref type="bibr" target="#b8">Kiperwasser and Goldberg (2016)</ref>. As the biaffine attention is widely used in other tasks like NER <ref type="bibr" target="#b23">(Yu et al., 2020a)</ref> and semantic role labeling <ref type="bibr" target="#b13">(Li et al., 2019b)</ref>, we propose to use it for the entity relation extraction task in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Entity Relation Extraction as Dependency Parsing</head><p>Both semantic entity relation extraction and dependency parsing tasks aim to decide whether there exists relation between two entities/words and assume that links always point from key/head unit to value/modifier unit shown in <ref type="figure">Figure 1</ref>. Therefore, we can draw lessons from the dependency parsing exploration as it has been studied for several decades and achieved great progress. Biaffine parser, a strong model in dependency parsing, achieves competitive performance and is widely used in different scenes and tasks. This section introduces how to apply the biaffine parser to our relation extraction task according to their similarity and difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Definition</head><p>Each scanned visually rich document is composed of a list of semantic entities, and each entity composes of a group of words and coordinates of the bounding box, defined as</p><formula xml:id="formula_0">b i = {[w 1 i , . . . , w m i ], [x 1 i , x 2 i , y 1 i , y 2 i ]}, where [w 1 i , .</formula><p>. . , w m i ] mean the word group, x 1 i /x 2 i and y 1 i /y 2 i are left/right x-coordinates and top/down y-coordinates respectively. Documents in our used dataset are annotated with the label of each entity and relations between entities. We represent each annotated document as</p><formula xml:id="formula_1">D = {[b 1 , ...b n ], [l 1 , ..., l n ], [(b 1 , b h 1 ), ..., (b m , b hm )]},</formula><p>where l ? L is the label of each entity and L is the predefined entity label set. (b i , b h i ) mean the relation between entities b i and b h i , and the link points from b h i to b i . Notably, the entity may exist relations with more than one entity or does not have relation with any other entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Biaffine Parser</head><p>As <ref type="figure" target="#fig_0">Figure 2</ref> (right) shows, biaffine dependency parser takes word and POS-tag embedding as the word representation, and uses multi-layer BiLSTM to encode the input sentence. Then, two MLP modules are used to strip away information not relevant to the current link decision. At last, the biaffine attention mechanism is utilized to compute the score of the dependency link between words.</p><p>We explore various aspects of applying the biaffine parser to our relation extraction in VRDs due to their similarity. Especially, we take the layout information into consideration besides the text itself, compared to the regular dependency parsing. In our proposed entity relation extraction model, we exploit important layout information at different processing levels, including entity encoder, document encoder and relation scorer, as <ref type="figure" target="#fig_0">Figure 2</ref> (left) shows.</p><p>We name our proposed model as SERA (Semantic Entity Relation extraction As dependency parsing). Details of our proposed SERA are discussed in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Entity Representation</head><p>At the input layer, in order to obtain better entity representations, we compare different ways to encode the information of semantic entity, containing the word group and the layout features. In this work, we take the advantage of widely used pretrained models, including context-free word vector from word2vec <ref type="bibr" target="#b17">(Mikolov et al., 2013)</ref>, contextualized representations from BERT and LayoutLM. Specially, LayoutLM introduce coordinate information from bounding boxes during pretraining which is very suitable for our scenario.</p><p>In addition, we make use of the label of each semantic entity, such as "Question", "Answer" in FUNSD label set as <ref type="figure">Figure 1</ref> shows. We map the entity labels into label embedding, as POS-tag embedding in dependency parsing. Then, we concatenate the entity representation and label embedding as the input of the document encoder for each semantic entity, as the following equation shows:</p><formula xml:id="formula_2">e i = b i ? l i<label>(1)</label></formula><p>where l i means entity label embedding, and b i means the representation of semantic entity, which can be obtained from the above-mentioned three pretrained models, e.g. word2vec, BERT and Lay-outLM .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Document Encoder</head><p>We compare different document encoders, including transformer, BiLSTM, and GCN, for better encoding the information of the semantic entities in VRDs. Specifically, we feed the representation of entity into the document encoder and obtain the output of the encoder as the contextual representation of the entity. Details of BiLSTM and transformer can refer to <ref type="bibr" target="#b10">Lample et al. (2016)</ref> and <ref type="bibr" target="#b19">Vaswani et al. (2017)</ref>, respectively. For GCN encoder, initial entity representation in graph is computed as subsection 3.3 shows. While updating the representation of the entity and edge, we follow the computation of <ref type="bibr" target="#b14">Liu et al. (2019a)</ref>. The edge embedding consists of 2 layout features, as the following equation shows:</p><formula xml:id="formula_3">r i,j = [x i,j , y i,j ]<label>(2)</label></formula><p>where x ij and y ij are horizontal and vertical distance between the two entity boxes respectively:</p><formula xml:id="formula_4">x i,j = min(|x 1 i ? x 2 j |, |x 1 j ? x 2 i |) y i,j = min(|y 1 i ? y 2 j |, |y 1 j ? y 2 i |)<label>(3)</label></formula><p>For entity b i , we extract features h ij of each neighbour b j by concatenating the representation of the two entities and their corresponding edge.</p><formula xml:id="formula_5">h ij = e i ? r i,j ? e j<label>(4)</label></formula><p>Then, we update the representation of entity and edge so that each entity can extract relevant information from other entities according to the document layout information, as the following equation shows:</p><formula xml:id="formula_6">e i = n j=1 ? ij h ij r i,j = W r h ij + b r<label>(5)</label></formula><p>and ? ij is the attention weight and can be computed as follows:</p><formula xml:id="formula_7">? ij = exp(LeakyRelu(W a h ij )) n j=1 exp(LeakyRelu(W a h ij ))<label>(6)</label></formula><p>Where, n means the number of entities in a document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Relation Scorer</head><p>Following the biaffine parser, we firstly apply MLP module to drop trivial information which is unrelated to current relation decision. Two MLP are used to generate the different representation of key and value roles in each relation link, which indicates the direction of arc in <ref type="figure">Figure 1</ref>.</p><formula xml:id="formula_8">h key i = F (W key e i + b key ) h value j = F (W value e j + b value )<label>(7)</label></formula><p>where F is an activation function. Then, we use biaffine attention to compute the score between two semantic entities as follows:</p><formula xml:id="formula_9">Score B i,j =h key i W B 1 h value j + h key i W B 2<label>(8)</label></formula><p>Such biaffine mechanism can capture pairwise relationship between entities better. We also use layout information r i,j as external features to help the model predict relations between entities better. Such layout features indicate the position relationship between entity b i and entity b j : left-to-right or top-to-down. Empirically, we observe that entities in the left-to-right or top-todown order are more likely to exist relations. We use MLP to compute the layout feature score as follows:</p><formula xml:id="formula_10">Score F i,j = W F r i,j + b F<label>(9)</label></formula><p>Lastly, we add biaffine score with layout feature score together as the score of the relation between entity b i and entity b j :  </p><formula xml:id="formula_11">Score i,j = Score B i,j + Score F i,j<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Relation Decoder</head><p>Based on relation scores between entities, two different relation decoding methods decide different loss functions of our training objective.</p><p>The first method is to judge whether there exists relation between any two entities in each VRD and such way is similar to semantic role labeling (SRL). In such setting, we take the relation prediction as a binary classification task and use binary cross entropy loss as G. Jaume and Thiran <ref type="formula" target="#formula_2">(2019)</ref>.</p><p>The second is to choose one head entity from all entities in one VRD for the current one, which is similar to the decoder in dependency parsing. This method means that each entity must have exactly one head entity, namely single-head constraint. Now, relation prediction is seen as a multiclassification task and use softmax cross entropy loss as <ref type="bibr" target="#b3">Dozat and Manning (2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We conduct experiments on the FUNSD 4 data, which is published by G. Jaume and Thiran (2019) for the form understanding task. Moreover, to verify our proposed model, we also collect real-world dataset from the customs scenario.</p><p>FUNSD is composed of 199 fully annotated, scanned forms with comprehensive annotations to address form understanding tasks including entity labeling and relation extraction. We follow the data split as G. Jaume and Thiran (2019), and detailed data statistics are listed in <ref type="table" target="#tab_1">Table 1</ref>, including the entity/relation distribution in FUNSD.</p><p>Customs Data consists of about 1,600 customs declaration documents in different layouts and languages collected by us. There are four types of documents: packing list, invoice, sales contract and customs declaration form, and each kind of document provides different information which is useful to apply to the customs. <ref type="figure" target="#fig_1">Figure 3</ref> gives one invoice example, providing unit price, quantity and other details. Customs documents may be in Chinese or English, and their format may contain Word, Excel, PDF or image. We parse these documents by a self-developed OCR tool to get semantic entities in each VRD. We organize crowd-sourcing to annotate labels of entities given the predefined label set, containing 48 kinds of label which are important for customs information extraction system. We can get the key entities according to the map dictionary from each predefined entity label to its all possible names in VRDs due to these names are enumerable. Then, we link the entities from keys to values respectively with same labels. We finally get the annotated customs data annotated with labels of entities and relations between entities. The scale of our collected customs data is much bigger than the FUNSD data as <ref type="table" target="#tab_1">Table 1</ref> shows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data Preprocessing</head><p>Multi-Head &amp; Zero-Head Entities. In terms of dependency parsing, one word must have one and only one head (the single-head constraint). However, zero-head entity that has no relations with any other entities or multi-head entity that has multiple heads does appear in our dataset. For zero-head entity, we add a pseudo root entity and link these zerohead entities to the pseudo entity as <ref type="figure">Figure 1</ref> shows. For multi-head entity, we randomly remain one head entity and delete others to get single-head entity while under single-head constraint. In FUNSD, there are 324 (/4,236) and 16 (/1,048) multi-head entities in train/test data respectively, accounts for a small part in all data.</p><p>Auto Labels. It is intuitive that type-tagged entity will ease the prediction of relations between semantic entities. We employ an effective entity labeling model consisting of two modules: entity encoder and label scorer. We take LayoutLM to encode the document and get the entity representation in a similar way as our relation extraction model. We also introduce three layout features w i , h i , c i into our entity representation and map the features into 10-dim embedding. w i and h i mean the width and height of the bounding box and c i means the length of characters in word group of each semantic entity. After concatenating the feature embedding and LayoutLM output, we pass them into the MLP scorer to compute the score of each candidate label. By this way, we get the auto label of our relation extraction data 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Metrics</head><p>To evaluate our semantic entity linking model, we take the entity-level precision, recall and F1 score as measure standard. Under single-head constraint, we ignore the links pointed from pseudo root entity in gold and predicted results for fair comparison with other works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Parameters</head><p>We investigate several pretrained language models to obtain entity representation, i.e, word2vec, BERT, and LayoutLM. For word2vec, we obtain the entity representation by averaging embeddings of the words contained in one entity; and for BERT/LayoutLM, we use the base model and take the hidden state output of the first subword of word group as the whole entity representation. Therefore, the representation dimension of words within bounding box is 100 while using word2vec and 768 while using BERT or LayoutLM. We use 100-dim embedding to represent the entity labels, so our entity representation is 200 or 864 6 .</p><p>To encode the whole VRD, we investigate 1layer BiLSTM or 1-layer transformer or 2-layer GCN encoders. The hidden state dimension of BiLSTM and transformer is 300 and the dimension of output edge and entity representations generated by GCN is 100.</p><p>The learning rate for BERT and LayoutLM is set to 1e-5 and others to 1e-2. The model are trained <ref type="bibr">5</ref> We train the labeling model on the whole training data and predict the auto labels of the test data. And we split training data into 5-fold, and train model with 4-fold to generate automatic labels of the left 1-fold training data. 6 While using transformer, it's difficult to set the number of heads in multi-head self-attention if dim of entity representation is 868. Here, we use a 96-dim label embedding instead.  <ref type="table">Table 2</ref>: Performance of entity relation extraction task on the FUNSD test data of previous works and our model with different but important settings. We reimplement previous works after application to entity relation extraction task, except for the work of <ref type="bibr" target="#b0">Carbonell et al. (2021)</ref>. We report their published experiment results in their paper.</p><p>for 50 iterations on FUNSD data and 100 iterations on customs data 7 . And each iteration we traverse the whole training data under all settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overall Results</head><p>We adapt the biaffine model from the dependency parsing task to our entity relation extraction task, and conduct detailed experiments on FUNSD dataset. Experimental results are shown in <ref type="table">Table 2</ref>. Previous works. Firstly, we train the original biaffine model <ref type="bibr" target="#b3">(Dozat and Manning, 2017)</ref> after replacing each word and its POS-tag with word group and entity label of each entity, but achieve poor performance. Then, we re-implement the entity relation extraction model proposed by G. Jaume and Thiran (2019), which consists of BERT as the entity encoder and MLP as the relation scorer. And our re-implement results are much higher than the performance reported in their paper (0.04% F1). We replace BERT with LayoutLM and keep other parts unchanged to encode the layout coordinate information into relation extraction task and model performance improves a little. <ref type="bibr" target="#b0">Carbonell et al. (2021)</ref> also utilize MLP link scorer but encode documents with k-layer GNN instead of BERT or LayoutLM, P R F1 WORD2VEC 0.0187 0.0403 0.0256 BERT 0.5539 0.5887 0.5708 LAYOUTLM 0.6189 0.6756 0.6460 <ref type="table">Table 3</ref>: Performance of entity relation extraction on the FUNSD test data. We compare different pretrained language model used to encode entities and keep other modules of SERA unchanged. and they achieve higher performance than other previous works.</p><p>Our Models. We propose our semantic entity relation extraction model based on the architecture of the biaffine parser as Section 3 describes. We apply LayoutLM/GCN as our entity/document encoder and optimize our models with softmax cross entropy loss under the single-head constraint. Results show that our proposed SERA achieves much higher performance than previous works by a large margin. Performance improvement demonstrates that layout information plays an important role in entity relation extraction task. Two ablation experiments verify the effectiveness of the layout feature scorer and auto labels of entities. Our SERA model can further improve the performance with two training strategies: data augmentation and multi-task learning of entity labeling and relation extraction.</p><p>Detailed experiments about our different explorations for entity relation extraction task are discussed in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Entity Representation</head><p>While encoding semantic entities, we employ three different pretrained models 8 and comparison experiment results are listed in <ref type="table">Table 3</ref>. Results show that encoding entities with LayoutLM performs the best because it introduces layout information into its transformer encoder and has been pretrained on a large scale of VRDs compared with BERT. Word2vec achieves much poorer performance than the other two due to the missing context-aware information inside semantic entities. <ref type="table">Table 2</ref> demonstrates that taking entity label embedding as part of the entity representation can improve the model performance. From our analysis on the FUNSD data, we find that many entity relation links point from entities with label 'Question' to entities with label 'Answer' and almost no   relations in-between answers or questions 9 . Therefore, entity labels help the extraction model prune the unreasonable relations and enrich the entity representation. The gap between models with gold labels and auto labels is about 10% F1, which indicates the room for improvement is still large if we can obtain better auto entity labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Document Encoder</head><p>We investigate three popular encoders, including transformer, BiLSTM and GCN to encode VRDs. Experiment results in <ref type="table" target="#tab_4">Table 4</ref> show GCN encoder performs much better than the other two in our task. The GCN we applied can be seen as an improvement of self-attention mechanism due to it introduces layout information into the document encoder as Formula 4 shows. Such layout features indicate the positional relation between entities according to x-axis or y-axis coordinates. They help document encoder to copy more information from adjacent entities which are more relevant to current entity, while transformer updates entity representation according to the textual information alone. BiLSTM encodes the entities in documents in the plain sequential order. However, the sequential order is not suitable for the VRD understanding, for example, many key-value pairs in tables are in top and down order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Relation Decoder</head><p>Decoding relation links between entities with or without the single-head constraint leads to a large <ref type="bibr">9</ref> In FUNSD training data, relations between answers or questions occupy only about 1%.  <ref type="table">Table 6</ref>: Performance of entity relation extraction on the FUNSD test data. We train our SERA with two training strategies: data augmentation and multi-task learning.</p><p>performance gap as <ref type="table" target="#tab_5">Table 5</ref> shows. Using different relation scorer, the trend between these two decoders is contrary. MLP scorer performs poorer than biaffine scorer under single-head constraint. This is because biaffine scorer is more suitable for single-head constraint which has been proved by <ref type="bibr" target="#b3">Dozat and Manning (2017)</ref>. Without such constraint, the task is similar to SRL, and more SRL previous works prefer to the MLP scorer.</p><p>Our error analysis finds that biaffine scorer without single-head constraint leads to the model prefers to predict multi-head links for entities, which is not consistent with the data distribution.</p><p>Due to the big gap between the biaffine scorer with single-head constraint and the MLP scorer with multi-head constraint, we finally choose the biaffine scorer and add the single-head constraint in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Training Strategies</head><p>To get better performance in entity relation extraction task, we apply two training strategies. Firstly, we take entity labeling and relation extraction tasks as multi-task learning (MTL) <ref type="bibr" target="#b1">(Collobert and Weston, 2008;</ref><ref type="bibr" target="#b18">Nguyen and Verspoor, 2018)</ref> and these two tasks share the pretrained language model in entity encoder and fine-tune the sharing parameter together during training. Relation extraction task can improve by about 0.86% F1 while labeling model performance drops a little from <ref type="table">Table 6</ref>. Performance improvement demonstrates that MTL is highly effective on alleviating error propagation from entity labeling task.</p><p>Secondly, we try to augment our training data due to the small size of training documents in the FUNSD data <ref type="bibr" target="#b9">(Krizhevsky et al., 2017)</ref>. We randomly drop some words in ratio 0.2 from word group of each entity to obtain more pseudo documents. We combine these pseudo training data with the gold training data and keep the test data unchanged. Models trained on the training data P R F1 BERT ENGLISH 0.7726 0.7806 0.7853 CHINESE 0.7950 0.8320 0.8131 LayoutLM ENGLISH 0.8464 0.8602 0.8533 <ref type="table">Table 7</ref>: Performance of entity relation extraction on the customs data using SERA. We compare different language models in different languages. after augmentation improve performance by about 1.1% F1 with auto label and 2.9% F1 with gold label. Improvement gap between the two indicates that relation extraction model is sensitive to the accuracy of entity labels.</p><p>Combination of these two strategies performs the best under the auto entity label settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Customs Data</head><p>We apply our SERA with best configuration to our collected customs data. Due to documents in customs data may be in Chinese and English, pretrained Chinese or English language model cannot cover the words in documents by its vocabulary perfectly. We conduct experiments with different pretrained models in different languages to study this problem deeply.</p><p>As <ref type="table">Table 7</ref> shows, our proposed model works well on the customs data, whose scale is much larger than FUNSD. Customs data contain more layout information, such as tables as <ref type="figure" target="#fig_1">Figure 3</ref> shows. We observe that the Chinese BERT is better than the English BERT on our language mixed data. We analyse their vocabularies and find Chinese vocabulary can cover more words in documents. Even though Chinese BERT performs better, English LayoutLM still achieves the best results among three pretrained models. This indicates encoding layout information into language model makes difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper focuses on the largely-unexplored entity relation extraction task in VRDs. We take advantages of previous works in semantic entity labeling and dependency parsing and propose our relation extraction model SERA. Our improved entity relation extraction model achieves 64.60% F1 score on the FUNSD data, outperforming previous baseline by a large margin; and we employ two simple but effective training strategies to further improve the performance to 65.96%, i.e., multi-task learning with entity labeling and data augmentation. In addition, We verify the effectiveness of our model on the real-world customs data with different layouts in the production setting. In the future, we plan to incorporate more visual features into the relation extraction model and also extend it into more domains and business scenarios.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>The architecture of our proposed entity relation extraction model (left) and the biaffine parser model (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>One commercial invoice example in customs data and its filetype is Excel. Some sensitive information are replaced by blue blocks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Data statistics of the FUNSD and customs datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Performance of entity relation extraction on the FUNSD test data. We compare different document encoder and other modules of SERA remains unchanged.</figDesc><table><row><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>MLP + MULTI</cell><cell>0.5317</cell><cell>0.4803</cell><cell>0.5047</cell></row><row><cell>MLP + SINGLE</cell><cell>0.3041</cell><cell>0.3082</cell><cell>0.3062</cell></row><row><cell>BIAFFINE + MULTI</cell><cell>0.6470</cell><cell>0.3618</cell><cell>0.4641</cell></row><row><cell>BIAFFINE + SINGLE</cell><cell>0.6189</cell><cell>0.6756</cell><cell>0.6460</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>: Performance of SERA on the FUNSD test</cell></row><row><cell>data. Different relation scorers with different loss func-</cell></row><row><cell>tions are used under different constraints.</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In different papers, the bounding boxes are called differently, such as semantic entities, text segments, etc. In this paper, we follow the naming convention used in the paper of the FUNSD dataset (G. Jaume and Thiran, 2019).2 Other visual features such as font size, colors and so on are not provided in the FUNSD dataset, thus not considered in this work.3  To avoid confusion with the entity linking in knowledge graphs, we name the task as entity relation extraction instead of entity linking used in G. Jaume and Thiran (2019), as this task aims to discover relations between semantic entities</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The FUNSD data can be downloaded from https://guillaumejaume.github.io/FUNSD/.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">We train the model for 50/100 iterations, and then predict test set on the trained model.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">In our model, BERT and LayoutLM encode entities in each document as we concatenate words in all bounding boxes in the order from top left to bottom right as Xu et al. (2020b).</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Named entity recognition and relation extraction with graph neural networks in semi structured documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pau</forename><surname>Riba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauricio</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alicia</forename><surname>Forn?s</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josep</forename><surname>Llad?s</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 25th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9622" to="9627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008)</title>
		<meeting><address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008-06-05" />
			<biblScope unit="volume">307</biblScope>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
	<note>ACM International Conference Proceeding Series</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep biaffine attention for neural dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Funsd: A dataset for form understanding in noisy scanned documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ekenel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jaume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thiran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Document Analysis and Recognition Workshops (IC-DARW)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Grali?ski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Stanis?awek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Wr?blewska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawid</forename><surname>Lipi?ski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Kaliska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paulina</forename><surname>Rosalska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartosz</forename><surname>Topolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Przemys?aw</forename><surname>Biecek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.02356</idno>
		<title level="m">Kleister: A novel task for information extraction involving long documents with complex layout</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Eaten: Entity-aware attention for single shot visual text extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiameng</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingtuo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Errui</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="254" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ICDAR2019 competition on scanned receipt OCR and information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhua</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimosthenis</forename><surname>Karatzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijian</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Document Analysis and Recognition, ICDAR 2019</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-09-20" />
			<biblScope unit="page" from="1516" to="1520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simple and accurate dependency parsing using bidirectional LSTM feature representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliyahu</forename><surname>Kiperwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="313" to="327" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="84" to="90" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Hinton</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Tablebank: Table benchmark for image-based table detection and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/1903.01949</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.01038</idno>
		<title level="m">Docbank: A benchmark dataset for document layout analysis</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dependency or span, end-to-end uniform semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shexia</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6730" to="6737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Graph convolution for multimodal information extraction from visually rich documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huasha</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="32" to="39" />
		</imprint>
	</monogr>
	<note>Industry Papers</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Roberta: A robustly optimized BERT pretraining approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>abs/1907.11692</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Representation learning for information extraction from form-like documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navneet</forename><surname>Bodhisattwa Prasad Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Potti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">Bradley</forename><surname>Tata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wendt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Najork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 58th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6495" to="6504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An improved neural network model for joint POS tagging and dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>Dat Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Verspoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="81" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Robust layout-aware IE for visually rich documents with pre-trained language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengxi</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event</title>
		<meeting>the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-07-25" />
			<biblScope unit="page" from="2367" to="2376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Layoutlmv2: Multi-modal pre-training for visually-rich document understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengchao</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoxin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinei</forename><surname>Florencio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cha</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.14740</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Layoutlm: Pretraining of text and layout for document image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1192" to="1200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Named entity recognition as dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juntao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.577</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6470" to="6476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Pick: Processing key information extraction from documents using improved graph learning-convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianbiao</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.07464</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Ping Gong, and Rong Xiao</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elaheh</forename><surname>Shafieibavani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio Jimeno</forename><surname>Yepes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10683</idno>
		<title level="m">Image-based table recognition: data, model, and evaluation</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Publaynet: largest dataset ever for document layout analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Jimeno-Yepes</surname></persName>
		</author>
		<idno>abs/1908.07836</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
