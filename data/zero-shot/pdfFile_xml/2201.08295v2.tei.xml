<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DIVA-DAF: A Deep Learning Framework for Historical Document Image Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>V?gtlin</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Document Image and Voice Analysis Group (DIVA</orgName>
								<orgName type="institution">University of Fribourg</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Maergner</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Document Image and Voice Analysis Group (DIVA</orgName>
								<orgName type="institution">University of Fribourg</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rolf</forename><surname>Ingold</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Document Image and Voice Analysis Group (DIVA</orgName>
								<orgName type="institution">University of Fribourg</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DIVA-DAF: A Deep Learning Framework for Historical Document Image Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Framework, Open-Source ? Deep Learning ? Neural Net- works ? Reproducible Research ? Machine Learning ? Historical Document Image Analysis</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we introduce a new deep learning framework called DIVA-DAF. We have developed this framework to support our research on historical document image analysis tasks and to develop techniques to reduce the need for manually-labeled ground truth. We want to apply self-supervised learning techniques and use different kinds of training data. Our new framework aids us in performing rapid prototyping and reproducible experiments. We present a first semantic segmentation experiment on DIVA-HisDB using our framework, achieving state-of-theart results. The DIVA-DAF framework is open-source, and we encourage other research groups to use it for their experiments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep learning (DL) methods have played a significant role in the last decade in increasing the performance of Computer Vision (CV) tasks and, as such, also historical document image analysis (HDIA) tasks. The drawback of common DL approaches is their enormous hunger for annotated data. This hunger is particularly problematic in HDIA since most tasks, like semantic labeling, require experts to label the document images correctly. For example, historical handwritten documents often contain comments surrounding or intersecting the main text. Distinguishing between these two classes is crucial for analyzing the document. However, this distinction often requires expert knowledge. <ref type="figure" target="#fig_1">Fig. 1</ref> shows a few examples where the distinction between comment and the main text is difficult.</p><p>In our research, we want to reduce the requirement for manually-labeled ground truth for HDIA with the help of different techniques, like applying selfsupervised learning <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b16">17]</ref> and synthesizing data <ref type="bibr" target="#b43">[43]</ref>. We have created a new framework called DIVA-DAF that aids us with this research. Our framework allows us to perform rapid prototyping and reproducible experiments focusing on HDIA tasks. The framework is open-source 1 , and we encourage other research groups to use it for their experiments. This paper introduces our framework to the research community and shows some initial experiments.  A variety of general strategies exist to reduce the need for manually-labeled data. Four common strategies are transfer learning, data augmentation, synthesizing data, and unsupervised learning.</p><p>-Transfer learning trains a deep neural network on a similar dataset, which provides more labeled data and then fine-tunes it on the actual small labeled target dataset <ref type="bibr" target="#b13">[14]</ref>. -Data augmentation can be performed, e.g., by degrading real documents so that the existing ground truth can still be used <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b36">37]</ref>. -Synthesizing data is creating new documents based on existing real documents <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b43">43]</ref> or creating new documents from scratch. -Unsupervised learning strategies are, e.g., autoencoders <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b7">8]</ref>. Another unsupervised strategy is self-supervised learning where the network is pretrained using a pretext task <ref type="bibr" target="#b16">[17]</ref>.</p><p>DIVA-DAF supports these strategies by offering a powerful configuration file system. This configuration file defines the training data and the task used for training the neural network and the neural network architecture. A network train with one configuration file can be trained further using another configuration file. The neural network architecture consists of a backbone and a header, which can both be adjusted separately using the configuration file. The framework logs each run in detail and stores its configuration file to ensure that the same experiment can be reproduced later. Additionally, the framework takes advantage of current hardware acceleration like GPU clusters. These features make our framework a powerful tool to conduct Historical Document Image Analysis (HDIA) experiments.</p><p>In the remainder of this paper, we provide an overview of related work in section 2. Then, we introduce our framework in section 3. Next, we describe the features of our framework in section 4. Afterward, we present a case study using our framework in section 5. Finally, we offer our conclusion and outlook in section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In our literature research, we came across different existing frameworks for Deep Learning (DL) with which we share the general motivation as well as ideas.</p><p>Data Version Control <ref type="bibr" target="#b15">[16]</ref> takes care of managing Machine Learning (ML) project, including code and data. This is achieved with a git-like Command Line Interface (CLI).</p><p>Comet <ref type="bibr" target="#b2">[3]</ref>, Neptune <ref type="bibr" target="#b3">[4]</ref>, and Weights and Biases <ref type="bibr" target="#b11">[12]</ref> take care of tracking your code, experiments, and results as well as visualizing them. They work with a large amount of different machine learning libraries.</p><p>By making datasets, tasks, workflows, as well as results accessible for the public, OpenML <ref type="bibr" target="#b42">[42]</ref> focused on the reproducibility of experiments. The same focus was taken by DeepDIVA <ref type="bibr" target="#b6">[7]</ref> for Computer Vision (CV) as well as DeepZensols <ref type="bibr" target="#b30">[31]</ref> for Natural Language Processing (NLP). They made DL experiment intuitive and fast to set up by providing different out-of-the-box experiments and visualizations. Other tools like Tensorboard Sacred <ref type="bibr" target="#b20">[21]</ref>, CDE <ref type="bibr" target="#b21">[22]</ref>, FGBLab <ref type="bibr" target="#b9">[10]</ref>, Sumatra <ref type="bibr" target="#b17">[18]</ref>, and ReproZip <ref type="bibr" target="#b14">[15]</ref> store a verity of different information about code, dependencies, host information, system calls or files used to ensure reproducible research. Cobra <ref type="bibr" target="#b44">[44]</ref> supports the user to create a reproducible project by keeping track of the code and the versions of the dependencies.</p><p>With CodaLab <ref type="bibr" target="#b1">[2]</ref> users can run reproducible experiments and can rerun experiments of other users to validate their results. It also allows to participate in different competitions or host a new competition. All of these features are provided through a proprietary web interface.</p><p>Polyaxon <ref type="bibr" target="#b4">[5]</ref> lets you build, train, and monitor large-scale deep learning applications on their online open-source platform. It is compatible with a large variety of DL libraries.</p><p>Chainer <ref type="bibr" target="#b40">[41]</ref> provides a wide range of DL models for researchers in a flexible and intuitive fashion. The framework's focus is high-performance and distributed training, which is achieved with the help of standard Python libraries.</p><p>Orhei et al. <ref type="bibr" target="#b33">[34]</ref> tackled the problem of creating a true end-to-end ML platform, that allows to combine DL approach together with classical Pattern Recognition (PR) methods. Additionally, their platform is constructed to be easily usable for research and educational purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DIVA-DAF -Document Analysis Framework</head><p>In this section, we introduce our deep learning framework DIVA-DAF. We aim to develop a framework that allows rapid prototyping for historical document analysis while leveraging state-of-the-art deep learning technologies and architectures. Our framework is based on PyTorch <ref type="bibr" target="#b34">[35]</ref> and open-source. We encourage the research community to use it for their experiments.</p><p>The intended application for DIVA-DAF is historical document image analysis. We want to train models using different amounts and types of training data and apply self-supervised learning methods. Therefore, we have made many design decisions with these tasks in mind. For example, the framework supports high-resolution scans of historical document image pages that would not directly fit into GPU memory by cropping the image. The amount of training data can be adjusted easily, and it also supports training the network on different tasks.</p><p>Overall, we plan to run an extensive amount of different research experiments using this framework. We want to ensure that we can quickly set up different kinds of experiments, easily keep track of them, and rerun them in a reproducible manner. Therefore, we have three main objectives while developing our framework: (1) Rapid prototyping, (2) Reproducibility, (3) State-of-the-art deep learning technologies. We achieved these objectives using several different features. In the following paragraphs, we overview each objective and the related features. In section 4, we give a more detailed overview of each feature.</p><p>Our framework allows rapid prototyping by defining each experiment using a configuration file. This configuration file can link to multiple other configuration files that precisely define each class's parameters in the system. For example, the experiment configuration file can contain another configuration file that defines the loss function class. The classes can be from the framework itself or an imported library. This procedure allows the user to set up experiments and modify parameters without coding anything. Additionally, DIVA-DAF is compatible with other deep learning frameworks. This compatibility allows the user to reuse existing implementations before implementing everything from scratch. These features allow the user to set up experiments rapidly.</p><p>The reproducibility of experiments is one of the critical issues of our time, as stated by <ref type="bibr" target="#b32">[33]</ref>. Hutson even sees the research community in a reproducibility crisis <ref type="bibr" target="#b23">[24]</ref>. Our framework allows the user to run reproducible experiments by automatically saving the experiment's configuration file alongside the results and network weights. It also saves the seed used to initialize the pseudo-random generators used during training to initialize the neural network weights. Using the configuration file with this seed, other researchers can quickly reproduce published results with our framework.</p><p>The foundation of DIVA-DAF is PyTorch, one of the most popular machine-learning frameworks. This foundation allows us to benefit from the vast community of researchers constantly implementing new ideas using PyTorch. It supports the latest GPU and server architectures. Researchers can use certain implementations directly in our framework, e.g., the neural network model implementations provided by the well-known Torchvision <ref type="bibr" target="#b34">[35]</ref> library.</p><p>Our framework is open-source and publicly available for any scientific purpose. It is available on GitHub via this link: https://github.com/DIVA-DIA/ DIVA-DAF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Main Components</head><p>The framework consists of several components following an object-oriented programming paradigm. The framework's components are based on PyTorch-Lightning <ref type="bibr" target="#b19">[20]</ref>, a PyTorch research framework that focuses on the rapid development of research experiments. Four main components of our framework are (1) datamodule, (2) model, (3) task, (4) trainer (see <ref type="figure" target="#fig_2">Fig. 2</ref>). Compared to PyTorch-Lightning, we have separated the LightningModule into two components: the model, which defines the neural network architecture, and the task, which describes the task that we try to solve. By defining these components independently, we can solve the same task using different models or use the same model to solve different tasks. The datamodule handles the data and creates the different datasets needed for each stage (training, validation, testing). Furthermore, it calculates data statistics and defines special data handling, such as data augmentation and transformations.</p><p>The model specifies the neural network architecture by defining the backbone and the header. The backbone acts as the encoder part of the network and the header as the classifier. By defining these two parts separately, the framework can save them independently and combine them with other backbones or headers.</p><p>The task defines the workflow during training, validation, and testing. It requires four inputs: a loss function, an optimizer, a metric, and a model. Also, it produces the test output and provides the needed method to bring the network output into a loss or metric format.</p><p>The trainer connects the different components of our framework and runs them. It executes the different stages -training, validation, and testing -and runs the neural network. It is also responsible for initializing the different hardware devices and moving data and models to the correct device. We use the default implementation of PyTorch-Lightning, but users could also exchange or modify this part if required.</p><p>Additionally to the four core modules, the framework contains several smaller components: loss, optimizer, metric, logger, callbacks, and plugins. Loss, optimizer, and metric are a subpart of the task module. The logger provides the possibility to use the user's favorite logging system (see section 4.5). With plugins and callbacks, which PyTorch-Lightning provides, the user can control the behavior of devices, stage loops, and other parts of the framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Features</head><p>This section will present the complementary features to the previous subsection 3.1. The most important feature of our framework and also the base of other features is the configuration system that we present in subsection 4.1. Based on the configuration system, we introduce the out-of-the-box feature in subsection 4.2. In subsection 4.3, we will present the callback system of DIVA-DAF. To further adapt the framework to the user's need, we will discuss the modularity of the framework in subsection 4.4. Finally, in section 4.5 we will present the logging capability of our framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Configurations</head><p>We use configuration files to rerun an experiment quickly or share it with a colleague easily. The configuration system of our framework is provided by Hydra <ref type="bibr" target="#b45">[45]</ref>, which creates python objects based on configuration files in an elegant fashion. These configuration files contain the python path to a class and the arguments to initialize the class. The path can lead to a class implemented by the user or to one in a python package, e.g., Torchvision. By combining the different configurations for the task, model, metric, and loss, the user can create a precise definition of an experiment. When the framework has successfully read all configuration files, it combines them and stores this run configuration in the specific experiment output folder. Using this experiment configuration file, we can reproduce an experiment as all the parameters of each created object are stored.</p><p>Datamodules and tasks objects have an additional ability. Configurations can use run-time variables from these objects in their definitions. For example, the user can set the number of output filters for a segmentation network depending on the datamodule at run-time. In Listing 1.1, we show how we can use run-time information of the datamodule object in the network configuration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Out-of-the-box Deep Learning</head><p>The setup of DIVA-DAF is straightforward: The user clones the code from the GitHub repository 2 and create a new Anaconda <ref type="bibr" target="#b0">[1]</ref> environment based on the shipped environment file (conda env gpu.yaml). This environment contains all dependencies with the corresponding versions to run the framework. If a researcher wants to run the framework with GPU, TPU, or IPU support, the appropriate drivers and the correct PyTorch support packages (CUDA, ROCm, etc.) must be installed.</p><p>In its current state, DIVA-DAF contains sample code for two different Document Image Analysis tasks: semantic segmentation and image classification. These tasks can be combined with different datamodules (see section 3.1) like DIVA-HisDB <ref type="bibr" target="#b37">[38]</ref> or CIFAR10 <ref type="bibr" target="#b29">[30]</ref>. Additionally, our framework provides default implementations and their corresponding configuration for models, losses, optimizers, and metrics. For example, famous neural network architectures like ResNet <ref type="bibr" target="#b22">[23]</ref> and U-Net <ref type="bibr" target="#b35">[36]</ref>, or the widely used ADAM optimizer <ref type="bibr" target="#b28">[29]</ref> are part of the framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Callbacks</head><p>The callback functionality is provided by the underlying PyTorch-Lightning <ref type="bibr" target="#b19">[20]</ref> library. The user can inject code into specific parts of our framework with a callback. Callbacks are self-contained programs that are invoked in a specific position in the code (see PyTorch-Lightning callback api 3 ). Each hook has its own set of parameters that can be used for different jobs. For example, if the user wants to save the output of each validation batch on each device, he can create a callback and overwrite the method on validation batch end(). This method receives the following arguments: the trainer, the task, the outputs, the batch, the batch index, and the data loader index. Based on these arguments, the user can now store the network output of each batch.</p><p>We already provide callbacks to save the different parts of the model, to check the compatibility between the backbone and the header of the model, and to visualize the gradients of the different layers of the network when using the Weights and Biases logger (see <ref type="figure" target="#fig_4">Fig. 3</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Modules</head><p>Our framework is built in a modular fashion, as described in subsection 3.1. Each module is independent and can be replaced with a third-party or user-defined implementation. For example, we want to use U-Net <ref type="bibr" target="#b35">[36]</ref> for a segmentation task that takes as a parameter the number of classes we want to segment. The library Lightning-Bolts <ref type="bibr" target="#b18">[19]</ref> contains an implementation of this architecture. We can use this class by writing a corresponding configuration file (see listing 1.1) and adding it as a model to our experiment configuration. The user can use library classes for the datamodule, the network models, the metrics, the losses, the optimizer, the logger, and the callbacks. In <ref type="table">Table 1</ref> we show a list of all libraries that are compatible with our framework and their functionality:</p><p>Users of the framework also can create their own modules. To conveniently implement a task or datamodule, the user can inherit from the corresponding abstract base class of the desired module. These abstract classes provide general variables and methods, giving the user a good starting point for creating their modules. <ref type="table">Table 1</ref>: List of compatible libraries and their modules at the moment of writing. The denotes that a certain library provides a certain module and that it does not. In parentheses modules which we did not test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Library</head><p>Model Metric Loss Optimizer Datamodule Callbacks Logger PyTorch Torchvision Torchmetric Lightning Bolts ()</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Logging</head><p>To keep track of experiments, we use the logging functionality of PyTorch-Lightning. They provide the most common loggers like Weights and Biases <ref type="bibr" target="#b11">[12]</ref> (see <ref type="figure">Fig. 4</ref>) or Tensorboard. The framework allows using multiple loggers simultaneously. Besides using a cloud-based logger, like Weights and Biases, the user can also use a local logger like the CSV logger. The CSV logger writes all the logging information into the local experiment folder for later use. Logging is not limited to scalar data like metric or loss information. It is also possible to log figures, images, or histograms, but each logger needs to do this individually. As with all the other modules of our framework, users can also implement their own logger or adapt an existing one. <ref type="figure">Fig. 4</ref>: A typical dashboard on Weights and Biases. On the left side we see a list of experiments and on the right side the plots of the logged information during the training stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Case Study</head><p>A typical task in historical Document Image Analysis (DIA) is semantic segmentation. Each pixel of an input image gets assigned one of a predefined set of classes. This output can further be used for tasks like text line segmentation <ref type="bibr" target="#b8">[9]</ref> or handwriting recognition <ref type="bibr" target="#b25">[26]</ref>. We present how to perform semantic segmentation on the Cod. Bodmer 55 of the well known DIVA-HisDB <ref type="bibr" target="#b37">[38]</ref> dataset (see <ref type="figure" target="#fig_6">Fig. 5</ref>). The dataset contains 30 pages for training, 10 pages for validation, and 10 pages for testing. Each page has a dimension of 4872?6496 pixels with a resolution of 600 dpi. Each pixel belongs to one of 8 classes (background, main text body, decoration, comment, main text body + comment, main text body + decoration, comment + decoration, main text body + decoration + comment).  DIVA-DAF provides a task module for semantic segmentation. We have to select a datamodule and bring the dataset into the expected format. We decide to process the page in crops of size 256?256 pixel because of the size of the full-page images. Precisely, we have prepared the training and validation data by cropping each page into 1376 300?300 pixel patches with 50% overlap. Then, we take a random 256?256 crop from each patch during each training and validation epoch. Accordingly, we select the datamodule available in DIVA-DAF that works with this kind of data (DIVAHisDB/datamodule cropped.py).</p><p>We use a random initialized vanilla U-Net <ref type="bibr" target="#b35">[36]</ref> architecture (?31 million parameters), which has eight output layers. The network was trained using the ADAM <ref type="bibr" target="#b28">[29]</ref> optimizer with a learning rate of 0.001 for 50 epochs with a batch size of 16. As a loss, we used the Cross-Entropy loss. We run all of our experiments on a server with 4 ? NVIDIA 1080 GTX with 8GB of GPU memory each, an Intel i7-5960X CPU, and 64 GB of RAM. To evaluate the networks output after testing we use the official evaluation tool <ref type="bibr" target="#b5">[6]</ref> of the ICDAR 2017 competition <ref type="bibr" target="#b38">[39]</ref>. The tool computes the mean Intersection over Union (mIoU) and the F1-score between the prediction of our network and the ground truth.</p><p>In our repository you will find under configs/experiment a file cb55 fullrun unet.yaml, that contains all above listed parameters and configurations. We will train the network with the train/val split and automatically execute the testing routine after training. To run this experiment you start the framework with the following command:</p><p>$ python run . py e x p e r i m e n t=c b 5 5 f u l l r u n u n e t . yaml</p><p>The run logs and the output of the testing stage will be stored in the experiment directory. Each setup (30, 15, 1 training page(s)) was executed three times with three different seeds and then averaged. We used for the three different setups always the same three seeds for the runs. Using the same seeds ensures that the experiments start with the same initial network weights.</p><p>A configuration file change is not needed to run the experiment if only a few parameters need to be changed. Instead, parameters can be changed or added as a command-line argument. In this experiment, we only want to adjust the number of training pages and seeds, which we can do more quickly using the command line. The following command shows how to run the base experiment with 15 training pages and a seed of 2149823.</p><p>$ python run . py e x p e r i m e n t=c b 5 5 f u l l r u n u n e t . yaml datamodule . s e l e c t i o n t r a i n =15 +s e e d =2149823  <ref type="table">Table 3</ref>: Visual results of semantic segmentation on the testset of DIVA-HisDBs CB55 with a U-Net. In the images you see comments(red), main text(purple), decoration(yellow), and main text + decoration(turquoise). We can see that the quality of the segmentation decreases with the amount of training pages. In <ref type="table" target="#tab_0">Table 2</ref> the averages of the different setups we ran and some state-of-theart results. We can see that our system with 30 training pages is close to the current state-of-the-art reported in the ICDAR 2017 competition <ref type="bibr" target="#b38">[39]</ref>. With 15 pages our model outperforms both the SegNet and the DeepLabV3 reporeted by Studer et al. <ref type="bibr" target="#b39">[40]</ref>. Even with one training page, we outperform the SegNet, and we achieve this with a training time of ?0.25h. An explanation could be that the first page of the training set is an excellent overall representation of the dataset.</p><p>In <ref type="table">Table 3</ref>, you can observe that the segmentation quality decreases with fewer training examples. Additionally, we can see that all setups struggle in certain sections to separate main text and comments. Overall, every setup produces precise contours and has a clean border between classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we introduce DIVA-DAF. It is an open-source Python-based deep learning framework designed to create rapid prototypes and reproducible experiments for the historical DIA community. It can be used on different hardware and takes full advantage of the different devices. Users can easily use predefined experiments or adapt them to their needs. It is possible to implement own tasks and datamodules straightforwardly due to the framework's abstract classes.</p><p>To improve the framework, we want to extend our set of tasks with more DIA relevant scenarios to make it even more attractive for the community. Also, we want to introduce self-supervised strategies to the framework to tackle the lack of manually-labeled ground truth. To further support the users in analyzing their results, we work on classification activation maps and filter visualization techniques to add to the framework. Overall, we continue to improve the general structure and efficiency of DIVA-DAF.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>Two sample images of the DIVA-HisDB [38] dataset: Each image (a, b) shows the problem of distinguishing comments and main text. Image (a) is a challenging document with interlinear glosses and letters of different sizes and colors. For a non-expert, it is hard to say if the curved line in image (b) is a comment or part of the main text.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>The module schema of DIVA-DAF. The orange modules are the main components, blue are additional components, and green is the configuration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Listing 1 . 1 :</head><label>11</label><figDesc>Usage of the datamodule variable num classes which is set during run-time. t a r g e t : p l b o l t s . models . v i s i o n . UNet n u m c l a s s e s : $ { datamodule : n u m c l a s s e s }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 :</head><label>3</label><figDesc>We provide a callback to log the gradients of a neural network. Here you see the weights and biases change during training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>Sample pages of the medieval manuscripts Cod. Bodmer 55 of DIVA-HisDB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>Results of semantic segmentation on the testset of DIVA-HisDBs CB55 with a U-Net. All results are averages over three runs with different random seeds. All our networks were trained for 50 epochs.</figDesc><table><row><cell cols="3">Authors Year #train pages</cell><cell>Model</cell><cell>Run time</cell><cell cols="2">mIoU[%] F1-Score[%]</cell></row><row><cell>[40]</cell><cell>2019</cell><cell>30</cell><cell>SegNet</cell><cell>?8h</cell><cell>86.90</cell><cell>N/A</cell></row><row><cell>[40]</cell><cell>2019</cell><cell>30</cell><cell>DeepLabV3</cell><cell>?8h</cell><cell>92.90</cell><cell>N/A</cell></row><row><cell>[39]</cell><cell>2017</cell><cell>30</cell><cell>FCN  *</cell><cell>N/A</cell><cell>98.35</cell><cell>N/A</cell></row><row><cell>[39]</cell><cell>2017</cell><cell>30</cell><cell>ResNet18</cell><cell>N/A</cell><cell>98.64</cell><cell>N/A</cell></row><row><cell>Ours</cell><cell>2022</cell><cell>1</cell><cell>U-Net</cell><cell>?0.25h</cell><cell cols="2">90.93?3.09 94.93?1.89</cell></row><row><cell>Ours</cell><cell>2022</cell><cell>15</cell><cell>U-Net</cell><cell>?2.75h</cell><cell cols="2">96.33?0.44 98.03?0.20</cell></row><row><cell>Ours</cell><cell>2022</cell><cell>30</cell><cell>U-Net</cell><cell>?3.5h</cell><cell cols="2">97.26?0.20 98.63?0.11</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* : Fully-convolutional Neural Network</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/DIVA-DIA/DIVA-DAF arXiv:2201.08295v2 [cs.CV] 21 Jan 2022</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/DIVA-DIA/DIVA-DAF 3 https://pytorch-lightning.readthedocs.io/en/latest/extensions/ callbacks.html</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<title level="m">Anaconda software distribution</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Codalab</surname></persName>
		</author>
		<ptr target="https://codalab.org/" />
		<imprint>
			<date type="published" when="2022-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<ptr target="https://www.comet.ml/" />
	</analytic>
	<monogr>
		<title level="j">Comet. Supercharge Machine Learning</title>
		<imprint>
			<date type="published" when="2022-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Metadata Store for MLOps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neptune</surname></persName>
		</author>
		<ptr target="https://neptune.ai/" />
		<imprint>
			<date type="published" when="2022-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Machine learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polyaxon</surname></persName>
		</author>
		<ptr target="https://polyaxon.com/" />
		<imprint>
			<date type="published" when="2022-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Open evaluation tool for layout analysis of document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IAPR International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="43" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improving Reproducible Deep Learning Workflows with DeepDIVA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pondenkandath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>V?gtlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>W?rsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th Swiss Conference on Data Science (SDS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04332</idno>
		<title level="m">Pitfall of Unsupervised Pre-Training</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Labeling, cutting, grouping: An efficient text line segmentation method for medieval manuscripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Voegtlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pondenkandath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th IAPR International Conference on Document Analysis and Recognition (ICDAR)</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Arulkumaran</surname></persName>
		</author>
		<title level="m">FGLab: Machine Learning Dashboard</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Document Image Defect Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Baird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structured Document Image Analysis</title>
		<editor>Baird, H.S., Bunke, H., Yamamoto, K.</editor>
		<meeting><address><addrLine>Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="546" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Biewald</surname></persName>
		</author>
		<title level="m">Experiment tracking with weights and biases</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">DocEmul: A Toolkit to Generate Structured Historical Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Capobianco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marinai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IAPR International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">01</biblScope>
			<biblScope unit="page" from="1186" to="1191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multitask Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="75" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reprozip: Computational reproducibility with ease</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chirigati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rampin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shasha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Conference on Management of Data</title>
		<meeting>the 2016 International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2085" to="2088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Data Version Control Git extension for data scientists -manage your code and data together</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Control</surname></persName>
		</author>
		<ptr target="https://dataversioncontrol.com/" />
		<imprint>
			<date type="published" when="2022-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Self-supervised Representation Learning on Document Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghidoveanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Panaitescu-Liess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis Systems</title>
		<editor>Bai, X., Karatzas, D., Lopresti, D.</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="103" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automated capture of experiment context for easier reproducibility in computational research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="48" to="56" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A framework for contrastive self-supervised learning and designing a new approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Falcon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.00104</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The PyTorch Lightning team: PyTorch Lightning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Falcon</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3828935</idno>
		<ptr target="https://doi.org/10.5281/zenodo.3828935" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The Sacred Infrastructure for Computational Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chovanec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Python in Science Conferences -SciPy Conferences</title>
		<meeting>the Python in Science Conferences -SciPy Conferences</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">CDE: A Tool for Creating Portable Experimental Software Packages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science Engineering</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="32" to="35" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Artificial intelligence faces reproducibility crisis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hutson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>American Association for the Advancement of Science</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">I</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Soh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">I</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05229</idno>
		<title level="m">Handwritten Text Segmentation via Endto-End Learning of Convolutional Neural Network</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">DocCreator: A New Software for Creating Synthetic Ground-Truthed Document Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Journet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Visani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mansencal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van-Cuong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Billy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Imaging</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">62</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A character degradation model for grayscale ancient document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Visani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Journet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Domenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mullot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)</title>
		<meeting>the 21st International Conference on Pattern Recognition (ICPR2012)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="685" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Learning multiple layers of features from tiny images</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Landes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Di Eugenio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Caragea</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.03383</idno>
		<title level="m">DeepZensols: Deep Natural Language Processing Framework</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cire?an</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks and Machine Learning -ICANN 2011</title>
		<editor>Honkela, T., Duch, W., Girolami, M., Kaski, S.</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Olorisade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Brereton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Andras</surname></persName>
		</author>
		<title level="m">Reproducibility in Machine Learning-Based Studies: An Example of Text Mining</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">End-To-End Computer Vision Framework: An Open-Source Platform for Research and Education</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Orhei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mocofan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">3691</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">PyTorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Wallach, H., Larochelle, H., Beygelzimer, A., dAlch?-Buc, F., Fox, E., Garnett, R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Gradient-domain degradations for improving historical documents images layout analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Eichenbergery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ingold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1006" to="1010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">DIVA-HisDB: A Precisely Annotated Large Dataset of Challenging Medieval Manuscripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Simistira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Eichenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ingold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th International Conference on Frontiers in Handwriting Recognition (ICFHR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="471" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">ICDAR2017 Competition on Layout Analysis for Challenging Medieval Manuscripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Simistira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>W?rsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IAPR International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">01</biblScope>
			<biblScope unit="page" from="1361" to="1370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A Comprehensive Study of ImageNet Pre-Training for Historical Document Image Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Studer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pondenkandath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goktepe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kolonko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ingold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="720" to="725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Chainer: A Deep Learning Framework for Accelerating the Research Cycle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Okuta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Akiba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ogawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Uenishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<biblScope unit="page" from="2002" to="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<title level="m">KDD &apos;19</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">OpenML: Networked Science in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanschoren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Van Rijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bischl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torgo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="49" to="60" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Generating Synthetic Handwritten Historical Documents with OCR Constrained GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>V?gtlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Drazyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pondenkandath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ingold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis and Recognition -ICDAR 2021</title>
		<editor>Llad?s, J., Lopresti, D., Uchida, S.</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="610" to="625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Cobra: A CLI Tool To Create And Share Reproducible Projects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>V?gtlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pondenkandath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ingold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 7th Swiss Conference on Data Science (SDS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="47" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Hydra -A framework for elegantly configuring complex applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yadan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Github</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
