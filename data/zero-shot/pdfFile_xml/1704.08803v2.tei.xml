<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Ranking Models with Weak Supervision</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-08-07">2017. August 07-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bruce Cro</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Massachuse</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">University of Massachuse</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Ranking Models with Weak Supervision</title>
					</analytic>
					<monogr>
						<title level="m">ACM Reference format: Mostafa Dehghani</title>
						<meeting> <address><addrLine>Shinjuku, Tokyo, Japan</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="volume">10</biblScope>
							<date type="published" when="2017-08-07">2017. August 07-11, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3077136.3080832</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T22:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Ranking model</term>
					<term>weak supervision</term>
					<term>deep neural net- work</term>
					<term>deep learning</term>
					<term>ad-hoc retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite the impressive improvements achieved by unsupervised deep neural networks in computer vision and NLP tasks, such improvements have not yet been observed in ranking for information retrieval. e reason may be the complexity of the ranking problem, as it is not obvious how to learn from queries and documents when no supervised signal is available. Hence, in this paper, we propose to train a neural ranking model using weak supervision, where labels are obtained automatically without human annotators or any external resources (e.g., click data). To this aim, we use the output of an unsupervised ranking model, such as BM25, as a weak supervision signal. We further train a set of simple yet e ective ranking models based on feed-forward neural networks. We study their e ectiveness under various learning scenarios (point-wise and pair-wise models) and using di erent input representations (i.e., from encoding querydocument pairs into dense/sparse vectors to using word embedding representation). We train our networks using tens of millions of training instances and evaluate it on two standard collections: a homogeneous news collection (Robust) and a heterogeneous large-scale web collection (ClueWeb). Our experiments indicate that employing proper objective functions and le ing the networks to learn the input representation based on weakly supervised data leads to impressive performance, with over 13% and 35% MAP improvements over the BM25 model on the Robust and the ClueWeb collections. Our ndings also suggest that supervised neural ranking models can greatly bene t from pre-training on large amounts of weakly labeled data that can be easily obtained from unsupervised IR models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Learning state-of-the-art deep neural network models requires a large amounts of labeled data, which is not always readily available * Work done while interning at Google Research. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). SIGIR '17, Shinjuku, Tokyo, Japan ? 2017 Copyright held by the owner/author(s). 978-1-4503-5022-8/17/08. . . $15.00 DOI: <ref type="bibr">10.1145/3077136.3080832</ref> and can be expensive to obtain. To circumvent the lack of humanlabeled training examples, unsupervised learning methods aim to model the underlying data distribution, thus learning powerful feature representations of the input data, which can be helpful for building more accurate discriminative models especially when li le or even no supervised data is available.</p><p>A large group of unsupervised neural models seeks to exploit the implicit internal structure of the input data, which in turn requires customized formulation of the training objective (loss function), targeted network architectures and o en non-trivial training setups. For example in NLP, various methods for learning distributed word representations, e.g., word2vec <ref type="bibr" target="#b26">[27]</ref>, GloVe <ref type="bibr" target="#b30">[31]</ref>, and sentence representations, e.g., paragraph vectors <ref type="bibr" target="#b22">[23]</ref> and skip-thought <ref type="bibr" target="#b21">[22]</ref> have been shown very useful to pre-train word embeddings that are then used for other tasks such as sentence classi cation, sentiment analysis, etc. Other generative approaches such as language modeling in NLP, and, more recently, various avors of auto-encoders <ref type="bibr" target="#b1">[2]</ref> and generative adversarial networks <ref type="bibr" target="#b12">[13]</ref> in computer vision have shown a promise in building more accurate models.</p><p>Despite the advances in computer vision, speech recognition, and NLP tasks using unsupervised deep neural networks, such advances have not been observed in core information retrieval (IR) problems, such as ranking. A plausible explanation is the complexity of the ranking problem in IR, in the sense that it is not obvious how to learn a ranking model from queries and documents when no supervision in form of the relevance information is available. To overcome this issue, in this paper, we propose to leverage large amounts of unsupervised data to infer "noisy" or "weak" labels and use that signal for learning supervised models as if we had the ground truth labels. In particular, we use classic unsupervised IR models as a weak supervision signal for training deep neural ranking models. Weak supervision here refers to a learning approach that creates its own training data by heuristically retrieving documents for a large query set. is training data is created automatically, and thus it is possible to generate billions of training instances with almost no cost. <ref type="bibr" target="#b0">1</ref> As training deep neural networks is an exceptionally data hungry process, the idea of pre-training on massive amount of weakly supervised data and then ne-tuning the model using a small amount of supervised data could improve the performance <ref type="bibr" target="#b10">[11]</ref>.</p><p>e main aim of this paper is to study the impact of weak supervision on neural ranking models, which we break down into the following concrete research questions:</p><p>RQ1 Can labels from an unsupervised IR model such as BM25 be used as weak supervision signal to train an e ective neural ranker? RQ2 What input representation and learning objective is most suitable for learning in such a se ing? RQ3 Can a supervised learning model bene t from a weak supervision step, especially in cases when labeled data is limited?</p><p>We examine various neural ranking models with di erent ranking architectures and objectives, i.e., point-wise and pair-wise, as well as di erent input representations, from encoding query-document pairs into dense/sparse vectors to learning query/document embedding representations. e models are trained on billions of training examples that are annotated by BM25, as the weak supervision signal. Interestingly, we observe that using just training data that are annotated by BM25 as the weak annotator, we can outperform BM25 itself on the test data. Based on our analysis, the achieved performance is generally indebted to three main factors: First, de ning an objective function that aims to learn the ranking instead of calibrated scoring to relax the network from ing to the imperfections in the weakly supervised training data. Second, le ing the neural networks learn optimal query/document representations instead of feeding them with a representation based on prede ned features. is is a key requirement to maximize the bene ts from deep learning models with weak supervision as it enables them to generalize be er. ird and last, the weak supervision se ing makes it possible to train the network on a massive amount of training data.</p><p>We further thoroughly analyse the behavior of models to understand what they learn, what is the relationship among di erent models, and how much training data is needed to go beyond the weak supervision signal. We also study if employing deep neural networks may help in di erent situations. Finally, we examine the scenario of using the network trained on a weak supervision signal as a pre-training step. We demonstrate that, in the ranking problem, the performance of deep neural networks trained on a limited amount of supervised data signi cantly improves when they are initialized from a model pre-trained on weakly labeled data.</p><p>Our results have broad impact as the proposal to use unsupervised traditional methods as weak supervision signals is applicable to variety of IR tasks, such as ltering or classi cation, without the need for supervised data. More generally, our approach uni es the classic IR models with currently emerging data-driven approaches in an elegant way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Deep neural networks have shown impressive performance in many computer vision, natural language processing, and speech recognition tasks <ref type="bibr" target="#b23">[24]</ref>. Recently, several a empts have been made to study deep neural networks in IR applications, which can be generally partitioned into two categories <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b45">46]</ref>. e rst category includes approaches that use the results of trained (deep) neural networks in order to improve the performance in IR applications. Among these, distributed word representations or embeddings <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b30">31]</ref> have a racted a lot of a ention. Word embedding vectors have been applied to term re-weighting in IR models <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b46">47]</ref>, query expansion <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b42">43]</ref>, query classi cation <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b43">44]</ref>, etc. e main shortcoming of most of the approaches in this category is that the objective of the trained neural network di ers from the objective of these tasks. For instance, the word embedding vectors proposed in <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b30">31]</ref> are trained based on term proximity in a large corpus, which is di erent from the objective in most IR tasks. To overcome this issue, some approaches try to learn representations in an end-to-end neural model for learning a speci c task like entity ranking for expert nding <ref type="bibr" target="#b38">[39]</ref> or product search <ref type="bibr" target="#b37">[38]</ref>. Zamani and Cro <ref type="bibr" target="#b44">[45]</ref> recently proposed relevance-based word embedding models for learning word representations based on the objectives that ma er for IR applications. e second category, which this paper belongs to, consists of the approaches that design and train a (deep) neural network for a speci c task, e.g., question answering <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b40">41]</ref>, click models <ref type="bibr" target="#b3">[4]</ref>, context-aware ranking <ref type="bibr" target="#b41">[42]</ref>, etc. A number of the approaches in this category have been proposed for ranking documents in response to a given query. ese approaches can be generally divided into two groups: late combination models and early combination models (or representation-focused and interaction-focused models according to <ref type="bibr" target="#b13">[14]</ref>). e late combination models, following the idea of Siamese networks <ref type="bibr" target="#b4">[5]</ref>, independently learn a representation for each query and candidate document and then calculate the similarity between the two estimated representations via a similarity function. For example, Huang et al. <ref type="bibr" target="#b17">[18]</ref> proposed DSSM, which is a feed forward neural network with a word hashing phase as the rst layer to predict the click probability given a query string and a document title. e DSSM model was further improved by incorporating convolutional neural networks <ref type="bibr" target="#b34">[35]</ref>.</p><p>On the other hand, the early combination models are designed based on the interactions between the query and the candidate document as the input of network. For instance, DeepMatch <ref type="bibr" target="#b25">[26]</ref> maps each text to a sequence of terms and trains a feed-forward network for computing the matching score. e deep relevance matching model for ad-hoc retrieval <ref type="bibr" target="#b13">[14]</ref> is another example of an early combination model that feeds a neural network with the histogram-based features representing interactions between the query and document. Early combining enables the model to have an opportunity to capture various interactions between query and document(s), while with late combination approach, the model has only the chance of isolated observation of input elements. Recently, Mitra et al. <ref type="bibr" target="#b27">[28]</ref> proposed to simultaneously learn local and distributional representations, which are early and late combination models respectively, to capture both exact term matching and semantic term matching.</p><p>Until now, all the proposed neural models for ranking are trained on either explicit relevance judgements or clickthrough logs. However, a massive amount of such training data is not always available.</p><p>In this paper, we propose to train neural ranking models using weak supervision, which is the most natural way to reuse the existing supervised learning models where the imperfect labels are treated as the ground truth. e basic assumption is that we can cheaply obtain labels (that are of lower quality than human-provided labels) by expressing the prior knowledge we have about the task at hand by specifying a set of heuristics, adapting existing ground truth data for a di erent but related task (this is o en referred to distant supervision 2 ), extracting supervision signal from external knowledge-bases or ontologies, crowd-sourcing partial annotations that are cheaper to get, etc. Weak supervision is a natural way to bene t from unsupervised data and it has been applied in NLP for various tasks including relation extraction <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15]</ref>, knowledge-base completion <ref type="bibr" target="#b16">[17]</ref>, sentiment analysis <ref type="bibr" target="#b33">[34]</ref>, etc. ere are also similar a empts in IR for automatically constructing test collections <ref type="bibr" target="#b0">[1]</ref> and learning to rank using labeled features, i.e. features that an expert believes they are correlated with relevance <ref type="bibr" target="#b8">[9]</ref>. In this paper, we make use of traditional IR models as the weak supervision signal to generate a large amount of training data and train e ective neural ranking models that outperform the baseline methods by a signi cant margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">WEAK SUPERVISION FOR RANKING</head><p>Deep learning techniques have taken o in many elds, as they automate the onerous task of input representation and feature engineering. On the other hand, the more the neural networks become deep and complex, the more it is crucial for them to be trained on massive amounts of training data. In many applications, rich annotations are costly to obtain and task-speci c training data is now a critical bo leneck. Hence, unsupervised learning is considered as a long standing goal for several applications. However, in a number of information retrieval tasks, such as ranking, it is not obvious how to train a model with large numbers of queries and documents with no relevance signal. To address this problem in an unsupervised fashion, we use the idea of "Pseudo-Labeling" by taking advantage of existing unsupervised methods for creating a weakly annotated set of training data and we propose to train a neural retrieval model with weak supervision signals we have generated. In general, weak supervision refers to learning from training data in which the labels are imprecise. In this paper, we refer to weak supervision as a learning approach that automatically creates its own training data using an existing unsupervised approach, which di ers from imprecise data coming from external observations (e.g., click-through data) or noisy human-labeled data.</p><p>We focus on query-dependent ranking as a core IR task. To this aim, we take a well-performing existing unsupervised retrieval model, such as BM25. is model plays the role of "pseudo-labeler" in our learning scenario. In more detail, given a target collection and a large set of training queries (without relevance judgments), we make use of the pseudo-labeler to rank/score the documents for each query in the training query set. Note that we can generate as much as training data as we need with almost no cost. e goal is to train a ranking model given the scores/ranking generated by the pseudo-labeler as a weak supervision signal.</p><p>In the following section, we formally present a set of neural network-based ranking models that can leverage the given weak supervision signal in order to learn accurate representations and ranking for the ad-hoc retrieval task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NEURAL RANKING MODELS</head><p>In this section, we rst introduce our ranking models. en, we describe the architecture of the base neural network model shared by di erent ranking models. Finally, we discuss the three input layer architectures used in our neural rankers to encode (query, candidate document) pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Ranking Architectures</head><p>We de ne three di erent ranking models: one point-wise and two pair-wise models. We introduce the architecture of these models and explain how we train them using weak supervision signals.</p><p>Score model : is architecture models a point-wise ranking model that learns to predict retrieval scores for query-document pairs. More formally, the goal in this architecture is to learn a scoring function , where q is a query from training query set Q, d represents a retrieved document for the query q, and s q,d is the relevance score (calculated by a weak supervisor), which is acquired using a retrieval scoring function in our setup. We consider the mean squared error as the loss function for a given batch of training instances:</p><formula xml:id="formula_0">L(b;? ) = 1 |b| |b | i=1 (S({q,d} i ;? )?s {q,d } i ) 2<label>(1)</label></formula><p>where {q,d} i denotes the query and the corresponding retrieved document in the i th training instance, i.e. ? i in the batch b. e conceptual architecture of the model is illustrated in <ref type="figure" target="#fig_0">Figure 1a</ref>.</p><p>Rank model : In this model, similar to the previous one, the goal is to learn a scoring function S(q,d;? ) for a given pair of query q and document d with the set of model parameters ? . However, unlike the previous model, we do not aim to learn a calibrated scoring function. In this model, as it is depicted in <ref type="figure" target="#fig_0">Figure 1b</ref>, we use a pair-wise scenario during training in which we have two point-wise networks that share parameters and we update their parameters to minimize a pair-wise loss. In this model, each training instance has ve elements: ? = (q,d 1 ,d 2 ,s q,d 1 ,s q,d 2 ). During the inference, we treat the trained model as a point-wise scoring function to score query-document pairs.</p><p>We have tried di erent pair-wise loss functions and empirically found that the model learned based on the hinge loss (max-margin loss function) performs be er than the others. Hinge loss is a linear loss that penalizes examples that violate the margin constraint. It is widely used in various learning to rank algorithms, such as Ranking SVM <ref type="bibr" target="#b15">[16]</ref>. e hinge loss function for a batch of training instances is de ned as follows:</p><formula xml:id="formula_1">L(b;? ) = 1 |b | |b | i=1 max 0,? ?sign(s {q,d 1 } i ?s {q,d 2 } i ) (S({q,d 1 } i ;? )?S({q,d 2 } i ;? )) ,<label>(2)</label></formula><p>where ? is the parameter determining the margin of hinge loss. We found that as we compress the outputs to the range of [?1,1], ? = 1 works well as the margin for the hinge loss function.</p><p>RankProb model : e third architecture is based on a pair-wise scenario during both training and inference ( <ref type="figure" target="#fig_0">Figure 1c</ref>). is model learns a ranking function R(q,d 1 ,d 2 ;? ) which predicts the probability of document d 1 to be ranked higher than d 2 given q. Similar to the rank model, each training instance has ve elements:</p><formula xml:id="formula_2">? = (q,d 1 ,d 2 ,s q,d 1 ,s q,d 1 )</formula><p>. For a given batch of training instances, we de ne our loss function based on cross-entropy as follows:</p><formula xml:id="formula_3">L(b;? ) = ? 1 |b| |b | i=1 P {q,d 1 ,d 2 } i log(R({q,d 1 ,d 2 } i ;? )) (3) +(1?P {q,d 1 ,d 2 } i )log(1?R({q,d 1 ,d 2 } i ;? ))</formula><p>where P {q,d 1 ,d 2 } i is the probability of document d 1 being ranked higher thand 2 , based on the scores obtained from training instance? i :</p><formula xml:id="formula_4">P {q,d 1 ,d 2 } i = s {q,d 1 } i s {q,d 1 } i +s {q,d 2 } i<label>(4)</label></formula><p>It is notable that at inference time, we need a scalar score for each document. erefore, we need to turn the model's pair-wise predictions into a score per document. To do so, for each document, we calculate the average of predictions against all other candidate documents, which has O(n 2 ) time complexity and is not practical in real-world applications. ere are some approximations could be applicable to decrease the time complexity at inference time <ref type="bibr" target="#b39">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Neural Network Architecture</head><p>As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, all the described ranking architectures share a neural network module. We opted for a simple feed-forward neural network which is composed of: input layer z 0 , l ?1 hidden layers, and the output layer z l . e input layer z 0 provides a mapping ? to encode the input query and document(s) into a xed-length vector. e exact speci cation of the input representation feature function ? is given in the next subsection. Each hidden layer z i is a fully-connected layer that computes the following transformation:</p><formula xml:id="formula_5">z i =?(W i .z i?1 +b i ); 1 &lt;i &lt;l ?1,<label>(5)</label></formula><p>where W i and b i respectively denote the weight matrix and the bias term corresponding to the i t h hidden layer, and ?(.) is the activation function. We use the recti er linear unit ReLU(x) = max(0,x) as the activation function, which is a common choice in the deep learning literature <ref type="bibr" target="#b23">[24]</ref>. e output layer z l is a fully-connected layer with a single continuous output. e activation function for the output layer depends on the ranking architecture that we use. For the score model architecture, we empirically found that a linear activation function works best, while tanh and the sigmoid functions are used for the rank model and rankprob model respectively. Furthermore, to prevent feature co-adaptation, we use dropout <ref type="bibr" target="#b35">[36]</ref> as the regularization technique in all the models. Dropout sets a portion of hidden units to zero during the forward phase when computing the activations which prevents over ing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Input Representations</head><p>We explore three de nitions of the input layer representation z 0 captured by a feature function ? that maps the input into a xedsize vector which is further fed into the fully connected layers: (i) a conventional dense feature vector representation that contains various statistics describing the input query-document pair, (ii) a sparse vector containing bag-of-words representation, and (iii) bagof-embeddings averaged with learned weights. ese input representations de ne how much capacity is given to the network to extract discriminative signal from the training data and thus result in di erent generalization behavior of the networks. It is noteworthy that input representation of the networks in the score model and rank model is de ned for a pair of the query and the document, while the network in the rankprob model needs to be fed by a triple of the query, the rst document, and the second document.</p><p>Dense vector representation (Dense) : In this se ing, we build a dense feature vector composed of features used by traditional IR methods, e.g., BM25. e goal here is to let the network t the function described by the BM25 formula when it receives exactly the same inputs. In more detail, our input vector is a concatenation (||) of the following inputs: total number of documents in the collection (i.e., N ), average length of documents in the collection (i.e., a (l d ) D ), document length (i.e., l d ), frequency of each query term t i in the document (i.e., t f (t i ,d)), and document frequency of each query term (i.e., d f (t i )). erefore, for the point-wise se ing, we have the following input vector:</p><formula xml:id="formula_6">? (q,d) = [N ||a (l d ) D ||l d ||{d f (t i )||t f (t i ,d)} 1?i ?k ],<label>(6)</label></formula><p>where k is set to a xed value (5 in our experiments). We truncate longer queries and do zero padding for shorter queries. For the networks in the rankprob model, we consider a similar function with additional elements: the length of the second document and the frequency of query terms in the second document.</p><p>Sparse vector representation (Sparse) : Next, we move away from a fully featurized representation that contains only aggregated statistics and let the network performs feature extraction for us. In particular, we build a bag-of-words representation by extracting term frequency vectors of query (t f q ), document (t f d ), and the collection (t f c ) and feed the network with concatenation of these three vectors. For the point-wise se ing, we have the following input vector:</p><formula xml:id="formula_7">? (q,d) = [t f c ||t f q ||t f d ]<label>(7)</label></formula><p>For the network in rankprob model, we have a similar input vector with both t f d 1 and t f d 2 . Hence, the size of the input layer is 3 ? ocab size in the point-wise se ing, and 4 ? ocab size in the pair-wise se ing.</p><p>Embedding vector representation (Embed) : e major weakness of the previous input representation is that words are treated as discrete units, hence prohibiting the network from performing so matching between semantically similar words in queries and documents. In this input representation paradigm, we rely on word embeddings to obtain more powerful representation of queries and documents that could bridge the lexical chasm. e representation function ? consists of three components: an embedding function E : V ? R m (where V denotes the vocabulary set and m is the embedding dimension), a weighting function W : V ? R, and a compositionality function : (R m ,R) n ? R m . More formally, the function ? for the point-wise se ing is de ned as:</p><formula xml:id="formula_8">? (q,d) = [ |q | i=1 (E(t q i ),W(t q i ))|| |d | i=1 (E(t d i ),W(t d i ))],<label>(8)</label></formula><p>where t q i and t d i denote the i th term in query q and document d, respectively. For the network of the rankprob model, another similar term is concatenated with the above vector for the second document. e embedding function E transforms each term to a dense m-dimensional oat vector as its representation, which is learned during the training phase. e weighting function W assigns a weight to each term in the vocabulary set, which is supposed to learn term global importance for the retrieval task. e compositionality function projects a set of n embedding and weighting pairs to an m-dimensional representation, independent from the value of n. e compositionality function is given by:</p><formula xml:id="formula_9">n i=1 (E(t i ),W(t i )) = n i=1 W(t i )?E(t i ),<label>(9)</label></formula><p>which is the weighted element-wise sum of the terms' embedding vectors. W is the normalized weight that is learned for each term, given as follows:</p><formula xml:id="formula_10">W(t i ) = exp(W(t i )) n j=1 exp(W(t j ))<label>(10)</label></formula><p>All combinations of di erent ranking architectures and di erent input representations presented in this section can be considered for developing ranking models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL DESIGN</head><p>In this section, we describe the train and evaluation data, metrics we report, and detailed experimental setup. en we discuss the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data</head><p>Collections. In our experiments, we used two standard TREC collections: e rst collection (called Robust04) consists of over 500k news articles from di erent news agencies, that is available in TREC Disks 4 and 5 (excluding Congressional Records). is collection, which was used in TREC Robust Track 2004, is considered as a homogeneous collection, because of the nature and the quality of documents. e second collection (called ClueWeb) that we used is ClueWeb09 Category B, a large-scale web collection with over 50 million English documents, which is considered as a heterogeneous collection. is collection has been used in TREC Web Track, for several years. In our experiments with this collection, we ltered out the spam documents using the Waterloo spam scorer 3 <ref type="bibr" target="#b6">[7]</ref> with the default threshold 70%. e statistics of these collections are reported in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>Training query set. To train our neural ranking models, we used the unique queries (only the query string) appearing in the AOL query logs <ref type="bibr" target="#b29">[30]</ref>. is query set contains web queries initiated by real users in the AOL search engine that were sampled from a threemonth period from <ref type="bibr">March 1, 2006</ref> to <ref type="bibr">May 31, 2006</ref>. We ltered out a large volume of navigational queries containing URL substrings ("h p", "www.", ".com", ".net", ".org", ".edu"). We also removed all non-alphanumeric characters from the queries. We made sure that no queries from the training set appear in our evaluation sets. For each dataset, we took queries that have at least ten hits in the target corpus using the pseudo-labeler method. Applying all these processes, we ended up with 6.15 million queries for the Robust04 dataset and 6.87 million queries for the ClueWeb dataset. In our experiments, we randomly selected 80% of the training queries as training set and the remaining 20% of the queries were chosen as validation set for hyper-parameter tuning. As the "pseudo-labeler" in our training data, we have used BM25 to score/rank documents in the collections given the queries in the training query set.</p><p>Evaluation query sets. We use the following query sets for evaluation that contain human-labeled judgements: a set of 250 queries (TREC topics 301-450 and 601-700) for the Robust04 collection that were previously used in TREC Robust  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Metrics.</head><p>To evaluate retrieval e ectiveness, we report three standard evaluation metrics: mean average precision (MAP) of the top-ranked 1000 documents, precision of the top 20 retrieved documents (P@20), and normalized discounted cumulative gain (nDCG) <ref type="bibr" target="#b18">[19]</ref> calculated for the top 20 retrieved documents (nDCG@20). Statistically signi cant di erences of MAP, P@20, and nDCG@20 values are determined using the two-tailed paired t-test with p alue &lt; 0.05, with Bonferroni correction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experimental Setup</head><p>All models described in Section 4 are implemented using Tensor-Flow <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b36">37]</ref>. In all experiments, the parameters of the network are optimized employing the Adam optimizer <ref type="bibr" target="#b20">[21]</ref> and using the computed gradient of the loss to perform the back-propagation algorithm. All model hyper-parameters were tuned on the respective validation set (see Section 5.1 for more detail) using batched GP bandits with an expected improvement acquisition function <ref type="bibr" target="#b7">[8]</ref>. For each model, the size of hidden layers and the number of hidden layers were selected from <ref type="bibr">[16,32,</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS AND DISCUSSION</head><p>In the following, we evaluate our neural rankers trained with di erent learning approaches (Section 4) and di erent input representations (Section 4.3). We a empt to break down our research questions to several subquestions, and provide empirical answers along with the intuition and analysis behind each question:</p><p>How do the neural models with di erent training objectives and input representations compare? <ref type="table" target="#tab_3">Table 2</ref> presents the performance of all model combinations. Interestingly, combinations of the rank model and the rankprob model with embedding vector representation outperform BM25 by signi cant margins in both collections. For instance, the rankprob model with embedding vector representation that shows the best performance among the other methods, Regarding the modeling architecture, in the rank model and the rankprob model, compared to the score model, we de ne objective functions that target to learn ranking instead of scoring. is is particularly important in weak supervision, as the scores are imperfect values-using the ranking objective alleviates this issue by forcing the model to learn a preference function rather than reproduce absolute scores. In other words, using the ranking objective instead of learning to predict calibrated scores allows the rank model and the rankprob model to learn to distinguish between examples whose scores are close. is way, some small amount of noise, which is a common problem in weak supervision, would not perturb the ranking as easily.</p><p>Regarding the input representations, embedding vector representation leads to be er performance compared to the other ones in all models. Using embedding vector representation not only provides the network with more information, but also lets the network to learn proper representation capturing the needed elements for the next layers with be er understanding of the interactions between query and documents. Providing the network with already engineered features would block it from going beyond the weak supervision signal and limit the ability of the models to learn latent features that are una ainable through feature engineering.</p><p>Note that although the rankprob model is more precise in terms of MAP, the rank model is much faster in the inference time (O(n) compared to O(n 2 )), which is a desirable property in real-life applications.</p><p>Why do dense vector representation and sparse vector representation fail to replicate the performance of BM25? Although neural networks are capable of approximating arbitrarily complex non-linear functions, we observe that the models with dense vector representation fail to replicate the BM25 performance, while they are given the same feature inputs as the BM25 components (e.g., TF, IDF, average document length, etc). To ensure that the training converges and there is no over ing, we have looked into the training and validation loss values of di erent models during the training time. <ref type="figure" target="#fig_1">Figure 2</ref> illustrates the loss curves for the training and validation sets (see Section 5.1) per training step for di erent models. As shown, in models with dense vector representation, the training losses drop quickly to values close to zero while this is not the case for the validation losses, which is an indicator of over-ing on the training data. Although we have tried di erent regularization techniques, like l 2 -regularization and dropout with various parameters, there is less chance for generalization when the networks are fed with the fully featurized input. Note that over-ing would lead to poor performance, especially in weak supervision scenarios as the network learns to model imperfections from weak annotations. is phenomenon is also the case for models with the sparse vector representation, but with less impact. However, in the models with the embedding vector representation, the networks do not over t, which helps it to go beyond the weak supervision signals in the training data.</p><p>How are the models related? To be er understand the relationship of di erent neural models described above, we compare their performance across the query dimension following the approach in <ref type="bibr" target="#b27">[28]</ref>. We assume that similar models should perform similarly for the same queries. Hence, we represent each model by a vector, called the performance vector, whose elements correspond to per query performance of the model, in terms of nDCG@20. e closer the performance vectors are, the more similar the models are in terms of query by query performance. For the sake of visualization, we reduce the vectors dimension by projecting them to a two-dimensional space, using t-Distributed Stochastic Neighbor Embedding (t-SNE) <ref type="bibr" target="#b4">5</ref> . <ref type="figure" target="#fig_3">Figure 3</ref> illustrates the proximity of di erent models in the Ro-bust04 collection. Based on this plot, models with similar input representations (same color) have quite close performance vectors, which means that they perform similarly for same queries. is is not necessarily the case for models with similar architecture (same shape). is suggests that the amount and the way that we provide information to the networks are the key factors in the ranking performance.</p><p>We also observe that the score model with dense vector representation is the closest to BM25 which is expected. It is also interesting that models with embedding vector representation are placed far away from other models which shows they perform di erently compared to the other input representations.</p><p>How meaningful are the compositionality weights learned in the embedding vector representation? In this experiment, we   focus on the best performing combination, i.e., the rankprob model with embedding vector representation. To analyze what the network learns, we look into the weights W (see Section 4.3) learned by the network. Note that the weighting function W learns a global weight for each vocabulary term. We notice that in both collections there is a strong linear correlation between the learned weights and the inverse document frequency of terms. <ref type="figure" target="#fig_4">Figure 4</ref> illustrates the sca er plots of the learned weight for each vocabulary term and its IDF, in both collections. is is an interesting observation as we do not provide any global corpus information to the network in training How well do other alternatives for the embedding and weighting functions in the embedding vector representation perform? Considering embedding vector representation as the input representation, we have examined di erent alternatives for the embedding  <ref type="table" target="#tab_4">Table 3</ref> presents the performance of all these combinations on both collections. We note that learning both embedding and weighting functions leads to the highest performance in both collections. ese improvements are statistically signi cant. According to the results, regardless of the weighting approach, learning embeddings during training outperforms the models with xed pre-trained embeddings. is supports the hypothesis that with the embedding vector representation the neural networks learn an embedding that is based on the interactions of query and documents that tends to be tuned be er to the corresponding ranking task. Also, regardless of the embedding method, learning weights helps models to get be er performance compared to the xed weightings, with either IDF or uniform weights. Although weight learning can signi cantly a ect the performance, it has less impact than learning embeddings.</p><p>Note that in the models with pre-trained word embeddings, employing word embeddings trained on the target collection outperforms those trained on the external corpus in the ClueWeb collection; while this is not the case for the Robust04 collection. e reason could be related to the collection size, since the ClueWeb is approximately 100 times larger than the Robust04.</p><p>In addition to the aforementioned experiments, we have also tried initializing the embedding matrix with a pre-trained word embedding trained on the Google News corpus, instead of random initialization. <ref type="figure" target="#fig_5">Figure 5</ref> presents the learning curve of the models. According to this gure, the model initialized by a pre-trained embedding performs be er than random initialization when a limited amount of training data is available. When enough training data is fed to the network, initializing with pre-trained embedding and random values converge to the same performance. An interesting observation here is that in both collections, these two initializations converge when the models exceed the performance of the weak supervision source, which is BM25 in our experiments. is suggests that the convergence occurs when accurate representations are learned by the networks, regardless of the initialization.</p><p>Are deep neural networks a good choice for learning to rank with weak supervision? To see if there is a real bene t from using a non-linear neural network in di erent se ings, we examined RankSVM <ref type="bibr" target="#b19">[20]</ref> as a strong-performing pair-wise learning to rank method with linear kernel that is fed with di erent inputs: dense vector representation, sparse vector representation, and embedding vector representation. Considering that o -the-shelf RankSVM is not able to learn embedding representations during training, for embedding vector representation, instead of learning embeddings we use a pre-trained embedding matrix trained on Google News and xed IDF weights. e results are reported in <ref type="table" target="#tab_5">Table 4</ref>. As BM25 is not a linear function, RankSVM with linear kernel is not able to completely approximate it. However, surprisingly, for both dense vector representation and sparse vector representation, RankSVM works as well as neural networks (see <ref type="table" target="#tab_3">Table 2</ref>). Also, compared to the corresponding experiment in <ref type="table" target="#tab_4">Table 3</ref>, the performance of the neural network with an external pre-trained embedding and IDF weighting is not considerably be er than RankSVM. is shows that having non-linearity in neural networks does not help that much when we do not have representation learning as part of the model. Note that all of these results are still lower than BM25, which shows that they are not good at learning from weak supervision signals for ranking.  We have also examined the score model with a network with a single linear hidden layer, with the embedding vector representation, which is equivalent to a linear regression model with the ability of representation learning. Comparing the results of this experiment with Score-Embed in <ref type="table" target="#tab_3">Table 2</ref>, we can see that with a single-linear network we are not able to achieve a performance that is as good as a deep neural network with non-linearity. is shows that the most important superiority of deep neural networks over other machine learning methods is their ability to learn an e ective representation and take all the interactions between query and document(s) into consideration for approximating an e ective ranking/scoring function. is can be achieved when we have a deep enough network with non-linear activations.</p><p>How useful is learning with weak supervision for supervised ranking? In this set of experiments, we investigate whether employing weak supervision as a pre-training step helps to improve the performance of supervised ranking, when a small amount of training data is available. <ref type="table" target="#tab_6">Table 5</ref> shows the performance of the rankprob model with the embedding vector representation in three situations: (1) when it is only trained on weakly supervised data (similar to the previous experiments), <ref type="bibr" target="#b1">(2)</ref> when it is only trained on supervised data, i.e., relevance judgments, and (3) when the parameters of the network is pre-trained using the weakly supervised data and then ne tuned using relevance judgments. In all the supervised scenarios, we performed 5-fold cross-validation over the queries of each collection and in each step, we used the TREC relevance judgements of the training set as supervised signal. For each query with m relevant documents, we also randomly sampled m non-relevant documents as negative instances. Binary labels are used in the experiments: 1 for relevant documents and 0 for non-relevant ones. e results in <ref type="table" target="#tab_6">Table 5</ref> suggest that pre-training the network with a weak supervision signal, signi cantly improves the performance of supervised ranking. e reason for the poor performance of the supervised model compared to the conventional learning to rank models is that the number of parameters are much larger, hence it needs much more data for training.</p><p>In situations when li le supervised data is available, it is especially helpful to use unsupervised pre-training which acts as a network pre-conditioning that puts the parameter values in the appropriate range that renders the optimization process more e ective for further supervised training <ref type="bibr" target="#b10">[11]</ref>.</p><p>With this experiment, we indicate that the idea of learning from weak supervision signals for neural ranking models, which is presented in this paper, not only enables us to learn neural ranking models when no supervised signal is available, but also has substantial positive e ects on the supervised ranking models with limited amount of training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>In this paper, we proposed to use traditional IR models such as BM25 as a weak supervision signal in order to generate large amounts of training data to train e ective neural ranking models. We examine various neural ranking models with di erent ranking architectures and objectives, and di erent input representations.</p><p>We used over six million queries to train our models and evaluated them on Robust04 and ClueWeb 09-Category B collections, in an ad-hoc retrieval se ing. e experiments showed that our best performing model signi cantly outperforms the BM25 model (our weak supervision signal) by over 13% and 35% MAP improvements in the Robust04 and ClueWeb collections, respectively. We also demonstrated that in the case of having a small amount of training data, we can improve the performance of supervised learning by pre-training the network on weakly supervised data.</p><p>Based on our results, there are three key ingredients in neural ranking models that lead to good performance with weak supervision: e rst is the proper input representation. Providing the network with raw data and le ing the network to learn the features that ma er, gives the network a chance of learning how to ignore imperfection in the training data. e second ingredient is to target the right goal and de ne a proper objective function. In the case of having weakly annotated training data, by targeting some explicit labels from the data, we may end up with a model that learned to express the data very well, but is incapable of going beyond it. is is especially the case with deep neural networks where there are many parameters and it is easy to learn a model that over ts the data. e third ingredient is providing the network with a considerable amount of training examples. As an example, during the experiments we noticed that using the embedding vector representation, the network needs a lot of examples to learn embeddings that are more e ective for retrieval compared to pre-trained embeddings. anks to weak supervision, we can generate as much training data as we need with almost no cost.</p><p>Several future directions can be pursued. An immediate task would be to study the performance of more expressive neural network architectures e.g., CNNs and LSTMs, with weak supervision setup. Other experiment is to leverage multiple weak supervision signals from di erent sources. For example, we have other unsupervised ranking signals such as query likelihood and PageRank and taking them into consideration might bene t the learning process. Other future work would be to investigate the boosting mechanism for the method we have in this paper. In other words, it would be interesting to study if it is possible to use the trained model on weakly supervised data to annotate data with more quality from original source of annotation and leverage the new data to train a be er model. Finally, we can apply this idea to other information retrieval tasks, such as query/document classi cation and clustering.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Di erent Ranking Architectures S(q,d;? ) that determines the retrieval score of document d for query q, given a set of model parameters ? . In the training stage, we are given a training set comprising of training instances each a triple ? = (q,d,s q,d )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Training and validation loss curves for all combinations of di erent ranking architectures and feeding paradigms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Proximity of di erent models in terms of queryby-query performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Strong linear correlation between weight learned by the compositionality function in the embedding vector representation and inverse document frequency. and the network is able to infer such a global information by only observing individual training instances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Performance of the rankprob model with learned embedding, pre-trained embedding, and learned embedding with pre-trained embedding as initialization, with respect to di erent amount of training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Collections statistics.</figDesc><table><row><cell>Collection</cell><cell>Genre</cell><cell>eries</cell><cell cols="2"># docs length</cell></row><row><cell>Robust04</cell><cell>news</cell><cell>301-450,601-700</cell><cell>528k</cell><cell>254</cell></row><row><cell>ClueWeb</cell><cell>webpages</cell><cell>1-200</cell><cell>50m</cell><cell>1,506</cell></row><row><cell cols="5">(topics 1-200) were used for the experiments on the ClueWeb collec-</cell></row><row><cell cols="5">tion. ese queries were used in TREC Web Track 2009-2012. We</cell></row><row><cell cols="3">only used the title of topics as queries.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Performance of the di erent models on di erent datasets. ? or ? indicates that the improvements or degradations with respect to BM25 are statistically signi cant, at the 0.05 level using the paired two-tailed t-test.</figDesc><table><row><cell>Method</cell><cell></cell><cell>Robust04</cell><cell></cell><cell></cell><cell>ClueWeb</cell><cell></cell></row><row><cell></cell><cell>MAP</cell><cell>P@20</cell><cell>nDCG@20</cell><cell>MAP</cell><cell>P@20</cell><cell>nDCG@20</cell></row><row><cell>BM25</cell><cell>0.2503</cell><cell>0.3569</cell><cell>0.4102</cell><cell>0.1021</cell><cell>0.2418</cell><cell>0.2070</cell></row><row><cell>Score + Dense</cell><cell cols="2">0.1961 ? 0.2787 ?</cell><cell>0.3260 ?</cell><cell cols="2">0.0689 ? 0.1518 ?</cell><cell>0.1430 ?</cell></row><row><cell>Score + Sparse</cell><cell cols="2">0.2141 ? 0.3180 ?</cell><cell>0.3604 ?</cell><cell cols="2">0.0701 ? 0.1889 ?</cell><cell>0.1495 ?</cell></row><row><cell>Score + Embed</cell><cell>0.2423 ?</cell><cell>0.3501</cell><cell>0.3999</cell><cell>0.1002</cell><cell>0.2513</cell><cell>0.2130</cell></row><row><cell>Rank + Dense</cell><cell cols="2">0.1940 ? 0.2830 ?</cell><cell>0.3317 ?</cell><cell cols="2">0.0622 ? 0.1516 ?</cell><cell>0.1383 ?</cell></row><row><cell>Rank + Sparse</cell><cell cols="2">0.2213 ? 0.3216 ?</cell><cell>0.3628 ?</cell><cell cols="2">0.0776 ? 0.1989 ?</cell><cell>0.1816 ?</cell></row><row><cell>Rank + Embed</cell><cell cols="2">0.2811 ? 0.3773 ?</cell><cell>0.4302 ?</cell><cell cols="2">0.1306 ? 0.2839 ?</cell><cell>0.2216 ?</cell></row><row><cell>RankProb + Dense</cell><cell cols="2">0.2192 ? 0.2966 ?</cell><cell>0.3278 ?</cell><cell cols="2">0.0702 ? 0.1711 ?</cell><cell>0.1506 ?</cell></row><row><cell cols="3">RankProb + Sparse 0.2246 ? 0.3250 ?</cell><cell>0.3763 ?</cell><cell cols="2">0.0894 ? 0.2109 ?</cell><cell>0.1916</cell></row><row><cell cols="3">RankProb + Embed 0.2837 ? 0.3802 ?</cell><cell>0.4389 ?</cell><cell cols="2">0.1387 ? 0.2967 ?</cell><cell>0.2330</cell></row></table><note>? surprisingly, improves BM25 by over 13% and 35% in Robust04 and ClueWeb collections respectively, in terms of MAP. Similar improve- ments can be observed for the other evaluation metrics.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Performance of the rankprob model with variants of the embedding vector representation on di erent datasets. ? indicates that the improvements over all other models are statistically signi cant, at the 0.05 level using the paired two-tailed t-test, with Bonferroni correction.</figDesc><table><row><cell>Embedding type</cell><cell></cell><cell>Robust04</cell><cell></cell><cell></cell><cell>ClueWeb</cell><cell></cell></row><row><cell></cell><cell>MAP</cell><cell>P@20</cell><cell>nDCG@20</cell><cell>MAP</cell><cell>P@20</cell><cell>nDCG@20</cell></row><row><cell>Pretrained (external) + Uniform weighting</cell><cell>0.1656</cell><cell>0.2543</cell><cell>0.3017</cell><cell>0.0612</cell><cell>0.1300</cell><cell>0.1401</cell></row><row><cell>Pretrained (external) + IDF weighting</cell><cell>0.1711</cell><cell>0.2755</cell><cell>0.3104</cell><cell>0.0712</cell><cell>0.1346</cell><cell>0.1469</cell></row><row><cell>Pretrained (external) + Weight learning</cell><cell>0.1880</cell><cell>0.2890</cell><cell>0.3413</cell><cell>0.0756</cell><cell>0.1344</cell><cell>0.1583</cell></row><row><cell>Pretrained (target) + Uniform weighting</cell><cell>0.1217</cell><cell>0.2009</cell><cell>0.2791</cell><cell>0.0679</cell><cell>0.1331</cell><cell>0.1587</cell></row><row><cell>Pretrained (target) + IDF weighting</cell><cell>0.1402</cell><cell>0.2230</cell><cell>0.2876</cell><cell>0.0779</cell><cell>0.1674</cell><cell>0.1540</cell></row><row><cell>Pretrained (target) + Weight learning</cell><cell>0.1477</cell><cell>0.2266</cell><cell>0.2804</cell><cell>0.0816</cell><cell>0.1729</cell><cell>0.1608</cell></row><row><cell>Learned + Uniform weighting</cell><cell>0.2612</cell><cell>0.3602</cell><cell>0.4180</cell><cell>0.0912</cell><cell>0.2216</cell><cell>0.1841</cell></row><row><cell>Learned + IDF weighting</cell><cell>0.2676</cell><cell>0.3619</cell><cell>0.4200</cell><cell>0.1032</cell><cell>0.2419</cell><cell>0.1922</cell></row><row><cell>Learned + Weight learning</cell><cell cols="2">0.2837 ? 0.3802 ?</cell><cell>0.4389 ?</cell><cell cols="2">0.1387 ? 0.2967 ?</cell><cell>0.2330 ?</cell></row><row><cell cols="2">function E: (1) employing pre-trained word embeddings learned</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">from an external corpus (we used Google News), (2) employing pre-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">trained word embeddings learned from the target corpus (using the</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">skip-gram model [27]), and (3) learning embeddings during the net-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">work training as it is explained in Section 4.3. Furthermore, for the</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">compositionality function , we tried di erent alternatives: (1) uni-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">form weighting (simple averaging which is a common approach in</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">compositionality function), (2) using IDF as xed weights instead of</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">learning the weighting function W, and (3) learning weights during</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>the training as described in Section 4.3.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Performance of the linear RankSVM with di erent features.</figDesc><table><row><cell>Method</cell><cell></cell><cell>Robust04</cell><cell></cell><cell></cell><cell>ClueWeb</cell></row><row><cell></cell><cell>MAP</cell><cell cols="2">P@20 nDCG@20</cell><cell>MAP</cell><cell>P@20 nDCG@20</cell></row><row><cell>RankSVM + Dense</cell><cell cols="2">0.1983 0.2841</cell><cell>0.3375</cell><cell cols="2">0.0761 0.1840</cell><cell>0.1637</cell></row><row><cell>RankSVM + Sparse</cell><cell cols="2">0.2307 0.3260</cell><cell>0.3794</cell><cell cols="2">0.0862 0.2170</cell><cell>0.1939</cell></row><row><cell cols="3">RankSVM + (Pretrained (external) + IDF weighting) 0.1539 0.2121</cell><cell>0.1852</cell><cell cols="2">0.0633 0.1572</cell><cell>0.1494</cell></row><row><cell>Score (one layer with no nonlinearity) + Embed</cell><cell cols="2">0.2103 0.3986</cell><cell>0.3160</cell><cell cols="2">0.0645 0.1421</cell><cell>0.1322</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Performance of the rankprob model with embedding vector representation in fully supervised setting, weak supervised setting, and weak supervised plus supervision as ne tuning. ? indicates that the improvements over all other models are statistically signi cant, at the 0.05 level using the paired two-tailed t-test, with Bonferroni correction.</figDesc><table><row><cell>Method</cell><cell></cell><cell>Robust04</cell><cell></cell><cell></cell><cell>ClueWeb</cell><cell></cell></row><row><cell></cell><cell>MAP</cell><cell>P@20</cell><cell>nDCG@20</cell><cell>MAP</cell><cell>P@20</cell><cell>nDCG@20</cell></row><row><cell>Weakly supervised</cell><cell>0.2837</cell><cell>0.3802</cell><cell>0.4389</cell><cell>0.1387</cell><cell>0.2967</cell><cell>0.2330</cell></row><row><cell>Fully supervised</cell><cell>0.1790</cell><cell>0.2863</cell><cell>0.3402</cell><cell>0.0680</cell><cell>0.1425</cell><cell>0.1652</cell></row><row><cell cols="3">Weakly supervised + Fully supervised 0.2912 ? 0.4126 ?</cell><cell>0.4509 ?</cell><cell cols="2">0.1520 ? 0.3077 ?</cell><cell>0.2461 ?</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Although weak supervision may refer to using noisy data, in this paper, we assume that no external information, e.g., click-through data, is available.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We do not distinguish between weak and distant supervision as the di erence is subtle and both terms are o en used interchangeably in the literature.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">h ps://www.lemurproject.org/indri.php</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">h ps://lvdmaaten.github.io/tsne/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGMENTS is research was supported in part by Netherlands Organization for Scienti c Research through the Exploratory Political Search project (ExPoSe, NWO CI # 314.99.108), by the Digging into Data Challenge through the Digging Into Linked Parliamentary Data project (DiLi-PaD, NWO Digging into Data # 600.006.014), and by the Center for Intelligent Information Retrieval. Any opinions, ndings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily re ect those of the sponsors.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pseudo test collections for learning web search ranking functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamer</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval</title>
		<meeting>the 34th international ACM SIGIR conference on Research and development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1073" to="1082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Autoencoders, unsupervised learning, and deep architectures. ICML unsupervised and transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Baldi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="37" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improving Distant Supervision for Information Extraction Using Label Propagation rough Lists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sneha</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP &apos;15</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="524" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Neural Click Model for Web Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Borisov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Maarten De Rijke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Serdyukov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW &apos;16</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="531" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Signature Veri cation Using a &quot;Siamese&quot; Time Delay Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>S?ckinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roopak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS &apos;93</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="737" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">End to End Long Short Term Memory Networks for Non-Factoid estion Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bruce Cro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICTIR &apos;16</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="143" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">E cient and E ective Spam Filtering and Re-ranking for Large Web Datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="441" to="465" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Parallelizing exploration-exploitation tradeo s in Gaussian process bandit optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Omas Desautels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">W</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burdick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3873" to="3923" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to Rank with Labeled Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICTIR &apos;16</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="41" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ery Expansion with Locally-Trained Word Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL &apos;16</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Why does unsupervised pre-training help deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Deep Relevance Matching Model for Ad-hoc Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bruce Cro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM &apos;16</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Global Distant Supervision for Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI&apos;16</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2950" to="2956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Support Vector Learning for Ordinal Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graepel</forename><surname>Ore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Obermayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICANN &apos;99</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Knowledge-based Weak Supervision for Information Extraction of Overlapping Relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Ho Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Ze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL &apos;11</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning Deep Structured Semantic Models for Web Search Using Clickthrough Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM &apos;13</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cumulated Gain-based Evaluation of IR Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalervo</forename><surname>J?rvelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaana</forename><surname>Kek?l?inen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimizing Search Engines Using Clickthrough Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Orsten Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;02</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS &apos;15</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Distributed Representations of Sentences and Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML &apos;14</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geo</forename><surname>Rey Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classi cation and Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye-Yi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL &apos;15</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="912" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Deep Architecture for Matching Short Texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS &apos;13</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1367" to="1375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Je</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS &apos;13</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to Match Using Local and Distributed Representations of Text for Web Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW &apos;17</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1291" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Kezban Dilek Onal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinar</forename><surname>Sengor Altingovde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Karagoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De Rijke</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03305</idno>
		<title level="m">Ge ing Started with Neural Models for Semantic Matching in Web Search</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Abdur Chowdhury, and Cayley Torgeson</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Pass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>A Picture of Search. In InfoScale &apos;06</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Je Rey Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP &apos;14</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Word Embedding Causes Topic Shi ing; Exploit Global Context!</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;17</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Generalizing translation models in the probabilistic relevance framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="711" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Twi er Sentiment Analysis with Deep Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;15</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="959" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning Semantic Representations Using Convolutional Neural Networks for Web Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gr?goire</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW &apos;14</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="373" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Over ing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geo</forename><surname>Rey Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.04251</idno>
		<title level="m">TF.Learn: TensorFlow&apos;s High-level Module for Distributed Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning latent vector spaces for product search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Van Gysel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM&apos;16</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Unsupervised, e cient and semantic expertise retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Van Gysel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Worring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;16</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1069" to="1079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">E cient Ranking from Pairwise Comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">L</forename><surname>Wauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nebojsa</forename><surname>Jojic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;13</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">aNMM: Ranking Short Answer Texts with A ention-Based Neural Matching Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bruce Cro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM &apos;16</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Situational Context for Ranking in Personal Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW &apos;17</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1531" to="1540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Embedding-based ery Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bruce Cro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICTIR &apos;16</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="147" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Estimating Embedding Vectors for eries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bruce Cro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICTIR &apos;16</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="123" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Relevance-based Word Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bruce Cro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;17</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md</forename><surname>Musta Zur Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Braylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng-Lu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henna</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Angert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Banner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.06792</idno>
		<title level="m">Vivek Khetan, and others. 2016. Neural Information Retrieval: A Literature Review</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning to Reweight Terms with Distributed Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;15</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="575" to="584" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
