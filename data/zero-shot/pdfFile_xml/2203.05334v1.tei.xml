<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Iterative Corresponding Geometry: Fusing Region and Depth for Highly Efficient 3D Tracking of Textureless Objects</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Stoiber</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Aerospace Center (DLR)</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Technical University of Munich (TUM)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Aerospace Center (DLR)</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Technical University of Munich (TUM)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolph</forename><surname>Triebel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Aerospace Center (DLR)</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Technical University of Munich (TUM)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Iterative Corresponding Geometry: Fusing Region and Depth for Highly Efficient 3D Tracking of Textureless Objects</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Tracking objects in 3D space and predicting their 6DoF pose is an essential task in computer vision. State-of-theart approaches often rely on object texture to tackle this problem. However, while they achieve impressive results, many objects do not contain sufficient texture, violating the main underlying assumption. In the following, we thus propose ICG, a novel probabilistic tracker that fuses region and depth information and only requires the object geometry. Our method deploys correspondence lines and points to iteratively refine the pose. We also implement robust occlusion handling to improve performance in real-world settings. Experiments on the YCB-Video, OPT, and Choi datasets demonstrate that, even for textured objects, our approach outperforms the current state of the art with respect to accuracy and robustness. At the same time, ICG shows fast convergence and outstanding efficiency, requiring only 1.3 ms per frame on a single CPU core. Finally, we analyze the influence of individual components and discuss our performance compared to deep learning-based methods. The source code of our tracker is publicly available 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>For many applications in robotic manipulation and augmented reality, it is essential to know the six degrees of freedom (6DoF) pose of relevant objects. To provide this information at high frequency, 3D object tracking is used. The goal is to estimate an object's position and orientation from consecutive image frames given its 3D model. In real-world applications, occlusions, motion blur, background clutter, textureless surfaces, object symmetries, and real-time requirements remain difficult problems. Over the years many approaches have been developed <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b71">72]</ref>. They can be differentiated by the use of keypoints, edges, direct optimization, deep learning, object regions, and depth images.</p><p>While methods based on keypoints <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b63">64]</ref> The image on the left shows an overlay of the object model for the predicted pose. On the right, probabilities that a pixel belongs to the background are encoded in a grayscale image. Correspondence lines are shown in yellow, with high probabilities indicated in red. Projected correspondence points are illustrated in blue.</p><p>edges <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b54">55]</ref>, and direct optimization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b55">56]</ref> were very popular in the past, multiple drawbacks exist. Both keypoints and direct optimization are not suitable for textureless objects. Edge-based methods, on the other hand, typically struggle with background clutter and object texture. Further problems emerge from reflections and motion blur, which change the appearance of both texture and edges. To overcome those issues, data-driven techniques that use convolutional neural networks (CNNs) have been proposed <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b66">67]</ref>. While most of those methods require significant computational resources and a detailed 3D model, they achieve promising results. For the tracking of textureless objects in cluttered environments, region-based techniques have also become very popular <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b75">76]</ref>. Furthermore, the emergence of consumer depth sensors has enabled additional trackers that do not rely on texture <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b68">69]</ref>. Finally, while all those methods can be used independently, many approaches demonstrated the benefits of combining different techniques <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b61">62]</ref>. In the past, it was shown that a combination of region and depth has great potential for the tracking of textureless objects <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b46">47]</ref>. However, while region-based tech-niques improved greatly with respect to efficiency and quality <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref>, no recent combined approach exists. In the following, we thus build on current developments and propose ICG, a highly efficient method that fuses geometric information from region-based correspondence lines and depthbased correspondence points. An illustration of the used correspondences is shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. In a detailed evaluation on three different datasets, our method demonstrates stateof-the-art performance compared to both classical and deep learning-based techniques. In addition, given that only few such comparisons were conducted in the past, we are able to gain new insights into the current state of deep learningbased object tracking and pose estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In the following, we provide an overview on region-, depth-, and deep learning-based techniques. Region-based methods typically use color statistics to model the probability that a pixel belongs to the object or to the background. The object pose is then optimized to best explain the segmentation of the image. While early approaches treated segmentation and optimization separately <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b52">53]</ref>, subsequent work <ref type="bibr" target="#b13">[14]</ref> combined the two steps. Later, the pixel-wise posterior membership of <ref type="bibr" target="#b2">[3]</ref> was used to develop PWP3D <ref type="bibr" target="#b44">[45]</ref>. Based on this method, multiple combined approaches that incorporate depth information <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b46">47]</ref>, edges <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b59">60]</ref>, inertial measurements <ref type="bibr" target="#b43">[44]</ref>, or use direct optimization <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b74">75]</ref> were developed. In addition, it was suggested to localize the probabilistic segmentation model <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b75">76]</ref>. Different optimization techniques such as particle filters <ref type="bibr" target="#b73">[74]</ref>, Levenberg Marquardt <ref type="bibr" target="#b43">[44]</ref>, Gauss Newton <ref type="bibr" target="#b62">[63]</ref>, or Newton with Tikhonov regularization <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref> were also proposed. Finally, starting from the ideas of <ref type="bibr" target="#b27">[28]</ref>, the efficiency problem of region-based methods was addressed with the development of the sparse tracker SRT3D <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref>.</p><p>Depth-based methods try to minimize the distance between the surface of a 3D model and measurements from a depth camera. Often, approaches based on the Iterative Closest Point (ICP) framework <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9]</ref> are used. While many variants exist <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b51">52]</ref>, all algorithms iteratively establish correspondences and minimize a respective error function. For tracking, projective data association <ref type="bibr" target="#b3">[4]</ref> and the point-to-plane error metric <ref type="bibr" target="#b8">[9]</ref> are very common <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b61">62]</ref>. Apart from correspondence points and ICP, methods that utilize signed distance functions are often used <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b53">54]</ref>. In addition, approaches that employ particle filters <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b68">69]</ref> or robust Gaussian filters <ref type="bibr" target="#b26">[27]</ref> instead of gradient-based optimization are also very popular.</p><p>While deep learning has proven highly successful for 6DoF pose estimation <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b70">71]</ref>, pure tracking methods were only recently proposed. Many approaches are inspired by pose refinement and predict the relative pose between object renderings and subsequent images <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b66">67]</ref>. In addition, PoseRBPF <ref type="bibr" target="#b14">[15]</ref> uses a Rao-Blackwellized particle filter on pose-representative latent codes <ref type="bibr" target="#b60">[61]</ref> while 6-Pack <ref type="bibr" target="#b64">[65]</ref> tracks anchor-based keypoints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Probabilistic Model</head><p>In this section, mathematical concepts and the used notation are introduced. This is followed by an explanation of the sparse viewpoint model. Finally, the probability density functions (PDFs) for region and depth are derived.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminaries</head><p>In this work, we use X X X = X Y Z ? R 3 and the homogeneous form X X X = X Y Z 1 to describe 3D model points. Image coordinates x x x = x y ? R 2 are employed to access color values y y y = I I I c (x x x) and depth values d Z = I d (x x x) from the respective color and depth images. With the pinhole camera model, a 3D model point is projected into an undistorted image as follows</p><formula xml:id="formula_0">x x x = ? ? ?(X X X) = X Z f x + p x Y Z f y + p y ,<label>(1)</label></formula><p>where f x and f y are the focal lengths and p x and p y are the coordinates of the principal point.</p><p>To describe the relative pose between two reference frames A and B, the homogeneous matrix A T T T B ? SE(3) is used. It transforms 3D model points as follows</p><formula xml:id="formula_1">A X X X = A T T T BB X X X = A R R R B A t t t B 0 0 0 1 B X X X,<label>(2)</label></formula><p>with A X X X and B X X X a point written in the coordinate frames A and B. The rotation matrix A R R R B ? SO(3) and the translation vector A t t t B ? R 3 define the transformation from B to A. In this work, M, C, and D will be used to denote the model, the color camera, and the depth camera frames, respectively. For small variations of the pose in the model reference frame M, we use the following minimal representation</p><formula xml:id="formula_2">M X X X(? ? ?) = M T T T (? ? ?) M X X X = I I I + [? ? ? r ] ? ? ? ? t 0 0 0 1 M X X X,<label>(3)</label></formula><p>where [? ? ? r ] ? is the skew-symmetric matrix of ? ? ? r . The vectors ? ? ? r ? R 3 and ? ? ? t ? R 3 are the rotational and translational components of the full variation vector ? ? ? = ? ? ? r ? ? ? t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Sparse Viewpoint Model</head><p>To ensure efficiency and avoid the rendering of the 3D model during tracking, we represent the geometry using a sparse viewpoint model <ref type="bibr" target="#b58">[59]</ref>. In the generation process, the object is rendered from a large number of virtual cameras that are placed on the vertices of a geodesic grid all around r r s</p><formula xml:id="formula_3">?1 0 1 d(? ? ?) d s (? ? ?) 2</formula><p>?r c c c n n n X X X(? ? ?) <ref type="figure">Figure 2</ref>. Projection of a correspondence line from image space into scale space. The correspondence line is defined by a center c c c and a normal vector n n n. Pixels along the correspondence line are combined into segments, which are illustrated in blue and yellow. The number of pixels per segment is specified by the scale s = 2.</p><p>In the visualization, the pose-dependent 3D contour point X X X(? ? ?), which is associated with the correspondence line, is also shown. It is used to compute the distance d(? ? ?) from the estimated contour to the center c c c. The transformation from r into the scale space rs is indicated by dotted vertical lines. Note that the space is shifted by ?r and scaled according to s, as well as the line angle. the object. Similar to <ref type="bibr" target="#b61">[62]</ref>, image coordinates are then randomly sampled on the contour and surface of the rendered silhouette. For each coordinate, both the 3D point M X X X and the 3D normal vector M N N N are reconstructed. Together with the orientation that points from the camera to the model center, those vectors are stored for each viewpoint. Given a pose estimate, obtaining the contour and surface representation reduces to a search for the closest orientation vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Region Modality</head><p>In the following, we adopt the region-based approach of SRT3D <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref> and modify it to incorporate a user-defined uncertainty. In general, SRT3D considers region information sparsely along so-called correspondence lines l l l, which cross the estimated object contour. Similar to the image function I I I c , correspondence lines map coordinates r ? R to color values y y y = l l l(r). Each line is thereby defined by a center c c c ? R 2 and a normal vector n n n ? R 2 in image space. Both vectors are calculated by projecting a 3D contour point X X X and an associated 3D normal vector N N N from the sparse viewpoint model into the image to establish a correspondence. In order to make correspondence lines more efficient, SRT3D introduces a scale-space formulation that combines multiple pixel values y y y into segments s s s. The number of pixels is thereby defined by the scale s ? N + . In addition, line coordinates r are scaled and shifted to make correspondence lines independent of their orientation and sub-pixel location. An illustration is shown in <ref type="figure">Fig. 2</ref>.</p><p>Like in most region-based methods, color statistics are used to differentiate between foreground and background. </p><p>where the segment s s s is defined by the coordinate r s . The value describes the probability that a specific segment belongs to the foreground or background.</p><p>In addition to those measurements, theoretical probabilities that depend on the location of the object contour are developed. They are modeled by smoothed step functions</p><formula xml:id="formula_5">h f (x) = 1 2 ? ? h tanh x 2s h ,<label>(5)</label></formula><formula xml:id="formula_6">h b (x) = 1 2 + ? h tanh x 2s h ,<label>(6)</label></formula><p>with the amplitude parameter ? h ? [0, 0.5] and the slope parameter s h ? R + . Using the variated 3D model point</p><formula xml:id="formula_7">C X X X(? ? ?) = C T T T MM T T T (? ? ?) M X X X,<label>(7)</label></formula><p>the distance from the estimated contour to the correspondence line center c c c is approximated in scale space as follows d s (? ? ?) = n n n ? ? ? C X X X(? ? ?) ? c c c ? ?r n s ,</p><p>wheren = n n n max projects to the closest horizontal or vertical image coordinate, and ?r ? R is an offset to a defined pixel location. An illustration of the transformation is shown in <ref type="figure">Fig. 2</ref>. Finally, based on those functions, SRT3D estimates the PDF for the scaled contour distance as</p><formula xml:id="formula_9">p(d s (? ? ?) | ? s , l l l) ? rs??s i?{f,b} h i r s ? d s (? ? ?) p si (r s ),<label>(9)</label></formula><p>with ? s the considered correspondence line domain. Note that this PDF is defined in scale space. Thanks to the proof in <ref type="bibr" target="#b57">[58]</ref>, we know that, under certain conditions, the variance of the PDF is equal to the slope parameter s h defined for the smoothed step functions h f and h b . Given this variance, the expected unscaled variance in units of pixels is ? 2 = shs 2 /n 2 . In contrast to previous work, we want correspondence lines to be independent of scale and slope parameters. This has the advantage that for all correspondence lines, the variance is defined in the same unit of pixels. In addition, we want to define our confidence in the region modality. Introducing the user-defined standard deviation ? r , the PDF in Eq. (9) is thus scaled as follows</p><formula xml:id="formula_10">p(? ? ? | ? s , l l l) ? p(d s (? ? ?) | ? s , l l l) shs 2 ? 2 rn 2 .<label>(10)</label></formula><p>The formulation helps to fuse the region modality with other information, given a defined uncertainty. Also, as shown in Appendix C, it improves results compared to SRT3D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Depth Modality</head><p>Based on ICP <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9]</ref>, the depth modality starts with a search for correspondence points. Similar to projective data association <ref type="bibr" target="#b3">[4]</ref>, a 3D surface point X X X from the sparse viewpoint model is first projected into the depth image. Given a user-defined radius and stride, multiple 3D points within a quadratic area are then reconstructed. Finally, a correspondence point P P P ? R 3 is selected as the point closest to the point X X X. Correspondences with a distance bigger than a threshold are rejected. Note that techniques such as normal shooting <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b18">19]</ref>, and rejection strategies based on the median distance <ref type="bibr" target="#b15">[16]</ref>, the best percentage <ref type="bibr" target="#b45">[46]</ref>, and the compatibility of normal vectors <ref type="bibr" target="#b72">[73]</ref> were also tested. However, in the end, this simple procedure worked best.</p><p>For the probabilistic model, we formulate a normal distribution that uses the point-to-plane error metric <ref type="bibr" target="#b8">[9]</ref>. The distance between the 3D surface point X X X and correspondence point P P P is thereby calculated along the associated normal vector N N N . Given the correspondence point P P P , the probability for the pose variation vector ? ? ? is written as</p><formula xml:id="formula_11">p(? ? ? | P P P ) ? exp ? 1 2d 2 Z ? 2 d M N N N M X X X ? M P P P (? ? ?) 2 (11) with M P P P (? ? ?) = M T T T (?? ? ?) M T T T DD P P P .<label>(12)</label></formula><p>Note that the user-defined standard deviation ? d is scaled by the depth value d Z of the correspondence point P P P . The scaling takes into account that the number and quality of depth measurements decreases with the distance to the camera. In addition, it also ensures compatibility with the uncertainty of the region modality, which increases with the camera distance. In Eq. (11), we variate the correspondence point P P P instead of the model. This has the advantage that the normal vector remains fixed, and only one vector has to be variated. Based on the derived PDFs for region and depth, we can now optimize for the pose that best explains the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Optimization</head><p>In the following, we first introduce the Newton method with Tikhonov regularization that is used to maximize the probability. Subsequently, we define the gradient vector and the Hessian matrix that are required in this optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Regularized Newton Method</head><p>Assuming that measurements from both modalities are independent, the joint probability function is written as</p><formula xml:id="formula_12">p(? ? ? | D D D) = nr i=0 p(? ? ? | ? si , l l l i ) nd i=0 p(? ? ? | P P P i ),<label>(13)</label></formula><p>with D D D the considered data and n r and n d the number of used correspondence lines and correspondence points, re-Model Object Image Plane <ref type="figure">Figure 3</ref>. Optimization of the corresponding geometry. For blue surface points and normal vectors, the probability given a red correspondence point is illustrated by a normal distribution. For yellow correspondence lines, the discrete distribution is illustrated. The location of 3D contour points is thereby projected to the image plane. During optimization, the joint probability is maximized.</p><p>spectively. The joint optimization of correspondence lines and correspondence points is visualized in <ref type="figure">Fig. 3</ref>.</p><p>To maximize the probability, multiple iterations, where we calculate the variation vector? ? ? and update the object pose, are performed. In each iteration, the Newton method with Tikhonov regularization is used as follow?</p><formula xml:id="formula_13">? ? ? = ? H H H + ? r I I I 3 0 0 0 0 0 0 ? t I I I 3 ?1 g g g,<label>(14)</label></formula><p>where g g g is the gradient vector, H H H the Hessian matrix, and ? r and ? t are the rotational and translational regularization parameters. The gradient vector and the Hessian matrix are thereby defined as the first-and second-order derivatives of the logarithm of the joint probability function in Eq. <ref type="bibr" target="#b12">(13)</ref>. The big advantage of the Newton formulation is that, with the Hessian matrix, uncertainty is considered in all dimensions. This means that, in addition to weighting the two modalities with ? r and ? d , it also takes into account how well each correspondence constrains the different directions. In addition, Tikhonov regularization acts as a prior probability that controls how much we believe in the previous pose. For directions with little information, this regularization helps to keep the optimization stable.</p><p>Finally, given the knowledge that? ? ? r corresponds to the rotation vector of the axis-angle representation, we are able to update the pose using the exponential map as follows</p><formula xml:id="formula_14">A T T T + M = A T T T M exp([? ? ? r ] ? )? ? ? t 0 0 0 1 , A ? {C, D}. (15)</formula><p>Note that, typically, either the pose with respect to the color or the depth camera is calculated using Eq. <ref type="bibr" target="#b14">(15)</ref>. The other is then updated using the known relative transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Gradient and Hessian</head><p>Because the logarithm is applied in the calculation of the gradient vector and the Hessian matrix, products turn into summations and, based on Eq. (13), we can write</p><formula xml:id="formula_15">g g g = nr i=1 g g g ri + nd i=1 g g g di ,<label>(16)</label></formula><formula xml:id="formula_16">H H H = nr i=1 H H H ri + nd i=1 H H H di ,<label>(17)</label></formula><p>where g g g ri and H H H ri are calculated from individual correspondence lines of the region modality, and g g g di and H H H di are based on correspondence points from the depth modality. For the region modality, we apply the chain rule to calculate gradient vectors and Hessian matrices as follows</p><formula xml:id="formula_17">g g g ri = s h s 2 ? 2 rn 2 i ? ln p(d si | ? si , l l l i ) ?d si ?d si ? C X X X i ? C X X X i ?? ? ? ? ? ?=0 0 0 ,<label>(18)</label></formula><formula xml:id="formula_18">H H H ri ? s h s 2 ? 2 rn 2 i ? 2 ln p(d si | ? si , l l l i ) ?d si 2 ?d si ? C X X X i ? C X X X i ?? ? ? ?d si ? C X X X i ? C X X X i ?? ? ? ? ? ?=0 0 0 .<label>(19)</label></formula><p>Note that, similar to <ref type="bibr" target="#b57">[58]</ref>, second-order partial derivatives for d si and C X X X i are neglected. Using Eqs. <ref type="formula" target="#formula_7">(7)</ref> and <ref type="formula" target="#formula_8">(8)</ref>, the following first-order partial derivatives can be calculated</p><formula xml:id="formula_19">?d si ? C X X X i =n i s 1 C Z 2 i n xi f xC Z i n yi f y C Z i ?n xi f xC X i ? n yi f y C Y i ,<label>(20)</label></formula><formula xml:id="formula_20">? C X X X i ?? ? ? = C R R R M ?[ M X X X i ] ? I I I 3 .<label>(21)</label></formula><p>To estimate the first-and second-order partial derivatives for the posterior probability distribution p(d si | ? si , l l l i ), we use the same techniques as in <ref type="bibr" target="#b58">[59]</ref> and differentiate between global and local optimization. For global optimization, the PDF is sampled over d si , and the mean ? i and variance ? 2 i are calculated to approximate a normal distribution. Based on this normal distribution, derivatives are calculated as</p><formula xml:id="formula_21">? ln p(d si | ? si , l l l i ) ?d si ? ? 1 ? 2 i (d si ? ? i ),<label>(22)</label></formula><formula xml:id="formula_22">? 2 ln p(d si | ? si , l l l i ) ?d si 2 ? ? 1 ? 2 i .<label>(23)</label></formula><p>For local optimization, the two probability values corresponding to the discrete distances d ? si and d + si closest to d si are used to approximate first-order partial derivatives as</p><formula xml:id="formula_23">? ln p(d si | ? si , l l l i ) ?d si ? ? s ? 2 i ln p(d + si | ? si , l l l i p(d ? si | ? si , l l l i ) ,<label>(24)</label></formula><p>where ? s is a user-defined learning rate. Second-order partial derivatives are again calculated according to Eq. (23).</p><p>Finally, for the depth modality, gradient vectors and Hessian matrices can be calculated using Eqs. <ref type="bibr" target="#b10">(11)</ref> and <ref type="bibr" target="#b11">(12)</ref> </p><formula xml:id="formula_24">g g g di = ? 1 d 2 Z ? 2 d M N N N i M X X X i ? M P P P i M P P P i ? M N N N i M N N N i ,<label>(25)</label></formula><formula xml:id="formula_25">H H H di = ? 1 d 2 Z ? 2 d M P P P i ? M N N N i M N N N i M P P P i ? M N N N i M N N N i .<label>(26)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implementation</head><p>The following section provides implementation details, discusses how ICG can be used for pose refinement, and explains how occlusions are handled. For our implementation, we built on the code of SRT3D <ref type="bibr" target="#b58">[59]</ref>. To generate the sparse viewpoint model, the object is rendered from 2562 virtual cameras that are placed on a geodesic grid with a distance of 0.8 m to the object center. For each view, contour and surface points are sampled and normal vectors are approximated. For contour points, distances along the normal vector for which the foreground and background are not interrupted are also computed. To ensure only one transition exists on a correspondence line, lines with at least one of the two distances below 3 segments are rejected.</p><p>The two color histograms for foreground and background are discretized by 4096 equidistant bins. In their calculation, the first 20 pixels from the line center are used. During tracking, we update histograms once the final pose was computed using the online adaptation of <ref type="bibr" target="#b2">[3]</ref> with a learning rate of ? = 0.2. In addition to tracking, our algorithm can also be used for pose refinement. In such cases, we initialize histograms at each iteration before correspondences are established. Since we do not perform a continuous update, histograms do not show the same quality as for tracking. Nevertheless, they still include useful information that helps the algorithm to converge. Experiments that demonstrate the performance for pose refinement are provided in Appendix E.</p><p>For the region modality, the probability distributions p(d si | ? si , l l l i ) are evaluated at 12 discrete distance values d si ? {?5.5, ?4.5, . . . , 5.5}. In the calculation of each probability value, we use 8 precomputed values for the smoothed step functions h f and h b that correspond to x ? {?3.5, ?2.5, . . . , 3.5}. Also, we define the slope parameter s h = 0.5, the amplitude parameter ? h = 0.43, and the learning rate ? s = 1.3. To find correspondence points for the depth modality, image values on a quadratic grid with a stride of 5 mm and a radius equal to the correspondence threshold r t are considered. Both parameter values are projected from meters into pixels based on the depth of the 3D surface point. Correspondence points with a distance that is bigger than the threshold r t are rejected. Valid correspondences are then used in the optimization with the regularization parameters ? r = 1000 and ? t = 30000. To find the final pose, we conduct 4 iterations in which correspondences are established. For each iteration, the standard deviations ? r and ? d , the scale s, and the threshold r t can be adjusted. This allows to define our confidence in the data and the range in which region and depth information is considered. Many characteristics such as the resolution, depth image quality, or frame-to-frame pose difference depend on the sequence. We thus adjust the parameters for every dataset and provide them in the evaluation section. Finally, in each iteration, two optimization steps are conducted. For the region modality, global optimization is used in the first and local optimization in the second.</p><p>In many real-world cases, correspondence lines and correspondence points are subject to occlusion. Based on measurements from the depth camera and estimated positions of 3D model points, occlusions can be detected. First, the minimum depth based on 25 depth image values within a quadratic region of 20 ? 20 mm is computed. Similarly, during model generation, an offset between the depth of the sampled model point and the minimum depth within a quadratic region of 20 ? 20 mm is calculated. Finally, we are able to reject correspondences for which the depth of the model point minus the precomputed offset and a userdefined threshold of 30 mm is smaller than the measured minimum depth. Considering a region of values makes the technique robust to missing depth measurements and large local depth differences in the object surface. In cases where depth images are not available, depth renderings can be used. An illustration of the strategy is shown in <ref type="figure" target="#fig_2">Fig. 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Evaluation</head><p>In this section, we present an extensive evaluation of our approach on the YCB-Video dataset <ref type="bibr" target="#b70">[71]</ref>, the OPT dataset <ref type="bibr" target="#b69">[70]</ref>, and the dataset of Choi <ref type="bibr" target="#b9">[10]</ref>. We thereby evaluate the robustness, accuracy, and efficiency of ICG in comparison to the state of the art. In addition, we conduct an ablation study that demonstrates the importance of individual com-ponents. Finally, we explain limitations of our approach. Note that in Appendices B and C we present further results for the region modality and the Choi dataset. Also, in Appendices D and E, we discuss how ICG performs for pose refinement and how it compares to modern 6DoF pose estimation. Qualitative results on the YCB-Video dataset and in real-world applications can be found in the provided videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">YCB-Video Dataset</head><p>The YCB-Video dataset <ref type="bibr" target="#b70">[71]</ref> contains 21 YCB objects <ref type="bibr" target="#b7">[8]</ref> and evaluates on 12 sequences with a total of 2949 key frames. Because it includes additional training sequences, it is very popular with deep learning-based methods. In the evaluation, the conventional and symmetric average distance errors e ADD and e ADD-S <ref type="bibr" target="#b23">[24]</ref> are calculated as</p><formula xml:id="formula_26">e ADD = 1 n n i=1 M X X X i ? M T T T Mgt M X X X i 3?1 2 ,<label>(27)</label></formula><formula xml:id="formula_27">e ADD-S = 1 n n i=1 min j?[n] M X X X i ? M T T T Mgt M X X X j 3?1 2 ,<label>(28)</label></formula><p>where M T T T Mgt is the difference between the ground-truth and the estimated model pose, X X X i is a vertex from the object mesh, and n is the number of vertices. Based on those error metrics for a single frame, <ref type="bibr" target="#b70">[71]</ref> reports ADD and ADD-S area under curve scores. They can be calculated as</p><formula xml:id="formula_28">s i = 1 m m j=1 max 1 ? e ij e t , 0 ,<label>(29)</label></formula><p>with i ? {ADD, ADD-S}, the respective frame error e ij , the number of frames m, and the threshold e t = 0.1 m.</p><p>Results of the evaluation on the YCB-Video dataset are shown in Tab. 1. For our algorithm, we use the parameters ? r = {25, 15, 10}, ? d = {50, 30, 20}, s = {7, 4, 2}, and r t = {70, 50, 40}, where values are given in units of pixels and millimeters. Our method is compared to PoseCNN [71], the particle-filter-based approaches of <ref type="bibr" target="#b68">[69]</ref> and <ref type="bibr" target="#b26">[27]</ref>, and the current state of the art in deep learning-based 3D object tracking <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b66">[67]</ref>, and <ref type="bibr" target="#b14">[15]</ref>. The evaluation shows that ICG achieves state-of-the-art results with respect to the ADD-S metric, outperforming all other algorithms. For the ADD score, textureless methods have a significant disadvantage since, for some objects, the geometry is not conclusive. It is, for example, not possible to determine the rotation of a rotationally symmetric object without using texture. However, even with that handicap, ICG surpasses the texture-based approaches of PoseCNN and DeepIM. Also, it comes very close to the results of PoseRBPF. In the end, only se(3)-TrackNet is able to perform significantly better.</p><p>To utilize the full frequency of modern cameras, track multiple objects simultaneously, and save resources, efficiency is essential in real-world applications. We thus report the speed and the required hardware for all algorithms <ref type="table">Table 1</ref>. Results on the YCB-Video dataset <ref type="bibr" target="#b70">[71]</ref> with ADD and ADD-S area under curve scores in percent. Except for PoseRBPF <ref type="bibr" target="#b14">[15]</ref>, results are taken from <ref type="bibr" target="#b66">[67]</ref>. For DeepIM <ref type="bibr" target="#b33">[34]</ref>, the score over all frames was adjusted to be consistent with the evaluation of other methods. Objects with no conclusive geometry are indicated by a while objects with no or very little texture are marked by a .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach</head><p>PoseCNN + ICP + DeepIM <ref type="bibr" target="#b70">[71]</ref> W?thrich <ref type="bibr" target="#b68">[69]</ref> RGF <ref type="bibr" target="#b26">[27]</ref> DeepIM <ref type="bibr" target="#b33">[34]</ref> se <ref type="formula" target="#formula_2">(3)</ref>  <ref type="table">Table 2</ref>. Average speed in frames per second and hardware requirements for the CPU and GPU. Except for PoseRBPF <ref type="bibr" target="#b14">[15]</ref>, results are taken from <ref type="bibr" target="#b66">[67]</ref>. PoseRBPF was evaluated without SDF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Single Core No GPU FPS</head><p>PoseCNN+ICP+DeepIM <ref type="bibr" target="#b70">[71]</ref> 0.1 Hz W?thrich <ref type="bibr" target="#b68">[69]</ref> 12.9 Hz RGF <ref type="bibr" target="#b26">[27]</ref> 11.8 Hz DeepIM <ref type="bibr" target="#b33">[34]</ref> 12.0 Hz se(3)-TrackNet <ref type="bibr" target="#b66">[67]</ref> 90.9 Hz PoseRBPF <ref type="bibr" target="#b14">[15]</ref> 7.6 Hz ICG (Ours) 788.4 Hz in Tab. 2. The evaluation of ICG is conducted on an Intel Xeon E5-1630 v4 CPU. In comparison, <ref type="bibr" target="#b66">[67]</ref> used an Intel Xeon E5-1660 v3 CPU and a NVIDIA Tesla K40c GPU.</p><p>The results show the outstanding efficiency of our approach. While ICG runs only on a single CPU core, it is almost one order of magnitude faster than the second-best algorithm se(3)-TrackNet, which requires a high-performance GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">OPT Dataset</head><p>While the YCB-Video dataset features challenging sequences in real-world environments and a large number of objects, ground truth has limited accuracy and with a large threshold e t = 0.1 m, the dataset mostly evaluates robust- <ref type="table">Table 3</ref>. Results on the OPT dataset <ref type="bibr" target="#b69">[70]</ref>. The reported AUC scores are scaled between zero and twenty to match other evaluations. Results are taken from <ref type="bibr" target="#b69">[70]</ref> and the respective publications. ness. Also, images do not contain motion blur, favoring texture-based methods. The OPT dataset <ref type="bibr" target="#b69">[70]</ref> nicely complements those properties. It includes 6 objects and consists of 552 real-world sequences with significant motion blur. Ground truth is obtained using a calibration board. For the evaluation, the area under curve of the ADD metric is used with a threshold of r t = 0.2d, where d is the largest distance between model vertices. The final value is scaled between 0 and 20. Following <ref type="bibr" target="#b69">[70]</ref>, we refer to it as AUC score.</p><p>Evaluation results are reported in Tab. 3. For ICG, the parameters ? r = {15, 5, 1.5}, ? d = {35, 35, 25}, s = {6, 4, 1}, and r t = {50, 20, 10} are used. Also, like in <ref type="bibr" target="#b58">[59]</ref>, we constrain the rotationally symmetric soda object using  ? r = 70000. In the evaluation, ICG is compared to stateof-the-art classical methods that use different sources of information, including region, edge, texture, and depth. Our approach performs best or second-best for all objects and improves on the state of the art by a significant margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Choi Dataset</head><p>Finally, we also want to evaluate the accuracy of our method. For this, the simulated dataset of Choi <ref type="bibr" target="#b9">[10]</ref>, which features four sequences and perfect ground truth, is used. To evaluate the accuracy, root mean square (RMS) errors in the x, y, and z directions and in the roll, pitch, and yaw angles are calculated. The rotational and translational mean over all four sequences is reported in Tab. 4. Detailed results are provided in Appendix B.</p><p>For our algorithm, we use the parameters ? r = {5}, ? d = {10, 1}, s = {2, 1}, and r t = {10}. Note that since the dataset provides perfect depth and uncluttered color images, results have to be considered as an upper bound. Nevertheless, the experiments demonstrate that, with good enough data, the method is highly accurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Ablation Study</head><p>To demonstrate the importance of the algorithm's components, we perform an ablation study on all three datasets. Average results of this evaluation are provided in Tab. 5. The experiments show that while the effect of the depth and region modality differs between the datasets, each modality significantly contributes to the final result. Also, we observe that while values on the Choi dataset stay the same without regularization, it is very important to the challenging sequences of the OPT and YCB-Video dataset. For the case without occlusion handling, similar results are obtained.</p><p>Finally, the convergence of our approach is evaluated in <ref type="figure" target="#fig_4">Fig. 5</ref>. For the YCB-Video dataset, which values robustness, the algorithm converges after only two iterations. With  one additional iteration, accurate results are obtained on the Choi and OPT datasets. Independent of accuracy and robustness, fast convergence ensures that a maximum of only four iterations is sufficient to obtain excellent results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Limitations</head><p>While ICG achieves remarkable results, some limitations remain. First, our method requires the geometry of tracked objects. Also, for the region modality, objects have to be distinguishable from the background. In addition, the depth camera has to provide reasonable measurements for the object's surface. Another important limitation emerges if the object geometry is very similar in the vicinity of a particular pose. Naturally, using geometric information alone, it is impossible to predict the correct pose in such cases. Finally, like many conventional approaches that use line search, the algorithm has only a local view of the six-dimensional joint probability distribution. As a consequence, it is constrained by local minima with a limit to the maximum pose difference between consecutive frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this work, we developed ICG, a highly efficient, textureless approach to 3D object tracking. The method fuses region and depth in a well-founded probabilistic formulation that is able to handle occlusions in a robust manner. While the overall algorithm is relatively simple and requires little computation, it performs surprisingly well on multiple datasets, outperforming the current state of the art for many cases in robustness, accuracy, and efficiency. This is even more remarkable since ICG has an inherent disadvantage in not using texture. Assuming that texture would further improve results, our evaluation suggests that deep learningbased techniques do not yet surpass classical methods. This is especially surprising since, at the expense of high computational cost and limited real-time capability, such algorithms can, in theory, directly consider all available information. As a consequence, we believe that for both classical and learning-based tracking, as well as potential combinations, there remains a large number of ideas that wait to be explored to further improve 3D object tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Timings</head><p>In Tab. 2, an average framerate of 788.4 Hz was given for the evaluation on the YCB-Video dataset <ref type="bibr" target="#b70">[71]</ref>. This corresponds to a total duration of 1.27 ms per frame. Of this time, the algorithm needs 0.52 ms for the computation of correspondence lines, 0.58 ms for correspondence points, 0.09 ms for the calculation of gradient vectors and Hessian matrices, 0.05 ms for the update of color histograms, and the remaining 0.03 ms for other operations such as the optimization and pose update. The timings demonstrate that the region-and depth-modality are well balanced, requiring similar amounts of computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Choi Dataset</head><p>In the main paper in Tab. 4, only the averages over rotational and translational RMS errors were presented for the Choi dataset <ref type="bibr" target="#b9">[10]</ref>. For the sake of completeness, we also want to provide the full results with respect to the errors in the x, y, and z directions and in the roll, pitch, and yaw angles. The results for each of the four evaluated objects as well as the mean values are shown in Tab. 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. RBOT Dataset</head><p>In Sec. 3.3, we modified the region-based approach of SRT3D <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref> to be independent of the scale space and to incorporate a user-defined uncertainty. In the following, we want to show that this is not only convenient for the combination with the depth modality but that the modifications also improve tracking results. We thereby use the RBOT dataset <ref type="bibr" target="#b62">[63]</ref> to compare our approach to the state of the art in region-based tracking as well as to additional methods that include edge information.</p><p>All experiments in the evaluation are performed as defined by <ref type="bibr" target="#b62">[63]</ref>. The required translational and rotational errors are calculated as follows </p><formula xml:id="formula_29">e t = M t t t Mgt 2 ,<label>(30)</label></formula><formula xml:id="formula_30">e r = cos ?1 trace( M R R R Mgt ) ? 1 2 .<label>(31)</label></formula><p>Based on those errors, the tracking success is calculated as the percentage of estimated poses with e t &lt; 5 cm and e r &lt; 5 ? . In cases of unsuccessful tracking, the algorithm is re-initialized with the ground-truth pose. For ICG, we use the same parameter values as in <ref type="bibr" target="#b58">[59]</ref> and define a decreasing standard deviation of ? r = {15, 5, 3.5, 1.5}. Results of the evaluation are shown in Tab. 7. The reported scores show that both SRT3D and ICG achieve significantly higher results than the remaining algorithms. However, on average, ICG performs about half a percentage point better than SRT3D. This demonstrates that setting a defined standard deviation ? r instead of using an implicit variance of ? 2 = shs 2 /n 2 helps to further improve results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. 6DoF Pose Estimation</head><p>Given the strong results of modern 6DoF pose estimation methods <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b30">31]</ref>, the question arises whether 3D object tracking is even necessary. In order to answer this, we compare ICG with state-of-the-art pose estimation methods on the YCB-Video dataset <ref type="bibr" target="#b70">[71]</ref>. The ADD(S) metric is thereby adopted to ensure compatibility with reported results from PVN3D <ref type="bibr" target="#b21">[22]</ref> and FFB6D <ref type="bibr" target="#b20">[21]</ref>. It is a combined metric that uses the ADD-S score for symmetric objects and the ADD error in all other cases.</p><p>Results of the evaluation are shown in Tab. 8. The com- <ref type="table">Table 7</ref>. Tracking success rate for all objects and scenarios on the RBOT dataset <ref type="bibr" target="#b62">[63]</ref>. Methods that incorporate information from edges in addition to region are indicated by a . Results are from the respective publications. parison demonstrates that ICG is able to outperform most methods by a considerable margin for the ADD-S score, performing on par with the best reported results from FFB6D. This is remarkable since FFB6D trains on large amounts of pose-annotated real-world data that originates from a similar pose distribution. For many applications, such data is not available. In contrast, ICG only requires a texture-less 3D model and no training data. With respect to the ADD(S) metric, both PVN3D and FFB6D report better results. The main reason for this is that our method is by design not considering texture and thus has a considerable disadvantage if the geometry is not conclusive. However, in return, there is no need for textured 3D models, which are required for all 1 https://github.com/yuxng/YCB_Video_toolbox 2 https://github.com/DLR-RM/AugmentedAutoencoder 3 https://github.com/ylabbe/cosypose competing methods.</p><p>In contrast to 6DoF pose estimation algorithms, ICG considers the pose on a frame-to-frame basis without reinitialization. This leads to a small number of objects that get stuck in local minima and thus show relatively poor performance. On the other hand, ICG benefits from temporal consistency and performs more accurate than FFB6D for most objects. The advantage of our tracker becomes particularly obvious when comparing the required computation. While FFB6D depends on a high-end GPU and reports a runtime of 75 ms <ref type="bibr" target="#b20">[21]</ref>, ICG requires only 1.3 ms per frame on a single CPU core, which is 57? faster. This is especially crucial in reactive, real-time applications for which hardware constraints exist. In conclusion, the experiment demonstrates that while tracking by detection is possible, for many real-world applications, it is not the most sensible <ref type="table">Table 8</ref>. Comparison against state-of-the-art 6DoF pose estimation methods on the YCB-Video dataset <ref type="bibr" target="#b70">[71]</ref> with ADD(S) and ADD-S area under curve scores in percent. Results for Augmented Autoencoders 2 <ref type="bibr" target="#b60">[61]</ref>, CosyPose 3 <ref type="bibr" target="#b30">[31]</ref>, and ICG were computed by us. All other values are from the respective publications. While CosyPose was trained on real data, good results can also be obtained using synthetic data alone <ref type="bibr" target="#b24">[25]</ref>. Symmetric objects for which the ADD(S) metric reports the ADD-S instead of the ADD error are indicated by a .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach</head><p>PoseCNN <ref type="bibr" target="#b70">[71]</ref> Augmented Autoencoders 2 <ref type="bibr" target="#b60">[61]</ref> DenseFusion <ref type="bibr" target="#b65">[66]</ref> CosyPose 3 <ref type="bibr" target="#b30">[31]</ref> PVN3D <ref type="bibr" target="#b21">[22]</ref> FFB6D <ref type="bibr" target="#b20">[21]</ref> ICG (Ours)  solution. Given the high efficiency and good performance of ICG, in our opinion, it is best to rely on continuous 3D tracking for local pose updates while using 6DoF pose estimation for global initialization and long-term consistency. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. 6-DoF Pose Refinement</head><p>Given that ICG is a local optimization method, the question emerges how well it would work for pose refinement. In the following, we thus use ICG to improve the predictions of PoseCNN, Augmented Autoencoders, and Cosy-Pose and compare results on the YCB-Video dataset <ref type="bibr" target="#b70">[71]</ref>. Depending on the pose estimation algorithm, errors along the principal axis are relatively large. To cope with those larger translational errors, we use the following parameters r t = {300, 250, 100}, ? d = {100, 50, 20}, ? t = 100, and conduct 7 instead of 4 iterations. For efficiency, strides are increased from 5 mm to 10 mm. All other parameters remain the same as in the evaluation of tracking. With the increased number of iterations and considered area, the runtime increases to 2.7 ms per frame.</p><p>Results of the conducted evaluation are shown in Tab. 9. We thereby report both refined and unrefined scores for the considered 6DoF pose estimation methods. In addition, results from <ref type="bibr" target="#b70">[71]</ref> are provided, which were obtained using an extensive multi-hypothesis ICP approach on the predictions of PoseCNN. According to <ref type="bibr" target="#b65">[66]</ref>, this refinement algorithm requires more than 10 s for a single pose. The evaluation shows that, even for the very good results of CosyPose, ICG is able to improve pose estimations for almost all objects. Also, it is interesting to see that, while it can not fully compete with extensive multi-hypothesis ICP refinement, the difference is not as big as one might expect. This is especially impressive considering that ICG is more than three orders of magnitude faster.</p><p>Finally, we want to ensure that the pose refinement uses both depth and region information and that improvements are not only from the ICP-based depth modality. We thus conducted a short ablation study, for which results are shown in Tab. 10. The obtained scores demonstrate that ICG is not just a blown-up ICP approach but that the addition of region information significantly helps to improve performance. Given the good pose predictions and computational efficiency, we are thus confident that, while ICG is an excellent 3D object tracking approach, it also has many applications in pose refinement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>, 1 https://github.com/DLR-RM/3DObjectTracking Tracking of a pentagon object for robotic manipulation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>The probabilities p(y y y | m f ) and p(y y y | m b ) are approximated using normalized color histograms. They describe the likelihood that pixel colors y y y are part of the foreground or background model m f or m b . Based on those probabilities, segment-wise posteriors are calculated as p si (r s ) = y y y?s s s p(y y y | m i ) y y y?s s s p(y y y | m f ) + y y y?s s s p(y y y | m b ), i ? {f, b},</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Visualization of the occlusion handling strategy. For each blue model point, the considered region is defined by a blue line and dotted gray cone. The lower yellow line in each cone visualizes the depth value that is calculated from the model offset, while the upper yellow line adds the user-defined threshold. Red lines indicate the minimum depth measurements from the camera. For the right point, an occlusion is detected since the red depth measurement is smaller than the expected value in yellow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Convergence plot showing the final results for the YCB-Video, OPT, and Choi dataset in red, yellow, and blue, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>(</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .</head><label>4</label><figDesc>Mean RMS errors for translation and rotation parameters on the Choi dataset<ref type="bibr" target="#b9">[10]</ref>. Results are from the respective papers.</figDesc><table><row><cell>Approach</cell><cell cols="2">Choi [10] Krull [30]</cell><cell>Tan [62]</cell><cell cols="2">Kehl [28] ICG (Ours)</cell></row><row><cell>Translation [mm]</cell><cell>1.36</cell><cell>0.82</cell><cell>0.10</cell><cell>0.51</cell><cell>0.04</cell></row><row><cell>Rotation [degree]</cell><cell>2.45</cell><cell>1.38</cell><cell>0.07</cell><cell>0.26</cell><cell>0.04</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 .</head><label>5</label><figDesc>Ablation study on critical components of our algorithm.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Choi [10]</cell><cell>OPT [70]</cell><cell cols="2">YCB-Video [71]</cell></row><row><cell>Experiment</cell><cell>Trans.</cell><cell>Rot.</cell><cell>AUC</cell><cell>ADD</cell><cell>ADD-S</cell></row><row><cell>Original</cell><cell>0.04</cell><cell>0.04</cell><cell>16.54</cell><cell>86.4</cell><cell>96.5</cell></row><row><cell>W/o Region</cell><cell>0.06</cell><cell>0.04</cell><cell>8.94</cell><cell>66.1</cell><cell>84.1</cell></row><row><cell>W/o Depth</cell><cell>41.65</cell><cell>23.39</cell><cell>15.88</cell><cell>26.6</cell><cell>42.8</cell></row><row><cell>W/o Regularization</cell><cell>0.04</cell><cell>0.04</cell><cell>14.48</cell><cell>72.0</cell><cell>91.5</cell></row><row><cell>W/o Occlusion Hand.</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>77.6</cell><cell>91.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 .</head><label>6</label><figDesc>RMS errors for translation and rotation parameters on the Choi dataset<ref type="bibr" target="#b9">[10]</ref>. Results are from the respective papers.</figDesc><table><row><cell>Approach</cell><cell></cell><cell cols="5">Choi [10] Krull [30] Tan [62] Kehl [28] ICG (Ours)</cell></row><row><cell></cell><cell>X</cell><cell>1.84</cell><cell>0.83</cell><cell>0.15</cell><cell>0.76</cell><cell>0.05</cell></row><row><cell></cell><cell>Y</cell><cell>2.23</cell><cell>1.67</cell><cell>0.19</cell><cell>1.09</cell><cell>0.11</cell></row><row><cell>Kinect</cell><cell>Z</cell><cell>1.36</cell><cell>0.79</cell><cell>0.09</cell><cell>0.38</cell><cell>0.03</cell></row><row><cell>Box</cell><cell>Roll</cell><cell>6.41</cell><cell>1.11</cell><cell>0.09</cell><cell>0.17</cell><cell>0.02</cell></row><row><cell></cell><cell>Pitch</cell><cell>0.76</cell><cell>0.55</cell><cell>0.06</cell><cell>0.18</cell><cell>0.02</cell></row><row><cell></cell><cell>Yaw</cell><cell>6.32</cell><cell>1.04</cell><cell>0.04</cell><cell>0.20</cell><cell>0.02</cell></row><row><cell></cell><cell>X</cell><cell>0.93</cell><cell>0.51</cell><cell>0.09</cell><cell>0.64</cell><cell>0.02</cell></row><row><cell></cell><cell>Y</cell><cell>1.94</cell><cell>1.27</cell><cell>0.11</cell><cell>0.59</cell><cell>0.05</cell></row><row><cell>Milk</cell><cell>Z Roll</cell><cell>1.09 3.83</cell><cell>0.62 2.19</cell><cell>0.08 0.07</cell><cell>0.24 0.41</cell><cell>0.02 0.06</cell></row><row><cell></cell><cell>Pitch</cell><cell>1.41</cell><cell>1.44</cell><cell>0.09</cell><cell>0.29</cell><cell>0.04</cell></row><row><cell></cell><cell>Yaw</cell><cell>3.26</cell><cell>1.90</cell><cell>0.06</cell><cell>0.42</cell><cell>0.06</cell></row><row><cell></cell><cell>X</cell><cell>0.96</cell><cell>0.52</cell><cell>0.11</cell><cell>0.50</cell><cell>0.04</cell></row><row><cell></cell><cell>Y</cell><cell>1.44</cell><cell>0.74</cell><cell>0.09</cell><cell>0.69</cell><cell>0.03</cell></row><row><cell>Orange</cell><cell>Z</cell><cell>1.17</cell><cell>0.63</cell><cell>0.09</cell><cell>0.17</cell><cell>0.02</cell></row><row><cell>Juice</cell><cell>Roll</cell><cell>1.32</cell><cell>1.28</cell><cell>0.08</cell><cell>0.12</cell><cell>0.05</cell></row><row><cell></cell><cell>Pitch</cell><cell>0.75</cell><cell>1.08</cell><cell>0.08</cell><cell>0.20</cell><cell>0.03</cell></row><row><cell></cell><cell>Yaw</cell><cell>1.39</cell><cell>1.20</cell><cell>0.08</cell><cell>0.19</cell><cell>0.06</cell></row><row><cell></cell><cell>X</cell><cell>0.83</cell><cell>0.69</cell><cell>0.08</cell><cell>0.34</cell><cell>0.02</cell></row><row><cell></cell><cell>Y</cell><cell>1.37</cell><cell>0.81</cell><cell>0.09</cell><cell>0.49</cell><cell>0.03</cell></row><row><cell>Tide</cell><cell>Z Roll</cell><cell>1.20 1.78</cell><cell>0.81 2.10</cell><cell>0.07 0.05</cell><cell>0.18 0.15</cell><cell>0.01 0.03</cell></row><row><cell></cell><cell>Pitch</cell><cell>1.09</cell><cell>1.38</cell><cell>0.12</cell><cell>0.39</cell><cell>0.04</cell></row><row><cell></cell><cell>Yaw</cell><cell>1.13</cell><cell>1.27</cell><cell>0.05</cell><cell>0.37</cell><cell>0.03</cell></row><row><cell cols="2">Mean Translation</cell><cell>1.36</cell><cell>0.82</cell><cell>0.10</cell><cell>0.51</cell><cell>0.04</cell></row><row><cell cols="2">Mean Rotation</cell><cell>2.45</cell><cell>1.38</cell><cell>0.07</cell><cell>0.26</cell><cell>0.04</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 9 .</head><label>9</label><figDesc>Refined and unrefined results on the YCB-Video dataset<ref type="bibr" target="#b70">[71]</ref> with ADD and ADD-S area under curve scores in percent. For PoseCNN with multi-hypothesis ICP, results are taken from the corresponding publication<ref type="bibr" target="#b70">[71]</ref>. To evaluate the refinement, predicted poses for PoseCNN<ref type="bibr" target="#b70">[71]</ref> are taken from the YCB Video toolbox 1 while results for Augmented Autoencoders 2<ref type="bibr" target="#b60">[61]</ref> and CosyPose 3<ref type="bibr" target="#b30">[31]</ref> are computed using source code from the respective repositories.</figDesc><table><row><cell>002 master chef can</cell><cell>50.9</cell><cell>84.0</cell><cell>27.1</cell><cell>50.6</cell><cell>-</cell><cell>96.4</cell><cell>37.3</cell><cell>90.6</cell><cell>80.5</cell><cell>96.0</cell><cell>80.6</cell><cell>96.3</cell><cell>66.4</cell><cell>89.7</cell></row><row><cell>003 cracker box</cell><cell>51.7</cell><cell>76.9</cell><cell>32.2</cell><cell>64.5</cell><cell>-</cell><cell>95.5</cell><cell>76.8</cell><cell>94.9</cell><cell>94.8</cell><cell>96.1</cell><cell>94.6</cell><cell>96.3</cell><cell>82.4</cell><cell>92.1</cell></row><row><cell>004 sugar box</cell><cell>68.6</cell><cell>84.3</cell><cell>73.6</cell><cell>88.6</cell><cell>-</cell><cell>97.5</cell><cell>95.2</cell><cell>97.6</cell><cell>96.3</cell><cell>97.4</cell><cell>96.6</cell><cell>97.6</cell><cell>96.1</cell><cell>98.4</cell></row><row><cell>005 tomato soup can</cell><cell>66.0</cell><cell>80.9</cell><cell>72.3</cell><cell>84.4</cell><cell>-</cell><cell>94.6</cell><cell>90.5</cell><cell>94.6</cell><cell>88.5</cell><cell>96.2</cell><cell>89.6</cell><cell>95.6</cell><cell>73.2</cell><cell>97.3</cell></row><row><cell>006 mustard bottle</cell><cell>79.9</cell><cell>90.2</cell><cell>77.5</cell><cell>90.9</cell><cell>-</cell><cell>97.2</cell><cell>92.7</cell><cell>96.5</cell><cell>96.2</cell><cell>97.5</cell><cell>97.0</cell><cell>97.8</cell><cell>96.2</cell><cell>98.4</cell></row><row><cell>007 tuna fish can</cell><cell>70.4</cell><cell>87.9</cell><cell>71.2</cell><cell>92.2</cell><cell>-</cell><cell>96.6</cell><cell>93.9</cell><cell>97.5</cell><cell>89.3</cell><cell>96.0</cell><cell>88.9</cell><cell>96.8</cell><cell>73.2</cell><cell>95.8</cell></row><row><cell>008 pudding box</cell><cell>62.9</cell><cell>79.0</cell><cell>47.9</cell><cell>67.7</cell><cell>-</cell><cell>96.5</cell><cell>93.5</cell><cell>96.2</cell><cell>95.7</cell><cell>97.1</cell><cell>94.6</cell><cell>97.1</cell><cell>73.8</cell><cell>88.9</cell></row><row><cell>009 gelatin box</cell><cell>75.2</cell><cell>87.1</cell><cell>74.8</cell><cell>82.9</cell><cell>-</cell><cell>98.1</cell><cell>94.1</cell><cell>96.1</cell><cell>96.1</cell><cell>97.7</cell><cell>96.9</cell><cell>98.1</cell><cell>97.2</cell><cell>98.8</cell></row><row><cell>010 potted meat can</cell><cell>59.6</cell><cell>78.5</cell><cell>53.6</cell><cell>63.3</cell><cell>-</cell><cell>91.3</cell><cell>75.9</cell><cell>84.0</cell><cell>88.6</cell><cell>93.3</cell><cell>88.1</cell><cell>94.7</cell><cell>93.3</cell><cell>97.3</cell></row><row><cell>011 banana</cell><cell>72.3</cell><cell>85.9</cell><cell>13.1</cell><cell>51.6</cell><cell>-</cell><cell>96.6</cell><cell>90.0</cell><cell>95.6</cell><cell>93.7</cell><cell>96.6</cell><cell>94.9</cell><cell>97.2</cell><cell>95.6</cell><cell>98.4</cell></row><row><cell>019 pitcher base</cell><cell>52.5</cell><cell>76.8</cell><cell>77.6</cell><cell>91.7</cell><cell>-</cell><cell>97.1</cell><cell>94.0</cell><cell>97.3</cell><cell>96.5</cell><cell>97.4</cell><cell>96.9</cell><cell>97.6</cell><cell>97.0</cell><cell>98.8</cell></row><row><cell>021 bleach cleanser</cell><cell>50.5</cell><cell>71.9</cell><cell>42.0</cell><cell>62.6</cell><cell>-</cell><cell>95.8</cell><cell>82.1</cell><cell>92.7</cell><cell>93.2</cell><cell>96.0</cell><cell>94.8</cell><cell>96.8</cell><cell>92.6</cell><cell>97.5</cell></row><row><cell>024 bowl</cell><cell>69.7</cell><cell>69.7</cell><cell>79.1</cell><cell>79.1</cell><cell>-</cell><cell>88.2</cell><cell>87.8</cell><cell>87.8</cell><cell>90.2</cell><cell>90.2</cell><cell>96.3</cell><cell>96.3</cell><cell>98.4</cell><cell>98.4</cell></row><row><cell>025 mug</cell><cell>57.7</cell><cell>78.0</cell><cell>58.0</cell><cell>80.9</cell><cell>-</cell><cell>97.1</cell><cell>87.8</cell><cell>94.9</cell><cell>95.4</cell><cell>97.6</cell><cell>94.2</cell><cell>97.3</cell><cell>95.6</cell><cell>98.5</cell></row><row><cell>035 power drill</cell><cell>55.1</cell><cell>72.8</cell><cell>61.2</cell><cell>77.9</cell><cell>-</cell><cell>96.0</cell><cell>89.7</cell><cell>95.1</cell><cell>95.1</cell><cell>96.7</cell><cell>95.9</cell><cell>97.2</cell><cell>96.7</cell><cell>98.5</cell></row><row><cell>036 wood block</cell><cell>65.8</cell><cell>65.8</cell><cell>55.2</cell><cell>55.2</cell><cell>-</cell><cell>89.7</cell><cell>80.5</cell><cell>80.5</cell><cell>90.4</cell><cell>90.4</cell><cell>92.6</cell><cell>92.6</cell><cell>97.2</cell><cell>97.2</cell></row><row><cell>037 scissors</cell><cell>35.8</cell><cell>56.2</cell><cell>0.8</cell><cell>7.0</cell><cell>-</cell><cell>95.2</cell><cell>67.6</cell><cell>81.5</cell><cell>92.7</cell><cell>96.7</cell><cell>95.7</cell><cell>97.7</cell><cell>93.5</cell><cell>97.3</cell></row><row><cell>040 large marker</cell><cell>58.0</cell><cell>71.4</cell><cell>55.6</cell><cell>67.6</cell><cell>-</cell><cell>97.5</cell><cell>84.3</cell><cell>93.1</cell><cell>91.8</cell><cell>96.7</cell><cell>89.1</cell><cell>96.6</cell><cell>88.5</cell><cell>97.8</cell></row><row><cell>051 large clamp</cell><cell>49.9</cell><cell>49.9</cell><cell>72.2</cell><cell>72.2</cell><cell>-</cell><cell>72.9</cell><cell>91.3</cell><cell>91.3</cell><cell>93.6</cell><cell>93.6</cell><cell>96.8</cell><cell>96.8</cell><cell>96.9</cell><cell>96.9</cell></row><row><cell>052 extra large clamp</cell><cell>47.0</cell><cell>47.0</cell><cell>59.5</cell><cell>59.5</cell><cell>-</cell><cell>69.8</cell><cell>75.7</cell><cell>75.7</cell><cell>88.4</cell><cell>88.4</cell><cell>96.0</cell><cell>96.0</cell><cell>94.3</cell><cell>94.3</cell></row><row><cell>061 foam brick</cell><cell>87.8</cell><cell>87.8</cell><cell>56.2</cell><cell>56.2</cell><cell>-</cell><cell>92.5</cell><cell>94.7</cell><cell>94.7</cell><cell>96.8</cell><cell>96.8</cell><cell>97.3</cell><cell>97.3</cell><cell>98.5</cell><cell>98.5</cell></row><row><cell>All Frames</cell><cell>60.0</cell><cell>75.9</cell><cell>57.5</cell><cell>72.8</cell><cell>-</cell><cell>93.1</cell><cell>83.8</cell><cell>92.6</cell><cell>91.8</cell><cell>95.5</cell><cell>92.7</cell><cell>96.6</cell><cell>87.9</cell><cell>96.5</cell></row><row><cell>Approach</cell><cell cols="2">PoseCNN [71]</cell><cell></cell><cell cols="2">PoseCNN 1 [71]</cell><cell></cell><cell cols="4">Augmented Autoencoders 2 [61]</cell><cell></cell><cell cols="2">CosyPose 3 [31]</cell><cell></cell></row><row><cell>Refinement</cell><cell cols="2">MH ICP</cell><cell>-</cell><cell></cell><cell cols="2">ICG (Ours)</cell><cell>-</cell><cell></cell><cell cols="2">ICG (Ours)</cell><cell cols="2">Iterative Matching</cell><cell cols="2">IM + ICG (Ours)</cell></row><row><cell>Objects</cell><cell cols="2">ADD ADD-S</cell><cell cols="2">ADD ADD-S</cell><cell cols="2">ADD ADD-S</cell><cell cols="2">ADD ADD-S</cell><cell cols="2">ADD ADD-S</cell><cell cols="2">ADD ADD-S</cell><cell cols="2">ADD ADD-S</cell></row><row><cell>002 master chef can</cell><cell>69.0</cell><cell>95.8</cell><cell>50.0</cell><cell>84.6</cell><cell>66.7</cell><cell>94.7</cell><cell>27.1</cell><cell>50.6</cell><cell>38.3</cell><cell>67.2</cell><cell>37.3</cell><cell>90.6</cell><cell>38.6</cell><cell>93.1</cell></row><row><cell>003 cracker box</cell><cell>80.7</cell><cell>91.8</cell><cell>53.0</cell><cell>77.5</cell><cell>67.8</cell><cell>85.6</cell><cell>32.2</cell><cell>64.5</cell><cell>43.8</cell><cell>71.6</cell><cell>76.8</cell><cell>94.9</cell><cell>81.4</cell><cell>97.9</cell></row><row><cell>004 sugar box</cell><cell>97.2</cell><cell>98.2</cell><cell>68.3</cell><cell>84.5</cell><cell>91.9</cell><cell>96.3</cell><cell>73.6</cell><cell>88.6</cell><cell>85.2</cell><cell>94.9</cell><cell>95.2</cell><cell>97.6</cell><cell>95.8</cell><cell>98.2</cell></row><row><cell>005 tomato soup can</cell><cell>81.6</cell><cell>94.5</cell><cell>66.1</cell><cell>81.4</cell><cell>82.8</cell><cell>91.3</cell><cell>72.3</cell><cell>84.4</cell><cell>82.3</cell><cell>90.0</cell><cell>90.5</cell><cell>94.6</cell><cell>92.6</cell><cell>95.9</cell></row><row><cell>006 mustard bottle</cell><cell>97.0</cell><cell>98.4</cell><cell>80.8</cell><cell>91.1</cell><cell>93.9</cell><cell>97.4</cell><cell>77.5</cell><cell>90.9</cell><cell>87.9</cell><cell>96.9</cell><cell>92.7</cell><cell>96.5</cell><cell>96.3</cell><cell>98.4</cell></row><row><cell>007 tuna fish can</cell><cell>83.1</cell><cell>97.1</cell><cell>70.5</cell><cell>88.4</cell><cell>82.2</cell><cell>93.5</cell><cell>71.2</cell><cell>92.2</cell><cell>78.6</cell><cell>95.2</cell><cell>93.9</cell><cell>97.5</cell><cell>92.2</cell><cell>95.6</cell></row><row><cell>008 pudding box</cell><cell>96.6</cell><cell>97.9</cell><cell>62.2</cell><cell>79.3</cell><cell>72.3</cell><cell>85.1</cell><cell>47.9</cell><cell>67.7</cell><cell>58.6</cell><cell>81.7</cell><cell>93.5</cell><cell>96.2</cell><cell>81.9</cell><cell>91.6</cell></row><row><cell>009 gelatin box</cell><cell>98.2</cell><cell>98.8</cell><cell>74.9</cell><cell>87.7</cell><cell>95.1</cell><cell>97.8</cell><cell>74.8</cell><cell>82.9</cell><cell>81.9</cell><cell>88.9</cell><cell>94.1</cell><cell>96.1</cell><cell>93.5</cell><cell>97.9</cell></row><row><cell>010 potted meat can</cell><cell>83.8</cell><cell>92.8</cell><cell>59.3</cell><cell>78.8</cell><cell>69.1</cell><cell>82.4</cell><cell>53.6</cell><cell>63.3</cell><cell>61.7</cell><cell>68.0</cell><cell>75.9</cell><cell>84.0</cell><cell>78.8</cell><cell>85.7</cell></row><row><cell>011 banana</cell><cell>91.6</cell><cell>96.9</cell><cell>72.3</cell><cell>86.3</cell><cell>80.4</cell><cell>92.0</cell><cell>13.1</cell><cell>51.6</cell><cell>18.2</cell><cell>60.1</cell><cell>90.0</cell><cell>95.6</cell><cell>95.2</cell><cell>98.2</cell></row><row><cell>019 pitcher base</cell><cell>96.7</cell><cell>97.8</cell><cell>52.9</cell><cell>77.6</cell><cell>85.9</cell><cell>93.6</cell><cell>77.6</cell><cell>91.7</cell><cell>92.1</cell><cell>98.0</cell><cell>94.0</cell><cell>97.3</cell><cell>96.7</cell><cell>98.7</cell></row><row><cell>021 bleach cleanser</cell><cell>92.3</cell><cell>96.8</cell><cell>50.2</cell><cell>71.7</cell><cell>74.7</cell><cell>87.6</cell><cell>42.0</cell><cell>62.6</cell><cell>54.4</cell><cell>70.9</cell><cell>82.1</cell><cell>92.7</cell><cell>90.0</cell><cell>97.8</cell></row><row><cell>024 bowl</cell><cell>17.5</cell><cell>78.3</cell><cell>3.0</cell><cell>69.6</cell><cell>5.5</cell><cell>78.0</cell><cell>17.3</cell><cell>79.1</cell><cell>19.6</cell><cell>79.5</cell><cell>34.5</cell><cell>87.8</cell><cell>36.6</cell><cell>89.8</cell></row><row><cell>025 mug</cell><cell>81.4</cell><cell>95.1</cell><cell>58.4</cell><cell>78.8</cell><cell>88.2</cell><cell>96.6</cell><cell>58.0</cell><cell>80.9</cell><cell>82.8</cell><cell>93.6</cell><cell>87.8</cell><cell>94.9</cell><cell>94.9</cell><cell>98.2</cell></row><row><cell>035 power drill</cell><cell>96.9</cell><cell>98.0</cell><cell>55.2</cell><cell>73.2</cell><cell>95.1</cell><cell>97.9</cell><cell>61.2</cell><cell>77.9</cell><cell>81.9</cell><cell>89.3</cell><cell>89.7</cell><cell>95.1</cell><cell>96.2</cell><cell>98.3</cell></row><row><cell>036 wood block</cell><cell>79.2</cell><cell>90.5</cell><cell>26.4</cell><cell>64.3</cell><cell>35.5</cell><cell>69.9</cell><cell>1.6</cell><cell>55.2</cell><cell>2.5</cell><cell>60.8</cell><cell>24.8</cell><cell>80.5</cell><cell>29.0</cell><cell>87.4</cell></row><row><cell>037 scissors</cell><cell>78.4</cell><cell>92.2</cell><cell>34.8</cell><cell>55.9</cell><cell>59.0</cell><cell>79.6</cell><cell>0.8</cell><cell>7.0</cell><cell>0.7</cell><cell>7.5</cell><cell>67.6</cell><cell>81.5</cell><cell>73.9</cell><cell>86.9</cell></row><row><cell>040 large marker</cell><cell>85.4</cell><cell>97.2</cell><cell>58.2</cell><cell>71.9</cell><cell>83.6</cell><cell>95.3</cell><cell>55.6</cell><cell>67.6</cell><cell>65.9</cell><cell>75.7</cell><cell>84.3</cell><cell>93.1</cell><cell>90.8</cell><cell>97.5</cell></row><row><cell>051 large clamp</cell><cell>52.6</cell><cell>75.4</cell><cell>24.6</cell><cell>50.1</cell><cell>50.7</cell><cell>74.0</cell><cell>32.8</cell><cell>72.2</cell><cell>41.2</cell><cell>83.3</cell><cell>40.1</cell><cell>91.3</cell><cell>40.8</cell><cell>94.6</cell></row><row><cell>052 extra large clamp</cell><cell>28.7</cell><cell>65.3</cell><cell>16.3</cell><cell>44.5</cell><cell>25.8</cell><cell>67.7</cell><cell>26.9</cell><cell>59.5</cell><cell>32.5</cell><cell>63.6</cell><cell>40.2</cell><cell>75.7</cell><cell>40.5</cell><cell>75.1</cell></row><row><cell>061 foam brick</cell><cell>48.3</cell><cell>97.1</cell><cell>40.4</cell><cell>88.2</cell><cell>42.2</cell><cell>92.5</cell><cell>19.4</cell><cell>56.2</cell><cell>22.5</cell><cell>57.7</cell><cell>51.7</cell><cell>94.7</cell><cell>52.7</cell><cell>97.6</cell></row><row><cell>All Frames</cell><cell>79.3</cell><cell>93.0</cell><cell>53.7</cell><cell>76.3</cell><cell>73.1</cell><cell>89.3</cell><cell>50.5</cell><cell>72.8</cell><cell>61.2</cell><cell>80.3</cell><cell>76.1</cell><cell>92.6</cell><cell>78.9</cell><cell>94.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 10 .</head><label>10</label><figDesc>Ablation study comparing refined results for ICG with and without the region modality to unrefined results. Values show ADD and ADD-S area under curve scores over all frames on the YCB-Video dataset<ref type="bibr" target="#b70">[71]</ref> in percent.</figDesc><table><row><cell>Approach</cell><cell>PoseCNN 1 [71]</cell><cell cols="2">Augmented Autoencoders 2 [61]</cell><cell>CosyPose 3 [31]</cell></row><row><cell>Refinement</cell><cell>ADD ADD-S</cell><cell cols="2">ADD ADD-S</cell><cell>ADD ADD-S</cell></row><row><cell>Unrefined</cell><cell>53.7 76.3</cell><cell>50.5</cell><cell>72.8</cell><cell>76.1 92.6</cell></row><row><cell>ICG w/o Region</cell><cell>65.0 84.2</cell><cell>57.5</cell><cell>76.9</cell><cell>76.8 93.3</cell></row><row><cell>ICG w/ Region</cell><cell>73.1 89.3</cell><cell>61.2</cell><cell>80.3</cell><cell>78.9 94.7</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>In the following, we first state timings for the individual steps of our algorithm. After this, the full results on the Choi dataset <ref type="bibr" target="#b9">[10]</ref> are presented, for which a concise version was shown in the main paper. Subsequently, the developed region modality is evaluated on the RBOT dataset [63], demonstrating improved tracking success. Also, we compare to state-of-the-art 6DoF pose estimation algorithms on the YCB-Video dataset <ref type="bibr" target="#b70">[71]</ref> and discuss the role of 3D object tracking. Finally, using predictions from modern pose estimation algorithms, we demonstrate that ICG is well-suited for highly efficient pose refinement.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Real-time image-based tracking of planes using efficient second-order minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Selim</forename><surname>Benhimane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ezio</forename><surname>Malis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="943" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A method for registration of 3-D shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><forename type="middle">D</forename><surname>Besl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mckay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust real-time visual tracking using pixel-wise posteriors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Bibby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Registering multiview range data to create 3D computer objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?rard</forename><surname>Blais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">D</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Uncertaintydriven 6D pose estimation of objects and scenes from a single RGB image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Krull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3364" to="3372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Combined region and motion-based 3D tracking of rigid and articulated objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="402" to="415" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Combining 3D model contour energy and keypoints for object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Bugaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Kryshchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Belov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="55" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The YCB object and model set: Towards common benchmarks for manipulation research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berk</forename><surname>Calli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Walsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Srinivasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">M</forename><surname>Dollar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Advanced Robotics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="510" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Object modelling by registration of multiple range images. Image and Vision Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?rard</forename><surname>Medioni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">RGB-D object tracking: A particle filter approach on GPU</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhyun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><forename type="middle">I</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Probabilistic articulated realtime tracking for robot manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristina</forename><forename type="middle">G</forename><surname>Cifuentes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Issac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>W?thrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Schaal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeannette</forename><surname>Bohg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="577" to="584" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Real-time markerless tracking for augmented reality: The virtual visual servoing framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">I</forename><surname>Comport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muriel</forename><surname>Pressigout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Chaumette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="615" to="628" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust 3D tracking with descriptor fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Crivellaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3414" to="3421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Robust 3D pose estimation and efficient 2D region-based segmentation from a 3D shape prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Dambreville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romeil</forename><surname>Sandhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Yezzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><surname>Tannenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="169" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">PoseRBPF: A Rao-Blackwellized particle filter for 6-D object pose tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinke</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arsalan</forename><surname>Mousavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Bretl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1328" to="1342" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simultaneous localization and mapping with active stereo vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Diebel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kjell</forename><surname>Reutersward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakesh</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="3436" to="3443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Real-time visual tracking of complex structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Drummond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="932" to="946" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Robust registration of 2D and 3D point sets. Image and Vision Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">W</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1145" to="1153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Registration of multiple range views for automatic 3-d model building</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>Gagnon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Soucy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bergevin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Laurendeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="581" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">RAPID -A video rate object tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Stennett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference</title>
		<meeting>the British Machine Vision Conference</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="15" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">FFB6D: A full flow bidirectional fusion network for 6D pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqiang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">PVN3D: a deep point-wise 3D keypoints voting network for 6DoF pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianran</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqiang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">2D-3D pose estimation of heterogeneous objects using a region based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Hexner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><forename type="middle">R</forename><surname>Hagege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="112" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Model based training, detection and pose estimation of texture-less 3D objects in heavily cluttered scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Hinterstoisser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Holzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Bradski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Konolige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="548" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bop challenge 2020 on 6d object localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom??</forename><surname>Hoda?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertram</forename><surname>Drost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Labb?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji??</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020 Workshops</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An occlusion-aware edge-based method for monocular 3d object tracking using edge confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueying</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="399" to="409" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Depth-based object tracking using a robust gaussian filter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Issac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>W?thrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristina</forename><forename type="middle">G</forename><surname>Cifuentes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeannette</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Trimpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Schaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="608" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Real-time 3D model tracking in color and depth on a single CPU core</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wadim</forename><surname>Kehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Manipulator and object tracking for in-hand 3D object modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Krainin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1311" to="1327" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">6-DOF model based tracking via object coordinate regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Krull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Ihrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">CosyPose: Consistent multi-view multi-object 6D pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Labb?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Carpentier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aubry</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Monocular Model-Based 3D Tracking of Rigid Objects: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Computer Graphics and Vision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">3D object tracking with adaptively weighted local bundles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Hua</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue-Ying</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">DeepIM: Deep iterative matching for 6D pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="695" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An off-board vision system for relative attitude measurement of aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fulin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhong</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangjun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Target tracking of moving and rotating object by high-speed monocular active vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pansiyu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akio</forename><surname>Namiki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Sensors Journal</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6727" to="6744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application to stereo vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 7th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1981" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="674" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep model-based 6D pose refinement in RGB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Manhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wadim</forename><surname>Kehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="833" to="849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">ORB-SLAM2: An open-source SLAM system for monocular, stereo, and RGB-D cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raul</forename><surname>Mur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Artal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">D</forename><surname>Tard?s</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1255" to="1262" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">KinectFusion: Real-time dense surface mapping and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">A</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahram</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otmar</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Molyneaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Mixed and Augmented Reality</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Feature harvesting for tracking-by-detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Mustafa?zuysal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fleuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<editor>Ale? Leonardis, Horst Bischof, and Axel Pinz</editor>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="592" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Real-time object pose recognition and tracking with an imprecisely calibrated moving rgb-d camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pauwels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Ivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sethu</forename><surname>Vijayakumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2733" to="2740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A review of point cloud registration algorithms for mobile robotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Colas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Siegwart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Robotics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="104" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Real-time 3D tracking and reconstruction on mobile phones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Prisacariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>K?hler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="557" to="570" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">PWP3D: Real-time segmentation and tracking of 3D objects. International Journal of Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">D</forename><surname>Prisacariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="335" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multiview registration for large data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kari</forename><surname>Pulli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second International Conference on 3-D Digital Imaging and Modeling</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="160" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Real-time tracking of single and multiple objects from depth-colour imagery using 3D signed distance functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Carl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">A</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Prisacariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">D</forename><surname>K?hler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="80" to="95" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A unified energy minimization framework for model fitting in depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Carl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2012. Workshops and Demonstrations</title>
		<editor>Andrea Fusiello, Vittorio Murino, and Rita Cucchiara</editor>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="72" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Three-dimensional shape knowledge for joint image segmentation and pose tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Bodo Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="262" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Fusing points and lines for high performance tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Rosten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1508" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">ORB: An efficient alternative to SIFT or SURF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Rublee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Rabaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Konolige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Bradski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2564" to="2571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Efficient variants of the ICP algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Szymon</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Conference on 3-D Digital Imaging and Modeling</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="145" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Region-based pose tracking with occlusions using 3D models. Machine Vision and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Schmaltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Weickert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="557" to="577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Dart: dense articulated real-time tracking with consumer depth cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanner</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autonomous Robots</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="239" to="258" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Optimal local searching for fast and robust textureless 3D object tracking in highly cluttered backgrounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Byung-Kuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanhoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong-Il</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Hinterstoisser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ilic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="110" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A direct method for robust model-based 3D object tracking from a monocular RGB image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><surname>Byung-Kuk Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wuest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision Workshop</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="551" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Scene modelling, recognition and tracking with invariant image features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Skrypnyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third IEEE and ACM International Symposium on Mixed and Augmented Reality</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A sparse gaussian approach to region-based 6DoF object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Stoiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Pfanne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><forename type="middle">H</forename><surname>Strobl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolph</forename><surname>Triebel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alin Albu-</forename><surname>Schaeffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">SRT3D: A sparse regionbased 3D object tracking approach for the real world. International Journal of Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Stoiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Pfanne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><forename type="middle">H</forename><surname>Strobl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolph</forename><surname>Triebel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alin Albu-</forename><surname>Schaeffer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Robust monocular pose tracking of less-distinct objects based on contour-part model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiexin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenlong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifeng</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Implicit 3D orientation learning for 6D object detection from RGB images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Zoltan-Csaba Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Durner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolph</forename><surname>Brucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Triebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Looking beyond the simple scenarios: Combining learners and optimizers in 3D temporal tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A region-based Gauss-Newton approach to real-time monocular multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Henning Tjaden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elmar</forename><surname>Schwanecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sch?mer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Stable realtime 3D tracking using online and offline information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Vacchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1385" to="1391" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">6-PACK: Category-level 6D pose tracker with anchor-based keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Mart?n-Mart?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danfei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="10059" to="10066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">DenseFusion: 6D object pose estimation by iterative dense fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danfei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Mart?n-Mart?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">se(3)-TrackNet: Data-driven 6D pose tracking by calibrating image residuals in synthetic domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Bowen Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baozhang</forename><surname>Mitash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><forename type="middle">E</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bekris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="10367" to="10373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">ElasticFusion: Dense SLAM without a pose graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Whelan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Leutenegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renato</forename><forename type="middle">S</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Probabilistic object tracking using a range camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>W?thrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Pastor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrinal</forename><surname>Kalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeannette</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Schaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="3195" to="3202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A benchmark dataset for 6DoF object pose tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueh-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsuan-I</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shao-Yi</forename><surname>Chien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Mixed and Augmented Reality</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="186" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">PoseCNN: A convolutional neural network for 6D object pose estimation in cluttered scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanner</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatraman</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Object tracking: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alper</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Iterative point matching for registration of free-form curves and surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyou</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="152" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">3D object tracking via boundary constrained region-based model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huai-Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhong</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="486" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A robust monocular 3D object tracking method combining statistical and photometric constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="973" to="992" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Occlusion-aware region-based 3D pose tracking of objects with temporally consistent polar-based local partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunli</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tjaden</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">63</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
