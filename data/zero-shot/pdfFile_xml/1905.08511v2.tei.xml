<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-05-29">29 May 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kosuke</forename><surname>Nishida</surname></persName>
							<email>kosuke.nishida.ap@hco.ntt.co.jp</email>
							<affiliation key="aff0">
								<orgName type="laboratory">NTT Media Intelligence Laboratories</orgName>
								<orgName type="institution">NTT Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyosuke</forename><surname>Nishida</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NTT Media Intelligence Laboratories</orgName>
								<orgName type="institution">NTT Corporation</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">NTT Communication Science Laboratories</orgName>
								<orgName type="institution" key="instit2">NTT Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Otsuka</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NTT Media Intelligence Laboratories</orgName>
								<orgName type="institution">NTT Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itsumi</forename><surname>Saito</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NTT Media Intelligence Laboratories</orgName>
								<orgName type="institution">NTT Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisako</forename><surname>Asano</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NTT Media Intelligence Laboratories</orgName>
								<orgName type="institution">NTT Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junji</forename><surname>Tomita</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NTT Media Intelligence Laboratories</orgName>
								<orgName type="institution">NTT Corporation</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-05-29">29 May 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Question answering (QA) using textual sources for purposes such as reading comprehension (RC) has attracted much attention. This study focuses on the task of explainable multi-hop QA, which requires the system to return the answer with evidence sentences by reasoning and gathering disjoint pieces of the reference texts. It proposes the Query Focused Extractor (QFE) model for evidence extraction and uses multi-task learning with the QA model. QFE is inspired by extractive summarization models; compared with the existing method, which extracts each evidence sentence independently, it sequentially extracts evidence sentences by using an RNN with an attention mechanism on the question sentence. It enables QFE to consider the dependency among the evidence sentences and cover important information in the question sentence. Experimental results show that QFE with a simple RC baseline model achieves a state-of-the-art evidence extraction score on HotpotQA. Although designed for RC, it also achieves a state-of-the-art evidence extraction score on FEVER, which is a recognizing textual entailment task on a large textual database.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Reading comprehension (RC) is a task that uses textual sources to answer any question. It has seen significant progress since the publication of numerous datasets such as SQuAD <ref type="bibr" target="#b23">(Rajpurkar et al., 2016)</ref>. To achieve the goal of RC, systems must be able to reason over disjoint pieces of information in the reference texts. Recently, multi-hop question answering (QA) datasets focusing on this capability, such as QAngaroo  and HotpotQA <ref type="bibr" target="#b37">(Yang et al., 2018)</ref>, have been released.</p><p>Multi-hop QA faces two challenges. The first is the difficulty of reasoning. It is difficult for the Figure 1: Concept of explainable multi-hop QA. Given a question and multiple textual sources, the system extracts evidence sentences from the sources and returns the answer and the evidence. system to find the disjoint pieces of information as evidence and reason using the multiple pieces of such evidence. The second challenge is interpretability. The evidence used to reason is not necessarily located close to the answer, so it is difficult for users to verify the answer. <ref type="bibr" target="#b37">Yang et al. (2018)</ref> released HotpotQA, an explainable multi-hop QA dataset, as shown in <ref type="figure">Figure 1</ref>. Hotpot QA provides the evidence sentences of the answer for supervised learning. The evidence extraction in multi-hop QA is more difficult than that in other QA problems because the question itself may not provide a clue for finding evidence sentences. As shown in <ref type="figure">Figure 1</ref>, the system finds an evidence sentence (Evidence 2) by relying on another evidence sentence (Evidence 1). The capability of being able to explicitly extract evidence is an advance towards meeting the above two challenges.</p><p>Here, we propose a Query Focused Extractor (QFE) that is based on a summarization model. We regard the evidence extraction of the explainable multi-hop QA as a query-focused summarization task. Query-focused summarization is the task of summarizing the source document with regard to the given query. QFE sequentially extracts the evidence sentences by using an RNN with an attention mechanism on the question sentence, while the existing method extracts each evidence sentence independently. This query-aware recurrent structure enables QFE to consider the dependency among the evidence sentences and cover the important information in the question sentence. Our overall model uses multi-task learning with a QA model for answer selection and QFE for evidence extraction. The multi-task learning with QFE is general in the sense that it can be combined with any QA model.</p><p>Moreover, we find that the recognizing textual entailment (RTE) task on a large textual database, FEVER <ref type="bibr" target="#b28">(Thorne et al., 2018)</ref>, can be regarded as an explainable multi-hop QA task. We confirm that QFE effectively extracts the evidence both on HotpotQA for RC and on FEVER for RTE.</p><p>Our main contributions are as follows.</p><p>? We propose QFE for explainable multi-hop QA. We use the multi-task learning of the QA model for answer selection and QFE for evidence extraction.</p><p>? QFE adaptively determines the number of evidence sentences by considering the dependency among the evidence sentences and the coverage of the question.</p><p>? QFE achieves state-of-the-art performance on both HotpotQA and FEVER in terms of the evidence extraction score and comparable performance to competitive models in terms of the answer selection score. QFE is the first model that outperformed the baseline on Hot-potQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definition</head><p>Here, we re-define explainable multi-hop QA so that it includes the RC and the RTE tasks.  exists only if there are not enough answer candidates to answer Q. The answer string A S is a short span in C. Evidence E consists of the sentences in C and is required to answer Q.</p><p>For RC, we tackle HotpotQA. In HotpotQA, the answer candidates are 'Yes', 'No', and 'Span'. The answer string A S exists if and only if the answer type A T is 'Span'. C consists of ten Wikipedia paragraphs. The evidence E consists of two or more sentences in C.</p><p>For RTE, we tackle FEVER. In FEVER, the answer candidates are 'Supports', 'Refutes', and 'Not Enough Info'. The answer string A S does not exist. C is the Wikipedia database. The evidence E consists of the sentences in C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Method</head><p>This section first explains the overall model architecture, which contains our model as a module, and then the details of our QFE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Architecture</head><p>Except for the evidence layer, our model is the same as the baseline <ref type="bibr" target="#b7">(Clark and Gardner, 2018)</ref> used in HotpotQA <ref type="bibr" target="#b37">(Yang et al., 2018)</ref>. <ref type="figure" target="#fig_0">Figure 2</ref> shows the model architecture. The input of the model is the context C and the query Q. The model has the following layers.</p><p>The Word Embedding Layer encodes C and Q as sequences of word vectors. A word vector is the concatenation of a pre-trained word embedding and a character-based embedding obtained using a CNN <ref type="bibr" target="#b13">(Kim, 2014)</ref>. The outputs are C 1 ? R lw?dw , Q 1 ? R mw?dw , where l w is the length (in words) of C, m w is the length of Q and d w is the size of the word vector.</p><p>The Context Layer encodes C 1 , Q 1 as contextual vectors C 2 ? R lw?2dc , Q 2 ? R mw?2dc by using a bi-directional RNN (Bi-RNN), where d c is the output size of a uni-directional RNN.</p><p>The Matching Layer encodes C 2 , Q 2 as matching vectors C 3 ? R lw?dc by using bi-directional attention <ref type="bibr" target="#b26">(Seo et al., 2017)</ref>, a Bi-RNN, and selfattention <ref type="bibr" target="#b33">(Wang et al., 2017)</ref>.</p><formula xml:id="formula_0">The Evidence Layer first encodes C 3 as [ ? ? C 4 ; ? ? C 4 ] ? R lw?2dc</formula><p>by a Bi-RNN. Let j 1 (i) be the index of the first word of the i-th sentence in C and j 2 (i) be the index of the last word. We define the vector of the i-th sentence as:</p><formula xml:id="formula_1">x i = [ ???? c 4,j 2 (i) ; ???? c 4,j 1 (i) ] ? R 2dc .</formula><p>Here, X ? R ls?2dc is the sentence-level context vectors, where l s is the number of sentences of C.</p><p>QFE, described later, receives sentence-level context vectors X ? R ls?2dc and the contextual query vectors Q 2 ? R mw?2dc as Y. QFE outputs the probability distribution that the i-th sentence is the evidence:</p><formula xml:id="formula_2">Pr(i) = QFE(X, Y = Q 2 ).</formula><p>(1)</p><p>Then, the evidence layer concatenates the wordlevel vectors and the sentence-level vectors:</p><formula xml:id="formula_3">c 5,j = [c 3,j ; x i(j) ] ? R 3dc , where the j-th word in C is included in the i(j)-th sentence in C.</formula><p>The Answer Layer predicts the answer type A T and the answer string A S from C 5 . The layer has stacked Bi-RNNs. The output of each Bi-RNN is mapped to the probability distribution by the fully connected layer and the softmax function.</p><p>For RC, the layer has three stacked Bi-RNNs. Each probability indicates the start of the answer string,? S1 ? R lw , the end of the answer strin? A S2 ? R lw , and the answer type,? T ? R 3 . For RTE, the layer has one Bi-RNN. The probability indicates the answer type.</p><formula xml:id="formula_4">??? ? ??? ??? ? ??? ??? Extraction RNN ??? ??? ? ??? ? ??? ??? ? ? ?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Glimpse</head><p>Sentence Vectors Query Vectors <ref type="figure">Figure 3</ref>: Overview of Query Focused Extractor at step t. z t is the current summarization vector. g t is the query vector considering the current summarization. e t is the extracted sentence. x e t updates the RNN state.</p><p>Loss Function: Our model uses multi-task learning with a loss function L = L A + L E , where L A is the loss of the answer and L E is the loss of the evidence. The answer loss L A is the sum of the cross-entropy losses for all probability distributions obtained by the answer layer. The evidence loss L E is defined in subsection 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Focused Extractor</head><p>Query Focused Extractor (QFE) is shown as the red box in <ref type="figure" target="#fig_0">Figure 2</ref>. QFE is an extension of the extractive summarization model of <ref type="bibr" target="#b3">Chen and Bansal (2018)</ref>, which is not for query-focused settings.</p><p>Chen and Bansal used an attention mechanism to extract sentences from the source document such that the summary would cover the important information in the source document. To focus on the query, QFE extracts sentences from C with attention on Q such that the evidence covers the important information with respect to Q. <ref type="figure">Figure 3</ref> shows an overview of QFE. The inputs of QFE are the sentence-level context vectors X ? R ls?2dc and contextual query vectors Y ? R mw?2dc . We define the timestep to be the operation to extract a sentence. QFE updates the state of the RNN (the dark blue box in <ref type="figure">Figure 3</ref>) as follows:</p><formula xml:id="formula_5">z t = RNN(z t?1 , x e t ) ? R 2dc ,</formula><p>where e t ? {1, ? ? ? , l s } is the index of the sentence extracted at step t. We define E t = {e 1 , ? ? ? , e t } to be the set of sentences extracted until step t.</p><p>QFE extracts the i-th sentence according to the probability distribution (the light blue box):</p><formula xml:id="formula_6">Pr(i; E t?1 ) = softmax i (u t i ) u t i = ? ? ? ? ? v ? p tanh(W p1 x i + W p2 g t + W p3 z t ) (i ? E t?1 ) ??<label>(otherwise)</label></formula><p>.</p><p>Then, QFE selects e t = argmax Pr(i; E t?1 ).</p><p>Let g t be a query vector considering the importance at step t. We define g t as the glimpse vector <ref type="bibr" target="#b29">(Vinyals et al., 2016)</ref> (the green box):</p><formula xml:id="formula_7">g t = j ? t j W g1 y j ? R 2dc ? t = softmax(a t ) ? R mw a t j = v ? g tanh(W g1 y j + W g2 z t ).</formula><p>The initial state of the RNN is the vector obtained via the fully connected layer and the max pooling from X. All parameters W ? ? R 2dc?2dc and v ? ? R 2dc are trainable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training Phase</head><p>In the training phase, we use teacher-forcing to make the loss function. The loss of the evidence L E is the negative log likelihood regularized by a coverage mechanism <ref type="bibr" target="#b25">(See et al., 2017)</ref>:</p><formula xml:id="formula_8">L E = ? |E| t=1 log max i?E\E t?1 Pr(i; E t?1 ) + i min(c t i , ? t i ).</formula><p>The max operation in the first term enables the sentence with the highest probability to be extracted. This operation means that QFE extracts the sentences in the predicted importance order.</p><p>On the other hand, the evidence does not have the ground truth order in which it is to be extracted, so the loss function ignores the order of the evidence sentences. The coverage vector c t is defined as c t = t?1 ? =1 ? ? . In order to learn the terminal condition of the extraction, QFE adds a dummy sentence, called the EOE sentence, to the sentence set. When the EOE sentence is extracted, QFE terminates the extraction. The EOE sentence vector x EOE ? R 2dc is a trainable parameter in the model, so x EOE is independent of the samples. We train the model to extract the EOE sentence after all evidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Test Phase</head><p>In the test phase, QFE terminates the extraction by reaching the EOE sentence. The predicted evidence is defined a?</p><formula xml:id="formula_9">E = argmin ? 1 |?| t log max i ?? t?1 Pr(i;? t?1 ) ,</formula><p>where? t is the predicted evidence until step t. QFE uses the beam search algorithm to search?.  In HotpotQA, the query Q is created by crowd workers, on the condition that answering Q requires reasoning over two paragraphs in Wikipedia. The candidates of A T are 'Yes', 'No', and 'Span'. The answer string A S , if it exists, is a span in the two paragraphs. The context C is ten paragraphs, and its content has two settings. In the distractor setting, C consists of the two gold paragraphs used to create Q and eight paragraphs retrieved from Wikipedia by using TF-IDF with Q. <ref type="table" target="#tab_2">Table 1</ref> shows the statistics of the distractor setting. In the fullwiki setting, all ten paragraphs of C are retrieved paragraphs. Hence, C may not include two gold paragraphs, and in that case, A S and E cannot be extracted. Therefore, the oracle model does not achieve 100 % accuracy. Hot-potQA does not provide the training data for the fullwiki setting, and the training data in the fullwiki setting is the same as the distractor setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Setup</head><p>Comparison models Our baseline model is the same as the baseline in <ref type="bibr" target="#b37">Yang et al. (2018)</ref> except as follows. Whereas we use equation <ref type="formula">(1)</ref>, they use</p><formula xml:id="formula_10">Pr(i) = sigmoid(w ? x i + b), where w ? R 2dc , b ? R are trainable parame- ters.</formula><p>The evidence loss L E is the sum of binary cross-entropy functions on whether each of the sentences is evidence or not. In the test phase, the sentences with probabilities higher than a threshold are selected. We set the threshold to 0.4 because it gave the highest F1 score on the development set. The remaining parts of the implementations of our and baseline models are the same. The details are in Appendix A.1.</p><p>We also compared DFGN + BERT <ref type="bibr" target="#b36">(Xiao et al., 2019)</ref>, Cognitive Graph <ref type="bibr" target="#b9">(Ding et al., 2019)</ref>, GRN and BERT Plus, which were unpublished at the submission time (4 March 2019).   Evaluation metrics We evaluated the prediction of A T , A S and E by using the official metrics in HotpotQA. Exact match (EM) and partial match (F1) were used to evaluate both the answer and the evidence. For the answer evaluation, the score was measured by the classification accuracy of A T . Only when A T was 'Span' was the score also measured by the word-level matching of A S . For the evidence, the partial match was evaluated by the sentence ids, so word-level partial matches were not considered. For metrics on both the answer and the evidence, we used Joint EM and Joint F1 <ref type="bibr" target="#b37">(Yang et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Does our model achieve state-of-the-art performance? <ref type="table" target="#tab_4">Table 2</ref> shows that, in the distractor setting, QFE performed the best in terms of the evidence extraction score among all models compared. It also achieved comparable performance in terms of the answer selection score and therefore achieved state-of-the-art performance on the joint EM and F1 metrics, which are the main metric on the dataset. QFE outperformed the baseline model in all metrics. Although our model does not use any pre-trained language model such as  BERT <ref type="bibr" target="#b8">(Devlin et al., 2019)</ref> for encoding, it outperformed the methods that used BERT such as DFGN + BERT and BERT Plus. In particular, the improvement in the evidence EM score was +37.5 points against the baseline and +5.4 points against GRN.</p><p>In the fullwiki setting, <ref type="table" target="#tab_5">Table 3</ref> shows that QFE outperformed the baseline in all metrics. Compared with the unpublished model at the submission time, Cognitive Graph <ref type="bibr" target="#b9">(Ding et al., 2019)</ref> outperformed our model. There is a dataset shift problem <ref type="bibr" target="#b22">(Quionero-Candela et al., 2009)</ref> in Hot-potQA, where the distribution of the number of gold evidence sentences and the answerability differs between training (i.e., the distractor setting) and test (i.e., the fullwiki setting) phases. In the fullwiki setting, the questions may have less than two gold evidence sentences or be even unanswerable. Our current QA and QFE models do not consider solving the dataset shift problem; our future work will deal with it.</p><p>Does QFE contribute to the performance? Table 4 shows the results of the ablation study.</p><p>QFE performed the best among the models compared. Although the difference between our overall model and the baseline is the evidence extraction model, the answer scores also improved. QFE also outperformed the model that used only RNN extraction without glimpse.</p><p>QFE defines the terminal condition as reaching the EOE sentence, which we call adaptive termination. We confirmed that the adaptive termination of QFE contributed to its performance. We compared QFE with a baseline that extracts the two sentences with the highest scores, since the most frequent number of evidence sentences is two. QFE outperformed this baseline.  <ref type="table">Table 5</ref>: Performance of our model and the baseline in evidence extraction on the development set in the distractor setting. The correlation is the Kendall tau correlation of the number of predicted evidence sentences and that of gold evidence. Our model uses the results of evidence extraction as a guide for selecting the answer, but it is not a pipeline model of evidence extraction and answer selection. Therefore, we evaluated a pipeline model that selects the answer string A S only from the extracted evidence sentences, where the outputs of the answer layer corresponding to nonevidence sentences are masked with the prediction of the evidence extraction. Although almost all answer strings in the dataset are in the gold evidence sentences, the model performed poorly. We consider that the evidence extraction helps QA model to learn, but its performance is not enough to improve the performance of the answer layer with the pipeline model.</p><p>What are the characteristics of our evidence extraction? <ref type="table">Table 5</ref> shows the evidence extraction performance in the distractor setting. Our model improves both precision and recall, and the improvement in precision is larger. <ref type="figure" target="#fig_1">Figure 4</ref> reveals the reason for the high EM and precision scores; QFE rarely extracts too much evidence. That is, it predicts the number of evidence sentences more accurately than the baseline. <ref type="table">Table  5</ref> also shows the correlation of our model about the number of evidence sentences is higher than that of the baseline.</p><p>We consider that the sequential extraction and the adaptive termination help to prevent overextraction. In contrast, the baseline evaluates each sentence independently, so the baseline often ex-   tracts too much evidence.</p><p>What questions in HotpotQA are difficult for QFE? We analyzed the difficulty of the questions for QFE from the perspective of the number of evidence sentences and reasoning type; the results are in <ref type="table" target="#tab_10">Table 6 and Table 7</ref>. First, we classified the questions by the number of gold evidence sentences. <ref type="table" target="#tab_10">Table 6</ref> shows the model performance for each number. The answer scores were low for the questions answered with five evidence sentences, which indicated that questions requiring much evidence are difficult. However, the five-evidence questions amount to only 80 samples, so this observation needs to be confirmed with more analysis. QFE performed well when the number of gold evidence sentences was two. Even though QFE was relatively conservative when extracting many evidence sentences, it was able to extract more than two sentences adaptively.</p><p>Second, we should mention the reasoning types in <ref type="table" target="#tab_11">Table 7</ref>. HotpotQA has two reasoning types: entity bridge and entity comparison. Entity bridge means that the question mentioned one entity and the article of this entity has another entity required for the answer. Entity comparison means that the question compares two entities. <ref type="table" target="#tab_11">Table 7</ref> shows that QFE works on each reasoning type. We consider that the difference between the results is due to the characteristics of the dataset. The answer F1 was relatively low in the comparison questions, because all yes/no  questions belong to the comparison question and partial matches do not happen in yes/no questions. The evidence EM was relatively high in the comparison questions. One of the reason is that 77.1 % of the comparison questions have just two evidence sentences. This proportion is larger than that in the bridge questions, 64.9%. From another perspective, the comparison question sentence itself will contain the clues (i.e., two entities) required to gather all evidence sentences, while the bridge question sentence itself will provide only a part of the clues and require multi-hop reasoning, i.e., finding an evidence sentence from another evidence sentence. Therefore, the evidence extraction of the bridge questions is more difficult than that of the comparison questions.</p><p>Qualitative Analysis. <ref type="table" target="#tab_13">Table 8</ref> shows an example of the behavior of QFE. In it, the system must compare the number of members of Kitchens of Distinction and with those of Royal Blood. The system extracted the two sentences describing the number of members. Then, the system extracted the EOE sentence. We should note two sentences that were not extracted. The first sentence includes 'members' and 'Kitchens of Distinction', which are included in the query. However, this sentence does not mention the number of the members of Kitchens of Distinction. The second sentence also shows that Royal Blood is a duo. However, our model preferred Royal Blood (band name) to Royal Blood (album name) as the subject of the sentence.</p><p>Other examples are shown in Appendix A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments on RTE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">FEVER Dataset</head><p>In FEVER, the query Q is created by crowd workers. Annotators are given a randomly sampled sen-  tence and a corresponding dictionary. The given sentence is from Wikipedia. The key-value of the corresponding dictionary consists of an entity and a description of the entity. Entities are those that have a hyperlink from the given sentence. The description is the first sentence of the entity's Wikipedia page. Only using the information in the sentence and the dictionary, annotators create a claim as Q. The candidates of A T are 'Supports', 'Refutes' and 'Not Enough Info (NEI)'. The proportion of samples with more than one evidence sentence is 27.3% in the samples whose label is not 'NEI'. The context C is the Wikipedia database shared among all samples. <ref type="table" target="#tab_15">Table 9</ref> shows the statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Setup</head><p>Because C is large, we used the NSMN document retriever <ref type="bibr" target="#b19">(Nie et al., 2019)</ref> and gave only the topfive paragraphs to our model. Similar to NSMN, in order to capture the semantic and numeric relationships, we used 30-dimensional WordNet features and five-dimensional number embeddings. The WordNet features are binaries reflecting the existence of hypernymy/antonymy words in the input. The number embedding is a real-valued embedding assigned to any unique number. Because the number of samples in the training data is biased on the answer type A T , randomly selected samples were copied in order to equalize the numbers. Our model used ensemble learning of 11 randomly initialized models. For the evidence extraction, we used the union of the predicted evidences of each model. If the model predicts A T as 'Supports' or 'Refutes', the model extracts at least one sentence. Details of the implementation are in Appendix A.1. We evaluated the prediction of A T and the evidence E by using the official metrics in FEVER. A T was evaluated in terms of the label accuracy. E was evaluated in terms of precision, recall and F1, which were measured by sentence id. The FEVER score was used as a metric accounting for both A T and E. The FEVER score of a sample is 1 if the predicted evidence includes all gold evidence and the answer is correct. That is, the FEVER score emphasizes the recall of extracting evidence sentences over the precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>Does our multi-task learning approach achieve state-of-the-art performance? <ref type="table" target="#tab_2">Table 10</ref> shows QFE achieved state-of-the-art performance in terms of the evidence F1 and comparable performance in terms of label accuracy to the competitive models. The FEVER score of our model is lower than those of other models, because the FEVER score emphasizes recall. However, the importance of the precision and the recall depends on the utilization. QFE is suited to situations where concise output is preferred. What are the characteristics of our evidence extraction? <ref type="table" target="#tab_2">Table 11</ref> shows our model achieved high performance on all metrics of evidence extraction. On the test set, it ranked in 2nd place in precision, 3rd place in recall, and 1st place in F1.</p><p>As for the results on the development set, QFE extracted with higher precision than recall. This tendency was the same as in the RC evaluation. The single model has a larger difference between precision and recall. The ensemble model improves recall and F1. Examples are shown in Appendix A.2.</p><p>6 Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Reading Comprehension</head><p>RC is performed by matching the context and the query <ref type="bibr" target="#b26">(Seo et al., 2017)</ref>. Many RC datasets referring to multiple texts have been published, such as MS MARCO <ref type="bibr" target="#b18">(Nguyen et al., 2016)</ref> and TriviaQA <ref type="bibr" target="#b11">(Joshi et al., 2017)</ref>. For such datasets, the document retrieval model is combined with the contextquery matching model <ref type="bibr" target="#b1">(Chen et al., 2017a;</ref><ref type="bibr">Wang et al., 2018a,b;</ref><ref type="bibr" target="#b20">Nishida et al., 2018)</ref>. Some techniques have been proposed for understanding multiple texts. <ref type="bibr" target="#b7">Clark and Gardner (2018)</ref> used simple methods, such as connecting texts. ; <ref type="bibr" target="#b39">Zhong et al. (2019)</ref> proposed a combination of coarse reading and fine reading. However, <ref type="bibr" target="#b27">Sugawara et al. (2018)</ref> indicated that most questions in RC require reasoning from just one sentence including the answer. The proportion of such questions is more than 63.2 % in TriviaQA and 86.2 % in MS MARCO.</p><p>This observation is one of the motivations behind multi-hop QA. HotpotQA <ref type="bibr" target="#b37">(Yang et al., 2018)</ref> is a task including supervised evidence extraction. QAngaroo ) is a task created by using Wikipedia entity links. The difference between QAngaroo and our focus is two-fold: (1) QAngaroo does not have supervised evidence and (2) the questions in QAngaroo are inherently limited because the dataset is constructed using a knowledge base. MultiRC <ref type="bibr" target="#b12">(Khashabi et al., 2018)</ref> is also an explainable multi-hop QA dataset that provides gold evidence sentences. However, it is difficult to compare the performance of the evidence extraction with other studies because its evaluation script and leaderboard do not report the evidence extraction score.</p><p>Because annotation of the evidence sentence is costly, unsupervised learning of the evidence extraction is another important issue. <ref type="bibr" target="#b30">Wang et al. (2019)</ref> tackled unsupervised learning for explainable multi-hop QA, but their model is restricted to the multiple-choice setting. <ref type="bibr" target="#b0">(Bowman et al., 2015;</ref><ref type="bibr" target="#b35">Williams et al., 2018)</ref> is performed by sentence matching <ref type="bibr" target="#b24">(Rockt?schel et al., 2016;</ref><ref type="bibr" target="#b2">Chen et al., 2017b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Recognizing Textual Entailment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RTE</head><p>FEVER <ref type="bibr" target="#b28">(Thorne et al., 2018)</ref> has the aim of verification and fact checking for RTE on a large database. FEVER requires three sub tasks: document retrieval, evidence extraction, and answer prediction. In the previous work, the sub tasks are performed using pipelined models <ref type="bibr" target="#b19">(Nie et al., 2019;</ref><ref type="bibr" target="#b38">Yoneda et al., 2018)</ref>. In contrast, our approach performs evidence extraction and answer prediction simultaneously by regarding FEVER as an explainable multi-hop QA task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Summarization</head><p>A typical approach to sentence-level extractive summarization has an encoder-decoder architecture <ref type="bibr" target="#b4">(Cheng and Lapata, 2016;</ref><ref type="bibr" target="#b16">Nallapati et al., 2017;</ref><ref type="bibr" target="#b17">Narayan et al., 2018)</ref>. Sentence-level extractive summarization is also used for content selection in abstractive summarization <ref type="bibr" target="#b3">(Chen and Bansal, 2018)</ref>. The model extracts sentences in order of importance and edits them. We have extended this model so that it can be used for evidence extraction because we consider that the evidence must be extracted in order of importance rather than the original order, which the conventional models use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We consider that the main contributions of our study are (1) the QFE model that is based on a summarization model for the explainable multihop QA, (2) the dependency among the evidence and the coverage of the question due to the usage of the summarization model, and (3) the state-ofthe-art performance in evidence extraction in both RC and RTE tasks.</p><p>Regarding RC, we confirmed that the architecture with QFE, which is a simple replacement of the baseline, achieved state-of-the-art performance in the task setting. The ablation study showed that the replacement of the evidence extraction model with QFE improves performance. Our adaptive termination contributes to the exact matching and the precision score of the evidence extraction. The difficulty of the questions for QFE depends on the number of the required evidence sentences. This study is the first to base its experimental discussion on HotpotQA.</p><p>Regarding RTE, we confirmed that, compared with competing models, the architecture with QFE has a higher evidence extraction score and comparable label prediction score. This study is the first to show a joint approach for RC and FEVER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Samples of QFE Outputs</head><p>The section describes some examples of QFE outputs. <ref type="table" target="#tab_2">Table 13 shows examples on HotpotQA, and  Table 14</ref> shows examples on FEVER. We should note that QFE does not necessarily extract the sentence with the highest probability score at any step because QFE determines the evidence by using the beam search algorithm.  Three or four correct evidence sentences are extracted in the first and second examples in <ref type="table" target="#tab_2">Table  13</ref>. The third example is a typical mistake of QFE; QFE extracts too few evidence sentences. In the fourth example, QFE extracts too many evidence sentences. The fifth and sixth questions are typical yes/no questions in HotpotQA. However, like other QA models, our model makes mistakes in answering such easy questions.</p><p>One or two evidence sentences are extracted correctly in the first, second, and third examples in <ref type="table" target="#tab_2">Table 14</ref>. In FEVER, most claims requiring two evidence sentences can be verified by either of two correct evidence sentences, like in the second example. However, there are some claims that require both evidence sentences, like the third example. The fourth example is a typical mistake of QFE; QFE extracts too few evidence sentences. In the fifth and sixth example, the answers of the questions are 'Not Enough Info'. QFE unfortunately extracts evidence when the QA model predicts another label.  <ref type="table" target="#tab_2">Table 13</ref>: Outputs of QFE on HotpotQA. The sentences are extracted in the order shown in the predicted column. The extraction scores of the sentences at each step are in the probability column.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Overall model architecture. The answer layer is the version for the RC task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Number of predicted evidence sentences minus the number of gold evidence sentences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics of HotpotQA (the development set in the distractor setting).</figDesc><table><row><cell>4 Experiments on RC</cell></row><row><cell>4.1 HotpotQA Dataset</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>59.0 20.3 64.5 10.8 40.2 BERT Plus 56.0 69.9 42.3 80.6 26.9 58.1 DFGN + BERT 55.2 68.5 49.9 81.1 31.9 58.2 GRN 52.9 66.7 52.4 84.1 31.8 58.5 QFE 53.9 68.1 57.8 84.5 34.6 59.6</figDesc><table><row><cell cols="2">Answer</cell><cell cols="2">Evidence</cell><cell cols="2">Joint</cell></row><row><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell></row><row><cell>Baseline 45.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Performance of the models on the HotpotQA distractor setting leaderboard 1 (4 March 2019). The models except for the baseline were unpublished at the time of submission of this paper. Our model was submitted on 21 November 2018, three months before the other submissions.</figDesc><table><row><cell cols="2">Answer</cell><cell cols="2">Evidence</cell><cell cols="2">Joint</cell></row><row><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell></row><row><cell cols="6">Baseline 24.0 32.9 3.86 37.7 1.85 16.2</cell></row><row><cell cols="6">GRN 27.3 36.5 12.2 48.8 7.40 23.6</cell></row><row><cell cols="6">Cognitive Graph 37.1 48.9 22.8 57.8 12.4 34.9</cell></row><row><cell cols="6">QFE 28.7 38.1 14.2 44.4 8.69 23.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Performance of the models on the HotpotQA fullwiki setting leaderboard 1 (4 March 2019). The models except for the baseline were unpublished at the time of submission of this paper. Our model was submitted on 25 November 2018, three months before the other submissions.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>. (2018) 44.4 58.3 22.0 66.7 11.6 40.9 our implementation 2 52.7 67.3 38.0 78.4 21.9 54.9 + top 2 extraction 52.7 67.3 48.0 77.8 27.6 54.4 QFE 53.7 68.7 58.8 84.7 35.4 60.6 without glimpse 53.1 67.9 58.4 84.3 34.8 59.6</figDesc><table><row><cell cols="2">Answer</cell><cell cols="2">Evidence</cell><cell cols="2">Joint</cell></row><row><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell></row><row><cell cols="2">Yang et alpipeline model 46.9 63.6</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Performance of our models and the baseline models on the development set in the distractor setting.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell cols="6">: Performance of our model in terms of the num-</cell></row><row><cell cols="6">ber of gold evidence sentences on the development set</cell></row><row><cell cols="6">in the distractor setting. # sample, Num, P and R mean</cell></row><row><cell cols="6">the proportion in the dataset, number of predicted evi-</cell></row><row><cell cols="6">dence sentences, precision, and recall, respectively.</cell></row><row><cell cols="2">Answer</cell><cell cols="2">Evidence</cell><cell cols="2">Joint</cell></row><row><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell></row><row><cell cols="6">all 53.7 68.7 58.8 84.7 35.4 60.6</cell></row><row><cell cols="6">comparison 54.1 60.7 71.2 88.8 42.0 55.6</cell></row><row><cell cols="6">bridge 53.6 70.7 55.7 83.7 33.8 61.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table /><note>Performance of our model for each reasoning type on the development set in the distractor setting.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Which band has more members, Kitchens of Distinction or Royal Blood? A T =? T : Kitchens of Distinction Kitchens of Distinction ... are an English three-person alternative rock band ... 2 0.2 ? 81.4 Royal Blood are an English rock duo formed in Brighton in 2013. 3 0.0 ? 0.0 ? 52.3 EOE sentence -2.9 ? 16.8 ? 31.9 In September 2012, ... members ... as Kitchens of Distinction.</figDesc><table><row><cell cols="2">gold predicted probability[%]</cell><cell>text</cell></row><row><cell>1</cell><cell>96.9</cell><cell></cell></row><row><cell>-</cell><cell>0.0 ? 0.0 ? 0.0</cell><cell>Royal Blood is the eponymous debut studio album by British rock duo Royal Blood.</cell></row></table><note>Q:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc>Outputs of QFE. The sentences are extracted in the order shown in the predicted column. The extraction scores of the sentences at each step are in the probability column.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table /><note>Statistics of FEVER (the development set).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 12 :</head><label>12</label><figDesc>Hyper Parameters.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head></head><label></label><figDesc>What plant has about 40 species native to Asia , Manglietia or Abronia? A T : Manglietia,? T : Manglietia gold predicted probability[%] text 1 85.4 Abronia ... is a genus of about 20 species of .... 2 14.6 ? 54.5 Manglietia is a genus of flowering plants in the family Magnoliaceae. 3 0.0 ? 45.1 ? 61.4 There are about 40 species native to Asia. 4 0.0 ? 0.0 ? 37.2 ? 99.2 EOE sentence Q:Ricky Martin's concert tour in 1999 featured an American heavy metal band formed in what year? A ? 0.0 ? 20.8 Robert Rihmeek Williams ... known by his stage name, Meek Mill, .... Q: Which comic series involves characters such as Nick Fury and Baron von Strucker? A T : Marvel,? T : Sgt. Andrea von Strucker ... characters appearing in American comic books published by Marvel Comics. 2 1.7 ? 41.6 It is the first series to feature Nick Fury Jr. as its main character. Nick Fury: ... the Marvel Comics character Nick Fury. Q: Are both "Cooking Light" and "Vibe" magazines? A T : yes,? T : yes</figDesc><table><row><cell cols="2">:1991,? T : 1991</cell><cell></cell></row><row><cell cols="2">gold predicted probability[%]</cell><cell>text</cell></row><row><cell>1</cell><cell>100.0</cell><cell>Formed on October 12, 1991, the group was founded by vocal-ist/guitarist Robb Flynn and bassist Adam Duce.</cell></row><row><cell>2</cell><cell>0.0 ? 98.8</cell><cell>Other bands that were featured included Machine Head, Slip-knot, and Amen.</cell></row><row><cell>3</cell><cell>0.0 ? 0.0 ? 97.7</cell><cell>Machine Head is an American heavy metal band from Oakland, California.</cell></row><row><cell>4</cell><cell>0.0 ? 1.1 ? 1.4 ? 97.3</cell><cell>Livin La Vida Loco ... by Ricky Martin, was a concert tour in 1999.</cell></row><row><cell>5</cell><cell cols="2">0.0 ? 0.0 ? 0.9 ? 2.0 ? 97.0 EOE sentence</cell></row><row><cell cols="2">Q: Where is the singer of "B Boy" raised?</cell><cell></cell></row><row><cell cols="2">A T : Philadelphia,? T : Philadelphia</cell><cell></cell></row><row><cell cols="2">gold predicted probability[%]</cell><cell>text</cell></row><row><cell>1</cell><cell>100.0</cell><cell>Raised in Philadelphia, he embarked ....</cell></row><row><cell>2</cell><cell>0.0 ? 100.0</cell><cell>"B Boy" is a song by American hip hop recording artist Meek Mill.</cell></row><row><cell>3</cell><cell>0.0 ? 0.0 ? 79.0</cell><cell>EOE sentence</cell></row><row><cell>-</cell><cell>0.0 Fury</cell><cell></cell></row><row><cell cols="2">gold predicted probability[%]</cell><cell>text</cell></row><row><cell>1</cell><cell>70.7</cell><cell></cell></row><row><cell>3</cell><cell>17.3 ? 38.2 ? 31.6</cell><cell>Nick Fury is a 2017 ongoing comic book series published by Marvel Comics.</cell></row><row><cell>4</cell><cell>0.0 ? 0.0 ? 41.6 ? 92.0</cell><cell>EOE sentence</cell></row><row><cell>-</cell><cell>0.0 ? 0.0 ? 0.0 ? 0.0</cell><cell></cell></row><row><cell cols="2">gold predicted probability[%]</cell><cell>text</cell></row><row><cell>1</cell><cell>89.0</cell><cell>Cooking Light is an American monthly food and lifestyle mag-azine founded in 1987.</cell></row><row><cell>2</cell><cell>11.0 ? 97.4</cell><cell>Vibe is an American music and entertainment magazine founded by producer Quincy Jones.</cell></row><row><cell>3</cell><cell>0.0 ? 0.0 ? 95.4</cell><cell>EOE sentence</cell></row><row><cell cols="3">Q: Are Robert Philibosian and David Ignatius both politicians?</cell></row><row><cell cols="2">A T : no,? T : yes</cell><cell></cell></row><row><cell cols="2">gold predicted probability[%]</cell><cell>text</cell></row><row><cell>1</cell><cell>100.0</cell><cell>Robert Harry Philibosian (born 1940) is an American politi-cian.</cell></row><row><cell>2</cell><cell>0.0 ? 98.7</cell><cell>David R. Ignatius (May 26, 1950), is an American journalist and novelist.</cell></row><row><cell>3</cell><cell>0.0 ? 0.0 ? 97.4</cell><cell>EOE sentence</cell></row></table><note>Q:T</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://hotpotqa.github.io/ 2 The differences in score among the original and our implementations of<ref type="bibr" target="#b37">Yang et al. (2018)</ref> are due to the hyper parameters. The main change is increasing dc from 50 to 150.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Supplemental Material</head><p>A.1 Details of the Implementation We implemented our model in PyTorch and trained it on four Nvidia Tesla P100 GPUs. The RNN was a gated recurrent unit (GRU) <ref type="bibr" target="#b5">(Cho et al., 2014)</ref>. The optimizer was Adam (Kingma and Ba, 2014). The word-based word embeddings were fixed GloVe 300-dimensional vectors <ref type="bibr" target="#b21">(Pennington et al., 2014)</ref>. The character-based word embeddings were obtained using trainable eightdimensional character embeddings and a 100dimensional CNN and max pooling. <ref type="table">Table 12</ref> shows other hyper parameters.</p><p>In FEVER, if the model predicts A T as 'Supports' or 'Refutes', the model extracts at least one sentence by removing the EOE sentence from the candidates to be extracted at t = 1.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to Answer Open-Domain Questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Enhanced LSTM for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1657" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast abstractive summarization with reinforce-selected sentence rewriting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="675" to="686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural summarization by extracting sentences and words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianpeng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="484" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Illia Polosukhin, Alexandre Lacoste, and Jonathan Berant</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hewlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="209" to="220" />
		</imprint>
	</monogr>
	<note>Coarse-to-fine question answering for long documents</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="845" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding. NAACL-HLT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cognitive graph for multi-hop reading comprehension at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ukp-athene: Multi-sentence textual entailment for claim verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Hanselowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zile</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniil</forename><surname>Sorokin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Schiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FEVER@EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="103" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Looking beyond the surface: A challenge set for reading comprehension over multiple sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="252" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Team papelo: Transformer networks at fever</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Malon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FEVER@EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="109" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Summarunner: A recurrent neural network based sequence model for extractive summarization of documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifei</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3075" to="3081" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ranking sentences for extractive summarization with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1747" to="1759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">MS MARCO: A human generated machine reading comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoCo@NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Combining fact extraction and verification with neural semantic matching networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haonan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Retrieve-and-Read: Multi-task Learning of Information Retrieval and Reading Comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyosuke</forename><surname>Nishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itsumi</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Otsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisako</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junji</forename><surname>Tomita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="647" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Dataset Shift in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joaquin</forename><surname>Quionero-Candela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Schwaighofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Reasoning about entailment with neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom??</forename><surname>Ko?isk?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Get to the point: Summarization with pointer-generator networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1073" to="1083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">What makes reading comprehension questions easier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saku</forename><surname>Sugawara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akiko</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4208" to="4219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The fact extraction and verification (FEVER) shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oana</forename><surname>Cocarascu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpit</forename><surname>Mittal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FEVER@EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Order matters: Sequence to sequence for sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjunath</forename><surname>Kudlur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Evidence sentence extraction for machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcallester</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.08852</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">R3: Reinforced reader-ranker for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5981" to="5988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evidence aggregation for answer re-ranking in open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Gated self-matching networks for reading comprehension and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="189" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Constructing datasets for multi-hop reading comprehension across documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="287" to="302" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1112" to="1122" />
		</imprint>
	</monogr>
	<note>Bowman</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dynamically fused graph network for multi-hop reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunxuan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanru</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">HotpotQA: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">UCL Machine Reading Group: Four factor framework for fact finding (HexaF)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuma</forename><surname>Yoneda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FEVER@EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Coarse-grain fine-grain coattention network for multi-evidence question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
