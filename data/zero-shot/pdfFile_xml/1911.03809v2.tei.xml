<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Meta Label Correction for Noisy Label Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqing</forename><surname>Zheng</surname></persName>
							<email>zheng@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">Hassan</forename><surname>Awadallah</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Dumais</surname></persName>
							<email>sdumais@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Meta Label Correction for Noisy Label Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T17:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Leveraging weak or noisy supervision for building effective machine learning models has long been an important research problem. Its importance has further increased recently due to the growing need for large-scale datasets to train deep learning models. Weak or noisy supervision could originate from multiple sources including non-expert annotators or automatic labeling based on heuristics or user interaction signals. There is an extensive amount of previous work focusing on leveraging noisy labels. Most notably, recent work has shown impressive gains by using a meta-learned instance re-weighting approach where a meta-learning framework is used to assign instance weights to noisy labels. In this paper, we extend this approach via posing the problem as a label correction problem within a meta-learning framework. We view the label correction procedure as a meta-process and propose a new meta-learning based framework termed MLC (Meta Label Correction) for learning with noisy labels. Specifically, a label correction network is adopted as a meta-model to produce corrected labels for noisy labels while the main model is trained to leverage the corrected labels. Both models are jointly trained by solving a bi-level optimization problem. We run extensive experiments with different label noise levels and types on both image recognition and text classification tasks. We compare the re-weighing and correction approaches showing that the correction framing addresses some of the limitations of re-weighting. We also show that the proposed MLC approach outperforms previous methods in both image and language tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Recent advances in deep learning have enabled impressive performance on various tasks, including image recognition ) and natural language processing <ref type="bibr" target="#b3">(Devlin et al. 2018)</ref>. At the core of this success lies the availability of large amounts of annotated data. However, such datasets are not readily available at scale for many tasks. Learning with weak supervision aims to address this challenge by leveraging weak evidences of supervision. Weak supervision can come in several forms including: incomplete supervision; where only a small subset of the training data has labels, inexact supervision; where only coarse-grained annotations are available, and inaccurate supervision; where noisy labels Copyright ? 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.  <ref type="figure">Figure 1</ref>: Illustration of label reweighting vs label correction. The first image is a truck and the given noisy label is truck, where MW-Net (A label reweighting method) and MLC successfully recover it. However, for the second image whose true label is dog and the given noisy label is automobile, MW-Net is unable to down-weight the incorrect label while MLC correctly adjusts its label by predicting the maximum weight on the class dog than all other classes. So is the case for the airplane with noisy label frog.</p><p>are given <ref type="bibr" target="#b44">(Zhou 2017)</ref>. In this work, we focus on using inaccurate (noisy) labels as a form of weak supervision. Noisy labels may originate from multiple sources including: corrupted labels, non-expert annotators, automatic labels based on heuristics or user interaction signals, etc. Training deep networks with noisy labels is challenging since they are prone to fitting and memorizing the noise <ref type="bibr" target="#b42">(Zhang et al. 2017</ref>) given their high model capacity. As such, multiple lines of work have been proposed recently to effectively combine clean (or gold) labeled data with noisy (or weak) supervision data for more effective learning. One line of work focused on selecting samples from the noisy data that are likely to be correct using co-teaching or curriculum learning <ref type="bibr" target="#b12">(Jiang et al. 2017;</ref><ref type="bibr" target="#b9">Han et al. 2018b)</ref>. Another line of work tries to re-weight the weak instances for selective training <ref type="bibr" target="#b30">(Ren et al. 2018;</ref><ref type="bibr" target="#b31">Shu et al. 2019)</ref>, instead of either including or excluding them. Some of these approaches use a meta-learning framework to assign importance scores to each sample in the noisy training set such that the ones with higher weights can contribute more to the main model training <ref type="bibr" target="#b30">(Ren et al. 2018;</ref><ref type="bibr" target="#b31">Shu et al. 2019)</ref>.</p><p>One of the limitations of label re-weighting is that it is limited to up or down weighting the contribution of an instance in the learning process. An alternative approach relies on the idea of label correction. It aims to correct the noisy labels based on certain assumptions about the weak label generation process. In a sense, label correction aims to go beyond selecting or assigning high weights to useful examples to also altering the assigned labels of incorrectly labeled examples. However, previous methods of label correction rely on assumptions about the weak label generation process and thus often involves two independent steps: (1) estimating a label corruption matrix <ref type="bibr" target="#b11">(Hendrycks et al. 2018</ref>), (2) training a model on the noisy data leveraging the corruption matrix. Estimating the corruption matrix often involves assumptions about the noise generation process, such as assuming that the noisy label is only dependent on the true label and is independent of the data itself <ref type="bibr" target="#b11">(Hendrycks et al. 2018)</ref>.</p><p>In this paper, we adopt label correction to address the problem of learning with noisy labels, from a meta-learning perspective. We term our method meta label correction (MLC). Specifically, we view the label correction procedure as a meta-process, which objective is to provide corrected labels for the examples with noisy labels. Meanwhile, the main predictive model is trained with such corrected labels generated by the meta-model. Both the meta-model and the main model are learned concurrently via a bi-level optimization procedure. This allows the model to maximize the performance on the clean data set (i.e., the clean labels serve as a validation set w.r.t. the noisy set) by updating the label correction process in a differentiable manner. MLC extends work on re-weighting and correction leveraging the advantages of both approaches. In contrast to meta-learning based instance re-weighting, which only considers up or down weighting the given noisy label, MLC provides a more refined way of leveraging noisy labels by exploring all possible classes in the label space. In contrast to previous label correction methods, MLC doesn't make assumptions about the underlying label noises and concurrently learns a correction model with the main model. <ref type="figure">Figure 1</ref> shows examples where label reweighting could at best down-weight noisy samples, reducing their impact on the learning process. On the other hand, MLC can successfully correct the noisy labels to the true ones.</p><p>Meta learning has been successfully used for many applications including hyper-parameter tuning <ref type="bibr" target="#b19">(Maclaurin, Duvenaud, and Adams 2015)</ref>, optimizer learning <ref type="bibr" target="#b28">(Ravi and Larochelle 2017)</ref>, model selection <ref type="bibr" target="#b25">(Pedregosa 2016)</ref>, adaptation to new tasks <ref type="bibr" target="#b5">(Finn, Abbeel, and Levine 2017)</ref> and neural architecture search <ref type="bibr" target="#b18">(Liu, Simonyan, and Yang 2019)</ref>. This work leverages meta-learning for label correction to learn from noisy labels and makes the following contributions:</p><p>? We pose the problem of learning from weak (noisy) supervision as a meta label correction where a correction network is trained as a meta process to provide reliable labels for the main models to learn;</p><p>? We compare and contrast re-weighting and correction as two strategies for handling noisy labeled data;</p><p>? We conduct experiments on a combination of 3 image recognition and 4 large-scale text classification tasks with varying noise levels and types, including real-world noisy labels. We show that the proposed method outperform previous best methods on label correction and re-weighting, demonstrating the power of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Labeled data largely determines whether a machine learning system can perform well on a task or not, as noisy label or corrupted labels could cause dramatic performance drop <ref type="bibr" target="#b22">(Nettleton, Orriols-Puig, and Fornells 2010)</ref>. The problem gets even worse when an adversarial rival intentionally injects noises into the labels <ref type="bibr" target="#b29">(Reed et al. 2014)</ref>. Thus, understanding, modeling, correcting, and learning with noisy labels has been of interest at large in the research communities <ref type="bibr" target="#b21">(Natarajan et al. 2013;</ref><ref type="bibr" target="#b6">Fr?nay and Verleysen 2013)</ref>. Several approaches <ref type="bibr" target="#b20">(Mnih and Hinton 2012;</ref><ref type="bibr" target="#b24">Patrini et al. 2017;</ref><ref type="bibr" target="#b32">Sukhbaatar et al. 2014;</ref><ref type="bibr" target="#b15">Larsen et al. 1998</ref>) have attempted to address the weak labels by modifying the model's architecture or by implementing a loss correction. <ref type="bibr" target="#b32">(Sukhbaatar et al. 2014</ref>) introduced a stochastic variant to estimate label corruption, however the method has to have access to the true labels, rendering it inapplicable when no true labels are present. A forward loss correction adds a linear layer to the end of the model and the loss is adjusted accordingly to incorporate learning about the label noise. <ref type="bibr" target="#b24">(Patrini et al. 2017)</ref> also make use of the forward loss correction mechanism, and propose an estimate of the label corruption estimation matrix which relies on strong assumptions, and does not make use of clean labels that might be available for a portion of the data set. Similar idea is also explored in <ref type="bibr" target="#b7">(Goldberger and Ben-Reuven 2017)</ref>. In this paper, we limit our attention to the setting where in addition to a large amount of weakly labeled data, there is also a small set of clean data available. Under this setup, two major lines of work have been proposed to solve learning problem with noisy labels and we briefly review them here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning with Label Correction</head><p>The first line of work aims to correct the weak labels as much as possible by imposing assumptions of how the noisy labels are generated from its underlying true labels. Consider the problem of classifying the data into k categories, label correction involves estimating a label corruption matrix C k?k whose entry C ij denotes the probability of observing noisy label for class i while the underlying true class label is actually j <ref type="bibr" target="#b8">(Han et al. 2018a;</ref><ref type="bibr" target="#b40">Yao et al. 2020;</ref><ref type="bibr" target="#b36">Xia et al. 2019)</ref>. For example, gold loss correction <ref type="bibr" target="#b11">(Hendrycks et al. 2018</ref>) falls into this category; a key drawback of this line of work is that the label corruption matrix is estimated in an adhoc way and also that the estimation process is separate from the main model process, hence allowing no feedback from the main model to the estimation process. In addition, the estimated label corruption matrices are global, thus ignoring data dependent noises, a setting prevalent in real world label noises <ref type="bibr" target="#b35">(Xia et al. 2020</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning to Re-weight Training Instances</head><p>Knowing that not all training examples are equally important and useful for building a main model given the noise, another line of work for learning with weak supervision focuses on selecting a subset of samples from the noisy data that are likely to be correct <ref type="bibr" target="#b12">(Jiang et al. 2017;</ref><ref type="bibr" target="#b9">Han et al. 2018b;</ref><ref type="bibr" target="#b41">Yu et al. 2019;</ref><ref type="bibr" target="#b4">Fang et al. 2020)</ref>. Instead of discarding examples, an extension of this idea focused on assigning learnable weights to each example in the training noisy set. The goal is to assign a weight for each training example, indicating how useful the example is, such that the main model could use these weights to improve performance on a separate validation set (the clean set) <ref type="bibr" target="#b30">(Ren et al. 2018;</ref><ref type="bibr" target="#b31">Shu et al. 2019)</ref>. The example weights are essentially hyper-parameters for the main model and can be learned by formulating a bi-level optimization problem. This framework allows the example weights learning and the main model to communicate with each other and a better model could be learned.</p><p>Our work follows the learning to correct framework by learning to model and correct the label noise in the noisy examples. Instead of separately handling the label correction and model learning steps, we propose a meta-learning approach to co-optimize for the two steps. We show that our model can outperform state-of-the-art methods for both learning to correct and learning to re-weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meta Label Correction</head><p>Following <ref type="bibr" target="#b0">(Charikar, Steinhardt, and Valiant 2017;</ref><ref type="bibr" target="#b34">Veit et al. 2017;</ref><ref type="bibr" target="#b17">Li et al. 2017;</ref><ref type="bibr" target="#b37">Xiao et al. 2015;</ref><ref type="bibr" target="#b30">Ren et al. 2018)</ref>, we assume that the setup of learning with noisy labels involves two sets of data: a small set of data with clean/trusted labels and a large set of data with noisy/weak labels. Typically the clean set is much smaller compared to the noisy set, due to scarcity of expert labels and high labeling costs. Training directly on the small clean set often tends to be sub-optimal, as too little data can easily cause over-fitting. Training directly on the noisy set (or a combination of the noisy and clean sets) also tends to be sub-optimal, as large high-capacity models can fit and memorize the noise <ref type="bibr" target="#b42">(Zhang et al. 2017)</ref>. Note that unlike some of the work in this area, e.g., <ref type="bibr" target="#b34">(Veit et al. 2017</ref>), we do not require having trusted and noisy labels for the same instances.</p><p>One advantage of the label correction approach is that it allows us to combine clean labels and corrected noisy labels in the learning process. Our proposed approach adopts the label correction methodology while also co-optimizing the label correction process together with the main model process through a unified meta-learning framework. We achieve that by training a meta learner (meta model) that tries to correct the noisy labels and a main model that tries to build the best predictive model with corrected labels coming from the meta model, allowing the meta model and main model to reinforce each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Meta-learning Method for Label Correction</head><p>We describe the framework in detail as follows. Given a set of clean data examples D = {x, y} m and a set of weak (noisy) data examples D = {x, y } M with m much smaller than M . ? &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 u p j 4 G 4 K 7 n A s F Y 4 r u d w W 5 d Z l w U A = " &gt; A A A B 6 3 i c b V B N S 8 N A E N 3 4 W e t X 1 a O X x S J 4 K k k t 6 L H g x W M F + w F t K J v t p F 2 6 m 4 T d i V B C / 4 I X D 4 p 4 9 Q 9 5 8 9 + 4 a X P Q 1 g c D j / d m m J k X J F I Y d N 1 v Z 2 N z a 3 t n t 7 R X 3 j 8 4 P D q u n J x 2 T J x q D m 0 e y 1 j 3 A m Z A i g j a K F B C L 9 H   </p><formula xml:id="formula_0">A V C C h G 0 z v c r / 7 B N q I O H r E W Q K + Y u N I h I I z z K U B I B t W q m 7 N X Y C u E 6 8 g V V K g N a x 8 D U Y x T x V E y C U z p u + 5 C f o Z 0 y i 4 h H l 5 k B p I G J + y M f Q t j Z g C 4 2 e L W + f 0 0 i o j G s b a V o R 0 o f 6 e y J g y Z q Y C 2 6 k Y T s y q l 4 v / e f 0 U w 1 s / E 1 G S I k R 8 u S h M J c W Y 5 o / T k d D A U c 4 s Y V w L e y v l E 6 Y Z R x t P 2 Y b</formula><formula xml:id="formula_1">i J O E + x E d K h E K R t F K D 5 e k X y q 7 F X c O s k q 8 n J Q h R 6 N f + u o N Y p Z G X C G T 1 J i u 5 y b o Z 1 S j Y J J P i 7 3 U 8 I S y M R 3 y r q W K R t z 4 2 f z S K T m 3 y o C E s b a l k M z V 3 x M Z j Y y Z R I H t j C i O z L I 3 E / / z u i m G N 3 4 m V J I i V 2 y x K E w l w Z j M 3 i Y D o T l D O b G E M i 3 s r Y S N q K Y M b T h F G 4 K 3 / P I q a V U</formula><formula xml:id="formula_2">Q = " &gt; A A A B 6 H i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e z G g F 6 E g B e P C Z g H J E u Y n f Q m Y 2 Z n l 5 l Z I Y R 8 g R c P i n j 1 k 7 z 5 N 0 6 S P W h i Q U N R 1 U 1 3 V 5 A I r o 3 r f j u 5 j c 2 t 7 Z 3 8 b m F v / + D w q H h 8 0 t J x q h g 2 W S x i 1 Q m o R s E l N g 0 3 A j u J Q h o F A t v B + G 7 u t 5 9 Q a R 7 L B z N J 0 I / o U P K Q M 2 q s 1 L j t F 0 t u 2 V 2 A r B M v I y X I U O 8 X v 3 q D m K U R S s M E 1 b r r u Y n x p 1 Q Z z g T O C r 1 U Y 0 L Z m A 6 x a 6 m k E W p / u j h 0 R i 6 s M i B h r G x J Q x b q 7 4 k p j b S e R I H t j K g Z 6 V V v L v 7 n d V M T 3 v h T L p P U o G T L R W E q i I n J / G s y 4 A q Z E R N L K F P c 3 k r Y i C r K j M 2 m Y E P w V l 9 e J 6 1 K 2 b s q V x r V U q 2 a x Z G H M z i H S / D g G m p w D 3 V o A g O E Z 3 i F N + f R e X H</formula><formula xml:id="formula_3">g i P Y M F R h R 1 c 8 W y e f O p V G G T h h L 8 4 R 2 F u r v j Q w j p W Z R Y C b z h G r V y 8 X / v F 6 q w 9 t + x k S S a i r I 8 l C Y c k f H T l 6 D M 2 S S E s 1 n h i C R z G R 1 y B g l E m 3 K K p s S v N U v r 5 N 2 r e p d V 2 s P 9 U q j X t R R g n O 4 g C v w 4 A Y a c A 9 N a A G B K T z D K 7 x Z m f V i v V</formula><p>s f y 9 E N q 9 g 5 g z + w P n 8 A / J C T 2 A = = &lt; / l a t e x i t &gt; ? &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 3 u i n 2 G R 4 c 1 w N s W l p W L G O n U 0 X   </p><formula xml:id="formula_4">8 R 8 = " &gt; A A A B + H i c b V D L S s N A F L 3 x W e u j U Z d u g k V w V Z J a 0 G X B j c s K 9 g F N K T f T S T t 0 M g k z E 6 G G f o k b F 4 q 4 9 V P c + T d O 2 i y 0 9 c D A 4 Z x 7 u W d O k H C m t O t + W x u b W 9 s 7 u 6 W 9 8 v 7 B 4 V H F P j 7 p q D i V h L Z J z G P Z C 1 B R z g R t a 6 Y 5 7 S W S Y h R w 2 g 2 m t 7 n f f a R S s V g 8 6 F l C B x G O B Q s Z Q W 2 k o V 3 x I 9 S T I M x 8 5 M k E 5 0 O 7 6 t b c B Z x 1 4 h W k C g V a Q / v L H 8 U k j a j Q h K N S f c 9 N 9 C B D q R n h d F 7 2 U 0 U T J F M c 0 7 6 h A i O q B t k i + N y 5 M M r I C W N p n t D O Q v 2 9 k W G k 1 C w K z G Q e U 6 1 6 u f i f 1 0 9 1 e D P I m E h S T Q V Z H g p T 7 u j Y y V t w R k x S o v n M E C S S m a w O m a B E o k 1 X Z V O C t / r l d d K p 1 7 y r W v 2 + U W 0 2 i j p K c A b n c A k e X E M T 7 q A F b S C Q w j O 8 w p v 1 Z L 1 Y 7 9 b H c n T D K n Z O 4 Q + s z x 8 q D p N f &lt; / l a t e x i t &gt; w &lt; l a</formula><formula xml:id="formula_5">W A S W N F t G C t q M g L y h O i 2 4 k = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h X k p S B T 0 W v H i s a G u h D W W z 3 b R L N 5 u w O x F K 6 E / w 4 k E R r / 4 i b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k Q K g 6 7 7 7 R T W 1 j c 2 t 4 r b p Z 3 d v f 2 D 8 u F R 2 8 S p Z r z F Y h n r T k A N l 0 L x F g q U v J N o T q N A 8 s d g f D P z H 5 + 4 N i J W D z h J u B / R o R K h Y B S t d F 8 N z v v l i l t z 5 y C r x M t J B X I 0 + + W v 3 i B m a c Q V M k m N 6 X p u g n 5 G N Q o m + b T U S w 1 P K B v T I</formula><formula xml:id="formula_6">p U E K z Y W A N g Q f W u F h 6 C A K x 0 c E U d g j N / 8 i K 0 q h X n v F K 9 q Z X q t T y O A j p E x 6 i M H H S B 6 u g a N V A T Y f S A n t A L e j U e j W f j z X i f t S 4 Z + c w B + i P j 4 x u Z 0 5 i W &lt; / l a t e x i t &gt; h(x i ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e w w S V 0 P 3 A s o d Y a f w Y 9 c F d x n M K T w = " &gt; A A A B + H i c b V D L S s N A F L 2 p r 1 o f j b p 0 M 1 i E u i l J L e i y 4 M Z l B f u A N o T J d N I O n U z C z E S s o V / i x o U i b v 0 U d / 6 N 0 z Y L b T 0 w c D j n X u 6 Z E y S c K e 0 4 3 1 Z h Y 3 N r e 6 e 4 W 9 r b P z g s 2 0 f H H R W n k t A 2 i X k s e w F W l D N B 2 5 p p T n u J p D g K O O 0 G k 5 u 5 3 3 2 g U r F Y 3 O t p Q r 0 I j w Q L G c H a S L 5 d H l c H E d b j I M w e Z z 6 7 8 O 2 K U 3 M W Q O v E z U k F c r R 8 + 2 s w j E k a U a E J x 0 r 1 X S f R X o a l Z o T T W W m Q K p p g M s E j 2 j d U 4 I g q L 1 s E n 6 F z o w x R G E v z h E Y L 9 f d G h i O l p l F g J u c h 1 a o 3 F / / z + q k O r 7 2 M i S T V V J D l o T D l S M d o 3 g I a M k m J 5 l N D M J H M Z E V k j C U m 2 n R V M i W 4 q 1 9 e J 5 1 6 z b 2 s 1 e 8 a l W Y j r 6 M I p 3 A G V X D h C p p w C y 1 o A 4 E U n u E V 3 q w n 6 8 V 6 t z 6 W o w U r 3 z m B P 7 A + f w C I Q Z L 2 &lt; / l a t e x i t &gt; y 0 i &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w 7 v W w S m C b u H s b c J v y s o T j H + Q l F g = " &gt; A A A B 9 H i c b V D L S s N A F L 2 p r 1 p f U Z d u B o v o q i S 1 o M u C G 5 c V 7 A P a U C b T S T t 0 M o k z k 0 I I / Q 4 3 L h R x 6 8 e 4 8 2 + c t F l o 6 4 G B w z n 3 c s 8 c P + Z M a c f 5 t k o b m 1 v b O + X d y t 7 + w e G R f X z S U V E i C W 2 T i E e y 5 2 N F O R O 0 r Z n m t B d L i k O f 0 6 4 / v c v 9 7 o x K x S L x q N O Y e i E e C x Y w g r W R v E G I 9 c Q P s n R + O W R D u + r U n A X Q O n E L U o U C r a H 9 N R h F J A m p 0 I R j p f q u E 2 s v w 1 I z w u m 8 M k g U j T G Z 4 j H t G y p w S J W X L U L P 0 Y V R R i i I p H l C o 4 X 6 e y P D o V J p 6 J v J P K R a 9 X L x P 6 + f 6 O D W y 5 i I E 0 0 F W R 4 K E o 5 0 h P I G 0 I h J S j R P D c F E M p M V k Q m W m G j T U 8 W U 4 K 5 + e Z 1 0 6 j X 3 u l Z / a F S b j a K O M p z B O V y B C z f Q h H t o Q R s I P M E z v M K b N b N e r H f</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>m o l h T Q Z a H / J g j H a K s A j R h k h L N E 0 M w k c x k R W S G J S b a F F U x J T i r X 1 4 n 3 U b d u a o 3 7 p u 1 V r O o o w x n c A 6 X 4 M A 1 t O A O 2 t A B A h K e 4 R X e r C f r x X q 3 P p a j J a v Y O Y U / s D 5 / A P b G k s Q = &lt; / l a t e x i t &gt;</head><p>x i &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 3 S g 2 b j K r F L q 7 J e S + Z z g 9   </p><formula xml:id="formula_7">v J X S N A c = " &gt; A A A B 8 3 i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i S 1 o M u C G 5 c V 7 A O a U C b T S T t 0 M g n z E E v o b 7 h x o Y h b f 8 a d f + O k z U J b D w w c z r m X e + a E K W d K u + 6 3 U</formula><formula xml:id="formula_8">I x w O q / 4 R t E U k y k e 0 4 G l A s d U B d k i 8 x x d W G W E o k T a J z R a q L 8 3 M h w r N Y t D O 5 l n V K t e L v 7 n D Y y O b o K M i d R o K s j y U G Q 4 0 g n K C 0 A j J i n R f G Y J J p L Z r I h M s M R E 2 5 o q t g R v 9 c v</formula><formula xml:id="formula_9">E q Q q + G Y n 7 1 B S G K f B o p w L G X X t i L V T 7 B Q j H C a F n u x p B E m Y z y k X Y 0 B 9 q n s J 9 M r U n S i n Q H y Q q F f o N D U / T 2 R Y F / K i e / q z m x J O V / L z P 9 q 3 V h 5 F / 2 E B V G s a E B m H 3 k x R y p E W S R o w A Q l i k 8 0 Y C K Y 3 h W R E R a Y K B 1 c U Y d g z 5 + 8 C K 1 q x T 6 r V K 9 r p X o t j 6 M A h 3 A M Z b D h H O p w B Q 1 o A o E H e I I X e D U e j W f j z X i f t S 4 Z + c w B / J H x 8 Q 1 Q s 5 k K &lt; / l a t e x i t &gt; (y c i , f w (x i )) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 W Z y A W / v H w V O G c E J D G 6 X g s K a c l k = " &gt; A A A C G H i c b V D L S s N A F J 3 U V 6 2 v q E s 3 w S K 0 I D W p B V 0 W 3 L i s Y B / Q x j C Z T t</formula><formula xml:id="formula_10">b N b M K Y x F Y u W k D H K 0 H H 0 y G A Y o 8 j G T i E I h + p Y Z S j u B X B J E c V o a R A K H E N 3 C E e 4 r y q C P h Z 1 M H 0 u N I 6 U M D S / g q p g 0 p u r v i Q T 6 Q s S + q z q z K 8 W 8 l 4 n / e f 1 I e u d 2 Q l g Y S c z Q b J E X U U M G R p a S M S Q c I 0 l j R S D i R N 1 q o D H k E E m V Z U m F Y M 2 / v E g 6 9 Z p 1 W q t f N c r N R h 5 H E R y A Q 1 A B F j g D T X A J W q A N E H g E z + A V v G l P 2 o v 2 r n 3 M W g t a P r M P / k C b f A G V 5 6 C u &lt; / l a t e x i t &gt;`( y j , f w 0 (x j ))</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " + W a G o Y 9 4 X U L X G q a k 5 u 1 u k h c l q T w = "  To best exploit the information carried by the weak labels, we propose to construct a label correction network (LCN), serving as a meta model, which takes a pair of noisy data example and its weak label as input and attempts to produce a corrected label for this data example. The LCN is parameterized as a function with parameters ?, y c = g ? (h(x), y ) to correct the weak label y of example feature h(x) to a more accurate one. (Note that y c is a soft label, i.e., a multinomial distribution for all possible classes and the subscription in y c emphasizes that it's generating a corrected label). Meanwhile, the main model f , that we aim to train and use for prediction after training, is instantiated as another function with parameters w, y = f w (x). Without linking the two models, there's no way to enforce that: 1) the corrected label from LCN for an example from the meta model g is indeed a meaningful one, let alone a corrected one, since directly training the LCN is not possible without clean labels for the noisy examples ; 2) The main model f ends up fitting onto the correct true labels, if the labels provided by the LCN do not align with the unknown true labels. Fortunately, the two models can be linked together via a bi-level optimization framework, motivated by the intuition that if the labels generated by the LCN are of high quality, then a classifier trained with such corrected labels as supervision should achieve low loss on a separate set of clean examples. Formally, this can be formulated as the following bi-level optimization problem:  (a) For any step, the optimal w * ? is approximated with onestep look-ahead optimizer update, and used to compute the evaluation loss L 1 , which is then used to update ?. (b) ? are updated once every two updates from w, i.e., a two-step lookahead update is used to approximate w * ? . (c) Extending to k-step look-ahead approximation of w * ? for updating ?. We find using a k in the range of 1 ? 10 works well empirically.</p><formula xml:id="formula_11">&gt; A A A C F 3 i c b V D L S s N A F J 3 U V 6 2 v q E s 3 w S K 2 I C G p B V 0 W 3 L i s Y B / Q h D C Z T t q x k w c z E z W E / I U b f 8 W N C</formula><formula xml:id="formula_12">I = " &gt; A A A B 8 3 i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i S 1 o M u C G 5 c V b C s 0 o U y m k 3 b s Z B L m I Z b Q 3 3 D j Q h G 3 / o w 7 / 8 Z J m 4 W 2 H h g 4 n H M v 9 8 w J U 8 6 U d t 1 v p 7 S 2 v r G 5 V d 6 u 7 O z u 7 R 9 U D 4 + 6 K j G S 0 A 5 J e C L v Q 6 w o Z 4 J 2 N N O c 3 q e S 4 j j k t B d O r n O / 9 0 i l Y o m 4 0 9 O U B j E e C R Y x g r W V f D / G e h x G 2 d N s 8 D C o 1 t y 6 O w d a J V 5 B a l C g P a h + + c O E m J g K T T h W q u + 5 q Q 4 y L D U j n M 4 q v l E 0 x W S C R 7 R v q c A x V U E 2 z z x D Z 1 Y Z o i i R 9 g m N 5 u r v j Q z H S k 3 j 0 E 7 m G d W y l 4 v / e X 2 j o 6 s g Y y I 1 m g q y O B Q Z j n S C 8 g L Q k E l K N J 9 a g o l k N i s i Y y w x 0 b a m i i 3 B W / 7 y K u k 2 6 t 5 F v X H b r L W a R R 1 l O I F T O A c P L q E F N 9 C G D h B I 4 R l e 4 c 0 x z o v z 7 n w s R k t O s X M M f + B 8 / g B 9 3 J H v &lt; / l a t e x i t &gt; y j &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g 0 H 1 7 9 I B Y w / Y 5 e p i i V v X f O 4 D n 2 0 = " &gt; A A A B 8 3 i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i S 1 o M u C G 5 c V 7 A O a U C b T S T t 2 M g k z E y G E / o Y b F 4 q 4 9 W f c + T d O 0 i y 0 9 c D A 4 Z x 7 u W e O H 3 O m t G 1 / W 5 W N z a 3 t n e p u b W / / 4 P C o f n z S V 1 E i C e 2 R i E d y 6 G N F O R O 0 p 5 n m d B h L i k O f 0 4 E / v 8 3 9 w R O V i k X i Q a c x 9 U I 8 F S x g B G s j u W 6 I 9 c w P s n Q x f h z X G 3 b T L o D W i V O S B p T o j u t f 7 i Q i S U i F J h w r N X L s W H s Z l p o R T h c 1 N 1 E 0 x m S O p 3 R k q M A h V V 5 W Z F 6 g C 6 N M U B B J 8 4 R G h f p 7 I 8 O h U m n o m 8 k 8 o 1 r 1 c v E / b 5 T o 4 M b L m I g T T Q V Z H g o S j n S E 8 g L Q h E l K N E 8 N w U Q y k x W R G Z a Y a F N T z Z T g r H 5 5 n f R b T e e q 2 b p v N z r t s o 4 q n M E 5 X I I D 1 9 C B O + h C D w j E 8 A y v 8 G Y l 1 o v 1 b n 0 s R y t W u X M K f 2 B 9 / g B / Y 5 H w &lt; / l a t e x i t &gt;</formula><formula xml:id="formula_13">min ? E (x,y)?D y, f w * ? (x)<label>(1)</label></formula><formula xml:id="formula_14">s.t. w * ? = arg min w E (x,y )?D (g ? (h(x), y ), f w (x)) ? 1 &lt; l a t</formula><formula xml:id="formula_15">I v N T y h b E y H v G u p o h E 3 f j Y / d U r O r T I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 b W f C Z W k y B V b L A p T S T A m s 7 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t O 0 Y b g L b + 8 S l r V i n d Z q d 7 V y v V a H k c B T u E M L s C D K 6 j D L T S g C Q y G 8 A y v 8 O Z I 5 8 V 5 d z 4 W r W t O P n M C f + B 8 / g A F v o 2 U &lt; / l a t e x i t &gt; L 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 K c Z W V g y a q t w 1 O 1 R v j k N 0 C o I M O Q = " &gt; A A A B 9 H i c b V D L S g M x F L 2 p r 1 p f V Z d u g k V w V W Z q Q Z c F N</formula><p>where (?) is the loss function for classification, i.e., crossentropy 1 . We term this framework as Meta Label Correction (MLC); <ref type="figure">Figure 2</ref> provides an overview of the framework. Note that to facilitate a light-weight design of the LCN, we take h(x) to be the feature representations from the main classifier, e.g., representations from the last layer, with stopgradient operators before feeding to LCN to prevent gradient flowing the LCN back to the main model.</p><p>In this bi-level optimization, the LCN parameters ? are the upper parameters (or meta parameters) while the main model parameters w are the lower parameters (or main parameters). Like many other work involving bi-level optimizations, exact solutions to Problem (1) requires solving for the optimal w * whenever ? gets updated. This is both analytically infeasible and computationally expensive, particularly when the main model f is complex, such as ResNet  for image recognition and BERT <ref type="bibr" target="#b3">(Devlin et al. 2018</ref>) for text classification.</p><p>Gradient-based optimization for bi-level optimization. Outside of label correction research, various other studies, including differentiable architecture search <ref type="bibr" target="#b18">(Liu, Simonyan, and Yang 2019)</ref>, few-shot meta learning <ref type="bibr" target="#b5">(Finn, Abbeel, and Levine 2017;</ref><ref type="bibr" target="#b23">Nichol, Achiam, and Schulman 2018)</ref>, have used similar bi-level formulation as Problem (1). Instead of solving for the optimal for w * for each ?, one step of SGD update for w to approximate the optimal main model for a given ? has been employed 2</p><formula xml:id="formula_16">w * ? ? w (?) = w ? ?? w L D (?, w)<label>(2)</label></formula><p>while not converged do Update meta parameters ? by descending Eq. (6) Update model parameters w by descending</p><formula xml:id="formula_17">? w L D (?, w) end Algorithm 1: MLC -Meta Label Correction where L D (?, w) E (x,y )?D (g ? (x, y ), f w (x)</formula><p>) is a shorthand for the lower-level objective function and ? is the learning rate for the main model f . Denoting the upper-level objective function (meta loss) as L D (w) w E (x,y)?D (y, f w (x)), the proxy optimization problem with one-step look ahead SGD now becomes min</p><formula xml:id="formula_18">? L D (w (?)) = L D (w ? ?? w L D (?, w)) (3)</formula><p>Efficient Meta-gradient with k-step SGD of Main Parameters Different from DARTS <ref type="bibr" target="#b18">(Liu, Simonyan, and Yang 2019)</ref>, the meta loss L D (w * ? ) depends only implicitly on the meta parameters ? via the trained model w * ? , hence a more accurate estimate of the optimal solution w * ? for the current LCN parameters ? is desired. To this end, we propose to employ a k-step ahead SGD update as the proxy estimate for the optimal solution. <ref type="figure" target="#fig_12">Figure 3</ref> demonstrates the parameter updating schemes for different k. A larger k principally provides less noisy estimate for the optimal solution w * ? , however it also results in longer dependencies over the past k iterations, which requires caching k copies of the model parameters w. To address this, we further propose to approximate the current meta-parameter gradient with information from the previous k step as follows ?w ??</p><formula xml:id="formula_19">= (I ? ?H w,w ) ?w ?? ? ?H ?,w (4) g w ?w ?? = g w (I ? ?H w,w ) ?w ?? ? g w ?H ?,w (5) ?L D (w ) ?? ? g w (I ? ?) g w g w 2 ?L D (w) ?? ? g w ?H ?,w<label>(6)</label></formula><p>where w is the model parameter for next step, g w is a short hand for the gradient of the training loss w.r.t w, ? is a diagonal matrix representing the current learning rates for all parameters in w, and H ?,w is a short hand for ? 2 ???w L D (?, w). H w,w is estimated with identity to ease computation and the second term can be computed as</p><formula xml:id="formula_20">g w ?H ?,w =? 2 ?,w L D (?, w)?? w L D (w ) =? ? ? w L D (?, w)?? w L D (w )<label>(7)</label></formula><p>Algorithm 1 outlines an iterative procedure to solve the above proxy problem with k-step look ahead SGD for the main model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training with Soft Labels from LCN</head><p>Not only does the LCN explicitly model the dependency of the corrected label on both the data example and its noisy label, but also it ensures that the output from the LCN is a valid categorical distribution over all possible classes. Soft labels are crucial in MLC as they make gradient propagation back to the meta model from the main model possible. However, when the main model takes these examples with soft corrected labels, it brings difficulty to training due to the additional uncertainly in the corrected labels. This can be alleviated by the following strategy. In training for each batch of clean data, we split it into two parts, with one serving as the clean evaluation set and add the other to the training process for f , as a small portion of the clean set will provide clean guidance for training, to ease model training. This has been shown to be effective in similar settings <ref type="bibr" target="#b27">(Ranzato et al. 2015;</ref><ref type="bibr" target="#b26">Pham et al. 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark: Label Correction vs Label Reweighting</head><p>To address noisy labels, Meta-WN <ref type="bibr" target="#b31">(Shu et al. 2019</ref>) leverages the Weight-Network (WN) as the meta-module to reweight the given noisy label, while MLC aims to provide a more refined treatment, i.e., to correct the noisy label. More explicitly, <ref type="figure" target="#fig_13">Figure 4</ref> demonstrates the difference of the underlying operations between Meta-WN and MLC. To highlight ? For an input, Meta-WN tries to learn a weight for the given noisy class only, whiling ignoring all other possible classes (demonstrated by the single non-negative weight ? for Class 2 while 0 for all other classes in <ref type="figure" target="#fig_13">Figure 4(a)</ref>), while since MLC tries to correct the given weak label, essentially it considers all possible classes (demonstrated by the full non-negative vector resulting from the final softmax layer of the LCN, i.e., (? 1 , ? 1 , ? 3 , ? 4 , ? 5 ) for all classes with ? 1 + ? 1 + ? 3 + ? 4 + ? 5 = 1, essentially weighting all possible classes) ? Another key difference between MLC and Meta-WN relies on the information bottleneck to their corresponding meta-modules. For Meta-WN doesn't directly take an pair of data and noisy label as input, but rather relies on the scalar loss of the classifier that particular input incurs as input. In other words, the meta-module lacks the ability to differentiate the different input pairs if the loss values for them are similar, effectively limiting the modeling capacity of the meta-module. While the LCN in MLC directly takes the data feature h(x) and its weak label as input, allowing a more flexible treatment and enabling the LCN to identify different information brought by different input pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>To test the performance of MLC, we conduct experiments on a combination of three image recognition and four text classification tasks, and compare with previous state-of-theart approaches for learning with noisy labels under different types of label noises.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets and Setup</head><p>Datasets. We evaluate our method on 3 image recognition datasets, CIFAR-10, CIFAR-100 <ref type="bibr" target="#b14">(Krizhevsky 2009</ref>) and Clothing1M <ref type="bibr" target="#b37">(Xiao et al. 2015)</ref> and 4 large-scale multi-class text classification benchmark datasets, that are widely used by text classification research <ref type="bibr" target="#b43">(Zhang, Zhao, and LeCun 2015;</ref><ref type="bibr" target="#b38">Xie et al. 2019;</ref><ref type="bibr" target="#b2">Dai et al. 2019;</ref><ref type="bibr" target="#b39">Yang et al. 2016;</ref><ref type="bibr" target="#b1">Conneau et al. 2016)</ref>, AG news, Amazon reviews, Yelp reviews and Yahoo answers. Information about all datasets is summarized in <ref type="table" target="#tab_2">Table 1</ref>. Noisy label sources Following related work <ref type="bibr" target="#b11">(Hendrycks et al. 2018;</ref><ref type="bibr" target="#b30">Ren et al. 2018;</ref><ref type="bibr" target="#b31">Shu et al. 2019)</ref>, for each dataset, we sample a portion of the entire training set as the clean set (except for Clothing1M). To ensure a fair and consistent evaluation, we use only 1000 images as clean set for both CIFAR-10 and CIFAR-100, and only 100 instances per class for the four large scale text classification data sets. The noisy sets are generated by corrupting the labels of all the remaining data points based on the following two setting:</p><p>Uniform label noise (UNIF). For a dataset with C classes, a clean example with true label y is randomly corrupted to all possible classes y with probability ? C and stays in its original label with probability 1 ? ?. (Note the corrupted label might also happen to be the original label, hence the label has probability of 1 ? ? + ? C to stay uncorrupted.) Flipped label noise (FLIP). For a dataset with C classes, a clean example with true label y is randomly flipped to one of the rest C ? 1 classes with probability ? and stays in its original label with probability 1 ? ?.</p><p>We vary ? in the range of [0, 1] to simulate different noise levels for both types. We emphasize that both simulated noise types make the assumption that given the true label the noisy label doesn't depend on the data itself. Hence we also evaluate all the methods on another source of noisy labels:</p><p>Real-world noisy labels. Clothing1M <ref type="bibr" target="#b37">(Xiao et al. 2015</ref>) is a dataset where noisy labels for images are devised by leveraging user tags as proxy annotations. As Clothing1M is the only dataset that comes with real-world noisy labels, we use its original split of clean and noisy sets.</p><p>Finally, we also note that regardless of noise types, none of the methods tested in this paper is aware of the label corruption probability ? nor do they have knowledge about which data sample in the noisy set is actually corrupted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline Methods and Model Architectures</head><p>We focus our evaluation of MLC against state-of-the-art methods for learning with weak supervision from two different themes, i.e., <ref type="bibr" target="#b11">(Hendrycks et al. 2018)</ref> for label correction (denoted by GLC hereafter) and instance re-weighting with meta learning <ref type="bibr" target="#b31">(Shu et al. 2019</ref>) (denoted by MW-Net hereafter).    Note that GLC and MW-Net were shown to consistently outperform other methods such as training on clean data only, cleaning on weak data only, combining clean and weak data, as well as more sophisticated models for combining the clean and weak labels such as distillation ) and forward loss correction <ref type="bibr" target="#b32">(Sukhbaatar et al. 2014)</ref>. Additionally, MW-Net was shown to outperform a slightly different variant for instance re-weighting with meta-parameters <ref type="bibr" target="#b30">(Ren et al. 2018)</ref>. As such, we do not show results from these methods. For fair and consistent comparisons, we use the same classifier architectures for all methods, i.e., ResNet 32 for CIFAR-10 and CIFAR-100, ResNet 50 pretrained from ImageNet for Clothing1M, and pre-trained BERT-base for the four largescale text data sets. We implement all models and experiments in PyTorch. All models are trained with the same number of epochs for the same dataset. <ref type="bibr">3</ref> LCN architecture. We use the same LCN architecture for MLC across all settings as follows <ref type="figure">(Figure 2(a)</ref>):</p><p>An embedding layer of size (C, 128) to embed the input noisy labels, followed by a three-layer feed-forward network with dimensions of (128+xdim, hdim), (hdim, hdim), (hdim,C) respectively. tanh is used as the nonlinear activation function in-between them and lastly a Softmax layer to output a categorical distribution as the corrected labels where C is the number of classes, xdim is the feature dimension of input x from the last layer from the main classifier, i.e., 64 from ResNet32 for CIFAR-10 and CIFAR-100, 2048 from ResNet 50 for Clothing1M and 768 from BERT-base for text datasets and hdim is the hidden dimension for the LCN (set to 768 for text datasets and 64 otherwise).</p><p>3 Code for MLC is available at https://aka.ms/MLC</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main Results</head><p>MLC on image recognition. We start by comparing all methods on the standard image recognition datasets. <ref type="table" target="#tab_3">Table 2</ref> presents the averaged accuracies across multiple configurations (two noise types, 10 noise levels) with k = 5. The table shows that MLC consistently outperforms other methods over all datasets. In addition, on Clothing1M with real noisy labels <ref type="table" target="#tab_4">(Table 3)</ref>, MLC outperforms all baseline methods and improves over GLC and MW-Net by over 2 points in accuracy, suggesting its ability to capture better data-dependent label corruptions via the meta-learning framework.</p><p>MLC on text classification. <ref type="table" target="#tab_3">Table 2</ref> also presents the mean accuracies of MLC on 4 large text data sets with pre-trained BERT-base as its main classifier. Overall, label reweighting (MW-Net) seems insufficient to fully address the text classification problem; label correction approaches demonstrate much higher performances, while MLC achieves the best thanks to its nature of combining of both label correction and the data-driven meta-learning framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis and Ablation Studies</head><p>Effects of noise levels ? and k for MLC. <ref type="figure">Figure 5</ref> presents the results of all methods under UNIF with noise levels from 0 to 1.0 with a step size of 0.1. It's clear that, since Meta-WN only attempts to re-weight the observed weak label, its performance decreases significantly when the noise level goes up, as the given label turns more likely to be the wrong label thus re-weighting for this case is insufficient; while label correction based methods (GLC and MLC) show to be robust against severe label noises. This is consistent with results reported in <ref type="bibr" target="#b11">(Hendrycks et al. 2018)</ref> where label correction was shown to perform well even in extreme noise level situations. Moreover, we observe that MLC is more effective in doing this than previous label correction methods for severe noise. In terms of the number of look-ahead steps, k, used to compute the meta-gradient, the value of k does not seem to have an impact on MLC's performance when the noise level is low; however when the noise level is high (more than 0.6), a larger k leads to higher test accuracy, validating the strategy of using multiple steps to compute the meta-gradients. Similar trends are also observed on FLIP. Meta net evaluation. We perform additional experiments to understand what the meta model, i.e., the LCN, actually learns after model convergence. Additionally, we seek to quantify the benefit of correcting noisy labels, v.s. reweighting instances. We use the FLIP setting to generate corrupted labels for instances in the test set in CIFAR-10 and feed them to the meta nets of both MLC and Meta-WN. MLC will produce a probability distribution over all possible classes where Meta-WN will assign a scalar weight to each instance. Note that, for CIFAR-10, we know which of the noisy label is actually correct and which is not but neither of the models have access to this information. Ideally, Meta-WN will assign higher weights to the correct instances and lower weights to the incorrect ones. Similarly, MLC should keep the label of correct instances as is and alter the labels of the incorrect ones. We see from <ref type="figure">Figure 7</ref> that this is actually the case. On average, both model seem to be able to distinguish between the correct and incorrect labels. However, for incorrect labels, Meta-WN can only down-weight the sample reducing the dependence of the training process on it. MLC goes beyond this by also trying to change the label to assign the sample to the correct one, allowing the main model to fully leverage it. We can see from <ref type="figure" target="#fig_14">Figure 6</ref> that it does that successfully. On other other hand, MW-Net can only assign a weight to the noisy label. MLC training dynamics. <ref type="figure">Figure 8(a,b,c)</ref> shows the training progress for one run on the CIFAR-10 with UNIF under different noise levels. We monitor a set of different metrics during training, including the loss function on the noisy data with corrected labels, loss function on clean data, and the test set accuracy as training progresses. The figure shows that both losses decrease and test accuracy increases as the training process progresses. Note that with larger noise levels (hence more difficult cases), training with MLC gets harder (as seen by the slightly higher loss on clean data and loss on noisy data). However, MLC still converges and achieves good results on test set as shown in <ref type="figure">Figure 8</ref>(c).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>In this paper, we address the problem of learning with noisy labels from a meta-learning perspective. Specifically, we propose to use a meta network to correct the noisy labels from the data set, and a main classifier network is trained to fit the example to a provided label, i.e., corrected labels for the noisy examples and true labels for the clean ones. The meta network and main network are jointly optimized in a bi-level optimization fashion; to address the computation challenge, we employ a k-step ahead SGD update to compute the metagradient. Empirical experiments on three image recognition and four text classification tasks with various label noise types show the benefits of label correction over instance reweighting and demonstrate the strong performance of MLC over previous methods leveraging noisy labels.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>g r b 6 8 T j r 1 m n d d q z 8 0 q s 1 G E U e J n J M L c k U 8 c k O a 5 J 6 0 S J t w M i H P 5 J W 8 O c p 5 c d 6 d j 2 X r h l P M n J E / c D 5 / A A X 6 j i 4 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v a R 1 i b e G z W W O R u w M M + l A V R 8 G i D 4 = " &gt; A A A B 6 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S S 1 o M e C F 4 9 V 7 A e 0 o W y 2 m 3 b p Z h N 2 J 0 I J / Q d e P C j i 1 X / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E h h 0 H W / n b X 1 j c 2 t 7 c J O c X d v / + C w d H T c M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M b 2 d + + 4 l r I 2 L 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>r 3 l W l e l 8 r 1 2 t 5 H A U 4 h T O 4 A A + u o Q 5 3 0 I A m M A j h G V 7 h z R k 7 L 8 6 7 8 7 F o X X P y m R P 4 A + f z B 8 c 2 j N E = &lt; / l a t e x i t &gt; ? &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E C C D M p P 6 h A F 0 4 M X 4 I 3 Y E Z I S U v n k = " &gt; A A A B 6 H i c b V D L S g N B E O y N r x h f U Y 9 e B o M g H s J u D O g x 4 M V j A u Y B y R J m J 7 3 J m N n Z Z W Z W C C F f 4 M W D I l 7 9 J G / + j Z N k D 5 p Y 0 F B U d d P d F S S C a + O 6 3 0 5 u Y 3 N r e y e / W 9 j b P z g 8 K h 6 f t H S c K o Z N F o t Y d Q K q U X C J T c O N w E 6 i k E a B w H Y w v p v 7 7 S d U m s f y w U w S 9 C M 6 l D z k j B o r N a 7 6 x Z J b d h c g 6 8 T L S A k y 1 P v F r 9 4 g Z m m E 0 j B B t e 5 6 b m L 8 K V W G M 4 G z Q i / V m F A 2 p k P s W i p p h N q f L g 6 d k Q u r D E g Y K 1 v S k I X 6 e 2 J K I 6 0 n U W A 7 I 2 p G e t W b i / 9 5 3 d S E t / 6 U y y Q 1 K N l y U Z g K Y m I y / 5 o M u E J m x M Q S y h S 3 t x I 2 o o o y Y 7 M p 2 B C 8 1 Z f X S a t S 9 q 7 L l U a 1 V K t m c e T h D M 7 h E j y 4 g R r c Q x 2 a w A D h G V 7 h z X l 0 X p x 3 5 2 P Z m n O y m V P 4 A + f z B 2 0 Z j K Q = &lt; / l a t e x i t &gt; = &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f Y E E R x q 8 l 7 5 Z L 7 u T N R F u 6 n o 3 j P</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>e n Y 9 l a 8 7 J Z k 7 h D 5 z P H 4 n l j L c = &lt; / l a t e x i t &gt; rw &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h 5 D A 7 p u 1 d I m v O w X 1 9 X r r / k y S z H k = " &gt; A A A B + X i c b V D L S s N A F L 3 x W e s r 6 t J N s A i u S l I L u i y 4 c V n B P q A p 5 W Y 6 a Y d O J m F m U i m h f + L G h S J u / R N 3 / o 2 T N g t t P T B w O O d e 7 p k T J J w p 7 b r f 1 s b m 1 v b O b m m v v H 9 w e H R s n 5 y 2 V Z x K Q l s k 5 r H s B q g o Z 4 K 2 N N O c d h N J M Q o 4 7 Q S T u 9 z v T K l U L B a P e p b Q f o Q j w U J G U B t p Y N u + w I C j H 6 E e B 2 H 2 N B / Y F b f q L u C s E 6 8 g F S j Q H N h f / j A m a U S F J h y V 6 n l u o v s Z S s 0 I p / O y n y q a I J n</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " m L c w J V 3 P l O / c 9 m I t W U g b Y Q G r T / 4 = " &gt; A A A B 8 X i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F c l Z l a 0 G X B j c s K 9 o F t K Z k 0 0 4 Z m M k N y R y l D / 8 K N C 0 X c + j f u / B s z 7 S y 0 9 U D g c M 6 9 5 N z j x 1 I Y d N 1 v Z 2 1 9 Y 3 N r u 7 B T 3 N 3 b P z g s H R 2 3 T J R o x p s s k p H u + N R w K R R v o k D J O 7 H m N P Q l b / u T m 8 x v P 3 J t R K T u c R r z f k h H S g S C U b T S Q y + k O P a D 9 G k 2 K J X d i j s H W S V e T s q Q o z E o f f W G E U t C r p B J a k z X c 2 P s p 1 S j Y J L P i r 3 E 8 J i y C R 3 x r q W K h t z 0 0 3 n i G T m 3 y p A E k b Z P I Z m r v z d S G h o z D X 0 7 m S U 0 y 1 4 m / u d 1 E w y u + 6 l Q c Y J c s c V H Q S I J R i Q 7 n w y F 5 g z l 1 B L K t L B Z C R t T T R n a k o q 2 B G / 5 5 F X S q l a 8 y 0 r 1 r l a u 1 / I 6 C n A K Z 3 A B H l x B H W 6 h A U 1 g o O A Z X u H N M c 6 L 8 + 5 8 L E b X n H z n B P 7 A + f w B + M y R E Q = = &lt; / l a t e x i t &gt; 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B T V Z d b 2 c X 4 d 6 u r F N v p R q k V L a X 9 U = " &gt; A A A B + H i c d V D L S g M x F M 3 4 r P X R U Z d u g k V w V W a m l n Z 2 B T c u K 9 g H t K V k 0 r Q N z W S G 5 I 5 Y h 3 6 J G x e K u P V T 3 P k 3 Z t o K K n r g w u G c e 5 N 7 T x A L r s F x P q y 1 9 Y 3 N r e 3 c T n 5 3 b / + g Y B 8 e t X S U K M q a N B K R 6 g R E M 8 E l a w I H w T q x Y i Q M B G s H 0 8 v M b 9 8 y p X k k b 2 A W s 3 5 I x p K P O C V g p I F d 6 A G 7 A 8 o V F W y Y u v O B X X R K f q 1 S K d e w U 3 I c 3 / O r h v i + 7 1 Z d 7 B o l Q x G t 0 B j Y 7 7 1 h R J O Q S a C C a N 1 1 n R j 6 K V H A z Z P z f C / R L C Z 0 S s a s a 6 g k I d P 9 d L H 4 H J 8 Z Z Y h H k T I l A S / U 7 x M p C b W e h Y H p D A l M 9 G 8 v E / / y u g m M a v 2 U y z g B J u n y o 1 E i M E Q 4 S w E P u W I U x M w Q Q h U 3 u 2 I 6 I Y p Q M F n l T Q h f l + L / S c s r u e W S d + 0 V 6 x e r O H L o B J 2 i c + S i K q q j K 9 R A T U R R g h 7 Q E 3 q 2 7 q 1 H 6 8 V 6 X b a u W a u Z Y / Q D 1 t s n s L 6 T u g = = &lt; / l a t e x i t &gt; 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 5 C 8 O m w C U E I R O V V q q 4 t I U M I + H S o = " &gt; A A A B + H i c d V D L S s N A F J 3 4 r P X R q E s 3 g 0 V w V Z L U 0 m Z X c O O y g n 1 A G 8 p k O m m H T h 7 M 3 I g 1 9 E v c u F D E r Z / i z r 9 x 0 l Z Q 0 Q M X D u f c O 3 P v 8 R P B F V j W h 7 G 2 v r G 5 t V 3 Y K e 7 u 7 R + U z M O j j o p T S V m b x i K W P Z 8 o J n j E 2 s B B s F 4 i G Q l 9 w b r + 9 D L 3 u 7 d M K h 5 H N z B L m B e S c c Q D T g l o a W i W B s D u g H J J B R t l z n x o l q 2 K 2 6 j V q g 1 s V S z L d d y 6 J q 7 r 2 n U b 2 1 rJ U U Y r t I b m + 2 A U 0 z R k E V B B l O r b V g J e R i R w / e S 8 O E g V S w i d k j H r a x q R k C k v W y w + x 2 d a G e E g l r o i w A v 1 + 0 R G Q q V m o a 8 7 Q w I T 9 d v L x b + 8 f g p B w 8 t 4 l K T A I r r 8 K E g F h h j n K e A R l 4 y C m G l C q O R 6 V 0 w n R B I K O q u i D u H r U v w / 6 T g V u 1 p x r p 1 y 8 2 I V R w G d o F N 0 j m x U R 0 1 0 h V q o j S h K 0 Q N 6 Q s / G v f F o v B i v y 9 Y 1 Y z V zj H 7 A e P s E s k O T u w = = &lt; / l a t e x i t &gt; 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " D K r 9 o 6 Y x N A b I M 6 E i D 1 + U T U A N I I g = " &gt; A A A B + H i c d V D L S g M x F M 3 4 r P X R U Z d u g k V w V W a m l n Z 2 B T c u K 9 g H t K V k 0 r Q N z W S G 5 I 5 Y h 3 6 J G x e K u P V T 3 P k 3 Z t o K K n r g w u G c e 5 N 7 T x A L r s F x P q y 1 9 Y 3 N r e 3 c T n 5 3 b / + g Y B 8 e t X S U K M q a N B K R 6 g R E M 8 E l a w I H w T q x Y i Q M B G s H 0 8 v M b 9 8 y p X k k b 2 A W s 3 5 I x p K P O C V g p I F d 6 A G 7 A 8 o V F W y Y l u c D u + i U / F q l U q 5 h p + Q 4 v u d X D f F 9 3 6 2 6 2 D V K h i J a o T G w 3 3 v D i C Y h k 0 A F 0 b r r O j H 0 U 6 K A m y f n + V 6 i W U z o l I x Z 1 1 B J Q q b 7 6 W L x O T 4 z y h C P I m V K A l 6 o 3 y d S E m o 9 C w P T G R K Y 6 N 9 e J v 7 l d R M Y 1 f o p l 3 E C T N L l R 6 N E Y I h w l g I e c s U o i J k h h C p u d s V 0 Q h S h Y L L K m x C + L s X / k 5 Z X c s s l 7 9 o r 1 i 9 W c e T Q C T p F 5 8 h F V V R H V 6 i B m o i i B D 2 g J / R s 3 V u P 1 o v 1 u m x d s 1 Y z x + g H r L d P s 8 i T v A = = &lt; / l a t e x i t &gt; 4 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B o u + m n 8 u 9 A t 3 S q 0 4 h t h w J 9 C B U w c = " &gt; A A A B + H i c d V D L S g M x F M 3 U V 6 2 P j r p 0 E y y C q z L T B + 3 s C m 5 c V r A P a I e S S d M 2 N J M Z k j t i H f o l b l w o 4 t Z P c e f f m D 4 E F T 1 w 4 X D O v c m 9 J 4 g F 1 + A 4 H 1 Z m Y 3 N r e y e 7 m 9 v b P z j M 2 0 f H b R 0 l i r I W j U S k u g H R T H D J W s B B s G 6 s G A k D w T r B 9 H L h d 2 6 Z 0 j y S N z C L m R + S s e Q j T g k Y a W D n + 8 D u g H J F B R u m l f n A L j h F r 1 6 t l u v Y K T q O V / J q h n i e 5 9 Z c 7 B p l g Q J a o z m w 3 / v D i C Y h k 0 A F 0 b r n O j H 4 K V H A z Z P z X D / R L C Z 0 S s a s Z 6 g k I d N + u l x 8 j s + N M s S j S J m S g J f q 9 4 m U h F r P w s B 0 h g Q m + r e 3 E P / y e g m M 6 n 7 K Z Z w A k 3 T 1 0 S g R G C K 8 S A E P u W I U x M w Q Q h U 3 u 2 I 6 I Y p Q M F n l T A h f l + L / S b t U d M v F 0 n W p 0 K i s 4 8 i i U 3 S G L p C L a q i B r l A T t R B F C X p A T + j Z u r c e r R f r d d W a s d Y z J + g H r L d P t U 2 T v Q = = &lt; / l a t e x i t &gt; 5 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n v y f s K 2 X N q O r g Z Y d Z 0 w 2 r Q k E m O E = " &gt; A A A B + H i c d V D L S g M x F M 3 4 r P X R U Z d u g k V w V W a m l n Z 2 B T c u K 9 g H t K V k 0 r Q N z W S G 5 I 5 Y h 3 6 J G x e K u P V T 3 P k 3 Z t o K K n r g w u G c e 5 N 7 T x A L r s F x P q y 1 9 Y 3 N r e 3 c T n 5 3 b / + g Y B 8 e t X S U K M q a N B K R 6 g R E M 8 E l a w I H w T q x Y i Q M B G s H 0 8 v M b 9 8 y p X k k b 2 A W s 3 5 I x p K P O C V g p I F d 6 A G 7 A 8 o V F W y Y V u Y D u + i U / F q l U q 5 h p + Q 4 v u d X D f F 9 3 6 2 6 2 D V K h i J a o T G w 3 3 v D i C Y h k 0 A F 0 b r r O j H 0 U 6 K A m y f n + V 6 i W U z o l I x Z 1 1 B J Q q b 7 6 W L x O T 4 z y h C P I m V K A l 6 o 3 y d S E m o 9 C w P T G R K Y 6 N 9 e J v 7 l d R M Y 1 f o p l 3 E C T N L l R 6 N E Y I h w l g I e c s U o i J k h h C p u d s V 0 Q h S h Y L L K m x C + L s X / k 5 Z X c s s l 7 9 o r 1 i 9 W c e T Q C T p F 5 8 h F V V R H V 6 i B m o i i B D 2 g J / R s 3 V u P 1 o v 1 u m x d s 1 Y z x + g H r L d P t t K T v g = = &lt; / l a t e x i t &gt; 6 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 u O X F N / D f B m + F 8 8 j K F F k u B U 7 w E c = " &gt; A A A B + H i c d V D L S g M x F M 3 U V 6 2 P V l 2 6 C R b B 1 T D T W t v Z F d y 4 r G A f 0 A 4 l k 8 m 0 o Z k H y R 2 x D v 0 S N y 4 U c e u n u P N v T B + C i h 6 4 c D j n 3 u T e 4 y W C K 7 C s D y O 3 t r 6 x u Z X f L u z s 7 u 0 X S w e H H R W n k r I 2 j U U s e x 5 R T P C I t Y G D Y L 1 E M h J 6 g n W 9 y e X c 7 9 4 y q X g c 3 c A 0 Y W 5 I R h E P O C W g p W G p O A B 2 B 5 R L K p i f X c y G p b J l O o 1 a r d r A l m l Z T s W p a + I 4 j l 2 3 s a 2 V O c p o h d a w 9 D 7 w Y 5 q G L A I q i F J 9 2 0 r A z Y g E r p + c F Q a p Y g m h E z J i f U 0 j E j L l Z o v F Z / h U K z 4 O Y q k r A r x Q v 0 9 k J F R q G n q 6 M y Q w V r + 9 u f i X 1 0 8 h a L g Z j 5 I U W E S X H w W p w B D j e Q r Y 5 5 J R E F N N C J V c 7 4 r p m E h C Q W d V 0 C F 8 X Y r / J 5 2 K a V f N y n W l 3 D x f x Z F H x + g E n S E b 1 V E T X a E W a i O K U v S A n t C z c W 8 8 G i / G 6 7 I 1 Z 6 x m j t A P G G + f u F e T v w = = &lt; / l a t e x i t &gt; Label Embedding y 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 g C k y L o s 0 J s Z W n X 4 5 G C q x Q G k D 2 k = " &gt; A A A B 8 n i c b V D L S g M x F L 1 T X 7 W + q i 4 V C R b R V Z k R Q d 0 V 3 b h s w T 5 g O p R M m m l D M 5 k h y Q h l 6 N J P c O N C E b d + Q L / D n d / g T 5 h p u 9 D W A 4 H D O f e S c 4 8 f c 6 a 0 b X 9 Z u a X l l d W 1 / H p h Y 3 N r e 6 e 4 u 9 d Q U S I J r Z O I R 7 L l Y 0 U 5 E 7 S u m e a 0 F U u K Q 5 / T p j + 4 z f z m A 5 W K R e J e D 2 P q h b g n W M A I 1 k Z y 2 y H W f T 9 I h 6 e j T r F k l + 0 J 0 C J x Z q R U O R z X v h + P x t V O 8 b P d j U g S U q E J x 0 q 5 j h 1 r L 8 V S M 8 L p q N B O F I 0 x G e A e d Q 0 V O K T K S y e R R + j E K F 0 U R N I 8 o d F E / b 2 R 4 l C p Y e i b y S y i m v c y 8 T / P T X R w 5 a V M x I m m g k w / C h K O d I S y + 1 G X S U o 0 H x q C i W Q m K y J 9 L D H R p q W C K c G Z P 3 m R N M 7 L z k X 5 u m b a u I E p 8 n A A x 3 A G D l x C B e 6 g C n U g E M E T v M C r p a 1 n 6 8 1 6 n 4 7 m r N n O P v y B 9 f E D U 6 e V A Q = = &lt; / l a t e x i t &gt; h(x) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " U N P m X 0 u J u v E T q T V o L R g X r J z M w / c = " &gt; A A A B 9 H i c b V D L S g M x F L 3 j s 9 Z X 1 a W b 0 C J U h D I j g r o r u n F Z w T 6 g H U o m z b S h m c y Y Z I r D 0 L 8 Q 3 L h Q x K 0 f 4 6 5 / Y 6 b t Q l s P B A 7 n 3 M s 9 O V 7 E m d K 2 P b F W V t f W N z Z z W / n t n d 2 9 / c L B Y U O F s S S 0 T k I e y p a H F e V M 0 L p m m t N W J C k O P E 6 b 3 v A 2 8 5 s j K h U L x Y N O I u o G u C + Y z w j W R n I H 5 U 6 A 9 c D z 0 6 f x a b d Q s i v 2 F G i Z O H N S q h Y 7 Z 8 + T a l L r F r 4 7 v Z D E A R W a c K x U 2 7 E j 7 a Z Y a k Y 4 H e c 7 s a I R J k P c p 2 1 D B Q 6 o c t N p 6 D E 6 M U o P + a E 0 T 2 g 0 V X 9 v p D h Q K g k 8 M 5 l F V I t e J v 7 n t W P t X 7 k p E 1 G s q S C z Q 3 7 M k Q 5 R 1 g D q M U m J 5 o k h m E h m s i I y w B I T b X r K m x K c x S 8 v k 8 Z 5 x b m o X N + b N m 5 g h h w c Q x H K 4 M A l V O E O a l A H A o / w A m / w b o 2 s V + v D + p y N r l j z n S P 4 A + v r B 6 4 C l Q o = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " j 7 T 0 h N Q a K A G V c J l K a 8 R b l V g G e 5 o = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h X k p S B T 0 W v H i s a G u h D W W z 3 b R L N 5 u w O x F K 6 E / w 4 k E R r / 4 i b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k Q K g 6 7 7 7 R T W 1 j c 2 t 4 r b p Z 3 d v f 2 D 8 u F R 2 8 S p Z r z F Y h n r T k A N l 0 L x F g q U v J N o T q N A 8 s d g f D P z H 5 + 4 N i J W D z h J u B / R o R K h Y B S t d F + l 5 / 1 y x a 2 5 c 5 B V 4 u W k A j m a / f J X b x C z N O I K m a T G d D 0 3 Q T + j G g W T f F r q p Y Y n l I 3 p k H c t V T T i x s / m p 0 7 J m V U G J I y 1 L Y V k r v 6 e y G h k z C Q K b G d E c W S W v Z n 4 n 9 d N M b z 2 M 6 G S F L l i i 0 V h K g n G Z P Y 3 G Q j N G c q J J Z R p Y W 8 l b E Q 1 Z W j T K d k Q v O W X V 0 m 7 X v M u a v W 7 e q V x m c d R h B M 4 h S p 4 c A U N u I U m t I D B E J 7 h F d 4 c 6 b w 4 7 8 7 H o r X g 5 D P H 8 A f O 5 w + F I 4 0 + &lt; / l a t e x i t &gt; (b) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " s e D W T E</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>e 9 a q m j E j Z / N T 5 2 S M 6 s M S B h r W w r J X P 0 9 k d H I m E k U 2 M 6 I 4 s g s e z P x P 6 + b Y n j t Z 0 I l K X L F F o v C V B K M y e x v M h C a M 5 Q T S y j T w t 5 K 2 I h q y t C m U 7 I h e M s v r 5 J 2 v e Z d 1 O p 3 9 U r j M o + j C C d w C l X w 4 A o a c A t N a A G D I T z D K 7 w 5 0 n l x 3 p 2 P R W v B y W e O 4 Q + c z x + G q I 0 / &lt; / l a t e x i t &gt; w 0 (?) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " J C A R u + Q 6 x x 1 3 P + p a H i j X Y p e x u g I = " &gt; A A A C B X i c b Z D L S s N A F I Y n X m u 9 R V 3 q I l j E u i l J L e i y 4 M Z l B X u B J p S T 6 a Q d O p m E m Y l S Q j d u f B U 3 L h R x 6 z u 4 8 2 2 c t B G 0 9 Y e B j / + c w 5 z z + z G j U t n 2 l 7 G 0 v L K 6 t l 7 Y K G 5 u b e / s m n v 7 L R k l A p M m j l g k O j 5 I w i g n T U U V I 5 1 Y E A h 9 R t r + 6 C q r t + + I k D T i t 2 o c E y + E A a c B x a C 0 1 T O P 3 B D U 0 A / S + 8 l p + Y d d Y P E Q J m c 9 s 2 R X 7 K m s R X B y K K F c j Z 7 5 6 f Y j n I S E K 8 x A y q 5 j x 8 p L Q S i K G Z k U 3 U S S G P A I B q S r k U N I p J d O r 5 h Y J 9 r p W 0 E k 9 O P K m r q / J 1 I I p R y H v u 7 M 9 p T z t c z 8 r 9 Z N V H D p p Z T H i S I c z z 4 K E m a p y M o i s f</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>r Y z l a s o q d U / g D 6 / M H 4 o K S I A = = &lt; / l a t e x i t &gt; y c i &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 3 h Z C + F C 2 I P l n U v F f 6 h 8 v 3 D R s F s = " &gt; A A A B 9 X i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i S 1 o M u C G 5 c V 7 A P a t E y m k 3 b o Z B J m J k o I / Q 8 3 L h R x 6 7 + 4 8 2 + c p F l o 6 4 G B w z n 3 c s 8 c L + J M a d v + t k o b m 1 v b O + X d y t 7 + w e F R 9 f i k q 8 J Y E t o h I Q 9 l 3 8 O K c i Z o R z P N a T + S F A c e p z 1 v f p v 5 v U c q F Q v F g 0 4 i 6 g Z 4 K p j P C N Z G G g 0 D r G e e n y a L E R m z c b V m 1 + 0 c a J 0 4 B a l B g f a 4 + j W c h C Q O q N C E Y 6 U G j h 1 p N 8 V S M 8 L p o j K M F Y 0 w m e M p H R g q c E C V m + a p F + j C K B P k h 9 I 8 o V G u / t 5 I c a B U E n h m M k u p V r 1 M / M 8 b x N q / c V M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>9 r Y 3 N r e K e 9 W 9 v Y P D o + q x y d d l R h J a I c k P J H 9 E C v K m a A d z T S n / V R S H I e c 9 s L p b e 7 3 H q l U L B E P e p b S I M Z j w S J G s L a S 7 8 d Y T 8 I o e 5 o P 2 b B a c + v u A m i d e A W p Q Y H 2 s P r l j x J i Y i o 0 4 V i p g e e m O s i w 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>r p N u o e 1 f 1 x n 2 z 1 m o W d Z T h D M 7 h E j y 4 h h b c Q R s 6 Q C C F Z 3 i F N 8 c 4 L 8 6 7 8 7 E c L T n F z i n 8 g f P 5 A 3 x Y k e 4 = &lt; / l a t e x i t &gt; f w (x i ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " c L s I R N f H N H I X u g U g h / 0 u D o T + S Z U = " &gt; A A A C B X i c b Z D L S s N A F I Z P v N Z 6 i 7 r U x W A R 6 q Y k t a D L g h u X F e w F 2 h I m 0 0 k 7 d H J h Z q K W k I 0 b X 8 W N C 0 X c + g 7 u f B s n b Q R t / W H g 4 z / n M O f 8 b s S Z V J b 1 Z S w t r 6 y u r R c 2 i p t b 2 z u 7 5 t 5 + S 4 a x I L R J Q h 6 K j o s l 5 S y g T c U U p 5 1 I U O y 7 n L b d 8 W V W b 9 9 S I V k Y 3 K h J R P s + H g b M Y w Q r b T n m k e c k P R + r k e s l d 2 l a / u H 7 1 G G n j l m y K t Z U a B H s H</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>r B y S T M T N Q Q 8 h l u / B U 3 L h R x 2 5 1 / 4 6 S N o q 0 H L h z O u Z d 7 7 3 F D S o Q 0 z U + t s L S 8 s r p W X C 9 t b G 5 t 7 + i 7 e x 0 R R B z h N g p o w H s u F J g S h t u S S I p 7 I c f Q d y n u u r c X m d + 9 w 1 y Q g F 3 L O M S 2 D 0 e M e A R B q S R H P x l g S i s D H 8 q x 6 y V x e o M c c u w 5 3 8 J 9 + u M 9 p A 6 p V h 2 9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>0 X c 6 s 6 / c d J G 0 e q B g T P n 3 M u 9 9 7 g R J V w Y x o d S W l h c W l 4 p r 1 b W 1 j c 2 t 9 T t n S 4 P Y 4 Z w B 4 U 0 Z H 0 X c k x J g D u C C I r 7 E c P Q d y n u u Z O z 3 O 9 d Y 8 Z J G F y K J M K 2 D 0 c B 8 Q i C Q k q O q l u Y 0 p r l Q z F 2 v T T J n K s j z / n 6 3 h x m 3 9 a t t O p 1 R 6 0 a u j G F 9 p e Y B a m C A m 1 H f b e G I Y p 9 H A h E I e c D 0 4 i E n U I m C K I 4 q 1 g x x x F E E z j C A 0 k D 6 G N u p 9 O 7 M u 1 A K k P N C 5 l 8 g d C m 6 s + O F P q c J 7 4 r K / M t + b y X i / 9 5 g 1 h 4 p 3Z K g i g W O E C z Q V 5 M N R F q e U j a k D C M B E 0 k g Y g R u a u G x p B B J G S U F R m C O X / y X 9 J t 6 O a x 3 r h o V l v N I o 4 y 2 A P 7 o A Z M c A J a 4 B y 0 Q Q c g c A c e w B N 4 V u 6 V R + V F e Z 2 V l p S i Z x f 8 g v L 2 C X U n o A w = &lt; / l a t e x i t &gt; f w 0 (x j ) &lt; l at e x i t s h a 1 _ b a s e 6 4 = " X K d e n R H 3 g f x L z 1 e a B P r A M P l G Y O k = " &gt; A A A C B H i c b Z D L S s N A F I Y n X m u 9 R V 1 2 M 1 j E u i l J L e i y 4 M Z l B X u B N o T J d N K O n U z C z E Q t I Q s 3 v o o b F 4 q 4 9 S H c + T Z O 2 g j a + s P A x 3 / O Y c 7 5 v Y h R q S z r y 1 h a X l l d W y 9 s F D e 3 t n d 2 z b 3 9 t g x j g U k L h y w U X Q 9 J w i g n L U U V I 9 1 I E B R 4 j H S 8 8 U V W 7 9 w S I W n I r 9 U k I k 6 A h p z 6 F C O l L d c s + W 4 / Q G r k + c n d c V r 5 4 f v U v T l x z b J V t a a C i 2 D n U A a 5 m q 7 5 2 R + E O A 4 I V 5 g h K X u 2 F S k n Q U J R z E h a 7 M e S R A i P 0 Z D 0 N H I U E O k k 0 y N S e K S d A f R D o R 9 X c O r + n k h Q I O U k 8 H R n t q S c r 2 X m f 7 V e r P x z J 6 E 8 i h X h e P a R H z O o Q p g l A g d U E K z Y R A P C g u p d I R 4 h g b D S u R V 1 C P b 8 y Y v Q r l X t 0 2 r t q l 5 u 1 P M 4 C q A E D k E F 2 O A M N M A l a I I W w O A B P I E X 8 G o 8 G s / G m / E + a 1 0 y 8 p k D 8 E f G x z f e T Z g w &lt; / l a t e x i t &gt; x j &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K z 8 1 m I I W t 1 q U P s T p e g Q g h t o X L 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " w x 6 A x 5 w 6 z p 4 L 4 u z r C i 9 g q 8 T X k U 8 = " &gt; A A A B 8 3 i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i S 1 o M u C G 5 c V 7 A O a W C b T S T t 0 M g k z E y G E / o Y b F 4 q 4 9 W f c + T d O 0 i y 0 9 c D A 4 Z x 7 u W e O H 3 O m t G 1 / W 5 W N z a 3 t n e p u b W / / 4 P C o f n z S V 1 E i C e 2 R i E d y 6 G N F O R O 0 p 5 n m d B h L i k O f 0 4 E / v 8 3 9 w R O V i k X i Q a c x 9 U I 8 F S x g B G s j u W 6 I 9 c w P s n T x S M b 1 h t 2 0 C 6 B 1 4 p S k A S W 6 4 / q X O 4 l I E l K h C c d K j R w 7 1 l 6 G p W a E 0 0 X N T R S N M Z n j K R 0 Z K n B I l Z c V m R f o w i g T F E T S P K F R o f 7 e y H C o V B r 6 Z j L P q F a 9 X P z P G y U 6 u P E y J u J E U 0 G W h 4 K E I x 2 h v A A 0 Y Z I S z V N D M J H M Z E V k h i U m 2 t R U M y U 4 q 1 9 e J / 1 W 0 7 l q t u 7 b j U 6 7 r K M K Z 3 A O l + D A N X T g D r r Q A w I x P M M r v F m J 9 W K 9 W x / L 0 Y p V 7 p z C H 1 i f P 3 N C k e g = &lt; / l a t e x i t &gt; Figure 2: MLC computation graph. (x i , y i ) denotes a pair of sample with weak label and (x j , y j ) is a pair of sample with clean label. (a) Architecture of the label correction network, where h(x) is a feature representation of input x; (b) Computation flow of updating the LCN. In order, operations are:1 Feed the weak instance to the LCN and get its corrected label, 2 Feed the data instance to the current classifier and compute the logits for prediction, 3 Compute the loss with the logits and corrected label, and compute the gradient of the loss w.r.t. the parameter of the classifier. Note that the gradient will be a function of the parameters of the LCN. 4 Update the classifier parameter while keeping the computation graph for its gradient, 5 Feed a pair of clean instance to the new model and compute its loss, 6 Compute the gradient of the loss w.r.t the parameter of LCN and update the LCN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>e x i t s h a 1 _ b a s e 6 4 = " S N y O 8 c 7 B 3 j g a / F b + L B U e Z 6 S 3 S N U = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l q Q Y 8 F L x 4 r 2 A 9 o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k r e N U U d a i s Y h V N 0 D N B J e s Z b g R r J s o h l E g W C e Y 3 M 7 9 z h N T m s f y w U w T 5 k c 4 k j z k F I 2 V u n 0 U y R g H 3 q B c c a v u A m S d e D m p Q I 7 m o P z V H 8 Y 0 j Z g 0 V K D W P c 9 N j J + h M p w K N i v 1 U 8 0 S p B M c s Z 6 l E i O m / W x x 7 4 x c W G V I w l j Z k o Y s 1 N 8 T G U Z a T 6 P A d k Z o x n r V m 4 v / e b 3 U h D d + x m W S G i b p c l G Y C m J i M n + e D L l i 1 I i p J U g V t 7 c S O k a F 1 N i I S j Y E b / X l d d K u V b 2 r a u 2 + X m n U 8 z i K c A b n c A k e X E M D 7 q A J L a A g 4 B l e 4 c 1 5 d F 6 c d + d j 2 V p w 8 p l T + A P n 8 w e x 6 Y + y &lt; / l a t e x i t &gt; w 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 J y e W Z 6 5 Z D 4 e i R k g L j B Q V M u L W U 4 = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k t 6 L H g x W N F + w F t K J v t p l 2 6 2 Y T d i V J C f 4 I X D 4 p 4 9 R d 5 8 9 + 4 b X P Q 1 g c D j / d m m J k X J F I Y d N 1 v Z 2 1 9 Y 3 N r u 7 B T 3 N 3 b P z g s H R 2 3 T J x q x p s s l r H u B N R w K R R v o k D J O 4 n m N A o k b w f j m 5 n f f u T a i F g 9 4 C T h f k S H S o S C U b T S / V P f 7 Z f K b s W d g 6 w S L y d l y N H o l 7 5 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 3 :</head><label>3</label><figDesc>y 5 c V L A P a I e S S T N t a C Y z J p l C G f o d b l w o 4 t a P c e f f m G l n o a 0 H A o d z 7 u W e H D 8 W X B v H + U a F j c 2 t 7 Z 3 i b m l v / + D w q H x 8 0 t Z R o i h r 0 U h E q u s T z Q S X r G W 4 E a w b K 0 Z C X 7 C O P 7 n N / M 6 U K c 0 j + W h m M f N C M p I 8 4 J Q Y K 3 n 9 k J g x J S K 9 n w / c Q b n i V J 0 F 8 D p x c 1 K B H M 1 B + a s / j G g S M m m o I F r 3 X C c 2 X k q U 4 V S w e a m f a B Y T O i E j 1 r N U k p B p L 1 2 E n u M L q w x x E C n 7 p M E L 9 f d G S k K t Z 6 F v J 7 O Q e t X L x P + 8 X m K C G y / l M k 4 M k 3 R 5 K E g E N h H O G s B D r h g 1 Y m Y J o Y r b r J i O i S L U 2 J 5 K t g R 3 9 c v r p F 2 r u l f V 2 k O 9 0 q j n d R T h D M 7 h E l y 4 h g b c Q R N a Q O E J n u E V 3 t A U v a B 3 9 L E c L a B 8 5 x T + A H 3 + A K u x k f w = &lt; / l a t e x i t &gt; ? 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 5 r X i h B E D S A C A q 6 u U x M c A c C v g V R Y = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l q Q Y 8 F L x 4 r 2 A 9 o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k r e N U U d a i s Y h V N 0 D N B J e s Z b g R r J s o h l E g W C e Y 3 M 7 9 z h N T m s f y w U w T 5 k c 4 k j z k F I 2 V u n 0 U y R g H 7 q B c c a v u A m S d e D m p Q I 7 m o P z V H 8 Y 0 j Z g 0 V K D W P c 9 N j J + h M p w K N i v 1 U 8 0 S p B M c s Z 6 l E i O m / W x x 7 4 x c W G V I w l j Z k o Y s 1 N 8 T G U Z a T 6 P A d k Z o x n r V m 4 v / e b 3 U h D d + x m W S G i b p c l G Y C m J i M n + e D L l i 1 I i p J U g V t 7 c S O k a F 1 N i I S j Y E b / X l d d K u V b 2 r a u 2 + X m n U 8 z i K c A b n c A k e X E M D 7 q A J L a A g 4 B l e 4 c 1 5 d F 6 c d + d j 2 V p w 8 p l T + A P n 8 w e w Z Y + x &lt; / l a t e x i t &gt; w 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " R q i f o 3 t i R M g u D 8 j f j s R 1 5 C C h P a A = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k t 6 L H g x W N F + w F t K J v t p F 2 6 2 Y T d j V J C f 4 I X D 4 p 4 9 R d 5 8 9 + 4 b X P Q 1 g c D j / d m m J k X J I J r 4 7 r f z t r 6 x u b W d m G n u L u 3 f 3 B Y O j p u 6 T h V D J s s F r H q B F S j 4 B K b h h u B n U Q h j Q K B 7 W B 8 M / P b j 6 g 0 j + W D m S T o R 3 Q o e c g Z N V a 6 f + p 7 / V L Z r b h z k F X i 5 a Q M O R r 9 0 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N h L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J u l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O 0 Y b g L b + 8 S l r V i n d Z q d 7 V y v V a H k c B T u E M L s C D K 6 j D L T S g C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r W t O P n M C f + B 8 / g A H Q o 2 V &lt; / l a t e x i t &gt; L 0 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h / d i 5 w w H G t r Z r G d L N c T d 4 y y N 3 0 o = " &gt; A A A B 9 X i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F d l Z l a 0 G X B j Q s X F e w D 2 r F k 0 k w b m k m G J K O U o f / h x o U i b v 0 X d / 6 N m X Y W 2 n o g c D j n X u 7 J C W L O t H H d b 2 d l d W 1 9 Y 7 O w V d z e 2 d 3 b L x 0 c t r R M F K F N I r l U n Q B r y p m g T c M M p 5 1 Y U R w F n L a D 8 X X m t x + p 0 k y K e z O J q R / h o W A h I 9 h Y 6 a E X Y T M i m K e 3 0 7 O + 1 y + V 3 Y o 7 A 1 o m X k 7 K k K P R L 3 3 1 B p I k E R W G c K x 1 1 3 N j 4 6 d Y G U Y 4 n R Z 7 i a Y x J m M 8 p F 1 L B Y 6 o 9 t N Z 6 i k 6 t c o A h V L Z J w y a q b 8 3 U h x p P Y k C O 5 m l 1 I t e J v 7 n d R M T X v k p E 3 F i q C D z Q 2 H C k Z E o q w A N m K L E 8 I k l m C h m s y I y w g o T Y 4 s q 2 h K 8 x S 8 v k 1 a 1 4 l 1 U q n e 1 c r 2 W 1 1 G A Y z i B c / D g E u p w A w 1 o A g E F z / A K b 8 6 T 8 + K 8 O x / z 0 R U n 3 z m C P 3 A + f w A Q o J I t &lt; / l a t e x i t &gt; ? 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 5 r X i h B E D S A C A q 6 u U x M c A c C v g V R Y = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l q Q Y 8 F L x 4 r 2 A 9 o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k r e N U U d a i s Y h V N 0 D N B J e s Z b g R r J s o h l E g W C e Y 3 M 7 9 z h N T m s f y w U w T 5 k c 4 k j z k F I 2 V u n 0 U y R g H 7 q B c c a v u A m S d e D m p Q I 7 m o P z V H 8 Y 0 j Z g 0 V K D W P c 9 N j J + h M p w K N i v 1 U 8 0 S p B M c s Z 6 l E i O m / W x x 7 4 x c W G V I w l j Z k o Y s 1 N 8 T G U Z a T 6 P A d k Z o x n r V m 4 v / e b 3 U h D d + x m W S G i b p c l G Y C m J i M n + e D L l i 1 I i p J U g V t 7 c S O k a F 1 N i I S j Y E b / X l d d K u V b 2 r a u 2 + X m n U 8 z i K c A b n c A k e X E M D 7 q A J L a A g 4 B l e 4 c 1 5 d F 6 c d + d j 2 V p w 8 p l T + A P n 8 w e w Z Y + x &lt; / l a t e x i t &gt; w 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " R q i f o 3 t i R M g u D 8 j f j s R 1 5 C C h P a A = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k t 6 L H g x W N F + w F t K J v t p F 2 6 2 Y T d j V J C f 4 I X D 4 p 4 9 R d 5 8 9 + 4 b X P Q 1 g c D j / d m m J k X J I J r 4 7 r f z t r 6 x u b W d m G n u L u 3 f 3 B Y O j p u 6 T h V D J s s F r H q B F S j 4 B K b h h u B n U Q h j Q K B 7 W B 8 M / P b j 6 g 0 j + W D m S T o R 3 Q o e c g Z N V a 6 f + p 7 / V L Z r b h z k F X i 5 a Q M O R r 9 0 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N h L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J u l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O 0 Y b g L b + 8 S l r V i n d Z q d 7 V y v V a H k c B T u E M L s C D K 6 j D L T S g C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r W t O P n M C f + B 8 / g A H Q o 2 V &lt; / l a t e x i t &gt; w 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E Y s m n p f x O 1 W v Q 6 n r N + 8 c R K c 5 5 O Y = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k t 6 L H g x W N F + w F t K J v t p l 2 6 2 Y T d i V J C f 4 I X D 4 p 4 9 R d 5 8 9 + 4 b X P Q 1 g c D j / d m m J k X J F I Y d N 1 v Z 2 1 9 Y 3 N r u 7 B T 3 N 3 b P z g s H R 2 3 T J x q x p s s l r H u B N R w K R R v o k D J O 4 n m N A o k b w f j m 5 n f f u T a i F g 9 4 C T h f k S H S o S C U b T S / V O / 2 i + V 3 Y o 7 B 1 k l X k 7 K k K P R L 3 3 1 B j F L I 6 6 Q S W p M 1 3 M T 9 D O q U T D J p 8 V e a n h C 2 Z g O e d d S R S N u / G x + 6 p S c W 2 V A w l j b U k j m 6 u + J j E b G T K L A d k Y U R 2 b Z m 4 n / e d 0 U w 2 s / E y p J k S u 2 W B S m k m B M Z n + T g d C c o Z x Y Q p k W 9 l b C R l R T h j a d o g 3 B W 3 5 5 l b S q F e + y U r 2 r l e u 1 P I 4 C n M I Z X I A H V 1 C H W 2 h A E x g M 4 R l e 4 c 2 R z o v z 7 n w s W t e c f O Y E / s D 5 / A E I x o 2 W &lt; / l a t e x i t &gt; L 0 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h / d i 5 w w H G t r Z r G d L N c T d 4 y y N 3 0o = " &gt; A A A B 9 X i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F d l Z l a 0 G X B j Q s X F e w D 2 r F k 0 k w b m k m G J K O U o f / h x o U i b v 0 X d / 6 N m X Y W 2 n o g c D j n X u 7 J C W L O t H H d b 2 d l d W 1 9 Y 7 O w V d z e 2 d 3 b L x 0 c t r R M F K F N I r l U n Q B r y p m g T c M M p 5 1 Y U R w F n L a D 8 X X m t x + p 0 k y K e z O J q R / h o W A h I 9 h Y 6 a E X Y T M i m K e 3 0 7 O + 1 y + V 3 Y o 7 A 1 o m X k 7 K k K P R L 3 3 1 B p I k E R W G c K x 1 1 3 N j 4 6 d Y G U Y 4 n R Z 7 i a Y x J m M 8 p F 1 L B Y 6 o 9 t N Z 6 i k 6 t c o A h V L Z J w y a q b 8 3 U h x p P Y k C O 5 m l 1 I t e J v 7 n d R M T X v k p E 3 F i q C D z Q 2 H C k Z E o q w A N m K L E 8 I k l m C h m s y I y w g o T Y 4 s q 2 h K 8 x S 8 v k 1 a 1 4 l 1 U q n e 1 c r 2 W 1 1 G A Y z i B c / D g E u p w A w 1 o A g E F z / A K b 8 6 T 8 + K 8 O x / z 0 R U n 3 z m C P 3 A + f w A Q o J I t &lt; / l a t e x i t &gt; L 0 2 &lt; l a te x i t s h a 1 _ b a s e 6 4 = " g E O P T / S W z D R T 3 a j N t W p X S a j 8 L Q w = " &gt; A AA B 9 X i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F d l Z l a 0 G X B j Q s X F e w D 2 r F k 0 k w b m k m G J K O U o f / h x o U i b v 0 X d / 6 N m X Y W 2 n o g c D j n X u 7 J C W L O t H H d b 2 d l d W 1 9 Y 7 O w V d ze 2 d 3 b L x 0 c t r R M F K F N I r l U n Q B r y p m g T c M M p 5 1 Y U R w F n L a D 8 X X m t x + p 0 k y K e z O J q R / h o W A h I 9 h Y 6 a E X Y T M i m K e 3 0 7 N + t V 8 q u x V 3 B r R M v J y U I U e j X / r q D S R J I i o M 4 V j r r u f G x k + x M o x w O i 3 2 E k 1 j T M Z 4 S L u W C h x R 7 a e z 1 F N 0 a p U B C q W y T x g 0 U 3 9 v p D j S e h I F d j J L q R e 9 T P z P 6 y Y m v P J T J u L E U E H m h 8 K E I y N R V g E a M E W J 4 R N L M F H M Z k V k h B U m x h Z V t C V 4 i 1 9 e J q 1 q x b u o V O 9 q 5 X o t r 6 M A x 3 A C 5 + D B J d T h B h r Q B A I K n u E V 3 p w n 5 8 V 5 d z 7 m o y t O v n M E f + B 8 / g A S J J I u &lt; / l a t e x i t &gt; L 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L 0 t K J R z w b g 6i i U A H H N b D J E j G R F s = " &gt; A A A B 9 H i c b V D L S g M x F L 2 p r 1 p f V Z d u g k V w V W Z q Q Z c F N y 5 c V L A P a I e S S T N t a C Y z J p l C G f o d b l w o 4 t a P c e f f m G l n o a 0 H A o d z 7 u W e H D 8 W X B v H + U a F j c 2 t 7 Z 3 i b m l v / + D w q H x 8 0 t Z R o i h r 0 U h E q u s T z Q S X r G W 4 E a w b K 0 Z C X 7 C O P 7 n N / M 6 U K c 0 j + W h m M f N C M p I 8 4 J Q Y K 3 n 9 k J g x J S K 9 n w 9 q g 3 L F q T o L 4 H X i 5 q Q C O Z q D 8 l d / G N E k Z N J Q Q b T u u U 5 s v J Q o w 6 l g 8 1 I / 0 S w m d E J G r G e p J C H T X r o I P c c X V h n i I F L 2 S Y M X 6 u + N l I R a z 0 L f T m Y h 9 a q X i f 9 5 v c Q E N 1 7 K Z Z w Y J u n y U J A I b C K c N Y C H X D F q x M w S Q h W 3 W T E d E 0 W o s T 2 V b A n u 6 p f X S b t W d a + q t Y d 6 p V H P 6 y j C G Z z D J b h w D Q2 4 g y a 0 g M I T P M M r v K E p e k H v 6 G M 5 W k D 5 z i n 8 A f r 8 A a 0 1 k f 0 = &lt; / l a t e x i t &gt; w 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 J y e W Z 6 5 Z D 4 e i R k g L j B Q V M u L W U 4 = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k t 6 L H g x W N F + w F t K J v t p l 2 6 2 Y T d i V J C f 4 I X D 4 p 4 9 R d 5 8 9 + 4 b X P Q 1 g c D j / d m m J k X J F I Y d N 1 v Z 2 1 9 Y 3 N r u 7 B T 3 N 3 b P z g s H R 2 3 T J x q x p s s l r H u B N R w K R R v o k D J O 4 n m N A o k b w f j m 5 n f f u T a i F g 9 4 C T h f k S H S o S C U b T S / V P f 7 Z f K b s W d g 6 w S L y d l y N H o l 7 5 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 2 I v N T y h b E y H v G u p o h E 3 f j Y / d U r O r T I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 b W f C Z W k y B V b L A p T S T A m s 7 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t O 0 Y b g L b + 8 S l r V i n d Z q d 7 V y v V a H k c B T u E M L s C D K 6 j D L T S g C Q y G 8 A y v 8 O Z I 5 8 V 5 d z 4 W r W t O P n M C f + B 8 / g A F v o 2 U &lt; / l a t e x i t &gt; ? 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S N y O 8 c 7 B 3 j g a / F b + L B U e Z 6 S 3 S N U = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l q Q Y 8 F L x 4 r 2 A 9 o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k r e N U U d a i s Y h V N 0 D N B J e s Z b g R r J s o h l E g W C e Y 3 M 7 9 z h N T m s f y w U w T 5 k c 4 k j z k F I 2 V u n 0 U y R g H 3 q B c c a v u A m S d e D m p Q I 7 m o P z V H 8 Y 0 j Z g 0 V K D W P c 9 N j J + h M p w K N i v 1 U 8 0 S p B M c s Z 6 l E i O m / W x x 7 4 x c W G V I w l j Z k o Y s 1 N 8 T G U Z a T 6 P A d k Z o x n r V m 4 v / e b 3 U h D d + x m W S G i b p c l G Y C m J i M n + e D L l i 1 I i p J U g V t 7 c S O k a F 1 N i I S j Y E b / X l d d K u V b 2 r a u 2 + X m n U 8 z i K c A b n c A k e X E M D 7 q A J L a A g 4 B l e 4 c 1 5 d F 6 c d + d j 2 V p w 8 p l T + A P n 8 w e x 6 Y + y &lt; / l a t e x i t &gt; ? ? ? &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W x c C 8 X E 4 O f l + d b n o d A 4 2 E E + / J n 8 = " &gt; A A A B + H i c b V D L S g M x F M 3 U V 6 2 P j r p 0 E y y C q z J T C 7 o s u H F Z w T 6 g H U o m k 2 l D M 8 m Q 3 B H q 0 C 9 x 4 0 I R t 3 6 K O / / G 9 A F q 6 4 F 7 O Z x z L 7 k 5 Y S q 4 A c / 7 c g o b m 1 v b O 8 X d 0 t 7 + w W H Z P T p u G 5 V p y l p U C a W 7 I T F M c M l a w E G w b q o Z S U L B O u H 4 Z u Z 3 H p g 2 X M l 7 m K Q s S M h Q 8 p h T A l Y a u O U + j R T 8 t I F b 8 a r e H H i d + E t S Q U s 0 B + 5 n P 1 I 0 S 5 g E K o g x P d 9 L I c i J B k 4 F m 5 b 6 m W E p o W M y Z D 1 L J U m Y C f L 5 4 V N 8 b p U I x 0 r b k o D n 6 u + N n C T G T J L Q T i Y E R m b V m 4 n / e b 0 M 4 u s g 5 z L N g E m 6 e C j O B A a F Z y n g i G t G Q U w s I V R z e y u m I 6 I J B Z t V y Y b g r 3 5 5 n b R r V f + y W r u r V x r 1 Z R x F d I r O 0 A X y 0 R V q o F v U R C 1 E U Y a e 0 A t 6 d R 6 d Z + f N e V + M F p z l z g n 6 A + f j G w g a k 0 k = &lt; / l a t e x i t &gt; ? ? ? &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W x c C 8 X E 4 O f l + d b n o d A 4 2 E E + / J n 8 = " &gt; A A A B + H i c b V D L S g M x F M 3 U V 6 2 P j r p 0 E y y C q z J T C 7 o s u H F Z w T 6 g H U o m k 2 l D M 8 m Q 3 B H q 0 C 9 x 4 0 I R t 3 6 K O / / G 9 A F q 6 4 F 7 O Z x z L 7 k 5 Y S q 4 A c / 7 c g o b m 1 v b O 8 X d 0 t 7 + w W H Z P T p u G 5 V p y l p U C a W 7 I T F M c M l a w E G w b q o Z S U L B O u H 4 Z u Z 3 H p g 2 X M l 7 m K Q s S M h Q 8 p h T A l Y a u O U + j R T 8 t I F b 8 a r e H H i d + E t S Q U s 0 B + 5 n P 1 I 0 S 5 g E K o g x P d 9 L I c i J B k 4 F m 5 b 6 m W E p o W M y Z D 1 L J U m Y C f L 5 4 V N 8 b p U I x 0 r b k o D n 6 u + N n C T G T J L Q T i Y E R m b V m 4 n / e b 0 M 4 u s g 5 z L N g E m 6 e C j O B A a F Z y n g i G t G Q U w s I V R z e y u m I 6 I J B Z t V y Y b g r 3 5 5 n b R r V f + y W r u r V x r 1 Z R x F d I r O 0 A X y 0 R V q o F v U R C 1 E U Y a e 0 A t 6 d R 6 d Z + f N e V + M F p z l z g n 6 A + f j G w g a k 0 k = &lt; / l a t e x i t &gt; ? 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 5 r X i h B E D S A C A q 6 u U x M c A c C v g V R Y = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l q Q Y 8 F L x 4 r 2 A 9 o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k r e N U U d a i s Y h V N 0 D N B J e s Z b g R r J s o h l E g W C e Y 3 M 7 9 z h N T m s f y w U w T 5 k c 4 k j z k F I 2 V u n 0 U y R g H 7 q B c c a v u A m S d e D m p Q I 7 m o P z V H 8 Y 0 j Z g 0 V K D W P c 9 N j J + h M p w K N i v 1 U 8 0 S p B M c s Z 6 l E i O m / W x x 7 4 x c W G V I w l j Z k o Y s 1 N 8 T G U Z a T 6 P A d k Z o x n r V m 4 v / e b 3 U h D d + x m W S G i b p c l G Y C m J i M n + e D L l i 1 I i p J U g V t 7 c S O k a F 1 N i I S j Y E b / X l d d K u V b 2 r a u 2 + X m n U 8 z i K c A b n c A k e X E M D 7 q A J L a A g 4 B l e 4 c 1 5 d F 6 c d + d j 2 V p w 8 p l T + A P n 8 w e w Z Y + x &lt; / l a t e x i t &gt; w 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " R q i f o 3 t i R M g u D 8 j f j s R 1 5 C C h P a A = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k t 6 L H g x W N F + w F t K J v t p F 2 6 2 Y T d j V J C f 4 I X D 4 p 4 9 R d 5 8 9 + 4 b X P Q 1 g c D j / d m m J k X J I J r 4 7 r f z t r 6 x u b W d m G n u L u 3 f 3 B Y O j p u 6 T h V D J s s F r H q B F S j 4 B K b h h u B n U Q h j Q K B 7 W B 8 M / P b j 6 g 0 j + W D m S T o R 3 Q o e c g Z N V a 6 f + p 7 / V L Z r b h z k F X i 5 a Q M O R r 9 0 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N h L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J u l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O 0 Y b g L b + 8 S l r V i n d Z q d 7 V y v V a H k c B T u E M L s C D K 6 j D L T S g C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r W t O P n M C f + B 8 / g A H Q o 2 V &lt; / l a t e x i t &gt; L 0 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h / d i 5 w w H G t r Z r G d L N c T d 4 y y N 3 0 o = " &gt; A A A B 9 X i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F d l Z l a 0 G X B j Q s X F e w D 2 r F k 0 k w b m k m G J K O U o f / h x o U i b v 0 X d / 6 N m X Y W 2 n o g c D j n X u 7 J C W L O t H H d b 2 d l d W 1 9 Y 7 O w V d z e 2 d 3 b L x 0 c t r R M F K F N I r l U n Q B r y p m g T c M M p 5 1 Y U R w F n L a D 8 X X m t x + p 0 k y K e z O J q R / h o W A h I 9 h Y 6 a E X Y T M i m K e 3 0 7 O + 1 y + V 3 Y o 7 A 1 o m X k 7 K k K P R L 3 3 1 B p I k E R W G c K x 1 1 3 N j 4 6 d Y G U Y 4 n R Z 7 i a Y x J m M 8 p F 1 L B Y 6 o 9 t N Z 6 i k 6 t c o A h V L Z J w y a q b 8 3 U h x p P Y k C O 5 m l 1 I t e J v 7 n d R M T X v k p E 3 F i q C D z Q 2 H C k Z E o q w A N m K L E 8 I k l m C h m s y I y w g o T Y 4 s q 2 h K 8 x S 8 v k 1 a 1 4 l 1 U q n e 1 c r 2 W 1 1 G A Y z i B c / D g E u p w A w 1 o A g E F z / A K b 8 6 T 8 + K 8 O x / z 0 R U n 3 z m C P 3 A + f w A Q o J I t &lt; / l a t e x i t &gt; L 0 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g E O P T / S W z D R T 3 a j N t W p X S a j 8 L Q w = " &gt; A A A B 9 X i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F d l Z l a 0 G X B j Q s X F e w D 2 r F k 0 k w b m k m G J K O U o f / h x o U i b v 0 X d / 6 N m X Y W 2 n o g c D j n X u 7 J C W L O t H H d b 2 d l d W 1 9 Y 7 O w V d z e 2 d 3 b L x 0 c t r R M F K F N I r l U n Q B r y p m g T c M M p 5 1 Y U R w F n L a D 8 X X m t x + p 0 k y K e z O J q R / h o W A h I 9 h Y 6 a E X Y T M i m K e 3 0 7 N + t V 8 q u x V 3 B r R M v J y U I U e j X / r q D S R J I i o M 4 V j r r u f G x k + x M o x w O i 3 2 E k 1 j T M Z 4 S L u W C h x R 7 a e z 1 F N 0 a p U B C q W y T x g 0 U 3 9 v p D j S e h I F d j J L q R e 9 T P z P 6 y Y m v P J T J u L E U E H m h 8 K E I y N R V g E a M E W J 4 R N L M F H M Z k V k h B U m x h Z V t C V 4 i 1 9 e J q 1 q x b u o V O 9 q 5 X o t r 6 M A x 3 A C 5 + D B J d T h B h r Q B A I K n u E V 3 p w n 5 8 V 5 d z 7 m o y t O v n M E f + B 8 / g A S J J I u &lt; / l a t e x i t &gt; w 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 J y e W Z 6 5 Z D 4 e i R k g L j B Q V M u L W U 4 = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k t 6 L H g x W N F + w F t K J v t p l 2 6 2 Y T d i V J C f 4 I X D 4 p 4 9 R d 5 8 9 + 4 b X P Q 1 g c D j / d m m J k X J F I Y d N 1 v Z 2 1 9 Y 3 N r u 7 B T 3 N 3 b P z g s H R 2 3 T J x q x p s s l r H u B N R w K R R v o k D J O 4 n m N A o k b w f j m 5 n f f u T a i F g 9 4 C T h f k S H S o S C U b T S / V P f 7 Z f K b s W d g 6 w S L y d l y N H o l 7 5 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 2 I v N T y h b E y H v G u p o h E 3 f j Y / d U r O r T I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 b W f C Z W k y B V b L A p T S T A m s 7 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t O 0 Y b g L b + 8 S l r V i n d Z q d 7 V y v V a H k c B T u E M L s C D K 6 j D L T S g C Q y G 8 A y v 8 O Z I 5 8 V 5 d z 4 W r W t O P n M C f + B 8 / g A F v o 2 U &lt; / l a t e x i t &gt; ? 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S N y O 8 c 7 B 3 j g a / F b + L B U e Z 6 S 3 S N U = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l q Q Y 8 F L x 4 r 2 A 9 o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k r e N U U d a i s Y h V N 0 D N B J e s Z b g R r J s o h l E g W C e Y 3 M 7 9 z h N T m s f y w U w T 5 k c 4 k j z k F I 2 V u n 0 U y R g H 3 q B c c a v u A m S d e D m p Q I 7 m o P z V H 8 Y 0 j Z g 0 V K D W P c 9 N j J + h M p w K N i v 1 U 8 0 S p B M c s Z 6 l E i O m / W x x 7 4 x c W G V I w l j Z k o Y s 1 N 8 T G U Z a T 6 P A d k Z o x n r V m 4 v / e b 3 U h D d + x m W S G i b p c l G Y C m J i M n + e D L l i 1 I i p J U g V t 7 c S O k a F 1 N i I S j Y E b / X l d d K u V b 2 r a u 2 + X m n U 8 z i K c A b n c A k e X E M D 7 q A J L a A g 4 B l e 4 c 1 5 d F 6 c d + d j 2 V p w 8 p l T + A P n 8 w e x 6 Y + y &lt; / l a t e x i t &gt; L 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 K c Z W V g y a q t w 1 O 1 R v j k N 0 C o I M O Q = " &gt; A A A B 9 H i c b V D L S g M x F L 2 p r 1 p f V Z d u g k V w V W Z q Q Z c F N y 5 c V L A P a I e S S T N t a C Y z J p l C G f o d b l w o 4 t a P c e f f m G l n o a 0 H A o d z 7 u W e H D 8 W X B v H + U a F j c 2 t 7 Z 3 i b m l v / + D w q H x 8 0 t Z R o i h r 0 U h E q u s T z Q S X r G W 4 E a w b K 0 Z C X 7 C O P 7 n N / M 6 U K c 0 j + W h m M f N C M p I 8 4 J Q Y K 3 n 9 k J g x J S K 9 n w / c Q b n i V J 0 F 8 D p x c 1 K B H M 1 B + a s / j G g S M m m o I F r 3 X C c 2 X k q U 4 V S w e a m f a B Y T O i E j 1 r N U k p B p L 1 2 E n u M L q w x x E C n 7 p M E L 9 f d G S k K t Z 6 F v J 7 O Q e t X L x P + 8 X m K C G y / l M k 4 M k 3 R 5 K E g E N h H O G s B D r h g 1 Y m Y J o Y r b r J i O i S L U 2 J 5 K t g R 3 9 c v r p F 2 r u l f V 2 k O 9 0 q j n d R T h D M 7 h E l y 4 h g b c Q R N a Q O E J n u E V 3 t A U v a B 3 9 L E c L a B 8 5 x T + A H 3 + A K u x k f w = &lt; / l a t e x i t &gt; w k 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y o 6 r U v Y z P G T S T g a x R g l r 7 K O 7 8 x w = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W p g h 4 L X j x W s B / Q h r L Z b t q l m 0 3 Y n S g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 7 8 9 i P X R s T q A S c J 9 y M 6 V C I U j K K V 2 k / 9 b H z h T f v l i l t 1 5 y C r x M t J B X I 0 + u W v 3 i B m a c Q V M k m N 6 X p u g n 5 G N Q o m + b T U S w 1 P K B v T I e 9 a q m j E j Z / N z 5 2 S M 6 s M S B h r W w r J X P 0 9 k d H I m E k U 2 M 6 I 4 s g s e z P x P 6 + b Y n j j Z 0 I l K X L F F o v C V B K M y e x 3 M h C a M 5 Q T S y j T w t 5 K 2 I h q y t A m V L I h e M s v r 5 J W r e p d V m v 3 V 5 V 6 L Y + j C C d w C u f g w T X U 4 Q 4 a 0 A Q G Y 3 i G V 3 h z E u f F e X c + F q 0 F J 5 8 5 h j 9 w P n 8 A / 8 K P S w = = &lt; / l a t e x i t &gt; w k &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O d P 5 D a A O I j b Z 4 f u O O n e f 8 d V 5 B H Y = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j w 4 r G C a Q t t K J v t p l 2 6 2 Y T d i V J C f 4 M X D 4 p 4 9 Q d 5 8 9 + 4 b X P Q 1 g c D j / d m m J k X p l I Y d N 1 v Z 2 1 9 Y 3 N r u 7 R T 3 t 3 b P z i s H B 2 3 T J J p x n 2 W y E R 3 Q m q 4 F I r 7 K F D y T q o 5 j U P J 2 + H 4 d u a 3 H 7 k 2 I l E P O E l 5 E N O h E p F g F K 3 k P / X z 8 b R f q b o 1 d w 6 y S r y C V K F A s 1 / 5 6 g 0 S l s V c I Z P U m K 7 n p h j k V K N g k k / L v c z w l L I x H f K u p Y r G 3 A T 5 / N g p O b f K g E S J t q W Q z N X f E z m N j Z n E o e 2 M K Y 7 M s j c T / / O 6 G U Y 3 Q S 5 U m i F X b L E o y i T B h M w + J w O h O U M 5 s Y Q y L e y t h I 2 o p g x t P m U b g r f 8 8 i p p 1 W v e Z a 1 + f 1 V t 1 I s 4 S n A K Z 3 A B H l x D A + 6 g C T 4 w E P A M r / D m K O f F e X c + F q 1 r T j F z A n / g f P 4 A I 2 2 O 2 Q = = &lt; / l a t e x i t &gt; L 0 k &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j j r F G S s C I I k r 8 l b 6 s H Q m z d y Y D i 0 = " &gt; A A A B + X i c b V D L S s N A F L 3 x W e s r 6 t L N Y B F d l a Q K u i y 4 c e G i g n 1 A G 8 J k O m m H T i Z h Z l I o I X / i x o U i b v 0 T d / 6 N k z Y L b T 0 w c D j n X u 6 Z E y S c K e 0 4 3 9 b a + s b m 1 n Z l p 7 q 7 t 3 9 w a B 8 d d 1 S c S k L b J O a x 7 A V Y U c 4 E b W u m O e 0 l k u I o 4 L Q b T O 4 K v z u l U r F Y P O l Z Q r 0 I j w Q L G c H a S L 5 t D y K s x w T z 7 C H 3 s 0 l + 4 d s 1 p + 7 M g V a J W 5 I a l G j 5 9 t d g G J M 0 o k I T j p X q u 0 6 i v Q x L z Q i n e X W Q K p p g M s E j 2 j d U 4 I g q L 5 s n z 9 G 5 U Y Y o j K V 5 Q q O 5 + n s j w 5 F S s y g w k 0 V O t e w V 4 n 9 e P 9 X h r Z c x k a S a C r I 4 F K Y c 6 R g V N a A h k 5 R o P j M E E 8 l M V k T G W G K i T V l V U 4 K 7 / O V V 0 m n U 3 a t 6 4 / G 6 1 m y U d V T g F M 7 g E l y 4 g S b c Q w v a Q G A K z / A K b 1 Z m v V j v 1 s d i d M 0 q d 0 7 g D 6 z P H 6 5 F k 6 I = &lt; / l a t e x i t &gt; Different bi-level optimization learning strategies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 4 :</head><label>4</label><figDesc>WN &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H h Q 5 0 R n f c R w u P N e G t x + 9 z m j G m 1 E = " &gt; A A A B 6 X i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 5 i Y c q A j Z V E M R + Q H G F v M 5 c s 2 d s 7 d v e E c O Q f 2 F g o Y u s / s v P f u E m u 0 M Q H A 4 / 3 Z p i Z F y S C a + O 6 3 0 5 h Y 3 N r e 6 e 4 W 9 r b P z g 8 K h + f t H W c K o Y t F o t Y d Q O q U X C J L c O N w G 6 i k E a B w E 4 w u Z n 7 n S d U m s f y 0 U w T 9 C M 6 k j z k j B o r P X T u B u W K W 3 U X I O v E y 0 k F c j Q H 5 a / + M G Z p h N I w Q b X u e W 5 i / I w q w 5 n A W a m f a k w o m 9 A R 9 i y V N E L t Z 4 t L Z + T C K k M S x s q W N G S h / p 7 I a K T 1 N A p s Z 0 T N W K 9 6 c / E / r 5 e a s O 5 n X C a p Q c m W i 8 J U E B O T + d t k y B U y I 6 a W U K a 4 v Z W w M V W U G R t O y Y b g r b 6 8 T t q 1 q n d V r d 3 X K o 1 6 H k c R z u A c L s G D a 2 j A L T S h B Q x C e I Z X e H M m z o v z 7 n w s W w t O P n M K f + B 8 / g B N Y 4 0 r &lt; / l a t e x i t &gt; h(x) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b d R n o L N I / O X J C g d P c k G e Y y M z v 9 g = " &gt; A A A B 9 H i c b V D L S s N A F L 2 p r 1 p f V Z d u B o t Q N y W p o i 4 L b l x W s A 9 o Q 5 l M J + 3 Q y S T O T I o l 9 D v c u F D E r R / j z r 9 x k m a h r Q c G D u f c y z 1 z v I g z p W 3 7 2 y q s r W 9 s b h W 3 S z u 7 e / s H 5 c O j t g p j S W i L h D y U X Q 8 r y p m g L c 0 0 p 9 1 I U h x 4 n H a 8 y W 3 q d 6 Z U K h a K B z 2 L q B v g k W A + I 1 g b y R 1 X + w H W Y 8 9 P n u b n g 3 L F r t k Z 0 C p x c l K B H M 1 B + a s / D E k c U K E J x 0 r 1 H D v S b o K l Z o T T e a k f K x p h M s E j 2 j N U 4 I A q N 8 l C z 9 G Z U Y b I D 6 V 5 Q q N M / b 2 R 4 E C p W e C Z y T S i W v Z S 8 T + v F 2 v / x k 2 Y i G J N B V k c 8 m O O d I j S B t C Q S U o 0 n x m C i W Q m K y J j L D H R p q e S K c F Z / v I q a d d r z k W t f n 9 Z a V z l d R T h B E 6 h C g 5 c Q w P u o A k t I P A I z / A K b 9 b U e r H e r Y / F a M H K d 4 7 h D 6 z P H 4 0 r k e s = &lt; / l a t e x i t &gt; loss &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " D 9 y o f L t E D n S O h V b z Q c F i E 2 e H 5 N 4 = " &gt; A A A B 6 3 i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e x G U I 8 B L x 4 j m A c k S 5 i d z C Z D 5 r H M z A p h y S 9 4 8 a C I V 3 / I m 3 / j b L I H T S x o K K q 6 6 e 6 K E s 6 M 9 f 1 v r 7 S x u b W 9 U 9 6 t 7 O 0 f H B 5 V j 0 8 6 R q W a 0 D Z R X O l e h A 3 l T N K 2 Z Z b T X q I p F h G n 3 W h 6 l / v d J 6 o N U / L R z h I a C j y W L G Y E 2 1 z i y p h h t e b X / Q X Q O g k K U o M C r W H 1 a z B S J B V U W s K x M f 3 A T 2 y Y Y W 0 Z 4 X R e G a S G J p h M 8 Z j 2 H Z V Y U B N m i 1 v n 6 M I p I x Q r 7 U p a t F B / T 2 R Y G D M T k e s U 2 E 7 M q p e L / 3 n 9 1 M a 3 Y c Z k k l o q y X J R n H J k F c o f R y O m K b F 8 5 g g m m r l b E Z l g j Y l 1 8 V R c C M H q y + u k 0 6 g H V / X G Q 6 P W v C 7 i K M M Z n M M l B H A D T b i H F r S B w A S e 4 R X e P O G 9 e O / e x 7 K 1 5 B U z p / A H 3 u c P R 2 O O W Q = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n Gq G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n Gq G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P M M V A j 5 6 C w S F / 6 g a 4 o t p 5 I g d j p w = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U 9 A a l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 Xa k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A e O m M r w = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; ! &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " i a N i 8 b 2 i 2 j O Q o i T 2 G C m F / K E v F S k = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e x G w R w D X j x G M A 9 I l j A 7 m U 3 G z G O Z m R X C k n / w 4 k E R r / 6 P N / / G S b I H T S x o K K q 6 6 e 6 K E s 6 M 9 f 1 v r 7 C x u b W 9 U 9 w t 7 e 0 f H B 6 V j 0 / a R q W a 0 B Z R X O l u h A 3 l T N K W Z Z b T b q I p F h G n n W h y O / c 7 T 1 Q b p u S D n S Y 0 F H g k W c w I t k 5 q 9 5 W g I z w o V / y q v w B a J 0 F O K p C j O S h / 9 Y e K p I J K S z g 2 p h f 4 i Q 0 z r C 0 j n M 5 K / d T Q B J M J H t G e o x I L a s J s c e 0 M X T h l i G K l X U m L F u r v i Q w L Y 6 Y i c p 0 C 2 7 F Z 9 e b i f 1 4 v t X E 9 z J h M U k s l W S 6 K U 4 6 s Q v P X 0 Z B p S i y f O o K J Z u 5 W R M Z Y Y 2 J d Q C U X Q r D 6 8 j p p 1 6 r B V b V 2 f 1 1 p 1 P M 4 i n A G 5 3 A J A d x A A + 6 g C S 0 g 8 A j P 8 A p v n v J e v H f v Y 9 l a 8 P K Z U / g D 7 / M H j n 2 P F Q = = &lt; / l a t e x i t &gt; (a) Weighting-Network (WN) in Meta-WN (Shu et al. 2019) LCN &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 5 q u q U x S u 2 Y + M L u Z I p O P m k N F z Z I I = " &gt; A A A B 6 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 5 i Y c p A G g u R i O Y D k i P s b f a S J X t 7 x + 6 c E E J + g o 2 F I r b + I j v / j Z v k C k 1 8 M P B 4 b 4 a Z e U E i h U H X / X Z y G 5 t b 2 z v 5 3 c L e / s H h U f H 4 p G X i V D P e Z L G M d S e g h k u h e B M F S t 5 J N K d R I H k 7 G N f n f v u J a y N i 9 Y i T h P s R H S o R C k b R S g + 3 9 b t + s e S W 3 Q X I O v E y U o I M j X 7 x q z e I W R p x h U x S Y 7 q e m 6 A / p R o F k 3 x W 6 K W G J 5 S N 6 Z B 3 L V U 0 4 s a f L k 6 d k Q u r D E g Y a 1 s K y U L 9 P T G l k T G T K L C d E c W R W f X m 4 n 9 e N 8 W w 6 k + F S l L k i i 0 X h a k k G J P 5 3 2 Q g N G c o J 5 Z Q p o W 9 l b A R 1 Z S h T a d g Q / B W X 1 4 n r U r Z u y p X 7 i u l W j W L I w 9 n c A 6 X 4 M E 1 1 O A G G t A E B k N 4 h l d 4 c 6 T z 4 r w 7 H 8 v W n J P N n M I f O J 8 / x 6 2 N b Q = = &lt; / l a t e x i t &gt; ! 4 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " X V R X J o D r F u I v j T 2 U Y 7 y 6 P R Y W z a w = " &gt; A A A B 7 3 i c b V D L S g N B E J z 1 G e M r 6 t H L Y B A 8 h d 0 Y 1 G P A i 8 c I 5 g H J E m Y n v c m Q e a w z s 0 J Y 8 h N e P C j i 1 d / x 5 t 8 4 S f a g i Q U N R V U 3 3 V 1 R w p m x v v / t r a 1 v b G 5 t F 3 a K u 3 v 7 B 4 e l o + O W U a m m 0 K S K K 9 2 J i A H O J D Q t s x w 6 i Q Y i I g 7 t a H w 7 8 9 t P o A 1 T 8 s F O E g g F G U o W M 0 q s k z o 9 J W B I + r V + q e x X / D n w K g l y U k Y 5 G v 3 S V 2 + g a C p A W s q J M d 3 A T 2 y Y E W 0 Z 5 T A t 9 l I D C a F j M o S u o 5 I I M G E 2 v 3 e K z 5 0 y w L H S r q T F c / X 3 R E a E M R M R u U 5 B 7 M g s e z P x P 6 + b 2 v g m z J h M U g u S L h b F K c d W 4 d n z e M A 0 U M s n j h C q m b s V 0 x H R h F o X U d G F E C y / v E p a 1 U p w W a n e 1 8 r 1 q z y O A j p F Z + g C B e g a 1 d E d a q A m o o i j Z / S K 3 r x H 7 8 V 7 9 z 4 W r W t e P n O C / s D 7 / A G 7 x Y + 6 &lt; / l a t e x i t &gt; ! 5 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " I W G w L E b g M q 8 h n A f M e i 2 s + W h z b A E = " &gt; A A A B 7 3 i c b V D J S g N B E K 1 x j X G L e v T S G A R P Y S a u x 4 A X j x H M A s k Q e j o 9 S Z N e x u 4 e I Q z 5 C S 8 e F P H q 7 3 j z b + w k c 9 D E B w W P 9 6 q o q h c l n B n r + 9 / e y u r a + s Z m Y a u 4 v b O 7 t 1 8 6 O G w a l W p C G 0 R x p d s R N p Q z S R u W W U 7 b i a Z Y R J y 2 o t H t 1 G 8 9 U W 2 Y k g 9 2 n N B Q 4 I F k M S P Y O q n d V Y I O c O + y V y r 7 F X 8 G t E y C n J Q h R 7 1 X + u r 2 F U k F l Z Z w b E w n 8 B M b Z l h b R j i d F L u p o Q k m I z y g H U c l F t S E 2 e z e C T p 1 S h / F S r u S F s 3 U 3 x M Z F s a M R e Q 6 B b Z D s + h N x f + 8 T m r j m z B j M k k t l W S + K E 4 5 s g p N n 0 d 9 p i m x f O w I J p q 5 W x E Z Y o 2 J d R E V X Q j B 4 s v L p F m t B O e V 6 v 1 F u X a V x 1 G A Y z i B M w j g G m p w B 3 V o A A E O z / A K b 9 6 j 9 + K 9 e x / z 1 h U v n z m C P / A + f w C 9 S Y + 7 &lt; / l a t e x i t &gt; ! 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " a N j H C f U r j A r X P I u V 5 D r 7 a W g e N o E = " &gt; A A A B 7 3 i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e x G U Y 8 B L x 4 j m A c k S 5 i d z C Z D 5 r H O z A p h y U 9 4 8 a C I V 3 / H m 3 / j J N m D J h Y 0 F F X d d H d F C W f G + v 6 3 V 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t o 1 J N a J M o r n Q n w o Z y J m n T M s t p J 9 E U i 4 j T d j S + n f n t J 6 o N U / L B T h I a C j y U L G Y E W y d 1 e k r Q I e 4 H / X L F r / p z o F U S 5 K Q C O R r 9 8 l d v o E g q q L S E Y 2 O 6 g Z / Y M M P a M s L p t N R L D U 0 w G e M h 7 T o q s a A m z O b 3 T t G Z U w Y o V t q V t G i u / p 7 I s D B m I i L X K b A d m W V v J v 7 n d V M b 3 4 Q Z k 0 l q q S S L R X H K k V V o 9 j w a M E 2 J 5 R N H M N H M 3 Y r I C G t M r I u o 5 E I I l l 9 e J a 1 a N b i o 1 u 4 v K / W r P I 4 i n M A p n E M A 1 1 C H O 2 h A E w h w e I Z X e P M e v R f v 3 f t Y t B a 8 f O Y Y / s D 7 / A G 3 O Y + 3 &lt; / l a t e x i t &gt; ! 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P 0 x 7 g A T c v 1 g n l o p L R z Y 6 t u r e q b 0 = " &gt; A A A B 7 3 i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e x G U Y 8 B L x 4 j m A c k S 5 i d z C Z D 5 r H O z A p h y U 9 4 8 a C I V 3 / H m 3 / j J N m D J h Y 0 F F X d d H d F C W f G + v 6 3 V 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t o 1 J N a J M o r n Q n w o Z y J m n T M s t p J 9 E U i 4 j T d j S + n f n t J 6 o N U / L B T h I a C j y U L G Y E W y d 1 e k r Q I e 7 X + u W K X / X n Q K s k y E k F c j T 6 5 a / e Q J F U U G k J x 8 Z 0 A z + x Y Y a 1 Z Y T T a a m X G p p g M s Z D 2 n V U Y k F N m M 3 v n a I z p w x Q r L Q r a d F c / T 2 R Y W H M R E S u U 2 A 7 M s v e T P z P 6 6 Y 2 v g k z J p P U U k k W i + K U I 6 v Q 7 H k 0 Y J o S y y e O Y K K Z u x W R E d a Y W B d R y Y U Q L L + 8 S l q 1 a n B R r d 1 f V u p X e R x F O I F T O I c A r q E O d 9 C A J h D g 8 A y v 8 O Y 9 e i / e u / e x a C 1 4 + c w x / I H 3 + Q O 4 v Y + 4 &lt; / l a t e x i t &gt; ! 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b e 7 C n o u R 5 G j W 4 a W K + E f 7 0 O x P y 1 g = " &gt; A A A B 7 3 i c b V D L S g N B E J z 1 G e M r 6 t H L Y B A 8 h d 1 E 1 G P A i 8 c I 5 g H J E m Y n v c m Q e a w z s 0 J Y 8 h N e P C j i 1 d / x 5 t 8 4 S f a g i Q U N R V U 3 3 V 1 R w p m x v v / t r a 1 v b G 5 t F 3 a K u 3 v 7 B 4 e l o + O W U a m m 0 K S K K 9 2 J i A H O J D Q t s x w 6 i Q Y i I g 7 t a H w 7 8 9 t P o A 1 T 8 s F O E g g F G U o W M 0 q s k z o 9 J W B I + r V + q e x X / D n w K g l y U k Y 5 G v 3 S V 2 + g a C p A W s q J M d 3 A T 2 y Y E W 0 Z 5 T A t 9 l I D C a F j M o S u o 5 I I M G E 2 v 3 e K z 5 0 y w L H S r q T F c / X 3 R E a E M R M R u U 5 B 7 M g s e z P x P 6 + b 2 v g m z J h M U g u S L h b F K c d W 4 d n z e M A 0 U M s n j h C q m b s V 0 x H R h F o X U d G F E C y / v E p a 1 U p Q q 1 T v L 8 v 1 q z y O A j p F Z + g C B e g a 1 d E d a q A m o o i j Z / S K 3 r x H 7 8 V 7 9 z 4 W r W t e P n O C / s D 7 / A G 6 Q Y + 5 &lt; / l a t e x i t &gt; h(x) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b d R n o L N I / O X J C g d P c k G e Y y M z v 9 g = " &gt; A A A B 9 H i c b V D L S s N A F L 2 p r 1 p f V Z d u B o t Q N y W p o i 4 L b l x W s A 9 o Q 5 l M J + 3 Q y S T O T I o l 9 D v c u F D E r R / j z r 9 x k m a h r Q c G D u f c y z 1 z v I g z p W 3 7 2 y q s r W 9 s b h W 3 S z u 7 e / s H 5 c O j t g p j S W i L h D y U X Q 8 r y p m g L c 0 0 p 9 1 I U h x 4 n H a 8 y W 3 q d 6 Z U K h a K B z 2 L q B v g k W A + I 1 g b y R 1 X + w H W Y 8 9 P n u b n g 3 L F r t k Z 0 C p x c l K B H M 1 B + a s / D E k c U K E J x 0 r 1 H D v S b o K l Z o T T e a k f K x p h M s E j 2 j N U 4 I A q N 8 l C z 9 G Z U Y b I D 6 V 5 Q q N M / b 2 R 4 E C p W e C Z y T S i W v Z S 8 T + v F 2 v / x k 2 Y i G J N B V k c 8 m O O d I j S B t C Q S U o 0 n x m C i W Q m K y J j L D H R p q e S K c F Z / v I q a d d r z k W t f n 9 Z a V z l d R T h B E 6 h C g 5 c Q w P u o A k t I P A I z / A K b 9 b U e r H e r Y / F a M H K d 4 7 h D 6 z P H 4 0 r k e s = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 S P v T V / z 8 o I h j l R i K d 5 9 o q P v b V Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U d A e l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A d 2 W M r g = = &lt; / l a t e x i t &gt; 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P M M V A j 5 6 C w S F / 6 g a 4 o t p 5 I g d j p w = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 7 L H g x W M L 9 g P a U D b b S b t 2 s w m 7 G 6 G E / g I v H h T x 6 k / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k b u 5 3 n l B p H s s H M 0 3 Q j + h I 8 p A z a q z U 9 A a l s l t x F y D r x M t J G X I 0 B q W v / j B m a Y T S M E G 1 7 n l u Y v y M K s O Z w F m x n 2 p M K J v Q E f Y s l T R C 7 W e L Q 2 f k 0 i p D E s b K l j R k o f 6 e y G i k 9 T Q K b G d E z V i v e n P x P 6 + X m r D m Z 1 w m q U H J l o v C V B A T k / n X Z M g V M i O m l l C m u L 2 V s D F V l B m b T d G G 4 K 2 + v E 7 a 1 Y p 3 X a k 2 b 8 r 1 W h 5 H A c 7 h A q 7 A g 1 u o w z 0 0 o A U M E J 7 h F d 6 c R + f F e X c + l q 0 b T j 5 z B n / g f P 4 A e O m M r w = = &lt; / l a t e x i t &gt; (b) Label Correction Network (LCN) in MLC (Ours) Different treatments of noisy labels from Meta-WN and MLC. Total number of classes assumed to be 5 for illustration purpose. (a) Meta-WN; (b) MLC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 6 :</head><label>6</label><figDesc>(a) Heatmap of learned weights of MW-Net w.r.t to the true labels; note that MW-Net does not alter the noisy labels but only assigns them weight. (b) Heatmap of probability distribution of the corrected labels of MLC w.r.t to the true labels; note that MLC can alter the input label (For all examples in the test set with noise level ? = 0.6.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Effect of reweighting vs correction for FLIP with ? = 0.6. (Left) Weights assigned by MW-Net w.r.t to the input noisy label; (Right) Correction probabilities learned by LCN to the input noisy label. (a,b,c) Loss and test set accuracy dynamics w.r.t noise levels (losses are in log-scale). The two jump-points in the curves are due to the decay of learning rates at 60th and 80th Epoch, or ? 40K and 50K steps equivalently.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Dataset statistics and classifier architectures used. Note the clean set is significantly smaller than the noisy label set.</figDesc><table><row><cell>Datasets</cell><cell cols="2">CIFAR-10 CIFAR-100</cell><cell>AG</cell><cell>Yelp-5</cell><cell>Amazon-5</cell><cell>Yahoo</cell></row><row><cell>(# clean labels)</cell><cell>(10 ? 100)</cell><cell>(100 ? 10)</cell><cell cols="2">(4 ? 100) (5 ? 100)</cell><cell>(5 ? 100)</cell><cell>(10 ? 100)</cell></row><row><cell>MW-Net (Shu et al. 2019)</cell><cell>65.12</cell><cell>39.96</cell><cell>75.91</cell><cell>51.27</cell><cell>49.49</cell><cell>60.18</cell></row><row><cell>GLC (Hendrycks et al. 2018)</cell><cell>86.62</cell><cell>50.50</cell><cell>83.88</cell><cell>60.12</cell><cell>60.31</cell><cell>68.03</cell></row><row><cell>MLC (Ours)</cell><cell>86.81</cell><cell>53.68</cell><cell>85.27</cell><cell>62.61</cell><cell>61.21</cell><cell>73.72</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Mean accuracies on all data sets. Each cell represents the average runs over two noise types and 10 noise levels. A k = 5 (5-step ahead SGD) is used for all experiment. (Each configuration is run for 5 times and the mean is reported)<ref type="bibr" target="#b24">Patrini et al. 2017</ref>)<ref type="bibr" target="#b33">(Tanaka et al. 2018</ref>)<ref type="bibr" target="#b16">(Li et al. 2019</ref>)<ref type="bibr" target="#b31">(Shu et al. 2019</ref>)(Hendrycks et al. 2018) (Ours)    </figDesc><table><row><cell>Method</cell><cell>Forward</cell><cell>Joint Learning</cell><cell>MLNT</cell><cell>MW-Net</cell><cell>GLC</cell><cell>MLC</cell></row><row><cell>(Accuracy</cell><cell>69.84</cell><cell>72.23</cell><cell>73.47</cell><cell>73.72</cell><cell>73.69</cell><cell>75.78</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Test set accuracies on Clothing1M with real-world noisy labels (k = 5)</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that cross-entropy loss also works with soft labels in the lower-level optimization of Problem(1)2 For clarity, we derive this with plain SGD, however this also holds for most variants of SGD, including SGD with momentum, Adam<ref type="bibr" target="#b13">(Kingma and Ba 2014)</ref>.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning from untrusted data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Charikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing</title>
		<meeting>the 49th Annual ACM SIGACT Symposium on Theory of Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="47" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01781</idno>
		<title level="m">Very deep convolutional networks for text classification</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Transformer-xl: Attentive language models beyond a fixed-length context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.02860</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rethinking Importance Weighting for Deep Learning under Distribution Shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<ptr target="JMLR.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fr?nay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="845" to="869" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Training deep neural-networks using a noise adaptation layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ben-Reuven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Masking: A new perspective of noisy supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="5836" to="5846" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8527" to="8537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using trusted data to train deep networks on labels corrupted by severe noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10477" to="10486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.05055</idno>
		<title level="m">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Design of robust neural network classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nonboe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hintz-Madsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP&apos;98 (Cat. No. 98CH36181)</title>
		<meeting>the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP&apos;98 (Cat. No. 98CH36181)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1205" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to learn from noisy labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5051" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning From Noisy Labels With Distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Gradientbased hyperparameter optimization through reversible learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2113" to="2122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to label aerial images from noisy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International conference on machine learning</title>
		<meeting>the 29th International conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="567" to="574" />
		</imprint>
	</monogr>
	<note>ICML-12</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1196" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A study of the effect of different types of noise on the precision of supervised learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Nettleton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Orriols-Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fornells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence review</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="275" to="306" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishna Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1944" to="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02355</idno>
		<title level="m">Hyperparameter optimization with approximate gradient</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10580</idno>
		<title level="m">Meta pseudo labels</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06732</idno>
		<title level="m">Sequence level training with recurrent neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Optimization as a Model for Few-Shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to Reweight Examples for Robust Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4334" to="4343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Meta-weight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1917" to="1928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2080</idno>
		<title level="m">Training convolutional networks with noisy labels</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5552" to="5560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning from noisy large-scale datasets with minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Alldrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chechik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Krasin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="839" to="847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Part-dependent label noise: Towards instance-dependent label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Are Anchor Points Really Indispensable in Label-Noise Learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6838" to="6849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12848</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Hierarchical attention networks for document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies</title>
		<meeting>the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dual T: Reducing estimation error for transition matrix in label-noise learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">How does Disagreement Help Generalization against Label Corruption?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7164" to="7173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="649" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A brief introduction to weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">National Science Review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="53" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
