<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PointMixup: Augmentation for Point Clouds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunlu</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">Tao</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efstratios</forename><surname>Gavves</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mensink</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Google Research</orgName>
								<address>
									<settlement>Amsterdam</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Mettes</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengwan</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cees</forename><forename type="middle">G M</forename><surname>Snoek</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PointMixup: Augmentation for Point Clouds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T11:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>interpolation</term>
					<term>point cloud classification</term>
					<term>data augmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper introduces data augmentation for point clouds by interpolation between examples. Data augmentation by interpolation has shown to be a simple and effective approach in the image domain. Such a mixup is however not directly transferable to point clouds, as we do not have a one-to-one correspondence between the points of two different objects. In this paper, we define data augmentation between point clouds as a shortest path linear interpolation. To that end, we introduce PointMixup, an interpolation method that generates new examples through an optimal assignment of the path function between two point clouds. We prove that our PointMixup finds the shortest path between two point clouds and that the interpolation is assignment invariant and linear. With the definition of interpolation, PointMixup allows to introduce strong interpolation-based regularizers such as mixup and manifold mixup to the point cloud domain. Experimentally, we show the potential of PointMixup for point cloud classification, especially when examples are scarce, as well as increased robustness to noise and geometric transformations to points. The code for PointMixup and the experimental details are publicly available 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of this paper is to classify a cloud of points into their semantic category, be it an airplane, a bathtub or a chair. Point cloud classification is challenging, as they are sets and hence invariant to point permutations. Building on the pioneering PointNet by Qi et al. <ref type="bibr" target="#b14">[15]</ref>, multiple works have proposed deep learning solutions to point cloud classification <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr">29,</ref><ref type="bibr">30,</ref><ref type="bibr">36,</ref><ref type="bibr">23]</ref>. Given the progress in point cloud network architectures, as well as the importance of data augmentation in improving classification accuracy and robustness, we study how could data augmentation be naturally extended to support also point cloud data, especially considering the often smaller size of point clouds datasets (e.g. ModelNet40 <ref type="bibr">[31]</ref>). In this work, we propose point cloud data augmentation by interpolation of existing training point clouds. <ref type="figure">Fig. 1</ref>: Interpolation between point clouds. We show the interpolation between examples from different classes (airplane/chair, and monitor/bathtub) with multiple ratios ?. The interpolants are learned to be classified as (1 ? ?) the first class and ? the second class. The interpolation is not obtained by learning, but induced by solving the optimal bijective correspondence which allows the minimum overall distance that each point in one point cloud moves to the assigned point in the other point cloud.</p><p>To perform data augmentation by interpolation, we take inspiration from augmentation in the image domain. Several works have shown that generating new training examples, by interpolating images and their corresponding labels, leads to improved network regularization and generalization, e.g., <ref type="bibr" target="#b7">[8,</ref><ref type="bibr">24,</ref><ref type="bibr">34,</ref><ref type="bibr">26]</ref>. Such a mixup is feasible in the image domain, due to the regular structure of images and one-to-one correspondences between pixels. However, this setup does not generalize to the point cloud domain, since there is no one-to-one correspondence and ordering between points. To that end, we seek to find a method to enable interpolation between permutation invariant point sets.</p><p>In this work, we make three contributions. First, we introduce data augmentation for point clouds through interpolation and we define the augmentation as a shortest path interpolation. Second, we propose PointMixup, an interpolation between point clouds that computes the optimal assignment as a path function between two point clouds, or the latent representations in terms of point cloud. The proposed interpolation strategy therefore allows usage of successful regularizers of Mixup and Manifold Mixup [26] on point cloud. We prove that (i ) our PointMixup indeed finds the shortest path between two point clouds; (ii ) the assignment does not change for any pairs of the mixed point clouds for any interpolation ratio; and (iii ) our PointMixup is a linear interpolation, an important property since labels are also linearly interpolated. <ref type="figure">Figure 1</ref> shows two pairs of point clouds, along with our interpolations. Third, we show the empirical benefits of our data augmentation across various tasks, including classification, few-shot learning, and semi-supervised learning. We furthermore show that our approach is agnostic to the network used for classification, while we also become more robust to noise and geometric transformations to the points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Deep learning for point clouds. Point clouds are unordered sets and hence early works focus on analyzing equivalent symmetric functions which ensures permutation invariance. <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr">33]</ref>. The pioneering PointNet work by Qi et al. <ref type="bibr" target="#b14">[15]</ref> presented the first deep network that operates directly on unordered point sets. It learns the global feature with shared multi-layer perceptions and a max pooling operation to ensure permutation invariance. PointNet++ <ref type="bibr" target="#b15">[16]</ref> extends this idea further with hierarchical structure by relying on a heuristic method of farthest point sampling and grouping to build the hierarchy. Likewise, other recent methods follow to learn hierarchical local features either by grouping points in various manners <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr">29,</ref><ref type="bibr">30,</ref><ref type="bibr">32,</ref><ref type="bibr">36,</ref><ref type="bibr">23]</ref>. Li et al. <ref type="bibr" target="#b11">[12]</ref> propose to learn a transformation from the input points to simultaneously solve the weighting of input point features and permutation of points into a latent and potentially canonical order. Xu et al.</p><p>[32] extends 2D convolution to 3D point clouds by parameterizing a family of convolution filters. Wang et al. <ref type="bibr">[29]</ref> proposed to leverage neighborhood structures in both point and feature spaces.</p><p>In this work, we aim to improve point cloud classification for any point-based approach. To that end, we propose a new model-agnostic data augmentation. We propose a Mixup regularization for point clouds and show that it can build on various architectures to obtain better classification results by reducing the generalization error in classification tasks. A very recent work by Li et al. <ref type="bibr" target="#b10">[11]</ref> also considers improving point cloud classification by augmentation. They rely on auto-augmentation and a complicated adversarial training procedure, whereas in this work we propose to augment point clouds by interpolation.</p><p>Interpolation-based regularization. Employing regularization approaches for training deep neural networks to improve their generalization performances have become standard practice in deep learning. Recent works consider a regularization by interpolating the example and label pairs, commonly known as Mixup <ref type="bibr">[24,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr">34</ref>]. Manifold Mixup [26] extends Mixup by interpolating the hidden representations at multiple layers. Recently, an effort has been made on applying Mixup to various tasks such as object detection <ref type="bibr">[35]</ref> and segmentation <ref type="bibr" target="#b6">[7]</ref>. Different from existing works, which are predominantly employed in the image domain, we propose a new optimal assignment Mixup paradigm for point clouds, in order to deal with their permutation-invariant nature.</p><p>Recently, Mixup [34] has also been investigated from a semi-supervised learning perspective <ref type="bibr">[3,</ref><ref type="bibr">27,</ref><ref type="bibr">2]</ref>. Mixmatch <ref type="bibr">[3]</ref> guesses low-entropy labels for unlabelled data-augmented examples and mixes labelled and unlabelled data using Mixup <ref type="bibr">[34]</ref>. Interpolation Consistency Training [27] utilizes the consistency constraint between the interpolation of unlabelled points with the interpolation of the predictions at those points. In this work, we show that our PointMixup can be integrated in such frameworks to enable semi-supervised learning for point clouds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Point cloud augmentation by interpolation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem setting</head><p>In our setting, we are given a training set {(S m , c m )} M m=1 consisting of M point clouds. S m = {p m n } N n=1 ? S is a point cloud consisting of N points, p m n ? R 3 is the 3D point, S is the set of such 3D point clouds with N elements. c m ? {0, 1} C is the one-hot class label for a total of C classes. The goal is to train a function h : S ? [0, 1] C that learns to map a point cloud to a semantic label distribution. Throughout our work, we remain agnostic to the type of function h used for the mapping and we focus on data augmentation to generate new examples.</p><p>Data augmentation is an integral part of training deep neural networks, especially when the size of the training data is limited compared to the size of the model parameters. A popular data augmentation strategy is Mixup <ref type="bibr">[34]</ref>. Mixup performs augmentation in the image domain by linearly interpolating pixels, as well as labels. Specifically, let I 1 ? R W ?H?3 and I 2 ? R W ?H?3 denote two images. Then a new image and its label are generated as:</p><formula xml:id="formula_0">I mix (?) = (1 ? ?) ? I 1 + ? ? I 2 ,<label>(1)</label></formula><formula xml:id="formula_1">c mix (?) = (1 ? ?) ? c 1 + ? ? c 2 ,<label>(2)</label></formula><p>where ? ? [0, 1] denotes the mixup ratio. Usually ? is sampled from a beta distribution ? ? Beta(?, ?). Such a direct interpolation is feasible for images as the data is aligned. In point clouds, however, linear interpolation is not straightforward. The reason is that point clouds are sets of points in which the point elements are orderless and permutation-invariant. We must, therefore, seek a definition of interpolation on unordered sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Interpolation between point clouds</head><p>Let S 1 ? S and S 2 ? S denote two training examples on which we seek to perform interpolation with ratio ? to generate new training examples. Given a pair of source examples S 1 and S 2 , an interpolation function, f S1?S2 : [0, 1] ? S can be any continuous function, which forms a curve that joins S 1 and S 2 in a metric space (S, d) with a proper distance function d. This means that it is up to us to define what makes an interpolation good. We define the concept of shortest-path interpolation in the context of point cloud:</p><p>Definition 1 (Shortest-path interpolation). In a metric space (S, d), a shortest-path interpolation f * S1?S2 : [0, 1] ? S is an interpolation between the given pair of source examples S 1 ? S and S 2 ? S, such that for any ? ? [0, 1], d(S 1 , S (?) ) + d(S (?) , S 2 )) = d(S 1 , S 2 ) holds for S (?) = f * S1?S2 (?) being the interpolant.</p><p>We say that Definition 1 ensures the shortest path property because the triangle inequality holds for any properly defined distance d : d(S 1 , S (?) ) + d(S (?) , S 2 )) ? d(S 1 , S 2 ). The intuition behind this definition is that the shortest path property ensures the uniqueness of the label distribution on the interpolated data. To put it otherwise, when computing interpolants from different sources, the interpolants generated by the shortest-path interpolation is more likely to be discriminative than the ones generated by a non-shortest-path interpolation.</p><p>To define an interpolation for point clouds, therefore, we must first select a reasonable distance metric. Then, we opt for the shorterst-path interpolation function based on the selected distance metric. For point clouds a proper distance metric is the Earth Mover's Distance (EMD), as it captures well not only the geometry between two point clouds, but also local details as well as density distributions <ref type="bibr" target="#b4">[5,</ref><ref type="bibr">1,</ref><ref type="bibr" target="#b12">13]</ref>. EMD measures the least amount of total displacement required for each of the points in the first point cloud, x i ? S 1 , to match a corresponding point in the second point cloud, y j ? S 2 . Formally, the EMD for point clouds solves the following assignment problem:</p><formula xml:id="formula_2">? * = arg min ??? i x i ? y ?(i) 2 ,<label>(3)</label></formula><p>where ? = {{1, . . . , N } ? {1, . . . , N }} is the set of possible bijective assignments, which give one-to-one correspondences between points in the two point clouds. Given the optimal assignment ? * , the EMD is then defined as the average effort to move S 1 points to S 2 :</p><formula xml:id="formula_3">d EMD = 1 N i x i ? y ? * (i) 2 .<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">PointMixup: Optimal assignment interpolation for point clouds</head><p>We propose an interpolation strategy, which can be used for augmentation that is analogous of Mixup [34] but for point clouds. We refer to this proposed Point-Mixup as Optimal Assignment (OA) Interpolation, as it relies on the optimal assignment on the basis of the EMD to define the interpolation between clouds.</p><p>Given the source pair of point clouds S 1 = {x i } N i=1 and S 2 = {y j } N j=1 , the Optimal Assignment (OA) interpolation is a path function f * S1?S2 :</p><formula xml:id="formula_4">[0, 1] ? S. With ? ? [0, 1], f * S1?S2 (?) = {u i } N i=1 , where<label>(5)</label></formula><formula xml:id="formula_5">u i = (1 ? ?) ? x i + ? ? y ? * (i) ,<label>(6)</label></formula><p>in which ? * is the optimal assignment from S 1 to S 2 defined by Eq. 3. Then the interpolant S S1?S2,(?) OA</p><formula xml:id="formula_6">(or S (?)</formula><p>OA when there is no confusion) generated by the OA interpolation path function f * S1?S2 (?) is the required augmented data for point cloud Mixup.</p><formula xml:id="formula_7">S (?) OA = {(1 ? ?) ? x i + ? ? y ? * (i) } N i=1 .<label>(7)</label></formula><p>Under the view of f * S1?S2 being a path function in the metric space (S, d EMD ), f is expected to be the shortest path joining S 1 and S 2 since the definition of the interpolation is induced from the EMD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Analysis</head><p>Intuitively we expect that PointMixup is a shortest path linear interpolation. That is, the interpolation lies on the shortest path joining the source pairs, and the interpolation is linear with regard to ? in (S, d EMD ), since the definition of the interpolation is derived from the EMD. However, it is non-trivial to show the optimal assignment interpolation abides to a shortest path linear interpolation, because the optimal assignment between the mixed point cloud and either of the source point cloud is unknown. It is, therefore, not obvious that we can ensure whether there exists a shorter path between the mixed examples and the source examples. To this end, we need to provide an in-depth analysis.</p><p>To ensure the uniqueness of the label distribution from the mixed data, we need to show that the shortest path property w.r.t. the EMD is fulfilled. Moreover, we need to show that the proposed interpolation is linear w.r.t the EMD, in order to ensure that the input interpolation has the same ratio as the label interpolation. Besides, we evaluate the assignment invariance property as a prerequisite knowledge for the proof for the linearity. This property implies that there exists no shorter path between interpolants with different ?, i.e., the shortest path between the interpolants is a part of the shortest path between the source examples. Due to space limitation, we sketch the proof for each property. The complete proofs are available in the supplementary material.</p><p>We start with the shortest path property. Since the EMD for point cloud is a metric, the triangle inequality</p><formula xml:id="formula_8">d EM D (A, B) + d EM D (B, C) ? d EM D (A, C)</formula><p>holds (for which a formal proof can be found in <ref type="bibr" target="#b18">[19]</ref>). Thus we formalize the shortest path property into the following proposition:</p><formula xml:id="formula_9">Property 1 (shortest path) Given the source examples S 1 and S 2 , ?? ? [0, 1], d EMD (S 1 , S (?) OA ) + d EMD (S (?) OA , S 2 ) = d EMD (S 1 , S 2 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sketch of Proof From the definition of the EMD we can derive</head><formula xml:id="formula_10">d EMD (S 1 , S (?) OA )+ d EMD (S 2 , S (?) OA ) ? d EMD (S 1 , S 2 )</formula><p>. Then from the triangle inequity of the EMD, only the equality remains.</p><p>We then introduce the assignment invariance property of the OA Mixup as an intermediate step for the proof of the linearity of OA Mixup. The property shows that the assignment does not change for any pairs of the mixed point clouds with different ?. Moreover, the assignment invariance property is important to imply that the shortest path between the any two mixed point clouds is part of the shortest path between the two source point clouds.</p><formula xml:id="formula_11">Property 2 (assignment invariance) S (?1) OA and S (?2)</formula><p>OA are two mixed point clouds from the same given source pair of examples S 1 and S 2 as well as the mix ratios ? 1 and ? 2 such that 0</p><formula xml:id="formula_12">? ? 1 &lt; ? 2 ? 1. Let the points in S (?1) OA and S (?2) OA be u i = (1 ? ? 1 ) ? x i + ? 1 ? y ? * (i) and v k = (1 ? ? 2 ) ? x k + ? 2 ? y ? * (k) , where ? * is the optimal assignment from S 1 to S 2 . Then the identical assignment ? I is the optimal assignment from S (?1) OA to S (?2)</formula><p>OA .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sketch of Proof</head><p>We first prove that the identical mapping is the optimal assignment from S 1 to S (?1)</p><p>OA from the definition of the EMD. Then we prove that ? * is the optimal assignment from S (?1) OA to S 2 . Finally we prove that the identical mapping is the optimal assignment from S (?1)</p><formula xml:id="formula_13">OA to S (?2)</formula><p>OA similarly as the proof for the first intermediate argument.</p><p>Given the property of assignment invariance, the linearity follows: Property 3 (linearity) For any mix ratios ? 1 and ? 2 such that 0 ? ? 1 &lt; ? 2 ? 1, the mixed point clouds S (?1)</p><formula xml:id="formula_14">OA and S (?2) OA satisfies that d EMD (S (?1) OA , S (?2) OA ) = (? 2 ? ? 1 ) ? d EMD (S 1 , S 2 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sketch of Proof</head><p>The proof can be directly derived from the fact that the identical mapping is the optimal assignment between S (?1)</p><formula xml:id="formula_15">OA and S (?2) OA .</formula><p>The linear property of our interpolation is important, as we jointly interpolate the point clouds and the labels. By ensuring that the point cloud interpolation is linear, we ensure that the input interpolation has the same ratio as the label interpolation.</p><p>On the basis of the properties, we find that PointMixup is a shortest path linear interpolation between point clouds in (S, d EMD ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Manifold PointMixup: Interpolate between latent point features</head><p>In standard PointMixup, only the inputs, i.e., the XYZ point cloud coordinates are mixed. The input XYZs are low-level geometry information and sensitive to disturbances and transformations, which in turn limits the robustness of the PointMixup. Inspired by Manifold Mixup [26], we can also use the proposed interpolation solution to mix the latent representations in the hidden layers of point cloud networks, which are trained to capture salient and high-level information that is less sensitive to transformations. PointMixup can be applied for the purpose of Manifold Mixup to mix both at the XYZs and different levels of latent point cloud features and maintain their respective advantages, which is expected to be a stronger regularizer for improved performance and robustness.</p><p>We describe how to mix the latent representations. Following <ref type="bibr">[26]</ref>, at each batch we randomly select a layer l to perform PointMixup from a set of layers L, which includes the input layer. In a point cloud network network, the intermediate latent representation at layer l (before the global aggregation stage such as the max pooling aggregation in PointNet <ref type="bibr" target="#b14">[15]</ref> and PointNet++ <ref type="bibr" target="#b15">[16]</ref>) is</p><formula xml:id="formula_16">Z (l) = {(x i , z (x) i )} Nz i=1 , in which x i is 3D point coordinate and z (x) i</formula><p>is the corresponding high-dimensional feature. For the mixed latent representation, given the latent representation of two source examples are</p><formula xml:id="formula_17">Z (l),1 = {(x i , z (x) i )} Nz i=1 and Z (l),2 = {(y i , z (y) i )} Nz i=1</formula><p>, the optimal assignment ? * is obtained by the 3D point coordinates x i , and the mixed latent representation then becomes</p><formula xml:id="formula_18">Z (?) (l),OA = {(x mix i , z mix i )}, where x mix i = (1 ? ?) ? x i + ? ? y ? * (i) , z mix i = (1 ? ?) ? z (x) i + ? ? z (y) ? * (i) .</formula><p>Specifically in PointNet++, three layers of representations are randomly selected to perform Manifold Mixup: the input, and the representations after the first and the second SA modules (See appendix of <ref type="bibr" target="#b15">[16]</ref> Following <ref type="bibr" target="#b11">[12]</ref>, we discriminate between settings where each dataset is prealigned and unaligned with horizontal rotation on training and test point cloud examples. For the unaligned settings, we randomly rotate the training point cloud along the up-axis. Then, before solving the optimal assignment, we perform a simple additional alignment step to fit and align the symmetry axes between the two point clouds to be mixed. Through this way, the point clouds are better aligned and we obtain more reasonable point correspondences. Last, we also perform experiments using only 20% of the training data.</p><p>Network architectures. The main network architecture used throughout the paper is PointNet++ <ref type="bibr" target="#b15">[16]</ref>. We also report results with PointNet <ref type="bibr" target="#b14">[15]</ref> and <ref type="bibr">DGCNN [29]</ref>, to show that our approach is agnostic to the architecture that is employed. PointNet learns a permutation-invariant set function, which does not capture local structures induced by the metric space the points live in. Point-Net++ is a hierarchical structure, which segments a point cloud into smaller clusters and applies PointNet locally. DGCNN performs hierarchical operations by selecting a local neighbor in the feature space instead of the point space, resulting in each point having different neighborhoods in different layers.</p><p>Experimental details. We uniformly sample 1,024 points on the mesh faces according to the face area and normalize them to be contained in a unit sphere, which is a standard setting <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b11">12]</ref>. In case of mixing clouds with different number of points, we can simply replicate random elements from the each point set to reach the same cardinality. During training, we augment the point clouds on-the-fly with random jitter for each point using Gaussian noise with zero mean and 0.02 standard deviation. We implement our approach in PyTorch <ref type="bibr" target="#b13">[14]</ref>. For network optimization, we use the Adam optimizer with an initial learning rate of 10 ?3 . The model is trained for 300 epochs with a batch size of 16. We follow previous work [34, 26] and draw ? from a beta distribution ? ? Beta(?, ?). We also perform Manifold Mixup [26] in our approach, through interpolation on the transformed and pooled points in intermediate network layers. In this work, we opt to use the efficient algorithm and adapt the open-source implementation from <ref type="bibr" target="#b12">[13]</ref> to solve the optimal assignment approximation. Training for 300 epochs takes around 17 hours without augmentation and around 19 hours with PointMixup or Manifold PointMixup on a single NVIDIA GTX 1080 ti.</p><p>Baseline interpolations. For our comparisons to baseline point cloud augmentations, we compare to two variants. The first variant is random assignment interpolation, where a random assignment ? RA is used, to connect points from both sets, yielding:</p><formula xml:id="formula_19">S (?) RA = {(1 ? ?) ? x i + ? ? y ? RA (i) }.</formula><p>The second variant is point sampling interpolation, where random draws without replacement of points from each set are made according to the sampling frequency ?: S (?)</p><formula xml:id="formula_20">PS = S (1??) 1 ? S (?) 2 ,</formula><p>where S (?) 2 denotes a randomly sampled subset of S 2 , with ?N elements. ( ? is the floor function.) And similar for S 1 with N ? ?N elements, such that S (?) PS contains exactly N points. The intuition of the point sampling variant is that for point clouds as unordered sets, one can move one point cloud to another through a set operation such that it removes several random elements from set S 1 and replace them with same amount of elements from S 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Point cloud classification ablations</head><p>We perform four ablation studies to show the workings of our approach with respect to the interpolation ratio, comparison to baseline interpolations and other regularizations, as well robustness to noise. Effect of interpolation ratio. The first ablation study focuses on the effect of the interpolation ratio in the data augmentation for point cloud classification. We perform this study on ModelNet40 using the PointNet++ architecture. The results are shown in <ref type="figure" target="#fig_2">Fig. 4</ref> for the prealigned setting. We find that regardless of the interpolation ratio used, our approach provides a boost over the setting without augmentation by interpolation. Point-Mixup positively influences point cloud classification. The inclusion of manifold mixup adds a further boost to the scores. Throughout further experiments, we use ? = 0.4 for input mixup and ? = 1.5 for manifold mixup in unaligned setting, and ? = 1.0 for input mixup and ? = 2.0 for manifold mixup in pre-aligned setting.</p><p>Comparison to baseline interpolations. In the second ablation study, we investigate the effectiveness of our PointMixup compared to the two interpolation baselines. We again use ModelNet40 and PointNet++. We perform the evaluation on both the pre-aligned and unaligned dataset variants, where for both we also report results with a reduced training set. The results are shown in <ref type="table" target="#tab_1">Table 1</ref>. Across both the alignment variants and dataset sizes, our Point-Mixup obtains favorable results. This result highlights the effectiveness of our  <ref type="table">Table 2</ref>: Evaluating our approach to other data augmentations (left) and its robustness to noise and transformations (right). We find that our approach with manifold mixup (MM) outperforms augmentations such as label smoothing and other variations of mixup. For the robustness evaluation, we find that our approach with strong regularization power from manifold mixup provides more robustness to random noise and geometric transformations. approach, which abides to the shortest path linear interpolation definition, while the baselines do not.</p><p>PointMixup with other regularizers. Third, we evaluate how well Point-Mixup works by comparing to multiple existing data regularizers and mixup variants, again on ModelNet40 and PointNet++. We investigate the following augmentations: (i ) Mixup [34], (ii ) Manifold Mixup [26], (iii ) mix input only without target mixup, (iv ) mix latent representation at a fixed layer (manifold mixup does so at random layers), and (v ) label smoothing <ref type="bibr" target="#b21">[22]</ref>. Training is performed on the reduced dataset to better highlight their differences. We show the results in <ref type="table">Table 2</ref> on the left. Our approach with manifold mixup obtains the highest scores. The label smoothing regularizer is outperformed, while we also obtain better scores than the mixup variants. We conclude that PointMixup is forms an effective data augmentation for point clouds. Robustness to noise. By adding additional augmented training examples, we enrich the dataset. This enrichment comes with additional robustness with respect to noise in the point clouds. We evaluate the robustness by adding random noise perturbations on point location, scale, translation and different rotations. Note that for evaluation of robustness against up-axis rotation, we use the models which are trained with the pre-aligned setting, in order to test also the performance against rotation along the up-axis as a novel transform. The results are in <ref type="table">Table 2</ref> on the right. Overall, our approach including manifold mixup provides more stability across all perturbations. For example, with additional noise (? = 0.05), we obtain an accuracy of 56.5, compared to 35.1 for the baseline. We similar trends for scaling (with a factor of two), with an accuracy of 72.9 versus 59.2. We conclude that PointMixup makes point cloud networks such as PointNet++ more stable to noise and rigid transformations.</p><p>Qualitative analysis. In <ref type="figure" target="#fig_3">Figure 5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation on other networks and datasets</head><p>With PointMixup, new point clouds are generated by interpolating existing point clouds. As such, we are agnostic to the type of network or dataset. To highlight <ref type="table">Table 3</ref>: PointMixup on other networks (left) and another dataset (right). We find our approach is beneficial regardless the network or dataset. The experiments are performed on ModelNet40. For PointNet, we perform the evaluation on the unaligned setting and for DGCNN with pre-aligned setting to remain consistent with the alignment choices made in the respective papers. The results are shown in <ref type="table">Table 3</ref> on the left. We find improvements when including PointMixup for both network architectures.</p><p>PointMixup on real-world point clouds. We also investigate PointMixup on point clouds from real-world object scans, using ScanObjectNN <ref type="bibr">[25]</ref>, which collects object from 3D scenes in SceneNN <ref type="bibr" target="#b8">[9]</ref> and ScanNet <ref type="bibr" target="#b3">[4]</ref>. Here, we rely on PointNet++ as network. The results in <ref type="table">Table 3</ref> on the right show that we can adequately deal with real-world point cloud scans, hence we are not restricted to point clouds from virtual scans. This result is in line with experiments on point cloud perturbations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Beyond standard classification</head><p>The fewer training examples available, the stronger the need for additional examples through augmentation. Hence, we train PointNet++ on ModelNet40 in both a few-shot and semi-supervised setting.</p><p>Semi-supervised learning. Semi-supervised learning learns from a dataset where only a small portion of data is labeled. Here, we show how PointMixup directly enables semi-supervised learning for point clouds. We start from Interpolation Consistency Training [27], a state-of-the-art semi-supervised approach, which utilizes Mixup between unlabeled points. Here, we use our Mixup for point clouds within their semi-supervised approach. We evaluate on ModelNet40 using 400, 600, and 800 labeled point clouds. The result of semi-supervised learning are illustrated in <ref type="table" target="#tab_4">Table 4</ref>  Few-shot learning. Few-shot classification aims to learn a classifier to recognize unseen classes during training with limited examples. We follow <ref type="bibr">[28,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b20">21]</ref> to regard few-shot learning a typical meta-learning method, which learns how to learn from limited labeled data through training from a collection of tasks, i.e., episodes. In an N -way K-shot setting, in each task, N classes are selected and K examples for each class are given as a support set, and the query set consists of the examples to be predicted. We perform few-shot classification on ModelNet40, from which we select 20 classes for training, 10 for validation, and 10 for testing. We utilize PointMixup within ProtoNet <ref type="bibr" target="#b19">[20]</ref> by constructing mixed examples from the support set and update the model with the mixed examples before making predictions on the query set. We refer to the supplementary material for the details of our method and the settings. The results in <ref type="table" target="#tab_4">Table 4</ref> on the right show that incorporating our data augmentation provides a boost in scores, especially in the one-shot setting, where the accuracy increases from 72.3% to 77.2%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This work proposes PointMixup for data augmentation on point clouds. Given the lack of data augmentation by interpolation on point clouds, we start by defining it as a shortest path linear interpolation. We show how to obtain Point-Mixup between two point clouds by means of an optimal assignment interpolation between their point sets. As such, we arrive at a Mixup for point clouds, or latent point cloud representations in the sense of Manifold Mixup, that can handle permutation invariant nature. We first prove that PointMixup abides to our shortest path linear interpolation definition. Then, we show through various experiments that PointMixup matters for point cloud classification. We show that our approach outperforms baseline interpolations and regularizers. Moreover, we highlight increased robustness to noise and geometric transformations, as well as its general applicability to point-based networks and datasets. Lastly, we show the potential of our approach in both semi-supervised and few-shot settings. The generic nature of PointMixup allows for a comprehensive embedding in point cloud classification.</p><p>Acknowledgment This research was supported in part by the SAVI/MediFor and the NWO VENI What &amp; Where projects. We thank the anonymous reviewers for helpful comments and suggestions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDICES A Proofs for the properties of PointMixup interpolation</head><p>We provide detailed proofs for the shortest path property, the assignment invariance property and the linearity, stated in Section 3.4.</p><p>Proof for the shortest path property We denote x i ? S 1 and y j ? S 2 are the points in S 1 and S 2 , then the generated S (?)</p><formula xml:id="formula_21">OA = {u i } N i=1 and u i = (1 ? ?) ? x i + ? ? y ? * (i) , where ? * is the optimal assignment from S 1 to S 2 .</formula><p>Then we suppose an identical one-to-one mapping ? I such that ? I (i) = i. Then by definition of the EMD as the minimum transportation distance, so</p><formula xml:id="formula_22">d EMD (S 1 , S (?) OA ) ? 1 N i x i ? u ? I (i) 2 ,<label>(8)</label></formula><p>where the right term of (8) is the transportation distance under identical assign-</p><formula xml:id="formula_23">ment ? I . Since 1 N i x i ? u ? I (i) 2 = 1 N i x i ? ((1 ? ?) ? x i + ? ? y ? * (i) ) 2 = ? 1 N i x i ? y ? * (i) 2 = ? ? d EMD (S 1 , S 2 ). Thus, d EMD (S 1 , S (?) OA ) ? ? ? d EMD (S 1 , S 2 ).<label>(9)</label></formula><p>Similarly as in <ref type="formula" target="#formula_22">(8)</ref> and <ref type="formula" target="#formula_23">(9)</ref>, the following inequality (10) can be derived by assigning the correspondence from S (?)</p><p>OA to S 2 with ? * :</p><formula xml:id="formula_24">d EMD (S (?) OA , S 2 ) ? (1 ? ?) ? d EMD (S 1 , S 2 ).<label>(10)</label></formula><p>With <ref type="formula" target="#formula_23">(9)</ref> and <ref type="formula" target="#formula_0">(10)</ref>,</p><formula xml:id="formula_25">d EMD (S 1 , S (?) OA ) + d EMD (S 2 , S (?) OA ) ? d EMD (S 1 , S 2 ).<label>(11)</label></formula><p>However, as the triangle inequality holds for the EMD, i.e.</p><formula xml:id="formula_26">d EMD (S 1 , S (?) OA ) + d EMD (S 2 , S (?) OA ) ? d EMD (S 1 , S 2 ),<label>(12)</label></formula><p>Then by summarizing <ref type="formula" target="#formula_0">(11)</ref> and <ref type="formula" target="#formula_0">(12)</ref>, d EMD (S 1 , S (?)</p><formula xml:id="formula_27">OA ) + d EMD (S 2 , S (?) OA ) = d EMD (S 1 , S 2 ) is proved.</formula><p>Proof for the assignment invariance property We introduce two intermediate arguments. We begin with proving the first intermediate argument: ? I is the optimal assignment from S 1 to S (?1) OA . Similarly as in (9) ,(10) and <ref type="bibr" target="#b11">(12)</ref> from the proof for Proposition 1, in order to allow all the three inequalities, the equal signs need to be taken for all of the three inequalities. Consider that the equal sign being taken for (9) is equivalent to the the equal sign being taken for (8), then,</p><formula xml:id="formula_28">d EMD (S 1 , S (?1) OA ) = 1 N i x i ? u ? I (i) 2 ,<label>(13)</label></formula><p>which in turn means that ? I is the optimal assignment from S 1 to S (?1)</p><p>OA by the definition of the EMD. So the first intermediate argument is proved.</p><p>The second intermediate argument is that ? * is the optimal assignment from S (?1) OA to S 2 . This argument can be proved samely as the first one. Say the equal sign being taken for (10) is equivalent to that</p><formula xml:id="formula_29">d EMD (S (?1) OA , S 2 ) = 1 N i u i ? y ? * (i) 2 .<label>(14)</label></formula><p>Thus, ? * is the optimal assignment from S (?1)</p><p>OA to S 2 is proved. Then, with the two intermediate arguments, we can reformalize the setup to regard that S OA and S 2 with the mix ratio ?2??1 1??1 , because the optimal assignment from S (?1)</p><p>OA to S 2 is the same as the optimal assignment from S 1 to S 2 . This argument then becomes an isomorphic with respect to the first intermediate argument. Then we prove that ? I is the optimal assignment from S (?1)</p><formula xml:id="formula_30">OA to S (?2)</formula><p>OA similarly as the proof for the first intermediate argument.</p><p>Proof for linearity We have shown that ? I is optimal assignment between S (?1)</p><formula xml:id="formula_31">OA = {u k } = {(1 ? ? 1 ) ? x k + ? 1 ? y ? * (k) } and S (?2) OA = {v l } = {(1 ? ? 2 ) ? x l + ? 2 ? y ? * (l) }. Thus, d EMD (S (?1) OA , S (?2) OA ) = 1 N k ((1 ? ? 1 ) ? x k + ? 1 ? y ? * (k) ) ? ((1 ? ? 2 ) ? x ? I (k) + ? 2 ? y ? * (? I (k)) ) 2 = 1 N k (? 2 ? ? 1 )(x k ? y ? * (k) ) 2 = (? 2 ? ? 1 ) 1 N k (x k ? y ? * (k) ) 2 = (? 2 ? ? 1 ) ? d EMD (S 1 , S 2 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Few-shot learning with PointMixUp</head><p>We test if our PointMixup helps point cloud few-shot classification task, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples of each new class. We take ProtoNet <ref type="bibr">[3]</ref> as the baseline method for few-shot learning, and PointNet++ <ref type="bibr">[2]</ref> is the feature extractor h ? .</p><p>Episodic learning setup ProtoNet takes the episodic training for few-shot learning, where an episode is designed to mimic the few-shot task by subsampling classes as well as data. A N C -way N S -shot setting is defined as that in each episode, data from N C classes are sampled and N S examples for each class is labelled. In the i th episode of training, the dataset D i consists of the training example and class pairs from N C classes sampled from all training classes. Denote D S i ? D i is the support set which consists of labelled data from N C classes with N S examples, and D Q i = D i \D S i is the query set which consists of unlabelled examples to be predicted.</p><p>Baseline method for few-shot classification: ProtoNet <ref type="bibr">[3]</ref> In each episode D i , ProtoNet computes a prototype as the mean of embedded support examples z c for each class c, from all examples from the support set D S i . The latent embedding is from the network h ? (for which we use PointNet++ <ref type="bibr">[2]</ref> without the last fully-connected layer). Then each example S from the query set D Q i is classified into a label distribution by a softmax over (negative) distance to the class prototypes:</p><formula xml:id="formula_32">p(? = c|S) = exp(?d(S,z c )) c exp(?d(S,z c ))</formula><p>, where d(?, ?) is the Eudlidean distance in the embedding space. In training stage, the weights ? for the feature extractor h ? is updated by the cross-entropy loss for the predicted query label distribution and the ground truth. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Further Discussion on Interpolation Variants</head><p>The proposed PointMixUp adopts Optimal Assignment (OA) interpolation for point cloud because of its advantages in theory and in practice. To compare Optimal Assignment interpolation with the two alternative strategies, Random Assignment (RA) interpolation and Point Sampling (PS) interpolation, the proposed PointMixUp with OA interpolation is the best performing strategy, followed by PS interpolation. RA interpolation, which has a non-shortest path definition of interpolation, does not perform well.</p><p>Here we extend the discussion on the two alternative interpolation strategies, through which we analyze the possible advantages and limitations under certain conditions, which in turn validates our choice of applying Optimal Assignment interpolation for PointMixup. Reviewing the shortest path interpolation hypothesis, We argue that when the number of points N is large enough, or say N ? ?, Point Sampling interpolation also (approximately) defines a shortest path on the metric space (S, d EMD ) (Note that given the initial and the final points, the shortest path in (S, d EMD ) is not unique). This is a bit counter-intuitive, but reasonable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random Assignment interpolation</head><p>We show the shortest path property. Recall that point sampling interpolation randomly draws without replacement of points from each set are made according to the sampling frequency ?: S PS , S 1 ), the optimal assignment will return these identical points as matched pairs, thus they contribute zero to the overall EMD distance. Thus,</p><formula xml:id="formula_33">d EMD (S (?) PS , S 1 ) = N ? ?N N d EMD (S (?) PS \ S (1??) 1 , S 1 \ S (1??) 1 ) = N ? ?N N d EMD (S (?) 2 , S 1 \ S (1??) 1 ) ? N ? ?N N d EMD (S 2 , S 1 ) ? (1 ? ?) ? d EMD (S 1 , S 2 ), from which d EMD (S (?) 2 , S 1 \ S (1??) 1 ) ? d EMD (S 2 , S 1 ) is because that S 1 and S 1 \ S (1??) 1</formula><p>are the point clouds representing the same shape but with different density, and the same with S 2 and S PS , S 2 ) = d EMD (S 1 , S 2 ), which in turn proves the shortest path property. We note that the linearity of PS interpolation w.r.t. d EMD also holds and the proof can be derived similarly. Thus, although strictly not an ideally continuous interpolation path, PS interpolation is (appoximately) a shortest path linear interpolation in (S, d EMD ), which explains its good performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Point Sampling interpolation: limitations</head><p>The limitation of PS interpolation is from that the mix ratio ? controls change of local density distribution, but the underlying shape does not vary with ?. So, as shown in <ref type="table" target="#tab_6">Table 5</ref>, PS interpolation fails with PointNet <ref type="bibr">[1]</ref>, which is ideally invariant to the point density, because a max pooling operation aggregates the information from all the points.</p><p>A question which may come with PS interpolation is that how it performs relatively well with PointNet++, which is also designed to be density-invariant. This is due to the sampling and grouping stage. PointNet++ takes same operation as PointNet in learning features, but in order to be hierarchical, the sampling and grouping stage, especially the farthest point sampling (fps) operation is not invariant to local density changes such that it samples different groups of farthest points, resulting in different latent point cloud feature representations. Thus, PointNet++ is invariant to global density but not invariant to local density differences, which makes PS interpolation as a working strategy for PointNet++. However, we may still expect that the performance of Mixup based on PS interpolation is limited, because it does not work well with PointNet as a basic component in PointNet++.</p><p>By contrast, the proposed PointMixup with OA interpolation strategy is not limited by the point density invariance. As a well established interpolation, OA interpolation smoothly morphes the underlying shape. So we claim that OA interpolation is a more generalizable strategy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Intuition of shortest-path interpolation. The examples lives on a metric space (S, d) as dots in the figure. The dashed lines are the interpolation paths between different pairs of examples. When the shortest-path property is ensured (left), the interpolation paths from different pairs of source examples are likely to be not intersect in a complicated metric space. While in non-shortest path interpolation (right), the paths can intertwine with each other with a much higher probability, making it hard to tell which pair of source examples does the mixed data come from.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Baseline interpolation variants. Top: point cloud interpolation through random assignment. Bottom: interpolation through sampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Effect of interpolation ratios. MM denotes Manifold Mixup.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Qualitative examples of PointMixup. We provide eight visualizations of our interpolation. The four examples on the left show interpolations for different configurations of cups and tables. The four examples on the right show interpolations for different chairs and cars.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>, we show eight examples of PointMix for point cloud interpolation; four interpolations of cups and tables, four interpolations of chairs and cars. Through our shortest path interpolation, we end up at new training examples that exhibit characteristics of both classes, making for sensible point clouds and mixed labels, which in turn indicate why PointMixup is beneficial for point cloud classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>on the left. Compared to the supervised baseline, which only uses the available labelled examples, our mixup enables the use of additional unlabelled training examples, resulting in a clear boost in scores. With 800 labelled examples, the accuracy increases from 73.5% to 82.0%, highlighting the effectiveness of PointMixup in a semi-supervised setting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>23. Thomas, H., Qi, C.R., Deschaud, J.E., Marcotegui, B., Goulette, F., Guibas, L.J.: Kpconv: Flexible and deformable convolution for point clouds. In: ICCV. pp. 6411-6420 (2019) 24. Tokozume, Y., Ushiku, Y., Harada, T.: Between-class learning for image classification. In: CVPR (2018) 25. Uy, M.A., Pham, Q.H., Hua, B.S., Nguyen, T., Yeung, S.K.: Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data. In: ICCV (2019) 26. Verma, V., Lamb, A., Beckham, C., Najafi, A., Mitliagkas, I., Courville, A., Lopez-Paz, D., Bengio, Y.: Manifold mixup: Better representations by interpolating hidden states. In: ICML (2019) 27. Verma, V., Lamb, A., Kannala, J., Bengio, Y., Lopez-Paz, D.: Interpolation consistency training for semi-supervised learning. IJCAI (2019) 28. Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al.: Matching networks for one shot learning. In: NeurIPS (2016) 29. Wang, Y., Sun, Y., Liu, Z., Sarma, S.E., Bronstein, M.M., Solomon, J.M.: Dynamic graph cnn for learning on point clouds. TOG (2019) 30. Wu, W., Qi, Z., Fuxin, L.: Pointconv: Deep convolutional networks on 3d point clouds. In: CVPR (2019) 31. Wu, Z., Song, S., Khosla, A., Yu, F., Zhang, L., Tang, X., Xiao, J.: 3d shapenets: A deep representation for volumetric shapes. In: CVPR (2015) 32. Xu, Y., Fan, T., Xu, M., Zeng, L., Qiao, Y.: Spidercnn: Deep learning on point sets with parameterized convolutional filters. In: ECCV (2018) 33. Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.R., Smola, A.J.: Deep sets. In: NeurIPS. pp. 3391-3401 (2017) 34. Zhang, H., Cisse, M., Dauphin, Y.N., Lopez-Paz, D.: mixup: Beyond empirical risk minimization. In: ICLR (2017) 35. Zhang, Z., He, T., Zhang, H., Zhang, Z., Xie, J., Li, M.: Bag of freebies for training object detection neural networks. In: CoRR (2019) 36. Zhang, Z., Hua, B.S., Yeung, S.K.: Shellnet: Efficient point cloud convolutional neural networks using concentric shells statistics. In: ICCV (2019)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>From our shortest path interpolation hypothesis for Mixup, the inferiority of RA interpolation comes from that it does not obey the shortest path interpolation rule, so that the mixed point clouds from different source examples can easily entangle with each other. From Fig. 3 in the main paper, the Random assignment interpolation produces chaotic mixed examples which can hardly been recognized with the feature from the source class point clouds. Thus, RA interpolation fails especially under heavy Mixup (the value of ? is large). Point Sampling interpolation: yet another shortest path interpolation Point Sampling interpolation performs relatively well in PointNet++ and sometimes comparable with the Optimal Assignment interpolation. From Fig. 3 in the main paper, the PS interpolation produces mixed examples which can be recognized which classes of source data it comes from.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>sampled subset of S 2 , with ?N elements. ( ? is the floor function.) And similar for S (1??) 1 with N ? ?N elements, such that S (?) PS contains exactly N points. Imagine that a subset S(1??) 1 with a number of N ? ?N points in S (?) PS are identical with that in S 1 . For d EMD (S (?)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>PS , S 2 )</head><label>2</label><figDesc>? ? ? d EMD (S 1 , S 2 ), and thus d EMD (S (?) PS , S 1 ) + d EMD (S (?)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>We focus in our experiments on the ModelNet40 dataset [31]. This dataset contains 12,311 CAD models from 40 man-made object categories, split into 9,843 for training and 2,468 for testing. We furthermore perform experiments on the ScanObjectNN dataset [25]. This dataset consists of real-world point cloud objects, rather than sampled virtual point clouds. The dataset consists of 2,902 objects and 15 categories. We report on two variants of the dataset, a standard variant OBJ ONLY and one with heavy permutations from rigid transformations PB T50 RS[25].</figDesc><table><row><cell>).</cell></row><row><cell>4 Experiments</cell></row><row><cell>4.1 Setup</cell></row><row><cell>Datasets.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison of PointMixup to baseline interpolations on Mod-elNet40 using PointNet++. PointMixup compares favorable to excluding interpolation and to the baselines, highlighting the benefits of our shortest path interpolation solution.</figDesc><table><row><cell></cell><cell cols="7">No mixup Random assignment Point sampling PointMixup</cell></row><row><cell>Manifold mixup</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell></cell><cell>?</cell><cell></cell></row><row><cell>Full dataset</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Unaligned</cell><cell>90.7</cell><cell>90.8</cell><cell>91.1</cell><cell>90.9</cell><cell>91.4</cell><cell>91.3</cell><cell>91.7</cell></row><row><cell>Pre-aligned</cell><cell>91.9</cell><cell>91.6</cell><cell>91.9</cell><cell>92.2</cell><cell>92.5</cell><cell>92.3</cell><cell>92.7</cell></row><row><cell>Reduced dataset</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Unaligned</cell><cell>84.4</cell><cell>84.8</cell><cell>85.4</cell><cell>85.7</cell><cell>86.5</cell><cell>86.1</cell><cell>86.6</cell></row><row><cell>Pre-aligned</cell><cell>86.1</cell><cell>85.5</cell><cell>87.3</cell><cell>87.2</cell><cell>87.6</cell><cell>87.6</cell><cell>88.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Evaluating PointMixup in the context of semi-supervised (left) and few-shot learning (right). When examples are scarce, as is the case for both settings, using our approach provides a boost to the scores.</figDesc><table><row><cell></cell><cell cols="2">Semi-supervised classification</cell><cell cols="2">Few-shot classification</cell></row><row><cell></cell><cell>Supervised</cell><cell>[27]+PointMixup</cell><cell>[20]</cell><cell>+ PointMixup</cell></row><row><cell>400 examples</cell><cell>69.4</cell><cell>76.7</cell><cell>5-way 1-shot 72.3</cell><cell>77.2</cell></row><row><cell>600 examples</cell><cell>72.6</cell><cell>80.8</cell><cell>5-way 3-shot 80.2</cell><cell>82.2</cell></row><row><cell>800 examples</cell><cell>73.5</cell><cell>82.0</cell><cell>5-way 5-shot 84.2</cell><cell>85.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Few-shot point cloud classification with PointMixupWe use PointMixup to learn a better embedding space for each episode. Instead of using the h ? directly to predict examples from query set, we learn a episode-specific weight ? i from the mixed data, and the query examples are predicted by h ?i . We use PointMixup to construct a mixed set D mixi from the labelled support set D S i , which consists of examples from Nc 2 class pairs and for each class pairs N s mixed examples are constructed from randomly sampling support examples. Then the weight ? is updated as ? i from backprop the loss from the prediction Algorithm 1 Episodic training of ProtoNet with PointMixUp. From line 3 to line 8 is where PointMixUp takes a role in addition to the ProtoNet baseline. Testing stage is similar as training stage, but without line 13 and line 14 which learn new weight from query examples. of mixed examples from D mix i . After that, the label of query examples from D Q i is then predicted with the updated feature extractor h ?i . See Algorithm 1 for an illustration of the learning scheme.</figDesc><table><row><cell cols="5">Require: Set of sampled episodes {Di}, where Di = D S i ? D Q i denoting the support</cell></row><row><cell></cell><cell>and query sets</cell><cell></cell><cell></cell></row><row><cell cols="5">Require: h ? : feature extractor network: input ? latent embedding</cell></row><row><cell cols="2">1: randomly initialize ?</cell><cell></cell><cell></cell></row><row><cell cols="2">2: for episode i do</cell><cell></cell><cell></cell></row><row><cell>3:</cell><cell>for class c do</cell><cell></cell><cell></cell></row><row><cell>4:</cell><cell cols="4">calculate prototypezc from D S i , with h ? .</cell></row><row><cell>5:</cell><cell>end for</cell><cell></cell><cell></cell></row><row><cell>6:</cell><cell cols="2">Construct Mixup samples D mix i</cell><cell cols="2">from support set D S i .</cell></row><row><cell>7:</cell><cell cols="4">Predict the label distributions for mixed examples in D mix i</cell><cell>, with distance tozc.</cell></row><row><cell>8:</cell><cell cols="4">Update ? with prediction from mixed examples, as episode-specific weights ?i.</cell></row><row><cell>9:</cell><cell>for class c do</cell><cell></cell><cell></cell></row><row><cell>10:</cell><cell>calculate new prototypez</cell><cell cols="2">(? i ) c</cell><cell>from D S i , with h ? i</cell></row><row><cell>11:</cell><cell>end for</cell><cell></cell><cell></cell></row><row><cell>12:</cell><cell cols="4">Predict the label distributions for query examples in D Q i , with distance toz</cell><cell>(? i ) c</cell><cell>.</cell></row><row><cell>13:</cell><cell cols="4">Update ?i with prediction from query examples.</cell></row><row><cell>14:</cell><cell>? ? ?i</cell><cell></cell><cell></cell></row><row><cell cols="2">15: end for</cell><cell></cell><cell></cell></row><row><cell cols="2">16: return ?</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Different interpolation strategies on PointNet[1]  Following the original paper[1]  we test on unaligned setting. PS interpolation fails with Point-Net as a density-invariant model. The numbers are accuracy in percentage.</figDesc><table><row><cell>Baseline</cell><cell>PointMixup</cell><cell>Random Assignment</cell><cell>Point Sampling</cell></row><row><cell>89.2</cell><cell>89.9</cell><cell>88.2</cell><cell>88.7</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning representations and generative models for 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Achlioptas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Diamanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Remixmatch: Semi-supervised learning with distribution alignment and augmentation anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Scannet: Richly-annotated 3d reconstructions of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie?ner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A point set generation network for 3d object reconstruction from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Consistency regularization and cutmix for semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Finlayson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Mixup as locally linear out-of-manifold regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Scenenn: A scene meshes dataset with annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Yeung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">So-net: Self-organizing network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hee</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9397" to="9406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pointaugment: an auto-augmentation framework for point cloud classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6378" to="6387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Pointcnn: Convolution on x-transformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Morphing and sampling network for dense point cloud completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poczos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04500</idno>
		<title level="m">Deep learning with sets and point clouds</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The earth mover&apos;s distance as a metric for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rubner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
