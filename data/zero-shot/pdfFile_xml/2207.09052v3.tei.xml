<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Balanced Contrastive Learning for Long-Tailed Visual Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianggang</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Lab of Intelligent Information Processing</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shanghai Collaborative Innovation Center on Intelligent Visual Computing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Lab of Intelligent Information Processing</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shanghai Collaborative Innovation Center on Intelligent Visual Computing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Lab of Intelligent Information Processing</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shanghai Collaborative Innovation Center on Intelligent Visual Computing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ping</forename><forename type="middle">Phoebe</forename><surname>Chen</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science and Information Technology</orgName>
								<orgName type="institution">La Trobe University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Gang</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Lab of Intelligent Information Processing</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shanghai Collaborative Innovation Center on Intelligent Visual Computing</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Balanced Contrastive Learning for Long-Tailed Visual Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Real-world data typically follow a long-tailed distribution, where a few majority categories occupy most of the data while most minority categories contain a limited number of samples. Classification models minimizing crossentropy struggle to represent and classify the tail classes. Although the problem of learning unbiased classifiers has been well studied, methods for representing imbalanced data are under-explored. In this paper, we focus on representation learning for imbalanced data. Recently, supervised contrastive learning has shown promising performance on balanced data recently. However, through our theoretical analysis, we find that for long-tailed data, it fails to form a regular simplex which is an ideal geometric configuration for representation learning. To correct the optimization behavior of SCL and further improve the performance of long-tailed visual recognition, we propose a novel loss for balanced contrastive learning (BCL). Compared with SCL, we have two improvements in BCL: classaveraging, which balances the gradient contribution of negative classes; class-complement, which allows all classes to appear in every mini-batch. The proposed balanced contrastive learning (BCL) method satisfies the condition of forming a regular simplex and assists the optimization of cross-entropy. Equipped with BCL, the proposed twobranch framework can obtain a stronger feature representation and achieve competitive performance on long-tailed benchmark datasets such as CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, and iNaturalist2018. Our code is available at this URL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep neural networks have achieved remarkable success in a series of computer vision tasks, such as image recogni-* Indicates equal contribution. ? Jingjing-Chen is the corresponding author. tion <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b24">25]</ref>, video analysis <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b48">49]</ref>, object detection <ref type="bibr" target="#b34">[35]</ref>, etc. These achievements are owing largely to the availability of large-scale dataset such as ImageNet <ref type="bibr" target="#b10">[11]</ref>, where each class has sufficient and equal amount of training samples. However, real-world datasets are often imbalanced, where many classes have only a few samples and few classes have a great number of samples. Deep models trained with such unbalanced data usually generalize badly on balanced testing data, especially for rare classes. Improving recognition performance with unbalanced data poses a huge challenge to modern deep learning methods.</p><p>To tackle the problem of learning with imbalanced data, early methods mainly focus on re-sampling the training data <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b32">33]</ref> or re-weighting the loss functions <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b44">45]</ref> to pay more attention to rare classes. Recently, diverse methods have emerged. For example, Logit compensation methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b37">38]</ref> calibrate distribution between the training data and the test data. Decoupling <ref type="bibr" target="#b22">[23]</ref> adopts a two-stage training scheme where the classifier is rebalanced in the second stage. The work in <ref type="bibr" target="#b43">[44]</ref> has multiple distribution-aware experts for responding to samples of different class frequencies. Nevertheless, contrastive learning approaches are less explored before, not until contrastive learning <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b41">42]</ref> are introduced. We attach great importance to representation learning because it's the most remarkable capability of deep models.</p><p>In this paper, we focus on using supervised contrastive learning (SCL) <ref type="bibr" target="#b23">[24]</ref> to assist representation learning. Supervised contrastive loss has achieved better performance than supervised cross-entropy loss on large-scale classification problems. The work in <ref type="bibr" target="#b15">[16]</ref> then has explained in detail the reason for the excellent performance of SCL on the balanced datasets. Despite the great success, some recent work <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22]</ref> indicate that high-frequency classes dominate SCL for representing imbalanced data, which results in unsatisfactory performance across all classes. To analyze the optimizing behavior of SCL in learning the representations for long-tailed data, we depict the geometric arrangement of representations of training instances when the lower bound of loss is achieved. Specifically, we decouple the lower bound of loss by deriving two competing dynamics: an attraction term and a repulsion term as in <ref type="bibr" target="#b15">[16]</ref>. We reveal that the long-tailed distribution mainly affects the repulsion term. At the minimal supervised contrastive loss, the representations of classes of long-tailed data no longer attain a regular simplex configuration. In other words, when all instances with the same label collapse to points, these points are not equidistant from each other. A regular simplex configuration empirically confers important benefits, such as better generalization performance <ref type="bibr" target="#b31">[32]</ref>. Besides, it has been proved to be the target geometric configuration of SCL on balanced data <ref type="bibr" target="#b15">[16]</ref>, hence forming a regular simplex configuration will benefit recognition on long-tailed data <ref type="bibr" target="#b14">[15]</ref>.</p><p>Inspired by our analysis, we urge the model learning on imbalanced data to form a regular simplex, and propose a balanced contrastive learning (BCL) method (illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>). We have two modifications in BCL that distinguish it from SCL. First, class-complement introduces the classcenter embeddings, i.e., prototypes, as instances for comparison in every mini-batch. Second, class-averaging has the gradient contributions of all negatives of each class averaged for every mini-batch. Through these two improvements, BCL ensures that the overall lower bound of the loss is a class-independent constant, and alleviates the imbalance problem of SCL when representing long-tailed data. Furthermore, We adopt a cross-entropy loss with logit compensation to obtain a balanced classifier. Logit compensation can effectively alleviate overlooking tail classes in the classifier learning <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34]</ref>. Overall, we propose a twobranch framework to implement the mentioned techniques, i.e., a contrastive learning branch with BCL and a classifi-cation branch with logit compensated cross-entropy.</p><p>Our main contributions are as follows:</p><p>? We present a theoretical analysis showing that supervised contrastive learning forms an undesired asymmetric geometry configuration for long-tailed data due to the overwhelming numerical dominance of the head classes.</p><p>? Motivated by our analysis, we extend supervised contrastive learning to balanced contrastive learning, which overcomes the imbalance problem and remains a regular simplex configuration of long-tailed data.</p><p>? The proposed two-branch framework combines the classification module and the balanced contrastive learning module, achieving competitive results on several popular long-tailed datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Long-tailed Recognition Early solutions to address the long-tailed problem comprise two main ideas: re-sampling and re-weighting. Re-sampling methods undersample <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14]</ref> high-frequency classes or oversample <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b32">33]</ref> lowfrequency classes. Re-weighting methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b44">45]</ref> assign different losses to different training samples for each class or each example. Both BBN <ref type="bibr" target="#b50">[51]</ref> and Decoupling <ref type="bibr" target="#b22">[23]</ref> indicate that the re-balancing method is detrimental to representation learning. BBN dynamically adjusts the weights between features from the instance-balanced sampling branch and the reversed sampling branch. While Decoupling proposes a two-stage learning strategy that firstly obtains a good feature extractor and secondly fixes the feature extractor and fine-tunes the classifier. Recently proposed logit compensation methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b37">38]</ref> learn relatively larger margins between different classes based on the prior of class frequencies. For example, logit adjustment <ref type="bibr" target="#b30">[31]</ref> derives the general form of the compensation value based on the optimal Bayesian classifier. Our proposed framework simultaneously improves the representation learning with BCL and strengthens the classifier learning with logit compensation in an end-to-end manner. Supervised Contrastive Learning Contrastive learning (CL) trains the model in a pairwise way by aggregating semantically similar samples while excluding semantically dissimilar ones, which has been employed for feature representation learning in varies tasks <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46]</ref>. SimCLR <ref type="bibr" target="#b4">[5]</ref> and MoCo <ref type="bibr" target="#b17">[18]</ref> are two typical types of self-supervised contrastive learning. SCL <ref type="bibr" target="#b23">[24]</ref> leverages label information for fully-supervised representation learning, leading to state-ofthe-art performance for image classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contrastive Learning for Long-tailed Recognition</head><p>Trained on long-tailed data, conventional contrastive learning can pose potential problems. SSP <ref type="bibr" target="#b47">[48]</ref> boosts long-tailed learning with self-supervised and semi-supervised contrastive learning. Hybrid-SC <ref type="bibr" target="#b41">[42]</ref> designs a two-branch network, using a supervised contrastive learning branch for learning better representations and a classifier branch for eliminating the bias of the classifier towards head classes. Despite our framework shares a similar two-branch architecture with Hybrid-SC, our framework differs from Hybrid-SC as we introduce BCL loss in the SCL branch for dealing with the domination of majority classes problem. Hybrid-PSC <ref type="bibr" target="#b41">[42]</ref> is proposed to overcome the memory bottleneck problem of SCL with a prototype for each class for contrast. PaCo <ref type="bibr" target="#b7">[8]</ref> overcomes the performance degradation of SCL by introducing a set of class-wise learnable centers. KCL <ref type="bibr" target="#b21">[22]</ref> adopts the two-stage learning paradigm and uses the same number of positives for all classes in every batch.</p><p>The recently proposed TSC <ref type="bibr" target="#b27">[28]</ref> is the most relevant work to ours, which urges the features of classes closer to the target features on the vertices of a regular simplex. Targets in TSC are learned without class semantics, while our BCL uses the class prototypes as extra samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminaries</head><p>In the image classification task, we aim to learn a complex function ? mapping from an input space X to the target space Y = [K] = {1, 2, . . . , K}. The function ? is usually implemented as the composition of an encoder f : X ? Z ? R h and a linear classifier W : Z ? Y. The final classification accuracy strongly depends on the quality of the representations Z. Therefore, we aim to learn a good encoder f to improve long-tailed learning. Further, we have the following definitions to facilitate later analysis: Supervised contrastive loss. For an instance x i of representation z i in a batch B, supervised contrastive loss has the following expression:</p><formula xml:id="formula_0">L i = ? 1 |B y | ? 1 p?By\{i} log exp(z i ? z p /? ) k?B\{i} exp(z i ? z k /? )<label>(1)</label></formula><p>where B y is a subset of B that contains all samples of class y, and we further define B C y as the complement set of B y . | ? | stands for the number of samples in the set. ? &gt; 0 is a scalar temperature hyper parameter that controls tolerance to similar samples, and a small temperature tends to be less tolerant to similar samples <ref type="bibr" target="#b40">[41]</ref>. Note that we omit ? in the following contrastive losses for simplicity.</p><p>Similar to <ref type="bibr" target="#b15">[16]</ref>, we also introduce the class-specific batch-wise loss: <ref type="figure" target="#fig_6">Figure 2</ref>. Illustration of the geometry configuration of data points with regard to (a)SCL on balanced data, (b) SCL on long-tailed data, and (c) BCL on long-tailed data in a plane. The ? represents the class-mean of each class. Different colors represent different classes. SCL enlarges the distances between high-frequency classes and reduces the distances between low-frequency classes as in (b), causing an asymmetrical geometry configuration of longtailed data.</p><formula xml:id="formula_1">L SCL (Z; Y, B, y) = i?By L i if |B y | &gt; 1 0 else (2) (a) (b) (c)</formula><p>Regular simplex. A set of points ? 1 , . . . , ? K ? R h form the vertices of a regular simplex inscribed in the hypersphere of radius ? &gt; 0, if and only if the following conditions hold:</p><formula xml:id="formula_2">(1) i?[K] ? i = 0 (2) ?? i ? = ?, for i ? [K] (3) ?d ? R : d = ?? i , ? j ? for 1 ? i &lt; j ? K</formula><p>where h, K ? N with K ? h + 1, and ??? stands for the inner product operation. Regular simplex has a highly symmetric structure that all vertices are equally spaced. Given a balanced dataset, it's worth mentioning that when supervised contrastive loss attain the minimum, representations of each class collapse to the vertices of a regular simplex spontaneously <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b31">32]</ref>. See the illustration in <ref type="figure" target="#fig_6">Fig. 2</ref>(a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Analysis</head><p>Drawbacks of SCL. To clearly show the optimization behaviour of SCL on long-tailed data, we mainly focus on the variation of the geometry configuration formed by the representations of each class. Although representations of each class collapse to the vertices of a regular simplex when supervised contrastive loss attain its minimum on a balanced dataset, SCL forms an asymmetrical configuration on longtailed data as shown in <ref type="figure" target="#fig_6">Fig. 2(b)</ref>. In the following, we will give an in-depth analysis on the loss function to show why the geometry configuration changes for imbalanced data. In particular, we analysis the lower-bound of the loss. Since directly computing the lower bound on the whole longtailed dataset is often intractable, we pay attention to the loss of a specific mini-batch instead.  <ref type="figure">Figure 3</ref>. Left: Contrasting an anchor sample with others. Right: Applying both class-averaging and class-complement for a specific class. We average the similarity between the anchor sample and the batch sample as well as the class prototype. Note that the class colored blue does not appear in the mini-batch, so the similarity between the anchor and its prototype can be directly taken as the result.</p><formula xml:id="formula_3">1 | * + 1| exp( + * % " ) exp( + * &amp; " ) &amp; %?' $ ?{$ $ } exp( + + % ) &amp; # &amp; $ &amp; %</formula><p>wise loss is bounded by</p><formula xml:id="formula_4">LSCL(Z; Y, B, y) ? i?By log((|By| ? 1)+ |B C y | exp( 1 |B C y | k?B C y zi ? z k repulsion term ? 1 |By| ? 1 j?By \{i} zi ? zj attraction term )) (3)</formula><p>Proof. See Lemma S1 in <ref type="bibr" target="#b15">[16]</ref>.</p><p>The above lower bound of SCL loss is derived by <ref type="bibr" target="#b15">[16]</ref>, which consists of a repulsion term and an attraction term. The attraction term leads to variability collapse <ref type="bibr" target="#b31">[32]</ref> as training progresses, and all the within-class representations collapse to their class means in the end. The attraction term only relates to samples within a specific class. It means that whether the dataset is balanced or not, samples within the same class should be as close as possible.</p><p>The attraction term leads to intra-class feature collapse regardless of the class frequency. While the repulsion term affects inter-class uniformity and is dominated by classes with higher frequency, thereby features in SCL are less separable. We indicate that data imbalance mainly affects the repulsion term. Obviously, the repulsion term is strongly related to the data distribution of the classes appeared within a mini-batch. When the dataset is long-tailed, almost every mini-batch we sampled is long-tailed. This leads to the dominance of the head classes in the repulsion term and makes each sample farther away from the heads. However, due to the number of samples in each class being different, the distance between the head classes will be larger compared to the others. Additionally, for each sample, the gradients from negative head classes will be much larger than negative tail classes. This unavoidably causes the loss to focus more on optimizing the head classes and leads to an asymmetrical geometry as shown in <ref type="figure" target="#fig_6">Fig. 2(b)</ref>. Solution. We modify the supervised contrastive loss with two straightforward ideas, i.e., class-averaging and classcomplement. The modified loss will lead to a regular simplex configuration of long-tailed data as we will show below. To avoid excessive concentration on head classes, an intuitive approach is to equilibrate the gradients con-tributed by different negative classes. We call this operation as class-averaging. The gradients from the negative samples of head classes are reduced. Below, we give the lower bound after performing class-averaging.</p><formula xml:id="formula_5">Theorem 2. Let Z, Y be defined as in Theorem 1, Y B ? [K]</formula><p>denotes the set of classes that appear within batch. the class-specific batch-wise loss after performing classaveraging is bounded by</p><formula xml:id="formula_6">LBCL(Z; Y, B, y) ? i?By log(1 + (|YB|?1) ? exp( 1 |YB|?1 q?Y B \{y} 1 |Bq| k?Bq zi ?z k repulsion term ? 1 |By|?1 j?By \{i} zi ?zj attraction term )) (4)</formula><p>Proof. See the Supplementary Material.</p><p>Consequently, head classes no longer dominate the repulsion term. Since each class is not sampled with equal probability, this may still lead to an unstable optimization and fail to form a regular simplex. To address this problem, we make all classes appear in every mini-batch and name this operation as class-complement. Below, we give the overall lower bound after performing class-complement. Theorem 3. Let Z, Y be defined as in Theorem 1, if we have Y B = Y for every B, the overall loss is given by</p><formula xml:id="formula_7">L BCL (Z; Y ) ? |D| log(1 + (K ? 1) exp(? K K ? 1 )) (5)</formula><p>where D represents the dataset. Here, the normalization term is neglected. Recall that Z is an N point configuration with labels Y , the equality of Eq. 15 is attained if and only if the following conditions hold. There are ? 1 , . . . , ? K ? R h such that:</p><formula xml:id="formula_8">(1) ?n ? [N ] : z n = ? yn (2) ? 1 , . . . , ? K f orm a regular simplex</formula><p>Proof. See the Supplementary Material. Note that condition (1) implies variability collapse, and condition (2) demonstrates the regular simplex structure. When balanced contrastive loss attains its lower bound, </p><formula xml:id="formula_9">? " ? " ? " ? $ ! $ " $ # ! " % ? ? Figure 4.</formula><p>Overview of the proposed framework. The framework consists of a classification branch and a balanced contrastive learning branch. v2 and v3 adopt the same augmentation method different from v1. The backbone is shared between two branches. The classifier weights are separately transformed by a MLP to be used as prototypes. All representations are ?2-normalized for balanced contrastive loss.</p><p>each negative class contributes to the gradient equally. Additionally, BCL ensures that the loss of each sample is consistent and class-independent when attaining its lower bound, which implies that the learning will be less biased towards the head classes ( <ref type="figure" target="#fig_6">Fig. 2(c)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Balanced Contrastive Learning</head><p>Class-averaging The key idea is to average the instances of each class in a mini-batch so that each class has an approximate contribution for optimizing. Intuitively, it reduces the proportion of head classes in the denominator and emphasizes the importance of tails. In Section 3.2, we take the loss form as L 1 for analysis. However, there are other ways to implement class-averaging. Here, we give three loss forms as follows:</p><formula xml:id="formula_10">L 1 = ? 1 |B y |?1 p?By\{i} log exp(z i ?z p ) j?Y B 1 |Bj | k?Bj exp(z i ?z k )<label>(6)</label></formula><formula xml:id="formula_11">L 2 = ? 1 |B y |? 1 p?By\{i} log exp(z i ?z p ) j?Y B exp( 1 |Bj | k?Bj z i ?z k )<label>(7)</label></formula><formula xml:id="formula_12">L 3 = ? log exp(z i ? z cy ) j?Y exp(z i ? z cj )<label>(8)</label></formula><p>where the |B j | term will minus one when the positive class is averaged. The only difference between our L 1 and L 2 is that the averaging operation takes place in different positions. L 1 performs averaging outside the exponential function, while L 2 has averaging inside the exponential function. Since -log and exp are convex functions, which implies that L 1 ? L 2 by Jensen's inequality. L 3 take the form proposed in other prototype-based contrastive learning methods <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b41">42]</ref>, where each sample is pulled towards its class prototype and pushed away from others. Note that z ? Z ? R h is ? 2 -normalized for the inner product, so that ?z? 2 = 1. A comparison of their performance is in the experiment section. Below, we choose L 1 for optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class-complement</head><p>To have all classes appear in every mini-batch, we introduce class-center representations, i.e., prototypes for balanced contrastive learning. Now we have the formulation of balanced contrastive loss as follows:</p><formula xml:id="formula_13">L BCL = ? 1 |B y | ? p?{By\{i}}?{cy} log exp(z i ?z p ) j?Y 1 |Bj |+1 k?Bj ?{cj } exp(z i ?z k )<label>(9)</label></formula><p>where c j is the index of the prototype. In practice, we perform a nonlinear mapping of the classifier weights and regard the output as the prototype of each class.</p><p>By applying both class-averaging and class-complement, the lower bound is a class-independent constant, avoiding the model's preference for head classes. Note that in practice, we perform class-complement before class-averaging, as formulated in Eq. 9 and illustrated in <ref type="figure">Fig. 3</ref>. Framework The overview of the proposed framework is shown in <ref type="figure">Fig. 4</ref>. It consists of two main components: a classification branch and a contrastive learning branch. Both branches are trained simultaneously and share the same feature extractor. BCL is a unified end-to-end model, which is different from conventional contrastive learning methods that follow a two-stage training strategy. We have different augmentation methods for the two branches. Three different views are generated in total, where v 1 is the view used for the classification task, v 2 and v 3 are the pairwise views for the contrastive learning task. Following the work in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">24]</ref>, we utilize a symmetric architecture for the contrastive learning branch. We use a MLP with one hidden layer to obtain the representation z i for contrastive learning where z i = W 1 ?(W 2 f i ) and ? is a ReLU function. Instead of using mean embeddings <ref type="bibr" target="#b35">[36]</ref> or learnable parameters <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b41">42]</ref> as prototypes, we are motivated by that the weights of the linear classifier are co-linear with these simplex vertices to which the classes collapse <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b31">32]</ref>. Specifically, we have class-specific weights w 1 , w 2 , . . . , w K after a nonlinear transformation MLP as prototypes z c1 , z c2 , . . . , z c K . Ablations of using different configurations of views and different forms of prototypes are given in the Supplementary Material. All representations for contrastive learning is ? 2 normalized to ensure the feature space is a unit hypersphere. Optimization with Logit Compensation For long-tailed learning tasks, due to the imbalance of data, the output logit of the last classification layer usually exists bias. Logit compensation aims to eliminate the bias caused by the imbalance of data and learn the rectification of the boundary <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b37">38]</ref>. The compensation can be applied during either training or testing. Previous work <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b37">38]</ref> illustrates the desirability of logit compensation in long-tailed visual tasks and it can be summarized as the following form</p><formula xml:id="formula_14">L LC (y, ?(x)) = ?? y log exp(? y (x) + ? y ) y ? ?[Y] exp(? y ? (x) + ? y ? )<label>(10)</label></formula><p>Here, ? y is the factor that controls the importance of class y, ? y is the compensation for class y and its value is related to class-frequency. We define ? y = 1, ? y = log P y as in <ref type="bibr" target="#b30">[31]</ref> and perform logit compensation along with training, where P y denotes the class prior of label y. Finally, we have the following loss for training:</p><formula xml:id="formula_15">L = ?L LC + ?L BCL<label>(11)</label></formula><p>where ? and ? are hyperparameters that control the impact of L LC and L BCL , respectively. In addition, the contrastive branch only intends for the backbone to learn the desired feature embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset</head><p>Long-Tailed CIFAR-10 and CIFAR-100 CIFAR-10-LT and CIFAR-100-LT are the subsets of CIFAR-10 and CIFAR-100, respectively. Both CIFAR-10 and CIFAR-100 contain 50,000 images for training and 10,000 images for the validation of size 32 ? 32 with 10 and 100 classes respectively. Following <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b50">51]</ref>, we use the same long-tailed version for a fair comparison. The imbalanced factor ? is defined by ? = N max /N min , and this reflects the degree of imbalance in the data. The imbalance factors used in the experiment are set to 100, 50, and 10.</p><p>ImageNet-LT ImageNet-LT is proposed in <ref type="bibr" target="#b29">[30]</ref>, which is a long-tailed version of vanilla ImageNet by sampling a subset following the Pareto distribution with power value ? = 0.6. It consists of 115.8K images of 1000 classes in total with 1280 to 5 images per class. iNaturalist 2018 iNaturalist 2018 <ref type="bibr" target="#b39">[40]</ref> is a large-scale dataset containing 437.5K images from 8,142 classes. It is long-tailed by nature with an extremely imbalanced distribution. In addition to long-tailed recognition, this dataset is also used for evaluating the fine-grained classification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation details</head><p>For both CIFAR-10-LT and CIFAR-100-LT, we use the ResNet-32 as the backbone. Same to <ref type="bibr" target="#b7">[8]</ref>, we use AutoAugment <ref type="bibr" target="#b5">[6]</ref> and Cutout <ref type="bibr" target="#b12">[13]</ref> as data augmentation strategies for the classification branch and SimAugment <ref type="bibr" target="#b4">[5]</ref> for the contrastive learning branch. To control the impact of L LC and L BCL , ? is set to 2.0, ? is 0.6, and the temperature ? is set to 0.1. We set the batch size as 256 and the weight decay as 5e?4. The dimension of the hidden layer and the output layer of MLP are set to 512 and 128, respectively. We run BCL for 200 epochs with the learning rate warms up to 0.15 within the first 5 epochs and decays at epoch 160 and 180 with a step size of 0.1. Following <ref type="bibr" target="#b7">[8]</ref>, we also run the model for 400 epochs, where the learning rate warms up to 0.15 within the first 10 epochs and decays at epoch 360 and 380 with a step size of 0.1. We train the above models with one Nvidia GeForce 1080Ti GPU.</p><p>For ImageNet-LT, we use ResNet-50 <ref type="bibr" target="#b18">[19]</ref> and ResNeXt-50-32x4d <ref type="bibr" target="#b46">[47]</ref> as our backbone. We run BCL for 90 epochs with an initial learning rate of 0.1 and the weight decay is 5e?4. For iNaturalist, we use ResNet-50 as our backbone  <ref type="table">Table 4</ref>. Top-1 accuracy of ResNet-32 on CIFAR-100-LT with an imbalance factor of 100. We report the results of 200 epochs and 400 epochs. ? and ? denote results borrowed from <ref type="bibr" target="#b35">[36]</ref> and <ref type="bibr" target="#b7">[8]</ref>.</p><p>and run BCL for 100 epochs using an initial learning rate of 0.2 and the weight decay is 1e?4. For both ImageNet-LT and iNaturalist 2018, we use cosine scheduling for learning rate, ? is set to 1.0 and ? is set to 0.35. The batch size is set to 256. We use the RandAug augmentation strategy for the classification branch, and SimAug for the contrastive learning branch. The performances of different augmentation strategies are in the Supplementary Material. To reduce memory consumption, the dimension of the output layer of MLP is set to 1024 for both datasets. We use the cosine classifier. All models are trained using SGD optimizer with a momentum set to 0.9. For a fair comparison, we reproduce PaCo of ResNext-50 on ImageNet-LT for 180 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation study</head><p>We perform several ablation studies to characterize the proposed BCL method. All experiments are performed on CIFAR-100 with an imbalance factor of 100. First, we compare the performances of different class-averaging implementations (i.e., L 1 , L 2 and L 3 ) mentioned in Section 3.3.</p><p>The main difference between L 1 and L 2 is the order in which the averaging operations are implemented. For L 3 , we use the prototype implemented in our work instead of the average of all embeddings of the same class. As shown in <ref type="table">Table 1</ref>, L 1 achieves the best performance, which is consistent with our previous analysis. Surprisingly, L 3 achieves better performance than L 2 , which may be attributed to the well-represented characteristics of prototypes.</p><p>To demonstrate the superiority of the balanced contrastive loss, we compare the performance of the primary components of the loss in <ref type="table">Table 2</ref>. We use the crossentropy loss with logit compensation (LC) as the vanilla baseline. SC denotes a baseline that adds the contrastive learning branch with conventional supervised contrastive loss. Class-complement and class-averaging are the main techniques of the proposed balanced contrastive loss. We show that using either class-complement or class-averaging alone cannot improve the overall accuracy. In contrast, a significant performance boost can be obtained when both of them are applied, which indicates both components are indispensable components to achieve stronger performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Main results</head><p>Long-tailed CIFAR The comparison results between the proposed BCL and other existing methods on long-tailed CIFAR are shown in <ref type="table">Table 3</ref>. As can be seen from the table, BCL consistently outperforms the other methods. Furthermore, BCL achieves better performance on long-tailed CIFAR datasets with large imbalance factors. We note that the accuracy gap between BCL and Hybrid-SC decreases as the degree of data imbalance reduces. This result is mainly attributed to the fact that the conventional supervised contrastive loss leads to more serious bias in representation learning when unbalance problem is more severe.</p><p>Further, we report the accuracy on three groups of classes, including Many-shot(&gt;100 images), Mediumshot(20 ? 100 images), Few-shot(&lt;20 images), on CIFAR-100-LT with imbalance factor as 100. Additionally, for a It's worthwhile to mention that different to most of the previous methods which compromise the performance of the head classes, our BCL further improves the performance of the head classes while simultaneously improving the tails. ImageNet-LT <ref type="table">Table 5</ref> and <ref type="table">Table 6</ref> list the results on ImageNet-LT. We report the overall Top-1 accuracy as well as the Top-1 accuracy on Many-shot, Medium-shot, and Few-shot groups. Compared with Balanced Softmax <ref type="bibr" target="#b33">[34]</ref>, which proposes a logit compensation by adjusting the predictions according to the class frequency. BCL significantly outperforms Balanced Softmax on all groups, confirming the well-learned representations can boost the overall performance. LWS <ref type="bibr" target="#b22">[23]</ref>, ? -norm <ref type="bibr" target="#b22">[23]</ref>, and DisAlign <ref type="bibr" target="#b49">[50]</ref> adopt the two-stage learning strategy. These methods focus on fine-tuning the classifier in the second stage, while they neglect the bias implied in the representation learning stage. PaCo <ref type="bibr" target="#b7">[8]</ref> uses a set of parametric centers in supervised contrastive learning. These centers are assigned with a much greater weight, which can be regarded as the weights of a classifier. However, the prototypes used in BCL complement the samples of each class to make sure that all classes appear in every mini-batch. Compared with PaCo, BCL achieves a better overall accuracy of 57.1% with remarkable accuracy improvements on the head and few classes.</p><p>iNaturalist 2018 <ref type="table">Table 5</ref> shows the experimental results on iNaturalist 2018. Since BCL is a contrastive learning method, it benefits more from a longer training time. However, for a fair comparison, we report the results of various models trained for up to 100 epochs. Hybrid-SC <ref type="bibr" target="#b41">[42]</ref> and Hybrid-PSC <ref type="bibr" target="#b41">[42]</ref> are contrastive learning approaches, and their performances are inferior to BCL due to the potential </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we investigated the problem of long-tailed recognition from the perspective of representation learning. We provided in-depth analysis to demonstrate that existing supervised contrastive learning forms an undesired asymmetric geometry configuration for long-tailed data. To tackle the imbalanced data representation learning problem, we developed a balanced contrastive loss, so that all classes are optimized for a regular simplex configuration that yields a balanced feature space. In addition to BCL, we employ a classification branch with logit compensation to tackle the biased classifier. Overall we have presented a framework unifying both branches. We conducted extensive experiments on the long-tailed benchmarks of long-tailed CIFAR, ImageNet-LT, and iNaturalist 2018. The experimental results adequately demonstrate the superiority of BCL compared to existing long-tailed learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgements</head><p>This work was supported in part by NSFC project (# 62072116), Shanghai Municipal Commission of Economy and Informatization Project (2020-GYHLW-01009), and in part by Shanghai Pujiang Program (20PJ1401900).</p><p>In this section, we will proof Theorem 2 and Theorem 3 proposed in section 3.2. The main idea of the proof is to decouple the class-specific batch-wise loss as attraction term and repulsion term as in <ref type="bibr" target="#b15">[16]</ref>. First, we will show the spontaneous appearance of variability collapse as the training process in attraction term. When this condition holds, we find that to minimize the loss, the solution of the model spontaneously satisfies the simplex configuration.</p><p>Before the detailed derivation, recall the main notions and definitions of this paper:</p><formula xml:id="formula_16">? h, K, N ? N ? Z = R h ? Y = [K] = {1, 2, . . . , K}</formula><p>Definition 1 (Supervise contrastive loss) For an instance x i of representation z i in a batch B, supervised contrastive loss has the following expression:</p><formula xml:id="formula_17">L i = ? 1 |B y | ? 1 p?By\{i} log exp(z i ? z p ) k?B\{i} exp(z i ? z k )<label>(1)</label></formula><p>Definition 2 (Balanced contrastive loss) For an instance x i of representation z i in a batch B, balanced contrastive loss has the following expression:</p><formula xml:id="formula_18">L i = ? 1 |B y | ? 1 p?By\{i} log exp(z i ? z p ) j?Y B 1 |Bj | k?Bj exp(z i ? z k )<label>(2)</label></formula><p>Definition 3 (Class-specific batch-wise loss)</p><formula xml:id="formula_19">L(Z; Y, B, y) = i?By L i if |B y | &gt; 1 0 else (3)</formula><p>Definition 4 (Regular simplex) A set of points ? 1 , . . . , ? K ? R h form the vertices of a regular simplex inscribed in the hypersphere of radius ? &gt; 0, if and only if the following conditions hold:</p><formula xml:id="formula_20">(1) i?[K] ? i = 0 (2) ?? i ? = ?, for i ? [K] (3) ?d ? R : d = ?? i , ? j ? for 1 ? i &lt; j ? K</formula><p>where B y and Y B are subsets of B and Y, respectively. Note that the |B j | term in above equations will minus one when the positive class is averaged. Here, we omit hyper parameter temperature ? and ??? for the inner product operation. Additionally, we default to K ? h + 1 and assume ?z i ? 2 = 1.</p><p>Proof of Theorem 2 First we rewrite class-specific batch-wise loss as following form:</p><formula xml:id="formula_21">L BCL (Z; Y, B, y) = i?By ? 1 |B y | ? 1 p?By\{i} log exp(z i ? z p ) j?Y B 1 |Bj | k?Bj exp(z i ? z k ) = i?By log ? ? ? j?Y B 1 |Bj | k?Bj exp(z i ? z k ) p?By\{i} exp(z i , z p ) 1/|By|?1 ? ? ? = i?By log ? ? ? j?Y B 1 |Bj | k?Bj exp(z i ? z k ) exp( 1 |By|?1 p?By\{i} z i ? z p ) ? ? ?<label>(4)</label></formula><p>The key idea is to divide the sum in the numerator into positives and negatives. Since the exponential function is convex, by applying Jensen's inequality, we have</p><formula xml:id="formula_22">1 |B y | ? 1 k?By\{i} exp(z i ? z k ) (Q1) ? exp ? ? 1 |B y | ? 1 k?By\{i} z i ? z k ? ? 1 |B j | k?B j j? =y exp(z i ? z k ) (Q2) ? exp ? ? 1 |B j | k?Bj z i ? z k ? ?<label>(5)</label></formula><p>The equality is attained if and only if:</p><formula xml:id="formula_23">(Q1) There is C i (B, y) such that ?k ? B y \ {i} all inner products z i ? z k = C i (B, y) are equal.</formula><p>(Q2) There is D i (B, y, j) such that ?k ? B j,j? =y all inner products z i ? z k = D i (B, y, j) are equal.</p><p>Thus, the sum in the numerator can be written as follows</p><formula xml:id="formula_24">j?Y B 1 |B j | j?Bj exp(z i ? z k ) ? exp ? ? 1 |B y | ? 1 p?By\{i} z i ? z p ? ? + j?Y B j? =y exp ? ? 1 |B j | k?Bj z i ? z k ? ?<label>(6)</label></formula><p>By leverage Jensen's inequality again on the latter term, resulting in</p><formula xml:id="formula_25">j?Y B j? =y exp ? ? 1 |B j | k?Bj z i ? z k ? ? (Q3) ? (|Y B | ? 1) exp ? ? ? 1 |Y B | ? 1 j?Y B j? =y 1 |B j | k?Bj z i ? z k ? ? ?<label>(7)</label></formula><p>Here, the equality is attained if and only if</p><formula xml:id="formula_26">(Q3) There is E i (B, y) such that ?j ? Y B,j? =y , ?k ? B j all inner products z i ? z k = E i (B, y) are equal.</formula><p>Thus, for a specific mini-batch, Eq. 4 can be written as </p><formula xml:id="formula_27">L BCL (Z; Y, B, y) ? i?By log ? ? ? ? ? ? ? 1 + (|Y B | ? 1) exp ? ? ? ? ? ? ? 1 |Y B | ? 1 q?Y B \{y} 1 |B q | k?Bq z i ? z k repulsion term ? 1 |B y | ? 1 j?By\{i} z i ? z j attraction term ? ? ? ? ? ? ? ? ? ? ? ? ? ?</formula><formula xml:id="formula_28">S att (Z; Y, B, y) = ? 1 |B y | ? 1 j?By\{i} z i ? z j S rep (Z; Y, B, y) = 1 |Y| ? 1 q?Y\{y} 1 |B q | k?Bq z i ? z k<label>(9)</label></formula><p>Regroup the addends, we can obtain the following formulation </p><formula xml:id="formula_29">L BCL (Z; Y ) =</formula><p>Let ? &gt; 0, and f : R ? R, x ? log(1 + ? exp(x)). It is easy to verify that the function f is smooth with second derivative and convex. According to Jensen's inequality, we obtain the lower bound as follows</p><formula xml:id="formula_31">L BCL (Z; Y ) (Q4) ? |D| log ? ? 1 + (|Y| ? 1) exp ? ? B?B y?Y i?By S(Z; Y, B, y) ? ? ? ? (11)</formula><p>where D denotes the dataset, the equality is attained if and only if:</p><p>(Q4) There is constant ? such that ?B ? B, ?y ? Y and ?i ? B y , the values of S(Z; Y, B, y) = ? agree.</p><p>Next we derive the sum of attraction terms. For every Y ? Y N and every Z ? Z N , using the Cauchy-Schwarz inequality and the assumption that Z is a unit hypersphere, we have</p><formula xml:id="formula_32">i?By S att (Z; Y, B, y) = ? 1 |B y | ? 1 i?By j?By\{i} z i ? z j (Q5) ? ?|B y | ? 1 |B y |(|B y | ? 1) i?By j?By\{i} ?z i ??z j ? = ?|B y |<label>(12)</label></formula><p>Since the z i and z j are on a hypersphere, this implies the condition of equality is equivalent to z i = z j .</p><p>(Q5) For every n, m ? [N ], y n = y m implies z n = z m .</p><p>Note that (Q5) implies the variability collapse, that is all the within-class representations collapse to their class means. When this condition holds and recall the definition of balanced contrastive loss, for an instance x i with label y in a batch B, balanced contrastive loss has the following expression:</p><formula xml:id="formula_33">L BCL = B?B y?Y i?By L i L i = ? log exp(z i ? z cy ) exp(z i ? z cy ) + j?Y\{y} exp(z i ? z cj )<label>(13)</label></formula><p>Note that under the condition of (Q5), for every B ? B, every y ? Y and every i ? B y , it holds that z i = z cy , and the label configuration of L i is balanced. To minimize the above loss, the solution obviously satisfies the simplex configuration. Leveraging the lower bound of supervised contrastive loss under balanced settings <ref type="bibr" target="#b15">[16]</ref>, we have</p><formula xml:id="formula_34">L i (Q6) ? log 1 + (K ? 1) exp ? K K ? 1<label>(14)</label></formula><p>(Q6) z c1 , . . . , z c K f orm a regular simplex</p><p>Combine the aforementioned conditions, we can obtain the claimed lower bound of balanced contrastive loss:</p><formula xml:id="formula_35">L BCL (Z; Y ) ? |D| log 1 + (K ? 1) exp ? K K ? 1<label>(15)</label></formula><p>Recall that Z is an N point configuration with labels Y , the equality of Eq. 15 is attained if and only if the following conditions hold. There are ? 1 , . . . , ? K ? R h such that:</p><p>(1) ?n ? [N ] : z n = ? yn (2) ? 1 , . . . , ? K f orm a regular simplex</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Gradient Analysis</head><p>Balanced contrastive loss achieves the balance by averaging the parts of each class. An analysis of the gradients well reflects this conclusion. First, we will discus the defects of the supervised contrastive loss when working on the long-tailed data. Next, we will give the gradient derivation of the balanced contrastive loss, from which we can easily identify that balanced contrastive loss is better at handling long-tailed data.</p><p>Recall the definitions of supervised contrastive (SC) loss, neglecting the hyper parameter temperature ? , the gradient of SC loss has the following formulation <ref type="bibr" target="#b23">[24]</ref>: <ref type="bibr" target="#b15">(16)</ref> where B C y is the complement set of B y and we have defined:</p><formula xml:id="formula_36">?L SC i ?z i = p?By\{i} z p P ip ? 1 |B y | ? 1 positive term + n?B C y z n P in negative term</formula><formula xml:id="formula_37">P ip = exp(z i ? z p ) k?B\{i} exp(z i ? z k ) P in = exp(z i ? z n ) k?B\{i} exp(z i ? z k )<label>(17)</label></formula><p>Since there is a normalization function before computing the loss. Let w i denote the output prior to normalization in a slight abuse of notation, i.e., z i = w i /?w i ?. Then, the gradient with respect to w i is as follows:</p><formula xml:id="formula_38">?L SC i ?w i = 1 ?w i ? (I ? z i z T i ) ? ? p?By\{i} z p P ip ? 1 |B y | ? 1 + n?B C y z n P in ? ? = 1 ?w i ? ? ? ? ? ? ? ? p?By\{i} (z p ? (z i ? z p )z i )(P ip ? 1 |B y | ? 1 ) positive term + n?B C y (z n ? (z i ? z n )z i )P in negative term ? ? ? ? ? ? ?<label>(18)</label></formula><p>We mainly concern with the gradients from the negative term. For hard negatives, z i ? z n ? 0 (assume z i ? z n ? 0 ), so that the gradient of L SC i from the hard negatives is as follows:</p><formula xml:id="formula_39">n?B C y ?z n ? (z i ? z n )z i ?|P in | ? n?B C y |P in | = n?B C y 1 k?B\{i} exp(z i ? z k )<label>(19)</label></formula><p>Given an anchor, the term in the denominator is consistent for all negative samples, resulting in the negative class gradient is proportional to the number of samples. But under the long-tailed distribution, within almost every mini-batch, there are much more head class samples than tail class samples. This leads to all classes being as far away from the head category as possible, and results in an unbalanced feature space.</p><p>For balanced contrastive (BC) loss, the gradient has the following formulation:</p><formula xml:id="formula_40">?L BC i ?z i = ? 1 |B y | ? 1 p?By\{i} ? ? z p ? j?Y 1 |B j | k?Bj z k X ik ? ? = ? 1 |B y | ? 1 p?By\{i} ? ? z p ? 1 |B y | ? 1 p ? ?By\{i} z p ? X ip ? ? j?Y\{y} 1 |B j | k?Bj z k X ik ? ? = 1 |B y | ? 1 p?By\{i} z p (X ip ? 1) positive term + j?Y\{y} 1 |B j | k?Bj z k X ik negative term<label>(20)</label></formula><p>where we have defined:</p><formula xml:id="formula_41">X ip = exp(z i ? z p ) j?Y 1 |Bj | k?Bj exp(z i ? z k ) X ik = exp(z i ? z k ) j?Y 1 |Bj | k?Bj exp(z i ? z k )<label>(21)</label></formula><p>Similar to the derivation of supervised contrastive loss, the gradient with respect to w i of balanced contrastive loss is as follows:</p><formula xml:id="formula_42">?L BC i ?w i = 1 ?w i ? ? ? ? ? ? ? ? 1 |B y | ? 1 p?By\{i} (z p ? (z i ? z p )z i )(X ip ? 1) positive term + j?Y\{y} 1 |B j | k?Bj (z k ? (z i ? z k )z i )X ik negative term ? ? ? ? ? ? ?<label>(22)</label></formula><p>Intuitively, balanced contrastive loss balances the gradients from negative classes, avoiding a tremendous gradient update from the negative head class samples. It retains several good properties of supervised contrastive loss. Easy negatives z i ? z k ? ?1 contributes less gradient while hard negatives more gradient, and easy positives z i ? z p ? 1 (assume z i ? z p ? 0), contributes less gradient compared with hard positives. In addition to these common properties, the balanced contrastive loss is better at feature alignment, where points belonging to the same class are pulled together. Since almost every mini-batch is long-tailed, for these head class anchors, the gradients in Eq. 18 from the positives will be much larger than when the anchor is tails. It results in tail class samples being unconcerned to pulling these points together. Comparing Eq. 18 with Eq. 22, balanced contrastive loss also adjusts the gradients from the positives, eliminating excessive gradient fluctuations caused by having different anchor classes in different batches and allowing the points of tail classes been pulled closer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">More Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Ablations of Different Forms of Prototypes.</head><p>We compare our method with the other two implementations of the prototype. The first one is using the exponential moving average to calculate the prototype. The second one is using learnable parameters <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b41">42]</ref>. As shown in <ref type="table">Table 1</ref>, our implementation achieves the best results and the other two implementations achieve similar results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Many  <ref type="table">Table 1</ref>. Ablation study for different implementations of prototypes on CIFAR-100-LT with an imbalance fator of 100. All models run for 400 epochs with the same training scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Ablations of Different Configurations of Views.</head><p>We compare our configuration with the other two configurations of views. We use the simple augmentation method, i.e., SimAug, to generate both views for contrastive learning. We further have one of the views generated via a stronger augmentation method, i.e., RandAug, or both of the views generated by RandAug. As shown in <ref type="table">Table 2</ref>, stronger argumentation yields better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Many  <ref type="table">Table 2</ref>. Ablation study for different configurations of views on ImageNet-LT. All models run for 90 epochs with the same training scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Confusion Matrix.</head><p>To clearly show where the models are getting confused on long-tailed data, we illustrate the confusion matrix of predictions on CIFAR-10-LT in <ref type="figure" target="#fig_0">Figure 1</ref>. With vanilla cross-entropy, the model tends to misclassify low-frequency artifactory categories as high-frequency artifactory categories and low-frequency animal classes as high-frequency animal classes. With logit compensation, misclassification of low-frequency classes is greatly eased. With the proposed BCL, low-frequency classes are more correctly predicted than high-frequency classes, and the accuracies of high-frequency classes are also improved. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Visualization of Learned Features.</head><p>Similar to <ref type="bibr" target="#b27">[28]</ref>, we visualize the 2-dimensional MLP output feature learned by SCL and BCL on CIFAR-10-LT. Features of different classes learned by BCL distribute more uniform on the sphere and are more separable than SCL. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Illustration of Balanced Contrastive Learning. Head classes dominant the training procedure of SCL and compress the representation space of tail classes on the hypersphere (denoted by ?). BCL learns an embedding space that treats all classes equally and forms a regular simplex (denoted by ?).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Theorem 1 .</head><label>1</label><figDesc>Assuming the normalization function is applied for feature embedding, let Z = (z 1 , . . . , z N ) ? Z N be an N point configuration with labels Y = (y 1 , . . . , y N ) ? [K] N , where Z = {z ? R h : ?z? = 1}. The class-specific batch-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 8 )</head><label>8</label><figDesc>which ends the proof of Theorem 2. Here, the equality is attained if and only if conditions (Q1) and (Q3) hold for every i ? B y . Additionally, constants C i (B, y) and E i (B, y) only depend on the batch B and the label y. Proof of Theorem 3 On the basis of theorem 2, we assume Y B = Y for every batch B. For simplicity, we rewrite the two terms of the exponential function in Theorem 2 as the following form S(Z; Y, B, y) = S att (Z; Y, B, y) + S rep (Z; Y, B, y)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>B?B y?Y L BCL (Z; Y, B, y) ? B?B y?Y i?By log (1 + (|Y| ? 1) exp(S(Z; Y, B, y)))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 1 .</head><label>1</label><figDesc>Illustration of confusion matrix of prediction results on CIFAR-10-LT for different models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 .</head><label>2</label><figDesc>Illustration of features learned by SCL and BCL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Ablation study for different class-averaging methods. All models run for 200 epochs with the same training scheme. Ablation study for the primary components of BCL. LC and SC denote logit compensation and supervised contrastive loss.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Methods Top-1 Acc.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>L1</cell><cell>51.9</cell><cell></cell></row><row><cell></cell><cell></cell><cell>L2</cell><cell>50.2</cell><cell></cell></row><row><cell></cell><cell></cell><cell>L3</cell><cell>51.0</cell><cell></cell></row><row><cell cols="5">LC SC Complement Averaging Top-1 Acc.</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>50.8</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>52.4</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>52.3</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>52.0</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>53.9</cell></row></table><note>Complement and averaging stand for class-complement and class- averaging, respectively. All models run for 400 epochs.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>47.11 58.91 77.83 82.13 88.53 Focal loss ? [29] 38.41 44.32 55.78 70.38 76.72 86.66 CB-Focal [10] 39.60 45.17 57.99 74.57 79.27 87.10 BBN [51] 42.56 47.02 59.12 79.82 81.18 88.32</figDesc><table><row><cell></cell><cell></cell><cell>Method</cell><cell></cell><cell cols="2">CIFAR-100-LT</cell><cell></cell><cell>CIFAR-10-LT</cell></row><row><cell></cell><cell cols="2">Imbalance Factor</cell><cell></cell><cell>100</cell><cell>50</cell><cell>10</cell><cell>100</cell><cell>50</cell><cell>10</cell></row><row><cell></cell><cell cols="7">SSP [48] 43.43 Casual model [39] 44.10 50.30 59.60 80.60 83.60 88.50</cell></row><row><cell></cell><cell cols="2">LDAM-DRW [3]</cell><cell></cell><cell cols="4">42.04 46.62 58.71 77.03 81.03 88.16</cell></row><row><cell></cell><cell></cell><cell>ResLT [7]</cell><cell></cell><cell cols="4">48.21 52.71 62.01 82.40 85.17 89.70</cell></row><row><cell></cell><cell cols="2">Hybrid-SC [42]</cell><cell></cell><cell cols="4">46.72 51.87 63.05 81.40 85.36 91.12</cell></row><row><cell></cell><cell cols="3">MetaSAug-LDAM [27]</cell><cell cols="4">48.01 52.27 61.28 80.66 84.34 89.68</cell></row><row><cell></cell><cell></cell><cell>BCL(ours)</cell><cell></cell><cell cols="4">51.93 56.59 64.87 84.32 87.24 91.12</cell></row><row><cell cols="8">Table 3. Top-1 accuracy of ResNet-32 on CIFAR-100-LT and CIFAR-10-LT. The best results are marked in bold.  ? denotes results</cell></row><row><cell cols="4">borrowed from [42]. We report the results of 200 epochs.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell cols="3">Many Medium Few</cell><cell>All</cell><cell></cell><cell></cell></row><row><cell>200 epochs</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>? -norm  ? [23]</cell><cell>61.4</cell><cell>42.5</cell><cell cols="2">15.7 41.4</cell><cell></cell><cell></cell></row><row><cell>Hybrid-SC [42]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>46.7</cell><cell></cell><cell></cell></row><row><cell>MetaSAug-LDAM [27]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>48.0</cell><cell></cell><cell></cell></row><row><cell>DRO-LT [36]</cell><cell>64.7</cell><cell>50.0</cell><cell cols="2">23.8 47.3</cell><cell></cell><cell></cell></row><row><cell>RIDE(3 experts) [44]</cell><cell>68.1</cell><cell>49.2</cell><cell cols="2">23.9 48.0</cell><cell></cell><cell></cell></row><row><cell>BCL(Ours)</cell><cell>67.2</cell><cell>53.1</cell><cell cols="2">32.9 51.9</cell><cell></cell><cell></cell></row><row><cell>400 epochs</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Balanced Softmax  ? [34]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>50.8</cell><cell></cell><cell></cell></row><row><cell>PaCo [8]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>52.0</cell><cell></cell><cell></cell></row><row><cell>BCL(Ours)</cell><cell>69.7</cell><cell>53.8</cell><cell cols="2">35.5 53.9</cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>1. <ref type="table">Proof of Theorem 2 and Theorem 3</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A systematic study of the class imbalance problem in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuto</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej A</forename><surname>Mazurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="259" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">What is the effect of importance weighting in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Lipton</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="872" to="881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning imbalanced datasets with labeldistribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Neural Information Processing Systems</title>
		<meeting>the 33rd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1567" to="1578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A study of multi-task and region-wise deep learning for food ingredient recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong-Wah</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Gang</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1514" to="1526" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="113" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Reslt: Residual learning for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.10633</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Parametric contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="715" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="9268" to="9277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9268" to="9277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mixed-dish recognition with contextual relation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixi</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyan</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Multimedia</title>
		<meeting>the 27th ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="112" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Class imbalance and cost sensitivity: Why undersampling beats oversampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Drumnond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Holte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML-KDD 2003 Workshop: Learning from Imbalanced Datasets</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploring deep neural networks via layer-peeled model: Minority collapse in imbalanced training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangfeng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie J</forename><surname>Su</surname></persName>
		</author>
		<idno>2021. 2</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">43</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dissecting supervised constrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Graf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Hofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Niethammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kwitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Selfsupervised co-training for video representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengda</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5679" to="5690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Disentangling label distribution for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngkyu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungju</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwanghee</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seokjun</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beomsu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buru</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="6626" to="6636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning deep representation for imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5375" to="5384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Exploring balanced feature spaces for representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sa</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prannay</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Prototypical contrastive learning of unsupervised representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Metasaug: Meta semantic augmentation for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaixiong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><forename type="middle">Harold</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinjing</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="5212" to="5221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Targeted supervised contrastive learning for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijie</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dina</forename><surname>Katabi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.13998</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2537" to="2546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Long-tail learning via logit adjustment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Singh Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Prevalence of neural collapse during the terminal phase of deep learning training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vardan Papyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">L</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="24652" to="24663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Dynamic sampling in convolutional neural networks for imbalanced data classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samira</forename><surname>Pouyanfar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yudong</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anup</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiman</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kent</forename><surname>Kaseb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Gauen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Dailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yung-Hsiang</forename><surname>Aghajanzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu-Ching</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE conference on multimedia information processing and retrieval (MIPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="112" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Balanced meta-softmax for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunjun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunan</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Neural Information Processing Systems(NeurIPS)</title>
		<meeting>Neural Information Processing Systems(NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Distributional robustness loss for long-tail learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dvir</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Chechik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="9495" to="9504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Video relation detection via multiple hypothesis association</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixuan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xindi</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Gang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Multimedia</title>
		<meeting>the 28th ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3127" to="3135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Equalization loss for long-tailed object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingru</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changbao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="11662" to="11671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Longtailed classification by keeping the good and removing the bad momentum causal effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The inaturalist species classification and detection dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><forename type="middle">Mac</forename><surname>Grant Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8769" to="8778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Understanding the behaviour of contrastive loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaping</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page" from="2495" to="2504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Contrastive learning based hybrid networks for longtailed image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="943" to="952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cross-domain contrastive learning for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zejia</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Gang</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Long-tailed recognition by routing diverse distribution-aware experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7032" to="7042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Visual cooccurrence alignment learning for weakly-supervised video moment retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Gang</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Multimedia</title>
		<meeting>the 29th ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1459" to="1468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Rethinking the value of labels for improving class-imbalanced learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Token shift transformer for video classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbin</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong-Wah</forename><surname>Ngo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Multimedia</title>
		<meeting>the 29th ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="917" to="925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Distribution alignment: A unified framework for long-tail visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shipeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2361" to="2370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Min</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="9719" to="9728" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
