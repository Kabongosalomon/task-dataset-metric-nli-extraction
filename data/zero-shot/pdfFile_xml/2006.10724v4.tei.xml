<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cyclic Differentiable Architecture Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houwen</forename><surname>Peng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Fu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Du</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Ling</surname></persName>
						</author>
						<title level="a" type="main">Cyclic Differentiable Architecture Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>JOURNAL OF L A T E X CLASS FILES, VOL. *, NO. *, * * 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Cyclic</term>
					<term>Introspective Distillation</term>
					<term>Differentiable Architecture Search</term>
					<term>Unified Framework !</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Differentiable ARchiTecture Search, i.e., DARTS, has drawn great attention in neural architecture search. It tries to find the optimal architecture in a shallow search network and then measures its performance in a deep evaluation network. The independent optimization of the search and evaluation networks, however, leaves a room for potential improvement by allowing interaction between the two networks. To address the problematic optimization issue, we propose new joint optimization objectives and a novel Cyclic Differentiable ARchiTecture Search framework, dubbed CDARTS. Considering the structure difference, CDARTS builds a cyclic feedback mechanism between the search and evaluation networks with introspective distillation. First, the search network generates an initial architecture for evaluation, and the weights of the evaluation network are optimized. Second, the architecture weights in the search network are further optimized by the label supervision in classification, as well as the regularization from the evaluation network through feature distillation. Repeating the above cycle results in a joint optimization of the search and evaluation networks and thus enables the evolution of the architecture to fit the final evaluation network. The experiments and analysis on CIFAR, ImageNet and NATS-Bench demonstrate the effectiveness of the proposed approach over the state-of-the-art ones. Specifically, in the DARTS search space, we achieve 97.52% top-1 accuracy on CIFAR10 and 76.3% top-1 accuracy on ImageNet. In the chain-structured search space, we achieve 78.2% top-1 accuracy on ImageNet, which is 1.1% higher than EfficientNet-B0. Our code and models are publicly available at https://github.com/microsoft/Cream. ! 1. Cell is a basic building block for network construction. It consists of convolution, pooling, nonlinearity and a prudent selection of connections.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>D EEP learning has enabled remarkable progress in a variety of vision tasks over the past years. One crucial factor for this progress is the design of novel neural network architectures. Most of current employed architectures are designed by human experts, which is time-consuming and error-prone. Because of this, there is a growing interest in automatic Neural Architecture Search (NAS) for vision tasks, such as image recognition <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, object detection <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref> and semantic segmentation <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>.</p><p>Differentiable architecture search, i.e., DARTS <ref type="bibr" target="#b6">[7]</ref>, has become one of the most popular NAS pipelines nowadays due to its relatively low computational cost and competitive performance <ref type="bibr" target="#b7">[8]</ref>. Different from previous methods <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref> that search over a discrete set of candidate architectures, DARTS relaxes the search space to be continuous, so that the architecture can be optimized by the gradient descent. The efficiency of gradient-based optimization reduces the search cost from thousands of GPU days to a few. According to the recent NAS survey <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, due to the simplicity and elegance of the DARTS architecture, the research work related to DARTS is quite rich <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>. Moreover, gradient optimization in a continuous search strategy is an important trend of NAS. Existing DARTS approaches have to divide the search process into two steps: search and evaluation, as shown in <ref type="figure" target="#fig_1">Fig. 1 (a)</ref>. The search step employs a small network to discover the optimal cell 1 structures, and the evaluation step stacks the discovered cells to construct a large network for final evaluations. This results in the optimization of search process is independent from the target evaluation network. As shown in <ref type="figure" target="#fig_1">Fig. 1 (b)</ref>, PDARTS <ref type="bibr" target="#b14">[15]</ref> tried to alleviate the gap by gradually deepening the search network. In <ref type="figure" target="#fig_1">Fig. 1(c)</ref>, EnTranNAS <ref type="bibr" target="#b15">[16]</ref> built the search network by combining the evaluation network module and the search network module to reduce the gap. Besides, SNAS <ref type="bibr" target="#b16">[17]</ref> and GDAS <ref type="bibr" target="#b17">[18]</ref> applied Gumbel-softmax and modified straightthrough Gumbel-Softmax to relieve the gap caused by discretization. Furthermore, AutoHAS <ref type="bibr" target="#b18">[19]</ref> augmented GDAS with an entropy term to search for both hyperparameters and architectures. However, those methods still separates the search and evaluation process. As a consequence, the performance of discovered architectures in the search network has limited correlation with the actual performance of the evaluation network. On the other hand, there are several recent works casting doubt on the effectiveness of DARTS. Li and Talwalkar <ref type="bibr" target="#b19">[20]</ref> observe that even a simple random search method can find architectures outperforming the original DARTS. Zela et al. <ref type="bibr" target="#b20">[21]</ref> and Liang et al. <ref type="bibr" target="#b21">[22]</ref> show that DARTS is prone to degenerate to networks filled with parametric-free operations, e.g. skip connections, leading to a poor performance of the searched architecture. Wang et al. <ref type="bibr" target="#b22">[23]</ref> find that the problematic optimization of DARTS  In prior DARTS <ref type="bibr" target="#b6">[7]</ref>, PDARTS <ref type="bibr" target="#b14">[15]</ref>, and EnTranNAS <ref type="bibr" target="#b15">[16]</ref>, the target evaluation network does not engage in the architecture search. In contrast, our CDARTS combines the search and evaluation networks into a joint optimization framework. The blue and gold boxes indicate the search and evaluation networks, respectively. results in the learned architecture weights are insufficient to reflect the relative ranking of different architectures during evaluation <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>.</p><formula xml:id="formula_0">?</formula><p>To alleviate these issues, we propose a cyclic differentiable architecture search method, dubbed CDARTS. CDARTS integrates the search and evaluation networks into a unified architecture, and jointly trains the two networks in a cyclic way. As visualized in <ref type="figure" target="#fig_1">Fig. 1(c)</ref>, the shallow search network provides the best intermediate architecture to the evaluation network. In turn, the search network gets the feedback from the evaluation network (with higher model capacity due to more layers) by introspective distillation. The distillation is introspective because it does not require introducing thirdparty models, such as human-designed architectures, to serve as the teacher models. This is crucial for practical applications because there is usually no available teacher model in new tasks. As proved by Liu et al. <ref type="bibr" target="#b26">[27]</ref> and Li et al. <ref type="bibr" target="#b27">[28]</ref>, the knowledge of a network model not only lies in the network parameters but also the network structure. The introspective distillation could transfer the knowledge embedded in parameters as well as the the knowledge inside the structure from the evaluation network to the search network.</p><p>Moreover, instead of training the search and evaluation networks separately, we propose a joint learning algorithm to optimize the integrated architecture in a cyclic manner. It consists of a separate learning and a joint learning stage. The separate learning stage aims to optimize the search and evaluation networks to have good initializations. The joint learning stage is to update the architecture and network weights alternatively. Specifically, the joint learning stage first optimizes the architecture weights and the evaluation network weights by jointly training the search and evaluation networks. Then, it optimizes the search network weights according to the updated architecture weights. These two learning stages are performed alterna-tively, leading to a cyclic optimization between the search and evaluation networks. Eventually, the target evaluation network obtains a shaped architecture tailored by the search network. The proposed jointly training scheme allows the direct optimization of the evaluation network, reliving the problematic optimization of DARTS <ref type="bibr" target="#b22">[23]</ref>.</p><p>We evaluate our CDARTS algorithm on image classification task and conduct experiments on CIFAR <ref type="bibr" target="#b28">[29]</ref>, ImageNet <ref type="bibr" target="#b29">[30]</ref>, as well as the recently proposed NATS-Bench benchmark <ref type="bibr" target="#b95">[95]</ref>. The experiments demonstrate that, on CIFAR, CDARTS achieves superior performance to existing state-of-the-art DARTS approaches. On the large-scale ImageNet, the proposed CDARTS also shows its superiority in the DARTS family, while achieving comparable performance to MobileNet-V3 <ref type="bibr" target="#b31">[32]</ref>, which blends automatic search techniques with human intuition. Moreover, for a fair comparison with other NAS algorithms, such as oneshot <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b32">[33]</ref> and reinforcement learning-based <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref> approaches, we conduct an experiment on the NATS-Bench benchmark, which provides a fixed search space with a unified training setting. The experiment shows that CDARTS achieves competitive performance compared with 10 recent prevailing NAS approaches. Last but not the least, we also apply our introspective distillation search method to the chain-structured search space <ref type="bibr" target="#b11">[12]</ref> and achieve a gain of 1.6% over EfficientNet-B0 <ref type="bibr" target="#b35">[36]</ref> on ImageNet with a similar model size. We further transfer the discovered architectures to the downstream object detection task and semantic segmentation task. For object detection, we get an AP of 36.2 on the COCO validation set, which surpasses the state-of-theart MobileNetV3 by 6.3%. And for semantic segmentation, we obtain an mIoU of 78.2% on the cityscapes validation set and 40.4% on ADE20K validation set, which are 1.9% and 3% superior than the recent SegFormer <ref type="bibr" target="#b36">[37]</ref>, respectively.</p><p>Our main contributions are summarized as below:</p><p>? We rethink the bi-level optimization for NAS and empirically show that the performance of discovered architectures in the search network has a limited correlation with the actual performance of the evaluation network, leading to the instability issue. We propose brand-new joint optimization objectives for differentiable one-shot NAS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>We integrate the search and evaluation networks into a unified framework, and propose a cyclic learning algorithm. Such algorithm addresses the problematic optimization issue in previous differentiable methods <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b37">[38]</ref>, thus being able to improve the stability of the search algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>We propose an introspective distillation mechanism to transfer the knowledge embedded in both parameters and structure from the evaluation network to the search network. In contrast to classical distillation methods <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b38">[39]</ref>, such introspective method does not require a predefined third-party teacher model, which is more flexible in practice.</p><p>? Extensive experiments on three types of search spaces verify the robustness of the proposed method. Moreover, the results of the searched architectures in the object detection and semantic segmentation tasks demonstrate their generality and transferability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Deep neural networks (DNN) have played an important role in computer vision tasks such as image recognition <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, object detection <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, segmentation <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>, tracking <ref type="bibr" target="#b46">[47]</ref>, and so on <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b49">[50]</ref>. However, designing effective and efficient neural architectures is a labor-intensive process that may require lots of trials by human experts. Hence, automatic neural architecture search (NAS) <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b53">[54]</ref> has emerged in recent years. In this section, we first summarize the search space, and then discuss the search strategies in recent NAS methods. At last, we briefly review some distillation methods which are most related to our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Search Space</head><p>The search space defines all possible architectures in principle. A well designed search space can simplify the search. Current search spaces mainly fall into two categories: chainstructured space and cell-based space.</p><p>In the chain-structured search space, the neural architecture can be represented by a sequence of stacked layers. Baker et al. <ref type="bibr" target="#b54">[55]</ref> consider a set of layers that includes convolutions, pooling and dense connections. The corresponding hyperparameter settings contain the number of filters, kernel size, stride and pooling size. Zoph et al. <ref type="bibr" target="#b8">[9]</ref> define a relaxed version of the chain-structured search space by introducing skip connections between blocks. Xie et al. <ref type="bibr" target="#b55">[56]</ref> extend the search space by replacing feature concatenation operations with summations when merging features. Most recently, the inverted residual blocks are introduced to facilitate the search of neural architectures for mobile platforms. MNAS <ref type="bibr" target="#b56">[57]</ref>, ProxylessNAS <ref type="bibr" target="#b13">[14]</ref> and other related methods <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b57">[58]</ref>, <ref type="bibr" target="#b58">[59]</ref> searches architectures over the space consisting of the lightweight inverted bottleneck MBConvs <ref type="bibr" target="#b59">[60]</ref>. MobileNetV3 <ref type="bibr" target="#b31">[32]</ref> and OFA <ref type="bibr" target="#b61">[61]</ref> extend the space with the Swish activation function and squeeze-excitation modules, thus achieving impressive results under mobile settings.</p><p>Although models searched based on chain-structured search space have shown strong representation ability, it generally consumes extensive computation cost to exhaustively cover the search space during training. Motivated by hand-crafted architectures consisting of repeated motifs <ref type="bibr" target="#b62">[62]</ref>, <ref type="bibr" target="#b63">[63]</ref>, <ref type="bibr" target="#b64">[64]</ref>, Zoph et al <ref type="bibr" target="#b0">[1]</ref> and Zhong et al <ref type="bibr" target="#b65">[65]</ref> firstly build networks by repeating the searched cells which is easy to scale the model size by adjusting the number of cell <ref type="bibr" target="#b66">[66]</ref>.</p><p>The development of NAS algorithms in different kinds of search spaces indicates that a better search space is essential for designing search strategies. Recently, some works <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b24">[25]</ref> reveal that even random sampled cells can get pretty good results under those carefully designed search space. Therefore, several NAS benchmarks <ref type="bibr" target="#b67">[67]</ref>, <ref type="bibr" target="#b68">[68]</ref>, <ref type="bibr" target="#b95">[95]</ref> are released to eliminate the bias of search space and relieve the evaluation burden. In this paper, we apply our method to both chain-structured search space and cell-base search space and achieve promising results on CIFAR <ref type="bibr" target="#b28">[29]</ref> and ImageNet <ref type="bibr" target="#b29">[30]</ref>. Furthermore, we verify the efficiency of our method on NATS-Bench benchmark <ref type="bibr" target="#b95">[95]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Search Strategy</head><p>Early NAS approaches focus on searching a network motif by using either reinforcement learning <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref> or evolution algorithms <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b66">[66]</ref>, <ref type="bibr" target="#b69">[69]</ref>, <ref type="bibr" target="#b70">[70]</ref>, <ref type="bibr" target="#b71">[71]</ref>, <ref type="bibr" target="#b72">[72]</ref> and build a complete network for evaluation by stacking the motif. Unfortunately, these approaches require to train hundreds or thousands of candidate architectures from scratch, resulting in barely affordable computational overhead. Thus, several follow-up works are proposed to speed-up training by reducing the search space <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b73">[73]</ref>.</p><p>More recent works resort to the weight-sharing one-shot model to amortize the searching cost <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b74">[74]</ref>.</p><p>The key idea of one-shot approach is to train a single overparameterized model, and then share the weights between sampled child models. This weight sharing mechanism allows the searching of a high-quality architecture within a few GPU days <ref type="bibr" target="#b75">[75]</ref>, <ref type="bibr" target="#b76">[76]</ref>. Single path one-shot model families <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b61">[61]</ref>, <ref type="bibr" target="#b77">[77]</ref>, <ref type="bibr" target="#b78">[78]</ref> propose to train a single sampled path of the one-shot model in each iteration, rather than the entire over-parameterized model. Once the training process is finished, the child models can be ranked by the shared weights. However, <ref type="bibr" target="#b20">[21]</ref> finds that the weight sharing strategy results in inaccurate performance evaluation of the candidate architecture, making it difficult for the one-shot NAS to identify the best architecture. FairNAS <ref type="bibr" target="#b79">[79]</ref> and PC-NAS <ref type="bibr" target="#b80">[80]</ref> also demonstrate that neural architecture candidates based on these parameter sharing methods also cannot be adequately trained, which leads to an inaccurate ranking of architecture candidates . There are few works leveraging knowledge distillation <ref type="bibr" target="#b38">[39]</ref> to boost the training of the super network, and they commonly introduce additional large models as teachers. More specifically, OFA <ref type="bibr" target="#b61">[61]</ref> pretrains the largest model in the search space and use it to guide the training of other subnetworks, while DNA <ref type="bibr" target="#b27">[28]</ref> directly employs the third-party EfficientNet-B7 <ref type="bibr" target="#b35">[36]</ref> as the teacher model. These search algorithms will become infeasible if there is no available pretrained model, especially when the search task and data are entirely new. In contrast to those methods, our introspective distillation method does not require a predefined third-party teacher model, which is more flexible in practice.</p><p>Differentiable architecture search, i.e., DARTS <ref type="bibr" target="#b6">[7]</ref>, is another representative one-shot model. Instead of searching over a discrete set of candidate architectures, DARTS relaxes the search space to be continuous, so that the architecture can be optimized by the efficient gradient descent. Despite DARTS has achieved promising performance by only using orders of magnitude less computation resources, some issues remain. ProxylessNAS <ref type="bibr" target="#b13">[14]</ref> argues that the optimization objectives of search and evaluation networks are inconsistent in DARTS <ref type="bibr" target="#b6">[7]</ref>. Thus it employs a binary connection to tackle the issue. PDARTS <ref type="bibr" target="#b14">[15]</ref> points out the depth gap problem of DARTS, and thereby presents a progressive learning approach, which gradually increases the number of layers in the search network. Moreover, PCDARTS <ref type="bibr" target="#b81">[81]</ref> addresses the problem of high GPU memory cost through introducing a partially-connected strategy in network optimization. SNAS <ref type="bibr" target="#b16">[17]</ref> and GDAS <ref type="bibr" target="#b17">[18]</ref> tried to relieve the discretization gap with modified Gumbel-Softmax. Furthermore, AutoHAS <ref type="bibr" target="#b18">[19]</ref> augmented GDAS with an entropy term to search for both hyperparameters and architectures. ISTA-NAS <ref type="bibr" target="#b82">[82]</ref> formulated neural architecture search as a sparse coding problem to avoid the post-processing of DARTS. Moreover, EnTranNAS <ref type="bibr" target="#b15">[16]</ref> proposed an architecture derivation method to replace the hand-crafted postprocessing rules.</p><p>Our proposed approach differs from existing DARTS approaches <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b81">[81]</ref> in two major ways. One is that our approach integrates the search and evaluation networks into a unified architecture. Also, we build up connections to transfer the parameters as well as the structure knowledge of the evaluation network to the search network. The other difference is the searching algorithm. In contrast to previous methods where the optimization of architecture weights is independent from the evaluation network, our approach enables the evaluation network to guide the search of architectures by joint training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Knowledge Transfer Between Architectures</head><p>Transferring knowledge between architectures during the search is widely used in NAS. A simple way is sharing weights across architectures. Such way can largely reduce training cost because the knowledge from previous searches is reused. TAPAS <ref type="bibr" target="#b83">[83]</ref> starts with a simple architecture and scales up it based on a prediction model. T-NAML <ref type="bibr" target="#b84">[84]</ref> adapts a pre-trained network to target datasets with reinforcement learning, which makes decisions on optimizing neural architectures across datasets simultaneously. Xfer-Net <ref type="bibr" target="#b85">[85]</ref> accelerates NAS by transferring architecture knowledge across different tasks. NATS <ref type="bibr" target="#b86">[86]</ref> introduces a practical neural architecture transformation search algorithm for object detection. It explores architecture space based on existing networks and reusing their weights without searching and re-training. Instead of only inheriting weights from previously-trained networks, FNA++ <ref type="bibr" target="#b87">[87]</ref> adapt both the architecture and parameters of a seed network, which makes it possible to use NAS for segmentation and detection more efficiently. NAT <ref type="bibr" target="#b88">[88]</ref> is also designed to efficiently generate task-specific models under multiple searching objectives.</p><p>Knowledge distillation <ref type="bibr" target="#b38">[39]</ref> is another widely used technique for knowledge transfer between architectures. It compresses the "dark knowledge" of a well trained larger model to a smaller one <ref type="bibr" target="#b89">[89]</ref>. An enormous amount of approaches have been proposed to fortify the efficiency of student models' learning capability. Recently, one-shot methods try to improve the search process by using the supervision of other high-capacity networks, and they commonly introduce additional large models as teachers. BIGNAS <ref type="bibr" target="#b57">[58]</ref> and OFA <ref type="bibr" target="#b61">[61]</ref> pretrain the largest model in the search space and use it to guide the training of other subnetworks, while DNA <ref type="bibr" target="#b27">[28]</ref> directly employs the third-party EfficientNet-B7 <ref type="bibr" target="#b35">[36]</ref> as the teacher model. These search algorithms will become infeasible if there is no available pretrained model, especially when the search task and data are entirely new. Different from these methods, the teacher network of our method is generated by the model itself. Hence, our model does not need to spend extra time to train a teacher network alone and thereby is more flexible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>In this section, we present the Cyclic Differentiable Architecture Search method, i.e., CDARTS. We first briefly review the standard gradient-based differentiable method, which trains the search and evaluation networks independently <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b81">[81]</ref>. Then, we propose the cyclic search method, which learns the search and evaluation networks jointly. At the end, we present the implementation details of the network architecture in our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminary: Differentiable Architecture Search</head><p>The goal of Differentiable Architecture Search, i.e., DARTS, <ref type="bibr" target="#b6">[7]</ref> is to search a cell motif, which can be stacked repeatedly to construct a convolutional network. A cell is a directed acyclic graph consisting of an ordered sequence of N nodes</p><formula xml:id="formula_1">{x i } N ?1 i=0 .</formula><p>Each node x i is a latent representation (e.g., a feature map), while each directed edge (i, j) is associated with one operation o (i,j) which transforms information from x i to x j . Let O denote the operation space, consisting of a set of candidate operations, such as convolution, maxpooling, skip-connection, etc. Each operation represents a function o(?) to be performed on x i . To make the search space continuous, DARTS relaxes the choice of a particular operation to a softmax over all possible operations <ref type="bibr" target="#b6">[7]</ref>:</p><formula xml:id="formula_2">o (i,j) (x i ) = o?O exp(? (i,j) o ) o ?O exp(? (i,j) o ) ? o(x i ),<label>(1)</label></formula><p>where the operation weights for a pair of nodes (i, j) are parameterized by the architecture weights ?(i, j) of dimension |O|. Here, the parameter ? is the encoding of architectures to be optimized. An intermediate node of the cell is computed based on all of its predecessors as x j = i&lt;j? (i,j) (x i ), and the output node x N ?1 is obtained by concatenating all the intermediate nodes in the channel dimension.</p><p>With the definition of a cell, the search of the optimal architecture becomes to solve the following bilevel optimization problem:</p><formula xml:id="formula_3">min ? L val (w * S , ?), s.t. w * S = arg min w S L train (w S , ?),<label>(2)</label></formula><p>where ? contains the architecture weights optimized on the validation data (val), and w S denotes the parameters of the search network learnt on the training data (train). Eq.(2) amounts to optimize the network and architecture weights, i.e., w S and ?, in an alternative way. After getting the optimal architecture, DARTS constructs a new evaluation network by stacking the discovered neural cells and retrains from scratch over the training of the target task. Without loss of generality, here we only consider one cell from a simplified search space consists of two operations: (skip, conv). According to Wang et al. <ref type="bibr" target="#b22">[23]</ref>, the current estimation of the optimal feature map m * , which is shared across all edges, can then be written as:</p><formula xml:id="formula_4">m e (x e ) = exp (? conv ) exp (? conv ) + exp (? skip ) o e (x e ) + exp (? skip ) exp (? conv ) + exp (? skip ) x e<label>(3)</label></formula><p>where ? conv and ? skip are the architecture parameters defined in DARTS. o e (x e ) is the output of the convolution operation, and x e is the skip connection (i.e., the input feature map of edge e). By minimizing var (m e ? m * ), we can get the optimal ? * conv and ? * skip as:</p><formula xml:id="formula_5">? * conv ? var (x e ? m * ) , ? * skip ? var (o e (x e ) ? m * ) .<label>(4)</label></formula><p>During the training of the search network, x e will be theoretically closer to m * than o e (x e ), resulting in ? skip to be greater than ? conv . This leads to failed search because cells are full of skip-connections. Therefore, the magnitude of architecture parameters, essentially, cannot indicate how much the operation contributes to the search network's performance.</p><p>The above procedure shows that, in DARTS, the optimization of the evaluation network is separated from the search process of architectures, i.e., Eq.(2). As a consequence, the magnitude of architecture parameters cannot indicate how much the operation contributes to the search network's performance, leading to the discovered architectures are sub-optimal for the final evaluation networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Cyclic Differentiable Architecture Search</head><p>Different from previous methods <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b81">[81]</ref> where the search network is separated from the evaluation network, our CDARTS integrates the two networks into a unified architecture and models the architecture search as a joint optimization problem of the two networks:</p><formula xml:id="formula_6">min ? L val (w * E , w * S , ?), s.t. ? ? ? ? ? w * S = arg min w S L train (w S , ?), w * E = arg min w E L val (w E , ?),<label>(5)</label></formula><p>where w E is the weight of the evaluation network. To optimize this objective function, we propose an alternating learning algorithm, consisting of two iterative stages: a separate learning stage and a joint learning stage. The former is to train the search and evaluation networks on the train and val datasets respectively, and enable them to have good initialization weights w S and w E . The latter is to learn the architecture weights ? and the network weights jointly. These two stages are performed alternatively until convergence, leading to a joint optimization between the network search and evaluation, as presented in Algorithm 1. This cyclic process allows the evolution of searched architectures to fit the final target evaluation network. Stage 1: Separate Learning. The goal of this stage is to train the search and evaluation networks individually and make them adaptive to the given data. Specifically, for the search network, the architecture weights ? are initialized randomly before training. Then, the weights w S are optimized on the train data as follows:</p><formula xml:id="formula_7">w * S = arg min w S L S train (w S , ?),<label>(6)</label></formula><p>where L S train defines the loss function, and w * S denotes the learned weight. For the image classification problem, we specify L S train as a cross-entropy loss. if i mod S U = 0 then <ref type="bibr">6:</ref> Discretize ? to ? by selecting the top-k elements <ref type="bibr">7:</ref> Generate E-Net with ? 8:</p><p>for each evaluation step j ? [0, S E ] do <ref type="bibr">9:</ref> Calculate L E val according to Eq. <ref type="formula" target="#formula_8">(7)</ref> 10:</p><p>Update For the evaluation network, its internal cell structures are generated by discretizing the learned weights ?. Following the previous work <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b6">[7]</ref>, we retain the top-k (k = 2) operations for each node in the cells by thresholding the learned values in ?. The separate learning of the evaluation network is performed on the val set through optimizing the following objective function:</p><formula xml:id="formula_8">w * E = arg min w E L E val (w E , ?),<label>(7)</label></formula><p>where ? indicates the top-k discretization of the continuous ?, and w * S represents the learned weight. The separate learning of w S and w E enables the search and evaluation networks to obtain a good initialization.</p><p>Stage 2: Joint Learning. In this optimization stage, the search algorithm updates the architecture weights ? with the feature feedback from the evaluation network through introspective distillation. More concretely, the joint optimization of the two networks is formulated as:</p><formula xml:id="formula_9">? * , w * E = arg min ?,w E L S val (w * S , ?) + L E val (w E , ?) +? L S,E val (w * S , ?, w E , ?),<label>(8)</label></formula><p>where minimizing L S val (w * S , ?) is to optimize the architecture weights ? with the fixed weights w * S in the search network, L E val (w E .?) is to optimize the weights w E with a fixed architecture ? in the evaluation network. The L S,E val (w * S , ?, w E , ?) represents the proposed introspective distillation, which allows the knowledge transfer from the evaluation network to the search network. L S,E val (?) employs the features derived from the evaluation network as a supervision signal to guide the updates of the architecture hyperparameter ? in the search network. The introspective distillation is formulated by a soft target cross entropy function as:</p><formula xml:id="formula_10">L S,E val (w * S , ?, w E , ?) = T 2 N N i=1 (p(w E , ?) log( p(w E , ?) q(w * S , ?) )),<label>(9)</label></formula><p>where N is the number of training samples, and T is a temperature coefficient (set to 2). Here, p(?) and q(?) represent the output feature logits of the evaluation and search networks respectively, each of which is calculated as the soft target distribution <ref type="bibr" target="#b38">[39]</ref> over the feature logits, i.e.,</p><formula xml:id="formula_11">p(w E , ?) = exp(f E i /T ) j exp(f E j /T ) , q(w * S , ?) = exp(f S i /T ) j exp(f S j /T ) ,<label>(10)</label></formula><p>where f E i and f S i denote the features generated by the search and evaluation networks (see <ref type="figure" target="#fig_2">Fig. 2</ref>). The optimization of Eq. (9) distills the knowledge of the evaluation network to guide the updates of architecture weights in the search network, while the joint training in Eq. (8) allows the knowledge transfer between the two networks.</p><p>Compared to the classical distillation method <ref type="bibr" target="#b38">[39]</ref>, CDARTS performs knowledge transfer in an introspective manner such that the search network can get the informative feedback from the evaluation network consecutively. The introspective distillation has three advantages. First, the teacher model is endogenous, which enables our method to adapt to any scenario. For example, there is no need to train an extra teacher, which greatly saves computing resources. Second, instead of learning from a fixed teacher model, our method updates the teacher models during the search process, thus the teacher model can adapt to the learning state of the student model. This has also been proved by Pham et al. <ref type="bibr" target="#b90">[90]</ref> that when the teacher and student network are alternately optimized, the student network may learn from better distributions and achieve good validation performance. Last but not the least, the introspective distillation enables the search network to get the feedback information from the current search status, which prevents the search process from collapse <ref type="bibr" target="#b21">[22]</ref> and improves the search stability.</p><p>In addition, it has been observed that DARTS approaches tend to search the architectures with plenty of skipconnection operations rather than convolutions or poolings, because that the skip-connection allows rapid gradient descent <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b21">[22]</ref>. This is essentially a kind of overfitting of architecture search. To address this issue, we impose an 1norm regularization on the weight of the skip-connection operation in the architecture weights ? as:</p><formula xml:id="formula_12">L reg = ? ? 1 ,<label>(11)</label></formula><p>where ? 1 represents the 1 norm, and ? is a positive tradeoff coefficient. Eq. <ref type="formula" target="#formula_2">(11)</ref> is finally optimized with Eq. <ref type="formula" target="#formula_9">(8)</ref> jointly as an auxiliary item to inhibit overfitting. It is worth noting that during the separate learning of the evaluation network, i.e., Eq. <ref type="formula" target="#formula_8">(7)</ref>, we use a weight-sharing strategy for updating weight w E to alleviate the insufficient training. Specifically, when the architecture weights ? are updated, the architecture of the evaluation network will be  changed accordingly. The weights of the new evaluation network are initialized with the parameters inheriting from previous training. In other words, the evaluation network has a one-shot model that shares weights between architectures that have common edges. This speeds up the mature convergence of the new evaluation network, thus elevating its capacity on feature representation. This weight-sharing strategy is different from that in single-path one-shot approaches <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b77">[77]</ref>, which performs random sampling for architecture selection. In contrast, we select architectures to be optimized by the search network, which alleviates the issue of unbalanced training in prior methods <ref type="bibr" target="#b77">[77]</ref>, <ref type="bibr" target="#b91">[91]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Network Architecture</head><p>The network architecture of the proposed CDARTS is presented in <ref type="figure" target="#fig_2">Fig. 2</ref>. It consists of two branches: a search network with a few stacked cells and an evaluation network with dozens of cells. Note that the search and evaluation networks share the same architectures with previous DARTS approaches <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b81">[81]</ref>. For information transfer, we build up connections between the two branches. Concretely, there is an architecture transfer path delivering the discovered cell motifs from the search branch to the evaluation branch, as the top bold arrow presented in <ref type="figure" target="#fig_2">Fig. 2</ref>. Note that the cell structure discovered by the search network is a fully connected graph. In other words, all the candidate operations are applied to calculate the feature of each node in the graph, i.e., Eq (1). When using this continuous cell structure to construct a new evaluation network, we need to conduct discretization first. Following previous works <ref type="bibr" target="#b6">[7]</ref>, we retain the top-k (k = 2) strongest operations among all the candidates from all the previous nodes. This derived discrete cell structure serves as the basic building block for the evaluation branch.</p><p>On the other hand, there is another introspective distillation path transferring the feature feedback of the evaluation branch to the search branch, as the bottom solid arrow shown in <ref type="figure" target="#fig_2">Fig. 2</ref>. The feedback serves as the supervision signal for the search network to find better cell structures. In details, we use multi-level features of the evaluation network as the feedback signals, since they are representative on capturing image semantics. As the lateral embedding connections presented in <ref type="figure" target="#fig_2">Fig. 2</ref>, the multi-level features combine low-resolution, semantically strong features with high-resolution, semantically weak features. The features are derived from the outputs of each stage, and then passed through an embedding module to generate the corresponding feature logits. The function of the embedding module is to project the dense feature maps into a low dimensional subspace. The obtained logits of the evaluation network is used as the supervision signals for the search network through a soft cross-entropy layer, as in Eq. (9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We evaluate the proposed CDARTS algorithm on the image classification task and conduct a series of experiments on CIFAR <ref type="bibr" target="#b28">[29]</ref>, ImageNet <ref type="bibr" target="#b92">[92]</ref>, as well as the recent proposed NATS-Bench benchmark <ref type="bibr" target="#b95">[95]</ref>. Furthermore, we apply our introspective distillation search method into the chainstructured search space <ref type="bibr" target="#b11">[12]</ref> to verify the generalization capability of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Implementation Details</head><p>In Tab. 1, we elaborate the setting of the hyperparameters used in CDARTS on different benchmarks. The other settings are the same as DARTS families <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b81">[81]</ref>. In line with prior works <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b81">[81]</ref>, the architectures found on CIFAR10 and ImageNet need to be trained from scratch.</p><p>CIFAR10. To train the networks, we divide the 50K training images of CIFAR10 <ref type="bibr" target="#b28">[29]</ref> into two equal parts. One part serves as the train set to learn the weight w S of the search network, while the other part works as the val set to optimize the architecture hyperparameter ? and the evaluation network weights w E . In the search phase, w * E is only optimized on the validation set. After the search, we retrain the discovered architectures on both train and validation sets for a fair comparison with other DARTS methods. During training, the total number of search step S S is set to 30 epochs, the evaluation step S E and the update step S U are both set to 1 epoch. When training the weight w S and w E individually, the batch size, learning rate, momentum and weight decay are set to 64, 0.1, 0.9 and 3 ? 10 ?4 , respectively. When jointly updating ? and w E , we adopt the Adam optimizer <ref type="bibr" target="#b93">[93]</ref> with a fixed learning rate of 3 ? 10 ?4 . The momentum and weight decay are set to {0.5, 0.99} and 3 ? 10 ?4 , respectively. The coefficient ? is fixed to 4, while ? decays from 5 to 0 in the first 20 epochs and remains at 0 in the last 10 epochs.</p><p>ImageNet. ImageNet <ref type="bibr" target="#b92">[92]</ref> is much larger than CIFAR <ref type="bibr" target="#b28">[29]</ref> in both scale and complexity. In line with prior works, i.e., PCDARTS <ref type="bibr" target="#b81">[81]</ref> and DARTS+ <ref type="bibr" target="#b21">[22]</ref>, we randomly sample 10% images from ImageNet to form the train data, while sampling another 10% images to form the val data. The construction of networks tested on ImageNet is similar to the one on CIFAR, but has two differences. First, to align with previous works <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b81">[81]</ref> on ImageNet, we set the number of cells to 8 and 14 for the search and evaluation networks. Second, following the same setting as DARTS <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b81">[81]</ref>, the stem layer contains 3 convolution operations reducing the feature size from 224?244 to 28?28. During search, we first pre-train the search network with 10 epochs when the architecture hyperparameters are fixed. Then, the number of search step S S is set to 30 epochs, while the evaluation step S E is set to 3 epochs. When training the weight w S and w E individually, the batch size, learning rate, momentum and weight decay are set to 1024, 0.8, 0.9 and 3 ? 10 ?5 , respectively. When jointly updating ? and w E , we adopt the Adam optimizer <ref type="bibr" target="#b93">[93]</ref> with a fixed learning rate of 3 ? 10 ?4 . The momentum and weight decay are set to {0.5, 0.99} and 3 ? 10 ?5 , respectively. The coefficient ? is fixed to 4, and ? decays from 5 to 0 in the first 20 epochs and remains at 0 in the rest epochs. We use 8 NVIDIA Tesla V100 GPUs with a batch size of 1024 to search on ImageNet. It takes about 5 hours with our PyTorch <ref type="bibr" target="#b94">[94]</ref> implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation on NAS Benchmark</head><p>NATS-Bench benchmark <ref type="bibr" target="#b95">[95]</ref> includes the search space of 15,625 neural cell candidates for architecture topology and 32,768 for architecture size on three datasets. We conduct our experiments on the topology search space S t , covering all possible architectures generated by the fixed search space of 4 nodes and 5 associated operation options. It evaluates all the architectures on CIFAR10 <ref type="bibr" target="#b28">[29]</ref>, CIFAR100 <ref type="bibr" target="#b28">[29]</ref> and ImageNet-16-120 <ref type="bibr" target="#b98">[98]</ref>, and provides the corresponding performance. It also benchmarks 13 recent NAS algorithms on the search space using the same setup for a fair comparison.  <ref type="bibr" target="#b6">[7]</ref>, whose results are provided by the benchmark <ref type="bibr" target="#b95">[95]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR10 CIFAR100</head><p>ImageNet-16-120 According to the evaluation rules of NATS-Bench benchmark <ref type="bibr" target="#b95">[95]</ref>, i.e., no regularization for a specific operation and report results of multiple searching runs, we remove the 1 -norm regularization imposed on skip-connections, i.e., Eq.(11), and report the results of three independent runs. All the DARTS-based methods perform 50 searching epochs, following the same setting as <ref type="bibr" target="#b95">[95]</ref>.</p><p>We first compare our method with the 10 NAS methods that have been benchmarked on NATS-Bench benchmark <ref type="bibr" target="#b95">[95]</ref>, such as the evolution algorithm based REA <ref type="bibr" target="#b66">[66]</ref> and the one-shot based ENAS <ref type="bibr" target="#b34">[35]</ref>. As presented in Tab. 2, our CDARTS outperforms 9/10 methods on the three datasets. It achieves comparable performance to the REA method <ref type="bibr" target="#b66">[66]</ref>, while searching much faster. Both of REA and CDARTS perform superior to the human-design ResNet <ref type="bibr" target="#b62">[62]</ref>, being close to theoretical optimum on the benchmark, i.e., the "Optimal" in Tab. 2. The original DARTS underperforms due to overfitting <ref type="bibr" target="#b95">[95]</ref>, and its standard deviation of performance is 0 because the final found architecture has plenty of skip-connections. The underlying reason is that DARTS tends to overfit to the architectures with many skip-connection operations. GDAS <ref type="bibr" target="#b17">[18]</ref> is another DARTS based method. It performs much better than DARTS on NATS-Bench benchmark because it introduces an architecture sampling optimization algorithm to prevent overfitting. In contrast, our CDARTS can perform wellbalanced and achieves superior performance. The underlying reason is due to the proposed unified architecture, which allows the search network to discover architectures tailored for the target evaluation network. Except for CDARTS, the performance of all the NAS approaches in Tab. 2 are provided by the official NATS-Bench benchmark <ref type="bibr" target="#b95">[95]</ref>.</p><p>We conduct another experiment to evaluate the searching stability. With the NATS-Bench benchmark <ref type="bibr" target="#b95">[95]</ref> benchmark, it is easy to track the validation and test accuracy of   <ref type="figure">Fig. 3</ref>. We can see that DARTS <ref type="bibr" target="#b6">[7]</ref> achieves a relatively high accuracy at early stage, however, as the search process continues, its accuracy drops significantly and the stability becomes weak. Finally, DARTS falls into the overfitting status, in which the final architecture contains many skip-connections. In contrast, the performance of our CDARTS is improved gradually along with the increase of search epochs, and eventually reaches stable and converged. This may attribute to the knowledge transfer between the search and evaluation networks. CDARTS continually leverages the supervision from the evaluation network to guide the search process, thus preventing the searched architecture from collapsing. Moreover, it is observed that the one-shot NAS method SETN <ref type="bibr" target="#b32">[33]</ref> performs inferiorly to our method in term of both accuracy and searching stability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation on CIFAR</head><p>The CIFAR image classification dataset contains two subsets, CIFAR10 and CIFAR100. CIFAR10 has 10 classes. Each class consists of 6,000 images, in which 5,000 images are used for training and 1,000 for testing. CIFAR100 consists of 100 classes. Each class containing 600 images, where 500 images are used for training and the rest for testing. We search the architecture on CIFAR10 test set, and evaluate it on both CIFAR10 and CIFAR100. The cell topologies discovered on CIFAR10 are shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. After discovering the evaluation network architecture, we retrain it by following the same setting as PDARTS <ref type="bibr" target="#b14">[15]</ref>. Specifically, the number of channels is set to 36 and the structure is the same with the search stage. We use the entire CIFAR training images to train the network from scratch with 600 epochs. To speed up the training, the batch size is set to 128 and the learning rate decays from 0.025 to 0 with a cosine annealing <ref type="bibr" target="#b104">[103]</ref>. We choose SGD <ref type="bibr" target="#b105">[104]</ref> as the optimizer with a momentum of 0.9 and weight decay of 5 ? 10 ?4 .</p><p>In line with PDARTS, the drop-path <ref type="bibr" target="#b106">[105]</ref> rate is set to 0.3, the auxiliary towers <ref type="bibr" target="#b107">[106]</ref> is set to 0.4, and the cutout regularization <ref type="bibr" target="#b108">[107]</ref> length is set to <ref type="bibr" target="#b15">16</ref>. The experiments are executed on one NVIDIA Tesla V100 GPU. We report the performance of five individual runs of different search algorithms in Tab. 3. In the five independent runs, CDARTS consistently outperforms prior DARTS <ref type="bibr" target="#b6">[7]</ref> and PCDARTS <ref type="bibr" target="#b81">[81]</ref>. Moreover, in terms of performance deviations, CDARTS performs better than prior methods, i.e., CDARTS: 97.52?0.04% v.s. DARTSV1 <ref type="bibr" target="#b6">[7]</ref>: 96.93?0.13%, DARTSV2: 96.85 ? 0.29%, PC-DARTS: 97.33 ? 0.07%. The cell motifs discovered on CIFAR-10 are presented in <ref type="figure" target="#fig_3">Fig. 4</ref>. We observe that the network prefers to choose separable convolutions <ref type="bibr" target="#b114">[113]</ref>, and is therefore capable of improving the model capacity and serves as a key component for network construction. Besides, these cells usually contain either one or two skip-connections, and the depth of these cells are usually two (the longest path from input to output node).</p><p>The performance of discovered cells are reported in Tab. 4. It is observed that our CDARTS achieves superior performance to some ConvNets designed manually or automatically. For instance, CDARTS surpasses the manually designed DenseNet-BC [63] by 1.18 and 3.93 points on CIFAR10 and CIFAR100, respectively. Compared with the original DARTS method <ref type="bibr" target="#b6">[7]</ref>, CDARTS also achieves better performance (97.52 ? 0.04% v.s. 97.00 ? 0.14%). CDARTS is also slightly superior to the recently proposed PDARTS <ref type="bibr" target="#b14">[15]</ref> and PCDARTS <ref type="bibr" target="#b81">[81]</ref> on both CIFAR10 and CIFAR100. It is worthy noting that the performance of ProxylessNAS <ref type="bibr" target="#b13">[14]</ref> is slightly better than CDARTS, but at the cost of a larger model parameter size and longer model search time. Moreover, compared with other non-gradient based methods, such as reinforcement learning (RL) or evolutionary algorithms, our method is also competitive. For example, the RLbased ENAS <ref type="bibr" target="#b34">[35]</ref> method achieves 97.11% test accuracy on CIFAR10, which is slightly inferior to 97.52% of CDARTS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation on ImageNet</head><p>ImageNet <ref type="bibr" target="#b92">[92]</ref> is a large-scale image classification dataset. It consists of 1,000 categories with 1.2 million training images and 50K validation images. Note that, for a fair comparison, the images in ImageNet are resized to 224?224 pixels in our experiments in line with prior DARTS works <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b81">[81]</ref>. Once the search process is completed, we retrain the discovered architecture following the same setting as PDARTS. The final evaluation network contains 14 cells with a channel number of 48. We retrain it for 250 epochs from scratch with full ImageNet training data. A standard SGD <ref type="bibr" target="#b105">[104]</ref> optimizer is adopted with a momentum of 0.9 and weight decay of 3 ? 10 ?5 . The learning rate is set to 0.5 with the cosine scheduler; meanwhile, a learning rate warmup <ref type="bibr" target="#b115">[114]</ref> is applied in the first 5 epochs. Same as DARTS, the label smoothing <ref type="bibr" target="#b116">[115]</ref> ratio is set to 0.1 and the auxiliary tower is set to 0.4.</p><p>The evaluation results of the searched architectures are reported in Tab. 5. It shows that the architectures discoverd by our CDARTS is slightly better than the manually designed models, such as MobileNet-V2 <ref type="bibr" target="#b59">[60]</ref> and ShuffleNet <ref type="bibr" target="#b117">[116]</ref>. Compared with automated methods, e.g.,   RL-based MobileNet-V3 <ref type="bibr" target="#b31">[32]</ref>, our gradient-based CDARTS achieves comparable performance. MobileNet-V3 blends automatic search techniques with the interaction of human design, while CDARTS is purely automatic. Moreover, CDARTS outperforms the prior DARTS <ref type="bibr" target="#b6">[7]</ref> by 3.0 points in term of top-1 accuracy. This improvement is attributed to the proposed search algorithm. It is observed that the flops of CDARTS is a little higher than other DARTS methods. This is solely caused by the search algorithm itself, because the search space is the same among these DARTS methods.</p><p>To follow the mobile setting <ref type="bibr" target="#b6">[7]</ref> comparison, i.e., the number of multiply-add operations in the model is restricted to be less than 600M , we reduce the number of model channels from 48 to 44, while keeping other settings unchanged. We obtain 75.9% top-1 accuracy with 571M flops, which is still slightly superior than PDARTS <ref type="bibr" target="#b14">[15]</ref> and PCDARTS <ref type="bibr" target="#b81">[81]</ref>. In addition, when training the discovered CIFAR10 cells on Im-ageNet, CDARTS obtains a top-1 accuracy of 75.6%, which is on par with ImageNet cell 76.3%. This demonstrates the generalization potential of CDARTS.</p><p>In Tab. 6, we present the results of five independent searches on ImageNet. We observe that the five runs of our method consistently exceed that of PDARTS (75.6%) and PCDARTS (75.8%). The discovered cells on ImageNet are presented in <ref type="figure" target="#fig_3">Fig. 4</ref>. We observe that the cells discovered on ImageNet is deeper than the ones on CIFAR10, because the classification on ImageNet is more complex. This is aligned with the evidence that increasing network depth is beneficial for elevating model capability <ref type="bibr" target="#b62">[62]</ref>. Moreover, the discovered cells on ImageNet contain larger convolution kernels (i.e., 5x5 sep conv), which is helpful to improve model capacity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablation Study</head><p>Component-wise Analysis. To further understand the effects of the components in the proposed search algorithm, we test four variations of CDARTS on the ImageNet dataset. In particular, each variation corresponds to an optimization objective listed in Tab. 7, and parameters for each model are tuned separately to obtain the optimal results. It is worth noting that the alternating optimization of L S train + L S val fail to search on ImageNet, whose cells are full of skip-connections. So we use the 1 -norm regularization to stabilize the searching process, and achieve a top-1 accuracy of 72.8%. By adding the proposed joint learning L S,E val into optimization, the performance is improved to 75.7%. This indicates the effectiveness of the multi-level feature semantics guidance of the evaluation network, and the integration of the search and evaluation is beneficial to discover more robust architecture. Moreover, during joint training, updating the weights of the evaluation network can further improve the performance by 0.9%.</p><p>Correlation Analysis. In differentiable architecture search methods, the operations and edges with weak attention (i.e., small weights) are considered as redundant and are pruned to obtain a compact architecture (i.e., top-k discretization). However, it is not clear whether the operations and edges with weak attention are truly redundant, while strong attention indicates the high importance. Therefore, we conduct another experiment to evaluate the correlation between the architecture hyperparameter and the true performance of architectures. Specifically, we sample a variety of cell architectures and rank them according to the learned weights of the architecture hyperparameter. The quantitative results shown in <ref type="figure">Fig. 5</ref> demonstrate that our method obtains better correlation than DARTS <ref type="bibr" target="#b6">[7]</ref>. We further compare the Kendall Rank Correlation Coefficient (? ) metric that evaluates the rank correlation of data pairs. We repeat the experiment six times with different seeds. The Kendall's ? of SPOS <ref type="bibr" target="#b77">[77]</ref> is 0.19 <ref type="bibr" target="#b89">[89]</ref>, while ours is 0.49, being 0.3 point superior to SPOS. To some extent, the architecture in CDARTS is able to reflect the relative ranking of architectures. But it is worth noting that CDARTS still cannot well distinguish the architectures that share close performance.     Depth of Evaluation Network. Due to the limitation of GPU memory, the search network of DARTS can only stack 8 cells, while the evaluation network contains 20 cells. This brings the so-called depth gap issue studied in PDARTS <ref type="bibr" target="#b14">[15]</ref>. Such problem is not observed in our method, and we believe the reason is due to the integration of search and evaluation in a unified architecture. As shown in <ref type="figure">Fig. 6</ref>, we compare the performances of different numbers of cells in the evaluation network. It clearly shows that the 20-cell evaluation network (the red line) performs better than the 8-cell network (the green line). This indicates the proposed jointly training of the two networks mitigates the impacts of the depth gap.</p><p>Impact of Search Epoch. In DARTS methods <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b81">[81]</ref>, after certain searching epochs, the number of skip-connections increases dramatically in the selected architecture, which results in the search collapse <ref type="bibr" target="#b21">[22]</ref>. We study the impact of the number of search epochs in our CDARTS. From <ref type="figure">Fig. 6</ref>, we can see that when the number of search epochs approaches 30, the performance becomes saturated, and the structure of the evaluation network tends to be stable. So the search epoch is set to 30 in experiments. In addition, as the number of search epochs increases, CDARTS continues to search for better structures. Our method even achieves 97.77% top-1 accuracy on CIFAR10 when the search epochs are 90.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Generality and Robustness</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.1">Extension to Chain-structured Search Space</head><p>A robust search algorithm should be capable of searching architectures over diverse search spaces. We migrate the introspective distillation searching method to a chain-structured search space <ref type="bibr" target="#b11">[12]</ref>. The search space consisting of mobile inverted bottleneck MBConv <ref type="bibr" target="#b59">[60]</ref> and squeeze-excitation modules <ref type="bibr" target="#b64">[64]</ref>, which is the same as recent works <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr">[</ref>  <ref type="bibr" target="#b77">[77]</ref> as our baseline method and introduce a simple principle to select the teacher path. Specifically, the teacher path is first initialized with random paths within the search network. Then, for each batch, we randomly sample a single path from the search network and train the path under both the teacher path soft-label supervision and the ground truth supervision. After that, we evaluate the path on the validation dataset (a subset is used to save computation), and get its performance. If the current path performs superior to the teacher path and with less or the same Flops, then the teacher network will be replaced by the current path. In this way, the final left teacher path is the optimal path of all sampled paths during the search. We train the search network for 120 epochs using the following settings: the SGD optimizer <ref type="bibr" target="#b105">[104]</ref> with momen-  tum 0.9 and weight decay 4e-5, initial learning rate 0.5 with linear annealing. The discovered architectures are presented in <ref type="figure" target="#fig_6">Fig. 7</ref> and we retrain them for 350 epochs on ImageNet using similar settings as EfficientNet <ref type="bibr" target="#b35">[36]</ref>: RMSProp optimizer with momentum 0.9 and decay 0.9, weight decay 1e-5, dropout ratio 0.2, initial learning rate 0.04 with a warmup <ref type="bibr" target="#b115">[114]</ref> in the first 3 epochs and a cosine annealing. We also adopt the AutoAugment <ref type="bibr" target="#b121">[120]</ref> and exponential moving average techniques. We use 8 Nvidia Tesla V100 GPUs with a batch size of 1,024 for the retraining. It is worth noting that there are a few recent works that leverage knowledge distillation techniques to boost searching <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b61">[61]</ref>. As shown in Tab 8, our introspective distillation shows superior performance over these methods. Specifically, DNA-b <ref type="bibr" target="#b27">[28]</ref> recruits EfficientNet-B7 <ref type="bibr" target="#b35">[36]</ref>, a very high-performance third-party model, as the teacher and achieves 77.5% top-1 accuracy, while our method (CDARTSb) gets a superior accuracy of 78.2% without using any pre-trained model. Our model also surpasses EfficientNet-B0 by 1.1% with nearly the same model size. The leading performance indicates that the proposed introspective distillation method also works well on the chain-structured search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.2">Extension to Big Model</head><p>To further unleash the power of the searched architectures, we enlarge the evaluation network channels and train from scratch with more data augmentations <ref type="bibr" target="#b121">[120]</ref>, <ref type="bibr" target="#b122">[121]</ref>, which is denoted as big model.</p><p>Big Model on CIFAR10 We enlarge the numbers of feature channels from 36 to 50. After 2000 epochs training, the CDARTS-BIG model obtains impressive performance improvements. On CIFAR10, the test accuracy increases from 97.52% to 98.32%. This improvement further verifies the effectiveness of the proposed method. In addition, to have a fair comparison, we retrain the evaluation networks discov-  <ref type="bibr" target="#b35">[36]</ref>. Moreover, following the same settings, we train the big models of PDARTS and PCDARTS. Their performances are inferior to our CDARTS, as presented in Tab. 10. It should be noted that the original DARTS cells have been proved in many experiments to be inferior to the improved version, e.g. PDARTS <ref type="bibr" target="#b14">[15]</ref>, PCDARTS <ref type="bibr" target="#b81">[81]</ref>. In order to save computation resources, we did not train big model of DARTS on ImageNet. These results confirm again the generalization potential and effectiveness of CDARTS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.3">Extension to Object Detection</head><p>We also transfer the proposed method to the downstream object detection task, which is a fundamental task in the vision community. We use the discovered architecture and corresponding weights pre-trained on ImageNet as a dropin replacement for the backbone feature extractor in Reti-naNet <ref type="bibr" target="#b133">[132]</ref>. The capabilities of various light-weight backbones are compared on the COCO benchmark <ref type="bibr" target="#b134">[133]</ref>. We fine-tune the searched model on the train2017 set (118k images) and evaluate on the val2017 set (5k images) with the batch size of 16 on 8 V100 GPUs. Similar to <ref type="bibr" target="#b79">[79]</ref>, the schedule is the default 1?, i.e., 12 epochs. The initial learning rate is set to 0.02, and then decayed with the scaling factor of 0.1 at the 8-th and 11-th epoch. The optimizer is SGD with momentum 0.9 and weight decay 1e-4. We use the MMDetection toolbox <ref type="bibr" target="#b135">[134]</ref> based on PyTorch <ref type="bibr" target="#b94">[94]</ref>.</p><p>Results are summarized in Tab. 9. Specifically, CDARTSa surpasses MobileNetV2 by 6.9% while using fewer Flops. Compared to MnasNet <ref type="bibr" target="#b56">[57]</ref>, CDARTS-a utilizes 19% fewer Flops yet achieves 4.7% higher performance. CDARTS-b even achieves 36.2% mAP on the COCO val2017, which surpasses other methods by a large margin. With similar flops and parameters, CDARTS-b is 3.8% higher than FairNAS-A <ref type="bibr" target="#b79">[79]</ref>, suggesting the architecture has good generalization ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.4">Extension to Semantic Segmentation</head><p>To evaluate the generalization ability of the architectures found by CDARTS, we transfer the architectures to the downstream semantic segmentation <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b80">[80]</ref>, <ref type="bibr" target="#b136">[135]</ref> task. We leverage the discovered architecture and corresponding weights pre-trained on ImageNet as a drop-in replacement for the encoder in FasterSeg <ref type="bibr" target="#b129">[128]</ref>. The mean intersection over union per class (mIoU) is used as the metric for semantic segmentation.</p><p>Cityscapes <ref type="bibr" target="#b137">[136]</ref> is a popular dataset which contains a diverse set of stereo video sequences recorded in street scenes from 50 different cities. It has 5,000 high quality pixel-level annotations. There are 2,975 images for training, 500 images for validation. And for testing, it offers 1,525 images without ground-truth for a fair comparison. The dense annotation contains 19 classes for each pixel. We evaluate our CDARTS on Cityscapes validation set with the original image resolution of 1024 ? 2048. In <ref type="table" target="#tab_1">Table 11</ref>, we see the superior mIoU and model size of our CDARTS. Without any inference trick, our CDARTS achieves 78.1% mIoU, which is 5.0% better than FasterSeg <ref type="bibr" target="#b129">[128]</ref>. Specifically, our CDARTS surpasses SegFormer [37] by 1.9% with much fewer Flops.</p><p>ADE20K <ref type="bibr" target="#b138">[137]</ref> has 20k images for training, 2k images for validation and 3k images for testing. It is used in Ima-geNet scene parsing challenge 2016, and has 150 classes and diverse scenes with 1,038 image-level. We also evaluate our CDARTS on the ADE20K validation set with the original image resolution of 640 ? 640. From <ref type="table" target="#tab_1">Table 12</ref>, we can see that our model is much smaller than others. Specifically, our CDARTS achieves 40.4% mIoU with 5.9G Flops, which is 3.0% better than SegFormer <ref type="bibr" target="#b36">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Discussion</head><p>Computation cost. The computation cost of CDARTS is comparable to DARTSV1. Both of them adopt the first-order optimization method <ref type="bibr" target="#b6">[7]</ref> to train the networks. Compared with the original DARTS <ref type="bibr" target="#b6">[7]</ref>, we have an additional evaluation network and update it along with the search network in the search process. We denote the computation cost of updating the search network as C(|W S |), which is the same as DARTSV1. In the search network cell, the number of edges between nodes is ED S and the number of operations in each edge is OP S . The number of stacked cells in the search network is N S . Correspondingly, these factors of the evaluation network are denoted as ED E , OP E and N E . Then the cost of the evaluation network C(|W E |) is:</p><formula xml:id="formula_13">C(|W E |) = N E ? ED E ? OP E N S ? ED S ? OP S ? C(|W S |)<label>(12)</label></formula><p>In the experiments on CIFAR10, the ED E , OP E and N E are set to 8, 1 and 20, respectively, while the ED S , OP S and N S are set to 14, 8 and 8, respectively. Hence, the cost of the evaluation network C(|W E |) is about 1 6 of C(|W S |). Compared to these two networks, the cost of the embedding modules is much smaller and can be ignored in cost estimation. Considering the initialization stage of the evaluation network (i.e., one training epoch for CIFAR10), the final cost of the evaluation network is about <ref type="bibr" target="#b0">1</ref> 3 of C(|W S |). In ImageNet, the final cost of the evaluation network is about 1 2 of C(|W S |). Therefore, compared to DARTSV1 <ref type="bibr" target="#b6">[7]</ref>, the complexity of CDARTS is only increased by ?0.3 times.</p><p>Fast search speed on ImageNet. It is worth noting that our method takes about five hours to complete the search with eight GPUs on ImageNet. Such a fast search speed mainly attributes to the following three reasons. First, we use the fast first-order optimization algorithm <ref type="bibr" target="#b6">[7]</ref> when updating the hyperparameter of architecture. Second, following PC-DARTS <ref type="bibr" target="#b81">[81]</ref>, only 10% data in each category are used. Besides, the evaluation network is relatively lightweight and adopts the weight sharing strategy to speed up network training, so the extra computational cost of updating its parameters is small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>In this work, motivated by the separation problem of the search and evaluation networks in DARTS, we have proposed a cyclic differentiable architecture search algorithm that integrates the two networks into a unified architecture. The alternating joint learning enables the search of architectures to fit the final evaluation network. Experiments on three different search spaces demonstrate the efficacy of the proposed algorithm and searched architectures, which achieve competitive performance on CIFAR, ImageNet and NATS-Bench. In future work, we will consider adding more constraints on prioritized path selection, such as both Params and latency, thus improving the flexibility and userfriendliness of the search method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>Comparisons of prior DARTS and our CDARTS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Illustration of the proposed CDARTS. CDARTS contains two networks, the search network (left) and the evaluation network (right). The Embedding module maps each stage feature to a one-dimensional vector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Cells discovered on CIFAR10 and ImageNet. ImageNet cells are deeper than CIFAR10. The normal cell discovered on ImageNet (b) The reduction cell discovered on CIFAR10 (d) The reduction cell discovered on ImageNet</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :Fig. 6 :</head><label>56</label><figDesc>Operation weights and retrain accuracy correlation analysis. Weights Rank indicates the weight sorting of the learned architecture from small to large. Ablation of the search epochs and the depth of evaluation network. Evaluation-8/20 represent the evaluation networks with 8/20 cells, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 :</head><label>7</label><figDesc>Discovered architectures. "M B a b ? b" represents the inverted bottleneck MBConv with the expand rate of a and kernel size of b. "DS a b ? b" denotes the depthwise separable convolution with the expand rate of a and kernel size of b.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Hongyuan Yu, Yan Huang and Liang Wang are with the Center for Research on Intelligent Perception and Computing (CRIPAC), National Laboratory of Pattern Recognition (NLPR), the Center for Excellence in Brain Science and Intelligence Technology (CEBSIT) and the University of Chinese Academy of Sciences (UCAS), Beijing, China. Email: hongyuan.yu@nlpr.ia.ac.cn, {yhuang, wangliang}@nlpr.ia.ac.cn ? Houwen Peng and Jianlong Fu are with the Microsoft Research. Email: {houwen.peng,jianf}@microsoft.com ? Hao Du is with the Department of Computer Science, City University of Hong Kong, Hong Kong, China. Email: haodu8-c@my.cityu.edu.hk ? Haibin Ling is with the Department of Computer Science, Stony Brook University. Email: haibin.ling@stonybrook.edu</figDesc><table /><note>? Work performed when Hongyuan Yu and Hao Du were interns of Microsoft Research. Houwen Peng and Liang Wang are the corresponding authors.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Algorithm 1</head><label>1</label><figDesc>Cyclic Differentiable Architecture Search Input: The train and val data, search and evaluation iterations S S and S E , update iterations S U , architecture weights ?, and weights w S and w E for search S-Net and evaluation E-Net. Output: Evaluation network. 1: Initialize ? with randoms 2: Initialize w S 3: for each search step i ? [0, S S ] do</figDesc><table><row><cell>4:</cell><cell>/* Stage 1: Separate training */</cell></row><row><cell>5:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 1 :</head><label>1</label><figDesc>The hyperparameters used in search. BS, LR, OPT, MOME and WD are the batch size, learning rate, optimizer, momentum and weight decay. ? and ? are the coefficients in Eq. 8 and Eq. 11. Runs means the number of independent runs. The unit s of S S , S E and S U in Algorithm 1 represents the number of steps in one epoch.</figDesc><table><row><cell>Benchmark</cell><cell>BS</cell><cell cols="3">LR OPT MOME WD</cell><cell>SS</cell><cell cols="2">SE SU</cell><cell cols="2">? ?</cell><cell>Runs</cell></row><row><cell>NATS-Bench</cell><cell>64</cell><cell>0.1 SGD</cell><cell>0.9</cell><cell cols="2">3e-4 50s</cell><cell>1s</cell><cell>1s</cell><cell>4</cell><cell>5</cell><cell>3</cell></row><row><cell>CIFAR10</cell><cell>64</cell><cell>0.1 SGD</cell><cell>0.9</cell><cell cols="2">3e-4 30s</cell><cell>1s</cell><cell>1s</cell><cell>4</cell><cell>5</cell><cell>5</cell></row><row><cell>ImageNet</cell><cell cols="2">1024 0.8 SGD</cell><cell>0.9</cell><cell cols="2">3e-5 30s</cell><cell>3s</cell><cell>1s</cell><cell>4</cell><cell>5</cell><cell>5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 2 :</head><label>2</label><figDesc>Comparison with 10 NAS methods provided by NATS-Bench benchmark<ref type="bibr" target="#b95">[95]</ref> topology search space S t . Optimal indicates the best performing architecture in the search space.</figDesc><table><row><cell>Method</cell><cell cols="2">CIFAR10 validation</cell><cell>test</cell><cell cols="2">CIFAR100 validation</cell><cell>test</cell><cell>ImageNet-16-120 validation test</cell></row><row><cell>ResNet [62]</cell><cell>90.83</cell><cell></cell><cell>93.91</cell><cell>70.50</cell><cell cols="2">70.89</cell><cell>44.10</cell><cell>44.23</cell></row><row><cell>Optimal</cell><cell>91.61</cell><cell cols="2">94.37(94.37)</cell><cell>73.49</cell><cell cols="2">73.51(73.51)</cell><cell>46.73</cell><cell>46.20(47.31)</cell></row><row><cell>REA [66]</cell><cell>91.25?0.31</cell><cell cols="2">94.02?0.31</cell><cell>72.28?0.95</cell><cell cols="2">72.23?0.84</cell><cell>45.71?0.77</cell><cell>45.77?0.80</cell></row><row><cell>REINFORCE [34]</cell><cell>91.12?0.25</cell><cell cols="2">93.90?0.26</cell><cell>71.80?0.94</cell><cell cols="2">71.86?0.89</cell><cell>45.37?0.74</cell><cell>45.64?0.78</cell></row><row><cell>RANDOM [96]</cell><cell>91.07?0.26</cell><cell cols="2">93.86?0.23</cell><cell>71.46?0.97</cell><cell cols="2">71.55?0.97</cell><cell>45.03?0.91</cell><cell>45.28?0.97</cell></row><row><cell>BOHB [97]</cell><cell>91.17?0.27</cell><cell cols="2">93.94?0.28</cell><cell>72.04?0.93</cell><cell cols="2">72.00?0.86</cell><cell>45.55?0.79</cell><cell>45.70?0.86</cell></row><row><cell>ENAS [35]</cell><cell>90.20?0.00</cell><cell cols="2">93.76?0.00</cell><cell>70.21?0.71</cell><cell cols="2">70.67?0.62</cell><cell>40.78?0.00</cell><cell>41.44?0.00</cell></row><row><cell>SPS [20]</cell><cell>87.60?0.61</cell><cell cols="2">91.05?0.66</cell><cell>68.27?0.72</cell><cell cols="2">68.26?0.96</cell><cell>39.37?0.34</cell><cell>40.69?0.36</cell></row><row><cell>SETN [33]</cell><cell>90.02?0.97</cell><cell cols="2">92.72?0.73</cell><cell>69.19?1.42</cell><cell cols="2">69.36?1.72</cell><cell>39.77?0.33</cell><cell>39.51?0.33</cell></row><row><cell>DARTSV1 [7]</cell><cell>49.27?13.44</cell><cell cols="2">59.84?7.84</cell><cell>61.08?4.37</cell><cell cols="2">61.26?4.43</cell><cell>38.07?2.90</cell><cell>37.88?2.91</cell></row><row><cell>DARTSV2 [7]</cell><cell>58.78?13.44</cell><cell cols="2">65.38?7.84</cell><cell>59.48?5.13</cell><cell cols="2">60.49?4.95</cell><cell>37.56?7.10</cell><cell>36.79?7.59</cell></row><row><cell>GDAS [18]</cell><cell>89.69?0.72</cell><cell cols="2">93.23?0.58</cell><cell>68.35?2.71</cell><cell cols="2">68.17?2.50</cell><cell>39.55?0.00</cell><cell>39.40?0.00</cell></row><row><cell>CDARTS</cell><cell>91.12?0.44</cell><cell cols="2">94.02?0.31</cell><cell>72.12?1.23</cell><cell cols="2">71.92?1.30</cell><cell>45.09?0.61</cell><cell>45.51?0.72</cell></row><row><cell cols="8">Fig. 3: Test and validation accuracy (mean ? std) v.s. search epochs on NATS-Bench benchmark [95] topology search space</cell></row><row><cell>S</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>t . DARTSV1 and DARTSV2 indicate the first-order and second-order DARTS methods</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 3 :</head><label>3</label><figDesc>Top-1 accuracy of searched architectures in five independent search runs on CIFAR10. ) 97.11 96.85 97.01 96.93 96.73 96.93?0.13 DARTSV2(%) 96.89 96.32 97.23 96.86 96.94 96.85?0.29 PCDARTS(%) 97.28 97.33 97.43 97.25 97.36 97.33?0.07</figDesc><table><row><cell>Methods</cell><cell>#1</cell><cell>#2</cell><cell>Runs #3</cell><cell>#4</cell><cell>#5</cell><cell>Mean?std</cell></row><row><cell>DARTSV1(%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>CDARTS(%) 97.53 97.45 97.60 97.52 97.54 97.52?0.04</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 4 :</head><label>4</label><figDesc>Comparison with SOTA architectures on CIFAR10 and CIFAR100. ? indicates using the DARTS<ref type="bibr" target="#b6">[7]</ref> search space. Latency is measured on an NVIDIA Tesla-P100 GPU with a batch size of 32 and an input size of 32?32.</figDesc><table><row><cell>Architecture</cell><cell cols="2">Test Acc. (%) CIFAR10 CIFAR100</cell><cell>Param (M)</cell><cell>Latency (ms)</cell><cell>Search Cost (GPU days)</cell><cell>Search Method</cell></row><row><cell>Wide ResNet [99]</cell><cell>96.20</cell><cell>82.70</cell><cell>36.5</cell><cell>-</cell><cell>-</cell><cell>manual</cell></row><row><cell>ResNeXt-29, 16x64d [100]</cell><cell>96.42</cell><cell>82.69</cell><cell>68.1</cell><cell>-</cell><cell>-</cell><cell>manual</cell></row><row><cell>DenseNet-BC [63]</cell><cell>96.52</cell><cell>82.82</cell><cell>25.6</cell><cell>-</cell><cell>-</cell><cell>manual</cell></row><row><cell>NASNet-A [1]</cell><cell>97.35</cell><cell>-</cell><cell>3.3</cell><cell>-</cell><cell>1800</cell><cell>RL</cell></row><row><cell>AmoebaNet-B [66]</cell><cell>97.45</cell><cell>-</cell><cell>2.8</cell><cell>-</cell><cell>3150</cell><cell>evolution</cell></row><row><cell>PNAS [10]</cell><cell>96.59</cell><cell>-</cell><cell>3.2</cell><cell>-</cell><cell>225</cell><cell>SMBO</cell></row><row><cell>ENAS [35]</cell><cell>97.11</cell><cell>-</cell><cell>4.6</cell><cell>-</cell><cell>0.5</cell><cell>RL</cell></row><row><cell>NAONet [101]</cell><cell>96.82 1</cell><cell>84.33</cell><cell>10.6</cell><cell>-</cell><cell>200</cell><cell>NAO</cell></row><row><cell>SNAS (moderate) [17]</cell><cell>97.15 ? 0.02</cell><cell>-</cell><cell>2.8</cell><cell>30.2</cell><cell>1.5</cell><cell>gradient</cell></row><row><cell>ProxylessNAS [14]</cell><cell>97.92</cell><cell>-</cell><cell>5.7</cell><cell>-</cell><cell>4</cell><cell>gradient</cell></row><row><cell>GDAS [18]</cell><cell>97.07</cell><cell>81.62</cell><cell>3.4</cell><cell>30.6</cell><cell>4</cell><cell>gradient</cell></row><row><cell>Random  ?</cell><cell>96.75 ? 0.18</cell><cell>-</cell><cell>3.4</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DARTSV1 [7]  ?</cell><cell>97.00 ? 0.14</cell><cell>82.24</cell><cell>-</cell><cell>3.3</cell><cell>1.5</cell><cell>gradient</cell></row><row><cell>DARTSV2 [7]  ?</cell><cell>97.24 ? 0.09</cell><cell>82.46</cell><cell>40.9</cell><cell>3.3</cell><cell>4.0</cell><cell>gradient</cell></row><row><cell>PDARTS [15]  ?</cell><cell>97.50</cell><cell>83.45</cell><cell>3.4</cell><cell>40.9</cell><cell>0.3</cell><cell>gradient</cell></row><row><cell>PCDARTS [81]  ?</cell><cell>97.43 ? 0.06</cell><cell>-</cell><cell>3.6</cell><cell>40.7</cell><cell>0.1</cell><cell>gradient</cell></row><row><cell>FairDARTS [38]  ?</cell><cell>97.41 ? 0.14</cell><cell>-</cell><cell>3.8</cell><cell>-</cell><cell>0.1</cell><cell>gradient</cell></row><row><cell>LA-DARTS [102]  ?</cell><cell>97.28 ? 0.05</cell><cell>-</cell><cell>2.7</cell><cell>28.4</cell><cell>0.7</cell><cell>gradient</cell></row><row><cell>CDARTS  ?</cell><cell>97.52 ? 0.04</cell><cell>84.31</cell><cell cols="2">3.9 ? 0.08 41.2 ? 0.5</cell><cell>0.3</cell><cell>gradient</cell></row><row><cell cols="3">every discovered architecture after each training epoch, as</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>visualized in</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 5 :</head><label>5</label><figDesc>Results on ImageNet. ? We use the same search space as DARTS<ref type="bibr" target="#b6">[7]</ref>. MS denotes mobile setting. * denotes use 10% of ImageNet data for searching.</figDesc><table><row><cell>Architecture</cell><cell cols="2">Test Acc. (%) Top-1 Top-5</cell><cell>Params (M)</cell><cell>?+ (M)</cell><cell cols="2">Search Cost Search Method (GPU days)</cell></row><row><cell>Inception-V1 [108]</cell><cell>69.8</cell><cell>89.9</cell><cell>6.6</cell><cell>1448</cell><cell>-</cell><cell>manual</cell></row><row><cell>SqueezeNext [109]</cell><cell>67.5</cell><cell>88.2</cell><cell>3.23</cell><cell>708</cell><cell>-</cell><cell>manual</cell></row><row><cell>MobileNet-V2 (1.4?) [60]</cell><cell>74.7</cell><cell>-</cell><cell>6.9</cell><cell>585</cell><cell>-</cell><cell>manual</cell></row><row><cell>ShuffleNet-V2 (2?) [110]</cell><cell>74.9</cell><cell>-</cell><cell>7.4</cell><cell>591</cell><cell>-</cell><cell>manual</cell></row><row><cell>NASNet-A [1]</cell><cell>74.0</cell><cell>91.6</cell><cell>5.3</cell><cell>564</cell><cell>1800</cell><cell>RL</cell></row><row><cell>AmoebaNet-C [66]</cell><cell>75.7</cell><cell>92.4</cell><cell>6.4</cell><cell>570</cell><cell>3150</cell><cell>evolution</cell></row><row><cell>PNAS [10]</cell><cell>74.2</cell><cell>91.9</cell><cell>5.1</cell><cell>588</cell><cell>225</cell><cell>SMBO</cell></row><row><cell>EfficientNet-B0 [36]</cell><cell>77.1</cell><cell>93.2</cell><cell>5.3</cell><cell>390</cell><cell>-</cell><cell>RL</cell></row><row><cell>MnasNet-92 [57]</cell><cell>74.8</cell><cell>92.0</cell><cell>4.4</cell><cell>388</cell><cell>-</cell><cell>RL</cell></row><row><cell>SPOS [77]</cell><cell>74.3</cell><cell>-</cell><cell>-</cell><cell>319</cell><cell>-</cell><cell>evolution</cell></row><row><cell>FairNAS-A [79]</cell><cell>75.3</cell><cell>92.4</cell><cell>4.6</cell><cell>388</cell><cell>-</cell><cell>evolution</cell></row><row><cell>MobileNet-V3 [32]</cell><cell>76.6</cell><cell>-</cell><cell>7.5</cell><cell>356</cell><cell>-</cell><cell>RL</cell></row><row><cell>MoGA-A [78]</cell><cell>75.9</cell><cell>92.8</cell><cell>5.1</cell><cell>304</cell><cell>12</cell><cell>evolution</cell></row><row><cell>SNAS (mild) [17]</cell><cell>72.7</cell><cell>90.8</cell><cell>4.3</cell><cell>522</cell><cell>1.5</cell><cell>gradient</cell></row><row><cell>XNAS [111]</cell><cell>76.0</cell><cell>?</cell><cell>5.2</cell><cell>?</cell><cell>0.3</cell><cell>gradient</cell></row><row><cell>ProxylessNAS [14]</cell><cell>75.1</cell><cell>92.5</cell><cell>7.1</cell><cell>465</cell><cell>8.3</cell><cell>gradient</cell></row><row><cell>ASAP [112]</cell><cell>73.3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.2</cell><cell>gradient</cell></row><row><cell>DARTS [7]  ?</cell><cell>73.3</cell><cell>91.3</cell><cell>4.7</cell><cell>574</cell><cell>4.0</cell><cell>gradient</cell></row><row><cell>FairDARTS [38]  ? PDARTS [15]  *   ? PCDARTS [81]  *   ? EnTranNAS (ImageNet) [16]  *   ? CDARTS(MS)  *   ? CDARTS  *   ?</cell><cell cols="4">75.6 75.6 75.8 75.7 75.9 76.3 ? 0.3 92.9 ? 0.2 6.1 ? 0.2 701 ? 32 92.6 4.3 440 92.6 4.9 557 92.7 5.3 597 92.8 5.5 637 92.6 5.4 571</cell><cell>3.0 0.3 3.8 1.9 1.7 1.7</cell><cell>gradient gradient gradient gradient gradient gradient</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE 6 :</head><label>6</label><figDesc></figDesc><table /><note>Evaluation of searched architectures in five inde- pendent search runs on ImageNet.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE 7 :</head><label>7</label><figDesc>Ablation study on ImageNet.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE 8 :</head><label>8</label><figDesc>Comparisons of chain-structured search space models on ImageNet. The input size is 224 ? 224. : using the SE module. The unit of search time is GPU day. ?: the search space contains kernel-size-7 operation. for fair comparisons. There are seven basic operators, including MBConv with kernel sizes of {3,5,7} and expansion rates of {4,6}, and an additional skip connection to enable elastic depth of architectures. The space contains about 3.69 ? 10 16 architecture candidates in total. For simplicity, we set SPOS</figDesc><table><row><cell>61]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>TABLE 9 :</head><label>9</label><figDesc>Object detection results of various drop-in backbones on the COCO val2017. Acc represents the top-1 accuracy on ImageNet. ? reported by<ref type="bibr" target="#b79">[79]</ref> BackbonesInput Size FLOPS(G) Params(M) mAP(%) AP 50 AP 75 AP S AP M AP L Top-1(%)</figDesc><table><row><cell cols="2">MobileNetV2  ? [60] 1280?800</cell><cell>6.1</cell><cell>3.4</cell><cell>28.3</cell><cell>46.7 29.3 14.8 30.7 38.1</cell><cell>72.0</cell></row><row><cell>SPOS  ? [77]</cell><cell>1280?800</cell><cell>7.4</cell><cell>4.3</cell><cell>30.7</cell><cell>49.8 32.2 15.4 33.9 41.6</cell><cell>75.0</cell></row><row><cell cols="2">MobileNetV3  ? [32] 1280?800</cell><cell>4.5</cell><cell>-</cell><cell>29.9</cell><cell>49.3 30.8 14.9 33.3 41.1</cell><cell>75.2</cell></row><row><cell cols="2">MnasNet-A2  ? [57] 1280?800</cell><cell>6.9</cell><cell>4.8</cell><cell>30.5</cell><cell>50.2 32.0 16.6 34.1 41.1</cell><cell>75.6</cell></row><row><cell>MixNet-M  ? [118]</cell><cell>1280?800</cell><cell>7.3</cell><cell>5.0</cell><cell>31.3</cell><cell>51.7 32.4 17.0 35.0 41.9</cell><cell>77.0</cell></row><row><cell>FairNAS-A  ? [79]</cell><cell>1280?800</cell><cell>8.0</cell><cell>5.9</cell><cell>32.4</cell><cell>52.4 33.9 17.2 36.3 43.2</cell><cell>77.5</cell></row><row><cell>MixPath-A [122]</cell><cell>1280?800</cell><cell>7.1</cell><cell>5.0</cell><cell>31.5</cell><cell>51.3 33.2 17.4 35.3 41.8</cell><cell>76.9</cell></row><row><cell>CDARTS-a</cell><cell>1280?800</cell><cell>6.0</cell><cell>7.0</cell><cell>35.2</cell><cell>55.5 37.5 19.8 38.7 47.5</cell><cell>77.4</cell></row><row><cell>CDARTS-b</cell><cell>1280?800</cell><cell>8.1</cell><cell>6.4</cell><cell>36.2</cell><cell>56.7 38.3 20.9 39.8 48.5</cell><cell>78.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>TABLE 10 :</head><label>10</label><figDesc>Top-1 accuracy of big models.</figDesc><table><row><cell>Method</cell><cell cols="2">CIFAR10 ImageNet</cell></row><row><cell>DARTS [7]</cell><cell>97.95</cell><cell>-</cell></row><row><cell>PDARTS [15]</cell><cell>98.00</cell><cell>80.04</cell></row><row><cell cols="2">PCDARTS [81] 97.92</cell><cell>79.81</cell></row><row><cell>CDARTS</cell><cell>98.32</cell><cell>81.12</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>TABLE 11 :</head><label>11</label><figDesc>Comparisons of models for semantic segmentation on the Cityscapes validation set. ered by other DARTS methods, such as DARTS, PDARTS and PCDARTS with the same big setting. As presented in Tab. 10, our CDARTS performs the best among them.Big Model on ImageNet We increase the channel number from 48 to 96 and the input image size from 224?224 to 320?320 to construct a big model with 5.6B flops. This big model is trained for 250 epochs, and obtains a 4.86 points absolute improvement over the original CDARTS, achieving 81.12 top-1 accuracy on ImageNet, which is comparable to EfficientNet-B2</figDesc><table><row><cell>Methods</cell><cell>Encoder</cell><cell cols="3">Flops Params mIoU (G) (M) (%)</cell></row><row><cell>ESPNetV2 [123]</cell><cell cols="2">ESPNetV2 2.7</cell><cell>1.3</cell><cell>66.2</cell></row><row><cell>ICNet [124]</cell><cell>PSPNet50</cell><cell>-</cell><cell>-</cell><cell>69.5</cell></row><row><cell>HRNet [125]</cell><cell cols="2">HRNetV2 31.1</cell><cell>1.5</cell><cell>70.3</cell></row><row><cell>CAS [126]</cell><cell>CAS</cell><cell>-</cell><cell>-</cell><cell>71.6</cell></row><row><cell>MobilenetV3 [127]</cell><cell>Large</cell><cell>9.7</cell><cell>1.5</cell><cell>72.4</cell></row><row><cell>FasterSeg [128]</cell><cell cols="2">FasterSeg 28.2</cell><cell>4.4</cell><cell>73.1</cell></row><row><cell>BiSeNetV2-L [129]</cell><cell>-</cell><cell>21.2</cell><cell>-</cell><cell>73.4</cell></row><row><cell cols="3">SqueezeNAS [130] LAT Large 19.6</cell><cell>1.9</cell><cell>73.6</cell></row><row><cell cols="5">SwiftNetRN-18 [131] ResNet18 104.0 11.8 75.4</cell></row><row><cell>SegFormer [37]</cell><cell cols="3">MiT-B0 125.5 3.8</cell><cell>76.2</cell></row><row><cell cols="3">CDARTS(Ours) CDARTS-b 20.7</cell><cell>5.9</cell><cell>78.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>TABLE 12 :</head><label>12</label><figDesc>Comparisons of models for semantic segmentation on the ADE20K validation set.</figDesc><table><row><cell>Methods</cell><cell>Encoder</cell><cell cols="3">Flops Params mIoU (G) (M) (%)</cell></row><row><cell>FCN [138]</cell><cell cols="2">MobileNetV2 39.6</cell><cell>9.8</cell><cell>19.7</cell></row><row><cell>PSPNet [139]</cell><cell cols="4">MobileNetV2 52.9 13.7 29.6</cell></row><row><cell cols="5">DeepLabV3+ [140] MobileNetV2 69.4 15.4 34.0</cell></row><row><cell>SegFormer [37]</cell><cell>MiT-B0</cell><cell>8.4</cell><cell>3.8</cell><cell>37.4</cell></row><row><cell cols="3">CDARTS(Ours) CDARTS-b 5.9</cell><cell>2.7</cell><cell>40.4</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Data: Differentiable architecture approximation with distribution guided sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gaofeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Nas-fpn: Learning scalable feature pyramid architecture for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y.</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7036" to="7045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Detnas: Backbone search for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="6642" to="6652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Auto-deeplab: Hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="82" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fast neural architecture search of compact semantic segmentation models via auxiliary cells</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nekrasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9126" to="9135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A comprehensive survey of neural architecture search: Challenges and solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Progressive neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural architecture search with bayesian optimisation and optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kandasamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural architecture search: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">55</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A survey on neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wistuba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pedapati</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.01392</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">ProxylessNAS: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards improving the consistency, efficiency, and flexibility of differentiable neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SNAS: stochastic neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Searching for a robust neural architecture in four gpu hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Autohas: Efficient hyperparameter and architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gabrys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Random search and reproducibility for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI. PMLR, 2020</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="367" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Understanding and robustifying differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.06035</idno>
		<title level="m">Darts+: Improved differentiable architecture search with early stopping</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Rethinking architecture selection in differentiable NAS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2021. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Evaluating the search phase of neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sciuto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Nas evaluation is frustratingly hard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Esperan?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Weight-sharing neural architecture search: A battle to shrink the optimization gap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.01475</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Search to distill: Pearls are everywhere but not the eyes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vemulapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7539" to="7548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Block-wisely supervised neural architecture search with knowledge distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Citeseer, Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ImageNet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Nas-bench-201: Extending the scope of reproducible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Searching for mobilenetv3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">One-shot neural architecture search via self-evaluated template network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Efficient neural architecture search via parameters sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<editor>ICLR. PMLR</editor>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<editor>ICLR. PMLR</editor>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Segformer: Simple and efficient design for semantic segmentation with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fair darts: Eliminating unfair advantages in differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note>2, 4, 6, 9</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multilevel discriminative dictionary learning with application to large scale image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3109" to="3123" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dynamical system inspired adaptive time stepping controller for residual network families</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="6648" to="6655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep learning for generic object detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fieguth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pietik?inen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="261" to="318" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1149" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Robust subspace segmentation by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="8" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Sognet: Scene overlap graph network for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="12" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Expectationmaximization attention networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Gracker: A graph-based planar object tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1494" to="1501" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A deep network solution for attention and aesthetics aware photo cropping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1531" to="1544" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Towards efficient scene understanding via squeeze reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="7050" to="7063" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Joint subbands learning with clique structures for wavelet domain superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning both weights and connections for efficient neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Adanet: Adaptive structural learning of artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gonzalvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="874" to="883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Neural networks designing neural networks: multi-objective hyperparameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Smithson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Computer-Aided Design</title>
		<meeting>the 35th International Conference on Computer-Aided Design</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Convolutional neural fabrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="4053" to="4061" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Designing neural network architectures using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Genetic cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<biblScope unit="page" from="1379" to="1388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Bignas: Scaling up neural architecture search with big single-stage models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-J</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vajda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.02049</idno>
		<title level="m">Fbnetv3: Joint architecture-recipe search using neural acquisition function</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<title level="m">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Once for all: Train one network and specialize it for efficient deployment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
	<note>in ICLR, 2020. 3, 4</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in CVPR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Practical blockwise neural network architecture generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in CVPR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2423" to="2432" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Nas-bench-101: Towards reproducible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<editor>ICLR. PMLR</editor>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7105" to="7114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Nas-bench-1shot1: Benchmarking and dissecting one-shot neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Siems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Evolving deep convolutional neural networks by variable-length particle swarm optimization for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Congress on Evolutionary Computation (CEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Evolutionary architecture search for deep multitask networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference</title>
		<meeting>the Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="466" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Evolving unsupervised deep neural networks for learning meaningful representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="103" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Dppnet: Device-aware progressive search for pareto-optimal neural architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-C</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="517" to="531" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Hierarchical representations for efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICLR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Smash: oneshot model architecture search through hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICLR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Understanding and simplifying one-shot architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-J</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<editor>ICLR. PMLR</editor>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="550" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Single path one-shot neural architecture search with uniform sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Moga: Searching beyond mo-bilenetv3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note>in ICASSP. IEEE, 2020</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Fairnas: Rethinking evaluation fairness of weight sharing neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Improving one-shot nas by suppressing the posterior fading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">845</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">PC-DARTS: Partial channel connections for memory-efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Istanas: Efficient and consistent neural architecture search by sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Tapas: Train-less accuracy predictor for architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Istrate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mariani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nikolopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bekas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C I</forename><surname>Malossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3927" to="3934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Transfer learning with neural automl</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gesmundo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Xfernas: Transfer neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wistuba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="247" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Efficient neural architecture transformation searchin channel-level for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<idno>2020. 4</idno>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Fna++: Fast network adaptation via parameter remapping and architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Neural architecture transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sreekumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Boddeti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="issue">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Cream of the crop: Distilling prioritized paths for one-shot neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Meta pseudo labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2021</title>
		<imprint>
			<biblScope unit="volume">568</biblScope>
			<biblScope unit="page" from="11" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Evaluating the search phase of neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sciuto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Nats-bench: Benchmarking nas algorithms for architecture topology and size</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Musial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gabrys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Bohb: Robust and efficient hyperparameter optimization at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Falkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<editor>ICLR. PMLR</editor>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1437" to="1446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">A downsampled variant of imagenet as an alternative to the cifar datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chrabaszcz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.08819</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
		<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title/>
		<idno type="DOI">10.5244/C.30.87</idno>
		<idno>1-87.12</idno>
		<ptr target="https://dx.doi.org/10.5244/C.30.879" />
		<editor>E. R. H. Richard C. Wilson and W. A. P. Smith</editor>
		<imprint>
			<date type="published" when="2016-09" />
			<publisher>BMVA Press</publisher>
			<biblScope unit="volume">87</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Neural architecture optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Latency-aware differentiable neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.06392</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">The annals of mathematical statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Monro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1951" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note>A stochastic approximation method</note>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">Fractalnet: Ultradeep neural networks without residuals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<idno>2017. 10</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Squeezenext: Hardware-aware neural network design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gholami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1638" to="1647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Shufflenet v2: Practical guidelines for efficient cnn architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="116" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Xnas: Neural architecture search with expert advice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nayman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ridnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nayman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ridnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Doveh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.04123</idno>
		<title level="m">Asap: Architecture search, anneal and prune</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<title level="m" type="main">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Shufflenet: An extremely efficient convolutional neural network for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in CVPR</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6848" to="6856" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Dsnas: Direct neural architecture search without parameter retraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<idno>pp. 12 084-12 092. 12</idno>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Mixconv: Mixed depthwise convolutional kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Scarlet-nas: bridging the gap between stability and scalability in weight-sharing neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="113" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICLR</title>
		<imprint>
			<biblScope unit="issue">13</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title level="m" type="main">Mixpath: A unified approach for one-shot neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.05887</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Espnet: Efficient spatial pyramid of dilated convolutions for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Caspi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="552" to="568" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Icnet for real-time semantic segmentation on high-resolution images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="405" to="420" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">Deep high-resolution representation learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">TPAMI</note>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Customizable architecture search for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">650</biblScope>
			<biblScope unit="page" from="11" to="641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Searching for mobilenetv3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1314" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<title level="m" type="main">Fasterseg: Searching for faster real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Bisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Squeezenas: Fast neural architecture search for faster semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Landola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sidhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV Workshops</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">In defense of pretrained imagenet architectures for real-time semantic segmentation of road-driving images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Orsic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kreso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bevandic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Segvic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Mmdetection: Open mmlab detection toolbox and benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07155</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Spatial pyramid based graph reasoning for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="8950" to="8959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Scene parsing through ade20k dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barriuso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="633" to="641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="801" to="818" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
