<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pyramid Adversarial Training Improves ViT Performance</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Herrmann</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Sargent</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramin</forename><surname>Zabih</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiwen</forename><surname>Chang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Research</surname></persName>
						</author>
						<title level="a" type="main">Pyramid Adversarial Training Improves ViT Performance</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Aggressive data augmentation is a key component of the strong generalization capabilities of Vision Transformer (ViT). One such data augmentation technique is adversarial training (AT); however, many prior works <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b45">45]</ref> have shown that this often results in poor clean accuracy. In this work, we present pyramid adversarial training (Pyra-midAT), a simple and effective technique to improve ViT's overall performance. We pair it with a "matched" Dropout and stochastic depth regularization, which adopts the same Dropout and stochastic depth configuration for the clean and adversarial samples. Similar to the improvements on CNNs by AdvProp [61] (not directly applicable to ViT), our pyramid adversarial training breaks the trade-off between in-distribution accuracy and out-of-distribution robustness for ViT and related architectures. It leads to 1.82% absolute improvement on ImageNet clean accuracy for the ViT-B model when trained only on ImageNet-1K data, while simultaneously boosting performance on 7 ImageNet robustness metrics, by absolute numbers ranging from 1.76% to 15.68%. We set a new state-of-the-art for ImageNet-C (41.42 mCE), ImageNet-R (53.92%), and ImageNet-Sketch (41.04%) without extra data, using only the ViT-B/16 backbone and our pyramid adversarial training. Our code is publicly available at pyramidat.github.io. * Equal contribution, ordered alphabetically. ? Currently affiliated with Microsoft Azure AI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Robustness of ViT</head><p>ViT models have been found to be more adversarially robust than CNNs <ref type="bibr" target="#b41">[41,</ref><ref type="bibr" target="#b49">49]</ref>, and more im-</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>One fascinating aspect of human intelligence is the ability to generalize from limited experiences to new environments <ref type="bibr" target="#b30">[30]</ref>. While deep learning has made remarkable progress in emulating or "surpassing" humans on classification tasks, deep models have difficulty generalizing to outof-distribution data <ref type="bibr" target="#b31">[31]</ref>. Convolutional neural networks (CNNs) may fail to classify images with challenging contexts <ref type="bibr" target="#b22">[22]</ref>, unusual colors and textures <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b59">58]</ref> and common or adversarial corruptions <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b20">20]</ref>. To reliably deploy neural networks on diverse tasks in the real world, we must <ref type="bibr">Figure 1</ref>. Top: Visualization of our learned multi-scale pyramid perturbations. We show the original image, multiple scales of a perturbation pyramid, and the perturbed image. Bottom: We show thumbnails of in-distribution and out-of-distribution datasets, and the gains from applying our technique on each dataset. (Note that lower is better for ImageNet-C.)</p><p>improve their robustness to out-of-distribution data.</p><p>One major line of research focuses on network design. Recently the Vision Transformer (ViT) <ref type="bibr" target="#b15">[15]</ref> and its variants <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b56">55]</ref> have advanced the state of the art on a variety of computer vision tasks. In particular, ViT models are more robust than comparable CNN architectures <ref type="bibr" target="#b36">[36,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b49">49]</ref>. With a weak inductive bias and powerful model capacity, ViT relies heavily on strong data augmentation and regularization to achieve better generalization <ref type="bibr" target="#b51">[51,</ref><ref type="bibr" target="#b56">55]</ref>. To further push this envelope, we explore using adversarial training <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b66">65]</ref> as a powerful regularizer to improve the performance of ViT models.</p><p>Prior work <ref type="bibr" target="#b57">[56]</ref> suggests that there exists a performance trade-off between in-distribution generalization and robustness to adversarial examples. Similar trade-offs have been observed between in-distribution and out-of-distribution generalization <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b66">65]</ref>. These trade-offs have primarily been observed in the context of CNNs <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b45">45]</ref>. However, recent work has demonstrated the trade-off can be broken. AdvProp <ref type="bibr" target="#b62">[61]</ref> achieves this via adversarial training (abbreviated AT) with a "split" variant of Batch Normalization <ref type="bibr" target="#b24">[24]</ref> for EfficientNet <ref type="bibr" target="#b53">[53]</ref>. In our work, we demonstrate that the trade-off can be broken for the newly introduced vision transformer architecture <ref type="bibr" target="#b15">[15]</ref>.</p><p>We introduce pyramid adversarial training (abbreviated as PyramidAT) that trains the model with input images altered at multiple spatial scales, as illustrated in <ref type="figure">Fig. 1</ref>; the pyramid attack is designed to make large edits to the image in a structured, controlled manner (similar to augmenting brightness) and small edits to the image in a flexible manner (similar to pixel adversaries). Using these structured, multiscale adversarial perturbations leads to significant performance gains compared to both baseline and standard pixelwise adversarial perturbations. Interestingly, we see these gains for both clean (in-distribution) and robust (out-ofdistribution) accuracy. We further enhance the pyramid attack with additional regularization techniques: "matched" Dropout and stochastic depth. Matched Dropout uses the same Dropout configuration for both the regular and adversarial samples in a mini-batch (hence the word matched). Stochastic depth <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b51">51]</ref> randomly drops layers in the network and provides a further boost when matched and paired with matched Dropout and multi-scale perturbations.</p><p>Our ablation studies confirm the importance of matched Dropout when used in conjunction with the pyramid adversarial training. They also reveal a complicated interplay between adversarial training, the attack being used, and network capacity. We additionally show that our approach is applicable to datasets of various scales (ImageNet-1K and ImageNet-21K) and for a variety of network architectures such as ViT <ref type="bibr" target="#b15">[15]</ref>, Discrete ViT <ref type="bibr" target="#b37">[37]</ref>, ResNet <ref type="bibr" target="#b18">[18]</ref>, and MLP-Mixer <ref type="bibr" target="#b54">[54]</ref>. Our contributions are summarized below:</p><p>? To our knowledge, we appear to be the first to demonstrate that adversarial training improves ViT model performance on both ImageNet <ref type="bibr" target="#b13">[13]</ref> and out-ofdistribution ImageNet robustness datasets <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b59">58]</ref>.</p><p>? We demonstrate the importance of matched Dropout and stochastic depth for the adversarial training of ViT.</p><p>? We design pyramid adversarial training to generate multi-scale, structured adversarial perturbations, which achieve significant performance gains over nonadversarial baseline and adversarial training with pixel perturbations.</p><p>? We establish a new state of the art for ImageNet-C, ImageNet-R, and ImageNet-Sketch without extra data, using only our pyramid adversarial training and the standard ViT-B/16 backbone. We further improve our results by incorporating extra ImageNet-21K data.</p><p>? We perform numerous ablations which highlight several elements critical to the performance gains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>There exists a large body of work on measuring and improving the robustness of deep learning models, in the context of adversarial examples and generalization to nonadversarial but shifted distributions. We define out-ofdistribution accuracy/robustness to explicitly refer to performance of a model on non-adversarial distribution shifts, and adversarial accuracy/robustness to refer to the special case of robustness on adversarial examples. When the evaluation is performed on a dataset drawn from the same distribution, we call this clean accuracy.</p><p>Adversarial training and robustness The discovery of adversarial examples <ref type="bibr" target="#b52">[52]</ref> has stimulated a large body of literature on adversarial attacks and defenses <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b61">60]</ref>. Of the many proposed defenses, adversarial training <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b35">35]</ref> has emerged as a simple, effective, albeit expensive approach to make networks adversarially robust. Although some work <ref type="bibr" target="#b57">[56,</ref><ref type="bibr" target="#b66">65]</ref> has suggested a tradeoff between adversarial and out-of-distribution robustness or clean accuracy, other analysis <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b45">45]</ref> has suggested simultaneous improvement is achievable. In <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b45">45]</ref>, the authors note improved accuracy on both clean and adversarially perturbed data, though only on smaller datasets such as CIFAR-10 <ref type="bibr" target="#b27">[27]</ref> and SVHN <ref type="bibr" target="#b42">[42]</ref>, and only through the use of additional data extending the problem to the semisupervised setting. Similarly in NLP, adversarial training leads to improvement of clean accuracy for machine translation <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b9">9]</ref>.</p><p>Most closely related to our work is the technique of <ref type="bibr" target="#b62">[61]</ref>, which demonstrates the potential of adversarial training to improve both clean accuracy and out-of-distribution robustness. They focus primarily on CNNs and propose split batch norms to separately capture the statistics of clean and adversarially perturbed samples in a mini-batch. At inference time, the batch norms associated with adversarially perturbed samples are discarded, and all data (presumed clean or out-of-distribution) flows through the batch norms associated with clean samples. Their results are demonstrated on EfficientNet <ref type="bibr" target="#b53">[53]</ref> and ResNet <ref type="bibr" target="#b18">[18]</ref> architectures. However, their approach is not directly applicable to ViT where batch norms do not exist. In our work, we propose novel approaches, and find that properly constructed adversarial training helps clean accuracy and out-of-distribution robustness for ViT models. portantly, generalize better than CNNs with similar model capacity on ImageNet out-of-distribution robustness benchmarks <ref type="bibr" target="#b49">[49]</ref>. While existing works focus on analyzing the cause of ViT's superior generalizability, this work aims at further improving the strong out-of-distribution robustness of the ViT model. A promising approach to this end is data augmentation; as shown recently <ref type="bibr" target="#b51">[51,</ref><ref type="bibr" target="#b56">55]</ref>, ViT benefits from strong data augmentation. However, the data augmentation techniques used in ViT <ref type="bibr" target="#b51">[51,</ref><ref type="bibr" target="#b56">55]</ref> are optimized for clean accuracy on ImageNet, and knowledge about robustness is still limited. Different from prior works, this paper focuses on improving both the clean accuracy and robustness for ViT. We show that our technique can effectively complement strong ViT augmentation as in <ref type="bibr" target="#b51">[51]</ref>. We additionally verify that our proposed augmentation can benefit three other architectures: ResNet <ref type="bibr" target="#b18">[18]</ref>, MLP-Mixer <ref type="bibr" target="#b54">[54]</ref>, and Discrete ViT <ref type="bibr" target="#b37">[37]</ref>.</p><p>Data augmentation Existing data augmentation techniques, although mainly developed for CNNs, transfer reasonably well to ViT models <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b60">59]</ref>. Other work has studied larger structured attacks <ref type="bibr" target="#b61">[60]</ref>. Our work is different from prior work in that we utilize adversarial training to augment ViT and tailor our design to the ViT architecture. To our knowledge, we appear to be the first to demonstrate that adversarial training substantially improves ViT performance in both clean and out-of-distribution accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>We work in the supervised learning setting where we are given a training dataset D consisting of clean images, represented as x and their labels y. The loss function considered is a cross-entropy loss L(?, x, y), where ? are the parameters of the ViT model, with weight regularization f . The baseline models minimize the following loss:</p><formula xml:id="formula_0">E (x,y)?D L(?,x, y) + f (?) ,<label>(1)</label></formula><p>wherex refers to a data-augmented version of the clean sample x, and we adopt the standard data augmentations as in <ref type="bibr" target="#b51">[51]</ref>, such as RandAug <ref type="bibr" target="#b10">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Adversarial Training</head><p>The overall training objective for adversarial training <ref type="bibr" target="#b58">[57]</ref> is given as follows:</p><formula xml:id="formula_1">E (x,y)?D max ??P L(?,x + ?, y) + f (?) ,<label>(2)</label></formula><p>where ? a per-pixel, per-color-channel additive perturbation, and P is the perturbation distribution. Note that the adversarial image, x a , is given byx + ?, and we use these two interchangeably below. The perturbation, ?, is computed by optimizing the objective inside the maximization of Eqn. 2. This objective tries to improve the worst-case performance of the network w.r.t. the perturbation; subsequently, the resulting model has lower clean accuracy.</p><p>To remedy this, we can train on both clean and adversarial images <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b62">61]</ref> using the following objective:</p><formula xml:id="formula_2">E (x,y)?D L(?,x, y) + ? max ??P L(?,x + ?, y) + f (?) ,<label>(3)</label></formula><p>This objective uses adversarial images as a form of regularization or data augmentation, to force the network towards certain representations that perform well on out-ofdistribution data. These networks exhibit some degree of robustness but still have good clean accuracy. More recently, <ref type="bibr" target="#b62">[61]</ref> proposes a split batch norm that leads to performance gains for CNNs on both clean and robust ImageNet test datasets. Note that they do not concern themselves with adversarial robustness, and neither do we in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pyramid Adversarial Training</head><p>Pixel-wise adversarial images are defined <ref type="bibr" target="#b29">[29]</ref> as x a = x+? where the perturbation distribution P consists of a clipping function C B? that clips the perturbation at each pixel location to be inside the specified ball (B ? ) for a specified l pnorm <ref type="bibr" target="#b35">[35]</ref>, with maximal radius ? for the perturbation.</p><p>Motivation For pixel-wise adversarial images, increasing the value of ? or the number of steps of the inner loop in Eqn. 3 eventually causes a drop in clean accuracy <ref type="figure">(Fig 2)</ref>. Conceptually, pixel attacks are very flexible and, if given the ability to make large changes (in L 2 distance), can destroy the object being classified; training with these images may harm the network. In contrast, augmentations, like brightness, can lead to large L 2 distances but will preserve the object because they are structured. Our main motivation is to design an attack which has the best of both worlds: a low-magnitude flexible component and a high-magnitude structured component; this attack can lead to large image differences while still preserving the class identity.</p><p>Approach We propose pyramid adversarial training (PyramidAT) which generates adversarial examples by perturbing the input image at multiple scales. This attack is more flexible and yet also more structured, since it consists of multiple scales, but the perturbations are constrained at each scale.</p><formula xml:id="formula_3">x a = C B1 x + s?S m s ? C B? s (? s ) ,<label>(4)</label></formula><p>where C B1 is the clipping function that keeps the image within the normal range, S is the set of scales, m s is the multiplicative constant for scale s, ? s is the learned perturbation (with the same shape as x). For scale s, the weights in ? s are shared for pixels in square regions of size s?s with top left corner [s ? i, s ? j] for all discrete i ? [0, width/s] and j ? [0, height/s], as shown in <ref type="figure">Fig. 1</ref>. Note that, similar to pixel AT, each channel of the image is perturbed independently. More details of the parameter settings are given in Section 4 and pseudocode is included in the supplementals.</p><p>Setting up the attack For both the pixel and pyramid attacks, we use Projected Gradient Descent (PGD) on a random label using multiple steps <ref type="bibr" target="#b35">[35]</ref>. With regards to the loss, we observe that for ViT, maximizing the negative loss of the true label leads to aggressive label leaking <ref type="bibr" target="#b29">[29]</ref>, i.e., the network learns to predict the adversarial attack and performs better on the perturbed image. To avoid this, we pick a random label and then minimize the softmax crossentropy loss towards that random label as described in <ref type="bibr" target="#b29">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">"Matched" Dropout and Stochastic Depth</head><p>Standard training for ViT models uses both Dropout <ref type="bibr" target="#b50">[50]</ref> and stochastic depth <ref type="bibr" target="#b23">[23]</ref> as regularizers. During adversarial training, we have both the clean samples and adversarial samples in a mini-batch. This poses a question about Dropout treatment during adversarial training (either pixel or pyramid). In the adversarial training literature, the usual strategy is to run the adversarial attack (to generate adversarial samples) without using Dropout or stochastic depth. However, this leads to a training mismatch between the clean and adversarial training paths when both are used in the loss (Eqn. 3), with the clean samples trained with Dropout and the adversarial samples without Dropout. For each training instance in the mini-batch, the clean branch will only update subsets of the network while the adversarial branch updates the entire network. The adversarial branch updates are therefore more closely aligned with the model performance during evaluation, thereby leading to an improvement of adversarial accuracy at the expense of clean accuracy. This objective function is given below:</p><formula xml:id="formula_4">E (x,y)?D L(M(?),x, y)+? max ??P L(?, x a , y)+f (?) ,<label>(5)</label></formula><p>where, with a slight abuse of notation, M(?) denotes a network with a random Dropout mask and a stochastic depth configuration. To address the issue above, we propose adversarial training of ViT with "matched" Dropout, i.e., using the same Dropout configuration for both clean and adversarial training branches (as well as for the generation of adversarial samples). We show through ablation in Section 4 that using the same Dropout configuration leads to the best overall performance for both the clean and robust datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we compare the effectiveness of our proposed PyramidAT to non-AT models, and PixelAT models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>Models We focus primarily on ViT-B/16 <ref type="bibr" target="#b15">[15]</ref>, the baseline ViT with a patch size of 16. We also demonstrate our technique on other network architectures, such as ViT-Ti/16, ResNet <ref type="bibr" target="#b18">[18]</ref>, MLP-Mixer <ref type="bibr" target="#b54">[54]</ref>, and the recent Discrete ViT <ref type="bibr" target="#b37">[37]</ref>. Datasets We train models on both ImageNet-1K and ImageNet-21K <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b48">48]</ref>. We evaluate in-distribution performance on 2 additional variants: ImageNet-ReaL <ref type="bibr" target="#b3">[4]</ref> which relabels the validation set of the original ImageNet in order to correct labeling errors; and ImageNet-V2 <ref type="bibr" target="#b47">[47]</ref> which collects another version of ImageNet's evaluation set. We evaluate out-of-distribution robustness on 6 datasets: ImageNet-A <ref type="bibr" target="#b22">[22]</ref> which places the ImageNet objects in unusual contexts or orientations; ImageNet-C <ref type="bibr" target="#b20">[20]</ref> which applies a series of corruptions (e.g. motion blur, snow, JPEG, etc.); ImageNet-Rendition <ref type="bibr" target="#b19">[19]</ref> which contains abstract or rendered versions of the object; ObjectNet <ref type="bibr" target="#b2">[3]</ref> which consists of a large real-world set from a large number of different backgrounds, rotations, and imaging view points; ImageNet-Sketch <ref type="bibr" target="#b59">[58]</ref> which contains artistic sketches of the objects; and Stylized ImageNet <ref type="bibr" target="#b16">[16]</ref> which processes the ImageNet images with style transfer from an unrelated source image. For brevity, we may abbreviate ImageNet as IM. For all datasets except IM-C, we report top-1 accuracy (where higher is better). For IM-C, we report the standard "Mean corruption error" (mCE) (where lower is better). Implementation details Following <ref type="bibr" target="#b51">[51]</ref>, we use a batch size of 4096, a cosine decay learning rate schedule (0.001 magnitude) with linear warmup for the first 10k steps, <ref type="bibr" target="#b34">[34]</ref>, and the AdamW optimizer <ref type="bibr" target="#b26">[26]</ref> in all our experiments. Augmentations and regularizations include RandAug <ref type="bibr" target="#b10">[10]</ref> with the default setting of (2, 15), Dropout <ref type="bibr" target="#b50">[50]</ref> at probability 0.1, and stochastic depth <ref type="bibr" target="#b23">[23]</ref> at probability 0.1. We train with Scenic <ref type="bibr" target="#b12">[12]</ref>, a Jax <ref type="bibr" target="#b4">[5]</ref> library, on DragonFish TPUs.</p><p>To generate the pixel adversarial attack, we follow <ref type="bibr" target="#b62">[61]</ref>. We use a learning rate of 1/255, ? = 4/255, and attack for 5 steps with SGD. We use PGD <ref type="bibr" target="#b35">[35]</ref> to generate the adversarial perturbations. We also experiment with using more recent optimizers <ref type="bibr" target="#b67">[66]</ref> to construct the attacks (results are provided in the supplementals). For pyramid attacks, we find using stronger perturbations at coarser scales is more effective than equal perturbation strengths across all scales. By default, we use a 3-level pyramid and use perturbation scale factors S = [32, 16, 1] (a scale of 1 means that each pixel has one learned parameter, a scale of 16 means that each <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b16">16]</ref> patch has one learned parameter) with multiplicative terms of m s = [20, 10, 1] (see Eqn. 4). We use a clipping value of ? s = 6/255 for all levels of the pyramid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental Results on ViT-B/16</head><p>ImageNet-1K <ref type="table">Table 1</ref>  ial training, with pixel adversarial attacks and with pyramid adversarial attacks. Both adversarial training attacks use matched Dropout and stochastic depth, and optimize the random target loss. The pyramid attack provides consistent improvements, on both clean and robustness accuracies, over the baseline and pixel adversaries. In <ref type="table">Table 1</ref>, we also compare against CutMix <ref type="bibr" target="#b64">[63]</ref> augmentation. We find that CutMix improves performance over the ViT baseline but cannot improve performance when combined with Ran- dAug. Similar to <ref type="bibr" target="#b33">[33]</ref>, we find that CutOut <ref type="bibr" target="#b14">[14]</ref> does not boost performance on ImageNet for our models. The robustness gains of our technique are preserved through fine-tuning on clean data at higher resolution (384x384), as shown in the second set of rows of <ref type="table">Table 1</ref>. Further, adversarial perturbations are consistently better than random perturbations on either pre-training or fine-tuning, for both pixel and pyramid models.</p><p>State of the art Our model trained on IM-1K sets a new overall state of the art for IM-C <ref type="bibr" target="#b20">[20]</ref>, IM-Rendition <ref type="bibr" target="#b19">[19]</ref>, and IM-Sketch <ref type="bibr" target="#b59">[58]</ref>, as shown in Tables 2, 3, and 4. While we compare all our models under a unified framework in our main experiments, we select the optimal pre-processing, fine-tuning, and Dropout setting for the given dataset when comparing against the state-of-the-art. We also compare against <ref type="bibr" target="#b37">[37]</ref> on IM-21K and find that our results still compare favorably.  <ref type="table" target="#tab_2">Table 5</ref>. Main results from pre-training on ImageNet-21K, fine-tuning on ImageNet-1K. We pre-train with the adversarial technique mentioned (pixel or pyramid), but fine-tune on clean data only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ImageNet-21K In</head><p>pre-train on IM-21K and fine-tune on IM-1K at a higher resolution (in our case, 512x512). We apply adversarial training during the pre-training stage only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablations</head><p>ImageNet-1k on other backbones We explore the effects of adversarial training on three other backbones: ResNet <ref type="bibr" target="#b18">[18]</ref>, Discrete ViT <ref type="bibr" target="#b37">[37]</ref>, and MLP-Mixer <ref type="bibr" target="#b54">[54]</ref>. As shown in <ref type="table">Table 6</ref>, we find slightly different results. For ResNet, we use the split BN from <ref type="bibr" target="#b62">[61]</ref> and show improved performance from PyramidAT. Other ResNet variants (-101, -200) show the same trend and are included in the supplementals. For Discrete ViT, we show that AT with both pixel and pyramid leads to general improvements, though the gain from pyramid over pixel is less consistent than with ViT-B/16. For MLP-Mixer, we observe decreases in clean accuracy but gains in the robustness datasets for Pix-elAT, similar to what has traditionally been observed from AT on ConvNets. However, with PyramidAT, we observe improvements for all evaluation datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Matched Dropout and Stochastic Depth</head><p>We study the impact of handling Dropout and stochastic depth for the clean and adversarial update in <ref type="table">Table 7</ref>. We find that applying matched Dropout for the clean and adversarial update is crucial for achieving simultaneous gains in clean and robust performance. When we eliminate Dropout in the adversarial update ("without Dropout" rows in 7), we observe significant decreases in performance on clean, IM-ReaL, and IM-A; and increases in performance on IM-Sketch and IM-Stylized. This result appears similar to the usual tradeoff suggested in <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b66">65]</ref>. By contrast, carefully handling Dropout and stochastic depth can lead to performance gains in both clean and out-of-distribution datasets.</p><p>Pyramid attack setup In <ref type="table">Table 8</ref>, we ablate the pyramid attacks. Pyramid attacks are consistently better than pixel or patch attacks, while the 3-level pyramid attack tends to have the best overall performance. Note that a 2-level pyramid attack consists of both the pixel and patch attacks. Please refer to the supplementals for comparison on all the metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network capacity and random augmentation</head><p>We test the effect of network capacity on adversarial training and, consistent with existing literature <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b35">35]</ref>, find that large capacity is critical to effectively utilizing PixelAT. Specifically, low-capacity networks, like ViT-Ti/16, which already struggle to represent the dataset, can be made worse through PixelAT. <ref type="table">Table 9</ref> shows that PixelAT hurts in-distribution performance of the RandAugment 0.4 model but improves out-of-distribution performance. Unlike prior work, we note that this effect depends on both the network capacity and the random augmentation applied to the dataset. <ref type="table">Table 9</ref> shows that a low-capacity network can benefit from adversarial training if the random augmentation is of a small magnitude. Standard training with RandAugment [10] magnitude of 0.4 (abbreviated as RAm=0.4) provides a better clean accuracy than standard training with RAm=0.1; however, PixelAT with the weaker augmentation, RAm=0.1, performs better than either standard training or PixelAT at RAm=0.4. This suggests that the augmentation should be tuned for adversarial training and not fixed based on standard training. <ref type="table">Table 9</ref> also shows that PyramidAT acts differently than PixelAT and can provide in-distribution gains despite being used with stronger augmentation. For these models, we find that for the robustness datasets, PixelAT tends to marginally outperform PyramidAT.</p><p>Attack strength Pixel attacks are much smaller in L 2 norm than pyramid attacks. We check that simply scaling up the PixelAT cannot achieve the same performance as PyramidAT in <ref type="figure">Figure 2</ref>. For both ImageNet and ImageNet-C, we show the effect of raising the pixel and pyramid attack strength. While the best PyramidAT performance is achieved at high L 2 perturbation norm, the PixelAT performance degrades beyond a certain norm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Analysis and Discussions</head><p>Qualitative results Following <ref type="bibr" target="#b15">[15]</ref>, we visualize the learned pixel embeddings (filters) of models trained normally, with pixel adversaries, and with pyramid adversaries in <ref type="figure">Fig. 3</ref>. We observe that the PixelAT model tends to tightly "snap" its attention to the perceived object, disregarding the majority of the background. While this may appear to be a desirable behavior, this kind of focusing can be suboptimal for the in-distribution datasets (where the background can provide valuable context) and prone to errors for out-ofdistribution datasets. Specifically, the PixelAT model may under-estimate the size or shape of the object and focus on <ref type="bibr">Figure 2</ref>. Performance on clean and robust data as a function of perturbation size. Pyramid performance increases as perturbation size is increased, while pixel performance with large perturbation size is poor a part of the object and not the whole. This can be problematic for fine-grained classification when the difference between two classes comes down to something as small as the stripes or subtle shape cues (tiger shark vs great white); or texture and context (green mamba vs vine snake). <ref type="figure">Figure 4</ref> shows the heat maps for the average attention on images in the evaluation set of ImageNet-A. We observe that PyramidAT tends to more evenly spread its attention across the entire image than both the baseline and PixelAT.  of the dog. This suggests that the representation for the PyramidAT model focuses on shape and is less sensitive to texture than the baseline model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of attacks</head><p>Inspired by <ref type="bibr" target="#b63">[62]</ref>, we analyze the pyramid adversarial training from a frequency perspective. For this analysis, all visualizations and graphs are averaged  over the entire ImageNet validation set. <ref type="figure" target="#fig_2">Figure 6</ref> shows a Fourier heat map of random and adversarial versions of the pixel and pyramid attacks. While random pixel noise is evenly concentrated over all frequencies, adversarial pixel attack tends to concentrate in the lower frequencies. Random pyramid shows a bias towards low frequency as well, a trend which is amplified in the adversarial pyramid. To further explore this, we replicate an analysis from <ref type="bibr" target="#b63">[62]</ref>, where low-pass-and high-pass-filtered random noise is added to test data to perturb a classifier. <ref type="figure" target="#fig_3">Figure 7</ref> gives the result for our baseline, pixel, and pyramid adversarially trained models. While pixel and pyramid models are generally more robust than the baseline, the pyramid model is more robust than the pixel model to low-frequency perturbations.</p><p>Limitations The cost of our technique is increased training time. A k-step PGD attack requires k forward and backward passes for each step of training. Note that this limitation holds for any adversarial training and the inference time is the same. Without adversarial training, more training time does not improve the baseline ViT-B/16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have introduced pyramid adversarial training, a simple and effective data augmentation technique that substantially improves the performance of ViT and MLP-Mixer architectures on in-distribution and a number of out-ofdistribution ImageNet datasets.</p><p>Thanks for viewing the supplementary material, in which we provide a detailed explanation of the pyramid structure in Section A, detailed experiments for different backbones in Section B, more ablation study in Section C, additional analysis in Section D, visualizations in Section E, and finally a discussion on the effect of optimizers in Section F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Pyramid Attack Details</head><p>In this section, we provide a conceptual description and pseudocode for the pyramid attack.</p><p>Description Scale s determines the size of the patch that an individual perturbation parameter will be applied to; e.g. for s = 16, we learn and add a single adv parameter to each non-overlapping patch of size 16x16. The application is equivalent to a nearest neighbor resize on the 14x14 adv tensor to the image size of 224x224 and then addition. The scales s and multipliers m s used by PyramidAT are hyperparameters.</p><p>Code We provide a minimal implementation of our technique in <ref type="figure" target="#fig_4">Fig. 8</ref>.  <ref type="table" target="#tab_4">Table 10</ref> shows results for multiple variants of ResNet <ref type="bibr" target="#b18">[18]</ref>: ResNet-50, ResNet-101, and ResNet-200. As the capacity of the network increases, we observe larger gains from both PixelAT and PyramidAT. PyramidAT performs the best on all evaluation sets.</p><p>For these runs, we follow the training protocol and network details set up in <ref type="bibr" target="#b62">[61]</ref>. We use the proposed split BN and standard ResNet training: 90 epochs, cosine learning rate at 0.1 with linear warmup for 7 epochs, minimal augmentations (left right flip and Inception crop). For network optimization, we use SGD with momentum and for the adversarial steps, we use SGD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. ViT Tiny/16</head><p>ViT Ti/16 has the same overall structure and design as ViT B/16 (the primary model used in our main paper) but is significantly smaller, at 5.8 million parameters (as opposed to the 86 million parameters of B/16). More specifically, Ti/16 has a width of 192 (instead of 768), MLP size of 768 (instead of 3072), and 3 heads (instead of 12). In total, this decrease in parameters and model size leads to a substantial decrease in capacity. We experiment with ViT Ti/16 primarily in order to understand the impact of this decreased capacity on our adversarial training methods. We start with an exploration of the impact of the random augmentation's strength on the overall performance of the model. <ref type="table" target="#tab_5">Table 11</ref> shows the performance of Ti/16 models with different RandAugment parameters (the two parameters are in order the number of transforms applied and the magnitude of the transforms); this table suggests that the network's lower capacity benefits from weaker random augmentation. Specifically, the best RandAugment parameters for the majority of the evaluation datasets is (1,0.8), which is considerably lower than the RandAugment parameters tuned for B/16 <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b15">15)</ref>. In <ref type="table">Table 12</ref> and 13, we pick several of the better performing RandAugment parameters and then show results from adversarial training with steps of 1 and 3, respectively. <ref type="table">Table 12</ref> shows that the performance of adversarial training depends heavily on both the random augmentation and the type of attack. Note, RAm refers to the RandAugment mangitude parameter. As shown by RAm=0.1, pixel attacks can improve performance for in-distribution evaluation datasets when the random augmentation strength is low. However, at higher random augmentation, RAm=0.4 and RAm=0.8, PixelAT leads to the commonly observed trade-off between clean performance and adversarial robustness. In contrast, pyramid tends to improve performance across the board regardless of the starting augmentation (for all RAm of 0.1, 0.4, and 0.8). Interestingly, PixelAT exhibits better robustness properties (out-of-distribution performance) than PyramidAT for Ti/16. We hypothesize that the limited capacity can be "spent" on either in-distribution or out-of-distribution representations and that pyramid tends to bias the network towards in-distribution as opposed to pixel which has a bias towards out-of-distribution. <ref type="table" target="#tab_6">Table 13</ref> shows that the strength of the adversarial attack also matters substantially to the overall performance of the model. Both attacks, pixel and pyramid, with 3 steps tend to degrade the model's performance on in-distribution evaluation datasets. Adversarial training still provides some benefits for out-of-distribution, with pyramid performing the best in terms of robustness. We hypothesize that pyramid outperforms pixel in the steps=3 runs because pyramid is a weaker out-ofdistribution augmentation and pixel at 3 steps has over-regularized the network, leading to decreased performance. Note that pyramid at steps=3 produces the best out-of-distribution performance out of any Ti/16 runs including strong random augmentation and PixelAT at steps=1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of Distribution Robustness Test</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3. MLP-Mixer</head><p>As shown in the main paper, we observe gains across the board for MLP-Mixer with PyramidAT. Here, we show that the gain is robust to a change in the LR schedule and that the gain is, again, affected by the starting augmentation. <ref type="table" target="#tab_1">Table 14</ref> shows baseline and adversarially trained models for two different training schedules of MLP-Mixer, one with the default LR schedule of 10k warm-up steps and then linear decay to an end learning rate (LR) of 1e ? 5 and another with a more aggressive end learning rate of 1e ? 7. We show that this change in LR schedule does not affect the gains from adversarial training.  <ref type="table" target="#tab_2">Table 15</ref> shows that, similar to ViT Ti/16, the gains are improved when the random augmentation is weakened. However, in this case, the gain is not enough to overcome the drop in performance from using the weaker augmentation.  <ref type="table" target="#tab_2">Table 15</ref>. MLP-Mixer ablations with random augmentation magnitude. Weaker random augmentations lead to larger gains from the adversarial training but with these parameters do not lead to better overall performance than the strong random augmentation plus adversarial training. Note that for both the starting point and weaker random augmentation, the gain from pyramid is substantial compared to the gain from pixel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of Distribution Robustness Test</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Additional Ablations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Dropout</head><p>One of the key findings of this paper is the importance of "matched" Dropout <ref type="bibr" target="#b50">[50]</ref> and stochastic depth <ref type="bibr" target="#b23">[23]</ref>. Here we describe numerous ablations on these Dropout terms and list several detailed findings including:</p><p>? Matching the Dropout and stochastic depth matters significantly for balanced clean performance and robustness.</p><p>? Running without Dropout in the adversarial training branch can improve robustness even more.</p><p>? Dropout matters more than Stochastic Depth Note that in the tables below, we use the term "dropparams" to refer to a tuple of the Dropout probability and stochastic depth probability. Clean dropparams (abbreviated as c dp) refer to the dropparams used for the clean training branch; adversarial dropparams (abbreviated as a dp) refer to the dropparams used for the adversarial training branch; and matched dropparams (abbreviated as m dp) refer to dropparams used for both clean and adversarial branches. So c dp = (10, 0) means that the clean training branch had a 10% probability of Dropout but a 0% probability of stochastic depth. <ref type="table">Table 16</ref> explores different possible values for adversarial dropparams. In general, lower values of Dropout and stochastic depth in the adversarial branch improve out-of-distribution performance while hurting in-distribution performance; however, the opposite is not true: higher levels of Dropout and stochastic depth in the adversarial branch do not improve in-distribution performance. In-distribution performance seems to peak when the params for the adversarial and clean branches match.  <ref type="table">Table 16</ref>. Ablation on the values of Dropout and stochastic depth for adversarial training branch. All c dp are kept constant at (10, 10) in the adversarial section.  <ref type="table">Table 18</ref> explores if one of these parameters is more important than the others. To do so, we set clean dropparams to (10, 10) for the entire table (besides the included baselines) and only vary the adversarial dropparams. For both PixelAT and PyramidAT, the Dropout parameter seems to be more important for clean, in-distribution performance. Without Dropout, the top-1 of ImageNet drops 0.41 for PixelAT and 0.92 for PyramidAT. However, no Dropout does give a substantial boost to out-of-distribution performance, with Rendition gains of 11.59 for PixelAT and 15.68 for PyramidAT and Sketch gains of 7.49 for PixelAT and 11.96 for PyramidAT. Without stochastic depth, the adversarially trained models seem to perform roughly as well as with stochastic depth, exhibitly marginally more clean accuracy for PyramidAT than the model with both Dropout and stochastic depth. Our main takeaway is that Dropout seems to be the primary determinant in whether the gains are balanced between in-distribution and out-of-distribution or primarily focused on out-of-distribution. In fact, no Dropout PyramidAT performs so well on out-of-distribution that it sets new state-of-the-art numbers for Rendition and Sketch.  <ref type="table">Table 18</ref>. Ablation on the values of Dropout and stochastic depth for unmatched attacks. For the adversarial techniques, clean dropparams will be the same as RegVit at <ref type="bibr" target="#b10">(10,</ref><ref type="bibr" target="#b10">10)</ref>. For the adversarial training rows, either Dropout or stochastic depth will be 0 and the other will be the base value. This table explores whether one of these parameters is more important than the other. For both PixelAT and PyramidAT, Dropout appears to be more important in determining the balance between in-distribution and out-of-distribution performance. PyramidAT no Dropout is SOTA for Rendition and Sketch. <ref type="table">Table 19</ref> explores parameter settings where the Dropout and stochastic depth are not equal. In general, there does not seem to be a consistent trend or recognizable pattern for the overall performance, though some patterns exist for specific attacks and evaluation datasets. For example, increasing stochastic depth probability for pixel attacks tend to improve Real, ImageNet-C, and ObjectNet performance.  <ref type="table">Table 19</ref>. Ablation on settings where the Dropout parameter and stochastic depth parameter are not equal for adversarial training branch. All c dp are kept constant at (10, 10) in the adversarial section. <ref type="table">Table 20</ref> explores the effects of adversarial training with different dropparams without Dropout or stochastic depth in the main branch. In general, the lack of Dropout and stochastic depth in the clean branch has a substantial negative effect on the performance of the model and all of the resulting models under-perform their counterparts with non-zero clean dropparams. In this setting, adversarial training does provide substantial improvements for both in-distribution (+5.18 for clean using PyramidAT) and out-of-distribution performances (+12.29 for Rendition using PyramidAT and +11.68 for Sketch using PyramidAT), but not enough to offset the poor starting performance of the baseline model.  <ref type="table">Table 20</ref>. Ablation on the values of Dropout and stochastic depth for adversarial training branch for a clean branch with no Dropout or stochastic depth; specifically, all c dp are kept constant at (0, 0). The loss of Dropout and stochastic depth causes poor performance across the board.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of Distribution Robustness Test</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of Distribution Robustness Test</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of Distribution Robustness Test</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of Distribution Robustness Test</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Pyramid Structure</head><p>In the main paper, <ref type="table">Table 8</ref> presented an abridged version (with only a subset of the evaluation datasets) of an ablation on the structure of the pyramid used in the pyramid adversarial training. We present the full version (complete with all the evaluation datasets) of this ablation in <ref type="table" target="#tab_14">Table 21</ref>. This table remains consistent with the description and explanation in the main table: adding more layers to the pyramid tends to improve performance. In fact, <ref type="table" target="#tab_14">Table 21</ref> shows the full extent of the trade-off between the 3rd and 4th levels of the pyramid. Specifically, the 4th level seems to lead to a slight improvement in out-of-distribution performance and a slight decline in in-distribution performance. Note that 2-level Pyramid is simply the combination of Pixel and Patch.  In <ref type="table" target="#tab_0">Table 23</ref>, we explore different magnitudes for the patch level. We note that some of the gains from 2-level are from the higher magnitude for the coarse level.  <ref type="table" target="#tab_0">Table 23</ref>. Pyramid structure ablations where m is the multiplicative term of the perturbation. Shows that the combination of patch and pixel is better than only patch, even when patch is tested at different magnitudes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of Distribution Robustness Test</head><p>We additionally include <ref type="table" target="#tab_1">Table 24</ref> which shows a random subset of pyramid structures tested. The best pyramids tend to be structured based on the patches of the ViT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scale factor</head><p>Strengths ImageNet <ref type="bibr" target="#b13">[13]</ref> Real <ref type="bibr" target="#b13">[13]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3. More epochs for baseline</head><p>We tested the effect of additional epochs for the baseline training. We found that going from 300 epochs to 500 (with the learning rate being adjusted accordingly) did not provide any benefits to the network's performance. In fact, <ref type="table" target="#tab_2">Table 25</ref> shows that the longer run performs worse in most evaluation datasets than the shorter run. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4. Number of Attack Steps</head><p>We perform an ablation on the number of steps in the adversarial attack. AdvProp <ref type="bibr" target="#b62">[61]</ref> uses 5 for their main paper; we also adopt this parameter as a reasonable balance between performance and train time (each additional step in the attack requires a forward and backward pass of the model and increases the train time accordingly). <ref type="table">Table 26</ref> shows that higher number of steps tends to lead to better performance for both pixel and pyramid.  <ref type="table">Table 26</ref>. Ablation on the number of steps in the adversarial attack. For both PixelAT and PyramidAT, larger number of steps tend to give higher performance. Note that increasing the number of steps also increases the train time. We chose 5 for both PixelAT and PyramidAT as a reasonable tradeoff between performance and train time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of Distribution Robustness Test</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5. Magnitude</head><p>We also perform ablations on the magnitude of perturbations (specifically L2 of the difference between adversarial image and the original image) and show that there exists an inverted U curve for both PixelAT and PyramidAT where one perturbation setting tends to produce the best model for most evaluation datasets.</p><p>For PixelAT, we change the perturbation magnitude by editing the learning rate (lr) and the epsilon parameter (?) which is used for the clipping function. Since we use the SGD optimizer, a larger learning rate and epsilon will naturally lead to larger perturbations. <ref type="table">Table 27</ref> shows the results of these experiments, which suggests that pixel attacks can very quickly become too large to help the overall network performance.</p><p>For PyramidAT, we adjust the perturbation size by editing the magnitude of the multiplicative terms. In <ref type="table">Table 28</ref>, we perform an exhaustive sweep of these terms starting with an initial list of <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b0">1]</ref> and multiplying the list by a constant. This table shows that there also exists an inverted U curve where the performance will degrade if the perturbation magnitude is either too small or too big.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Additional Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1. Positional embedding</head><p>In <ref type="table">Table 29</ref>, we explore training on a ViT model without the positional embedding in order to understand the effects of the PixelAT and PyramidAT. We observe that without the positional embedding, PixelAT and PyramidAT tend to perform  <ref type="table">Table 29</ref>. Analysis of the effect of adversarial training on a ViT without positional embedding. We observe that without the positional embedding, PixelAT and PyramidAT tend to perform similarly for many of the evaluation datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. Optimizing each level individually</head><p>In the pyramid attack, the different multiplicative magnitudes for each level mean that each level's parameter takes different sized steps; for example, with the default settings, a change of 1 in the patch parameter leads to a change of 10 on the final image, whereas a change of 1 in the pixel parameter leads to a change of 1. Here, we attempt to understand whether the gradients for the different levels of the pyramid can be informative in the presence of each other; specifically, if the patch level makes a step of 10 in one direction, will this invalidate the gradient in the pixel level which only makes a step of 1. To do this, we experiment with running each level of the pyramid separately, going from coarse to fine: for a given k, we run k steps of only the coarsest level, k steps of only the next coarsest level, etc. In this experiment, we try to keep the amount of training time roughly equal and select k so that the sum of k on each level is roughly equal to the steps taken in the pyramid method in the main paper <ref type="bibr" target="#b4">(5)</ref>. <ref type="table" target="#tab_21">Table 30</ref> shows the results from this experiment and suggests that the gradients from each individual level are still useful when combined and that separating this optimization does not in fact lead to performance improvements; note that k = 2 leads to more overall optimization steps (6 total steps) than the main technique (5 total steps). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of Distribution Robustness Test</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3. Evaluation of white-box attacks</head><p>We evaluate the performance of the B/16 baseline, PixelAT, and PyramidAT models against pixel and pyramid PGD attacks. The results are given in table 31. Both adversarially trained models give the best performance when attacked in the setting in which they were trained. PyramidAT provides comparably more protection against pixel attacks (48.8% Top-1) than PixelAT against pyramid attacks (43.0% Top-1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Pixel PGD Pyramid PGD </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Additional Visualizations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1. Pixel attacks</head><p>In <ref type="figure">Figure 9</ref>, we include 4 additional visualizations of pixel attacks against the baseline and PixelAT models. Some structure is visible in the PixelAT model. Note that for pixel attacks, we would expect more structure to appear in the PixelAT model than the PyramidAT model since the attack is in-distribution for the PixelAT model but out-of-distribution for the PyramidAT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2. Pyramid attacks</head><p>In <ref type="figure">Figure 10</ref>, we include 4 additional visualizations of pyramid attacks against the PyramidAT models. Note that in the finest level, more structure is visible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3. Attention</head><p>We include the average attentions of baseline, PixelAT, and PyramidAT on the following datasets: ImageNet <ref type="figure">(Figure 11</ref>), ImageNet-A <ref type="figure">(Figure 12</ref>), ImageNet-ReaL <ref type="figure">(Figure 13</ref>), ImageNet-Rendition ( <ref type="figure">Figure 14</ref>), ObjectNet <ref type="figure">(Figure 15</ref>), and Stylized ImageNet <ref type="figure" target="#fig_2">(Figure 16</ref>). The trend, as stated in the main paper, (PixelAT tightly focusing on the center and PyramidAT taking a more global perspective) stays consistent across the various evaluation datasets.</p><p>We also include 32 examples of the attention for individual images sampled from the following datasets: ImageNet <ref type="figure" target="#fig_3">(Figure 17</ref>), ImageNet-A <ref type="figure" target="#fig_4">(Figure 18</ref>), ImageNet-ReaL <ref type="figure">(Figure 19</ref>), ImageNet-Rendition ( <ref type="figure">Figure 20)</ref>, ObjectNet ( <ref type="figure">Figure 21</ref>), and StylizedImageNet <ref type="figure">(Figure 22</ref>). The trend, as stated in the main paper, remains consistent through most of the examples. Baseline tends to be random and highlight both the object and background (particularly corners); PixelAT tries to aggressively crop to the object in the image, often cutting off parts of the object; and PyramidAT crops more closely than baseline but less aggressively than PixelAT. PyramidAT tends to take a more global perspective on the image and attends to both the object but also potentially relevant pieces of the background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline</head><p>PixelAT PyramidAT <ref type="figure">Figure 9</ref>. Visualizations of pixel attacks on different pre-trainings: baseline, PixelAT, and PyramidAT. Note that PixelAT models should have better defense against pixel attacks than PyramidAT models since the attack is in-distribution to the train data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Optimizers</head><p>We observe different behavior from adversarial training depending on the optimizer used in generating the attacks; note, discussion of optimizers was omitted from the main paper due to concerns regarding space and complexity. Throughout the main paper, we use SGD, the standard optimizer in the adversarial attack and training community. However after testing multiple optimizers (Adam <ref type="bibr" target="#b26">[26]</ref>, AdaBelief <ref type="bibr" target="#b67">[66]</ref>), we observe significantly different behavior from AdaBelief. Specifically, as shown in <ref type="table">Table 32</ref>, AdaBelief provides a significant improvement to PixelAT (0.71 to ImageNet, 1.72 in ImageNet-R) and AdaBelief. Shown in <ref type="figure">Figure 24</ref>, this visual difference is more apparent when looking at pixel attacks using AdaBelief on these four Baseline Pixel Pyramid <ref type="figure" target="#fig_2">Figure 16</ref>. Visualizations of the average attention for different pre-trainings. Examples on dataset StylizedImageNet.  <ref type="table">Table 32</ref>. SGD vs AdaBelief different pre-trainings. In the pixel attacks using AdaBelief on AdaBelief pixel-trained model, contours and edges are clearly visible and the edits to the texture are smoother and more consistent. Even beyond classification, this may provide a way to do semi-supervised segmentation (with only the class label). Currently, AdaBelief does not provide such visible changes or improvements to pyramid. We leave this adaptation to future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of Distribution Robustness Test</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 5 Figure 3 .</head><label>53</label><figDesc>demonstrates the difference in representation between the baseline, PixelAT, and PyramidAT models. The pixel attacks on the baseline and PixelAT have a small amount of structure but appear to consist of mostly texturelevel noise. In contrast, the pixel level of the PyramidAT shows structures from the original image: the legs and backOriginal BaselinePixelAT PyramidAT Visualizations of the attention for different models. Pix-elAT focuses aggressively on the perceived object. However, if the object is not identified correctly, this focus can be detrimental, as shown above where large parts of the object are discarded. PyramidAT uses a more global perspective and considers context.BaselinePixelAT PyramidAT</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .Figure 5 .</head><label>45</label><figDesc>Averaged attentions on ImageNet-A: PyramidAT models attend to more of the image than the baseline or PixelAT.ImageBaseline PixelAT PyramidAT Visualizations of attacks: a pixel attack on a baseline ViT; a pixel attack on a PixelAT ViT; and the pixel level of a pyramid attack on a PyramidAT ViT. The pixel attack on the baseline exhibits low amounts of structure and can perturb the label with small changes. The pixel level on the PyramidAT model makes larger changes to the structure; this suggests that the representation is robust to semi-random noise and focuses primarily on structures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 .</head><label>6</label><figDesc>Heatmaps of fourier spectrum for various perturbations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 .</head><label>7</label><figDesc>Model performance when inputs are corrupted with lowpass/high-pass filtered noise. The L2 norm of the filtered noise is held constant as the bandwidth is increased.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 .</head><label>8</label><figDesc>i m p o r t j a x i m p o r t j a x . numpy a s j n p H=224 , l r = 1 / 2 5 5 , M= [ 2 0 , 1 0 , 1 ] , S = [ 3 2 , 1 6 , 1 ] , BOUNDS= [ 0 , 1 ] , n s t e p s =5 d e f g e t a t t a c k e d i m a g e ( model , l o s s f n , image ) : d e f g e t p e r t u r b e d i m a g e ( d e l t a ) : r e t u r n image + sum ( M[ i ] * j a x . image . r e s i z e ( d e l t a [ i ] , (H, H, 3 ) , ' n e a r e s t ' ) f o r i i n d e l t a ) d e f g e t p e r t u r b e d l o s s ( d e l t a ) : r e t u r n l o s s f n ( model ( g e t p e r t u r b e d i m a g e ( d e l t a ) ) ) d e l t a = { i : j n p . z e r o s ( ( H / s , H / s , 3 ) ) f o r ( i , s ) i n e n u m e r a t e ( S ) } f o r i n r a n g e ( n s t e p s ) : d e l t a g r a d = j a x . g r a d ( g e t p e r t u r b e d l o s s ) ( d e l t a ) d e l t a = { i : d e l t a [ i ] + l r * j n p . s i g n ( d e l t a g r a d [ i ] ) f o r i i n d e l t a } p e r t u r b e d i m a g e = g e t p e r t u r b e d i m a g e ( d e l t a ) r e t u r n j n p . c l i p ( p e r t u r b e d i m a g e , BOUNDS[ 0 ] , BOUNDS [ 1 ] ) Implementation of our technique in JAX. B. Discussing Backbones B.1. ResNets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 10 .Figure 11 .Figure 12 .Figure 13 .Figure 14 .Figure 15 .</head><label>101112131415</label><figDesc>Visualizations of pyramid attacks on pyramid-trained model. Baseline Pixel Pyramid Visualizations of the average attention for different pre-trainings. Examples on dataset ImageNet. a marginal improvement to PyramidAT (0.08 to ImageNet, 0.98 in ImageNet-R). As shown in Figure 23, we also observe significant visual difference in the pixel attacks on the pixel-trained model with Baseline PixelAT PyramidAT Visualizations of the average attention for different pre-trainings. Examples on dataset ImageNet-A. Baseline PixelAT PyramidAT Visualizations of the average attention for different pre-trainings. Examples on dataset ImageNet2012-ReaL. Baseline PixelAT PyramidAT Visualizations of the average attention for different pre-trainings. Examples on dataset ImageNet-Rendition. Baseline PixelAT PyramidAT Visualizations of the average attention for different pre-trainings. Examples on dataset ObjectNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 17 .Figure 18 .Figure 19 .Figure 20 .Figure 21 .Figure 22 .Figure 23 .Figure 24 .</head><label>1718192021222324</label><figDesc>Visualizations of the attention for different pre-trainings. Examples on dataset ImageNet. Visualizations of the attention for different pre-trainings. Examples on dataset ImageNet-A. Visualizations of the attention for different pre-trainings. Examples on dataset ImageNet2012-ReaL. Visualizations of the attention for different pre-trainings. Examples on dataset ImageNet-Rendition. Visualizations of the attention for different pre-trainings. Examples on dataset ObjectNet. Visualizations of the attention for different pre-trainings. Examples on dataset StylizedImageNet. Visualizations of pixel attacks using SGD on different pre-trainings: baseline, pixel, pyramid, and pixel Adabelief. Visualizations of pixel attacks using AdaBelief on different pre-trainings: baseline, PixelAT SGD, PyramidAT SGD, and PixelAT Adabelief.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .Table 3 .</head><label>23</label><figDesc></figDesc><table><row><cell>shows results on ImageNet-1K and</cell></row><row><cell>robustness datasets for ViT-B/16 models without adversar-</cell></row></table><note>images. The second set of rows shows performance by fine-tuning on 384 ? 384 images.Comparison to state of the art for mean Corruption Error (mCE) on ImageNet-C. Extra data is IM-21k.Comparison to state of the art for Top-1 on ImageNet-R. Extra data is IM-21k.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table><row><cell>Method</cell><cell cols="2">Extra Data IM-Sketch</cell></row><row><cell>ConViT-B [11]</cell><cell>?</cell><cell>35.70</cell></row><row><cell>Swin-B [32]</cell><cell>?</cell><cell>32.40</cell></row><row><cell>Robust ViT [38]</cell><cell>?</cell><cell>36.00</cell></row><row><cell>Discrete ViT [37]</cell><cell>?</cell><cell>39.10</cell></row><row><cell>Ours (ViT-B/16 + PyramidAT)</cell><cell>?</cell><cell>41.04</cell></row><row><cell>Discrete ViT [37]</cell><cell>?</cell><cell>44.72</cell></row><row><cell>Ours (ViT-B/16 + PyramidAT)</cell><cell>?</cell><cell>46.03</cell></row></table><note>Comparison to state of the art for Top-1 on ImageNet- Sketch. Extra data is IM-21k.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>table 5</head><label>5</label><figDesc></figDesc><table><row><cell>Out of Distribution Robustness Test</cell></row></table><note>, we show that our technique maintains gains over the baseline Reg-ViT and pixel-wise attack on the larger dataset IM-21K. Following [51], we</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 .Table 7 .Table 8 .Table 9 .</head><label>6789</label><figDesc>Pyramid adversarial training improves the performance of ResNet, MLP-Mixer, and Discrete ViT. On MLPMixer, pixel attacks degrade clean performance but improve robustness, similar to the traditionally observed effect of adversarial training. Matched Dropout leads to better performance on in-distribution datasets than AT without Dropout. Pyramid 81.65 22.79 45.27 47.00 36.71 3-level Pyramid 81.71 22.99 44.99 47.66 36.77 4-level Pyramid 81.66 23.21 45.29 47.68 37.41 Pyramid structure ablation. This shows the effect of the layers of the pyramid. Adding coarser layers with larger magnitudes typically improves performance. Patch attack is a 1-level pyramid with shared parameters across a patch of size 16 ? 16. Results on Ti/16 with lower random augmentation. RAm is the RandAugment [10] magnitude -larger means stronger augmentation; both have RandAugment number of transforms = 1. The strength of the random augmentation affects whether PixelAT improves clean accuracy; in contrast, PyramidAT provides consistent gains over the baseline.</figDesc><table><row><cell>Out of Distribution Robustness Test</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 10 .</head><label>10</label><figDesc>For all variants of ResNet, PyramidAT leads to improvements. Note that this is with the standard training of ResNet.</figDesc><table><row><cell>Out of Distribution Robustness Test</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 11</head><label>11</label><figDesc></figDesc><table><row><cell>Method</cell><cell>ImageNet</cell><cell>Real</cell><cell>A</cell><cell>C?</cell><cell>ObjectNet</cell><cell>V2</cell><cell cols="2">Rendition Sketch Stylized</cell></row><row><cell>RA=(2,10)</cell><cell>61.07</cell><cell cols="3">68.77 3.95 85.84</cell><cell>12.88</cell><cell>48.50</cell><cell>21.95</cell><cell>11.21</cell><cell>4.84</cell></row><row><cell>RA=(2,5)</cell><cell>64.62</cell><cell cols="3">72.57 4.59 80.79</cell><cell>15.44</cell><cell>52.37</cell><cell>25.68</cell><cell>14.48</cell><cell>8.36</cell></row><row><cell>RA=(1,10)</cell><cell>63.64</cell><cell cols="3">71.26 4.64 83.04</cell><cell>14.53</cell><cell>51.37</cell><cell>23.67</cell><cell>13.14</cell><cell>7.27</cell></row><row><cell>RA=(1,5)</cell><cell>64.96</cell><cell cols="3">72.54 4.80 81.32</cell><cell>14.94</cell><cell>52.05</cell><cell>25.03</cell><cell>13.69</cell><cell>8.98</cell></row><row><cell>RA=(1,3)</cell><cell>64.88</cell><cell cols="3">72.66 4.80 79.04</cell><cell>15.61</cell><cell>52.59</cell><cell>25.43</cell><cell>13.54</cell><cell>8.13</cell></row><row><cell>RA=(1,0.8)</cell><cell>65.33</cell><cell cols="3">73.19 4.79 77.08</cell><cell>16.16</cell><cell>53.03</cell><cell>25.98</cell><cell>14.15</cell><cell>8.98</cell></row><row><cell>RA=(1,0.4)</cell><cell>64.27</cell><cell cols="3">72.17 4.69 78.10</cell><cell>15.46</cell><cell>52.18</cell><cell>24.99</cell><cell>13.47</cell><cell>8.59</cell></row><row><cell>RA=(1,0.1)</cell><cell>63.58</cell><cell cols="3">71.41 4.80 79.23</cell><cell>15.39</cell><cell>51.43</cell><cell>23.66</cell><cell>12.54</cell><cell>8.36</cell></row></table><note>. ViT Ti/16 baseline training with different random augmentations. In this table, RA denotes the two RandAugment parameters: number of applied transforms, and mangitude of transforms. Note that weaker augmentation tends to perform better.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 13</head><label>13</label><figDesc></figDesc><table><row><cell>Out of Distribution Robustness Test</cell></row></table><note>. ViT Ti/16 adversarial training experiments with steps=3. RAm gives the RandAugment magnitude parameter; all experiments have RandAugment number of transforms equal to 1. All techniques degrade from the baseline suggesting that 3 adversarial steps produces augmentation that is too strong for Ti's capacity.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 14</head><label>14</label><figDesc></figDesc><table><row><cell>Method</cell><cell>ImageNet</cell><cell>Real</cell><cell>A</cell><cell>C?</cell><cell>ObjectNet</cell><cell>V2</cell><cell cols="3">Rendition Sketch Stylized</cell></row><row><cell>MLP-Mixer [54] end LR=1e-5 (default)</cell><cell>78.27</cell><cell cols="3">83.64 10.84 58.50</cell><cell>25.90</cell><cell>64.97</cell><cell>38.51</cell><cell>29.00</cell><cell>10.08</cell></row><row><cell>+PixelAT</cell><cell>77.17</cell><cell>82.99</cell><cell>9.93</cell><cell>57.68</cell><cell>24.75</cell><cell>64.03</cell><cell>44.43</cell><cell>33.68</cell><cell>15.31</cell></row><row><cell>+PyramidAT</cell><cell>79.29</cell><cell cols="3">84.78 12.97 52.88</cell><cell>28.60</cell><cell>66.56</cell><cell>45.34</cell><cell>34.79</cell><cell>14.77</cell></row><row><cell>MLP-Mixer [54] end LR=1e-7</cell><cell>75.92</cell><cell>81.28</cell><cell>9.45</cell><cell>64.29</cell><cell>22.13</cell><cell>62.17</cell><cell>33.70</cell><cell>25.15</cell><cell>7.27</cell></row><row><cell>+PixelAT</cell><cell>74.96</cell><cell>80.81</cell><cell>7.81</cell><cell>61.85</cell><cell>20.87</cell><cell>60.94</cell><cell>39.82</cell><cell>28.59</cell><cell>12.27</cell></row><row><cell>+PyramidAT</cell><cell>77.98</cell><cell cols="3">83.60 11.17 56.19</cell><cell>25.59</cell><cell>64.92</cell><cell>41.65</cell><cell>31.99</cell><cell>12.66</cell></row></table><note>. MLP-Mixer ablations with different training. The pyramid gains are preserved even with different training schedules.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 17 Table 17 .</head><label>1717</label><figDesc>explores different possible values for matched dropparams. In general, the dropparams determined by RegViT<ref type="bibr" target="#b51">[51]</ref> seem to be roughly optimal for both the baselines and the adversarially trained models, with some variation for some datasets. Ablation on the values of Dropout and stochatic depth for matched attacks.</figDesc><table><row><cell>Out of Distribution Robustness Test</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 21 .</head><label>21</label><figDesc>Pyramid structure ablations. This shows the effect of the number of layers of the pyramid. Adding coarser layers with larger magnitudes generally improves performance. Using the the scale notation established in 3.2 Pyramid Adversarial Training, the details of these layers are as follows inTable 22.</figDesc><table><row><cell>Out of Distribution Robustness Test</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 22 .</head><label>22</label><figDesc>Pyramid details.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 25 .</head><label>25</label><figDesc>Exploration of the number of steps for the baseline.</figDesc><table><row><cell>Out of Distribution Robustness Test</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 27 .Table 28 .</head><label>2728</label><figDesc>Ablation on the magnitude of PixelAT. PixelAT tends to degrade with higher lr and ?. Ablation on the magnitude of the pyramid adversarial training.similarly; in fact, the gap between PixelAT and PyramidAT for clean ImageNet decreases from 1.29 with the positional embedding to 0.17 without the positional embedding. This suggests that much of the improvements for in-distribution performance come from improved training of the positional embedding. However, even without the positional embedding, we observe improvements in the out-of-distribution datasets; e.g. going from pixel to pyramid results in a gain of 2.27 on Rendition and 2.37 on Sketch with the positional embedding and slightly smaller gains of 1.27 and 1.43 without the positional embedding. This suggests that PyramidAT is still improving the learned features used for out-of-distribution performance.</figDesc><table><row><cell>Out of Distribution Robustness Test</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 30 .</head><label>30</label><figDesc>Ablation on CoarseThenFine. The separated gradients do not seem strictly better than simply running all levels at once.</figDesc><table><row><cell>Method</cell><cell>ImageNet</cell><cell>Real</cell><cell>A</cell><cell>C?</cell><cell>ObjectNet</cell><cell>V2</cell><cell cols="2">Rendition Sketch Stylized</cell></row><row><cell>Pyramid Separate k = 1 (3 total)</cell><cell>81.17</cell><cell cols="3">86.06 19.41 49.10</cell><cell>30.35</cell><cell>69.27</cell><cell>42.94</cell><cell>33.41</cell><cell>15.55</cell></row><row><cell>Pyramid Separate k = 2 (6 total)</cell><cell>81.36</cell><cell cols="3">86.36 22.31 47.73</cell><cell>32.12</cell><cell>69.92</cell><cell>46.13</cell><cell>35.66</cell><cell>15.31</cell></row><row><cell>Pyramid (5 steps total)</cell><cell>81.71</cell><cell cols="3">86.82 22.99 44.99</cell><cell>32.92</cell><cell>70.82</cell><cell>47.66</cell><cell>36.77</cell><cell>19.14</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anish</forename><surname>Athalye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="274" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">BEit: BERT pre-training of image transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangbo</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songhao</forename><surname>Piao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<idno>2022. 1</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Barbu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Alverio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gutfreund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Xiaohua Zhai, and Aaron van den Oord. Are we done with imagenet?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><forename type="middle">J</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<idno>2020. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<imprint>
			<publisher>Peter Hawkins</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Jax: composable transformations of python+numpy programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">James</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dougal</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Necula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Skye</forename><surname>Wanderman-Milne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiao</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards evaluating the robustness of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE symposium on security and privacy (SP)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="39" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unlabeled data improves adversarial robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Carmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditi</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy S</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Robust neural machine translation with doubly adversarial inputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Advaug: Robust adversarial augmentation for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Ekin Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Convit: Improving vision transformers with soft convolutional inductive biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Stephane D&amp;apos;ascoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><forename type="middle">S</forename><surname>Leavitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giulio</forename><surname>Morcos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levent</forename><surname>Biroli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sagun</surname></persName>
		</author>
		<idno>PMLR, 2021. 5</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page" from="2286" to="2296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Scenic: A jax library for computer vision research and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Gritsenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<idno>2021. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno>abs/1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note>ICLR), 2021. 1, 2, 4, 5</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Felix A Wichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brendel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The many faces of robustness: A critical analysis of out-of-distribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Dorundo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samyak</forename><surname>Parajuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Augmix: A simple data processing method to improve robustness and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lakshminarayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
	<note>Natural adversarial examples. 2021. 1, 2, 4</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep networks with stochastic depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sedra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Quality-agnostic image recognition via invertible decoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Insoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungju</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji-Won</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seong-Jin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae-Joon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="12257" to="12266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
	<note>Yoshua Bengio and Yann LeCun</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Adversarial machine learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Adversarial machine learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Building machines that learn and think like people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brenden M Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tomer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gershman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">40</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Enhancing the reliability of out-of-distribution image detection in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR). OpenReview.net</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021-10" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Improving robustness without sacrificing accuracy with patch gaussian augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael Gontijo</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin Dogus</forename><surname>Cubuk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">SGDR: stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR). OpenReview.net</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR). OpenReview.net</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">On the robustness of vision transformers to adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaleel</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rigel</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marten</forename><surname>Van Dijk</surname></persName>
		</author>
		<idno>Oc- tober 2021. 1</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<biblScope unit="page" from="7838" to="7847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Discrete representations strengthen vision transformer robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengzhi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irfan</forename><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Towards robust vision transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gege</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuefeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjie</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaokai</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xue</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>volume abs/2105.07926, 2021. 1, 5</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Shin-Ichi Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1979" to="1993" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Robustness via curvature regularization, and vice versa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alhussein</forename><surname>Seyed-Mohsen Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9078" to="9086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Intriguing properties of vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kanchana</forename><surname>Muhammad Muzammal Naseer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ranasinghe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Salman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munawar</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Distillation as a defense to adversarial perturbations against deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananthram</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE symposium on security and privacy (SP)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="582" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Adversarial robustness through local linearization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongli</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Gowal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishnamurthy</forename><surname>Dvijotham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alhussein</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soham</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Stanforth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Understanding and mitigating the tradeoff between robustness and accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditi</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang</forename><forename type="middle">Michael</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanny</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Vision transformers for dense prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren?</forename><surname>Ranftl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Bochkovskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="12179" to="12188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Do imagenet classifiers generalize to imagenet?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<idno>PMLR, 2019. 4</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page" from="5389" to="5400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="211" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">On the adversarial robustness of visual transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rulin</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouxing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pin-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>volume abs/2103.15670, 2021. 1</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">How to train your vit? data, augmentation, and regularization in vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Wightman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note>volume abs/2106.10270, 2021. 1, 2, 3, 4, 5</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Ilya O Tolstikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yung</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Mlp-mixer: An all-mlp architecture for vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Training data-efficient image transformers &amp; distillation through attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Robustness may be at odds with accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Statistical decision functions which minimize the maximum risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Wald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1945" />
			<publisher>JSTOR</publisher>
			<biblScope unit="page" from="265" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning robust global representations by penalizing local predictive power</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songwei</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Augmax: Adversarial composition of random augmentations for robust training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaowei</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Kossaifi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Spatially transformed adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaowei</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Warren</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Adversarial examples improve image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cihang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A fourier perspective on model robustness in computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><forename type="middle">Gontijo</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Ekin Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gilmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6023" to="6032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Theoretically principled trade-off between robustness and accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaodong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiantao</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<idno>PMLR, 09-15</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>Kamalika Chaudhuri and Ruslan Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="7472" to="7482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Adabelief optimizer: Adapting stepsizes by the belief in observed gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juntang</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommy</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicha</forename><surname>Tatikonda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xenophon</forename><surname>Dvornek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Papademetris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duncan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
