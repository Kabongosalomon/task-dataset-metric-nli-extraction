<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">KaggleDBQA: Realistic Evaluation of Text-to-SQL Parsers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Hsuan</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington ? Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
							<email>polozov@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington ? Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington ? Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">KaggleDBQA: Realistic Evaluation of Text-to-SQL Parsers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The goal of database question answering is to enable natural language querying of real-life relational databases in diverse application domains. Recently, large-scale datasets such as Spider and WikiSQL facilitated novel modeling techniques for text-to-SQL parsing, improving zero-shot generalization to unseen databases. In this work, we examine the challenges that still prevent these techniques from practical deployment. First, we present KaggleDBQA, a new cross-domain evaluation dataset of real Web databases, with domain-specific data types, original formatting, and unrestricted questions. Second, we re-examine the choice of evaluation tasks for text-to-SQL parsers as applied in real-life settings. Finally, we augment our in-domain evaluation task with database documentation, a naturally occurring source of implicit domain knowledge. We show that KaggleDBQA presents a challenge to state-ofthe-art zero-shot parsers but a more realistic evaluation setting and creative use of associated database documentation boosts their accuracy by over 13.2%, doubling their performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Text-to-SQL parsing is a form of database question answering (DBQA) that answers a user's natural-language (NL) question by converting it into a SQL query over a given relational database. It can facilitate NL-based interfaces for arbitrary enduser applications, thereby removing the need for domain-specific UX or learning query languages. As such, DBQA attracted significant attention in academia and industry, with development of supervised datasets <ref type="bibr" target="#b22">(Yu et al., 2018)</ref>, large-scale models <ref type="bibr" target="#b17">(Wang et al., 2020b;</ref><ref type="bibr" target="#b24">Zeng et al., 2020)</ref>, and novel modeling techniques <ref type="bibr" target="#b1">Deng et al., 2020)</ref>.</p><p>The key challenge of text-to-SQL parsing is zeroshot generalization to unseen domains, i.e. to new database schemas and differently distributed NL questions. Large-scale annotated datasets like Spider <ref type="bibr" target="#b22">(Yu et al., 2018)</ref> and WikiSQL <ref type="bibr" target="#b28">(Zhong et al., 2017)</ref> evaluate cross-domain generalization of textto-SQL parsers by restricting overlap between train and test domains. Such challenging benchmarks facilitate rapid progress in DBQA. State-of-the-art (SOTA) accuracy on Spider rose from 12.4% to 70.5% in just two years since its release, demonstrating the value of well-chosen evaluation settings.</p><p>Despite impressive progress in DBQA, deployment of SOTA parsers is still challenging. They often lack robustness necessary to deploy on reallife application domains. While many challenges underlie the gap between SOTA DBQA and its reallife deployment, we identify three specific discrepancies.</p><p>First, Spider and WikiSQL datasets normalize and preprocess database schemas or rely on academic example databases that originate with humanreadable schemas <ref type="bibr" target="#b13">(Suhr et al., 2020)</ref>. In contrast, industrial databases feature abbreviated and obscure naming of table, columns, and data values, often accrued from legacy development or migrations. <ref type="figure">Figure 1</ref> shows a characteristic example. After deployment, text-to-SQL parsers struggle with schema linking to domain-specific entities because they do not match the distribution seen in their pre-training (e.g. BERT) or supervised training (e.g. Spider).</p><p>Second, the NL questions of Spider and Wik-iSQL have high column mention percentage <ref type="bibr" target="#b1">(Deng et al., 2020)</ref>, which makes their language unrealistic. This can be an artifact of rule-generated NL templates (as in WikiSQL) or annotation UIs that prime the annotators toward the schema (as in Spider). Either way, real-world deployment of a text-to-SQL parser optimized on Spider faces a distribution shift in NL, which reduces its realistic performance.</p><p>Finally, the standard evaluation setting of crossdomain text-to-SQL parsing assumes no in-domain arXiv:2106.11455v1 [cs.CL] 22 Jun 2021 Database: Student Math Score Federal revenue through the state -Child Nutrition A . We present a technique to augment SOTA parsers with column and value descriptions, which significantly improves their out-of-domain accuracy (Section 4). <ref type="figure">Figure 1</ref> shows a representative example from the dataset. Aligning "federal revenue" and t_fed_rev is hard without domain knowledge.</p><p>In addition to more realistic data and questions, we argue that evaluation of real-world text-to-SQL performance should assume few-shot access to ?10 in-domain question-SQL examples rather than measuring zero-shot performance. In practical terms, few-shot evaluation assumes up to 1-2 hours of effort by a target database administrator or application developer, and translates to significant performance benefits. In a few-shot evaluation setting, augmenting a SOTA text-to-SQL parser (RAT-SQL by <ref type="bibr" target="#b17">Wang et al. (2020b)</ref>) with database documentation almost doubled its performance from 13.56% to 26.77%. See Section 4.</p><p>Text-to-SQL Semantic Parsing Semantic parsing has been studied extensively for decades <ref type="bibr" target="#b7">(Liang, 2016)</ref>. Key in-domain datasets such as <ref type="bibr">Geo-Query (Zelle and Mooney, 1996)</ref> and ATIS <ref type="bibr" target="#b0">(Dahl et al., 1994)</ref> acted as initial catalyst for the field by providing an evaluation measure and a training set for learned models. Applying a system to a domain with a different distribution of questions or parses required out-of-domain data or domain transfer techniques. Recently, cross-domain datasets WikiSQL <ref type="bibr" target="#b28">(Zhong et al., 2017)</ref> and Spider <ref type="bibr" target="#b22">(Yu et al., 2018)</ref> proposed a zero-shot evaluation methodology that required out-of-domain generalization to unseen database domains. This inspired rapid development of domain-conditioned parsers that work "out of the box" such as RAT-SQL <ref type="bibr" target="#b17">(Wang et al., 2020b)</ref> and IRNet <ref type="bibr" target="#b2">(Guo et al., 2019)</ref>. We use the same exact match accuracy metric as these works. Recent work <ref type="bibr" target="#b27">(Zhong et al., 2020)</ref> has proposed evaluating SQL prediction via semantic accuracy by computing denotation accuracy on automatically generated databases instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Few-shot learning</head><p>In this paper, we propose a few-shot evaluation to inspire future research of practical text-to-SQL parsers. Like zero-shot, fewshot has access to many out-of-domain examples, but it also has access to a small number of indomain examples as well. Few-shot learning has been applied to text classification in <ref type="bibr" target="#b9">(Mukherjee and Awadallah, 2020)</ref>, and has also been applied to semantic parsing. Common techniques include meta-learning <ref type="bibr" target="#b3">(Huang et al., 2018;</ref><ref type="bibr" target="#b16">Wang et al., 2020a;</ref><ref type="bibr" target="#b6">Li et al., 2021;</ref> and adversarial learning .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalization and Practical usability</head><p>Recent work has begun to question whether existing datasets are constructed in a way that will lead to models that generalize well to new domains. <ref type="bibr" target="#b13">Suhr et al. (2020)</ref> identified a number of challenges with text-to-SQL datasets, one of which is an artificially high overlap between words in a question and words in the tables. This issue appears in Spider and is a byproduct of the fact that question authors view the database schema as they write their question. The Spider-Realistic <ref type="bibr" target="#b1">(Deng et al., 2020)</ref> dataset aims to reduce this by explicitly rewriting the questions to avoid overlapping terms.</p><p>Other works has studied the problem of the gap between academic datasets and their practical us-ability <ref type="bibr" target="#b15">(de Vries et al., 2020;</ref><ref type="bibr" target="#b11">Radhakrishnan et al., 2020;</ref><ref type="bibr" target="#b26">Zhang et al., 2020)</ref>, including highlighting the need for data to be real. Our goal was to create an evaluation dataset and metric that minimizes this gap; our dataset is constructed from real data found on Kaggle that has been used for competitions or other analyses.</p><p>Another direction of generalization being explored is compositionality. <ref type="bibr" target="#b4">Keysers et al. (2020)</ref> used rules to generate a large-scale semantic parsing dataset that specifically tests models for composability. <ref type="bibr" target="#b12">Rastogi et al. (2020)</ref> provide NL descriptions for slots and intents to help dialogue state tracking. <ref type="bibr" target="#b8">Logeswaran et al. (2019)</ref> use descriptions to facilitate zero-shot learning for entity linking. <ref type="bibr" target="#b20">Weller et al. (2020)</ref> use descriptions to develop a system that can perform zero-shot learning on new tasks. We follow by including documentation on each included real-world database. Notably, this documentation was written for human consumption of the database rather than prepared for KaggleDBQA, and thus is a natural source of domain knowledge. It provides similar benefits to codebase documentation and comments, which improve source code encoding for AI-assisted software engineering tasks <ref type="bibr" target="#b10">(Panthaplackel et al., 2020;</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Leveraging other resources for learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">KaggleDBQA: A Real World Dataset</head><p>The goal of the KaggleDBQA evaluation dataset is to more closely reflect the data and questions a text-to-SQL parser might encounter in a real-world setting. As such, it expands upon contemporary cross-domain text-to-SQL datasets in three key aspects: (i) its databases are pulled from real-world data sources and not normalized; (ii) its questions are authored in environments that mimic natural question answering; (iii) its evaluation assumes the type of system augmentation and tuning that could be expected from domain experts that execute text-to-SQL parser deployment. We describe each of these components in turn in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Database Collection</head><p>We chose to obtain databases from Kaggle, a popular platform for hosting data science competitions and sharing datasets and code. Their hosted datasets are by definition "real" as they are used by members of the site for research. Competition hosts upload their data unnormalized, and the data content and formatting matches its domainspecific usage (see <ref type="figure">Figure 1</ref> for an example). To construct KaggleDBQA, we randomly selected 8 Kaggle datasets that satisfied the following criteria: (a) contained a SQLite database; (b) licensed under a republishing-permissive license; (c) had associated documentation that described the meaning of the tables and columns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Questions</head><p>For each database, we asked five annotators to write ten domain-specific questions that they think someone might be interested in and that can be answered using the database. We use five annotators per database to help guarantee diversity of questions. Each annotated two databases, for a total of 20 annotators and 400 questions. The annotators are not required to possess SQL knowledge so their questions are more reflective of natural user interests. Importantly, to discourage users from using the same terms from the database schema in their questions, we replace the original column names with the column descriptions. When annotating the questions, the annotators are shown a paragraph description of the database, table names, column descriptions and ten sampled rows for each table. We do not provide any constraints or templates other than asking them to avoid using exact phrases from the column headings in the questions. Appendix A.2.3 shows the full guidelines.</p><p>Separately, each question is annotated with its SQL equivalent by independent SQL experts. They are given full access to all of the data content and database schema. One-third of the questions were yes/no, percentage, temporal, or unexpressible in SQL and were not considered in our evaluation of SOTA models (see Appendix A.2.2 for details), leaving 272 questions in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Database Documentation</head><p>Each database has associated plain-text documentation that can assist text-to-SQL parsing. It is commonly found as internal documentation for database administrators or external documentation accompanying a dataset release.</p><p>The contents vary but often contain an overview of the database domain, descriptions of tables and columns, sample queries, original sources, and more.</p><p>While all of these types of information could be leveraged to assist with domain transfer, in this work we focus on the column descriptions. They help address the schema linking problem of textto-SQL parsing, i.e. aligning entity references in the question with database columns <ref type="bibr" target="#b17">(Wang et al., 2020b)</ref>. For example, "federal revenue" in Figure 1 must be aligned to the column t_fed_rev even though its abbreviated name makes alignment non-obvious.</p><p>We manually extract the column descriptions from the database documentation and provide the mapping from column to description as part of KaggleDBQA. The descriptions are free text and sometimes contain additional information such as defining the values in an categorical column. Such information could help with the value-linking prob- lem (mapping a value in the question to the column that likely contains it). We leave the entire description as a single field and leave it to future work to explore these uses further. In addition to column descriptions, we also include the original unstructured documentation which can be used for future research on automatically extracting descriptions or leveraging other domain knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Few-shot Evaluation Setting</head><p>The current cross-domain datasets Spider <ref type="bibr" target="#b22">(Yu et al., 2018)</ref> and WikiSQL <ref type="bibr" target="#b28">(Zhong et al., 2017)</ref> evaluate models in a zero-shot setting, meaning the model is trained on one set of domains and evaluated on a completely disjoint set. This evaluation encourages the development of systems that work well "out of the box" and has spurred great development in cross-domain text-to-SQL systems that are able to generalize to new domains. However, we believe the zero-shot setting is overly-restrictive compared to how text-to-SQL systems are likely to be actually used in practice. We postulate that it is more realistic to assume a setting where an application author spends 1-2 hours authoring examples and adapting existing database documentation. This time investment is a small fraction of the time required to prepare an application itself and so we believe application authors would devote the time if it resulted in increased text-to-SQL accuracy. In informal experiments, we have found SQL annotators can author 10-20 examples in an hour. Thus, the KaggleDBQA evaluation setting is few-shot: 30% of the questions for each domain (6-15 depending on the domain) are designated as in-domain and may be used as part of training for that domain, along with documentation. The remaining 70% are used for evaluation.</p><p>We report accuracy in both the few-shot as well as the standard zero-shot (cross-domain) setting in this paper, but consider the few-shot setting to be the primary evaluation setting for KaggleDBQA. Evaluation is conducted on the same 70% portion regardless of setting, to ensure comparable results.  <ref type="figure">Figure 2</ref>: Comparisons of text-to-SQL datasets in terms of SQL structure hardness. KaggleDBQA has more complex SQL query structure than the Spider dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Dataset Statistics and Comparison</head><p>We compare KaggleDBQA with previous benchmark datasets using key metrics in <ref type="table" target="#tab_2">Table 1</ref>. KaggleDBQA has the lowest value mention percentage among all datasets, and also exhibits a low overlap between question terms and column names similar to that in all of the datasets besides Spider, making it more in line with what would be expected in a real-world setting where the people asking questions are not familiar with the actual database schema and terminology. This is likely a result of replacing column names with descriptions in the question annotation task.</p><p>We also analyze the overlap between question terms and column descriptions in <ref type="table" target="#tab_3">Table 2</ref>. Because the descriptions are significantly longer than column names, we require only that they share an ngram in common (ignoring stop-words) rather than requiring exact match as was done for column mention percent. Unigram overlap is reasonably high (56% of correct columns match the question) but also results in many false-positive matches with other columns. Increasing n-gram size decreases false-positives but also rapidly decreases the correct column match percent. Thus, column descriptions may help guide the model, but are not as strong of a signal as found in Spider which suffers from high exact column name match overlap. This was our intention in asking our annotators to avoid using the descriptions verbatim when writing questions.</p><p>To measure the complexity of SQL in KaggleDBQA, we adopt the hardness criteria of Spider and report the numbers in <ref type="figure">Figure 2</ref>. The queries are on average more complex than Spider's, with significantly more hard and extra-hard ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline Results</head><p>We first evaluate KaggleDBQA using models that were developed for the Spider dataset.</p><p>EditSQL <ref type="figure">(Zhang et al., 2019)</ref>: EditSQL (with BERT) is the highest-performing model on the Spider dataset that also provides an open-source implementation along with a downloadable trained model. <ref type="bibr">3</ref> The model was built for edit-based multiturn parsing tasks, but can also be used as a singleturn parser for Spider or KaggleDBQA. It employs a sequence-to-sequence model with a questiontable co-attention encoder for schema encoding. <ref type="figure">Wang et al., 2020b)</ref>: RAT-SQL (v3 + BERT) is the model with highest accuracy on the Spider leaderboard that also provides an opensource implementation. 4,5 It adds string matching to the encoder through the use of relation-aware self-attention and adopts a tree-based decoder to ensure the correctness of the generated SQL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RAT-SQL (</head><p>Throughout this paper, we use the same exactmatch accuracy metric introduced by the Spider dataset. Although our primary evaluation setting is few-shot, we first examine the traditional zeroshot setting to present an unbiased comparison with previous results. <ref type="table" target="#tab_4">Table 3</ref> compares the performance of these two models (both trained on Spider). As can be seen, the performance of both models is significantly lower on KaggleDBQA. This echoes the findings of <ref type="bibr" target="#b13">Suhr et al. (2020)</ref> who found that a model trained on Spider did not generalize well to other datasets. Also, KaggleDBQA has much fewer column mentions and much more complex SQL than Spider (see <ref type="table" target="#tab_2">Table 1</ref> and <ref type="figure">Figure 2</ref>).</p><p>For all further experiments on KaggleDBQA that emulate real-world evaluation, we choose RAT-SQL as the best performing parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">RAT-SQL on KaggleDBQA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Moving to the Few-Shot Setting</head><p>To apply RAT-SQL to KaggleDBQA's few-shot setting, for each domain we create a model by fine-tuning on its 30% in-domain data. See Appendix A.3 for implementation details. This fine-3 https://github.com/ryanzhumich/ editsql 4 As of one month before paper authoring. Current SOTA systems are also based on RAT-SQL and add less than 5% accuracy, thus will likely behave similarly. 5 https://github.com/microsoft/rat-sql   53.40 11.73 tuning is always performed as the last step before evaluation.</p><p>As <ref type="table" target="#tab_5">Table 4</ref> shows, fine-tuning on a small amount of in-domain data dramatically increases overall accuracy from 13.56% to 17.96% (rows (a) and (e)),</p><p>Although the few-shot setting is our primary setting, we also present results in the zero-shot setting to compare to previous work <ref type="table" target="#tab_5">(Table 4</ref> rows (e)-(h)). However, in the remainder of the paper we will be focusing on the few-shot setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Leveraging Database Documentation</head><p>The database schemas in KaggleDBQA are obscure, making the task difficult without leveraging the database documentation. We consider only the column descriptions, but other portions of the documentation may prove useful in future work. The best approach for incorporating column descriptions into a text-to-SQL model is model-specific. RAT-SQL makes use of relations between question tokens and schema terms to assist with schemalinking. We extend the same functionality to column descriptions by appending the column descriptions to the column names (separated by a period) and recomputing matching relations. The concatenated column name is also presented to the transformer encoder for schema encoding.</p><p>Simply adding these descriptions results in mismatch between the training set (Spider) which does not have descriptions, and the evaluation set (KaggleDBQA) which does. To alleviate it, we first augment the schemas in Spider with artificial descriptions. For column of table , the description for is "the of the ". We then retrain RAT-SQL on Spider with these artificial descriptions.</p><p>Since the artificial descriptions simply restate information from the schema, the model may not learn to leverage them for any further information about schema linking and simply treat them as noise. Therefore, we also evaluate RAT-SQL adapted to the general domain of KaggleDBQA so that it (a) experiences useful descriptions and (b) adapts to the language distribution of KaggleDBQA. We evaluate the benefits of this adaptation using leaveone-out: for each domain in KaggleDBQA, we finetune the model on all other domains except for the target (with the same fine-tuning parameters as for few-shot learning). Adapting in this way is predictive of the performance of a novel domain with similar characteristics. As with the other few-shot results, the model is then fine-tuned on the few examples of target domain data. Adaptation and fine-tuning are two separate training processes. Adaptation is meant to adapt to the real-world distribution. Fine-tuning is meant to adjust for in-domain knowledge. The most effective setting for a target database in our experiments is to conduct adaptation first, followed by fine-tuning.</p><p>Table 4 (row (d)) shows the results. Using column descriptions in the context of adaptation increases model accuracy from 17.96% to 26.77%. Ablations show that adaptation and descriptions each contribute approximately half of this gain (row (c)). Descriptions provide no benefit without adaptation (row (b)), likely due to the train-test mismatch between artificial descriptions and real ones. With- out any artificial descriptions, accuracy drops even further so they are critical to leveraging in-domain knowledge. Overall, incorporating in-domain data (i.e. a few-shot setting and database documentation) nearly doubles model accuracy from 13.56% to 26.77% on KaggleDBQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Column Normalization</head><p>One of the major challenges in KaggleDBQA is that column names are often obscure or abbreviated. A natural question is whether this creates difficulty because the model struggles to understand the meaning of a column or because it leads to a low overlap between question and column terms. In an attempt to tease these factors apart, we created a normalized version of KaggleDBQA by replacing the obscure column names with normalized column names such as one might find in the Spider dataset. This was done manually using column descriptions to help clarify each column and without introducing any extra knowledge into the column names except for the expansion of abbreviations (e.g. t_fed_rev ? total federal revenue).</p><p>In <ref type="table" target="#tab_6">Table 5</ref> we give the results of evaluation on the normalized KaggleDBQA, following the same setup as <ref type="table" target="#tab_5">Table 4</ref>. Normalization provides a significant boost in performance (row (c) vs. row (a)). The trend is similar to <ref type="table" target="#tab_5">Table 4</ref>. Without adaptation, models with descriptions are not better than those without (row (b) vs. row (a), row (d) vs. row (c)). After adaptation, the train-test mismatch is partly mitigated and the performance improves (row (f) vs. row (e), row (h) vs. row (g)). Normalization and descriptions provide complementary knowledge augmentation, jointly improving accuracy by 5% (row (h) vs. row (e)), more than either alone. Normalization helps clarify the obscure column names of KaggleDBQA. However, the other chal-  lenges such as low column mention percentage and in-domain schema conventions still leave significant room for improvement. We provide the full experimental results on normalized tables in the Appendix. <ref type="table" target="#tab_7">Table 6</ref> shows examples of improvements due to descriptions. First, column descriptions help the parser correctly identify columns to select. For instance, it chooses STAT_CAUSE_CODE over STAT_CAUSE_DESCR when asked for "the most common cause of the fire (code)". Second, they clarify necessary constraints. For instance, when asked "how many samples come from other countries?", the parser chooses the correct origin column rather than superficially-matching country in the clause WHERE sampledata15.origin = "2". <ref type="table" target="#tab_8">Table 7</ref> shows a distribution of error types in KaggleDBQA using 10 randomly-selected erroneous predictions for each domain. The error categories mostly follow <ref type="bibr" target="#b13">Suhr et al. (2020)</ref>, modulo (a) removing unobserved categories, (b) separat-ing semantically equivalent predictions into their own "Equivalent" category, and (c) categorizing significant structural errors as "Understanding Errors". We also provide more characteristics of each database in <ref type="table" target="#tab_9">Table 8</ref> in an attempt to understand the difference in performance across databases. Our model performs worst on the databases with the most columns (Pesticide, Baseball and Soccer). The only database with lower accuracy is Math-Score which has multiple tables and a relatively small fine-tuning set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Error Analysis</head><p>The most common error types and their examples are summarized in <ref type="table" target="#tab_10">Table 9</ref>. (i) The most common type is "Incorrect Final Column" (33.75%), illustrating the difficulty of schema linking in KaggleDBQA even with documentation and finetuning. (ii) 32.5% of the errors are in "Missing Constraints". In KaggleDBQA questions, users sometimes use implications instead of directly mentioning the desired constraint, e.g. "in preparation" for  <ref type="table" target="#tab_2">#Tables  1  1  2  3  5  1  2  2  #Columns  15  6  34  15  44  19  10  37  #Fine-tuning Examples  10  9  16  9  12  12  13  6  #Test Examples  22  18  34  19  27  25</ref> 28 12 descending order. (iv) 15% of the errors are in "Entity-column matching", e.g. aligning "Salford" to Location rather than LSOA. This illustrates the difficulty of value linking, partly mitigated by value descriptions for categorical columns in the database documentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion &amp; Future Work</head><p>KaggleDBQA provides two resources to facilitate real-world applications of text-to-SQL parsing. First, it encourages an evaluation regime that bridges the gap between academic and industrial settings, leveraging in-domain knowledge and more realistic database distribution. We encourage adopting this regime for established text-to-SQL benchmarks. Second, it is a new dataset of more realistic databases and questions, present-ing a challenge to state-of-the-art parsers. Despite the addition of domain knowledge in the form of database documentation, our baselines reach only 26.77% accuracy, struggling to generalize to harder questions. We hope that better use of documentation and new modeling and domain adaptation techniques will help further advance state of the art. The KaggleDBQA dataset is available at https://aka.ms/KaggleDBQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethical Considerations</head><p>Dataset Collection The data collection process was pre-approved by IRB. Each annotator agreed to a consent form before having access to the labeling task. Each annotator was rewarded with a $20 e-gift card for the approximately one hour of their time. The authors of this paper acted as the SQL an-notators and incurred no additional compensation. The databases collected for KaggleDBQA were individually reviewed to ensure they were properly licensed for re-distribution. For other details of dataset construction, please refer to Section 3. Aside from email addresses, no personal information of annotators was collected during our study. Email addresses were not shared and were promptly deleted after compensation had been provided. The association between annotator and annotation was deleted before any analysis or distribution was conducted.</p><p>Language Distribution KaggleDBQA only includes question annotations and databases in English, thus evaluating multi-lingual text-to-SQL models on it will require translation. The set of annotators included both native and second-language speakers of English, all fluent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Usage of DBQA Technology Our goal with</head><p>KaggleDBQA is to encourage the development of DBQA that will work in real-world settings. The actual deployment of a text-to-SQL parser must be conducted with appropriate safeguards in place to ensure users understand that the answers may be incorrect, especially if those answers are to be used in decision making.   For adaptation and fine-tuning, we decrease the learning rate of BERT parameters by 50 times to 6e-8 to avoid overfitting. We keep the learning rate of non-BERT parameters the same at 7.44e-4. We also increase the dropout rate of the transformers from 0.1 to 0.3 to provide further regularization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table FINREV_FED_17</head><label>FINREV_FED_17</label><figDesc>Column Descriptions: t_fed_rev Total federal revenue through the state to each school district c14Federal revenue through the state-Title 1 (no child left behind act) c15</figDesc><table><row><cell>:</cell><cell cols="5">state_code school_district yr_data t_fed_rev c14</cell><cell>c15</cell><cell>?</cell></row><row><cell></cell><cell>33</cell><cell>NEW YORK CITY</cell><cell>17</cell><cell>2061297</cell><cell>956851 439209 ?</cell></row><row><cell></cell><cell></cell><cell>SCHOOL DISTRICT</cell><cell></cell><cell></cell></row><row><cell></cell><cell>47</cell><cell cols="2">FAIRFAX CO SCHS 17</cell><cell>126916</cell><cell>21035 36886 ?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table FINREV_FED_17_KEY</head><label>FINREV_FED_17_KEY</label><figDesc></figDesc><table><row><cell>:</cell><cell cols="2">state_code state</cell><cell>#_Records</cell></row><row><cell>1</cell><cell></cell><cell cols="2">Alabama 137</cell></row><row><cell cols="2">?</cell><cell>?</cell><cell>?</cell></row><row><cell cols="2">50</cell><cell cols="2">Wisconsin 425</cell></row><row><cell cols="2">51</cell><cell cols="2">Wyoming 48</cell></row><row><cell cols="4">Example Question: Which school district received the most of federal revenue through state in Wisconsin?</cell></row><row><cell cols="3">Example SQL: SELECT T1.KaggleDBQA We introduce KaggleDBQA, a</cell><cell>272 questions, while expressible, can only be solved to 13.56% accuracy (Section 4). ? Finally, we augment KaggleDBQA with database documentation, common metadata for real-world databases and a rich source of implicit domain knowledge. Database documentation includes column and table descriptions, categorical value descriptions (known as data dictionaries), SQL examples, and more (Section 3.3)</cell></row><row><cell cols="3">new dataset and evaluation setting for text-to-SQL</cell></row><row><cell cols="3">parsers to bridge the gap between SOTA DBQA</cell></row><row><cell cols="3">research and its real-life deployment. 1 It systemati-</cell></row><row><cell cols="3">cally addresses three aforementioned challenges:</cell></row><row><cell cols="3">? To test database generalization, it includes real-</cell></row><row><cell cols="3">world databases from Kaggle, 2 a platform for</cell></row><row><cell cols="3">data science competitions and dataset distribu-</cell></row><row><cell cols="3">tion. They feature abbreviated and obscure col-</cell></row><row><cell cols="3">umn names, domain-specific categorical values,</cell></row><row><cell cols="2">and minimal preprocessing (Section 3.1).</cell><cell></cell></row><row><cell cols="3">? To test question generalization, we collected un-</cell></row><row><cell cols="3">restricted NL questions over the databases in</cell></row><row><cell cols="3">KaggleDBQA. Importantly, the annotators were</cell></row><row><cell cols="3">not presented with original column names, and</cell></row><row><cell cols="3">given no task priming (Section 3.2). Out of 400</cell></row><row><cell cols="3">collected questions, one-third were out of scope</cell></row><row><cell cols="3">for SOTA text-to-SQL parsers. The remaining</cell></row></table><note>school_district FROM FINREV_FED_17 as T1 JOIN FINREV_FED_KEY_17 as T2 ON T1.state_code = T2.state_code WHERE T2.state = "Wisconsin" ORDER BY T1.t_fed_rev DESC LIMIT 1 Figure 1: Two table excerpts from the Student Math Score database in KaggleDBQA and an example question-SQL pair. The column names are abbreviated (e.g. t_fed_rev) or obscure (e.g. c14, c25) but documentation (e.g. column descriptions) alleviates this. Source: https://kaggle.com/loganhenslee/studentmathscores.supervision. This simplifies parser evaluation and raises the challenge level for zero-shot generaliza- tion. However, it does not leverage knowledge sources commonly present in real-world applica- tions, both explicit (annotated in-domain examples) and implicit (e.g. database documentation, SQL queries in the application codebase, or data dis- tributions). A well-chosen alternative evaluation setting would facilitate development of DBQA tech- nologies that match their real-world evaluation.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Comparison of text-to-SQL datasets. We follow the data filtering rules of<ref type="bibr" target="#b13">Suhr et al. (2020)</ref> and<ref type="bibr" target="#b1">Deng et al. (2020)</ref>, which reduces the effective number of examples from the original datasets to make them consistent. %WHERE measures the percentage of examples where all WHERE/HAVING columns in the SQL query are explicitly mentioned in the NL question. %VAL compares all the values in the SQL queries; %SELECT compares all the SELECT columns; %NON SELECT compares all columns except the SELECT columns. KaggleDBQA has low column mention percentage and contains databases with multiple tables.</figDesc><table><row><cell>Dataset</cell><cell cols="7"># Examples # DB # Table/DB % WHERE % VAL % SELECT % NON-SELECT</cell></row><row><cell>ATIS</cell><cell>275</cell><cell>1</cell><cell>25</cell><cell>0.0</cell><cell>95.6</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>GeoQuery</cell><cell>525</cell><cell>1</cell><cell>7</cell><cell>3.8</cell><cell>100.0</cell><cell>32.9</cell><cell>9.1</cell></row><row><cell>Restaurants</cell><cell>39</cell><cell>1</cell><cell>3</cell><cell>0.0</cell><cell>100.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>Academic</cell><cell>179</cell><cell>1</cell><cell>17</cell><cell>5.2</cell><cell>100.0</cell><cell>15.1</cell><cell>1.7</cell></row><row><cell>IMDB</cell><cell>111</cell><cell>1</cell><cell>17</cell><cell>1.6</cell><cell>100.0</cell><cell>7.1</cell><cell>0.8</cell></row><row><cell>Yelp</cell><cell>68</cell><cell>1</cell><cell>8</cell><cell>4.2</cell><cell>100.0</cell><cell>5.7</cell><cell>4.1</cell></row><row><cell>Scholar</cell><cell>396</cell><cell>1</cell><cell>10</cell><cell>0.0</cell><cell>100.0</cell><cell>0.7</cell><cell>0.2</cell></row><row><cell>Advising</cell><cell>281</cell><cell>1</cell><cell>15</cell><cell>4.0</cell><cell>100.0</cell><cell>6.1</cell><cell>3.9</cell></row><row><cell>Spider Train</cell><cell>7000</cell><cell>140</cell><cell>5.26</cell><cell>40.8</cell><cell>89.01</cell><cell>52.4</cell><cell>41.6</cell></row><row><cell>Spider Dev</cell><cell>1034</cell><cell>20</cell><cell>4.05</cell><cell>39.2</cell><cell>91</cell><cell>48.2</cell><cell>33.1</cell></row><row><cell>KaggleDBQA</cell><cell>272</cell><cell>8</cell><cell>2.25</cell><cell>8.7</cell><cell>73.5</cell><cell>24.6</cell><cell>6.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Average partial match % of columns descriptions across examples. We check whether 1-to 3-grams in the question are part of any column descriptions.</figDesc><table><row><cell>Type of n-gram</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell cols="4">% Cols matched in golden SQL 56.27 21.47 4.80</cell></row><row><cell># Cols matched in golden SQL</cell><cell>1.06</cell><cell>0.37</cell><cell>0.07</cell></row><row><cell># Cols matched not in the SQL</cell><cell>4.69</cell><cell>1.29</cell><cell>0.13</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Zero-shot testing results of various open-source models on KaggleDBQA and on the test set of Spider. All numbers are the exact match accuracy evaluated by the Spider official scripts. The Spider results are from the official leaderboard. The KaggleDBQA results are the average of three different runs.</figDesc><table><row><cell>Models</cell><cell cols="2">Spider KaggleDBQA</cell></row><row><cell cols="2">RAT-SQL (Wang et al., 2020b) 65.60</cell><cell>13.56</cell></row><row><cell>EditSQL</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Exact match accuracy and standard error on KaggleDBQA, mean of three runs with different random seeds.</figDesc><table><row><cell>With fine-tuning</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Exact match accuracy and standard error on schema-normalized KaggleDBQA, average of three runs with different random seeds.</figDesc><table><row><cell>With fine-tuning</cell><cell></cell></row><row><cell>Models</cell><cell>Avg</cell></row><row><cell>(a) RAT-SQL</cell><cell>17.96 ? 0.5%</cell></row><row><cell>(b) w. desc</cell><cell>17.55 ? 0.6%</cell></row><row><cell>(c) w. normalization</cell><cell>23.09 ? 0.9%</cell></row><row><cell>(e) w. adaptation</cell><cell>22.82 ? 0.1%</cell></row><row><cell>(f) w. desc + adaptation</cell><cell>26.77 ? 0.4%</cell></row><row><cell>(g) w. normalization + adaptation</cell><cell>25.60 ? 0.9%</cell></row><row><cell cols="2">(h) w. desc + normalization + adaptation 27.83 ? 0.7%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :USWildFires Column Descriptions</head><label>6</label><figDesc>Examples where description-augmented ("desc.") models solve a question that unaugmented models ("no desc.") do not. Both models are adapted and fine-tuned. Both omit values, as per the official Spider metric. STAT_CAUSE_CODE Code for the (statistical) cause of the fire STAT_CAUSE_DESCR Description of the (statistical) cause of the fire.FIRE_SIZEEstimate of acres within the final perimeter of the fire</figDesc><table><row><cell>Database Question</cell><cell>What's the most common cause of the fire (code) in the database?</cell></row><row><cell>no desc.</cell><cell>SELECT Fires.STAT_CAUSE_DESCR FROM Fires GROUP BY Fires.</cell></row><row><cell></cell><cell>STAT_CAUSE_DESCR ORDER BY Count( * )DESC LIMIT 1</cell></row><row><cell>desc.</cell><cell>SELECT Fires.STAT_CAUSE_CODE FROM Fires GROUP BY Fires.</cell></row><row><cell></cell><cell>STAT_CAUSE_CODE ORDER BY Count( * )DESC LIMIT 1</cell></row><row><cell>Question</cell><cell>What is the total area that has been burned until now?</cell></row><row><cell>no desc.</cell><cell>SELECT Sum( * )FROM Fires</cell></row><row><cell>desc.</cell><cell>SELECT Sum(Fires.FIRE_SIZE)FROM Fires</cell></row><row><cell>Database Pesticide</cell><cell>Column Descriptions</cell></row><row><cell>origin</cell><cell>Code indicating sample origin (1=U.S. 2=imported 3=unknown)</cell></row><row><cell>country</cell><cell>Country of origin if the sample was imported</cell></row><row><cell>Question</cell><cell>How many samples come from other countries?</cell></row><row><cell>no desc.</cell><cell>SELECT sampledata15.country FROM sampledata15</cell></row><row><cell>desc.</cell><cell>SELECT Count( * )FROM sampledata15 WHERE sampledata15.origin = '?'</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Distribution of error types in each domain over 10 randomly-selected erroneous examples.</figDesc><table><row><cell>Error Types</cell><cell cols="8">Nuclear Crime Pesticide MathScore Baseball Fires WhatCD Soccer</cell><cell>%</cell></row><row><cell>Entity-column matching</cell><cell>0</cell><cell>2</cell><cell>2</cell><cell>3</cell><cell>0</cell><cell>2</cell><cell>0</cell><cell>0</cell><cell>15.00%</cell></row><row><cell>Incorrect Final Column</cell><cell>3</cell><cell>2</cell><cell>5</cell><cell>3</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>2</cell><cell>33.75%</cell></row><row><cell>Missing Constraint</cell><cell>5</cell><cell>3</cell><cell>3</cell><cell>1</cell><cell>5</cell><cell>5</cell><cell>2</cell><cell>2</cell><cell>32.50%</cell></row><row><cell>Incorrect Constraint</cell><cell>4</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>6</cell><cell>0</cell><cell>7</cell><cell>2</cell><cell>31.25%</cell></row><row><cell>Understanding Error</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>4</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>13.75%</cell></row><row><cell>Ambiguous Columns</cell><cell>0</cell><cell>2</cell><cell>2</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>7.50%</cell></row><row><cell>Equivalent</cell><cell>1</cell><cell>0</cell><cell>2</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>3.75%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Statistics of each database in KaggleDBQA. Nuclear Crime Pesticide MathScore Baseball Fires WhatCD Soccer</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>The most common error types of our best model and their representative examples.</figDesc><table><row><cell></cell><cell>33.75%: Incorrect Final Column</cell></row><row><cell cols="2">Question What is the latitudinal band that is most likely to experience wildfires in the USA?</cell></row><row><cell cols="2">Predicted SELECT STAT_CAUSE_DESCR FROM Fires GROUP BY STAT_CAUSE_DESCR ORDER BY</cell></row><row><cell></cell><cell>Count( * )Desc LIMIT 1</cell></row><row><cell>Gold</cell><cell>SELECT LATITUDE FROM Fires GROUP BY LATITUDE ORDER BY count( * )DESC LIMIT 1</cell></row><row><cell></cell><cell>32.5%: Missing Constraint</cell></row><row><cell>Question</cell><cell>How many nuclear power plants are in preparation to be used in Japan?</cell></row><row><cell cols="2">Predicted SELECT Count( * )FROM nuclear_power_plants WHERE Country = '?'</cell></row><row><cell>Gold</cell><cell>SELECT count( * )FROM nuclear_power_plants WHERE Country = "Japan"AND Status</cell></row><row><cell></cell><cell>= "Under Construction"</cell></row><row><cell></cell><cell>31.25%: Incorrect Constraint</cell></row><row><cell cols="2">Question Which state gets the highest revenue?</cell></row><row><cell cols="2">Predicted SELECT NDECoreExcel_Math_Grade8.state FROM FINREV_FED_17 JOIN</cell></row><row><cell></cell><cell>NDECoreExcel_Math_Grade8 GROUP BY NDECoreExcel_Math_Grade8.state ORDER</cell></row><row><cell></cell><cell>BY Sum(FINREV_FED_17.t_fed_rev)Asc</cell></row><row><cell>Gold</cell><cell>SELECT T2.13.75%: Understanding Error</cell></row><row><cell>Question</cell><cell>How many downloads of ep and album respectively?</cell></row><row><cell cols="2">Predicted SELECT Sum(totalSnatched), Sum(totalSnatched)FROM torrents WHERE</cell></row><row><cell></cell><cell>releaseType = '?'</cell></row><row><cell>Gold</cell><cell>SELECT sum(totalSnatched)FROM torrents WHERE releaseType = "ep"UNION</cell></row><row><cell></cell><cell>SELECT sum(totalSnatched)FROM torrents WHERE releaseType = "album"</cell></row></table><note>state FROM FINREV_FED_KEY_17 as T2 JOIN FINREV_FED_17 as T1 ON T1.state_code = T2.state_code GROUP BY T2.state ORDER BY sum(t_fed_rev) DESC LIMIT 1 15%: Entity-column matching Question Which type of crime happens the most in Salford? Predicted SELECT Type FROM GreaterManchesterCrime WHERE Location LIKE '?' GROUP BY Type ORDER BY Count( * )Desc LIMIT 1 Gold SELECT Type FROM GreaterManchesterCrime WHERE LSOA LIKE "%Salford%"GROUP BY Type ORDER BY count( * )DESC LIMIT 1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 :</head><label>10</label><figDesc>Evaluation results on KaggleDBQA using 100% of the evaluation data. All numbers are the exact match accuracy evaluated by the Spider official scripts. Here we report the average score of three runs with different random seeds.</figDesc><table><row><cell>Models</cell><cell cols="8">Nuclear Crime Pesticide MathScore Baseball Fires WhatCD Soccer</cell><cell>Avg</cell></row><row><cell>RATSQL</cell><cell>22.91</cell><cell>23.45</cell><cell>8.00</cell><cell>0.00</cell><cell>11.11</cell><cell>25.22</cell><cell>4.76</cell><cell>11.11</cell><cell>13.32</cell></row><row><cell>w. desc</cell><cell>21.87</cell><cell>20.98</cell><cell>9.99</cell><cell>0.00</cell><cell>11.11</cell><cell>18.01</cell><cell>6.50</cell><cell>11.11</cell><cell>12.44</cell></row><row><cell>w. adaptation</cell><cell>20.83</cell><cell>33.33</cell><cell>12.66</cell><cell>3.57</cell><cell>11.11</cell><cell>24.32</cell><cell>8.93</cell><cell>12.96</cell><cell>15.96</cell></row><row><cell>w. desc + adaptation</cell><cell>29.16</cell><cell>25.88</cell><cell>18.00</cell><cell>3.57</cell><cell>16.23</cell><cell>30.62</cell><cell>10.53</cell><cell>12.96</cell><cell>18.37</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 :</head><label>11</label><figDesc>The original user question distribution. This reflects the natural information need from users.</figDesc><table><row><cell>Question Types</cell><cell>#</cell><cell>Example</cell></row><row><cell>Yes/No Percentage</cell><cell>51</cell><cell>Has there been a recent surge in violent crime in Manchester? What percentage of August crime detections resulted in prosecution of a suspect?</cell></row><row><cell>Time-related</cell><cell>46</cell><cell>Divide the day into 3 slots (6am to 4pm, 4pm to 11pm, 11pm to 6am),</cell></row><row><cell></cell><cell></cell><cell>which has the highest amount of crime conducted per hour?</cell></row><row><cell cols="2">SQL-unexpressible 31</cell><cell>Which states had the highest percentage change in average scores</cell></row><row><cell></cell><cell></cell><cell>over the last few years?</cell></row><row><cell>SQL-expressible</cell><cell cols="2">272 Which LSOA has had the most instances of bicycle theft this month?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 12 :</head><label>12</label><figDesc>Exact match accuracy and standard error on schema-normalized KaggleDBQA, average of three runs with different random seeds.</figDesc><table><row><cell>With fine-tuning</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Available at https://aka.ms/KaggleDBQA. 2 https://www.kaggle.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Status = "Under Construction". (iii) 31.25% of the errors are in "Incorrect Constraint", e.g. failing to parse "highest" into the top-1 result in</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Evaluation on Full Testing Data</head><p>We show the zero shot testing and out-of-domain adaptation results in <ref type="table">Table 10</ref>. In contrast to <ref type="table">Table 4</ref>, they are evaluated using the full set of testing data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Details of Dataset Construction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.1 Example Page of User Instructions</head><p>For each user, we show two different HTML files that contain different instructions of the task, database overview, table name(s), column descriptions, ten sampled rows of the database content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 Question Types</head><p>Question annotators were allowed to write any type of question without restriction. While this represents a natural distribution of questions one might expect to encounter in a realistic setting, some types do not appear in the Spider training set and thus pose particular difficulty with current text-to-SQL systems. We remove these from the official evaluation but still include them in the dataset for future work on these types of questions. <ref type="table">Table 11</ref> summarizes the distribution over these types of questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.3 SQL annotation Guidelines</head><p>We also establish few guidelines and follow them throughout the annotation process:</p><p>1. If the referred column is categorical, use "=" operator with the value from the database (e.g., Where is the area with the largest number of sexual offenses crime events? ? SELECT Location FROM GreaterManchesterCrime WHERE Type = "Violence and sexual offences"GROUP BY Location ORDER BY count( * )DESC LIMIT 1). If it is free-form text use "LIKE" operator with a term from the question (e.g., What were the closing odds for a draw in matches with VfB Stuttgart? ? SELECT DRAW_CLOSING FROM betfront WHERE MATCH LIKE "%VfB Stuttgart%").</p><p>2. Sometimes ID columns are paired with their name realizations (e.g., state_code and state) We choose to return ID whenever users do not explicitly ask for the name realizations.</p><p>3. Duplicate rows can sometimes yield an incorrect result. However, it is not possible for models to know in advance unless they encode database content. So we use the DISTINCT operator when necessary to return the correct answer or it is explicitly asked for by the user (e.g., What are titles for each unique entry?).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Expanding the scope of the ATIS task: The ATIS-3 corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deborah</forename><forename type="middle">A</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madeleine</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Hunicke-Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pallett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Pao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rudnicky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Shriberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technology: Proceedings of a Workshop held at Plainsboro</title>
		<meeting><address><addrLine>New Jersey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-03-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">Hassan</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12773</idno>
		<title level="m">Structure-grounded pretraining for text-to-sql</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards complex text-to-SQL in cross-domain database with intermediate representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zecheng</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1444</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4524" to="4535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Natural language to structured query generation via meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2115</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="732" to="738" />
		</imprint>
	</monogr>
	<note>New Orleans, Louisiana. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Measuring compositional generalization: A comprehensive method on realistic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Sch?rli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hylke</forename><surname>Buisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Furrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergii</forename><surname>Kashubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Momchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danila</forename><surname>Sinopalnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Stafiniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tibor</forename><surname>Tihon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Tsarkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Marc Van Zee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bousquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Domain adaptation for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zechang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2020/515</idno>
		<ptr target="ijcai.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJ-CAI 2020</title>
		<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJ-CAI 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3723" to="3729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Few-shot semantic parsing for new predicates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gholamreza</forename><surname>Haffari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.10708</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning executable semantic parsers for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="68" to="76" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Zero-shot entity linking by reading entity descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lajanugen</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1335</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3449" to="3460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Uncertainty-aware self-training for few-shot text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhabrata</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Awadallah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Associating natural language comment and source code entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheena</forename><surname>Panthaplackel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milos</forename><surname>Gligoric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyi Jessy</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8592" to="8599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Colloql: Robust cross-domain text-to-sql over search queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Karthik Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi Victoria</forename><surname>Srikantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.09927</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxue</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Sunkara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Khaitan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8689" to="8696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exploring unexplored generalization challenges for cross-database semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alane</forename><surname>Suhr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.742</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8372" to="8388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural semantic parsing in low-resource settings with back-translation and meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibo</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeyun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8960" to="8967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Harm De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.14435</idno>
		<title level="m">Towards ecologically valid research on language user interfaces</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Meta-learning for domain generalization in semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11988</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">RAT-SQL: Relation-aware schema encoding and linking for text-to-SQL parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.677</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th</title>
		<meeting>the 58th</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="7567" to="7578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Code generation as a dual task of code summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyi</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08" />
			<biblScope unit="page" from="6559" to="6569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning from task descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orion</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.105</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1361" to="1375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chern Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.13845</idno>
		<title level="m">Grappa: Grammar-augmented pre-training for table semantic parsing</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingning</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanelle</forename><surname>Roman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1425</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3911" to="3921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national conference on artificial intelligence</title>
		<meeting>the national conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Photon: A robust cross-domain text-to-SQL system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jichuan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>King</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-demos.24</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="204" to="214" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Editing-based SQL query generation for cross-domain contextdependent questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heyang</forename><surname>Er</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungrok</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1537</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5338" to="5349" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Did you ask a good question? a cross-domain question intention classification benchmark for text-to-sql</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuaichen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12634</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semantic evaluation for text-to-sql with distilled test suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="396" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.00103</idno>
		<title level="m">Seq2sql: Generating structured queries from natural language using reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Implementation Details For all our experiments we use the RAT-SQL official implementation and the pre-trained BERT-Large from Google</title>
		<imprint/>
	</monogr>
	<note>6 We follow the original settings to get the pre-fine-tuned/pre-adapted models</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<ptr target="https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip" />
		<title level="m">We use the BERT-Large, Uncased (Whole Word Masking</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
