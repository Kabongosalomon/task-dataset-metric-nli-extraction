<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">To Smooth or Not? When Label Smoothing Meets Noisy Labels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaheng</forename><surname>Wei</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangyu</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
						</author>
						<title level="a" type="main">To Smooth or Not? When Label Smoothing Meets Noisy Labels</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T07:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Label smoothing (LS) is an arising learning paradigm that uses the positively weighted average of both the hard training labels and uniformly distributed soft labels. It was shown that LS serves as a regularizer for training data with hard labels and therefore improves the generalization of the model. Later it was reported LS even helps with improving robustness when learning with noisy labels. However, we observed that the advantage of LS vanishes when we operate in a high label noise regime. Intuitively speaking, this is due to the increased entropy of P(noisy label|X) when the noise rate is high, in which case, further applying LS tends to "oversmooth" the estimated posterior. We proceeded to discover that several learning-with-noisy-labels solutions in the literature instead relate more closely to negative/not label smoothing (NLS), which acts counter to LS and defines as using a negative weight to combine the hard and soft labels! We provide understandings for the properties of LS and NLS when learning with noisy labels. Among other established properties, we theoretically show NLS is considered more beneficial when the label noise rates are high. We provide extensive experimental results on multiple benchmarks to support our findings too. Code is publicly available at https://github.com/UCSC-REAL/ negative-label-smoothing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Label smoothing (LS) <ref type="bibr">(Szegedy et al., 2016)</ref> is an arising learning paradigm that uses positively weighted average of both the hard training labels and the uniformly distributed 1 University of California, Santa Cruz 2 Brown University 3 TML Lab, Sydney AI Centre, The University of Sydney 4 RIKEN AIP 5 University of Tokyo. Correspondence to: Yang Liu &lt;yan-gliu@ucsc.edu&gt;.</p><p>Proceedings of the 39 th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the author(s). soft label:</p><formula xml:id="formula_0">y LS,r = (1 ? r) ? y + r K ? 1,<label>(1)</label></formula><p>where we denote the one-hot vector form of hard label and an all one vector as y, 1 respectively. K is the number of label classes, and r is the smooth rate in the range of <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. It was shown that LS serves as a regularizer for the hard training data and therefore improves generalization of the model. The regularizer role of LS prevents the model from fitting overly on the target class. Empirical studies have demonstrated the effectiveness of LS in improving the model performance across various benchmarks <ref type="bibr">(Pereyra et al., 2017)</ref> (such as image classification <ref type="bibr">(Szegedy et al., 2016)</ref>, machine translation <ref type="bibr">(Vaswani et al., 2017)</ref>, language modelling <ref type="bibr" target="#b6">(Chorowski &amp; Jaitly, 2017</ref>)), and model calibration <ref type="bibr">(M?ller et al., 2019)</ref>. Later it was reported LS even helps with improving robustness when learning with noisy labels <ref type="bibr">(Lukasik et al., 2020)</ref>. However, we observed that the advantage of LS vanishes when we operate in a high label noise regime: in <ref type="figure" target="#fig_0">Figure 1</ref>, we present a set of experiments on some UCI datasets <ref type="bibr" target="#b8">(Dua &amp; Graff, 2017)</ref> with synthetic noisy labels. We highlight the best two smooth rates when the classifier is trained under each label noise rate. Since UCI datasets are of small scales, it is possible to have tied smooth rates when evaluating the classifier on the separate clean test data. Indeed, non-negative smooth rates (circles colored in red) outperform negative ones when the label noise rates are low. Nonetheless, with the increasing of noise rates, negative smooth rates r &lt; 0 (Eqn. (1), diamonds colored in green) appear to be more competitive when learning with noisy labels. Intuitively speaking, this is due to the increased entropy of P(noisy label|X) when the noise rate is high, in which case, further applying LS tends to "oversmooth" the estimated posterior. Motivated by this observation, we aim to provide a more thorough understanding of whether should we adopt label smoothing or not when learning with noisy labels, specifically, how to make a choice between LS and negative/not label smoothing (NLS)?</p><p>With the presence of label noise, we theoretically demonstrate that there exists a phase transition when finding the optimal label smoothing rate for r ? (??, 1]. Particularly, when the label noise rate is low, LS is able to uncover the optimal model while NLS is considered more beneficial in a high label noise regime. Discovering that NLS differs substantially from LS in their achieved model confidence, we then proceed to explain such a transition. We also bridge the gap between NLS and several learning-with-noisy-labels solutions in the literature, including Loss Correction <ref type="bibr">(Patrini et al., 2017)</ref>, NLNL <ref type="bibr" target="#b21">(Kim et al., 2019)</ref> and Peer Loss <ref type="bibr">(Liu &amp; Guo, 2020)</ref>, to further validate our results.</p><p>We provide extensive experimental evidences to support our findings. For instance, on multiple benchmark datasets, we present the clear transition of the optimal smoothing rate going from positive to negative when we keep increasing noise rates. In particular, we show a negative smoothing rate elicits higher model confidence on correct predictions and lower confidence on wrong predictions compared with the behavior of a positive one on CIFAR-10 test data.</p><p>Our contributions summarize as follows:</p><p>? We provide understandings for the decision between LS and NLS, when learning with noisy labels.</p><p>? We demonstrate learning with a negative smooth rate can be more robust to label noise compared with a positive rate when label noise rates are high. And this is best explained by the fact that NLS improves the confidence of model prediction. (Section 3 and 4) <ref type="bibr">?</ref> We show that several robust loss functions in the labelnoise literature correspond to learning with NLS, under certain noise rate models. (Section 5)</p><p>? Extensive empirical results validate our main theoretical conclusions. In Appendix, we discuss practical considerations to mitigate the impact of label noise, and empirically show how LS and NLS result in trade-offs in model confidence, bias and variance of the generalization error.</p><p>We defer all proofs to Appendix F. Our work primarily contributes to the literature of learning with noisy labels <ref type="bibr">(Scott et al., 2013;</ref><ref type="bibr">Natarajan et al., 2013;</ref><ref type="bibr">Liu &amp; Tao, 2015;</ref><ref type="bibr">Patrini et al., 2017;</ref><ref type="bibr">Liu &amp; Guo, 2020)</ref>. Our core results are contingent on recent works of understanding the effect of label smoothing when training deep neural network models, i.e., label smoothing improves model calibration <ref type="bibr">(M?ller et al., 2019)</ref>, more complicated forms of label smoothing <ref type="bibr">(Li et al., 2020;</ref><ref type="bibr">Yuan et al., 2020)</ref>, and in particular when label noise presents <ref type="bibr">(Lukasik et al., 2020;</ref><ref type="bibr" target="#b2">Liu, 2021</ref>). Due to the space limit, we defer a more detailed discussion of related works to Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Learning with noisy labels</head><p>For a K-class classification task, we denote by X ? X a high-dimensional feature and Y ? Y := {1, 2, ..., K} the corresponding label. Suppose (X, Y ) ? X ? Y are drawn from a joint distribution D. The noisy label literature <ref type="bibr">(Natarajan et al., 2013;</ref><ref type="bibr">Liu &amp; Tao, 2015;</ref><ref type="bibr">Patrini et al., 2017)</ref> considers the setting where we only have access to samples with noisy labels from (X, Y ). Suppose random variables (X, Y ) ? X ? Y are drawn from a noisy joint distribution D.</p><p>Statistically, the random variable of noisy labels Y can be characterized by a noise transition matrix T , where each element T i,j represents the probability of flipping the clean label Y = i to the noisy label Y = j, i.e., T ij = P( Y = j|Y = i). In this paper, we concentrate on the widely adopted class-dependent label noise <ref type="bibr">(Natarajan et al., 2013;</ref><ref type="bibr">Liu &amp; Tao, 2015;</ref><ref type="bibr">Patrini et al., 2017)</ref>, which assumes that the label noise is conditionally independent of features X, i.e.,</p><formula xml:id="formula_1">P( Y = j|Y = i) = P( Y = j|X, Y = i), ?i, j ? [K].</formula><p>For the binary classification setting, define e 0 := P( Y = 1|Y = 0), e 1 := P( Y = 0|Y = 1). Without loss of generality, we assume e 1 ? e 0 = e ? ? 0. The binary noise transition matrix in the noisy label setting then becomes:</p><formula xml:id="formula_2">T = 1 ? e 0 e 0 e 1 1 ? e 1 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Learning with smoothed labels</head><p>Let y i be the one-hot encoded vector form of y i which generates according to Y . The random variable of smoothed </p><formula xml:id="formula_3">y LS,r i = (1 ? r) ? y i + r K ? 1.</formula><p>For example, when r = 0.3, the smoothed label of</p><formula xml:id="formula_4">y i = [1, 0, 0] becomes y LS,r=0.3 i = [0.8, 0.1, 0.1] .</formula><p>To enable ease of presentations (instead of highlighting a crucial concept), we unify LS <ref type="bibr">(Szegedy et al., 2016;</ref><ref type="bibr">Lukasik et al., 2020)</ref> and NLS into the generalized label smoothing (GLS), i.e., r ? (??, 1]:</p><formula xml:id="formula_5">y GLS,r i := (1 ? r) ? y i + r K ? 1,<label>(2)</label></formula><p>where y GLS,r i is given by the random variable of generalized smooth label Y GLS,r . We name the scenario r &lt; 0 as negative/not label smoothing (NLS). A negative r indicates that the smoothed label might be negatively related to the corresponding feature and should not be (positively) smoothed. For example, when r = ?0.3, the smoothed label of</p><formula xml:id="formula_6">y i = [1, 0, 0] becomes y GLS,r=?0.3 i = [1.2, ?0.1, ?0.1] .</formula><p>We observe that the entries in y GLS,r i still add up to 1: 1 ? r + r K ? K = 1. Nonetheless we want to point out y GLS,r i is no longer a valid probability measure since for entries y = y i , the corresponding weight will be negative ( r K ) when r &lt; 0. This points us to the definition of an extended label distribution:</p><p>Definition 2.1 (Extended label distribution). We call y an extended label distribution if 1 y = 1, but y is not necessarily entry-wise non-negative.</p><p>What negative labels really mean Negative label smoothing is indeed one of such extended label distribution. We proceed the illustration using the previous three-class classification example: a one-hot label [1, 0, 0] (three elements stand for class dog (0), cat (1), deer (2), respectively) means this sample x is categorized as a dog and is irrelevant to class cat and deer. LS [0.8, 0.1, 0.1] indicates that the representation x might encode uncertainty and is slightly related to cat/deer (positive correlation between cat/deer and dog given x). NLS [1.2, ?0.1, ?0.1] not only implies high confidence in label dog, but it is even more so that predicting cat (1) or deer (2) should be penalized by 0.1, i.e., given any loss that is linear in y (e.g., CE loss), this x receives the loss 1.2 ? (f (x), 0) ? 0.1 ? (f (x), 1) ? 0.1 ? (f (x), 2). Such a penalization mechanism is not uncommon and it appeared in the design of backward loss correction <ref type="bibr">(Natarajan et al., 2013)</ref> i?{0,1,2} T ?1 0,i ? (f (x), i) with T ?1 0,1 , T ?1 0,2 ? 0 (T ?1 is the inverse matrix of T ), peer loss <ref type="bibr">(Liu &amp; Guo, 2020)</ref> (f (x), 0)? (f (x), y rand ) where y rand = i with probability P( Y = i) for i ? {0, 1, 2}, and complementary loss (more details in Section 5).</p><p>We will present the surprising power of negative labels in handling label noise, though a bit counter-intuitive at first sight. To clarify, although we may adopt the negative label for calculating the loss, the model prediction is processed by the soft-max function, so the prediction still lies on the K-simplex. Besides, we do not assume a strict lower bound for r. If r ? ??, normalizing y GLS,r i by 1 ? r returns y GLS,r i = y i ? 1 K . We will show when imposing a negative smoothing parameter will be considered beneficial as compared to a positive one. In the main paper, we mainly focus on the binary classification task where y i ? {0, 1} and K = 2, although we do include the discussion of multi-class extensions in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Model confidence</head><formula xml:id="formula_7">Denote a deep neural network as f , f (x i ) is the model prediction of x i ? X with element f (x i ) yi := P(Y = y i |X = x i , f ), the binary cross-entropy loss is then defined as CE (f (x i ), y i ) := ? log(f (x i ) yi )</formula><p>. Throughout this paper, we shorthand CE as for a clean presentation. We define a key quantity, model confidence, that plays an important role in later sections.</p><formula xml:id="formula_8">Definition 2.2 (Confidence of model f for sample (x, y)). Given a model f , a sample x with its target label y ? {0, 1}, the model confidence of f w.r.t. sample x is defined as MC(f ; x, y) = f (x) y ? f (x) 1?y .</formula><p>MC(f ; x, y) in Definition 2.2 characterizes the difference of the predicted probability between the target class and the other class. MC(f ; x, y) = 0 simply means f has no confidence on its predictions since the model can not identify the target class of x. MC(f ; x, y) is negative when f gives a wrong prediction and is not confident to predict the label of x as the target label y. To dig into how GLS influences the model confidence on correct and wrong predictions in following sections, we separate the distribution D into:</p><formula xml:id="formula_9">D + f := {(X, Y ) ? D : MC(f ; X, Y ) &gt; 0}, D ? f := {(X, Y ) ? D : MC(f ; X, Y ) ? 0}.</formula><p>Similarly, we introduce the confidence of model prediction under the metric of -loss as: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">To Smooth or Not? In the View of Risk Minimization</head><p>In this section, we aim to characterize the optimal candidates of r in the unified setting to distinguish the preferences for LS and NLS, when the label noise presents.</p><p>Let? be the vector form of noisy label? obtained from Y . For r ? 1, we define the r-smoothed label of? as? GLS,r , where? GLS,r := (1 ? r) ?? + r K ? 1 and is generated by the random variable Y GLS,r . Risk minimization w.r.t. smoothed noisy label distribution Y GLS,r is then defined as:</p><formula xml:id="formula_10">min f ?F E (X, Y )? D (f (X), Y GLS,r ) ,<label>(3)</label></formula><p>where in above F is the hypothesis space we consider. In <ref type="figure" target="#fig_0">Figure 1</ref>, we have shown that given the unseen test data, learning with non-negative smooth rates may not always return the best outcome. Based on this observation, we delve into details to show when NLS is more favorable than LS and Vanilla Loss (VL, r = 0). We start with stating Assumption 3.1: Assumption 3.1. We assume learning with clean data distribution D with smooth rate r * ? 1 in GLS makes the corresponding classifier f * D return the best performance on the unseen clean test data distribution D test , where f * D is given by:</p><formula xml:id="formula_11">f * D ? arg min f ?F E (X,Y )?D [ (f (X), Y GLS,r * )].</formula><p>Assumption 3.1 simply offers us a view to initiate our analysis for the noisy label setting. To clarify, the expected risk of random variables could be approximated/replaced by the empirical one over a finite number of samples: i.e.,</p><formula xml:id="formula_12">when D = {x i , y i } N i=1 , D = {x i ,? i } N i=1 , Eqn. (3) be- comes: min f ?F 1 N i?[N ] (f (x i ),? GLS,r i</formula><p>). In this case, D represents the empirical distribution for the finite dataset, and Dtest can be thought of as the expected risk with infinite samples. With this being said, our analysis does require taking the expectation over the noisy labels (over Y |X, Y ). Besides, we don't rule out the possibility that other methods outperform LS, VL or NLS with optimal smooth rate r * . At the end of this section and Appendix D, we will empirically test what r * usually is on various benchmarks. We denote the r * smoothed label distribution as Y * : Y * = Y GLS,r * . With the introduction of r * and f * D , our goal is then to recover the classifier f * D using the noisy training labels. We define ? 1 , ? 2 and offer Theorem 3.2.</p><formula xml:id="formula_13">? 1 := (e 0 ? r * 2 ) + (1 ? 2e 0 ) ? r 2 , ? 2 := e ? ? (1 ? r).</formula><p>Theorem 3.2. The risk minimization w.r.t. Y GLS,r in the noisy setting (Eqn. <ref type="formula" target="#formula_10">(3)</ref>) is equivalent to the risk w.r.t Y * defined on the clean data, with two additional bias terms:</p><formula xml:id="formula_14">min f ?F E (X,Y )?D (f (X), Y * ) True Risk +? 1 ? E (X,Y )?D (f (X), 1 ? Y ) ? (f (X), Y ) M-Inc1 +? 2 ? E X,Y =1 (f (X), 0) ? (f (X), 1) M-Inc2 .<label>(4)</label></formula><p>Remember that = ce , we have:</p><formula xml:id="formula_15">MC (f ; X, Y ) = log (f (X) Y / (1 ? f (X) Y )), MC(f ; X, Y ) = 2f (X) Y ? 1.</formula><p>Both log( x 1?x ) and 2x ? 1 are monotonically increasing for x ? (0, 1), model f with a high MC (f ; X, Y ) has high MC(f ; X, Y ). The two extra bias terms explicitly affect the model confidence. Now we proceed to answer "what r is preferred in the noisy setting".</p><p>3.1. Symmetric noise rates with e ? = 0 Symmetric noise rates e := e 0 = e 1 indicates the probability of flipping to the other class is equal for both classes. In this case, ? 2 = 0, Term M-Inc2 is cancelled and Eqn. (4) reduces to</p><formula xml:id="formula_16">min f ?F E (X,Y )?D (f (X), Y * ) True Risk +? 1 ? E (X,Y )?D (f (X), 1 ? Y ) ? (f (X), Y ) M-Inc1 . (5)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noisy labels impair model confidence on Vanilla Loss</head><p>In the unified framework, define the optimal r that will cancel the impact of Term M-Inc1 as:</p><formula xml:id="formula_17">when r opt := r * ? 2e 1 ? 2e , M-Inc1 = 0.<label>(6)</label></formula><p>The threshold r opt in Eqn. 6 implies: Theorem 3.3. With Assumption 3.1, learning with smooth rate r = r opt under (X, Y ) ? D yields f * D : ? When noise rate e &lt; r * /2, r = r opt &gt; 0 (LS);</p><p>? When noise rate e = r * /2, r = 0 (VL);</p><p>? When noise rate e &gt; r * /2, r = r opt &lt; 0 (NLS).  In Theorem 3.3, adopting NLS when noise rate e &lt; r * 2 induces ? 1 &lt; 0, Term M-Inc1 makes f overly-confident on its predictions compared with Y * . In <ref type="figure" target="#fig_2">Figure 2</ref>, with the decreasing of r * , LS is less tolerant of labels with high noise.</p><p>Similarly, if e ? r * 2 , with the decreasing of r * , NLS is more robust in the high noise regime while LS makes the model f become less-confident on its predictions. Clearly, NLS outperforms LS especially when noise rates are large and r * is small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Asymmetric noise rates with e ? = 0</head><p>In this case, adopting r = r * ?2e0 1?2e0 removes the Term M-Inc1. However, when r &lt; 1, Term M-Inc2 is not negligible due to assymetric noise transition matrix. As a result, Term M-Inc2 becomes:</p><formula xml:id="formula_18">e ? ? 1 ? r * 1 ? 2e 0 ? E X,Y =1 (f (X), 0) ? (f (X), 1) ,</formula><p>with e ? ? 1?r * 1?2e0 ? 0. Term M-Inc2 in the minimization increases the model confidence on (X, Y = 0) ? D + f . The model will then become overly-confident with the class that has a low noise rate e 0 . Meanwhile, Term M-Inc2 decreases the model confidence on (X, Y = 1) ? D + f (less-confident to the class with a high noise rate e 1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Analysis of empirical risks</head><p>The popularity of LS is largely due to its effectiveness in practice, i.e., through the optimization of the smoothed empirical risk. Given the smooth rate r, potentially we could adopt the Rademacher bound on the maximal deviation between the expected risk R r exp (f ) (objective in Eqn.</p><p>(3)) and the empirical risk</p><formula xml:id="formula_19">R r emp (f ) := 1 N i?[N ] (f (x i ),? GLS,r i</formula><p>) when learning with noisy labels, formally, we have: Theorem 3.4. With probability at least 1 ? ?, we have:</p><formula xml:id="formula_20">max f ?F |R r emp (f ) ? R r exp (f )| ?(2 + |r| ? r) ? L ? R(F) + (1 ? r) ? ? ? log(1/?) 2N ,</formula><p>where , denote the upper/lower bound of , R is the Rademacher complexity.</p><p>Theorem 3.4 bridges the gap between the expected risk R r exp (f ) and the empirical risk R r emp (f ) by offering an upper bound. Intuitively, with a large sample size N and a low Rademacher complexity of the hypothesis space R(F), R r emp (f ) is supposed to well-approximate R r exp (f ). When learning with finite samples, LS is popular by referring to its impacts on reducing the model confidence (or avoids over-fitting). NLS indeed may force model become confident on the prediction, including wrong ones. What we observe in practice is that neural nets firstly memorize on easy/clean samples <ref type="bibr">(Liu et al., 2020)</ref>, warm-up with CE and then switch to NLS significantly improves the model performance. Since in the latter stage, the model is encouraged to be more confident on learned patterns (clean samples) and less likely to over-confident on samples with wrong labels (large-loss samples). When noise rate is high, the noisy training data is already over-smoothing the training process. Think of the noisy label flipping corresponding to a certain smooth rate, and a case where a certain representation x, with its similar patterns, are sampled multiple times -then their associated noisy labels formed a smoothed distribution. In this case, applying the NLS corrects the over-smoothness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Multi-class extension</head><p>As an extension to the binary classification task, we next show how Theorem 3.3 could be generalized to the multiclass setting under two broad families of noise transition model. We assume Assumption 3.1 holds in the multi-class setting. And for Y, Y ? [K], we extend the definition of model confidence to multi-class classification tasks as:</p><formula xml:id="formula_21">Definition 3.5 (Model confidence of sample (x, y) (K-class classification)). Given a model f , a sample x with its target label y ? [K], the model confidence score of f w.r.t. sample x is defined as MC(f ; x, y) = f (x) y ? 1 K?1 i =y f (x) i .</formula><p>Sparse noise transition matrix Sparse noise model (Wei &amp; Liu, 2021) assumes K is an even number. For c ? [ K 2 ], i c &lt; j c , sparse noise model specifies K 2 disjoint pairs of classes (i c , j c ) to simulate the scenario where particular pairs of classes are ambiguity and misleading for human annotators. The off-diagonal element of T reads T ic,jc = e 0 , T jc,ic = e 1 . Suppose e 0 + e 1 &lt; 1, the diagonal entries become T ic,ic = 1 ? e 0 , T jc,jc = 1 ? e 1 . Clearly, our conclusions in Theorem 3.3 extends directly to the sparse noise transition matrix by simply splitting the K-class classification task into K 2 disjoint binary ones.</p><p>Symmetric noise transition matrix Symmetric noise model <ref type="bibr" target="#b21">(Kim et al., 2019</ref>) is a widely accepted synthetic noise model in the literature of learning with noisy labels. The symmetric noise model generates the noisy labels by randomly flipping the clean label to the other possible classes with probability . ?i = j, T i,j = K?1 , and the diagonal entry is T i,i = 1 ? . Define the optimal r under the unified setting in the multi-class setting as r opt := (K?1)?r * ?K? (K?1)?K? , Theorem 3.3 can be extended to the multi-class setting as: Theorem 3.6. Under Assumption 3.1, suppose the symmetric noise rate is not too large, i.e, &lt; K?1 K , learning with smooth rate r = r opt under (X, Y ) ? D yields f * D : ? When noise rate &lt; (K?1)?r * K , r = r opt &gt; 0 (LS);</p><p>? When noise rate = (K?1)?r * K , r = 0 (VL);</p><p>? When noise rate &gt; (K?1)?r * K , r = r opt &lt; 0 (NLS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Clean empirical risk v.s. noisy empirical risk</head><p>Now we empirically verify Theorem 3.2 under symmetric noise setting, which relates the risk in the noisy setting to the clean ones. Assume the the noise label is generated through the symmetric noise transition matrix. We name the noisy risk as E (X, Y )? D (f (X), Y GLS,r ) , which is the objective in Eqn. (4).</p><p>We use a UCI dataset (Waveform, binary classification) for illustration where the value of r * is approximately 0. When the noise rates are 0.1, 0.2, 0.3, 0.4, the optimal smooth rate <ref type="table">Table 1</ref>. Test accuracies of LS, VL, NLS on clean and noisy UCI Heart, Splice datasets, with best two smooth rates highlighted (green: NLS; red: VL or LS). We adopt the two independent sample T-test (5 non-negative smooth rates V.S. the last 5 rows of reported negative smooth rates) to verify the overall performance comparisons between VL/LS and NLS. p-value is highlighted in green if NLS generally returns a higher accuracy (i.e., t-value&lt; 0) than VL/LS, otherwise, in red. Results on more benchmark datasets are given in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Smooth Rate</head><p>UCI-Heart UCI-Splice  should be ?0.25, ?0.67, ?1.5, ?4 according to Eqn. (6). The estimated noisy risk of LS/VL/NLS on these noise settings can be summarized in <ref type="table">Table 1</ref>. Clearly, when e = 0.1, r = ?0.25 is closest to the estimated (clean) true risk (also returns the best test accuracy among these smooth rates). Similar observations hold for all other e. Learning with r opt on the noisy data yields the closest risk to the corresponding clean risk with r * ! r * and r opt on CIFAR datasets <ref type="bibr" target="#b23">(Krizhevsky et al., 2009)</ref> When learning with a larger scale and more complex dataset, like CIFAR-10 and CIFAR-100, models are prone to converge on a local optimal solution rather than the global optimum. This phenomenon occurs frequently in NLS which ends up with performance degradation. Thus, in <ref type="table" target="#tab_5">Table 3</ref> and 4, when learning with noisy labels, we report the better performance of LS and NLS between direct training and loading the same warm-up model. We observe that the performance of NLS is more competitive than LS when learning with clean data. Clearly, NLS outperforms LS in CIFAR-10 and CIFAR-100 under various synthetic noise settings. The gap is larger when the noise rates are high. The results of two independent sample T-test 1 further verify this conclusion.  </p><formula xml:id="formula_22">ei = 0 ei = 0.1 ei = 0.2 ei = 0.3 ei = 0.4 ei = 0 ei = 0.1 ei = 0.2 ei = 0.3 ei = 0.4 r = 0.8 0.</formula><formula xml:id="formula_23">0.845 ropt = [0.0, 0.6] [-8.0, -1.0] -8.0 -4.0 -8.0 0.8 [-0.6, -0.4] [-8.0, -4.0] -8.0 -8.0 p-value = 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The Impacts on the Model Confidence</head><p>Continuing the discussion of differed model confidence in the previous section, we now empirically explore how such differences distinguish LS and NLS.</p><p>Remember that when the label is clean (e 0 = e 1 = 0), Eqn.</p><p>(3) reduces to:</p><formula xml:id="formula_24">min f ?F E (X,Y )?D (f (X), Y ) + r 2 ? E (X,Y )?D (f (X), 1 ? Y ) ? (f (X), Y ) Term MC (f ;X,Y )</formula><p>. <ref type="formula">(7)</ref> The difference between LS and NLS lie in the weight of Term MC (f ; X, Y ) when learning with clean labels: NLS encourages high MC (f ; X, Y ) and MC(f ; X, Y ) while LS has an opposite effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Side-effects of over-confident</head><p>We adopt the generation of 2D (binary) synthetic dataset from <ref type="bibr" target="#b0">(Amid et al., 2019)</ref> by randomly sampling two circularly distributed classes. The inner annulus indicates one class (blue), while the outer annulus denotes the other class (red). We hold 20% data samples for performance comparison. The test accuracy is annotated above each plot.</p><p>In <ref type="figure" target="#fig_3">Figure 3</ref>, the colored bands depict the different levels of prediction probabilities: light blue + orange bands indicate samples that satisfy MC &lt; 0.4 (low model confidence). When learning with the clean data, a non-positive smooth rate may yield over-confidence on the model prediction and a relatively low test accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Label noise reduces model confidence</head><p>Recent works <ref type="bibr" target="#b2">(Liu, 2021;</ref><ref type="bibr" target="#b4">Cheng et al., 2021a)</ref> have demonstrated that with the presence of label noise, learning with noisy labels directly will eventually result in unconfident model predictions. Continuing the synthetic 2D dataset, we flip the clean labels according to a symmetric noise transition matrix with noise rate e i for both classes. With the presence of label noise in <ref type="figure" target="#fig_4">Figure 4</ref>, the trained models generally become less confident on its predictions. Besides, when the smooth rate increases from negative to positive, more samples are of uncertain predictions. Thus, a smaller/negative smooth rate is beneficial when the noise rate increases by encouraging more confident predictions. The test accuracy is annotated above each plot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Model confidence on CIFAR-10 test dataset</head><p>When trained on symmetric 0.2 noisy CIFAR-10 training dataset (see <ref type="figure" target="#fig_5">Figure 5)</ref>, with the decreasing of smooth rates (from right to left), the model confidence on correct predictions gradually approach to its maximum, while for wrong predictions, the model confidence converges to its minimum value. We observe that NLS makes the model prediction become over-confident on correct predictions and in-confident on wrong predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Connection to Other Robust Methods</head><p>In this section, we aim to theoretically explore the connection between NLS and popular robust methods such as backward/forward loss correction <ref type="bibr">(Natarajan et al., 2013;</ref><ref type="bibr">Patrini et al., 2017)</ref>, NLNL <ref type="bibr" target="#b21">(Kim et al., 2019)</ref> and peer loss <ref type="bibr">(Liu &amp; Guo, 2020)</ref>, under the unified setting. We defer the corresponding empirical verification to Appendix B. </p><formula xml:id="formula_25">E (X, Y )? D ? (f (X), Y ) = min f ?F E (X, Y )? D ? (f (X), Y ) = min f ?F E (X, Y )? D (f (X), Y GLS,rLC ) + ? LC ? E X,Y =1 (f (X), 1) ? (f (X), 0) Bias-LC .</formula><p>The incurred Bias-LC controls the model confidence on (X, Y = 1) ? D f . Note that when the noise rate is not substantially high, i.e., e 0 ? [0, 1 2 ), ? LC &gt; 0. Then, compared with loss correction, NLS with smooth rate r LC makes the model f to be less confident on (X, Y = 1) ? D + f and more confident on (X, Y = 1) ? D ? f (wrong predictions). However, the impact of term Bias-LC is diminishing when either e ? ? 0 (symmetric noise rates) or e 0 ? 0 (low noise rates) as specified in Theorem 5.2.</p><p>Theorem 5.2. Assume the noise transition matrix is symmetric, i.e., e ? = 0, backward and forward loss correction are a special form of NLS with smooth rate r LC .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Learning from complementary labels</head><p>Complementary labels <ref type="bibr" target="#b17">(Ishida et al., 2017)</ref> were firstly introduced to mitigate the cost of collecting data. Rather than encouraging the model to fit directly on the target, learning from complementary labels trains the model to not fit on the complementary label which differs from the target. Later, an indirect training method "Negative Learning" (NL) <ref type="bibr" target="#b21">(Kim et al., 2019)</ref> was proposed to reduce the risk of providing incorrect information with the presence of noisy labels and is robust to label noise in multi-class classification tasks. A more generic unbiased risk estimator of learning with complementary labels was proposed <ref type="bibr" target="#b18">(Ishida et al., 2019)</ref>, a popular case is: <ref type="bibr">CL</ref> </p><formula xml:id="formula_26">(f (X), Y ) := (f (X), Y ) ? (f (X), 1 ? Y ).</formula><p>Theorem 5.3. Learning from complementary labels with CL is equivalent to NLS with smooth rate r CL ? ??:</p><formula xml:id="formula_27">min f ?F E (X, Y )? D CL (f (X), Y ) = min f ?F E (X, Y )? D [ (f (X), Y GLS,rCL??? )].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Peer loss functions</head><p>Peer loss functions (Liu &amp; Guo, 2020) proposed a family of robust loss measures which do not require the knowledge of noise rates. The mathematical representation of peer loss functions is <ref type="bibr">PL</ref> </p><formula xml:id="formula_28">(f (X), Y ) := (f (X), Y ) ? (f (X 1 ), Y 2 ), where (X i , Y i ) ? D.</formula><p>The second term of the peer loss evaluates on randomly paired data samples and labels (X 1 and Y 2 for two randomly selected samples) to punish f from overly fitting on noisy labels.</p><p>Proposition 5.4. For r PL := 2 ? P( Y = 1), ? P L := 1 ? r PL , risk minimization of peer loss is equivalent to negative label smoothing regularization with an extra term Bias-PL, i.e.,</p><formula xml:id="formula_29">min f ?F E (X, Y )? D PL (f (X), Y ) = min f ?F E (X, Y )? D (f (X), Y ) ? (f (X), Y GLS,rPL ) + ? P L ? E X, Y =1 (f (X), 1) ? (f (X), 0) Bias-PL .</formula><p>The incurred term Bias-PL controls the model confidence on (X, Y = 1) ? D and has a diminishing effect as P( Y = 1) ? 1/2. Generally, the peer loss relates to the unified setting (GLS) as the negatively weighted GLS term appears to be a regularizer. Note that we have access to the <ref type="table">Table 5</ref>. Performance comparisons on synthetic noisy CIFAR datasets: we adopt the same model architecture for all methods (ResNet 34 <ref type="bibr" target="#b15">(He et al., 2016)</ref>), best achieved test accuracy is reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>CIFAR-10, Symmetric CIFAR-10, Asymmetric CIFAR-100, Symmetric ? = 0.2 ? = 0.4 ? = 0.6 ? = 0.2 ? = 0.3 ? = 0.4 ? = 0.6 Theorem 5.5. When the noisy labels have equal prior, i.e., P( Y = 0) = P( Y = 1), the peer loss is a special form of NLS regularization with the smooth rate r PL . Besides,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross</head><formula xml:id="formula_30">min f ?F E (X, Y )? D PL (f (X), Y ) = min f ?F E (X, Y )? D (f (X), Y GLS,r??? ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Practical significance</head><p>In <ref type="table">Table 5,</ref>   at different scenarios. The popularity of label smoothing is largely due to its simplicity and being complementary, so we expect our observations for NLS can be combined with other SOTA methods to further improve model performance in the high-noise regime. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we provide understandings for whether should we adopt label smoothing or not when learning with noisy labels. We show that learning with negatively smoothed labels explicitly improves the confidence of model prediction. This key property acts as a significant role when the confidence of model prediction drops. In contrast to existing works that promote the use of positive label smoothing, we show both theoretically and empirically the advantage of a negative smooth rate when the label noise rate increases. We also bridge the gap between negative label smoothing and existing learning with noisy label solutions, which further demonstrates the importance of negative/not label smoothing. In a nutshell, our observations provide new understanding for the effects of label smoothing, especially when the training labels are imperfect. Future works include exploring the benefits of negative labels in other tasks.</p><p>Kumar, A. and Amid, E. Constrained instance and class reweighting for robust learning under label noise. arXiv preprint arXiv:2111.05428, 2021.</p><p>Li, W., Dasarathy, G., and Berisha, V. Regularization via structural label smoothing. In International Conference on Artificial Intelligence and Statistics, pp. 1453-1463. PMLR, 2020.</p><p>Liu, S., Niles-Weed, J., Razavian, N., and Fernandez-Granda, C. Early-learning regularization prevents memorization of noisy labels. Advances in neural information processing systems, 33:20331-20342, 2020.</p><p>Liu, S., Li, X., Zhai, Y., You, C., Zhu, Z., Fernandez-Granda, C., and Qu, Q. Zhang, X., Zhao, J., and LeCun, Y. Character-level convolutional networks for text classification. Advances in neural information processing systems, 28, 2015.</p><p>Zhou, H., Song, L., Chen, J., Zhou, Y., Wang, G., Yuan, J., and Zhang, Q. Rethinking soft labels for knowledge distillation: A bias-variance tradeoff perspective. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum? id=gIHd-5X324.</p><p>Zhu, Z., Dong, Z., Cheng, H., and Liu, Y. A good representation detects noisy labels. arXiv preprint arXiv:2110.06283, 2021a.</p><p>Zhu, Z., Liu, T., and Liu, Y. A second-order approach to learning with instance-dependent label noise. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10113-10123, 2021b.</p><p>Zhu, Z., Song, Y., and Liu, Y. Clusterability as an alternative to anchor points when learning with noisy labels.</p><p>In Proceedings of the 38th International Conference on Machine Learning, ICML '21, 2021c.</p><p>Zhu, Z., Wang, J., and Liu, Y. Beyond images: Label noise transition matrix estimation for tasks with lower-quality features. arXiv preprint arXiv:2202.01273, 2022.</p><p>The Appendix is organized as follows.</p><p>? Section A presents the full version of related works.</p><p>? Section B includes empirical validations of theoretical conclusions in Section 5.</p><p>? Section C discusses practical considerations of the robustness for LS and NLS.</p><p>? Section D shows additional experiments on synthetic dataset and UCI datasets.</p><p>? Section E illustrates the bias and variance trade-off when learning with LS and NLS from clean data.</p><p>? Section F includes omitted proofs for theoretical conclusions in the main paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Full Version of Related Works</head><p>Our work supplements to two lines of related works.</p><p>Learning with noisy labels Annotated labels from human labelers usually consists of an non-negligible amount of mis-labeled data samples. Making deep neural nets perform robust training on "noisily" labeled datasets remains a challenge. Classical approaches of learning with noisy labels assume the noisy labels are independent to features. They firstly estimate the noise transition matrix <ref type="bibr">(Liu &amp; Tao, 2015;</ref><ref type="bibr">Menon et al., 2015;</ref><ref type="bibr" target="#b14">Harish et al., 2016;</ref><ref type="bibr">Patrini et al., 2017;</ref><ref type="bibr" target="#b4">Zhu et al., 2021a;</ref><ref type="bibr">Yang et al., 2021;</ref><ref type="bibr" target="#b3">Cheng et al., 2022;</ref><ref type="bibr">Zhu et al., 2022)</ref>, then proceed with a loss correction <ref type="bibr">(Natarajan et al., 2013;</ref><ref type="bibr">Patrini et al., 2017;</ref><ref type="bibr">Liu &amp; Tao, 2015)</ref> to mitigate label noise. Recent works mainly focus on: (1) proposing robust loss functions <ref type="bibr" target="#b21">(Kim et al., 2019;</ref><ref type="bibr">Liu &amp; Guo, 2020;</ref><ref type="bibr">Wei &amp; Liu, 2021;</ref><ref type="bibr" target="#b10">Englesson &amp; Azizpour, 2021b;</ref><ref type="bibr">a)</ref> to train deep neural nets directly without the knowledge of noise rates, or design a pipeline which dynamically select and train on "clean" samples with small loss <ref type="bibr" target="#b19">(Jiang et al., 2018;</ref><ref type="bibr" target="#b13">Han et al., 2018;</ref><ref type="bibr">Yu et al., 2019;</ref><ref type="bibr">Yao et al., 2020a;</ref><ref type="bibr">Xia et al., 2021b)</ref>; (2) hindering the memorization on noisy labels <ref type="bibr">(Xia et al., 2020a;</ref><ref type="bibr">Liu et al., 2020;</ref><ref type="bibr" target="#b5">Cheng et al., 2021b;</ref><ref type="bibr" target="#b2">Liu et al., 2021;</ref><ref type="bibr">Wei et al., 2021;</ref><ref type="bibr">Bai et al., 2021;</ref><ref type="bibr">Yi et al., 2022)</ref>; (3) sample-level re-weighting to mitigate the impacts of wrong labels <ref type="bibr">(Liu &amp; Tao, 2016;</ref><ref type="bibr">Majidi et al., 2021;</ref><ref type="bibr">Kumar &amp; Amid, 2021;</ref><ref type="bibr">Liu &amp; Wang, 2021)</ref>. More recently, several approaches target at addressing more challenging noise settings, such as group/instance-dependent label noise <ref type="bibr" target="#b4">(Cheng et al., 2021a;</ref><ref type="bibr">Wang et al., 2021;</ref><ref type="bibr" target="#b2">Berthon et al., 2021;</ref><ref type="bibr" target="#b5">Zhu et al., 2021b;</ref><ref type="bibr" target="#b7">Dawson &amp; Polikar, 2021;</ref><ref type="bibr" target="#b20">Jiang et al., 2022)</ref>, or considering more practical applications such as open-set data <ref type="bibr">(Xia et al., 2020b;</ref><ref type="bibr">Wei et al., 2021;</ref><ref type="bibr">Xia et al., 2021a)</ref>, partial label learning <ref type="bibr" target="#b11">(Feng et al., 2020;</ref><ref type="bibr">Lv et al., 2021;</ref><ref type="bibr" target="#b3">Wang et al., 2022)</ref>, samples with multiple noisy annotations <ref type="bibr">(Wei et al., 2022a;</ref>.</p><p>Understanding the effect of label smoothing Learning with one-hot labels is prone to over-fitting, soft label learning then naturally draws attentions of machine learning researchers. Successful applications of soft label learning include the label distribution learning <ref type="bibr" target="#b12">(Geng, 2016)</ref> which provides an instance with description degrees of all the labels. Label smoothing (LS) (Szegedy et al., 2016) is another arising learning paradigm that uses positively weighted average of both the hard training labels and uniformly distributed soft labels. Empirical studies have demonstrated the effectiveness of LS in improving the model performance <ref type="bibr">(Pereyra et al., 2017;</ref><ref type="bibr">Szegedy et al., 2016;</ref><ref type="bibr">Vaswani et al., 2017;</ref><ref type="bibr" target="#b6">Chorowski &amp; Jaitly, 2017)</ref> and model calibration <ref type="bibr">(M?ller et al., 2019)</ref>. However, knowledge distilling a teacher network (trained on smoothed labels) into a student network is much less effective <ref type="bibr">(M?ller et al., 2019)</ref>. Later, generalization effects of more advanced forms of label smoothing was studied, such as structural label smoothing <ref type="bibr">(Li et al., 2020)</ref>. More recently, it was shown that an appropriate label smoothing regularizer with reduced label variance boosts the convergence <ref type="bibr" target="#b11">(Xu et al., 2020)</ref>. When label noise presents, <ref type="bibr" target="#b2">(Liu, 2021)</ref> gives theoretical justifications for the memorizing effects of label smoothing. And the effectiveness of label smoothing in mitigating label noise is investigated in <ref type="bibr">(Lukasik et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Empirical Validations of Main Theorems</head><p>In this section, we empirically validate our main theoretical conclusions in Section 5, i.e, the connection between LS/NLS and popular methods.</p><p>We compare the unified setting (GLS) with backward correction <ref type="bibr">(Natarajan et al., 2013)</ref>, forward correction <ref type="bibr">(Patrini et al., 2017)</ref> and peer loss (Liu &amp; Guo, 2020) on CIFAR-10 dataset. To approximate the performance of backward/forward Loss Correction, we adopt GLS with smooth rate <ref type="bibr">( ?1)</ref> . As for the approximation of peer loss, we choose (f (X), Y ) ? (f (X), Y GLS,r=0.5 ) which is equivalent to NLS when r ? ??. Experiment results in <ref type="table" target="#tab_11">Table 7</ref> on CIFAR-10 under symmetric noise settings demonstrate that the equivalent forms of GLS are robust to label noise. Explanation of the performance gap In practice, we adopt the same hyper-parameter setting as used for all other smooth rates for GLS form <ref type="bibr">(VL, LS and NLS)</ref>. Loss corrections will firstly warm-up with the cross-entropy loss, estimate the noise transition matrix with this pre-trained model, and then proceed to train with the backward/forward corrected loss. Peer loss functions adopt a dynamical adjustment for learning rate. The warming up, estimation error of noise transition matrix as well as the special hyper-parameter settings explain performance gaps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Practical Consideration of LS and NLS</head><p>In the main paper, we theoretically show when we should adopt NLS and LS. In this section, we discuss more practical considerations, including the optimal smoothing parameter, how to reduce the impacts of bias terms, and multi-class extensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. The optimal smoothing parameter</head><p>In practice, we don't have access to noise rates e i .</p><p>Our work does not intend to particularly focus on the noise rate estimation. For readers interested in the noise rate estimation, please refer to <ref type="bibr">(Liu &amp; Tao, 2015;</ref><ref type="bibr">Menon et al., 2015;</ref><ref type="bibr" target="#b14">Harish et al., 2016;</ref><ref type="bibr">Patrini et al., 2017;</ref><ref type="bibr">Yao et al., 2020b;</ref><ref type="bibr">Zhu et al., 2021c)</ref>. To estimate r opt = r * ?2e 1?2e , one can simply assume r * ? 0. And the noise rate e is estimable by a large family of noise estimation methods mentioned above. Our practical observations show that NLS with a CE warm-up is not sensitive to the negative smooth rate, for example, on CIFAR-10 and CIFAR-100 synthetic noisy datasets, r &lt; ?1.0 frequently achieves best results (see <ref type="table" target="#tab_5">Table 3</ref> in the main paper). Our current contribution focuses on understanding the generalized label smoothing, and we prefer leaving the task of identifying the optimal smooth rate to future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Making LS and NLS more robust to label noise</head><p>There is a line of related works targeting at distinguishing clean labels from the noisy labels. Current literature in selecting clean samples from noisily labeled dataset is based on the empirical evidence that samples with noisy/wrong labels have a larger loss than clean ones. For interested readers, please refer to <ref type="bibr" target="#b13">(Han et al., 2018;</ref><ref type="bibr" target="#b19">Jiang et al., 2018;</ref><ref type="bibr">Yu et al., 2019;</ref><ref type="bibr">Yao et al., 2020a;</ref><ref type="bibr">Wei et al., 2020;</ref><ref type="bibr">Northcutt et al., 2021)</ref>. Compared with the risk minimization over the clean data distribution (X, Y ) ? D, learning directly with GLS on the noisy distribution (X, Y ) ? D will result in an extra term (e 1 ? e 0 ) ? (1 ? r) ? E (X,Y =1)?D [ (f (X), 0) ? (f (X), 1)] compared to the clean scenario. Empirically, we can estimate the bias term, perform a bias correction by subtracting the estimated bias term from the objective function in Eqn. (3).</p><p>Suppose we have access to a clean distribution D clean which consists of selected clean samples. Denote the estimated noise rates as? i , when e ? = 0, in order to make LS/NLS be more robust to label noise and fit on the optimal distribution Y * , we improve by performing a model confidence correction on the dominating class through:</p><formula xml:id="formula_31">min f ?F E (X, Y )? D f (X), Y GLS,r ?(? 1 ?? 0 ) ? (1 ? r) ? E (X,Y =1)?Dclean f (X), 0 ? f (X), 1 confidence correction .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Additional Experiment Results and Details</head><p>In this section, we include more experiment results, observations and details for learning with LS/NLS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1. Experiment details on CIFAR-10, CIFAR-100</head><p>We firstly introduce experiment details on CIFAR-10 dataset adopted in our experiment designs.</p><p>Training settings of clean CIFAR-10 dataset <ref type="bibr" target="#b23">(Krizhevsky et al., 2009</ref>) We adopted ResNet34 <ref type="bibr" target="#b15">(He et al., 2016)</ref>, trained for 200 epochs with batch-size 128, SGD <ref type="bibr">(Robbins &amp; Monro, 1951)</ref> optimizer with Nesterov momentum of 0.9 and weight decay 1e-4. The learning rate of first 100 epochs is 0.1. Then it multiples with 0.1 for every 50 epochs.</p><p>Generating noise labels on CIFAR datasets We adopt symmetric noise model which generates noisy labels by randomly flipping the clean label to the other possible classes with probability . And we set = 0.2, 0.4, 0.6 for CIFAR-10, = 0.4, 0.6 for CIFAR-100. We also make use of asymmetric noise model. The asymmetric noise is generated by flipping the true label to the next class with probability . We set = 0.2, 0.3 for CIFAR-10.</p><p>Training settings of synthetic noisy CIFAR datasets The generation of symmetric noisy dataset is adopted from <ref type="bibr" target="#b4">(Cheng et al., 2021a)</ref>. The symmetric noise rates are [0.2, 0.4, 0.6]. We choose two methods to train LS and NLS.</p><p>? Direct training: this setting is the same as training on clean CIFAR-10 dataset.</p><p>? Warm-up: in this case, we firstly train a ResNet34 model with Cross-Entropy loss for 120 epochs. For this warm-up, the only difference in hyper-parameter setting is the learning rate, where the initial learning rate is 0.1 and it multiplies 0.1 for every 40 epochs. After the warm-up, LS/NLS loads the same pre-trained model and trains for 100 epochs with learning rate 1e-6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. Why NLS is overlooked?</head><p>When learning from a relative large scale dataset, NLS tends to push the model become overly confident early in the training. The poor performances of NLS (direct-train) in <ref type="table" target="#tab_12">Table 8</ref> explain why NLS is neglected. When there is no warm-up, training NLS directly without warming up will reach a 88% ? 92% test accuracy on the clean data. The performance will degrade much more significantly than LS when the noise level is high or |r| is large. In <ref type="table" target="#tab_12">Table 8</ref>, we provide the comparisons between direct-train and warm-up in several settings. The improvement bring by a warm-up procedure becomes much more significantly in the high noise regime. NLS makes the classifier be overly confident at the early training which results in converging to a bad local optimum (without CE warm-up, NLS frequently results in a worse performance in CIFAR-10 and CIFAR-100). Since the model will usually fit on the clean data first, then over-fits on the noisy ones (Liu et al., 2020), a large number of approaches (such as Loss corrections <ref type="bibr">(Patrini et al., 2017)</ref>, Peer Loss (Liu &amp; Guo, 2020), etc) adopt a CE warm-up firstly. Note that there is no difference in the computing costs between NLS (with CE warmup) and CE loss, proceeding with NLS to enhance the model confidence makes NLS much more competitive in the high noise regime, also gives practical insights on how to make NLS work better when learning with clean data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3. Experiment details on synthetic datasets and UCI</head><p>We introduce experiment details on synthetic datasets and UCI datasets adopted in our experiment designs.</p><p>Generation of synthetic dataset In the synthetic (Type 1) dataset, we generate 500 points for both classes. Class +1 distributes inside the circle with radius 0.25. Class -1 generates by randomly sampling 500 data points in the annulus with inner radius 0.28 and outer radius 0.45. As for synthetic (Type 2) dataset, we uniformly assign labels for 50% samples in the annulus (with inner radius 0.22, outer radius 0.31) based on Type 1 dataset.</p><p>Generating noisy labels on synthetic datasets and UCI datasets Note that these datasets are all binary classification datasets, each label in the training and validation set is flipped to the other class with probability e, and we set e = 0.1, 0.4 for synthetic Type 1 dataset, e = 0.1, 0.3 for synthetic Type 2 dataset.</p><p>Training settings of synthetic datasets For both types of synthetic datasets, we adopted a three-layer ReLU Multi-Layer Perceptron (MLP), trained for 200 epochs with batch-size 128 and Adam <ref type="bibr" target="#b22">(Kingma &amp; Ba, 2014)</ref> optimizer. The initial learning rate is 0.1, and it multiplies 0.1 for every 40 epochs.</p><p>Training settings of UCI datasets <ref type="bibr" target="#b8">(Dua &amp; Graff, 2017</ref>) We adopted (Liu &amp; Guo, 2020) a two-layer ReLU Multi-Layer Perceptron (MLP) for classification tasks on multiple UCI datasets, trained for 1000 episodes with batch-size 64 and Adam <ref type="bibr" target="#b22">(Kingma &amp; Ba, 2014)</ref> optimizer. We report the best performance for each smooth rate under a set of learning rate settings, [0.0007, 0.001, 0.005, 0.01, 0.05].</p><p>D.4. Additional experiment on r * and r opt r * and r opt on synthetic dataset We generate 2D (binary) synthetic dataset by randomly sampling two circularly distributed classes. The inner annulus indicates one class (blue), while the outer annulus denotes the other class (red). Clearly, the generated synthetic dataset is well-separable (Type 1) and we hold 20% data samples for performance comparison. The noise transition matrix takes a symmetric form with noise rate e i for both classes. To simulate the scenario where the clean data may not be perfectly separated due to a non-negligible amount of uncertainty samples clustering at the decision boundary, we flip the label of 50% samples near the intersection of two annulus to the other class (Type 2). As specified in <ref type="table" target="#tab_13">Table 9</ref>, r * = [0.1, 0.4] for Type 1 data and r * = [0.0, 0.2] for Type 2 data. With the presence of label noise, the distribution of r opt shifts from non-negative ones to negative values. Even though NLS fails to outperform LS on clean data, we observe that NLS is less sensitive to noisy labels. Data with high level noise rates clearly favor NLS with a low smooth rate! r * and r opt on more UCI datasets We further test the performance of generalized label smoothing on 7 more UCI datasets (Heart, Breast 1, Breast 2, Diabetes, German, Image and Waveform). Our observation remains unchanged: there exists a general trend that with the increasing of noise rates, NLS becomes much more competitive than LS. Here, we attach the results of 4 additional UCI datasets for illustration. The noisy labels are generated by a symmetric noise transition matrix with noise rate e i = [0.1, 0.2, 0.3, 0.4]. As highlighted in <ref type="table" target="#tab_14">Table 10</ref>, r opt appears with positive values when the data is clean (same as r * ) or of a low noise rate. With the increasing of noise rates, NLS becomes more competitive than LS. We color-code different noise regimes where either LS (red-ish) or NLS (green-ish) outperforms the other. Clearly, there is a separation of the favored smoothing rate for different noise scenarios (upper left &amp; low noise for LS, bottom right &amp; high noise for NLS).</p><p>r * and r opt on AGNews We next provide an additional empirical justification of Theorem 3.1. Note that when we have access to r * , Theorem 3.6 reveals what smooth rate recovers the performance on the clean data when learning with noisy labels. We adopt an NLP dataset AGNews <ref type="bibr">(Zhang et al., 2015)</ref> for illustration. In <ref type="table" target="#tab_15">Table 11</ref>, we do observe that r opt achieves the best performance for most noise settings. D.5. Additional experiment results on model confidence NLS improves model confidence on Synthetic Type 2 dataset In this case, the clean data that are close to decision boundary distributes randomly. In <ref type="figure" target="#fig_7">Figure 6</ref>-7, the colored bands depict the different levels of prediction probabilities. When the smooth rate increases from negative to positive, more samples fall in the orange and light blue band which indicates uncertain predictions. When the smooth rate increases from negative to positive, learning with smoothed labels will result in more uncertain predictions. With the increasing of noise rates (e i = 0 ? 0.4), Learning with a fixed smooth rate generally becomes less confident on its predictions. Thus, a smaller smooth rate is required when the noise rate increases.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.6. Effect of LS and NLS on pre-logits</head><p>We visualise the pre-logits of a ResNet-34 for three classes on CIFAR-10. We adopt the method from <ref type="bibr">(M?ller et al., 2019)</ref> which illustrates how representations differ between penultimate layers of networks trained with different smooth rates in GLS. In <ref type="figure" target="#fig_9">Figure 8</ref>, NLS makes the model f be confident on her predictions and the distances between three clusters are clearly larger than those appeared in Vanilla Loss and LS. Proof. With the Rademacher bound on the maximal deviation between risks and empirical ones, for ?f ? F and with probability at least 1 ? ?, we have: </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Optimal smooth rates on UCI datasets with different label noise rates (possible to have tied smooth rates).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Decision between NLS, LS given e, r * .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Model confidence visualization of NLS, VL, and LS on synthetic data (Type 1) with the clean data. The optimal smooth rate falls in [0, 0.4]. (left: NLS; middle: Vanilla Loss; right: LS).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Model confidence visualization of NLS, VL, and LS on synthetic data (Type 1) with noise rate ei = 0.4. The optimal smooth rate is ?0.4. (left: NLS; middle: Vanilla Loss; right: LS).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Model confidence distribution of correct and wrong predictions on CIFAR-10 test data samples. (From left to right: NLS (r = ?0.8, ?0.4), Vanilla Loss, LS (r = 0.4), trained on symmetric 0.2 noisy CIFAR-10 dataset).5.1. Loss correctionLoss correction (Patrini et al., 2017) studies two robust loss designs which are based on the knowledge of nonsingular noise transition matrix T . The backward correction ? (f (X), Y ) re-weights the loss (f (X), Y ) by T ?1 Y , Y wit? Y being the model predicted label, while the proposed forward correction ? (f (X), Y ) multiplies the model predictions by T . Proposition 5.1. For r LC := 2e0 2e0?1 &lt; 0, ? LC := e ? ? 1 1?2e0 , risk minimization of both backward and forward correction (with the knowledge of noise rates) are equivalent to the combination of NLS and an extra bias term Bias-LC min f ?F</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>we compare VL(CE), LS and NLS with several robust methods in synthetic noisy CIFAR datasets. Clearly, LS and NLS can be viewed as competitive and efficient robust loss functions which outperform Cross Entropy, Bootsrap (Reed et al., 2014), SCE (Wang et al., 2019), APL (Ma et al., 2020) and Forward loss correction (FLC) (Patrini et al., 2017) in most settings. We also provide experimental results of LS and NLS on real-world human noise benchmarks: CIFAR-N (Wei et al., 2022b) and Clothing 1M (Xiao et al., 2015), along with several baseline methods for comparisons, i.e., backward loss correction (BLC) (Natarajan et al., 2013; Patrini et al., 2017), forward loss correction (FLC) (Patrini et al., 2017), Peer Loss (PL) (Liu &amp; Guo, 2020), and F-div (Wei &amp; Liu, 2021).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>Model confidence visualization of NLS, VL and LS on synthetic data (Type 2) with the clean data. r * ? [0, 0.2]. (left: NLS; middle: Vanilla Loss; right: LS).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>Model confidence visualization of NLS, VL and LS on synthetic data (Type 2) with noise rate ei = 0.3. ropt = ?0.5. (left: NLS; middle: Vanilla Loss; right: LS).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 .</head><label>8</label><figDesc>Effect of GLS on pre-logits (left: NLS; middle: Vanilla Loss; right: LS; trained with symmetric 0.2 noisy CIFAR-10 training dataset).E (X,Y )?D f (X), 1 ? Y ? f (X), Y M-Inc1 +? 2 ? E X,Y =1 f (X), 0 ? f (X), 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>max f ?F |R r emp (f ) ? R r exp (f )| ?2R( GLS,r ? F) + GLS,r ? GLS,r ? log(1/?) 2N ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>To Smooth or Not? When Label Smoothing Meets Noisy Labels label Y LS,r with smooth rate r ? [0, 1] generates y LS,r</figDesc><table><row><cell>i</cell><cell>as</cell></row><row><cell>(Szegedy et al., 2016):</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>The difference between the empirical true risk of Y * on the clean data and empirical risk of LS/VL/NLS on noisy labels (UCI-Waveform data): r * , empirical true risk, and empirical noisy risks of ropt under various noise levels are highlighted in purple. What is the practical distribution of r * and r opt ? r * and r opt on UCI datasets<ref type="bibr" target="#b8">(Dua &amp; Graff, 2017)</ref> As for UCI datasets, we pick Twonorm and Splice for illustration. The noisy labels are generated by a symmetric noise transition matrix with noise rate e i = [0.1, 0.2, 0.3, 0.4]. As highlighted inTable 1 (top of this page), r opt appears with positive values when the data is clean (same as r * ) or of a low noise rate. With the increasing of noise rates, the performance of LS results in a much larger degradation compared</figDesc><table><row><cell cols="5">Smooth rate Risk (clean) Risk (e i = 0.1) Risk (e i = 0.2) Risk (e i = 0.3)</cell></row><row><cell>r = 0.8</cell><cell>0.6773</cell><cell>0.6831</cell><cell>0.6873</cell><cell>0.6899</cell></row><row><cell>r = 0.6</cell><cell>0.6295</cell><cell>0.6521</cell><cell>0.6689</cell><cell>0.6833</cell></row><row><cell>r = 0.4</cell><cell>0.5437</cell><cell>0.5994</cell><cell>0.6408</cell><cell>0.6718</cell></row><row><cell>r = 0.2</cell><cell>0.4134</cell><cell>0.5212</cell><cell>0.5956</cell><cell>0.6550</cell></row><row><cell>r  *  = 0.0</cell><cell>0.1798</cell><cell>0.4057</cell><cell>0.5399</cell><cell>0.6314</cell></row><row><cell>r = ?0.25</cell><cell>-36.8095</cell><cell>0.1983</cell><cell>0.4381</cell><cell>0.5957</cell></row><row><cell>r = ?0.67</cell><cell>-333.1283</cell><cell>-28.3508</cell><cell>0.2167</cell><cell>0.5132</cell></row><row><cell>r = ?1.5</cell><cell>-97.4378</cell><cell>-61892.8047</cell><cell>-94.9509</cell><cell>0.1911</cell></row><row><cell>3.6.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>with NLS. We color-code different noise regimes where either VL/LS (red-ish) or NLS (green-ish) outperforms the other. Clearly there is a separation of the favored smoothing rate for different noise scenarios (upper left &amp; low noise for VL/LS, bottom right &amp; high noise for NLS).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Test accuracy (mean?std) comparisons on symmetric noisy CIFAR-10 datasets. Best two smooth rates for each synthetic noise setting are highlighted for each (green: NLS; red: VL/LS). 91?0.06 88.88?1.61 81.48?2.91 73.16?0.16 r = 0.6 92.33?0.09 87.50?1.31 82.11?0.86 73.59?0.15 r = 0.4 93.05?0.04 87.13?0.07 81.50?1.42 74.21?0.19 r = 0.0 91.44?0.16 85.08?0.86 80.42?2.29 75.34?0.13 r = ?0.4 93.55?0.06 87.55?0.08 81.58?0.19 75.95?0.13 r = ?0.8 92.74?0.05 88.46?0.11 81.56?0.15 76.15?0.14 r = ?1.0 92.58?0.08 88.58?0.08 81.95?0.10 76.20?0.10 r = ?2.0 93.30?0.03 88.78?0.09 83.64?0.15 76.11?0.07 r = ?4.0 93.13?0.04 88.90?0.07 84.34?0.13 77.22?0.09 r = ?6.0 93.14?0.08 88.94?0.11 84.52?0.13 77.42?0.16</figDesc><table><row><cell>Smooth Rate</cell><cell>? = 0.0</cell><cell cols="2">CIFAR-10 Symmetric ? = 0.2 ? = 0.4</cell><cell>? = 0.6</cell></row><row><cell cols="2">r = 0.8 92.p-value = 0.0004</cell><cell>0.008</cell><cell>0.011</cell><cell>&lt; 1e ? 14</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc>Test accuracy (mean?std) comparisons on asymmetric noisy CIFAR-10, symmetric CIFAR-100 datasets. Best two smooth rates for each synthetic noise setting are highlighted for each (green: NLS; red: VL/LS). 45?0.06 87.83?0.13 54.04?0.93 39.50?0.18 r = 0.6 90.41?0.09 87.83?0.13 52.72?0.15 40.49?0.07 r = 0.4 90.49?0.10 87.90?0.13 54.26?0.07 41.57?0.05 r = 0.0 88.32?0.24 86.27?0.32 48.03?0.29 38.11?0.14 r = ?0.4 87.27?1.83 88.33?0.06 56.87?0.08 43.70?0.16 r = ?0.8 86.40?1.32 87.96?0.43 57.35?0.08 44.10?0.06 r = ?1.0 88.47?0.15 87.50?0.73 57.44?0.09 43.85?0.19</figDesc><table><row><cell>Smooth Rate</cell><cell cols="2">CIFAR-10 Asymmetric ? = 0.2 ? = 0.3</cell><cell cols="2">CIFAR-100 Symmetric ? = 0.4 ? = 0.6</cell></row><row><cell cols="5">r = 0.8 90.r = ?2.0 88.66?0.17 87.27?0.70 58.10?0.08 44.88?0.11</cell></row><row><cell>r = ?4.0</cell><cell cols="4">89.56?0.17 87.29?0.59 58.35?0.09 46.38?0.05</cell></row><row><cell>r = ?6.0</cell><cell cols="4">89.70?0.24 87.57?0.42 57.73?0.10 46.46?0.09</cell></row><row><cell>p-value =</cell><cell>&lt; 1e ? 7</cell><cell>0.106</cell><cell>&lt; 1e ? 14</cell><cell>&lt; 1e ? 15</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell cols="2">demonstrates the effectiveness of NLS. Be-</cell></row><row><cell cols="2">sides, we observe that NLS ranks 4-th among 21 existing</cell></row><row><cell cols="2">robust methods on Clothing 1M (no extra train data, evalu-</cell></row><row><cell cols="2">ated on the clean test data) 2 . This simple trick clearly reveals</cell></row><row><cell cols="2">the importance and great potential of NLS. Nonetheless we</cell></row><row><cell cols="2">would like to clarify that our main purposes are (instead of</cell></row><row><cell cols="2">chasing SOTA): (1) Provide new understandings of whether</cell></row><row><cell cols="2">we should smooth the label or not when learning with noisy</cell></row><row><cell cols="2">labels. (2) Reveal the importance and effectiveness of NLS</cell></row><row><cell cols="2">2 Public leaderboard of CIFAR-N, Clothing 1M: http:</cell></row><row><cell>//noisylabels.com/,</cell><cell>https://paperswithcode.</cell></row><row><cell cols="2">com/sota/image-classification-on-clothing1m</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 .</head><label>6</label><figDesc>Performance comparisons on Clothing 1M and CIFAR-N: results of baselines are obtained through the public leader-board.</figDesc><table><row><cell>Method</cell><cell>Clothing 1M</cell><cell>CIFAR-10N Aggre</cell><cell>CIFAR-10N Rand1</cell><cell>CIFAR-10N Worse</cell><cell>CIFAR-100N Fine</cell></row><row><cell>CE</cell><cell>68.94</cell><cell>87.77</cell><cell>85.02</cell><cell>77.69</cell><cell>55.50</cell></row><row><cell>BLC</cell><cell>69.13</cell><cell>88.13</cell><cell>87.14</cell><cell>77.61</cell><cell>57.14</cell></row><row><cell>FLC</cell><cell>69.84</cell><cell>88.24</cell><cell>86.88</cell><cell>79.79</cell><cell>57.01</cell></row><row><cell>PL</cell><cell>72.60</cell><cell>90.75</cell><cell>89.06</cell><cell>82.53</cell><cell>57.59</cell></row><row><cell>F-div</cell><cell>73.09</cell><cell>91.64</cell><cell>89.70</cell><cell>82.53</cell><cell>57.10</cell></row><row><cell>LS (best)</cell><cell>73.44</cell><cell>91.57</cell><cell>89.80</cell><cell>82.76</cell><cell>55.84</cell></row><row><cell>NLS (best)</cell><cell>74.24</cell><cell>91.97</cell><cell>90.29</cell><cell>82.99</cell><cell>58.59</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Normalized loss functions for deep learning with noisy labels. In International Conference on Machine Learning, pp. 6543-6553. PMLR, 2020. Majidi, N., Amid, E., Talebi, H., and Warmuth, M. K. Exponentiated gradient reweighting for robust training under label noise and beyond. arXiv preprint arXiv:2104.01493, 2021. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, ?., and Polosukhin, I. Attention is all you need. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 6000-6010, 2017. Xia, X., Liu, T., Han, B., Wang, N., Deng, J., Li, J., and Mao, Y. Extended T: Learning with mixed closed-set and open-set noisy labels. arXiv preprint arXiv:2012.00932, 2020b. Xia, X., Liu, T., Han, B., Gong, M., Yu, J., Niu, G., and Sugiyama, M. Instance correction for learning with openset noisy labels. arXiv preprint arXiv:2106.00455, 2021a. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3903-3911, 2020.</figDesc><table><row><cell>In</cell><cell></cell></row><row><cell>Wang, H., Xiao, R., Li, Y., Feng, L., Niu, G., Chen, G.,</cell><cell></cell></row><row><cell>and Zhao, J. PiCO: Contrastive label disambiguation for partial label learning. In International Conference on Learning Representations, 2022. URL https:// openreview.net/forum?id=EhYjZy6e1gJ.</cell><cell>Menon, A., Van Rooyen, B., Ong, C. S., and Williamson, B. Learning from corrupted binary labels via class-probability estimation. In International Conference on Xia, X., Liu, T., Han, B., Gong, M., Yu, J., Niu, G., and Sugiyama, M. Sample selection with uncertainty of Machine Learning, pp. 125-134, 2015. losses for learning with noisy labels. arXiv preprint</cell></row><row><cell>Convolutional normalization: Improving deep convolutional network robustness and training. Ad-Wang, J., Liu, Y., and Levy, C. Fair classification with group-dependent label noise. In Proceedings of the 2021 ACM conference on fairness, accountability, and transparency, pp. 526-536, 2021.</cell><cell>arXiv:2106.00445, 2021b. M?ller, R., Kornblith, S., and Hinton, G. When does label smoothing help? In Proceedings of the 33rd International Xiao, T., Xia, T., Yang, Y., Huang, C., and Wang, X. Learn-Conference on Neural Information Processing Systems, pp. 4696-4705, 2019. ing from massive noisy labeled data for image classifica-tion. In Proceedings of the IEEE Conference on Computer</cell></row><row><cell>vances in Neural Information Processing Systems, 34, Wang, Y., Ma, X., Chen, Z., Luo, Y., Yi, J., and Bailey, J.</cell><cell>Natarajan, N., Dhillon, I. S., Ravikumar, P. K., and Tewari, Vision and Pattern Recognition, pp. 2691-2699, 2015.</cell></row><row><cell>2021. Liu, S., Zhu, Z., Qu, Q., and You, C. Robust training un-Symmetric cross entropy for robust learning with noisy labels. In Proceedings of the IEEE International Confer-ence on Computer Vision, pp. 322-330, 2019.</cell><cell>A. Learning with noisy labels. In Advances in neural Xu, Y., Xu, Y., Qian, Q., Li, H., and Jin, R. To-information processing systems, pp. 1196-1204, 2013. wards understanding label smoothing. arXiv preprint</cell></row><row><cell>der label noise by over-parameterization. arXiv preprint</cell><cell>Northcutt, C., Jiang, L., and Chuang, I. Confident learn-arXiv:2006.11653, 2020.</cell></row><row><cell>arXiv:2202.14026, 2022. Liu, T. and Tao, D. Classification with noisy labels by importance reweighting. IEEE Transactions on pattern analysis and machine intelligence, 38(3):447-461, 2015. Wei, H., Feng, L., Chen, X., and An, B. Combating noisy labels by agreement: A joint training method with co-regularization. In Proceedings of the IEEE/CVF Confer-ence on Computer Vision and Pattern Recognition, pp. 13726-13735, 2020.</cell><cell>ing: Estimating uncertainty in dataset labels. Journal of Yang, S., Yang, E., Han, B., Liu, Y., Xu, M., Niu, G., and Artificial Intelligence Research, 70:1373-1411, 2021. Liu, T. Estimating instance-dependent label-noise transi-Patrini, G., Rozza, A., Krishna Menon, A., Nock, R., and tion matrix using dnns. arXiv preprint arXiv:2105.13001, Qu, L. Making deep neural networks robust to label noise: A loss correction approach. In Proceedings of the IEEE 2021.</cell></row><row><cell>Liu, T. and Tao, D. Classification with noisy labels by Wei, H., Tao, L., Xie, R., and An, B. Open-set label noise</cell><cell>Conference on Computer Vision and Pattern Recognition, Yang, Z., Yu, Y., You, C., Steinhardt, J., and Ma, Y. Rethink-</cell></row><row><cell>importance reweighting. IEEE Transactions on pattern can improve robustness against inherent label noise. Ad-</cell><cell>pp. 1944-1952, 2017. ing bias-variance trade-off for generalization of neural</cell></row><row><cell>analysis and machine intelligence, 38(3):447-461, 2016. Liu, Y. Understanding instance-level label noise: Disparate vances in Neural Information Processing Systems, 34, 2021.</cell><cell>networks. In International Conference on Machine Learn-Pereyra, G., Tucker, G., Chorowski, J., Kaiser, ?., and Hinton, G. Regularizing neural networks by penal-ing, pp. 10767-10777. PMLR, 2020.</cell></row><row><cell>impacts and treatments. In International Conference on Wei, H., Xie, R., Feng, L., Han, B., and An, B. Deep</cell><cell>izing confident output distributions. arXiv preprint Yao, Q., Yang, H., Han, B., Niu, G., and Kwok, J. T. Search-</cell></row><row><cell>Machine Learning, pp. 6725-6735. PMLR, 2021. learning from multiple noisy annotators as a union. IEEE</cell><cell>arXiv:1701.06548, 2017. ing to exploit memorization effect in learning with noisy</cell></row><row><cell>Liu, Y. and Guo, H. Peer loss functions: Learning from Transactions on Neural Networks and Learning Systems, 2022a. noisy labels without knowing noise rates. In Interna-Wei, J. and Liu, Y. When optimizing f -divergence is robust tional Conference on Machine Learning, pp. 6226-6236. PMLR, 2020. with label noise. In International Conference on Learning</cell><cell>labels. In Proceedings of the 37th International Confer-Pleiss, G., Zhang, T., Elenberg, E. R., and Weinberger, ence on Machine Learning, ICML '20, 2020a. K. Q. Identifying mislabeled data using the area under the margin ranking. arXiv preprint arXiv:2001.10528, Yao, Y., Liu, T., Han, B., Gong, M., Deng, J., Niu, G., and 2020. Sugiyama, M. Dual t: Reducing estimation error for</cell></row><row><cell>Liu, Y. and Wang, J. Can less be more? when increasing-to-balancing label noise rates considered beneficial. Ad-vances in Neural Information Processing Systems, 34, 2021. Representations, 2021. URL https://openreview. net/forum?id=WesiCoRVQ15. Wei, J., Zhu, Z., Cheng, H., Liu, T., Niu, G., and Liu, Y. Learning with noisy labels revisited: A study using real-</cell><cell>transition matrix in label-noise learning. In Advances in Reed, S., Lee, H., Anguelov, D., Szegedy, C., Erhan, D., and Neural Information Processing Systems, volume 33, pp. Rabinovich, A. Training deep neural networks on noisy la-7260-7271, 2020b. bels with bootstrapping. arXiv preprint arXiv:1412.6596, 2014. Yi, L., Liu, S., She, Q., McLeod, A. I., and Wang, B.</cell></row><row><cell>Lukasik, M., Bhojanapalli, S., Menon, A., and Kumar, S. Does label smoothing mitigate label noise? In Interna-tional Conference on Machine Learning, pp. 6448-6458. PMLR, 2020. world human annotations. In International Conference on Learning Representations, 2022b. URL https:// openreview.net/forum?id=TBWA6PLJZQm. Wei, J., Zhu, Z., Luo, T., Amid, E., Kumar, A., and Liu,</cell><cell>On learning contrastive representations for learning with Robbins, H. and Monro, S. A stochastic approximation noisy labels. In Proceedings of the IEEE/CVF Confer-method. The annals of mathematical statistics, pp. 400-ence on Computer Vision and Pattern Recognition, pp. 407, 1951. Scott, C., Blanchard, G., Handy, G., Pozzi, S., and Flaska, 16682-16691, 2022.</cell></row><row><cell>Y. To aggregate or not? learning with separate noisy</cell><cell>M. Classification with asymmetric label noise: Consis-Yu, X., Han, B., Yao, J., Niu, G., Tsang, I., and Sugiyama,</cell></row><row><cell>Lv, J., Feng, L., Xu, M., An, B., Niu, G., Geng, X., and labels, 2022c. URL https://arxiv.org/abs/</cell><cell>tency and maximal denoising. In COLT, pp. 489-511, M. How does disagreement help generalization against</cell></row><row><cell>Sugiyama, M. On the robustness of average losses for 2206.07181.</cell><cell>2013. label corruption? In Proceedings of the 36th International</cell></row><row><cell>partial-label learning. arXiv preprint arXiv:2106.06152,</cell><cell>Conference on Machine Learning, volume 97, pp. 7164-</cell></row><row><cell>2021.</cell><cell>7173. PMLR, 09-15 Jun 2019.</cell></row></table><note>Ma, X., Huang, H., Wang, Y., Romano, S., Erfani, S., and Bailey, J.Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z. Rethinking the inception architecture for computer vi- sion. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2818-2826, 2016.Xia, X., Liu, T., Han, B., Gong, C., Wang, N., Ge, Z., and Chang, Y. Robust early-learning: Hindering the memorization of noisy labels. In International conference on learning representations, 2020a.Yuan, L., Tay, F. E., Li, G., Wang, T., and Feng, J. Revisiting knowledge distillation via label smoothing regularization.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 .</head><label>7</label><figDesc>Comparison of test accuracies on CIFAR-10 under symmetric label noise.</figDesc><table><row><cell>Method</cell><cell cols="3">CIFAR-10, Symmetric ? = 0.2 ? = 0.4 ? = 0.6</cell></row><row><cell>Backward T (Patrini et al., 2017)</cell><cell>84.79</cell><cell>83.40</cell><cell>71.52</cell></row><row><cell>Forward T (Patrini et al., 2017)</cell><cell>84.85</cell><cell>83.98</cell><cell>73.97</cell></row><row><cell>GLS form</cell><cell>87.33</cell><cell>81.73</cell><cell>75.80</cell></row><row><cell>Peer Loss (Liu &amp; Guo, 2020)</cell><cell>90.21</cell><cell>86.40</cell><cell>79.64</cell></row><row><cell>GLS form</cell><cell>88.98</cell><cell>85.05</cell><cell>76.66</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 .</head><label>8</label><figDesc>Test accuracies of GLS on assymetric noisy CIFAR-10 and symmetric CIFAR-100 (left/right denotes direct train / warm-up).</figDesc><table><row><cell>Smooth Rate</cell><cell cols="2">CIFAR-10 Asymmetric ? = 0.2 ? = 0.3</cell><cell cols="2">CIFAR-100 Symmetric ? = 0.4 ? = 0.6</cell></row><row><cell>r = 0.8</cell><cell cols="4">87.89 / 90.51 86.38 / 87.97 54.78 / 51.27 40.21 / 39.80</cell></row><row><cell>r = 0.6</cell><cell cols="4">89.14 / 90.55 85.97 / 88.01 52.83 / 52.88 39.64 / 40.57</cell></row><row><cell>r = 0.4</cell><cell cols="4">88.23 / 90.61 86.95 / 88.04 51.40 / 54.36 38.29 / 41.63</cell></row><row><cell>r = ?0.4</cell><cell cols="4">19.71 / 89.60 21.86 / 88.42 40.30 / 56.97 31.35 / 43.91</cell></row><row><cell>r = ?0.8</cell><cell>-/ 89.02</cell><cell>-/ 88.28</cell><cell cols="2">22.63 / 57.45 26.75 / 44.19</cell></row><row><cell>r = ?1.0</cell><cell>-/ 88.68</cell><cell>-/ 88.29</cell><cell>-/ 57.53</cell><cell>-/ 44.59</cell></row><row><cell>r = ?2.0</cell><cell>-/ 88.86</cell><cell>-/ 88.13</cell><cell>-/ 58.21</cell><cell>-/ 45.47</cell></row><row><cell>r = ?4.0</cell><cell>-/ 89.80</cell><cell>-/ 88.20</cell><cell>-/ 58.47</cell><cell>-/ 46.86</cell></row><row><cell>r = ?6.0</cell><cell>-/ 90.02</cell><cell>-/ 88.18</cell><cell>-/ 57.87</cell><cell>-/ 47.18</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9 .</head><label>9</label><figDesc>Test accuracies of GLS on clean and noisy synthetic data. We report best test accuracy for each method. ropt and the corresponding test accuracy are highlighted (green: NLS; red: CE or LS).</figDesc><table><row><cell>Method</cell><cell cols="3">Synthetic data (Type 1) ei = 0 ei = 0.2 ei = 0.4</cell><cell cols="3">Synthetic data (Type 2) ei = 0 ei = 0.2 ei = 0.4</cell></row><row><cell>LS</cell><cell>0.896</cell><cell>0.878</cell><cell>0.786</cell><cell>0.894</cell><cell>0.848</cell><cell>0.842</cell></row><row><cell>Vanilla Loss</cell><cell>0.889</cell><cell>0.882</cell><cell>0.806</cell><cell>0.894</cell><cell>0.875</cell><cell>0.868</cell></row><row><cell>NLS</cell><cell>0.893</cell><cell>0.885</cell><cell>0.825</cell><cell>0.883</cell><cell>0.884</cell><cell>0.875</cell></row><row><cell>ropt =</cell><cell>[0.1, 0.4]</cell><cell>-0.2</cell><cell>-0.4</cell><cell>[0, 0.2]</cell><cell>-0.3</cell><cell>-0.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 .</head><label>10</label><figDesc>Test accuracy comparisons on clean and noisy UCI datasets (Image, Waveform, Heart, Banana) with best two smooth rates (green: NLS; red: CE or LS).</figDesc><table><row><cell>Smooth Rate</cell><cell>ei = 0</cell><cell>ei = 0.1</cell><cell>Image ei = 0.2</cell><cell>ei = 0.3</cell><cell>ei = 0.4</cell><cell>ei = 0</cell><cell>ei = 0.1</cell><cell>Waveform ei = 0.2</cell><cell>ei = 0.3</cell><cell>ei = 0.4</cell></row><row><cell>r = 0.8</cell><cell>0.993</cell><cell>0.983</cell><cell>0.973</cell><cell>0.946</cell><cell>0.875</cell><cell>0.939</cell><cell>0.935</cell><cell>0.931</cell><cell>0.927</cell><cell>0.885</cell></row><row><cell>r = 0.6</cell><cell>0.993</cell><cell>0.987</cell><cell>0.970</cell><cell>0.939</cell><cell>0.869</cell><cell>0.943</cell><cell>0.943</cell><cell>0.943</cell><cell>0.929</cell><cell>0.901</cell></row><row><cell>r = 0.4</cell><cell>0.997</cell><cell>0.980</cell><cell>0.973</cell><cell>0.939</cell><cell>0.865</cell><cell>0.941</cell><cell>0.937</cell><cell>0.943</cell><cell>0.931</cell><cell>0.905</cell></row><row><cell>r = 0.2</cell><cell>0.993</cell><cell>0.993</cell><cell>0.966</cell><cell>0.936</cell><cell>0.875</cell><cell>0.941</cell><cell>0.935</cell><cell>0.933</cell><cell>0.931</cell><cell>0.913</cell></row><row><cell>r = 0.0</cell><cell>0.990</cell><cell>0.976</cell><cell>0.963</cell><cell>0.929</cell><cell>0.865</cell><cell>0.945</cell><cell>0.935</cell><cell>0.937</cell><cell>0.933</cell><cell>0.911</cell></row><row><cell>r = ?0.2</cell><cell>0.912</cell><cell>0.96</cell><cell>0.953</cell><cell>0.919</cell><cell>0.872</cell><cell>0.937</cell><cell>0.939</cell><cell>0.939</cell><cell>0.933</cell><cell>0.907</cell></row><row><cell>r = ?0.4</cell><cell>0.882</cell><cell>0.923</cell><cell>0.953</cell><cell>0.936</cell><cell>0.872</cell><cell>0.925</cell><cell>0.937</cell><cell>0.939</cell><cell>0.933</cell><cell>0.917</cell></row><row><cell>r = ?0.8</cell><cell>0.842</cell><cell>0.882</cell><cell>0.926</cell><cell>0.933</cell><cell>0.872</cell><cell>0.921</cell><cell>0.925</cell><cell>0.939</cell><cell>0.931</cell><cell>0.923</cell></row><row><cell>r = ?1.0</cell><cell>0.832</cell><cell>0.869</cell><cell>0.909</cell><cell>0.929</cell><cell>0.882</cell><cell>0.921</cell><cell>0.923</cell><cell>0.933</cell><cell>0.929</cell><cell>0.907</cell></row><row><cell>r = ?2.0</cell><cell>0.818</cell><cell>0.815</cell><cell>0.889</cell><cell>0.909</cell><cell>0.906</cell><cell>0.911</cell><cell>0.913</cell><cell>0.921</cell><cell>0.927</cell><cell>0.911</cell></row><row><cell>Smooth Rate</cell><cell>ei = 0</cell><cell>ei = 0.1</cell><cell>Twonorm ei = 0.2</cell><cell>ei = 0.3</cell><cell>ei = 0.4</cell><cell>ei = 0</cell><cell>ei = 0.1</cell><cell>Banana ei = 0.2</cell><cell>ei = 0.3</cell><cell>ei = 0.4</cell></row><row><cell>r = 0.8</cell><cell>0.990</cell><cell>0.990</cell><cell>0.986</cell><cell>0.982</cell><cell>0.968</cell><cell>0.896</cell><cell>0.893</cell><cell>0.876</cell><cell>0.847</cell><cell>0.790</cell></row><row><cell>r = 0.6</cell><cell>0.990</cell><cell>0.989</cell><cell>0.987</cell><cell>0.981</cell><cell>0.972</cell><cell>0.903</cell><cell>0.881</cell><cell>0.876</cell><cell>0.855</cell><cell>0.811</cell></row><row><cell>r = 0.4</cell><cell>0.990</cell><cell>0.990</cell><cell>0.987</cell><cell>0.983</cell><cell>0.971</cell><cell>0.900</cell><cell>0.887</cell><cell>0.874</cell><cell>0.859</cell><cell>0.807</cell></row><row><cell>r = 0.2</cell><cell>0.990</cell><cell>0.989</cell><cell>0.986</cell><cell>0.985</cell><cell>0.969</cell><cell>0.896</cell><cell>0.894</cell><cell>0.876</cell><cell>0.856</cell><cell>0.810</cell></row><row><cell>r = 0.0</cell><cell>0.990</cell><cell>0.989</cell><cell>0.987</cell><cell>0.985</cell><cell>0.973</cell><cell>0.897</cell><cell>0.881</cell><cell>0.871</cell><cell>0.849</cell><cell>0.833</cell></row><row><cell>r = ?0.4</cell><cell>0.986</cell><cell>0.988</cell><cell>0.988</cell><cell>0.986</cell><cell>0.972</cell><cell>0.847</cell><cell>0.874</cell><cell>0.859</cell><cell>0.853</cell><cell>0.840</cell></row><row><cell>r = ?0.6</cell><cell>0.986</cell><cell>0.988</cell><cell>0.987</cell><cell>0.984</cell><cell>0.974</cell><cell>0.845</cell><cell>0.864</cell><cell>0.861</cell><cell>0.859</cell><cell>0.837</cell></row><row><cell>r = ?1.0</cell><cell>0.986</cell><cell>0.986</cell><cell>0.988</cell><cell>0.985</cell><cell>0.977</cell><cell>0.796</cell><cell>0.812</cell><cell>0.852</cell><cell>0.854</cell><cell>0.811</cell></row><row><cell>r = ?2.0</cell><cell>0.986</cell><cell>0.986</cell><cell>0.986</cell><cell>0.986</cell><cell>0.978</cell><cell>0.759</cell><cell>0.764</cell><cell>0.819</cell><cell>0.852</cell><cell>0.819</cell></row><row><cell>r = ?4.0</cell><cell>0.986</cell><cell>0.986</cell><cell>0.986</cell><cell>0.986</cell><cell>0.983</cell><cell>0.718</cell><cell>0.723</cell><cell>0.738</cell><cell>0.787</cell><cell>0.813</cell></row><row><cell>r = ?8.0</cell><cell>0.986</cell><cell>0.986</cell><cell>0.986</cell><cell>0.985</cell><cell>0.986</cell><cell>0.703</cell><cell>0.700</cell><cell>0.699</cell><cell>0.735</cell><cell>0.735</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 .</head><label>11</label><figDesc>Test accuracy comparisons on clean and symmetric noisy AGNews dataset. Highlighted numbers indicate the best performance under each .</figDesc><table><row><cell>Smooth Rate</cell><cell>= 0</cell><cell cols="3">AGNews (4 classes) = 0.1 = 0.2 = 0.3</cell><cell>= 0.4</cell></row><row><cell>r = 0.4</cell><cell>86.33</cell><cell>85.55</cell><cell>83.93</cell><cell>82.29</cell><cell>79.80</cell></row><row><cell>r = 0.2</cell><cell>87.79</cell><cell>86.99</cell><cell>85.67</cell><cell>83.47</cell><cell>81.04</cell></row><row><cell>r = 0.0</cell><cell>88.20</cell><cell>87.79</cell><cell>86.80</cell><cell>85.24</cell><cell>82.39</cell></row><row><cell>r = ?0.15</cell><cell>85.04</cell><cell>88.00</cell><cell>87.47</cell><cell>85.83</cell><cell>83.09</cell></row><row><cell>r = ?0.2</cell><cell>84.08</cell><cell>87.30</cell><cell>87.50</cell><cell>85.85</cell><cell>83.34</cell></row><row><cell>r = ?0.36</cell><cell>81.39</cell><cell>84.47</cell><cell>87.75</cell><cell>86.14</cell><cell>83.62</cell></row><row><cell>r = ?0.4</cell><cell>80.76</cell><cell>83.99</cell><cell>87.28</cell><cell>86.36</cell><cell>83.96</cell></row><row><cell>r = ?0.6</cell><cell>77.62</cell><cell>80.80</cell><cell>84.68</cell><cell>87.26</cell><cell>84.37</cell></row><row><cell>r = ?0.67</cell><cell>76.70</cell><cell>79.91</cell><cell>83.87</cell><cell>87.21</cell><cell>84.58</cell></row><row><cell>r = ?1.14</cell><cell>72.38</cell><cell>74.84</cell><cell>78.28</cell><cell>82.45</cell><cell>86.43</cell></row><row><cell>r = ropt = (K?1)r  *  ?K (K?1)?K</cell><cell>88.20</cell><cell>88.00</cell><cell>87.75</cell><cell>87.21</cell><cell>86.43</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">4 non-negative smooth rates V.S. the smallest 4 negative smooth rates, p-value is highlighted in green if NLS generally returns a higher accuracy (i.e., t-value&lt; 0) than VL/LS, otherwise, in red.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">, learning NLS with r = r opt &lt; 0 yields f * D .</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgement YL and JHW are partially supported by the grants IIS-2007951 and IIS-2143895. TLL is partially supported by Australian Research Council Projects DE-190101473, IC-190100031, and DP-220102121. MS and GN are supported by JST CREST Grant Number JP-MJCR18A2. The authors thank anonymous ICML reviewers for their comments that improved the presentation.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix E. Bias and Variance Trade-off of Learning with Smoothed Labels</head><p>Denotef H ,f S as pre-trained models on the training dataset D w.r.t. hard labels and soft labels, respectively. The vector form of the prediction w.r.t. sample x given byf H andf S aref H (x; D) andf S (x; D). For the ease of presentation, we relate notations with subscript H/S to hard/soft labels without further explanation. Given the sample x and the one-hot label y, we denote the averaged model prediction by:</p><p>where Z H , Z S are normalization constants. The bias of model prediction is defined as the KL divergence D KL between target distribution (one-hot encoded vector form) y and the averaged model prediction.</p><p>,</p><p>.</p><p>While the variance of model prediction measures the expectation of KL divergence between the averaged model prediction and model prediction over D:</p><p>Empirical observation from <ref type="bibr">(Zhou et al., 2021)</ref> shows that the variance brought by learning with positive soft labels given by a teacher's model <ref type="bibr" target="#b16">(Hinton et al., 2015)</ref> is less than the direct training w.r.t hard labels. As an extension, we are interested in how LS/NLS interferes with the bias and variance of model prediction.</p><p>Bias and variance of LS/NLS on clean dataset We introduce our empirical observation regarding the role of LS/NLS in bias and variance trade-off in <ref type="figure">Figure 9</ref>. We select nine smooth rates of LS/NLS for illustration. Each smooth rate setting of LS/NLS trains on the CIFAR-10 dataset for 5 times with different data augmentations. To estimate the variance and bias of pre-trained models, we adopt the implementation in <ref type="bibr">(Yang et al., 2020)</ref>. Empirical results show that learning directly with a larger positive smooth rate typically results in lower variance and higher bias. In <ref type="figure">Figure 9</ref>, we can observe almost constant bias values and very low variance for NLS. This is best explained by the warm-up of pre-trained models and the fact that NLS pushes the classifier to give confident predictions. As for LS, with the increase of smooth rate, the overall bias has an increasing tendency while the variance has the decreasing pattern. Especially when the smooth rate approaches to 1, i.e., r = 0.9, the variance is close to 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Omitted Proofs</head><p>We observe that NLS connects to a special case of label smoothing regularization <ref type="bibr">(Szegedy et al., 2016)</ref>. We highlight this in Theorem F.1.</p><p>Theorem F.1. ?r ? [0, 1], NLS with smooth rate ?r is a special form of label smoothing regularization:</p><p>Before we prove Theorem F.1, we first introduce Lemma F.2.</p><p>Proof of Lemma F.2</p><p>Proof. For CE loss, due to its linear property w.r.t. the label, we directly have:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof of Theorem F.1</head><p>Proof. Based on Lemma F.2, with a bit of math, for NLS, we have: </p><p>where we define GLS,r f (x), y GLS,r = 1? r 2 ? f (x), y + r 2 ? f (x), 1?y , and R indicates the Rademacher complexity. If is L-Lipshitz for every y, then for any f 1 (x), f 2 (x), we have: <ref type="bibr">GLS,r</ref> is also L r -Lipshitz such that for CE loss, we have:</p><p>Note that (1 ? r 2 ) ? r 2 so we need to concentrate on the term (f (x), y), what is more, (f (x), y) = (f (x), 1 ? y). We then have:</p><p>Thus we have:</p><p>Thus, we finally have:</p><p>Proof. Denote p i = P(Y = i) as the clean label distribution,p i = P( Y = i) as the clean label distribution. Let = K? K?1 , we have:</p><p>.</p><p>Adopting r opt = r * ? 1? , with a bit of math, the weight of Term M-Inc1 becomes 0 and</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust bi-tempered logistic loss based on bregman divergences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Amid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koren</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14987" to="14996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Understanding and improving early stopping for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Confidence scores make instance-dependent label-noise learning possible</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Berthon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="825" to="836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Instance-dependent labelnoise learning with manifold-regularized transition matrix estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="16630" to="16639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning with instance-dependent label noise: A sample sieve approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=2VXyy9mIyU3" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Demystifying how self-supervised features improve training from noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.09022</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards better decoding and language model integration in sequence to sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="523" to="527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Rethinking noisy label models: Labeler-dependent noise with adversarial awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Polikar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.14083</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Graff</surname></persName>
		</author>
		<ptr target="http://archive.ics.uci.edu/ml" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Englesson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Azizpour</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.01242</idno>
		<title level="m">Consistency regularization can improve robustness to label noise</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generalized jensen-shannon divergence loss for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Englesson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Azizpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Provably consistent partial-label learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="10948" to="10960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Label distribution learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1734" to="1748" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8527" to="8537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mixture proportion estimation via kernel embeddings of distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Harish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2052" to="2060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning from complementary labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5644" to="5654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Complementary-label learning for arbitrary losses and models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2971" to="2980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mentornet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An information fusion approach to learning with instance-dependent label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=ecH2FKaARUp" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Negative learning for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nlnl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
