<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Contrastive Regularization for Semi-Supervised Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doyup</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwoong</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ildoo</forename><surname>Kim</surname></persName>
							<email>ildoo.kim@kakaobrain.com2</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeongjae</forename><surname>Cheon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wook-Shin</forename><surname>Han</surname></persName>
							<email>wshan@postech.ac.kr1</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kakao</forename><surname>Brain</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dcml</forename><forename type="middle">Inc</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">South</forename><surname>Korea</surname></persName>
						</author>
						<title level="a" type="main">Contrastive Regularization for Semi-Supervised Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Consistency regularization on label predictions becomes a fundamental technique in semi-supervised learning, but it still requires a large number of training iterations for high performance. In this study, we analyze that the consistency regularization restricts the propagation of labeling information due to the exclusion of samples with unconfident pseudo-labels in the model updates. Then, we propose contrastive regularization to improve both efficiency and accuracy of the consistency regularization by well-clustered features of unlabeled data. In specific, after strongly augmented samples are assigned to clusters by their pseudo-labels, our contrastive regularization updates the model so that the features with confident pseudo-labels aggregate the features in the same cluster, while pushing away features in different clusters. As a result, the information of confident pseudo-labels can be effectively propagated into more unlabeled samples during training by the well-clustered features. On benchmarks of semisupervised learning tasks, our contrastive regularization improves the previous consistency-based methods and achieves state-of-the-art results, especially with fewer training iterations. Our method also shows robust performance on openset semi-supervised learning where unlabeled data includes out-of-distribution samples.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Recent semi-supervised learning (SSL) methods mostly make use of the consistency regularization to learn a specific task with sparse labels, showing competitive results to the fully supervised learning <ref type="bibr" target="#b2">(Berthelot et al. 2019a;</ref><ref type="bibr" target="#b25">Sohn et al. 2020;</ref><ref type="bibr" target="#b18">Li, Xiong, and Hoi 2020)</ref>. The consistency regularization enforces a model to produce consistent predictions on various augmented views of input with pseudo-labeling <ref type="bibr" target="#b17">(Lee et al. 2013)</ref>. Moreover, in order to avoid a confirmation bias <ref type="bibr" target="#b0">(Arazo et al. 2020</ref>) and increase the reliability of pseudo-labeling, a selection mask is typically used in this consistency regularization to exclude unconfident label predictions during SSL training. Consequently, the consistency regularization can propagate the labeling information into unlabeled samples around the augmented views of confident pseudo-labels <ref type="bibr" target="#b9">(Ghosh and Thiery 2021)</ref>.</p><p>Despite its promising results, the existing consistency regularization requires an expensive training cost to achieve * Corresponding Author high performance. For example, although FixMatch <ref type="bibr" target="#b25">(Sohn et al. 2020</ref>) can achieve high SSL performance without pretraining on a large scale unlabeled data <ref type="bibr" target="#b6">(Chen et al. 2020b)</ref>, it needs over 10,000 epochs to obtain the best performance even on small-scale datasets such as SVHN, CIFAR-10, or CIFAR-100. Thus, we first analyze the inefficiency of the consistency regularization for SSL, both theoretically and empirically, and then verify that this inefficiency is originated from the exclusion of samples with unconfident pseudo-labels when updating a model. Namely, it restricts the active propagation of confident labeling information into unlabeled samples, especially in the early stage of training.</p><p>Based on the above analysis, we propose contrastive regularization to improve the performance of SSL based on consistency regularization. The main idea is described in <ref type="figure" target="#fig_0">Figure 1</ref>. The consistency regularization moves the features of strongly augmented samples having only confident pseudolabels toward their corresponding class centers of the confident features by pseudo-labels. In contrast, the proposed contrastive regularization forms class clusters based on both confident and unconfident pseudo-labels. Then, it moves the features having confident pseudo-labels toward the center positions of their clusters, while pulling the features of samples with both confident and unconfident pseudo-labels in the same cluster and pushing the features in different clusters. Thus, a model can learn well-clustered features of unlabeled data, enabling the confident labeling information to be propagated into more unlabeled samples during training.</p><p>In the experiments, we show that our contrastive regularization improves the performance of consistency regularization methods on various SSL benchmarks, including SVHN, CIFAR-10, CIFAR-100, STL-10, and ImageNet with limited labels. Especially, different from the previous methods, we show that our method leverages unlabeled samples in the early stage of training and requires much fewer iterations for the outperformance. We also demonstrate that the contrastive regularization achieves the robust performance on the task of open-set SSL, which is more realistic in that unlabeled data contains out-of-distribution samples <ref type="bibr" target="#b20">(Oliver et al. 2018;</ref><ref type="bibr" target="#b29">Yu et al. 2020</ref>). Finally, we conduct an extensive ablation study to show that the contrastive regularization is valid and not highly sensitive to the selection of hyper-parameters.</p><p>Our main contributions can be summarized as follows. 1) It is the first study to analyze the limitation of the consis-arXiv:2201.06247v2 <ref type="bibr">[cs.</ref>LG] 9 Jun 2022 The symbol ? represents a cluster center that is estimated by confident samples only, and * represents a cluster center that is estimated by all samples in the same cluster. The length of arrows represents the magnitude of gradient vectors. The cluster centers are computed by the class weight vectors.</p><p>tency regularization with respect to the efficiency of SSL training. 2) We propose a simple yet powerful solution, the contrastive regularization, which consistently improves the SSL performance on different SSL benchmarks with fewer training iterations than the previous consistency regularization. 3) Contrastive regularization shows the robustness on the more realistic benchmark that includes out-ofdistribution samples in the unlabeled dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Consistency Regularization for SSL. Recent SSL methods use the consistency regularization <ref type="bibr" target="#b23">(Samuli and Timo 2017)</ref> and focus on the policies of stochastic data augmentations such as adversarial perturbations <ref type="bibr" target="#b19">(Miyato et al. 2018)</ref> or mixup <ref type="bibr">(Berthelot et al. 2019a,b;</ref><ref type="bibr" target="#b33">Zhang et al. 2018)</ref>. As the most simplified yet powerful framework of SSL, UDA and FixMatch <ref type="bibr" target="#b25">Sohn et al. 2020)</ref> show that the simple combination of strong data augmentation such as RandAugment ) and pseudo-labeling <ref type="bibr" target="#b17">(Lee et al. 2013</ref>) can obtain high performance. Thus, we focus on improving the consistency regularization, because they have shown state-of-the-art results compared with other SSL approaches <ref type="bibr" target="#b24">(Shi et al. 2018;</ref><ref type="bibr" target="#b12">Iscen et al. 2019)</ref>.</p><p>Semi-Supervised Learning with Self-Supervision. The SSL performance can be improved when self-supervised learning is used with an auxiliary task for representation learning, and our contrastive regularization can be viewed as an auxiliary task for SSL. S4L <ref type="bibr" target="#b32">(Zhai et al. 2019</ref>) demonstrates that auxiliary tasks such as rotation or exemplar selfsupervision can improve the SSL performance. For timeseries classification, forecasting of the next-step value is used as an auxiliary task <ref type="bibr" target="#b13">(Jawed, Grabocka, and Schmidt-Thieme 2020)</ref>. CoMatch <ref type="bibr" target="#b18">(Li, Xiong, and Hoi 2020)</ref> unifies pseudo-labeling, self-supervised learning, and graph-based SSL, using the graph contrastive learning and the pseudolabel smoothing with a large size of memory bank <ref type="bibr" target="#b11">(He et al. 2020)</ref>. Although both CoMatch and our method use a contrastive loss to regularize the unlabeled features, our method can be easily in tandem with the consistency regularization with minimal change for the contrastive loss.</p><p>Pretraining and Finetuning. Finetuning after pretraining on an upstream task is a solution for learning a task with scarce labels, when large-scale labeled or unlabeled datasets are available for the upstream task. For instance, a model, which is pretrained on a large-scale labeled dataset, can be well transferred to downstream tasks <ref type="bibr" target="#b16">(Kolesnikov et al. 2020)</ref>. but a negative transfer occurs when the target task is unrelated to the upstream domain or task <ref type="bibr" target="#b31">(Zamir et al. 2018)</ref>. When a large-scale unlabeled data is available, a framework using both task-agnostic pretraining and task-specific finetuning can become a strong SSL approach <ref type="bibr" target="#b28">(Vincent et al. 2010;</ref><ref type="bibr" target="#b11">He et al. 2020;</ref><ref type="bibr" target="#b6">Chen et al. 2020b</ref>). However, utilizing unlabeled samples in a task-specific way can outperform a task-agnostic approach without a large number of unlabeled samples. Thus, we emphasize that task-specific SSL methods are important because it is hard to collect a large number of unlabeled samples in the real world.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contrastive Regularization for Semi-Supervised Learning</head><p>In this section, we introduce our contrastive regularization to improve the SSL performance of the consistency regularization. We first formulate SSL and the consistency regularization, which is the most common approach and shows remarkable results with deep neural networks (DNNs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem Formulation</head><p>We assume that a labeled dataset D L and an unlabeled dataset D U are given to train a model parameterized by</p><formula xml:id="formula_0">?. A mini-batch B consists of B labeled samples X = {(x b , y b )|(x b , y b ) ? D L } B b=1 and ?B unlabeled samples U = {u b |u b ? D U } ?B b=1 ,</formula><p>where ? is the ratio of unlabeled samples to the labeled samples in a mini-batch. The total loss L is minimized at each training iteration</p><formula xml:id="formula_1">L(B) = L L (X ) + ? u L U (U),<label>(1)</label></formula><p>where L L is a supervised loss, L U is an unsupervised loss, and ? u is an unlabeled loss ratio. Cross entropy is used for a supervised loss, and the type of L U determines how to leverage the unlabeled samples. For example, entropy regularization <ref type="bibr" target="#b10">(Grandvalet, Bengio et al. 2005</ref>) and pseudo-labeling enforce the predictions on unlabeled samples to have a low entropy, so that the decision boundary is located in the lowdensity area <ref type="bibr" target="#b22">(Sajjadi, Javanmardi, and Tasdizen 2016)</ref>.</p><p>For an unlabeled sample u ? U, the label prediction p(y|u) = softmax[W h ? (u)] is given by the model with ? comprising K-class weight matrix W = [w 1 , w 2 , ..., w K ] ? R H?K , where h ? (u) ? R H denotes the penultimate features. We define a stochastic function of strong augmentation as ?, and the set of strongly augmented samples for an unlabeled mini-batch as A m (U) = {u i |u ? U, u i = ?(u), 1 ? i ? m}, where m is the number of augmented view per an unlabeled sample in the mini-batch. Then, the consistency regularization, R CS , is defined as</p><formula xml:id="formula_2">RCS(U) = 1 |Am(U)| u ?Am(U ) 1[max qu &gt; ?]H(qu,p(y|u )),<label>(2)</label></formula><p>where u is the augmented sample of u ? U, ? is a confidence threshold, and H is the cross entropy loss. In the remaining parts of this paper, a strongly augmented sample of u is represented as u for brevity.q u is the pseudo-label of u and defined asq u = arg max q u , where q u = sg[p(y|u)] and sg is the stop gradient. Note that the pseudo-label of u = ?(u) is determined by the label prediction on the sample without strong augmentation, u, for the reliability of pseudo-labeling.</p><p>The performance of consistency regularization highly depends on the choices of ? and ?. Data augmentation encourages DNNs to learn the generalized representations with the local geometry of the data-manifold, assuming that the learned manifolds of different classes are well-separated <ref type="bibr" target="#b27">(Verma et al. 2019;</ref><ref type="bibr" target="#b9">Ghosh and Thiery 2021)</ref>. Therefore, the features having different pseudo-labels become wellseparated, propagating the confident (pseudo-)labeling information into their neighbors on the data manifold. Determining the threshold ? is an inherent trade-off for the SSL performance, because the ? controls the balance of the reliability and the number of unlabeled samples leveraged. A higher value of ? is commonly used to avoid a confirmation bias, but it restricts unlabeled samples to be included in SSL training and can preclude the model from learning the transformation-invariant representations on the excluded samples <ref type="bibr" target="#b0">(Arazo et al. 2020)</ref>. It minimizes the entropy of only a sample using a confident pseudo-labeling for SSL training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Inefficiency of Consistency Regularization</head><p>As the consistency regularization achieves high SSL performance competitive with the fully supervised setting, it requires a large number of training iterations even on smallscale datasets. For example, FixMatch <ref type="bibr" target="#b25">(Sohn et al. 2020)</ref> requires over 10,000 epochs to train WRN-28-2 (Zagoruyko and Komodakis 2016) on the CIFAR-10 dataset. However, when the labels are fully provided, about 100 epochs are enough to learn the dataset under supervision.</p><p>Here, we analyze the consistency regularization to show its training inefficiency. Assume thatQ i is a set of strongly augmented samples assigned to the i-th class by the pseudolabel,Q i = {u |u ? A m (U), u ? U,q u = i}. The minus gradients of R CS with respect to the features h ? and to the i-th class weight vector w i are as follows:</p><formula xml:id="formula_3">? ?RCS ?wi = 1 |Am(U)| u ?Q i 1[max qu &gt; ?]h ? (u )(1 ?p(i|u )),<label>(3)</label></formula><formula xml:id="formula_4">? ?RCS ?h ? = 1 |Am(U)| u ?Am(U ) 1[max qu &gt; ?]{ i =qu wip(i|u ) + wq u (1 ?p(qu|u ))}.<label>(4)</label></formula><p>By this gradient analysis, we postulate that the inefficiency of the consistency regularization results from the exclusion of samples with unconfident pseudo-labels and the training bias on the confident pseudo-labels by the masking 1[max q u &gt; ?]. <ref type="figure" target="#fig_0">Figure 1(a)</ref> contains the interpretation of the gradient analysis. Here, we assume that the features with unconfident pseudo-labels are close to the deci-sion boundary, considering the linearity of softmax classifier <ref type="bibr">(Bishop 2006)</ref>. The class weight vector w i is updated to the weighted sum of only confident features in Eq. (3). Then, the confident features in Eq. (4) are updated by the class weight vectors, so the features only having confident pseudo-labels become close together. However, the unconfident samples are excluded in the gradients computations, and the labeling information of confident samples cannot be effectively propagated into the unlabeled samples. In addition, the class weight vector is slowly changed due to the exclusion of unconfident samples, because the gradient in Eq. 3 is bounded by the confidence threshold,</p><formula xml:id="formula_5">? ?R CS ?wi &lt; 1 |Am(U )| u ?Qi 1[max q u b &gt; ?]h ? (u )(1 ? ?),</formula><p>where ? is typically selected as a high value such as 0.95. Thus, the model cannot leverage lots of unlabeled samples over the SSL training and requires a large number of training iterations to gradually increase the number of confident samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contrastive Regularization for SSL</head><p>We propose contrastive regularization in <ref type="figure" target="#fig_0">Figure 1</ref>(b) to effectively leverage unlabeled samples for SSL. Even though <ref type="figure" target="#fig_0">Figure 1</ref>(b) describes the two-class classification, the concept can be generalized to the setting of multiple classes, and all experiments in this study are also conducted on multiclass tasks. Different from the consistency regularization, the class clusters are formed by the features with both confident and unconfident pseudo-labels. Then, our method regularizes the hidden features of confident unlabeled samples to be moved toward the samples with unconfident pseudolabels in the same cluster, and propagates the labeling information. At the same time, to leverage the unconfident samples without decreasing the confident threshold ?, the features having confident pseudo-labels pull the features of unconfident samples in the same cluster, while pushing the features in different clusters. It can achieve the entropy minimization for SSL, and unlabeled samples are beneficial with a small overlap of classes, since the contrastive regularization can learn well-clustered features that reduce the overlaps.</p><p>For this, we modify SupContrast <ref type="bibr" target="#b14">(Khosla et al. 2020)</ref>, which is used for a supervised pretraining on large-scale labeled data, into SSL setting by adding a projection head after the penultimate features. We define the set of pseudopositive pairs of u asP (u ) = {p |p ? A m (U)/u ,q p = q u }, whereq p andq u are the pseudo-label of p and u , respectively. Note that a pseudo-label of a strongly augmented sample u is defined by the label prediction on the unlabeled sample u before strong augmentation. The positive sample pairs represent the samples whose pseudo-labels are the same, and the augmented samples inP (u ) have the same pseudo-label with u . Then, the contrastive regularization, R CR , is defined as follows:</p><formula xml:id="formula_6">RCR(U) = 1 |Am(U)| u ?Am(U ) 1[max qu &gt; ? ]r(u ),<label>(5)</label></formula><formula xml:id="formula_7">r(u ) = ?1 |P (u )| p ?P (u ) log exp( z u , z p /? ) v ?Am(U )/u exp( z u , z v /? ) ,<label>(6)</label></formula><p>where ? is a confidence threshold, ? is a temperature scaling parameter, and z u is a normalized vector of the projection head. Our total loss is L(B) = L L (X ) + ? CS R CS (U) + ? CR R CR (U), where ? CS and ? CR is the loss ratio of consistency and contrastive regularization, respectively. The features of confident samples move toward the centroid of its feature cluster, which consists of features having the same pseudo-labels, and pull the unconfident features in the same cluster by our contrastive regularization. Without the loss of generalizability, we notate the softmax score of z p with z u as s <ref type="bibr">[u , p ]</ref>, and assume the normalized vector z = h, and ? = 1. For u and v ? A m (U)/u , the minus gradients of r(u ) with respect to h ? are as follows:</p><formula xml:id="formula_8">? ?r(u ) ?h ? (u ) = p ?P (u ) ( 1 |P (u )| ? s[u , p ])h ? (p ) + R(u ), (7) ? ?r(u ) ?h ? (v ) = ( 1 |P (u )| ? s[u , v ])h ? (u ), if v ?P (u ) ? s[u , v ]h ? (u ), if v / ?P (u ) ,<label>(8)</label></formula><p>where R(u ) is a remainder term and small enough. We attach the detailed derivation of Eq. <ref type="formula" target="#formula_10">(7)</ref> and <ref type="formula" target="#formula_8">(8)</ref> in Appendix A. If the u has a confident pseudo-label as Eq. <ref type="formula" target="#formula_10">(7)</ref>, the contrastive regularization updates its feature vector h ? (u ) toward the weighted sum of positive features both with confident and unconfident pseudo-labels. Different from the consistency regularization, the feature update of confident samples also considers the features with unconfident pseudolabels in the same cluster. At the same time, in Eq. <ref type="formula" target="#formula_8">(8)</ref> However, note that other negative samples in the different clusters still push v , avoiding a wrong cluster assignment by the negative values of Eq. (8) during training. Thus, the model can propagate the confident labeling information into the unlabeled samples, while learning well-clustered features for SSL <ref type="bibr" target="#b4">(Castelli and Cover 1996)</ref>. Although our contrastive regularization utilizes the information of unconfident pseudo-labeling, the confirmation bias does not more increase than previous consistency regularization methods. According to Appendix C, the performance degradation by the memorization of wrong pseudolabels occurs in the later stage of SSL training. In the early stage of training, our method learns well-clustered representations of unlabeled samples to effectively propagate labeling information of labeled samples and unlabeled samples with confident pseudo-labeling. Thus, the contrastive regularization can improve the SSL performance before the SSL model starts to memorize wrong pseudo-labels <ref type="bibr" target="#b1">(Arpit et al. 2017)</ref>. In addition, different from the consistency regularization, our method is performed on features of unlabeled samples, not directly on class predictions, to avoid the memorization of wrong labels by the contrastive regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>We empirically validate that the contrastive regularization consistently improves the performance on standard SSL benchmarks such as SVHN, CIFAR-10, CIFAR-100, STL-10, and ImageNet with limited labels. We also show that the contrastive regularization is also robust to the open-set SSL setting, and an extensive ablation study is conducted in this section. For experiments, we use an exponential moving average (EMA) of model parameters <ref type="bibr" target="#b26">(Tarvainen and Valpola 2017)</ref> with 0.999 momentum and cosine learning rate scheduling in <ref type="bibr" target="#b25">(Sohn et al. 2020)</ref> for all experiments. The training epochs are computed based on the batch size of unlabeled samples. For a fair comparison, we follow the experimental setting in the previous study <ref type="bibr" target="#b25">(Sohn et al. 2020)</ref>, and attach the implementation details in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification of SVHN, CIFAR-10, CIFAR-100</head><p>To analyze the effect of contrastive regularization (CR), we reproduce FixMatch and UDA using Pytorch 1.6.0 <ref type="bibr" target="#b21">(Paszke et al. 2019)</ref>. For a fair comparison with previous studies, we use the encoder of WRN-28-2 (1.5M parameters) for SVHN and CIFAR-10, and a WRN-28-8 (23.4M parameters) for CIFAR-100. For SVHN and CIFAR-10, we also use WRN-28-8 (FixMatch+CR++) for comparison with Self-Match <ref type="bibr" target="#b15">(Kim et al. 2021</ref>) which uses over 21M parameters.</p><p>For the projection embedding z, we add a 2-layer MLP after the feature extractor h ? , and its dimension sizes are 64 for WRN-28-2 and 256 for WRN-28-8. We use RandAugment  for strong data augmentation, and set ? CS = 1.0. We use ? CR = 1.0 for SVHN and CIFAR-10, and ? CR = 10.0 for CIFAR-100. Following <ref type="bibr" target="#b25">(Sohn et al. 2020</ref>), FixMatch and UDA use 10,500 epochs of unlabeled data. FixMatch+CR uses 6,500 epochs for CIFAR-10 and SVHN, and 2,500 epochs for CIFAR-100 to achieve stateof-the-art results. Nevertheless, note that much less time needs to outperform FixMatch in the next section.</p><p>For SVHN and CIFAR-10, <ref type="table">Table 1</ref> shows that our method consistently improves the SSL performance of FixMatch on the same codebase. Consequently, the proposed Fix-Match+CR achieves the state-of-the-art performance of WRN-28-2 except SVHN with 40 labels. Although Fix-Match+CR cannot outperform the reported result of ReMix-Match <ref type="bibr" target="#b2">(Berthelot et al. 2019a</ref>) on SVHN with 40 labels, our method improves the test accuracy of FixMatch by 1.50%.</p><p>We emphasize that the contrastive regularization has remarkable performance gains. For the setting of 20 labels (2 labels per class), FixMatch+CR significantly improves the accuracy and the robustness to the selection of labeled samples. FixMatch+CR outperforms CoMatch <ref type="bibr" target="#b18">(Li, Xiong, and Hoi 2020)</ref>, which has firstly reported the results on CIFAR-10 with 20 and 40 labels. In addition, WRN-28-2 with FixMatch+CR are competitive with SelfMatch, although the number of parameters is about 15 times smaller. When we increase the number of parameters into 23.4M, FixMatch+CR++ outperforms SelfMatch in all experimental settings of SVHN and CIFAR-10.</p><p>Our method is also effective on the CIFAR-100 dataset with 400, 2,500, and 10,000 labels <ref type="table" target="#tab_1">(Table 2)</ref>. When the <ref type="table">Table 1</ref>: Test accuracies (%) for SVHN and CIFAR-10 on five different runs with randomly selected labeled samples. The Asterisks mean that the results are from the previous studies <ref type="bibr" target="#b25">(Sohn et al. 2020;</ref><ref type="bibr" target="#b18">Li, Xiong, and Hoi 2020;</ref><ref type="bibr" target="#b15">Kim et al. 2021</ref>   contrastive regularization is used along with UDA and Fix-Match, it improves the performance and outperforms the previous methods. Note that the performance gains are significant and consistent regardless of the number of labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification of STL-10 and ImageNet</head><p>We evaluate our contrastive regularization on a larger scale of datasets such as STL-10 and ImageNet. We set ? CS = 1.0 for SVHN and ? CS = 10.0 for ImageNet, and ? CR = 10 for the two. The STL-10 dataset includes 5,000 labeled and 100,000 unlabeled 96?96 images in 10 classes. We train WRN-37-2 (5.9M parameters) on STL-10 with five folds of 1,000 and 5,000 labels. 10,500 and 5,000 epochs are used for FixMatch and FixMatch+CR, respectively. The projection head uses 2-layer MLP with 256 dimensions. For 1,000 labels, FixMatch+CR improves the results of FixMatch in <ref type="table" target="#tab_2">Table 3</ref>. For 5,000 labels, FixMatch+CR achieves 95.40%, improving 95.18% of FixMatch. We also evaluate our method on the ImageNet dataset that includes about 1.3M training images in 1,000 object classes. We use a self-supervised and pretrained ResNet-50 model by MoCo v2 <ref type="bibr" target="#b11">(He et al. 2020;</ref><ref type="bibr" target="#b7">Chen et al. 2020c</ref>), since reproducing FixMatch on ImageNet from scratch requires expensive cost such as about three days using 32 cores of TPU. We use 1,024 labeled and 5,120 unlabeled images in each minibatch, and train a model in 300 epochs of unlabeled data. 2-layer MLP with 512 dimensions is used for the projection embedding. For 1% and 10% of labels, our contrastive reg- ularization improves the accuracy of FixMatch in <ref type="table" target="#tab_2">Table 3</ref>, and our method significantly improves the performance on the fewer labels. Thus, we conclude that our contrastive regularization is also effective on large-scale datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cost Efficiency of the Contrastive Regularization</head><p>The contrastive regularization not only improves the accuracy, but also enhances the training efficiency of SSL. For a fair comparison of training time, four NVIDIA V100 GPUs are used to train both FixMatch and FixMatch+CR. In <ref type="figure">Figure</ref> 2(a), the accuracy of FixMatch gradually increases over the entire training time of 10,500 epochs. Although one iteration of FixMatch+CR takes about 1.5? more time than FixMatch due to the use of two strongly augmented views, FixMatch+CR only takes 31% of the total training time of FixMatch to achieve the best performance. Also, 7% of the training time of FixMatch is enough for FixMatch+CR to achieve the best performance of FixMatch (dashed line). For other datasets, 2,500 epochs for SVHN and CIFAR-10, 1,000 epochs for CIFAR-100, and 1,500 epochs for STL-10 are enough to outperform FixMatch of 10,500 epochs, as shown in Appendix C. Consequently, our method can save the training cost, reducing the training time and iterations. We conjecture that the improved efficiency comes from the well-clustered representations by the contrastive regularization in the early stage of training. <ref type="figure" target="#fig_2">Figure 2(b)</ref> shows how features are well-clustered according to their pseudolabels in terms of Silhouette score <ref type="bibr">(Rousseeuw 1987)</ref>. If the decision boundary lies in the low-density regions and the features are well-clustered, the score is closed to +1, other- wise it is closed to -1. For the features of strongly augmented samples, the clustering scores of FixMatch are near zero and it increases slowly after 40K iterations. However, the clustering score of FixMatch+CR increases fast in the early stage of training. In addition, the scores are much higher than those of FixMatch during the entire training. This means that our contrastive regularization is effective in feature clustering, especially in the early training stage, and eventually improves both the training efficiency and final performance. <ref type="table" target="#tab_3">Table 4</ref> shows that the contrastive regularization is especially effective to a smaller model for SSL. When the contrastive regularization is applied to WRN-28-4 and WRN-28-2 with 2500 labels of the CIFAR-100, the accuracies are improved by 2.25% and 4.29%, respectively. Thus, the obtained accuracies of WRN-28-2 and WRN-28-4 with the contrastive regularization are comparable with those of WRN-28-4 and WRN-28-8 without it, respectively. Note that increasing the widen factor by two times leads to a four times larger number of trainable parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open-Set Semi-Supervised Learning</head><p>For a realistic evaluation, open-set SSL <ref type="bibr" target="#b20">(Oliver et al. 2018;</ref><ref type="bibr" target="#b29">Yu et al. 2020</ref>) assumes that an unlabeled dataset includes out-of-distribution (OOD) samples, which are totally different from the training and test samples. Considering SVHN and CIFAR-10 as OOD of CIFAR-100, we add the OOD samples to the unlabeled data of CIFAR-100, and train WRN-28-4 on CIFAR-100 with 2500 and 10000 labels. Then, we evaluate the accuracy on the test data of CIFAR-100 according to the number of added OOD samples such as 10K, 20K, 30K, and 40K.</p><p>As shown in <ref type="figure" target="#fig_3">Figure 3</ref>, the contrastive regularization enhances the robustness of SSL to the OOD samples. FixMatch has severe degradation of accuracy as OOD samples are added into unlabeled data. However, FixMatch+CR avoids the accuracy degradation and always outperforms FixMatch regardless of the number of OOD samples, because Fix-Match+CR effectively leverages unlabeled samples from indistribution, when the number of labels is limited. ( <ref type="table">Table 1)</ref>. Note that FixMatch+CR is more robust to the OOD samples from SVHN than those from CIFAR-10, since SVHN has a totally different class distribution from CIFAR-100 and less affects the discrimination of the CIFAR-100 classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study</head><p>Effects of Hyper-parameter Settings. We conduct an extensive ablation study to understand the effects of the different components in our method. In <ref type="figure">Figure 4(a)</ref>, the contrastive regularization improves the accuracy when the weight of the contrastive loss ? CR is large enough (? CS is fixed to 1.0). Although an excessive large value of ? CR deteriorates the test accuracy by increased confirmation bias, the performance is robust to the selection of the ? CR . <ref type="figure">Figure 4(b)</ref> shows the effect of the consistency regularization on the SSL performance, where the weight of contrastive loss ? CR is fixed to 10.0. The test accuracy decreases when the weight of the consistency regularization ? CS increases, since the relative effect of our contrastive regularization decreases. When the ? CS becomes smaller than 1.0, the test accuracy is competitive with ? CS = 1.0 and shows the effectiveness of our method.</p><p>Although the consistency regularization can completely be replaced with our contrastive regularization, we use the two regularizations to consistently achieve the state-of-theart performance on different settings of the number of labeled samples. In <ref type="table" target="#tab_8">Table 6</ref>, we remove the consistency regularization and evaluate our contrastive regularization alone (CR-only, ? CS = 0) on CIFAR-10 with WRN-28-2. When 4000 labels are available, CR-only still outperforms Fix-Match, but the performance of CR-only is degraded when 40 and 250 labels are used. Without the consistency regularization, the task-specific classification head is trained only by a supervised loss on labeled data L L (X ) in Eq. (1), and it can be easily overfitted when the number of labeled samples is few. Thus, our method is complementary to the consistency regularization to maximize the SSL performance.</p><p>In <ref type="figure">Figure 4</ref>(c), the accuracies of both FixMatch and Fix-Match+CR decrease when the ratio of unlabeled samples is low. This observation is consistent with the findings in UDA and FixMatch. It indicates that both consistency and contrastive approaches require a sufficiently large number of unlabeled samples in a mini-batch for high SSL performance. <ref type="figure">Figure 4(d)</ref> shows that the confident threshold is related to the trade-off between the reliability of pseudo-labeling and the number of unlabeled samples leveraged. The confidence thresholds of the consistency and contrastive regularizations are denoted as ? in Eq. (2) and ? in Eq. (9), respectively. The low value of ? worsens the performance of both FixMatch and FixMatch+CR because of the low reliability of pseudolabeling. Although the test accuracy of FixMatch with ? = 0 drops to 68.74%, only half of the training epochs are needed to achieve the performance, since it leverages all unlabeled samples regardless of the pseudo-labeling quality. When ? becomes low, <ref type="table" target="#tab_1">FixMatch+CR suffers from the confirmation   385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400  401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416  417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432  433  434  435  436  437  438  439</ref> Submission and Formatting Instructions for ICML 2021  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Number of Views The main difference between</head><p>FixMatch and FixMatch+CR is the number of augmented views per each unlabeled sample since the contrastive learning requires at least two views of samples <ref type="bibr">(Chen et al., 2020;</ref><ref type="bibr" target="#b14">Khosla et al., 2020)</ref>. Thus, we compare the performance of the two methods according to the number of views. <ref type="table" target="#tab_2">Table 3)</ref> shows that the performance gain by the contrastive regularization does not come from just the increased number of views. The accuracy of FixMatch is not much improved when two different views of a sample are used for training. When three views are used for training, the accuracy of Fix-Match is more improved, but still less than the contrastive regularization. This result implies that the performance improvement by our method does not depend only on the increased number of views, but also on the clustering effects of the contrastive regularization, as shown in <ref type="figure" target="#fig_0">Figure 1(c)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with Unsupervised Contrastive Loss</head><p>We compare our contrastive regularization with pseudo-labels to the unsupervised contrastive loss, NT-Xent <ref type="bibr">(Chen et al., 2020)</ref>. As an auxiliary task, a self-supervised pretext task is known to improve the performance of semi-supervised learning <ref type="bibr" target="#b32">(Zhai et al., 2019;</ref><ref type="bibr" target="#b15">Kim et al., 2021)</ref>. Thus, we assume that unsupervised NT-Xent also improves the performance of semi-supervised learning if the improvement by the contrastive regularization only depends on an auxiliary representation learning. <ref type="table" target="#tab_3">Table 4</ref> shows that the NT-Xent rather decreases the performance of SSL. We hypothesize that the task-agnostic instance discrimination tends to push away a semantically similar instance in the same class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Related Work</head><p>Recent SSL methods make use of the consistency regularization with different data augmentations (Laine &amp; Aila, 2016). Previous approaches vary data augmentations to improve the performance of SSL <ref type="bibr" target="#b3">(Berthelot et al., 2019b;</ref><ref type="bibr">a;</ref><ref type="bibr">Xie et al., 2019)</ref>. CoMatch ) also uses contrastive learning, but contains the pseudo-labeling smoothing and complex graph contrastive regularization with a large-size of memory bank <ref type="bibr" target="#b11">(He et al., 2020)</ref>.</p><p>Learning with scarce labels is not limited to the SSL. For example, a pre-trained model can be a solution for the limited data of a task. The unsupervised pre-training learns task-agnostic representations from unlabeled samples, defining pre-text tasks such as reconstruction of inputs <ref type="bibr" target="#b28">(Vincent et al., 2010)</ref> or the instance discrimination <ref type="bibr" target="#b11">(He et al., 2020;</ref><ref type="bibr">Chen et al., 2020;</ref><ref type="bibr">Grill et al., 2020)</ref>. However, the representations can be a suboptimal initialization to learn a specific task. The supervised pre-training first learns the hidden representations on other domains or tasks by a large-scale annotated dataset, then transfer the model into a specific task with limited labels <ref type="bibr" target="#b32">(Kolesnikov et al., 2019)</ref>. However, pre-training on another domain or task can cause negative transfer, when the target task is unrelated to the domain or task <ref type="bibr" target="#b31">(Zamir et al., 2018)</ref>. <ref type="bibr">(Assran et al., 2020;</ref><ref type="bibr" target="#b14">Khosla et al., 2020)</ref> use a contrastive loss with the label information for large-scale pre-training. In this work, our contrastive loss regularizes the representations for the cluster assumption, while predicting pseudo-labels during SSL training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>SSL is important for learning a specific task with limited labels. We have shown that the previous consistency regularization is insufficient to hold the cluster assumption so that it incrementally increases the accuracy during training  <ref type="table" target="#tab_1">385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400  401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416  417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432  433  434  435  436  437  438  439</ref> Submission and Formatting Instructions for ICML 2021 <ref type="figure">(d)</ref> and <ref type="figure" target="#fig_4">Figure 6</ref>. The ablation study on the hyper-parameters of the contrastive regularization. The test accuracies on differ hyper-parameters is reported (WRN-28-4, CIFAR-100). </p><formula xml:id="formula_9">(a) CR (b) ? (c) ?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Number of Views The main difference between</head><p>FixMatch and FixMatch+CR is the number of augmented views per each unlabeled sample since the contrastive learning requires at least two views of samples <ref type="bibr">(Chen et al., 2020;</ref><ref type="bibr" target="#b14">Khosla et al., 2020)</ref>. Thus, we compare the performance of the two methods according to the number of views. <ref type="table" target="#tab_2">Table 3)</ref> shows that the performance gain by the contrastive regularization does not come from just the increased number of views. The accuracy of FixMatch is not much improved when two different views of a sample are used for training. When three views are used for training, the accuracy of Fix-Match is more improved, but still less than the contrastive regularization. This result implies that the performance improvement by our method does not depend only on the increased number of views, but also on the clustering effects of the contrastive regularization, as shown in <ref type="figure" target="#fig_0">Figure 1(c)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with Unsupervised Contrastive Loss</head><p>We compare our contrastive regularization with pseudo-labels to the unsupervised contrastive loss, NT-Xent <ref type="bibr">(Chen et al., 2020)</ref>. As an auxiliary task, a self-supervised pretext task is known to improve the performance of semi-supervised learning <ref type="bibr" target="#b32">(Zhai et al., 2019;</ref><ref type="bibr" target="#b15">Kim et al., 2021)</ref>. Thus, we assume that unsupervised NT-Xent also improves the performance of semi-supervised learning if the improvement by the contrastive regularization only depends on an auxiliary representation learning. <ref type="table" target="#tab_3">Table 4</ref> shows that the NT-Xent rather decreases the performance of SSL. We that the task-agnostic instance discrimination away a semantically similar instance in the sa</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Related Work</head><p>Recent SSL methods make use of the consis ization with different data augmentations (L 2016). Previous approaches vary data augmen prove the performance of SSL <ref type="bibr">(Berthelot et al. et al., 2019)</ref>. CoMatch  also us learning, but contains the pseudo-labeling sm complex graph contrastive regularization wit of memory bank <ref type="bibr" target="#b11">(He et al., 2020)</ref>.</p><p>Learning with scarce labels is not limited to example, a pre-trained model can be a solutio ited data of a task. The unsupervised pre-tr task-agnostic representations from unlabeled s ing pre-text tasks such as reconstruction of in et al., 2010) or the instance discrimination <ref type="bibr">(H Chen et al., 2020;</ref><ref type="bibr">Grill et al., 2020)</ref>. However tations can be a suboptimal initialization to le task. The supervised pre-training first learn representations on other domains or tasks by annotated dataset, then transfer the model i task with limited labels <ref type="bibr">(Kolesnikov et al.,</ref><ref type="bibr">20</ref> pre-training on another domain or task can c transfer, when the target task is unrelated to t task <ref type="bibr" target="#b31">(Zamir et al., 2018)</ref>. (Assran et al., 2020; 2020) use a contrastive loss with the label in large-scale pre-training. In this work, our co regularizes the representations for the cluste while predicting pseudo-labels during SSL tra</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>SSL is important for learning a specific task labels. We have shown that the previous con larization is insufficient to hold the cluster a that it incrementally increases the accuracy d <ref type="table" target="#tab_1">385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400  401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416  417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432  433  434  435  436  437  438  439</ref> Submission and Formatting Instructions for ICML 2021  Effect of Number of Views The main difference between FixMatch and FixMatch+CR is the number of augmented views per each unlabeled sample since the contrastive learning requires at least two views of samples <ref type="bibr">(Chen et al., 2020;</ref><ref type="bibr" target="#b14">Khosla et al., 2020)</ref>. Thus, we compare the performance of the two methods according to the number of views. <ref type="table" target="#tab_2">Table 3)</ref> shows that the performance gain by the contrastive regularization does not come from just the increased number of views. The accuracy of FixMatch is not much improved when two different views of a sample are used for training. When three views are used for training, the accuracy of Fix-Match is more improved, but still less than the contrastive regularization. This result implies that the performance improvement by our method does not depend only on the increased number of views, but also on the clustering effects of the contrastive regularization, as shown in <ref type="figure" target="#fig_0">Figure 1(c)</ref>.</p><formula xml:id="formula_10">(a) CR (b) ? (c) ?<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with Unsupervised Contrastive Loss</head><p>We compare our contrastive regularization with pseudo-labels to the unsupervised contrastive loss, NT-Xent <ref type="bibr">(Chen et al., 2020)</ref>. As an auxiliary task, a self-supervised pretext task is known to improve the performance of semi-supervised learning <ref type="bibr" target="#b32">(Zhai et al., 2019;</ref><ref type="bibr" target="#b15">Kim et al., 2021)</ref>. Thus, we assume that unsupervised NT-Xent also improves the performance of semi-supervised learning if the improvement by the contrastive regularization only depends on an auxiliary representation learning. <ref type="table" target="#tab_3">Table 4</ref> shows that the NT-Xent rather decreases the performance of SSL. We hypothesize that the task-agnostic instance discrimination tends to push away a semantically similar instance in the same class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Related Work</head><p>Recent SSL methods make use of the consistency regularization with different data augmentations <ref type="bibr">(Laine &amp; Aila, 2016)</ref>. Previous approaches vary data augmentations to improve the performance of SSL <ref type="bibr" target="#b3">(Berthelot et al., 2019b;</ref><ref type="bibr">a;</ref><ref type="bibr">Xie et al., 2019)</ref>. CoMatch ) also uses contrastive learning, but contains the pseudo-labeling smoothing and complex graph contrastive regularization with a large-size of memory bank <ref type="bibr" target="#b11">(He et al., 2020)</ref>.</p><p>Learning with scarce labels is not limited to the SSL. For example, a pre-trained model can be a solution for the limited data of a task. The unsupervised pre-training learns task-agnostic representations from unlabeled samples, defining pre-text tasks such as reconstruction of inputs <ref type="bibr" target="#b28">(Vincent et al., 2010)</ref> or the instance discrimination <ref type="bibr" target="#b11">(He et al., 2020;</ref><ref type="bibr">Chen et al., 2020;</ref><ref type="bibr">Grill et al., 2020)</ref>. However, the representations can be a suboptimal initialization to learn a specific task. The supervised pre-training first learns the hidden representations on other domains or tasks by a large-scale annotated dataset, then transfer the model into a specific task with limited labels <ref type="bibr" target="#b32">(Kolesnikov et al., 2019)</ref>. However, pre-training on another domain or task can cause negative transfer, when the target task is unrelated to the domain or task <ref type="bibr" target="#b31">(Zamir et al., 2018)</ref>. <ref type="bibr">(Assran et al., 2020;</ref><ref type="bibr" target="#b14">Khosla et al., 2020)</ref> use a contrastive loss with the label information for large-scale pre-training. In this work, our contrastive loss regularizes the representations for the cluster assumption, while predicting pseudo-labels during SSL training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>SSL is important for learning a specific task with limited labels. We have shown that the previous consistency regularization is insufficient to hold the cluster assumption so that it incrementally increases the accuracy during training</p><formula xml:id="formula_11">(c) u )(1 p(i|u )),<label>(3)</label></formula><formula xml:id="formula_12">]{ X i6 =qu wip(i|u 0 ) (qu|u 0 ))}.<label>(4)</label></formula><p>the inefficiency rom the exclu--labels and the ls by the maskthe interpretame that the feaose to the decisoftmax classir w i is updated tures in <ref type="figure" target="#fig_3">Eq. (3)</ref>. updated by the aving confident ever, the uncons computations, q u }, whereq p andq u are the pseudo-label of p and u , re-spectively. Note that a pseudo-label of a strongly augmented sample u 0 is defined by the label prediction on the unlabeled sample u before strong augmentation. The augmented samples inP (u 0 ) have the same pseudo-label with u 0 . Then, the contrastive regularization, R CR , is defined as follows:</p><formula xml:id="formula_13">RCR(U) = 1 |Am(U)| X u 0 2Am(U ) 1[max qu &gt; 0 ]r(u 0 ),<label>(5)</label></formula><formula xml:id="formula_14">r(u 0 ) = 1 |P (u 0 )| X p 0 2P (u 0 ) log exp(hz u 0 , z p 0 i/? ) P v 0 2Am(U )/u 0 exp(hz u 0 , z v 0 i/? ) ,<label>(6)</label></formula><p>where 0 is a confidence threshold, ? is a temperature scaling parameter, and z u 0 is a normalized vector of the projection head. Our total loss is L(B) = L L (X ) + CS R CS (U ) + CR R CR (U ), where CS and CR is the loss ratio of consistency and contrastive regularization, respectively.</p><p>The features of confident samples move toward the centroid of its feature cluster, which consists of features having the same pseudo-labels, and pull the unconfident features in <ref type="figure">Figure 4</ref>: The ablation study on the hyper-parameters (WRN-28-4, CIFAR-100 with 2500 labels): (a) contrastive regularization loss ratio, (b) consistency regularization loss ratio, (c) unlabeled sample ratio in a mini-batch, and (d) confidence thresholds.  bias to some degree, but the test accuracy of FixMatch+CR with ? = ? = 0 still outperforms FixMatch, since our contrastive regularization effectively leverages unlabeled samples to improve the SSL performance. When ? keeps high value (0.95) and ? becomes low, the performance of Fix-Match+CR decreases, but the results with ? = 0 still significantly outperforms FixMatch with ? = 0.95. The results imply that our contrastive regularization at the feature-level does not explicitly update the weights of the classifier, and therefore it shows robust results to the noisy pseudo-labels. However, as generating reliable pseudo-labels is still important to improve the SSL performance, we apply the selection mask with ? &gt; 0 in our method. Note that, different from the consistency regularization, our contrastive regularization in Eq. (8) can still leverage unlabeled samples with both confident and unconfident pseudo-labels, while keeping high reliability of pseudo-labeling by the confidence threshold.</p><p>Effect of the Number of Views. FixMatch and Fix-Match+CR are compared with different numbers of augmented views m of A m . Note that at least two views of each sample are required for FixMatch+CR to assure the existence of a positive sample in each mini-batch <ref type="bibr" target="#b5">(Chen et al. 2020a)</ref>. <ref type="table" target="#tab_7">Table 5</ref> shows that the performance gain does not come from the solely increased number of views in our contrastive regularization. The accuracy of FixMatch is not improved by two augmented views and does not outperform FixMatch+CR although three augmented views are used. The results imply that the performance gain by our method does not depend on the increased number of views, but is from effectively leveraging more unlabeled data in SSL training shown in <ref type="figure" target="#fig_2">Figure 2</ref>.</p><p>Comparison with Unsupervised Contrastive Loss. We compare our method, which uses a contrastive loss with pseudo-labels for regularization, with the unsupervised contrastive loss (NT-Xent <ref type="bibr" target="#b5">(Chen et al. 2020a)</ref>). As an auxiliary task, a self-supervised pretext task is known to improve the performance of semi-supervised learning. Thus, we assume that unsupervised NT-Xent also improves the performance of semi-supervised learning, if the improvement by the contrastive regularization depends only on an auxiliary representation learning. <ref type="table" target="#tab_9">Table 7</ref> shows that the NT-Xent highly decreases the SSL performance. This might be due to that the task-agnostic instance discrimination tends to push away semantically similar instances in the same class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Semi-supervised learning is important to learn a task with limited labels, while effectively leveraging unlabeled data in a task-specific way. In this work, we show that the SSL training of the previous consistency regularization is biased on unlabeled samples only with confident pseudo-labeling by a selection mask. Thus, we propose contrastive regularization that significantly improves SSL performance and can be used along with the consistency regularization by minimal change of implementation. On various SSL benchmarks, the contrastive regularization not only improves the test accuracy but also significantly reduces the number of training iterations to achieve high performance. Especially, our method shows more effective results on a dataset containing fewer labels or out-of-distribution samples.</p><p>In future work, our approach can be applied to other SSL methods based on pseudo-labels (? <ref type="bibr" target="#b6">Chen et al. 2020b</ref>) on large-scale datasets. However, our method still has a limita-tion on the memory efficiency for large-scale datasets due to large batch size, although the contrastive regularization improves training efficiency and the SSL performance. Thus, it is also worth exploration for leveraging large-scale unlabeled datasets in a task-specific way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Contrastive Regularization for Semi-Supervised Learning</head><p>In this section, we introduce the detailed derivation of the gradients of contrastive regularization. For a model parameterized by ?, the label prediction of an unlabeled sample u ? U isp(y|u) = softmax[W h ? (u)], where a mini-batch of unlabeled sample U, K-class weight matrix W = [w 1 , w 2 , ..., w K ] ? R H?K and the penultimate features of u h ? (u) ? R H . We assume that the model parameter ? comprises the class weight matrix W . For a stochastic strong augmentation ?, we define the set of m strongly augmented samples in an unlabeled mini-batch as A m (U) = {u i |u ? U, u i = ?(u), 1 ? i ? m}.q u is the pseudo-label of u and defined asq u = arg max q u , where q u = sg[p(y|u)] and sg is the stop gradient. We define the set of pseudo-positive pairs of u asP (u ) = {p |p ? A m (U)/u ,q p =q u }, whereq p andq u are the pseudo-label of p and u , respectively. Note that pseudo-labels of strongly augmented samples are defined by the label predictions on the samples before the strong data augmentation to improve the reliability of pseudo-labeling. Then, for an unlabeled sample u in an unlabeled mini-batch U, contrastive regularization, R CR , is defined as follows:</p><formula xml:id="formula_15">R CR (U) = 1 |A m (U)| u ?Am(U ) 1[max q u &gt; ? ]r(u ),<label>(9)</label></formula><formula xml:id="formula_16">r(u ) = ?1 |P (u )| p ?P (u ) log exp( z u , z p /? ) v ?Am(U )/u exp( z u , z v /? ) ,<label>(10)</label></formula><p>where a confidence threshold ? , a temperature scaling parameter? , and a normalized vector of the projection head output z u .</p><p>Assuming that an augmented sample u = ?A(u) has a confident pseudo-label, we first show that the contrastive regularization moves the features of u toward the centroid of the feature cluster having the same pseudo-label, while pushing away the features in different clusters. Without the loss of generalizability, we assume z = h and ? = 1. In addition, we omit ? for the notation brevity. The first-order derivative of R CR with respect to a feature vector of u is as follows: </p><formula xml:id="formula_17">? ?r(u ) ?h(u ) = ?1 |P (u )| p ?P (u ) (?h(p ) + v ?A(U )/u s[u , v ]h(v )) (11) = ?1 |P (u )| p ?P (u ) [?h(p ) + v p ?P (u ) s[u , v p ]h(v p ) + v n ?N (u ) s[u , v n ]h(v n )] (12) = p ?P (u ) ( 1 |P (u )| ? s[u , p ])h(p ) ? v n ?N (u ) s[u , v n ]h(v n )<label>(13)</label></formula><formula xml:id="formula_18">( 1 |P (u )| ? s[u , p ])h(p ) + R(u ),<label>(14)</label></formula><p>where R(u ) is a remainder term. The feature vector of u is updated toward the centroid, which is the weighted sum of positive features regardless of the confidence of the pseudo-labels. For another unlabeled sample v ? U and v = A(v), the contrastive regularization on features with confident pseudo-labels pushes the features of v if v has a different pseudo-label, and pulls them otherwise. By the same process of the derivation of above ??r(u )/?h(u ), we can derive ??r(u )/?h(v ) as follows:</p><formula xml:id="formula_19">? ?r(u ) ?h ? (v ) = ( 1 |P (u )| ? s[u , v ])h ? (u ), if v ?P (u ) ? s[u , v ]h ? (u ), if v / ?P (u ) .<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation Details</head><p>For the implementation, we follow the setting of the original FixMatch paper <ref type="bibr" target="#b25">(Sohn et al. 2020</ref>) except the hyper-parameters related to the contrastive regularization. We use Pytorch 1.6.0 to reproduce FixMatch and implement the contrastive regularization on the same codebase. We conduct all experiments using four Tesla V100 32GB GPUs, except the ImageNet dataset. For ImageNet, we use 32 V100 GPUs for FixMatch and 64 GPUs for FixMatch with the contrastive regularization. For all datasets, we use the stochastic gradient descent (SGD) optimizer with Nesterov momentum ? = 0.9, and temperature parameter ? = 0.01. We use an exponential moving average (EMA) of model parameters with 0.999 momentum and cosine learning scheduling used in <ref type="bibr" target="#b25">(Sohn et al. 2020)</ref>. The batch size of labeled data (B) is 64 for SVHN, CIFAR-10, CIFAR-100, and STL-10 except SVHN with 20 and 40 labels, and CIFAR-10 with 20 labels. Considering the small number of labeled samples, we use 16 labeled samples for training SVHN with 20 and 40 labels, and 32 labeled samples for CIFAR-10 with 20 labels per training iteration of WRN-28-2. For WRN-28-8, we use 16 labeled samples for training SVHN with 20 and 40 labels, and 32 labeled samples for CIFAR-10 with 20 and 40 labels. In the ablation study for different hyper-parameters, we use WRN-28-4 for CIFAR-100 with 2500 labels, because WRN-28-8 requires over two times more training time than WRN-28-4 but the accuracy gain is marginal (+0.83% in <ref type="table" target="#tab_3">Table 4</ref>). We use random horizontal flipping and the random crop for both weak and strong augmentations of training datasets. For the SVHN dataset, we do not use horizontal flipping, considering that a classifier can be easily confused to discriminate some classes such as eight and three. For strong augmentations, we use RandAugment <ref type="bibr" target="#b25">(Sohn et al. 2020)</ref> following the original paper of FixMatch. Please refer to the original paper of FixMatch and our source codes to check the details of augmentation policies according to the datasets. The other training details are available in <ref type="table" target="#tab_10">Table 8</ref>. In this study, we have claimed that the previous consistency regularization suffers from the training inefficiency by the exclusion of unconfident pseudo-labels to ensure the reliability of pseudo-labeling. <ref type="figure" target="#fig_8">Figure 5</ref> shows the relationship between the confident threshold ? and the convergence speed of SSL training in FixMatch. When low confidence thresholds are used such as 0.0 or 0.7, FixMatch can leverage more unlabeled samples than FixMatch with ? = 0.95. Thus, SSL training with low confidence thresholds can achieve the best performance much faster and increase the training efficiency with respect to the training iterations and time. However, the low ?s lower the best test accuracies, because the unreliable pseudo-labeling propagates wrong labeling information to other unlabeled samples. Meanwhile, when a high confidence threshold is used, the accuracy increases slower especially in the early stage of training, because it cannot leverage many unlabeled samples. Despite the low training efficiency, FixMatch with ? = 0.95 can achieve high performance, while leveraging only its confident labeling information. The results imply that the training inefficiency of the previous consistency regularization comes from the trade-off between the reliability of pseudo-labeling and the number of used unlabeled samples in training. In the ablation study, we have shown that the increased views (m) of unlabeled samples also increase the accuracy of FixMatch. However, we show that more numbers of views cannot improve the training efficiency, and the accuracy over training still increases gradually in the training. The results imply that the effect of our contrastive regularization does not result from the increased views of unlabeled samples, but well-clustered representations for SSL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Additional Experimental Results</head><p>We show the additional results to show the more efficient training of contrastive regularization than consistency regularization. For better visualization, we try to train FixMatch+CR in the same epochs of FixMatch, 10,500 epochs, until Fix-Match+CR starts to be overfitted. First, we show that the results described in Section 4.3 are also consistent with other datsets such as CIFAR-10 ( <ref type="figure" target="#fig_0">Figure 10</ref>) and STL-10 ( <ref type="figure" target="#fig_10">Figure 7)</ref>. <ref type="figure">Figure 8 and 9</ref> show the test accuracy of EMA models, the average ratio of selection mask in a training mini-batch, and clustering scores of features in training on the CIFAR-10 dataset. The results imply that our contrastive regularization learns well-clustered features for SSL and requires fewer iterations for high performance. The accuracy of FixMatch gradually increases over the entire training iterations, but the accuracy of FixMatch+CR increases much faster than FixMatch, especially in the early stage of training. Moreover, we find that about 10% </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The feature update of (a) consistency and (b) contrastive regularization. Different colors represent pseudolabels. The circles with solid and dashed line are penultimate features having confident and unconfident pseudo-labels, respectively. The black dashed line is the decision boundary.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>, the confident features pull the features of both confident and unconfident samples in the same clusterP (u ), while pushing the features in different clusters. Although our contrastive regularization of a confident feature u learns to aggregate positive samples with s[u , v ] = 1/|P (u )|, the u can push a positive sample v of u with a negative value in Eq. (8) during training, because all positive samples in a mini-batch are included in the denominator of the long term in Eq. (10).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Results of FixMatch and FixMatch+CR with WRN-28-4 trained on the CIFAR-100 with 10000 labels. (a) Test accuracy over training time, (b) Silhouette score of penultimate features based on pseudo-labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Open-set SSL results of WRN-28-4 on CIFAR-100 with (a) 2500 and (b) 10000 labels. OOD samples (SVHN, CIFAR-10) are added into the unlabeld samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>The ablation study on the hyper-parameters of the contrastive regularization. The test accuracies on different settings of hyper-parameters is reported (WRN-28-4, CIFAR-100).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>d) and 0 Figure 6 .</head><label>06</label><figDesc>The ablation study on the hyper-parameters of the contrastive regularization. The test accuracies on different settings of hyper-parameters is reported (WRN-28-4, CIFAR-100).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>where s[u , p ]  is the softmax score of the pair of h(u ) and h(p ), N (u ) = {n |n ? A m (U),q n =q u }, n is the original sample of strongly augmented n . Since the sum of minus log-sum-exp terms is the convex function, the first-order optimality condition holds when the s *[u , v ] = 1/|P (u )| if v ?P (u ) and s * [u , v ] = 0 otherwise. Thus, the contrastive regularization on an unlabeled sample pushes the features of different pseudo-labels and pulls those of the same pseudo-label. Assuming that the softmax scores of the negative pairs are small enough, Eq. (13) is summarized as follows: ? ?r(u ) ?h(u ) = p ?P (u )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Test accuracy of FixMatch with different confident thresholds views over training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Test accuracy of FixMatch with different views over training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Test accuracy of FixMatch and FixMatch+CR of WRN-37-2 trained on STL-10 with (a) 1000 and (b) 5000 labels. (a) Test Accuracy of the EMA Model (b) The Ratio of Selection Mask in Training (c) Clustering Score Figure 8: Empirical Results of FixMatch and FixMatch+CR with WRN-28-2 trained on the CIFAR-10 with 250 labels. (a) Test accuracy of EMA models, (b) the ratio of selection mask, and (c) Silhouette score of penultimate features of unlabeled samples based on pseudo-labels. of iterations for FixMatch+CR are enough to achieve the performance of FixMatch. (a) Test Accuracy of the EMA Model (b) The Ratio of Selection Mask in Training (c) Clustering Score Figure 9: Empirical Results of FixMatch and FixMatch+CR with WRN-28-2 trained on the CIFAR-10 with 4000 labels. (a) Test accuracy of EMA models, (b) the ratio of selection mask, and (c) Silhouette score of penultimate features of unlabeled samples based on pseudo-labels. (a) Test Accuracy of the EMA Model (b) The Ratio of Selection Mask in Training (c) Clustering ScoreFigure 10: Empirical Results of FixMatch and FixMatch+CR with WRN-28-4 trained on the CIFAR-100 with 1000 labels. (a) Test accuracy of EMA models, (b) the ratio of selection mask, and (c) Silhouette score of penultimate features of unlabeled samples based on pseudo-labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>45?14.53 96.02?0.23 96.50?0.28 -52.46?11.50 88.95?0.86 93.58?0.10 UDA* -43.75?20.51 94.31?2.76 97.54?0.24 -70.95?5.93 91.18?1.08 95.12?0.18</figDesc><table><row><cell></cell><cell>).</cell></row><row><cell>SVHN 40 labels 250 labels 1000 labels 57.ReMixMatch* Method 20 labels MixMatch* --96.66?0.20 97.08?0.48 97.35?0.08 CoMatch* ----FixMatch 90.05?8.01 94.83?2.24 97.28?0.66 97.46?0.09 74.98?11.38 20 labels -81.85?5.56 FixMatch+CR 94.96?4.77 96.33?1.84 97.55?0.08 97.61?0.06 88.26?1.38 SelfMatch* -96.58?1.02 97.37?0.43 97.49?0.07 -FixMatch+CR++ 96.88?0.60 97.05?0.28 97.95?0.09 98.11?0.05 94.24?3.48</cell><cell>CIFAR-10 40 labels 250 labels 4000 labels 81.90?9.64 94.46?0.05 95.28?0.13 91.51?2.15 --91.24?3.72 94.67?0.28 95.57?0.05 94.31?0.90 94.96?0.30 95.84?0.13 93.19?1.08 95.13?0.26 95.94?0.08 95.26?0.70 96.00?0.31 96.68?0.18</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: Test accuracy (%) of WRN-28-8 on the CIFAR-100 dataset with 400, 2500, and 10000 labels.</cell></row><row><cell>CIFAR-100 400 labels 2500 labels 10000 labels 48.02?2.66 70.50?0.53 77.07?0.33 49.91?0.79 72.12?0.28 78.58?0.11 48.48?0.55 71.53?0.29 78.03?0.26 FixMatch+CR 50.77?0.79 72.42?0.37 Medthod UDA UDA+CR FixMatch 78.97?0.23</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="3">: Test accuracy (%) on the STL-10 and ImageNet datasets. Top-1 (top-5) accuracies are reported for ImageNet</cell></row><row><cell>Method FixMatch FixMatch+CR</cell><cell>STL-10 1,000 labels 89.34?1.79 93.04?0.42</cell><cell>ImageNet 1% labels 10% labels 51.29 (72.48) 72.18 (89.98) 57.77 (78.12) 72.77 (90.15)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Test accuracy (%) with different sizes of the widen factor on the same random seed. 28 layers of WRN is trained on CIFAR-100 with 2500 labels.</figDesc><table><row><cell>Widen Factor # of Params FixMatch FixMatch+CR</cell><cell>1 0.38M 1.48M 5.87M 23.40M 2 4 8 55.86 64.74 69.75 72.02 59.94 69.03 72.00 72.83</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Test</figDesc><table><row><cell cols="3">accuracies (%) on the different number of views per</cell></row><row><cell cols="3">a sample (WRN-28-4 trained on CIFAR-100 with 10000 labels).</cell></row><row><cell cols="3"># of Views 1 views 2 views 3 views FixMatch 76.01 76.03 76.67 + CR 76.08 78.27 77.83</cell></row><row><cell cols="3">Table 4. Performance Comparison with unsupervised contrasrive</cell></row><row><cell cols="3">learning for the SSL regularization (WRN-28-4 with CIFAR-100).</cell></row><row><cell>400 labels 2500 labels 10000 labels</cell><cell>FixMatch 49.42 69.75 76.15</cell><cell>+ NT-Xent 32.27 (-17.15) 50.15 (+0.73) +CR 54.44 (-15.32) 72.00 (+2.25) 67.02 (-9.13) 78.27 (+2.12)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Test</figDesc><table><row><cell cols="3">accuracies (%) on the different number of views per</cell></row><row><cell cols="3">a sample (WRN-28-4 trained on CIFAR-100 with 10000 labels).</cell></row><row><cell cols="3"># of Views 1 views 2 views 3 views FixMatch 76.01 76.03 76.67 + CR 76.08 78.27 77.83</cell></row><row><cell cols="3">Table 4. Performance Comparison with unsupervised contrasrive</cell></row><row><cell cols="3">learning for the SSL regularization (WRN-28-4 with CIFAR-100).</cell></row><row><cell>400 labels 2500 labels 10000 labels</cell><cell>FixMatch 49.42 69.75 76.15</cell><cell>+ NT-Xent 32.27 (-17.15) 50.15 (+0.73) +CR 54.44 (-15.32) 72.00 (+2.25) 67.02 (-9.13) 78.27 (+2.12)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 .</head><label>3</label><figDesc>Test</figDesc><table><row><cell cols="3">accuracies (%) on the different number of views per</cell></row><row><cell cols="3">a sample (WRN-28-4 trained on CIFAR-100 with 10000 labels).</cell></row><row><cell cols="3"># of Views 1 views 2 views 3 views FixMatch 76.01 76.03 76.67 + CR 76.08 78.27 77.83</cell></row><row><cell cols="3">Table 4. Performance Comparison with unsupervised contrasrive</cell></row><row><cell cols="3">learning for the SSL regularization (WRN-28-4 with CIFAR-100).</cell></row><row><cell>400 labels 2500 labels 10000 labels</cell><cell>FixMatch 49.42 69.75 76.15</cell><cell>+ NT-Xent 32.27 (-17.15) 50.15 (+0.73) +CR 54.44 (-15.32) 72.00 (+2.25) 67.02 (-9.13) 78.27 (+2.12)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Test accuracies (%) on the numbers of views (m) per sample in A m (CIFAR-100 with 10000 labels).</figDesc><table><row><cell># of Views FixMatch FixMatch+CR</cell><cell>m = 1 m = 2 m = 3 76.01 76.03 76.67 76.08 78.27 77.83</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell cols="2">: Test accuracies (%) of contrastive regularization without consistency regularization on CIFAR-10</cell></row><row><cell>CIFAR-10 FixMatch CR FixMatch+CR</cell><cell>40 labels 250 labels 4000 labels 94.81 95.11 95.6 91.51 94.41 95.89 95.32 95.39 95.92</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>SSL performance of unsupervised contrastive learning as the SSL regularization.</figDesc><table><row><cell>400 labels 2500 labels 10000 labels</cell><cell>FixMatch +NT-Xent 49.42 32.27 69.75 54.44 76.15 67.02</cell><cell>+CR 50.15 72.00 78.27</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>The details of hyper-parameters on training datasets. LR and WD describe initial learning rate and weight decay, respectively.</figDesc><table><row><cell>Dataset SVHN CIFAR-10 CIFAR-100 WRN-28-8 Model WRN-28-2 16, 64 7 B ? Epochs ?CS 6500 1.0 WRN-28-2 32, 64 7 6500 1.0 64 7 2500 1.0 STL-10 WRN-37-2 64 7 5000 1.0 ImageNet ResNet-50 1024 5 300 10.0</cell><cell>?CR 1.0 1.0 10.0 0.03 LR 0.03 0.0005 0.95 0.95 WD ? ? 0.03 0.0005 0.95 0.95 0.001 0.95 0.95 10.0 0.03 0.0005 0.95 0.95 1.0 0.05 0.003 0.7 0.7</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pseudo-labeling and confirmation bias in deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">MixMatch: A Holistic Approach to Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems, 32. Bishop, C. M. 2006. Pattern recognition and machine learning</title>
		<imprint>
			<publisher>springer</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The relative value of labeled and unlabeled samples in pattern recognition with an unknown mixing parameter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Castelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on information theory</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="2102" to="2117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Big Self-Supervised Models are Strong Semi-Supervised Learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="22243" to="22255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<title level="m">Improved baselines with momentum contrastive learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="702" to="703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On Data-Augmentation and Consistency-Based Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Thiery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CAP</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="281" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Label propagation for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Avrithis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5070" to="5079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Selfsupervised learning for semi-supervised time series classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jawed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Grabocka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific-Asia Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="499" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Supervised Contrastive Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-D</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gwon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06480</idno>
		<title level="m">SelfMatch: Combining Contrastive Self-Supervision and Consistency for Semi-Supervised Learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Big transfer (bit): General visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020-08-23" />
			<biblScope unit="page" from="491" to="507" />
		</imprint>
	</monogr>
	<note>Proceedings, Part V 16</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">CoMatch: Semisupervised Learning with Contrastive Graph Regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.11183</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1979" to="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Realistic Evaluation of Deep Semi-Supervised Learning Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="3235" to="3246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Wallach, H.</editor>
		<editor>Larochelle, H.</editor>
		<editor>Beygelzimer, A.</editor>
		<editor>d&apos;Alch?-Buc, F.</editor>
		<editor>Fox, E.</editor>
		<editor>and Garnett, R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc. Rousseeuw</publisher>
			<date type="published" when="1987" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="53" to="65" />
		</imprint>
	</monogr>
	<note>P. J.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1163" to="1171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Samuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Timo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Transductive semi-supervised deep learning using min-max features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">M</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="299" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Interpolation Consistency Training for Semisupervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno>978-0-9992411-4-1</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence, IJCAI&apos;19</title>
		<meeting>the 28th International Joint Conference on Artificial Intelligence, IJCAI&apos;19</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3635" to="3641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-Task Curriculum Framework for Open-Set Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="438" to="454" />
		</imprint>
	</monogr>
	<note>European Conference on Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Wide Residual Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference 2016. British Machine Vision Association</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Taskonomy: Disentangling task transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3712" to="3722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">S4l: Self-supervised semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1476" to="1485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">mixup: Beyond Empirical Risk Minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
