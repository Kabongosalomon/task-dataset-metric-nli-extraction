<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AuGPT: Auxiliary Tasks and Data Augmentation for End-To-End Dialogue with Pre-Trained Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon??</forename><surname>Kulh?nek</surname></persName>
							<email>jonas.kulhanek@cvut.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics</orgName>
								<orgName type="institution">Charles University</orgName>
								<address>
									<settlement>Prague</settlement>
									<country>Czechia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Czech Technical University</orgName>
								<address>
									<settlement>Prague</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Robotics and Cybernetics</orgName>
								<orgName type="institution">Czech Institute of Informatics</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
								<address>
									<settlement>Prague</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vojt?ch</forename><surname>Hude?ek</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics</orgName>
								<orgName type="institution">Charles University</orgName>
								<address>
									<settlement>Prague</settlement>
									<country>Czechia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom??</forename><surname>Nekvinda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics</orgName>
								<orgName type="institution">Charles University</orgName>
								<address>
									<settlement>Prague</settlement>
									<country>Czechia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ond?ej</forename><surname>Du?ek</surname></persName>
							<email>odusek@ufal.mff.cuni.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics</orgName>
								<orgName type="institution">Charles University</orgName>
								<address>
									<settlement>Prague</settlement>
									<country>Czechia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AuGPT: Auxiliary Tasks and Data Augmentation for End-To-End Dialogue with Pre-Trained Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Attention-based pre-trained language models such as GPT-2 brought considerable progress to end-to-end dialogue modelling. However, they also present considerable risks for taskoriented dialogue, such as lack of knowledge grounding or diversity. To address these issues, we introduce modified training objectives for language model finetuning, and we employ massive data augmentation via backtranslation to increase the diversity of the training data. We further examine the possibilities of combining data from multiples sources to improve performance on the target dataset. We carefully evaluate our contributions with both human and automatic methods. Our model substantially outperforms the baseline on the MultiWOZ data and shows competitive performance with state of the art in both automatic and human evaluation. 2 https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Unlike traditional task-oriented systems based on modularized pipelines <ref type="bibr" target="#b39">(Young et al., 2013;</ref>, end-to-end dialogue systems integrate nearly all functionality required to hold a dialogue into a single neural network <ref type="bibr" target="#b37">(Wen et al., 2017;</ref><ref type="bibr" target="#b8">Eric et al., 2017;</ref><ref type="bibr" target="#b19">Lei et al., 2018)</ref>, reducing error-propagation and data annotation requirements. While these systems are not yet ready for production use, they made considerable progress in recent years, especially with the advent of pretrained neural language models (LMs) <ref type="bibr" target="#b3">(Devlin et al., 2019;</ref><ref type="bibr" target="#b31">Radford et al., 2019;</ref><ref type="bibr" target="#b42">Zhang et al., 2020c)</ref>. Systems such as GPT-2 finetuned by <ref type="bibr" target="#b0">Budzianowski and Vuli? (2019)</ref> show that with an LM pre-trained on a large number of generaldomain dialogues without annotation, only small amounts of data are required to perform well in a given task-oriented domain.</p><p>On the other hand, the pre-trained LMs run enormous risks. First, solely training for response generation may result in a lack of grounding for the responses, where the LM hallucinates words without any relation to the database. This has been addressed by multi-task training and auxiliary training objectives  to an extent. Second, finetuning on small datasets may reduce response diversity and fluency due to neural networks' known propensity for catastrophic forgetting <ref type="bibr" target="#b11">(Greco et al., 2019)</ref> -the model overfits the finetuning dataset too tightly, "forgetting" the pre-trained language modeling capabilities.</p><p>This paper presents an end-to-end model for multi-domain task-oriented response generation on the MultiWOZ data <ref type="bibr" target="#b1">(Budzianowski et al., 2018)</ref>, 1 where we address the above problems with pretrained LMs. AuGPT is based on the GPT-2 LM and 's basic approach. Our contributions can be summarized as follows: ? We introduce a new dialogue consistency classification task based on subtle changes to the dialogue state (instead of fully random resampling) used as an auxiliary training objective, and we demonstrate its performance improvements.</p><p>? We present a novel application of token unlikelihood loss  in taskoriented dialogue to further improve diversity of our model's responses.</p><p>? We apply pre-training on additional datasets and massive data augmentation using backtranslation via multiple languages <ref type="bibr" target="#b33">(Sennrich et al., 2016)</ref> and demonstrate that both markedly improve task-oriented dialogue performance.</p><p>? We compare our model to multiple baselines on MultiWOZ in a corpus-based and simulated evaluation. We also include human evaluation results from a shared task competition, as well as detailed manual error analysis. We publish our augmented training data, source code, and pre-trained models on GitHub. 2 2 Related Work While the first attempts to build generative endto-end task-oriented systems mimicked the traditional dialogue system components <ref type="bibr" target="#b37">(Wen et al., 2017)</ref>, the task was soon recast as a sequence prediction problem in a two-stage setup. A sequenceto-sequence (seq2seq) model first generates the belief state based on dialogue context, then generates the system response based on the context and the belief state (Sequicity; <ref type="bibr" target="#b19">Lei et al., 2018)</ref>.</p><p>Recently, large-scale multi-domain task-oriented datasets were proposed <ref type="bibr" target="#b1">(Budzianowski et al., 2018;</ref><ref type="bibr" target="#b2">Byrne et al., 2019;</ref><ref type="bibr" target="#b32">Rastogi et al., 2020)</ref>. To address multiple domains, <ref type="bibr" target="#b40">Zhang et al. (2020a)</ref> introduce the LABES-S2S model that -in addition to a two-stage seq2seq approach -models belief states as discrete latent variables. <ref type="bibr" target="#b41">Zhang et al. (2020b)</ref> present DAMD, a three-stage seq2seq architecture which explicitly decodes the system action. They optimize for multiple good actions given a single belief state. <ref type="bibr" target="#b30">Qin et al. (2020)</ref> investigate sharing of domain knowledge and performance on unseen domains. <ref type="bibr" target="#b24">Lubis et al. (2020)</ref>'s LAVA model employs reinforcement learning over latent system actions initialized using a variational autoencoder.</p><p>The line of research closest to our work makes use of large pre-trained LMs based on the transformer architecture <ref type="bibr" target="#b34">(Vaswani et al., 2017)</ref> such as GPT-2 <ref type="bibr" target="#b31">(Radford et al., 2019)</ref> or BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref>. For example,  propose finetuning BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref> for taskoriented dialogue, <ref type="bibr" target="#b42">Zhang et al. (2020c)</ref> extended the GPT-2 LM to model open-domain chit-chat.</p><p>We follow research initiated by <ref type="bibr" target="#b0">Budzianowski and Vuli? (2019)</ref>, who use GPT-2 to model multidomain task-oriented dialogues. Recently, three similar modifications to their model were proposed, namely SOLOIST , SimpleTOD <ref type="bibr" target="#b15">(Hosseini-Asl et al., 2020)</ref>, and the approach by <ref type="bibr" target="#b13">Ham et al. (2020)</ref>. Our work extends these models and proposes a novel training approach and data augmentation strategies based on back-translation <ref type="bibr" target="#b4">(Edunov et al., 2018;</ref><ref type="bibr" target="#b9">Federmann et al., 2019)</ref>. Earlier works used a single pivot language <ref type="bibr" target="#b5">Einolghozati et al., 2019)</ref>, whereas our work applies 10 languages to increase variability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>The task-oriented setting requires the dialogue system to respond adequately to the user's input and fulfill its goal, e.g., booking a train or request-ing restaurant details. The system must process the user's input, keep track of the belief state (user preferences regarding individual slots, i.e., indomain attributes) and generate a relevant response in natural language. It must also interact with a database to incorporate external information into its responses (see <ref type="figure">Figure 1</ref> for an example). Following <ref type="bibr" target="#b0">Budzianowski and Vuli? (2019)</ref>, we choose the GPT-2 LM as our backbone and use the LM to model both the belief state and the response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Representation</head><p>The training instances for an LM-based taskoriented dialogue system can be considered as tuples <ref type="bibr">(c, b, d, r)</ref>, where c is the context (i.e., a concatenation of all previous utterances in the dialogue -both system's and user's), b is the system's belief state (used to query the database), d are the database results, and r is the system's response.</p><p>In our case, the dialogue system handles multiple domains and the belief state is a set of pairs (domain name, domain belief ), where the domain belief is an assignment of values into slots, i.e., a set of pairs (slot name, value) (see Example 1). Similarly, the database results d are a set of pairs (domain name, domain database results), where the domain database results are an ordered list of entities returned by the database. We further define the database result counts d c denoting the number of results in d for each domain.</p><p>Ideally, we would like our system to model the probability distribution over possible responses conditioned on the context p(r|c). To simplify computation and model external database queries, we factorize this distribution as follows:</p><formula xml:id="formula_0">p(r|c) = ? d p(r|d, c)p(d|c) = ? d ? b p(r|d, b, c)p(d|b)p(b|c) = ? b p(r|Query(b), b, c)p(b|c) ,<label>(1)</label></formula><p>where p(d|b) is a deterministic distribution over the database results, and Query is a function returning database results.</p><p>Using this factorization allows the model to process the context, query the database and generate a response based on database results. However, generating responses directly would result in data sparsity issues with rare tokens (e.g., venue names or reference numbers). To maximally reuse the training samples, we choose to train our model  <ref type="figure">Figure 1</ref>: The architecture of AuGPT. The pipeline runs in two stages. First, a finetuned GPT-2 LM is used to predict a belief. Then the database results are obtained and everything is passed to the GPT-2 again to predict a final delexicalized response, along with possible auxiliary tasks (belief consistency, intent classification, system action classification). Unlikelihood loss is used for response prediction training.</p><p>on delexicalized responses denotedr, where slot values are replaced with placeholders <ref type="bibr" target="#b36">(Wen et al., 2015)</ref>. During inference, the responses are lexicalized back deterministically using the belief state and the database results. We assume perfect lexicalization, i.e., always being able to lexicalize the responser back based on d and b. <ref type="bibr">3</ref> Both the database lookup and the lexicalization are deterministic, and the delexicalized respons? r does not depend on the database results d, but only on their counts d c . Therefore, the distribution p(r|d, b, c) is equal to the distribution p(r|d c , b, c), and by maximizing its likelihood we are achieving the goal of maximizing the likelihood of p(r|c).</p><p>We use the same language modelp to model the belief state and to generate the delexicalized prediction. That is,</p><formula xml:id="formula_1">p(r|d c , b, c) ?p(r|d c , b, c, ? ) (2) p(b|c) ?p(b| / 0, / 0, c, ? ) ,<label>(3)</label></formula><p>where we denote the model's parameters as ? .</p><p>In the MultiWOZ dataset <ref type="bibr" target="#b1">(Budzianowski et al., 2018;</ref><ref type="bibr">Eric et al., 2020, see Section 4)</ref>, responses are delexicalized by replacing concrete values with placeholder tokens of the form domain_slot. For better generalization across domains, we chose to only use slot instead as responses rarely involve more than one domain. We train our model to predict the active domain by outputting it first in the <ref type="bibr">3</ref> We found in our experiments on the MultiWOZ data (see Section 4) that this assumption was almost always fulfilled. To fully exploit natural language pre-training of our LM, we represent the belief state and database result counts as strings containing as few special tokens as possible (see Example 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Training</head><p>Although parameters are shared for the belief state predictor and the delexicalized response predictor, the training objectives differ slightly. We use crossentropy loss for both; response prediction uses unlikelihood loss  as an additional objective. Unlikelihood loss penalizes repeated tokens, which helps the model avoid repetitions and increases output diversity.</p><p>To help the model learn a better internal representation from the data, we employ additional auxiliary tasks. Similarly to <ref type="bibr" target="#b3">Devlin et al. (2019)</ref> and , we train a binary classifier to detect dialogue inconsistencies. In each training batch, we corrupt half of the samples by randomly applying one or more of the following changes with the same probability:</p><p>1. We replace the belief state b with another belief state, sampled uniformly randomly from the training data. 2. We replace the delexicalized responser with a different randomly chosen one. If this change is applied in combination with the first one, the delexicalized response and the belief state are taken from the same random sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A different valid value is uniformly sampled</head><p>for each slot in the belief state. In this case, the domain names and domain order are unchanged (i.e., the active domain is the same).</p><p>The first two changes are identical to . The third one is a new one which we find very useful -it is much more challenging to detect if the belief state was changed when the domain stays the same. Consistency detection employs an affine binary classifier on top of last response token logits, trained using binary cross-entropy (BCE).</p><p>We also experiment with additional two classifiers predicting the user intent and the system action. These are implemented as two fullyconnected layers attached to the last context token and the last database result token logits, respectively. However, based on our experimental results (see <ref type="table">Table 4</ref>), we decided not to use these tasks in the final model.</p><p>We train the whole pipeline by optimizing the non-weighted sum of individual component losses, i.e., cross-entropy for belief state and response prediction, unlikelihood loss for the response, and BCE for consistency detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Response Generation</head><p>For each user input, the system goes through several stages (see <ref type="figure">Figure 1</ref>): (1) Previous dialogue context is passed to the LM, which greedily generates the string representation of the belief state. (2) The belief state is parsed and passed to the database handler.</p><p>(3) The database handler returns a set of results for each domain. (4) A string representation of database result counts is created (see Example 1). (5) The context, belief state and database results are concatenated and passed again to the LM. We use nucleus sampling <ref type="bibr" target="#b14">(Holtzman et al., 2020)</ref> to gener-ate the delexicalized response. 5 (6) Placeholders in the delexicalized response are replaced by values from the database results and the belief state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Data Augmentation</head><p>Following its successful usage in other NLP tasks, <ref type="bibr" target="#b17">(Konstas et al., 2017;</ref><ref type="bibr" target="#b6">Elder et al., 2020)</ref>, we experiment with data augmentation using paraphrases. In our setup, we generate multiple paraphrases for each training utterance and use them to augment the training data. This way, we effectively increase the variability of the data.</p><p>Various data-driven approaches for paraphrasing were proposed, the majority of them corpora-based <ref type="bibr" target="#b26">(Madnani and Dorr, 2010)</ref>. Recently, machine translation systems showed strong performance in generating paraphrases using back-translation <ref type="bibr" target="#b33">(Sennrich et al., 2016;</ref><ref type="bibr" target="#b4">Edunov et al., 2018;</ref><ref type="bibr" target="#b9">Federmann et al., 2019)</ref>, i.e., translating an English text into an intermediate language and then translating the result back into English. We use two different Transformer-based machine translation systems to paraphrase our data. We used <ref type="bibr" target="#b4">Edunov et al. (2018)</ref>'s system with French and the system of <ref type="bibr" target="#b25">Mach??ek et al. (2020)</ref>; <ref type="bibr" target="#b44">Zouhar et al. (2021)</ref> with additional 40 pivot languages. Based on empirical analysis of translation quality, we chose 10 pivot languages for our data -we obtain 10 different paraphrases for each input utterance. <ref type="bibr">6</ref> When training, we choose the input user utterance uniformly at random from the set of all 10+1 variants of the utterance (backtranslation outputs and the original one).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>As our primary dataset, we use MultiWOZ 2.1, a de-noised version of MultiWOZ 2.0 <ref type="bibr" target="#b1">(Budzianowski et al., 2018)</ref>. We also used the 2.0 version to compare to previous works. The dataset contains 7 distinct domains (all related to tourist information, e.g., hotels, restaurants) and 10,438 dialogues, 7,032 of which are multi-domain.</p><p>We experiment with pre-training our model on additional datasets. For the pre-training phase, we use Taskmaster-1 <ref type="bibr" target="#b2">(Byrne et al., 2019)</ref> and Schema-   Guided Dialogue <ref type="bibr" target="#b32">(Rastogi et al., 2020)</ref>. 7 Both Taskmaster-1 and Schema-Guided Dialogue are multi-domain, task-oriented, large dialogue corpora consisting of 12,215 and 22,825 dialogues, respectively. Taskmaster-1 was obtained using the Wizard-of-Oz and self-dialogue methods, while the collection of Schema-Guided Dialogue is somewhat artificial -humans are only employed to paraphrase machine-generated utterances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data Preprocessing</head><p>Although the MultiWOZ 2.1 dataset was collected by humans, it contains a lot of inconsistencies. We hypothesize that when using only clean samples which are consistent with the database, the benefit of using higher quality training data outweighs the decrease in the number of training samples. This claim is further supported by experiments (see Section 6). To filter the training data, we choose only those dialogues where the annotated dialogue goal corresponds with the turn-level annotated data. When using the clean samples, we omit about 30% of the training data.</p><p>To effectively combine all our datasets, we unified the data ontologies. Since the datasets use different naming conventions (e.g., leaveAt vs. leave_at) and different domain and slot names to describe the same concepts (e.g., restaurant-food vs. restaurant-type), we 7 There are also other large-sized task-oriented datasets such as MetalWOZ , however, their annotation is not detailed enough for our setup. manually designed a mapping between domain and slot names. Notably, we decided to rename some slots so they use natural language tokens, as we base our model on the GPT-2 LM which is pretrained on natural language texts (e.g. "leaveAt" ? "leave at"). Our final ontology that unifies all three datasets contains 22 domains and 135 slots.</p><p>We use our own implementation of delexicalization, which directly produces our belief state string representation (see Section 3.1 and Example 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training Details</head><p>We implement our model in PyTorch <ref type="bibr" target="#b28">(Paszke et al., 2019)</ref>, based on GPT-2-small. It uses 12 layers with a size of 768. For all auxiliary tasks, we use a dropout of 0.1 with label smoothing 0.1. We use the AdamW optimizer <ref type="bibr" target="#b23">(Loshchilov and Hutter, 2019)</ref>. The finetuning runs for 8 epochs on the MultiWOZ 2.1 data when all the training examples are used, and for the same number of minibatches when using only clean samples. The training takes less than one day when using 4 GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Corpus-based Evaluation</head><p>To compare with previous results on MultiWOZ, we evaluate the model performance with a set of corpus-based intrinsic metrics on both versions of the data. For MultiWOZ 2.0, we use the original delexicalization used by compared baselines <ref type="bibr" target="#b15">Hosseini-Asl et al., 2020;</ref><ref type="bibr" target="#b41">Zhang et al., 2020b)</ref>. For MultiWOZ 2.1, we use our own delexicalization. We employ the original evalua-  tion scheme by <ref type="bibr" target="#b1">Budzianowski et al. (2018)</ref>, which provides two metrics -the inform rate and the success rate. The inform rate is the percentage of dialogues in which the system mentioned a name or ID of an entity which does not contradict the current dialogue state and the user's goal, whereas the success rate is the percentage of dialogues in which the system outputted all the requested information. Moreover, we compute BLEU <ref type="bibr" target="#b27">(Papineni et al., 2002</ref>) between the generated system utterances and the ground truth to get an approximation of the output fluency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">ConvLab 2 Evaluation</head><p>We use the ConvLab 2 platform <ref type="bibr" target="#b43">(Zhu et al., 2020)</ref> for automatic evaluation with a simulated user agent. We run the evaluation component 1,000 times, i.e. on 1,000 simulated conversations. The agent mimics user behavior, interacts with the system under evaluation, and computes multiple metrics: The complete rate reflects the ratio of dialogues that are completed, i.e. all the user requests have been met. The success rate computes the percentage of dialogues which are successful, meaning the system captures correct informed entities and provides a valid booking if requested. Finally, the book rate is the proportion of dialogues where the system was able to book the correct entity (hotel, restaurant, train) if it was asked to. We also compute precision, recall and F1 score for the informed entities and the average number of turns in the dialogue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Human Evaluation and Error Analysis</head><p>Thanks to our participation in the DSTC9 taskoriented dialogue shared task <ref type="bibr">(Gunasekara et al., 2020;</ref>, a variant of our model (without pre-training on additional dialogue datasets, see <ref type="table">Table 4</ref>) was selected for evaluation by human judges on the Amazon Mechanical Turk platform. 8 <ref type="bibr">8</ref> The selection was done based on ConvLab 2 performance, but probably used a different version of the tool and thus arrived at different results -the chosen variant is not the best The judges communicated with the agent in natural language and rated the system afterward with respect to the success/failure of the dialogue, language understanding score, and response appropriateness. Information provided by the system was additionally checked for consistency with the database, and the average of success rates given by the judges and by database grounding is used as the main metric.</p><p>In addition to the crowdsourced evaluation, we perform a detailed in-house error analysis based on human interactions with our final system. Expert annotators followed randomly chosen dialogue goals accompanying the MultiWOZ test set and recorded any incorrect system behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We first discuss quantitative results for both corpusbased and crowdsourced human evaluation, then include a qualitative analysis of the model behavior. <ref type="table" target="#tab_2">Table 1</ref> shows a comparison between our methods and current state-of-the-art systems (cf. Section 2). Since some of the compared methods do not provide results with on MultiWOZ 2.1, we report results on both MultiWOZ 2.0 and MultiWOZ 2.1. As we can see, AuGPT compares favorably to other approaches. The chosen variant of our model is not the best-scoring variant on corpusbased metrics (see <ref type="table">Table 4</ref>). It was chosen based on the ConvLab evaluation, which may not be optimal for corpus-based evaluation. LABES-S2S produces higher BLEU scores, which would indicate a better fluency of the model, but scores lower on inform and success rates. LAVA, SOLOIST, SimpleTOD, and MD-Sequicity, on the other hand, provide slightly higher inform and success scores while doing worse in terms of fluency. <ref type="table" target="#tab_3">Table 2</ref> shows a comparison with two other models in the ConvLab evaluation scheme with a simulated user. The compared systems were chosen one according to our own measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Corpus-based Evaluation on MultiWOZ</head><p>[...] user: I want to make a booking at sitar tandoori belief: restaurant {name = sitar tandoori} train {arrive by = 18:00, day = sunday, departure = cambridge, destination = london liverpool street, people = 1} system: What day would you like the booking for? user: the same day, 13:30 belief: restaurant {day = sunday, name = sitar tandoori, people = 1, time = 13:30} train {arrive by = 18:00, day = sunday, departure = cambridge, destination = london liverpool street, people = 1} system: Booking was successful. The table will be reserved for 15 minutes. Reference number is: 00000200.</p><p>Example 2: A dialogue where the system did not ask for necessary information. The user previously booked a train trip for one person (cf. the belief state in the first turn shown). When they went on to book a restaurant, the system took over the number of persons from the train ride and did not ask again.</p><p>because they both implement fully trainable end-toend methods. Our system outperforms both compared systems by a wide margin. Our model is able to perform well not just in a single-turn response generation scenario, but over the course of the whole dialogue. As the example of DAMD shows, this is not always guaranteed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Human Evaluation</head><p>We show the DSTC9 human evaluation results in <ref type="table" target="#tab_5">Table 3</ref>. Our model outperformed the baseline on the main average success metric (along with only 3 other submissions out of 10). We did not match the winning submission on average success, but we achieved the best overall success rate based on human judgments (without checking consistency with the database). This suggests that the main drawback of our model lies in database grounding. This could have been caused by our new delexicalization (Section 4.2). Finally, our model needed the smallest number of turns on average to complete the dialogues. Note that the model variant chosen for human evaluation did not include pre-training on additional data (cf. Section 4.6 and Footnote 8), which could improve performance in human evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Error Analysis</head><p>Our expert annotators evaluated 130 dialogues in total, 50 of which contained at least one error. However, in most cases, the system was able to recover from the errors, resulting in an overall success rate user : I am looking for a cheap chinse restaurant. belief: restaurant {food = chinese, price range = cheap} system: I have 4 cheap chinese restaurants. What area of town would you like to dine in? user: downtown belief: restaurant {area = centre, food = chinese, price range = cheap} system: I have 3 cheap chinese restaurants in the centre.</p><p>Would you like to book at Charlie Chan? ...</p><p>Example 3: A snippet from a challenging but successful dialogue. The system deals with input noise ("chinse") as well as with paraphrases ("downtown"). of 86.9% (i.e., 17 unsuccessful dialogues). The purpose of this analysis was to identify different types of errors occurring during full dialogues. By far the most common error (21 counts) were hallucinated values, i.e., lack of grounding for some of the information provided (see the end of Example 2). Another frequent error type is missing information (5 counts), i.e., not asking for information that is required (and e.g. reusing information from a different domain without user confirmation). Example 2 also demonstrates another common error type, which is bad domain (4 counts). Here, the system does not react to the user's request for a different search (hotels instead of attractions in the example). This might be caused by a less frequent wording of the request in the given context, and usually gets resolved by rephrasing the request.</p><p>The analysis also found many examples of correct system behavior in non-trivial cases. As illustrated in Example 3, the model is able to deal with paraphrases and is robust to a certain amount of noise in the data. Specifically, it handles typos, various time formats, etc. Interaction between domains is also successful in most cases -the system is able to resolve references to another domain's belief state (e.g., make a booking for the same group of people as done before in a different venue).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Ablation Study</head><p>We tested many variants of our method with different combinations of components to evaluate their contributions. The results are presented in <ref type="table">Table 4</ref>. Namely, we are interested in the following components: (1) unlikelihood loss, (2) auxiliary tasks, (3) data augmentation, (4) modified consistency task and (5) unclean data filtering.</p><p>We can see that all proposed contributions which are a part of our final system, except for the unlikelihood training, have a positive effect on the  <ref type="table">Table 4</ref>: Ablation study (inf = inform, suc = success, book = book rate; see Section 4.4). The model version with the best ConvLab 2 success rate is chosen as our best model. Variants are denoted with their respective modifications compared to the default: "w/o. unlikelihood" = unlikelihood loss was not used; "w/o. clean" uses all training samples as opposed to using only the ones consistent with the database; "w/o. pre-training" = Taskmaster-1 and Schema-Guided datasets were not used for training (this variant was selected for human evaluation); "all auxiliary" = using two additional auxiliary tasks (see the Method section); "w/o. consistency" = dialogue consistency task is not used; "old consistency" refers to the consistency task by  (see the Section 3.2). system performance. In the ConvLab evaluation, our final system performs best. Removing either pre-training or back-translations decreases BLEU, inform and success rates substantially. Furthermore, we notice the positive effect of using our improved consistency detection task over the one used in SOLOIST , which in turn scores better than no consistency detection. Training on all data as opposed to using only "clean" samples clearly reduces performance. On the other hand, unlikelihood training improves performance only in ConvLab while causing a performance drop in corpus-based metrics. This can be caused by the fact that the unlikelihood training promotes diversity and reduces repetitions on the token level, and thus does not play well with corpus-based evaluation. We did not notice any increase in performance when the user intent prediction and system action prediction auxiliary tasks were used (cf. Section 3.2). The reason for this behavior could be that the model learns to represent the actions well enough implicitly, without the need for these additional objectives. Therefore, these tasks are not a part of our final model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions &amp; Future Work</head><p>We present a dialogue modeling pipeline based on the pre-trained GPT-2 language model. AuGPT uses modified training objectives and employs data augmentation to increase the diversity of generated utterances. Our experiments show that the proposed approach outperforms baselines and is competitive with state of the art on the MultiWOZ dataset. We also run a series of ablation experiments to assess the individual contributions of the modifications. According to our detailed ablation study, training data augmentation using backtranslation via multiple languages and a modified auxiliary training objective for dialogue consistency detection are the features that contribute most to our system's performance. Additionally, we perform a qualitative analysis of the outputs to give a better insight into our model behavior.</p><p>In the future, we plan to construct a latent representation of the belief state and optimize it jointly with the language model. We will replace the deterministic lexicalization with a trainable alternative, and possibly even integrate the database module into the model. To improve the transfer to new domains, we will learn a domain embedding and optimize it jointly with the model, unifying all datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Detailed Error Analysis</head><p>Our expert annotators evaluated 130 dialogues in total, 50 of which contained at least one error. However, in most cases, the system was able to recover from the errors, resulting in an overall success rate of 86.9% (i.e., 17 unsuccessful dialogues). The purpose of this analysis was to identify different types of errors occurring during full dialogues. The annotators were familiar with the model architecture and were instructed to categorize the errors according to the cause of the problem. Specifically, they identified which component caused the respective error and annotators categorized the errors into more specific types.</p><p>The overall results are given in <ref type="table" target="#tab_9">Table 5</ref>. We observe that the most common reason for a failed dialogue is an error related to the belief state (30 errors, 10 failed dialogues). Also, although policy errors happen relatively often (21x), they rarely cause the whole dialogue to fail (2 dialogues). We observe that we have a slightly higher number of successful dialogues compared to the 82.6% success rate (without checking database consistency) found in human evaluation (cf. <ref type="table" target="#tab_5">Table 3</ref>). The most likely cause is that our expert annotators were more motivated to recover from erroneous system behavior and finish the dialogue.</p><p>Fine-grained error types identified by annotators are given in <ref type="table">Table 6</ref> and Examples 2, 4 and 3. To extend the analysis from Section 5.3, we include another frequent error type -missing information (5 counts), i.e., not asking for information that is required (Example 4). In this case, the system uses information from a different domain without the user explicitly confirming this. A most probable cause of this is that most instances of the training data carry over the information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Individual Component Analysis</head><p>We have conducted additional tests to obtain a deeper insight into each component's performance -DST and NLG. We have evaluated the accuracy of the generated belief states. Joint accuracy, slot accuracy, and F1 score were used. Joint accuracy gives the percentage of successfully generated belief states -with no error. Slot accuracy, on the other hand, is the average accuracy of correctly predicting the value for a domain-slot pair. To evaluate NLG, we compared the end-to-end system where the generated belief state is used to query user: I'm looking for a theatre in Cambridge belief: attraction {type = theatre} system: There are 5 theatres in Cambridge. Is there an area of town you prefer? user: no I don't care belief: attraction {type = theatre} system: I recommend Adc Theatre in the centre. Would you like more information? user: no, I'm also looking for some place to stay belief: attraction {type = theatre} system: I have 5 theatres in the centre. Do you have a price range? user: I'm looking for a place to stay belief: attraction {type = theatre} system: There are 5 theatres in the centre. Do you have a preference for area? user: I'm looking for a hotel belief: hotel {type = hotel} attraction {type = theatre} system: There are 9 hotels in the north. Do you have a price range?</p><p>Example 4: Dialogue sample with a bad domain focus and a hallucination. First, the system ignores that the user switched from searching for a theater to searching for a hotel. After accepting the new domain, the system replies with hotels "in the north" even though the user did not specify.</p><p>the database and generate the response with a variant of the pipeline, where the ground-truth belief state and/or ground-truth database result counts were used. The BLEU <ref type="bibr" target="#b27">(Papineni et al., 2002)</ref> and ROUGE-L <ref type="bibr" target="#b22">(Lin, 2004)</ref> scores were used for evaluation.</p><p>In <ref type="table">Table 7</ref>, we can see the performance of each individual component of the system. One can notice that the performance of NLG is not decreased when we use the generated belief state instead of the oracle belief state. Since the belief state prediction is not perfect, this suggests that the model does not actually need belief states for generating the delexicalized response. However, when the real database result counts are used instead of oracle database result counts, the performance decreases, which implies that the database result counts are important for NLG.  <ref type="table" target="#tab_9">Table 5</ref>: Interactive analysis performed by human evaluators using 130 prepared dialogue goals. 17 of these dialogues contained an error that caused the dialogue to fail. We show summary statistics regarding the number of respective error sources (BS = belief state, DB = database). Note that some of the dialogues contain more than one error.  <ref type="table">Table 6</ref>: Distribution of the most common error types encountered during the human evaluation of 130 dialogues. Absolute counts of errors in the 50 erroneous dialogues are shown. The total error count is 61 as some dialogues contained multiple errors. The most likely source of the error (cf.  <ref type="table">Table 7</ref>: Performance of DST and NLG components. Joint and slot accuracies, as well as slot values F1 score, are used to evaluate DST. For NLG, BLEU and ROUGE-L metrics are used. Apart from using the generated belief states and database counts, we also evaluate the components with oracle values. Note that models were pre-trained on Taskmaster-1 and Schema-Guided Dialogue datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Comparison with previous works on the MultiWOZ dataset (see Section 4.4 for a description of the metrics). MD-Sequicity is a variant of Lei et al. (2018)'s model, extended for a multi-domain setting.</figDesc><table><row><cell>inform</cell><cell>turn</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>ConvLab evaluation comparison with other works (see Section 4.5 for a description of the metrics).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Human evaluation results obtained during the DSTC9 shared task using Amazon Mechanical Turk. Note that only 4 out of 10 submissions outperformed the Baseline according to the average success metric.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5</head><label>5</label><figDesc>) and a short description are given for each type.</figDesc><table><row><cell>oracle</cell><cell></cell><cell>DST</cell><cell></cell><cell>NLG</cell><cell></cell></row><row><cell cols="3">fine-tuned on bs db joint acc. slot acc.</cell><cell>F1</cell><cell cols="2">BLEU ROUGE-L</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>17.2</cell><cell>39.0</cell></row><row><cell>MW 2.0</cell><cell>54.1</cell><cell>97.2</cell><cell>90.0</cell><cell>17.4</cell><cell>39.3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>17.4</cell><cell>39.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>17.4</cell><cell>38.6</cell></row><row><cell>MW 2.1</cell><cell>56.5</cell><cell>97.2</cell><cell>90.6</cell><cell>17.6</cell><cell>38.8</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>17.6</cell><cell>38.8</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://convlab.github.io</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">A disadvantage of this approach is that we cannot determine the active domain if the belief state is empty. However, in such a case the lexicalization would fail anyway, so the system's performance is not affected by this decision.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We found nucleus sampling useful for generating the response since it increases diversity, but we prefer greedy decoding for the belief state with a fixed structure. 6 Pivot languages used: Albanian, Arabic, Bulgarian, Bosnian, French, German, Russian, Spanish, Slovak, Swedish.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the Charles University GAUK grant No. 302120 and No. 373921, the  SVV project No. 260575, and the Charles University project PRIMUS/19/SCI/10. Jon?? Kulh?nek was supported by the European Regional Development Fund under the project Robotics for Industry 4.0 (reg. no. CZ.02.1.01/0.0/0.0/15_003/0000470). Additional computational resources were supplied by the project "e-Infrastruktura CZ" (e-INFRA LM2018140) provided within the program Projects of Large Research, Development and Innovations Infrastructures.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hello, it&apos;s GPT-2 -how can I help you? Towards the use of pretrained language models for task-oriented dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawe?</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli?</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-5602</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Neural Generation and Translation</title>
		<meeting>the 3rd Workshop on Neural Generation and Translation<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">MultiWOZ -a large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawe?</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-Hsiang</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I?igo</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Osman Ramadan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ga?i?</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1547</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels; Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5016" to="5026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Taskmaster-1: Toward a realistic and diverse dialog dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Krishnamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chinnadhurai</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Duckworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Semih</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyu-Young</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Cedilnik</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1459</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4516" to="4525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Understanding back-translation at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1045</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improving robustness of task oriented dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Einolghozati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrinal</forename><surname>Mohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rushin</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd Conversational AI Workshop at 33rd Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Shape of synth to come: Why we should use synthetic data for English surface realization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Elder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander O&amp;apos;</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.665</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7465" to="7471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">MultiWOZ 2.1: A consolidated multi-domain dialogue dataset with state corrections and state tracking baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihail</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shachi</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanchit</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adarsh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuj</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="422" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Key-value retrieval networks for task-oriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihail</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lakshmi</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Charette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-5506</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue<address><addrLine>Saarbr?cken, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="37" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multilingual whispers: Generating paraphrases with translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oussama</forename><surname>Elachqar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-5503</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)</title>
		<meeting>the 5th Workshop on Noisy User-generated Text (W-NUT 2019)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="17" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural approaches to conversational AI: Question answering, task-oriented dialogues and social chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Psycholinguistics meets continual learning: Measuring catastrophic forgetting in visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Greco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Fern?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1350</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3601" to="3605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chulaka</forename><surname>Gunasekara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seokhwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D&amp;apos;</forename><surname>Haro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihail</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnam</forename><surname>Hedayatnia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao-Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-T?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxiao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Liden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaili</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahin</forename><surname>Shayandeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runze</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swadheen</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikib</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carla</forename><surname>Gordon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.06486</idno>
		<title level="m">Shivani Poddar, and Rajen Subba. 2020. Overview of the ninth dialog system technology challenge: DSTC9</title>
		<editor>Seyed Hossein Alavi, David Traum, Maxine Eskenazi, Ahmad Beirami, Eunjoon, Cho, Paul A. Crook, Ankita De</editor>
		<meeting><address><addrLine>Alborz Geramifard, Satwik Kottur, Seungwhan Moon</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">End-to-end neural pipeline for goal-oriented dialogue systems using GPT-2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghoon</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeong-Gwan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngsoo</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kee-Eung</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.54</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="583" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The curious case of neural text degeneration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A simple language model for task-oriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Hosseini-Asl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Semih</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<imprint>
			<date type="published" when="2020-12-06" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>virtual</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Using paraphrasing and memory-augmented models to combat data sparsity in question interpretation with a virtual patient dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amad</forename><surname>Hussein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Danforth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-0502</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="13" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural AMR: Sequence-to-sequence models for parsing and generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1014</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="146" to="157" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Multi-domain task-completion dialog challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannes</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Layla</forename><forename type="middle">El</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmoud</forename><surname>Adada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendy</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequicity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqiang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xisen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1133</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Long Papers; Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1437" to="1447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multi-domain task completion dialog challenge II at DSTC9</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxiao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Liden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaili</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahin</forename><surname>Shayandeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runze</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swadheen</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichi</forename><surname>Takanobu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DSTC9 Workshop at AAAI</title>
		<meeting><address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Don&apos;t say that! Making inconsistent dialogue unlikely with unlikelihood training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilia</forename><surname>Kulikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-Lan</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.428</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4715" to="4728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">LAVA: Latent action spaces via variational auto-encoding for dialogue policy optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nurul</forename><surname>Lubis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Geishauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsien-Chin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Moresi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-main.41</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="465" to="479" />
		</imprint>
	</monogr>
	<note>Carel van Niekerk, and Milica Gasic</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">ELITR non-native speech translation at IWSLT 2020</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominik</forename><surname>Mach??ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon??</forename><surname>Kratochv?l</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangeet</forename><surname>Sagar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mat??</forename><surname>?ilinec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ond?ej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thai-Son</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuekun</forename><surname>Yao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.iwslt-1.25</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Spoken Language Translation</title>
		<meeting>the 17th International Conference on Spoken Language Translation<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="200" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Generating phrasal and sentential paraphrases: A survey of data-driven methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bonnie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dorr</surname></persName>
		</author>
		<idno type="DOI">10.1162/coli_a_00002</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="387" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Py-Torch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>K?pf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08" />
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Soloist: Building task bots at scale with transfer learning and machine teaching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinchao</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00399</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="807" to="824" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>Shahin Shayandeh, Lars Liden, and Jianfeng Gao</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dynamic fusion network for multidomain end-to-end task-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libo</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.565</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6344" to="6354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>OpenAI</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxue</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Sunkara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Khaitan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8689" to="8696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Improving neural machine translation models with monolingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1009</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="86" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Neural text generation with unlikelihood training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilia</forename><surname>Kulikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Stochastic language generation in dialogue using recurrent neural networks with convolutional sentence reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongho</forename><surname>Ga?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Mrk?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W15-4639</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="275" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A networkbased end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Mrk?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">M</forename><surname>Ga?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="438" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">ToD-BERT: Pre-trained natural language understanding for task-oriented dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.66</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="917" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">POMDP-based statistical spoken dialog systems: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ga?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1109/JPROC.2012.2225812</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1160" to="1179" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A probabilistic end-to-end task-oriented dialog model with latent belief states towards semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijian</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junlan</forename><surname>Feng</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.740</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9207" to="9219" />
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Taskoriented dialog systems that consider multiple appropriate responses under the same context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijian</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9604" to="9611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">DIALOGPT : Largescale generative pre-training for conversational response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-demos.30</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="270" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">ConvLab-2: An open-source toolkit for building, evaluating, and diagnosing dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichi</forename><surname>Takanobu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-demos.19</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="142" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Backtranslation feedback improves user confidence in MT, not quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vil?m</forename><surname>Zouhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Nov?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mat??</forename><surname>?ilinec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ond?ej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateo</forename><surname>Obreg?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><forename type="middle">L</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Blain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marina</forename><surname>Fomicheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Yankovskaya</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.14</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="151" to="161" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
