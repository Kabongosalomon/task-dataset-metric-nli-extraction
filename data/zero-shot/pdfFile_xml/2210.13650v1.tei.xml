<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ReaRev: Adaptive Reasoning for Question Answering over Knowledge Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Costas</forename><surname>Mavromatis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
							<email>karypis@umn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ReaRev: Adaptive Reasoning for Question Answering over Knowledge Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T07:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge Graph Question Answering (KGQA) involves retrieving entities as answers from a Knowledge Graph (KG) using natural language queries. The challenge is to learn to reason over question-relevant KG facts that traverse KG entities and lead to the question answers. To facilitate reasoning, the question is decoded into instructions, which are dense question representations used to guide the KG traversals. However, if the derived instructions do not exactly match the underlying KG information, they may lead to reasoning under irrelevant context. Our method, termed REAREV, introduces a new way to KGQA reasoning with respect to both instruction decoding and execution. To improve instruction decoding, we perform reasoning in an adaptive manner, where KGaware information is used to iteratively update the initial instructions. To improve instruction execution, we emulate breadth-first search (BFS) with graph neural networks (GNNs). The BFS strategy treats the instructions as a set and allows our method to decide on their execution order on the fly. Experimental results on three KGQA benchmarks demonstrate the REAREV's effectiveness compared with previous state-of-the-art, especially when the KG is incomplete or when we tackle complex questions. Our code is publicly available at https: //github.com/cmavro/ReaRev_KGQA.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A knowledge graph (KG) is a relational graph that contains a set of known facts. These facts are represented as tuples <ref type="bibr">(subject, relation, object)</ref>, where the subject and object are KG entities that link with the given relation. The knowledge graph questionanswering (KGQA) task takes as input a natural language question and returns a set of KG entities as the answer. In the weakly-supervised KGQA setting <ref type="bibr" target="#b4">(Berant et al., 2013)</ref>, the only available supervisions during learning are question-answer  <ref type="figure">Figure 1</ref>: The given question is decomposed into instructions {i (1) , i <ref type="bibr">(2)</ref> } that are matched with relations date and direct, respectively. If the instructions are executed in an incorrect order (i (1) ? ? i (2) ), we cannot arrive at the answer. Moreover, if the instructions cannot be matched with the relation aired on (right KG traversal), we cannot arrive at the second answer.</p><p>pairs, e.g., "Q: Who is the director of Pulp Fiction? A: Q. Tarantino". Due to labelling costs, the ground-truth KG traversals, such as the path Pulp Fiction director ? ??? ? Q. Tarantino, whose execution leads to the answers, are seldom available.</p><p>The KGQA problem involves two modules: (i) retrieving question-relevant KG facts, and (ii) reasoning over them to arrive at the answers. For the reasoning module, a general approach  is to decode the question into dense representations (instructions) that guide the reasoning over the KG. The instructions are matched with one-hop KG facts (or relations) in an iterative manner, which induces KG traversals that lead to the answers. Instructions are usually generated by attending to different question's parts, e.g., "...is the director..." <ref type="bibr" target="#b32">(Qiu et al., 2020a)</ref>. KG traversals are typically performed by utilizing powerful graph reasoners, such as graph neural networks (GNNs) <ref type="bibr" target="#b19">(Kipf and Welling, 2016;</ref><ref type="bibr" target="#b47">Sun et al., 2018)</ref>.</p><p>The main challenge is that question answering is performed over rich graph structures with possibly complex semantics, and thus, instruction decoding and execution is a key factor for KGQA. <ref type="figure">Figure 1</ref> shows an example where suboptimal initial instructions lead to incorrect KG traversals. While some methods <ref type="bibr" target="#b28">(Miller et al., 2016;</ref><ref type="bibr" target="#b58">Zhou et al., 2018;</ref><ref type="bibr" target="#b47">Sun et al., 2018;</ref><ref type="bibr" target="#b54">Xu et al., 2019)</ref> attempt to improve the quality of the instructions, they are mainly designed to tackle specific question types, such as 2-hop or 3-hop questions, or show poor performance for complex questions <ref type="bibr" target="#b46">(Sun et al., 2019)</ref>.</p><p>Our method termed REAREV (Reason &amp; Revise) introduces a new way to KGQA reasoning with respect to both instruction execution and decoding. To improve instruction execution, we do not use instructions in a pre-defined (possibly incorrect) order, but allow our method to decide on the execution order on the fly. We achieve this by emulating breadth-first search (BFS) with GNN reasoners. The BFS strategy treats the instructions as a set and the GNN decides which instructions to accept. To improve instruction decoding, we reason over the KG to obtain KG-aware information and use this information to adapt the initial instructions. Then, we restart the reasoning with the new instructions that are conditioned to the underlying KG semantics. To the best of our knowledge, adaptive reasoning with emulating graph search algorithms with GNNs has not been previously proposed for KGQA.</p><p>We empirically show that REAREV performs effective reasoning over KGs and outperforms other state-of-the-art. For KGQA with complex questions, REAREV achieves improvement for 4.1 percentage points at Hits@1 over the best competing approach.</p><p>Our contributions are summarized below:</p><p>? We improve instruction decoding via adaptive reasoning, which updates the instructions with KG-aware information. ? We improve instruction execution by emulating the breadth-first search algorithm with graph neural networks, which provides robustness to the instruction ordering. ? We achieve state-of-the-art (or nearly) performance on three widely used KGQA datasets:</p><p>WebQuestions <ref type="bibr" target="#b56">(Yih et al., 2015)</ref>, Complex We-bQuestions <ref type="bibr" target="#b49">(Talmor and Berant, 2018)</ref>, and MetaQA <ref type="bibr" target="#b57">(Zhang et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There are two mainstream approaches to solve KGQA: (i) parsing the question to executable KG queries like SPARQL, and (ii) grounding question and KG representations to a common space for reasoning.</p><p>Regarding the first case, early methods <ref type="bibr" target="#b4">(Berant et al., 2013;</ref><ref type="bibr" target="#b34">Reddy et al., 2014;</ref><ref type="bibr" target="#b3">Bast and Haussmann, 2015)</ref> rely on pre-defined question templates to synthesize queries, which requires strong domain knowledge. Recent methods <ref type="bibr" target="#b56">(Yih et al., 2015;</ref><ref type="bibr" target="#b0">Abujabal et al., 2017;</ref><ref type="bibr" target="#b26">Luo et al., 2018;</ref><ref type="bibr" target="#b5">Bhutani et al., 2019;</ref><ref type="bibr" target="#b23">Lan et al., 2019;</ref><ref type="bibr" target="#b22">Lan and Jiang, 2020;</ref><ref type="bibr" target="#b33">Qiu et al., 2020b;</ref><ref type="bibr" target="#b8">Das et al., 2021)</ref> use deep learning techniques to automatically generate such executable queries. However, they need ground-truth executable queries as supervisions (which are costly to obtain) and their performance is limited when the KG has missing links (nonexecutable queries).</p><p>Methods in the second category alleviate the need for ground-truth queries by learning natural language and KG representations to reason in a common space. These methods match question representations to KG facts <ref type="bibr" target="#b28">(Miller et al., 2016;</ref><ref type="bibr" target="#b54">Xu et al., 2019;</ref><ref type="bibr" target="#b2">Atzeni et al., 2021)</ref> or to KG structure representations <ref type="bibr" target="#b57">(Zhang et al., 2018;</ref><ref type="bibr" target="#b13">Han et al., 2021;</ref><ref type="bibr" target="#b32">Qiu et al., 2020a)</ref>. More related to our work, GraftNet <ref type="bibr" target="#b47">(Sun et al., 2018)</ref>, PullNet <ref type="bibr" target="#b46">(Sun et al., 2019)</ref>, and NSM  enhance the reasoning with graph-based reasoners. Our approach aims at improving the graph-based reasoning via adaptive instruction decoding and execution.</p><p>Researchers have also considered the problem of performing KGQA over incomplete graphs <ref type="bibr" target="#b29">(Min et al., 2013)</ref>, where important information is missing. These methods either rely on KG embeddings <ref type="bibr" target="#b38">(Saxena et al., 2020;</ref> or on side information, such as text corpus <ref type="bibr" target="#b47">(Sun et al., 2018</ref><ref type="bibr" target="#b46">(Sun et al., , 2019</ref><ref type="bibr" target="#b53">Xiong et al., 2019;</ref><ref type="bibr" target="#b12">Han et al., 2020)</ref>, to infer missing information. However, they offer marginal improvement over other methods when the KG is mostly complete.</p><p>KGQA has also been adapted to specific domains, such as QA over temporal <ref type="bibr" target="#b27">(Mavromatis et al., 2021;</ref><ref type="bibr" target="#b37">Saxena et al., 2021)</ref> and commonsense <ref type="bibr" target="#b42">(Speer et al., 2017;</ref><ref type="bibr" target="#b50">Talmor et al., 2019;</ref><ref type="bibr" target="#b24">Lin et al., 2019;</ref><ref type="bibr" target="#b10">Feng et al., 2020;</ref> KGs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">KG</head><p>A KG G := (V, R, F) contains a set of entities V, a set of relations R, and a set of facts F. Each fact (v, r, v ) ? F is a tuple where v, v ? V denote the subject and object entities, respectively, and r ? R denotes the relation that holds between them. A KG is represented as a directed graph with |R| relation types, where nodes v and v connect with a directed relation r if (v, r, v ) ? F. Nodes and relations are usually initialized with d-dimensional vectors (representations).</p><p>We denote h v ? R d and r ? R d the representations for node v and relation r, respectively. We denote N e (v) and N r (v) the set of node v's neighboring entities and relations (including selflinks), respectively. For example, v ? N e (v) and r ? N r (v) if a fact (v , r, v) exists. We use the terms nodes and entities interchangeably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">KGQA</head><p>Given a KG G := (V, R, F) and a natural language question q, the task of KGQA is to extract a set of entities {a} ? V that correctly answer q. Following the standard setting in KGQA <ref type="bibr" target="#b47">(Sun et al., 2018)</ref>, we assume that the entities referred in the question are given and linked to nodes of G via entity linking algorithms <ref type="bibr" target="#b56">(Yih et al., 2015)</ref>. We denote these entities as {e} q ? V (seed entities), e.g., Q. Tarantino in <ref type="figure">Figure 1</ref>.</p><p>The problem complexity is further reduced by extracting a question-specific subgraph G q := (V q , R q , F q ) ? G which is likely to contain the answers (more details in Section 5). Each question q and its answers {a} q ? V q , referred to as question-answer pair, induces a question-specific labeling of the nodes. Node v ? G q has label y v = 1 if v ? {a} q and y v = 0 otherwise. The task can be thus reduced to performing binary node classification over G q .</p><p>The KGQA problem involves two modules: (i) retrieving a question-specific G q and (ii) reasoning over G q to perform answer classification. In this work, we introduce a new way to advance KGQA reasoning capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">GNNs</head><p>GNNs <ref type="bibr" target="#b19">(Kipf and Welling, 2016;</ref><ref type="bibr" target="#b39">Schlichtkrull et al., 2018)</ref> are well-established graph representation learners suited for tasks such as node classification. Following the message passing strategy <ref type="bibr">(Gilmer et al.)</ref>, the core idea of GNNs is to update the representation of each node by aggregating itself and its neighbors' representations.</p><p>The GNN updates node representation h</p><formula xml:id="formula_0">(l) v at layer l as h (l) v = ? h (l?1) v , ? {m (l) v v : v ? N e (v) , (1) where m (l)</formula><p>v v is the message between two neighbors v and v , and ?(?) is an aggregation function of all neighboring messages. Function ?(?) combines representations of consecutive layers. At each layer, GNNs capture 1-hop information (neighboring messages). An L-layer GNN model captures the neighborhood structure and semantics within L hops.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">GNNs for KGQA</head><p>To better reason over multiple facts (graphs), successful KGQA methods utilize GNNs <ref type="bibr" target="#b47">(Sun et al., 2018;</ref>. The idea is to condition the message passing of Eq.(1) to the given question q. For example, if a question refers to movies, then 1-hop movie entities are more important. It is common practice <ref type="bibr" target="#b32">(Qiu et al., 2020a;</ref><ref type="bibr" target="#b41">Shi et al., 2021;</ref> </p><formula xml:id="formula_1">to decompose q into L representations {i (l) } L l=1 (instructions),</formula><p>where each one may refer to a specific question's context, e.g., movies or actors.</p><p>The instructions are used to guide different reasoning steps over G q by writing the GNN updates as</p><formula xml:id="formula_2">h (l) v = ? h (l?1) v , ? {m (l) v v : v ? N e (v)|i (l) } , (2) where each GNN layer l is now conditioned to a different instruction i (l) . Message m (l) v v usually de- pends on the representations of the corresponding fact (v , r, v).</formula><p>The goal of GNNs is to selectively aggregate information from the question-relevant facts. Via Eq.(2), GNNs learn to match each i (l) with 1-hop neighboring facts. Using the instructions {i (l) } L l=1 recursively, GNNs learn the sequence of facts (KG traversal) that leads to the final answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">REAREV Approach</head><p>REAREV (Reason &amp; Revise) enhances instruction decoding and execution for effective KGQA reasoning. Our contributions across these two dimensions are described below.</p><p>Question: "Which are ...?"</p><formula xml:id="formula_3">i (1)</formula><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GNN layer</head><formula xml:id="formula_4">H out i (1) i (K) ... K instructions H in Fuse i (K)</formula><p>...</p><formula xml:id="formula_5">H (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reasoning</head><p>Step</p><formula xml:id="formula_6">L ? 1 Reasoning Steps Decoding T ? Adaptive Stages</formula><p>Answer Classification <ref type="figure">Figure 2</ref>: REAREV's adaptive reasoning. The question is decoded to K instructions. At L reasoning steps, we perform a BFS execution of the instructions. The procedure is repeated for T adaptive stages that enhance the initial instruction decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">REAREV's BFS Instruction Execution</head><p>GNN updates in Eq.</p><p>(2) execute the instructions in a pre-defined order, which assumes that the generated instruction sequence matches exactly the information that is present in the KG. REAREV does not impose this assumption. Instead, it improves instruction execution by selecting the order by which to process the instructions on the fly, e.g., based on the KG semantics.</p><p>To achieve this, we emulate the breadth-first search strategy (BFS) by modifying the GNN updates in Eq.(2). The idea is to reason with all instructions at each step (breadh-first), before we decide which execution results to accept. We decompose the question into K instructions {i (k) } K k=1 , but the number of instructions K is now decoupled form the number of GNN layers L. We derive instruction-specific representationsh</p><formula xml:id="formula_7">(k,l) v at each GNN layer as h (k,l) v = ? {m (l) v v : v ? N e (v)|i (k) } .<label>(3)</label></formula><p>To allow the model select which instructionspecific representations are useful, we fuse them with a learnable function ?(?) as</p><formula xml:id="formula_8">h (l) v = ? h (l?1) v , {h (k,l) v } K k=1 .<label>(4)</label></formula><p>As a result, the reasoning module has the capability to decide on the final execution plan, i.e., which instructions are accepted at which GNN layers. Specifically, we compute message m <ref type="bibr">(l)</ref> v v between nodes v and v as the representation of their corresponding relation r v v ? R d followed by a learnable projection matrix W (l)</p><formula xml:id="formula_9">R ? R d?d . We condi- tion m (l)</formula><p>v v to the underlying instruction i (k) by an element-wise multiplication followed by ReLU(?) nonlinerarity. In summary, we obtain</p><formula xml:id="formula_10">c (k,l) v v = ReLU(i (k) W (l) R r v v ),<label>(5)</label></formula><p>where c <ref type="bibr">(k,l)</ref> v v denotes the question-relevant message from node v at layer l and for instruction k.</p><p>To measure the importance of c</p><formula xml:id="formula_11">(k,l) v v from node v , we multiply it with p (l?1) v</formula><p>of the previous layer, where p (l) ? [0, 1] |Vq| is a probability vector (we shortly describe how it is computed). We aggregate neighboring facts for node v with a sum-operation and Eq. <ref type="formula" target="#formula_7">(3)</ref> becomes</p><formula xml:id="formula_12">h (k,l) v = v ?N (v) p (l?1) v c (k,l) v v .<label>(6)</label></formula><p>To combine node representations from different instructions, we use the column-wise concatenation operation || followed by a learnable projection matrix W (l) h ? R d?(K+1)d (we observe similar performance with other fusion mechanisms, such as self-attention). Eq.(4) becomes</p><formula xml:id="formula_13">h (l) v = K k=1h (k,l) v (7) h (l) v = ReLU W (l) h (h (l?1) v ||h (l) v ) .<label>(8)</label></formula><p>Finally, we collect h (l) v for all nodes to H (l) and compute the probability vector p (l) as</p><formula xml:id="formula_14">p (l) = softmax(H (l) w).<label>(9)</label></formula><p>Initially, we set p</p><formula xml:id="formula_15">(0) v = 0 if v / ? {e} q and p<label>(0)</label></formula><p>v = 1 otherwise, so that we start reasoning from the seed entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">REAREV's Adaptive Instruction Decoding</head><p>If the instructions are computed based solely on the question's context, they are not conditioned with respect to the underlying KG. This is important when we need to reason over multiple facts (complex questions), over KGs with rich semantics (see <ref type="figure">Figure 1</ref>) or over missing information <ref type="bibr" target="#b47">(Sun et al., 2018)</ref>. <ref type="figure">Figure 2</ref> shows how our adaptive reasoning works. After reasoning with L steps via Eq.(3) and Eq.(4), we keep the reasoning output (node representations H out ) that contains KG-aware information. We use it to update the initial instruction decomposition {i (k) } K k=1 as well as the initial node representations H in . This procedure is repeated for T adaptation stages. Our goal is twofold; (i) to ground the instruction decomposition to underlying KG semantics, and (ii) to guide the reasoning process in an iterative manner. For example, some instructions may correspond to a part of the question that needs to be answered first, before reasoning with the rest instructions.</p><p>To update each i (k) at every stage t ? {1, . . . , T }, we use the seed entities' final representations as the KG-aware information, which are computed by</p><formula xml:id="formula_16">h e = v?{e}q h (L) v ,<label>(10)</label></formula><p>and compute the adapted instructions i (k) as</p><formula xml:id="formula_17">i (k) =(1 ? g (k) ) i (k) + g (k) W q (i (k) ||h e ||i (k) ? h e ||i (k) h e ).<label>(11)</label></formula><p>Here, W q ? R d?4d are learnable parameters and g (k) ? [0, 1] d is the output gate vector computed by a standard GRU <ref type="bibr" target="#b6">(Cho et al., 2014)</ref>. At every reasoning stage t, we set H in = H (L) to encode information of the previous stage. However, we reset the probability vector p (0) to the seed entities. The algorithmic procedure of our REAREV method is summarized in Algorithm 1. It takes as input a question q with seed entities {e} q , and the corresponding question-specific KG subgraph G q and classifies nodes as answers or non-answers. The number of adaptation stages T , instructions K, and reasoning steps L are hyper-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Optimization and Initialization</head><p>After reasoning for T stages, we obtain the final probability vector p out by applying Eq.(9) to H out = H (L) . Here, we omit the superscript t ? {1, . . . , T } for readability, e.g., H <ref type="bibr">(T,L)</ref> . We optimize the model's parameters with a classification based loss function (we use the KLdivergence <ref type="bibr" target="#b20">(Kullback and Leibler, 1951)</ref>), so that Algorithm 1 The high-level algorithmic procedure of REAREV (inference). for l = 1 to L do 5:</p><formula xml:id="formula_18">for k = 1 to K do 6:h (k,l) v = ? {m (l) v v : v ? N (v)|i (k) } . 7: end for 8: h (l) v = ? h (l?1) v , {h (k,l) v } K k=1 . 9:</formula><p>end for 10:</p><p>Set H out and H in to H (L) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>Update {i (k) } K k=1 using H out . 12: end for 13: Result: Classify node v as answer or nonanswer based on h out v .</p><p>p out v is close to 1 if v ? {a} q and zero otherwise. During inference, since we do not have the answer nodes {a} q , we rank the nodes as possible answers based on their final probabilities.</p><p>For better generalization to unobserved entities, we initialize node representations h in v as a function of their direct relations r ? N r (v), as</p><formula xml:id="formula_19">h in v = ReLU r?Nr(v) W 0 r ,<label>(12)</label></formula><p>where r ? R d is the representation of relation r and W 0 ? R d?d are learnable parameters. We derive the representation r with the same pre-trained language model used for the question based on the relation's surface form, if applicable. Otherwise, we randomly initialize and update r during training.</p><p>To capture multiple question's contexts, each instruction is initialized by dynamically attending to different question's tokens <ref type="bibr" target="#b32">(Qiu et al., 2020a;</ref>. First, we derive a representation b j for token j and a question representation q with pre-trained language models, such as Sen-tenceBERT <ref type="bibr" target="#b35">(Reimers and Gurevych, 2019</ref>) (see also Appendix). Each instruction i (k) is computed by</p><formula xml:id="formula_20">i (k) = j u (k) j b j ,<label>(13)</label></formula><p>where u (k) j ? [0, 1] is an attention weight for token j. To ensure different instructions can attend to different tokens, the dynamic attention is computed by</p><formula xml:id="formula_21">u (k) j = softmax j (W u (q (k) b j )), q (k) = W (k) (i (k?1) ||q||q i (k?1) ||q ? i (k?1) ),<label>(14)</label></formula><p>where W u ? R d?d and W (k) ? R d?4d are learnable parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Complexity</head><p>REAREV's computational complexity for each question is O(T |V q |L?), assuming the KG is sparse with maximum node degree equal to ?. We also assume that the inner loop in Algorithm 1 (line 6) is parallelized. On the other hand, the computations of traditional GNN-based KGQA methods (Section 3.4) can be achieved in O(|V q |L?) time. However, we find that having T = 2 is sufficient for REAREV in practice, so REAREV's complexity does not necessarily increase linearly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>We experiment with three widely used KGQA benchmarks: WebQuestionsSP (Webqsp) (Yih et al., 2015), Complex WebQuestions 1.1 (CWQ) <ref type="bibr" target="#b49">(Talmor and Berant, 2018)</ref>, and MetaQA-3 <ref type="bibr" target="#b57">(Zhang et al., 2018)</ref>. We provide the final dataset statistics (see Section 5.2) in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset Details</head><p>Webqsp contains 4,737 natural language questions that are answerable using a subset Freebase KG. This KG contains 164.6 million facts and 24.9 million entities. The questions require up to 2-hop reasoning within this KG. Specifically, the model needs to aggregate over two KG facts for 30% of the questions, to reason over constraints for 7% of the questions, and to use a single KG fact for the rest of the questions. CWQ is generated from Webqsp by extending the question entities or adding constraints to answers, in order to construct more complex multihop questions (34,689 in total). There are four types of question: composition (45%), conjunction (45%), comparative (5%), and superlative (5%). The questions require up to 4-hops of reasoning over the KG, which is the same KG with Webqsp.</p><p>MetaQA-3 consists of more than 100k 3-hop questions in the domain of movies. The questions were constructed using the KG provided by the WikiMovies <ref type="bibr" target="#b28">(Miller et al., 2016)</ref> dataset, with about 43k entities and 135k triples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Implementation and Evaluation Details</head><p>Recall that our REAREV takes as input the question's seed entities {e} q and a question-specific subgraph G q . We use the seed entities provided by <ref type="bibr" target="#b56">(Yih et al., 2015)</ref> for Webqsp, by <ref type="bibr" target="#b49">(Talmor and Berant, 2018)</ref> for CWQ, and by <ref type="bibr" target="#b28">(Miller et al., 2016)</ref> for MetaQA-3. We obtain subgraphs by . It runs the PageRank-Nibble <ref type="bibr" target="#b1">(Andersen et al., 2006)</ref> (PRN) method from the seed entities to select the top-m entiites to be included in the subgraph, as in <ref type="bibr" target="#b47">(Sun et al., 2018)</ref>. We have m = 2, 000 for Webqsp (full KG) and CWQ, and m = 500 for MetaQA-3 and Webqsp (incomplete KG).</p><p>We tune the hyper-parameters T (number of iterations), K (number of instructions), and L (number of GNN layers) amongst T ? {2, 3}, K ? {2, 3}, and L ? {2, 3, 4}. We perform model selection based on the best validation scores (more implementation details in the Appendix). For evaluation, we adopt two widely used metrics, Hits@1, which is the accuracy of the top-predicted answer, and the F1 score. To compute the F1 score we set a threshold equal to 0.95. For the competing approaches, we reuse the evaluation results reported in the corresponding papers, unless otherwise stated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Competing Approaches</head><p>We compare with methods that focus on improving KGQA reasoning capabilities.</p><p>KV-Mem <ref type="bibr" target="#b28">(Miller et al., 2016</ref>) is a key-value memory network <ref type="bibr" target="#b44">(Sukhbaatar et al., 2015)</ref> for KGQA. EmbedKGQA <ref type="bibr" target="#b38">(Saxena et al., 2020)</ref> utilizes KG pre-trained embeddings <ref type="bibr" target="#b51">(Trouillon et al., 2016)</ref> to improve multi-hop reasoning. GraftNet <ref type="bibr" target="#b47">(Sun et al., 2018)</ref>, HGCN <ref type="bibr" target="#b12">(Han et al., 2020)</ref> and SGReader <ref type="bibr" target="#b53">(Xiong et al., 2019)</ref> are GNN-based approaches, where GraftNet and HGCN use a convolution-based GNNs (Kipf and Welling, 2016), while SGReader uses attention-based GNNs <ref type="bibr" target="#b52">(Veli?kovi? et al., 2017)</ref>.</p><p>NSM  is the adaptation of Neural State Machines <ref type="bibr" target="#b17">(Hudson and Manning, 2019)</ref> to KGQA and performs a GNN-based reasoning. NSM-distill  improves NSM for multi-hop reasoning by learning which intermediate nodes to visit via distillation <ref type="bibr" target="#b15">(Hinton et al., 2015)</ref>. TransferNet <ref type="bibr" target="#b41">(Shi et al., 2021)</ref> improves multi-hop reasoning over the relation set. EmQL  and Rigel (Sen et al., <ref type="table">Table 1</ref>: Performance comparison of different methods (Hits@1 or F1 scores in %). Bold fonts denote the best methods.</p><p>Webqsp CWQ Method H@1 / F1 H@1 KV-Mem <ref type="bibr" target="#b28">(Miller et al., 2016)</ref> 46.7 / 38.6 21.1 SGReader <ref type="bibr" target="#b53">(Xiong et al., 2019)</ref> 67.2 / 57.3 -EmbedKGQA <ref type="bibr" target="#b38">(Saxena et al., 2020)</ref> 66.6 / -* GraftNet <ref type="bibr" target="#b47">(Sun et al., 2018)</ref> 66.7 / 62.4 32.8 PullNet <ref type="bibr" target="#b46">(Sun et al., 2019)</ref> 68.1 / -45.9 TransferNet <ref type="bibr" target="#b41">(Shi et al., 2021)</ref> 71.4 / -48.6 Rigel <ref type="bibr" target="#b40">(Sen et al., 2021)</ref> 73.3 / -48.7 NSM  68.7 / 62.8 47.6 NSM-distill  74.3 / 67.4 48.8 EmQL  75.5 / -* SQALER <ref type="bibr" target="#b2">(Atzeni et al., 2021)</ref> 70.6 / -* SQALER+GNN <ref type="bibr" target="#b2">(Atzeni et al., 2021)</ref>  In addition, we compare with methods that focus on improving the question-specific input subgraph G q . PullNet <ref type="bibr" target="#b46">(Sun et al., 2019)</ref> is built on top of GraftNet, but learns which nodes to retrieve via selecting shortest paths to the answers. SQALER <ref type="bibr" target="#b2">(Atzeni et al., 2021)</ref> learns which relations (facts) to retrieve during KGQA by reconstructing KG traversals to answers.</p><p>6 Experimental Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Main Results</head><p>We present the KGQA performance for the compared methods in <ref type="table">Table 1</ref>. REAREV outperforms the best performing method by 0.3% and 4.1% points at H@1 for Webqsp and CWQ, respectively.</p><p>For Webqsp, although most questions involve one-hop or two-hop reasoning, few training examples are given. Methods such as NSM-distill and SQALER+GNN tackle this challenge with additional supervision signals (compare NSM with NSM-distill and SQALER with SQALER-GNN), while EmQL uses pre-defined question templates to facilitate instruction execution. In contrast, REAREV relies on its adaptive reasoning. If we compare REAREV with other reasoningbased approaches (NSM, GraftNet, and SGReader), REAREV performs better by 5.7-9.7% (H@1 points) and 8.1-13.6% (F1 points). In CWQ, many questions include multiple seed entities and require both composition (sequential) and conjunction (parallel) reasoning, which makes the instruction execution challenging. REAREV's breadth-first strategy and adaptive updates are designed to benefit such challenging cases. Note that some methods cannot inherently tackle this setting: EmbedKGQA requires single-entity questions, EmQL requires pre-defined question templates that are hard to derive for complex questions, and SQALER assumes that only composition question types are involved. REAREV outperforms all other methods by more than 4% points at H@1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Low-Data Regime Results</head><p>Webqsp contains mostly simple questions which are easily answerable over a full KG. <ref type="table" target="#tab_2">Table 2</ref> shows the performance for a more challenging task, when keeping 10%, 30%, and 50% of the KG's total facts. We compare against GraftNet, SGReader, and HGCN, which are GNN-based approaches especially designed for reasoning over incomplete KG subgraphs. REAREV outperforms competing methods by 1.1-5.7% points at H@1 and by 0.7-5.6% points at F1. The best improvement is obtained for KG-50%, since there is more KG information that REAREV can leverage during its adaptive reasoning.</p><p>MetaQA-3 has more than 100k train questions which involve only few KG relations. For a more challenging setting, we experiment with MetaQA-3 when we decrease the ratio of the KG completeness as well as the number of training question-answer pairs. We compare against NSM and NSM-distill that also rely on subgraph extraction with PRN (Section 5.2). We provide additional results in the Appendix. <ref type="table" target="#tab_3">Table 3</ref> shows that the more challenging the setting is, the better the improvement REAREV achieves over NSM and NSM-distill. When the KG is 50% complete and we only use 1% of the training questions, REAREV improves over NSM-distill by more than 10% points at H@1.  <ref type="table" target="#tab_4">Table 4</ref> verifies that KGQA improvements stem from the algorithmic design of our method. For complex questions (CWQ), deriving the correct execution order of the instructions becomes challenging. By treating the instructions as a set, our BFS execution provides a performance gain of 4.7% points. When there are missing facts (Webqsp-50%), grounding the instruction decoding to the available information becomes crucial. Our adaptive decoding leverages this KG-aware information and provides a performance gain of 2.2% points. Moreover, we experiment with hyper-parameter sensitivity. We intentionally set L = 2 for MetaQA-3, although it requires 3-hop reasoning, and gradually increase T ? {1, . . . , 5} to evaluate whether REAREV can reach the answers. For T = 4 and K ? {2, 3}, REAREV achieves 84.5%-88.9% at H@1. When we set T = 5, REAREV further improves and achieves 98.7%-98.8% at H@1. In <ref type="table">Table 5</ref>, we provide two case studies that show how the number T of adaptive stages impacts answer retrieval.</p><p>In addition, we have performed the following ablation study at MetaQA-3 as motivated by <ref type="figure">Figure 1</ref>. The idea is to switch some KG relations with semantically similar ones during inferece to evaluate REAREV's adaptiveness. We switch the KG relations {directed by, written by, starred actors, release year} (out of total 9 relations) to {has executive, plot by, has cast, air on} respectively. During training, we switch them with 5% probability, but during testing, we switch them with a 50% or 100% probability, which enforces a distribution shift over the underlying relations. REAREV (T=2) with adaptive stages outperforms REAREV (T=1) without adaptive stages in both cases. It performs 87.3% and 86.9% at F1, while REAREV (T=1) performs 84.5% and 81.1% at F1, respectively. This experiment also suggests that it is REAREV's algo-  <ref type="table">Table 5</ref>: Question-answer pairs and predicted answers (with probabilities) with respect to the number T of adaptive stages. rithmic design that leads to its improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Our method (REAREV) introduces a new way to KGQA reasoning with respect to instruction execution and decoding. We improve instruction decoding via adaptive reasoning, which updates the instructions with KG-aware information. We improve instruction execution by emulating the breadth-first search algorithm, which provides robustness to the initial instruction ordering. Experimental results on three KGQA benchmarks demonstrate the REAREV 's effectiveness compared with previous state-of-the-art, especially when the KG is incomplete or when we tackle complex questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Limitations</head><p>Our contributions are on the reasoning part, and our method assumes that we have the linked entities and a question-specific subgraph as input. Although improving entity linking is out of our scope, our approach cannot recover from entity linking errors. However, just like REAREV, all the methods that we compare against make the same assumption and rely on external entity linking tools. The linked entities are obtained as explained in Section 5.2. Moreover, our method assumes that using a single GNN layer per reasoning step (see <ref type="figure">Figure 2</ref>) <ref type="table">Table 6</ref>: Datasets statistics. "avg.|V q |" denotes average number of entities in subgraph, and "coverage" denotes the ratio of at least one answer in subgraph. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Implementation Details</head><p>To encode questions, we use Sente-ceBERT <ref type="bibr" target="#b35">(Reimers and Gurevych, 2019)</ref>; although we observe similar results if we use BERT <ref type="bibr" target="#b9">(Devlin et al., 2018)</ref> or RoBERTa <ref type="bibr" target="#b25">(Liu et al., 2019)</ref>. For MetaQA, we use an LSTM encoder <ref type="bibr" target="#b16">(Hochreiter and Schmidhuber, 1997)</ref> and initialize tokens with Glove <ref type="bibr" target="#b31">(Pennington et al., 2014)</ref>.</p><p>The number of hidden dimensions d is tuned amongst {50, 100}. We optimize the model with Adam optimizer (Kingma and Ba, 2014), where the learning rate is set tuned amongst {1e ?4 , 5e ?4 , 1e ?4 } and the batch size is tuned amongst {8, 16, 40}. We tune the number of epochs amongst {10, 30, 50, 100, 200}. We apply dropout regularization <ref type="bibr" target="#b43">(Srivastava et al., 2014)</ref> with probability tuned amongst {0.1, 0.2, 0.3}. We perform model selection based on the best validation scores. For Webqsp, REAREV achieves a validation score of 78.4% at H@1, and for CWQ, a validation score of 57.4% at H@1.</p><p>We implemented REAREV using Py-Torch <ref type="bibr" target="#b30">(Paszke et al., 2017)</ref>, reusing the source code of <ref type="bibr" target="#b47">(Sun et al., 2018;</ref>. Experiments were performed on a Nvidia Geforce RTX-2070 and on a Nvidia Geforce RTX-3090 GPU over 32GB and 128GB RAM machines. Our code is publicly available at https://github.com/cmavro/ReaRev_KGQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 MetaQA Results</head><p>We provide MetaQA full results in <ref type="table" target="#tab_6">Table 7</ref>. We devide methods in two categories: (i) subgraph-based that may not be able to access all possible answers, and (ii) full-graph/retrieval-based that can access all KG facts. Subgraph-based methods performs worse when answers are missing (see MetaQA-3 and <ref type="table">Table 6</ref>). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Q:</head><label></label><figDesc>Who wrote movies that share directors with the movie The Comebacks? A: R. Schneider, T. Brady T = 3 : 2007 (0.99) T = 4 : R. Schneider (0.99) T = 5 : R. Schneider (0.5), T. Brady (0.5) Q: When did the movies release whose writers also wrote Birdy? A: 1989 T = 3 : 1989 (0.60), GD. Goldberg (0.11) T = 4 : 1989 (0.99) T = 5 : 1989 (1.0)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Input: Question q, KG subgraph G q , seed entities {e} q , hyper-parameters: T, K, L. 2: Initialize: K instructions {i (k) } K k=1 , node representations H in . 3: for t = 1 to T do</figDesc><table><row><cell>4:</cell></row></table><note>1:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>H@1 / F1 results in % for Webqsp with incomplete KGs. "% KG completeness" denotes the percent of the remaining KG facts.</figDesc><table><row><cell>% of KG completeness</cell><cell>10%</cell><cell>30%</cell><cell>50%</cell></row><row><cell>GraftNet (Sun et al., 2018)</cell><cell cols="3">15.5 / 6.5 34.9 / 20.4 47.7 / 34.3</cell></row><row><cell cols="4">SGReader (Xiong et al., 2019) 17.1 / 7.0 35.9 / 20.2 49.2 / 33.5</cell></row><row><cell>HGCN (Han et al., 2020)</cell><cell cols="3">18.3 / 7.9 35.2 / 21.0 49.3 / 34.3</cell></row><row><cell>REAREV</cell><cell cols="3">19.4 / 8.6 37.9 / 23.6 53.4 / 39.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>H@1 results in % for MetaQA-3 under different settings. "% KG completeness" denotes the percent of the remaining KG facts and "% Train QAs" the percent of training question-answer pairs used.</figDesc><table><row><cell cols="4">% of KG completeness 100% 100% 50% 50%</cell></row><row><cell>% of Train QAs</cell><cell>10%</cell><cell>1% 10%</cell><cell>1%</cell></row><row><cell>NSM</cell><cell>98.8</cell><cell cols="2">89.6 71.8 49.7</cell></row><row><cell>NSM-distill</cell><cell>98.9</cell><cell cols="2">98.2 72.3 51.5</cell></row><row><cell>REAREV</cell><cell>98.9</cell><cell cols="2">98.6 75.4 62.7</cell></row><row><cell>6.3 Ablation Studies</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>H@1 results in % (with performance drop) under different REAREV's modifications for Webqsp (50% complete) and CWQ. BFS Execution is described in Section 4.1 and Adaptive Decoding in Section 4.2.</figDesc><table><row><cell>Modification</cell><cell cols="2">Webqsp-50% CWQ</cell></row><row><cell>REAREV</cell><cell>53.4</cell><cell>52.9</cell></row><row><cell>without BFS Execution</cell><cell>52.6 (-0.8)</cell><cell>48.2 (-4.7)</cell></row><row><cell cols="2">without Adaptive Decoding 51.2 (-2.2)</cell><cell>50.5 (-2.4)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>H@1 performance comparison for MetaQA.</figDesc><table><row><cell>MetaQA-2 MetaQA-3</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>is sufficient. This may not be the case when, for example, we need to reason for multiple steps with the same instruction. Our method could benefit from designing a multistep reasoning module.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Dataset Statistics</head><p>In <ref type="table">Table 6</ref>, we provide the dataset statistics with the subgraph extraction algorithm described in Section 5.2. We also include the 2-hop MetaQA-2 <ref type="bibr" target="#b57">(Zhang et al., 2018)</ref> dataset, which is easier than MetaQA-3.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automated template generation for question answering over knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdalghani</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirek</forename><surname>Riedewald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th international conference on world wide web</title>
		<meeting>the 26th international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Local graph partitioning using pagerank vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reid</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">47th Annual IEEE Symposium on Foundations of Computer Science (FOCS&apos;06)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sqaler: Scaling question answering by decoupling multi-hop and logical reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mattia</forename><surname>Atzeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasmina</forename><surname>Bogojeska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Loukas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">More accurate question answering on freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Bast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elmar</forename><surname>Haussmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
		<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to answer complex questions over knowledge bases with query composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Bhutani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyi</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitian</forename><surname>William W Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Hofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Siegler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06115</idno>
		<title level="m">Scalable neural methods for reasoning with a symbolic knowledge base</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Case-based reasoning for natural language queries over knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dung</forename><surname>Thai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameya</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay-Yoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lazaros</forename><surname>Polymenakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Scalable multi-hop relational reasoning for knowledge-aware question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyue</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peifeng</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahl</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Open domain question answering based on text enhanced knowledge graph with hyperedge infusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiale</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Twophase hypergraph based reasoning with dynamic relations for multi-hop kbqa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiale</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence</title>
		<meeting>the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving multi-hop knowledge base question answering by learning intermediate supervision signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaole</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunshi</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM International Conference on Web Search and Data Mining</title>
		<meeting>the 14th ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning by abstraction: The neural state machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Drew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">J. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">On information and sufficiency. The annals of mathematical statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Solomon</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leibler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1951" />
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunshi</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaole</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.11644</idno>
		<title level="m">A survey on complex knowledge base question answering: Methods, challenges and solutions</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Query graph generation for answering multi-hop complex questions from knowledge bases. Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunshi</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Knowledge base question answering with topic units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunshi</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Kagnet: Knowledge-aware graph networks for commonsense reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyue</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Knowledge base question answering via encoding of complex query graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kangqi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengli</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xusheng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenny</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Costas</forename><surname>Mavromatis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Prasanna Lakkur Subramanyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vassilis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soji</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adeshina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Phillip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetiana</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagib</forename><surname>Grinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Hakim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Karypis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.05785</idno>
		<title level="m">Tempoqr: Temporal question reasoning over knowledge graphs</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amir-Hossein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction with an incomplete knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gondek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Stepwise reasoning for multi-relation question answering over knowledge graph with weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
		<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Hierarchical query graph generation for complex question answering over knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saiping</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing without questionanswer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using Siamese BERTnetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Lego: Latent execution-guided reasoning for multi-hop question answering on knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanjun</forename><surname>Hongyu Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitian</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorv</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.01515</idno>
		<title level="m">Question answering over temporal knowledge graphs</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Improving multi-hop question answering over knowledge graphs using knowledge base embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorv</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditay</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European semantic web conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Expanding end-to-end question answering on differentiable knowledge graphs with intersection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priyanka</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Saffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armin</forename><surname>Oliya</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.05808</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Transfernet: An effective and transparent framework for multi-hop question answering over relation graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shulin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.07302</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Conceptnet 5.5: An open multilingual graph of general knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robyn</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-first AAAI conference on artificial intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Faithful embeddings for knowledge base queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tania</forename><forename type="middle">Bedrax</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="22505" to="22516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tania</forename><surname>Bedrax-Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Open domain question answering using early fusion of knowledge bases and text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathryn</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Skeleton parsing for complex question answering over knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web Semantics</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The web as a knowledge-base for answering complex questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">CommonsenseQA: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Th?o</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<title level="m">Graph attention networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Improving question answering over incomplete kbs with knowledgeaware reader</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Enhancing key-value memory neural networks for knowledge based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Qagnn: Reasoning with language models and knowledge graphs for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.06378</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Semantic parsing via staged query graph generation: Question answering with knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Variational reasoning for question answering with knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">An interpretable reasoning network for multirelation question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
