<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Guided Evolutionary Neural Architecture Search With E cient Performance Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasco</forename><surname>Lopes</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">NOVA Lincs</orgName>
								<orgName type="institution" key="instit2">Universidade da Beira Interior</orgName>
								<address>
									<settlement>Covilh?</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">DeepNeuronic</orgName>
								<address>
									<settlement>Covilh?</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Santos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">NOVA Lincs</orgName>
								<orgName type="institution" key="instit2">Universidade da Beira Interior</orgName>
								<address>
									<settlement>Covilh?</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Degardin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Instituto de Telecomunica??es</orgName>
								<address>
									<settlement>Covilh?</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">DeepNeuronic</orgName>
								<address>
									<settlement>Covilh?</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu?s</forename><forename type="middle">A</forename><surname>Alexandre</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">NOVA Lincs</orgName>
								<orgName type="institution" key="instit2">Universidade da Beira Interior</orgName>
								<address>
									<settlement>Covilh?</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Guided Evolutionary Neural Architecture Search With E cient Performance Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>A R T I C L E I N F O Keywords: Neural Architecture Search Convolutional Neural Networks Evolution Guided Search AutoML Zero-proxy Estimator A B S T R A C T</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural Architecture Search (NAS) methods have been successfully applied to image tasks with excellent results. However, NAS methods are often complex and tend to converge to local minima as soon as generated architectures seem to yield good results. This paper proposes GEA, a novel approach for guided NAS. GEA guides the evolution by exploring the search space by generating and evaluating several architectures in each generation at initialisation stage using a zero-proxy estimator, where only the highest-scoring architecture is trained and kept for the next generation. Subsequently, GEA continuously extracts knowledge about the search space without increased complexity by generating several o -springs from an existing architecture at each generation. More, GEA forces exploitation of the most performant architectures by descendant generation while simultaneously driving exploration through parent mutation and favouring younger architectures to the detriment of older ones. Experimental results demonstrate the e ectiveness of the proposed method, and extensive ablation studies evaluate the importance of di erent parameters. Results show that GEA achieves state-of-the-art results on all data sets of NAS-Bench-101, NAS-Bench-201 and TransNAS-Bench-101 benchmarks.</p><p>&lt; Corresponding author vasco.lopes@ubi.pt (V. Lopes) ORCID(s): 0000-0002-5577-1094 (V. Lopes); 0000-0003-2462-7310 (B. Degardin); 0000-0002-5133-5025 (L.A. Alexandre)</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Convolutional Neural Networks (CNNs) have been extensively applied with success to a panoply of tasks with unprecedented results, from image classification <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, to semantic segmentation <ref type="bibr" target="#b2">[3]</ref>, text analysis <ref type="bibr" target="#b3">[4]</ref>, amongst many others <ref type="bibr" target="#b4">[5]</ref>. Their inherent feature extraction capabilities allow CNNs to be easily applied and transferred to di erent problems. Over the years, several carefully designed architectures have incrementally out-performed the state-of-theart by proposing novel components and mechanisms, such as skip and residual connections, faster and less size intensive operations and attention mechanisms <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref>. However, designing tailor-made highly performant CNNs for a given problem is a grueling endeavour. The design choices intrinsic to the architectures, layer combinations and training require extensive architecture engineering, which is heavily dependant on human expertize and trial and error. Thus, a logical step was to start automating the architecture engineering and design, creating a growing interest in Neural Architecture Search (NAS).</p><p>NAS has been successfully applied in designing architectures for image and text problems <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref>. Commonly, NAS proposals are composed of three components. First, the search space, which specifies the possible operations to be sampled and their connections, ultimately defining the type of architectures that the search method can generate. Secondly, the search method, which represents the approach used to explore the search space and <ref type="figure" target="#fig_1">Figure 1</ref>: GEA example of scoring two different architectures using the same input. Generated architectures at each generation are ranked based on a score that correlates with their final performance, which determines which architecture is selected to be part of the population. generate architectures. The most common approaches are reinforcement learning, evolutionary strategies and gradientbased methods, which commonly work by updating a controller to sample more e cient architectures based on the performance of the generated models. Finally, the performance estimation strategy, which defines how the generated architectures are evaluated. Thus, the goal of a NAS method is to, based on the search method, e ciently search a large set of possible networks to find an optimal architecture for a given problem.</p><p>Despite excellent results obtained by prominent NAS methods, the computational cost of most approaches is high, which in some cases can be in the order of months of GPU computation <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>. To mitigate this, approaches focus on a cell-based design, where NAS methods design small cells that are replicated through an outer-skeleton, thus alleviating the complexity of the search space <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>. Furthermore, several performance estimation strategies have been proposed to reduce the time constraint of NAS methods, by mainly conducting low-fidelity estimates, learning curve extrapolations, statistical approaches <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b12">13]</ref> or by proposing one-shot methods, where the weights of the generated models are inherited from a super-network <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref>. However, searching through high-dimensional search spaces is highly complex, even when there is some prior knowledge about the space. Most prominent NAS methods fail to generalise to new data sets due to fast convergence to local minima <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>, thus jeopardizing the search and method's applicability. The most reliable approach to obtain information about the search space while searching is to fully train generated architectures and optimise the search based on the most performant ones. However, this is extremely costly, and results are highly dependant on the training schemes and initialisation setups <ref type="bibr" target="#b30">[31]</ref>. Therefore, zero-proxy estimators present an attractive solution, where statistics are drawn from the generated architectures to score them at initialisation stage, thus requiring no training <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>. These methods are time e cient and capable of performing good correlations between the score and respective accuracies when the architectures are trained <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b25">26]</ref>. This paper proposes GEA, an evolutionary NAS method that leverages zero-proxy estimation to e ciently guide the search. By using an evolutionary strategy where operations can be mutated and younger architectures are prefered, GEA forces an exploitation of the most performant architectures, and an exploration of the search space by performing mutations. More, we solve the problem of conducting full evaluation of the generated architectures to obtain knowledge about the search space by generating several architectures in each generation, where all are evaluated at initialisation stage using a zero-proxy estimator and only the highest scoring architecture is trained and kept for the next generation. By doing so, GEA is capable of continuously extracting knowledge about the search space without compromising the search, resulting in state-of-the-art results in NAS-Bench-101, NAS-Bench-201 and TransNAS-Bench-101 search spaces. <ref type="figure" target="#fig_1">Figure 1</ref> shows the process of evaluating generated architectures. The code is publicly available at https://github.com/VascoLopes/GEA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our contributions can be summarized as:</head><p>? We propose a guided NAS method based on evolutionary strategies and zero-proxy estimation to generate image classifier architectures -Convolutional Neural Networks.</p><p>? We empirically show that guided mechanisms can be used without compromising time e ciency nor the generated models performance. Also, we detail the algorithm, emphasizing the accessible transferability of the guiding mechanism.</p><p>? We achieve state-of-the-art results on all data sets of NAS-Bench-101, NAS-Bench-201 and TransNAS-Bench-101 benchmarks, thus showing GEA's generability.</p><p>? Extensive ablation studies show the importance of di erent parameters and regularization, thus shedding insights for the design of NAS evolutionary models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>NAS was initially proposed as a Reinforcement Learning (RL) problem, where a controller is trained based on the generated architecture's performances to incrementally sample more e cient ones <ref type="bibr" target="#b19">[20]</ref>. Follow-up approaches focused on improving the overall performance, and the computation required to frame NAS as a RL problem by proposing the use of di erent learning strategies, distributed computing, and novel incremental sampling strategies <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b35">36]</ref>. ENAS <ref type="bibr" target="#b27">[28]</ref>, showed that RL could be used to perform NAS in a reasonable time-frame by training a controller to discover architectures through optimal subgraph search within a large computational graph, requiring only a few computational days. DARTS <ref type="bibr" target="#b26">[27]</ref>, proposed the use of gradients to generate architectures by performing continuous relaxation of the parameters using a bi-level gradient optimization, resulting in the generation of competitive architectures in a few GPU days. These methods served as basis for follow-up weight-sharing NAS methods and one-shot models <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b28">29]</ref>.</p><p>Evolutionary computation is a common approach for NAS. NEAT was one of the first evolutionary methods to evolve simple neural networks <ref type="bibr" target="#b40">[41]</ref>, which served as base and inspiration for methods that evolve deeper architectures where parent architectures have their parameters mutated to force evolution towards better performances <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref>. REA was one of the first evolutionary NAS methods to be proposed <ref type="bibr" target="#b43">[44]</ref>. It evolves architectures through mutations, and employs a tournament selection to serve as a regularization mechanism for the population. Although several evolutionary algorithms have been proposed to incrementally improve the performance of the method by designing novel heuristics to perform the evolution <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47]</ref>, most proposals are still computationally heavy, requiring several days or weeks of computation, and quickly converge to non-optimal minima.</p><p>Guiding mechanisms have been proposed to improve NAS. PNAS introduced consortium learning to improve the search, where the design of architectures is gradual, based on the evaluation of increasingly larger networks <ref type="bibr" target="#b20">[21]</ref>. This approach allowed the method to be progressively guided through the search space, training only a portion of the architectures based on the estimation of the performance by a predictor network. However, this method still required immense computation. NPENAS guides an evolutionary search by proposing two predictors: a graph-based uncertainty estimation network and a performance predictor <ref type="bibr" target="#b47">[48]</ref>. In <ref type="bibr" target="#b48">[49]</ref>, the authors evaluate the similarity of the internal activations of the generated architectures against a known one, e.g., ResNet, via representational similarity analysis to extract information about the search. <ref type="bibr" target="#b49">[50]</ref> proposes the use of landmark architecture evaluation to regularize the ranking of child architectures in super-net settings, thus guiding the search towards a better ranking correlation between standalone architectures and the super-net ranking.</p><p>In this work, we leverage the findings that show that evolving architectures are an e cient approach for NAS <ref type="bibr" target="#b43">[44]</ref>, and that zero-proxy estimators provide a reasonably good and extremely fast scoring of untrained architectures <ref type="bibr" target="#b31">[32]</ref>. By coupling a zero-proxy estimator as a guiding mechanism to the search method, we force further exploitation of settings favourable to the generated architectures. At the same time, it also e ciently allows the exploration of the search space by quickly evaluating thousands of architectures, thus providing vital information to guide the search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>The goal of a NAS algorithm is to find an optimal architecture a &lt; from the space of architectures A, a &lt; ? A, such that it maximizes an objective function O. The proposed method, GEA, frames NAS as an optimization problem where an evolutionary strategy evolves architectures a ? A based on operation mutations and guided evolution. Therefore, we can define our problem as a nested optimization problem, where the goal is to find a final network, L, created from training the optimal architecture, a &lt; , on a training set, d <ref type="bibr">(train)</ref> , such that a &lt; maximizes an objective function O for a given task, on the validation set:</p><formula xml:id="formula_0">a &lt; = arg max a?A O(L(a, d (train) ), d (valid) )<label>(1)</label></formula><p>In the following sections, we detail GEA and the zeroproxy estimator leveraged to create the guiding mechanism.  using a zero-proxy estimator that scores the architectures at initialisation stage, without requiring any training (the zero-proxy estimation mechanism is detailed in section 3.2). Then, from the C scored architectures, only the top P scoring ones are added to the population and trained to extract their fitness, f . The fitness, f , is the validation accuracy after a partial train (few epochs). By scoring C architectures at initialisation stage, GEA acquires knowledge regarding the search space, which is then exploited by selecting the top performant architecture, thus guiding the upcoming search by weeding out bad architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Search Method</head><p>Once the initial population is defined, the evolution takes place for C cycles. At each iteration, the first step is to perform a tournament selection. For this, S architectures are randomly and uniformly sampled from the population. Then, the architecture with the highest fitness score, f , from the pool of S architectures is selected to be the parent of the next generation (cycle). To generate new architectures, GEA performs a mutation over the parent architecture. The mutation works by randomly changing one operation of the architecture by another from the pool of operations. An example of a mutation using the NAS-Bench-201 search space is visually represented in <ref type="figure" target="#fig_2">Figure 3</ref>. P new architectures are generated at each cycle by performing operation mutations over the selected parent, which are then scored using the zero-proxy estimator. The highest-scoring architecture is kept and added to the population after evaluating its fitness. Generating and evaluating P architectures strengthens the search method to find the best direction for the parent's evolution across the search space. This allows the method to be guided through a complex space without jeopardizing the time required to perform the evolution or the search method's complexity. When the new architecture is added to the population, a regularization mechanism (survivor selection) takes place, where the oldest architecture is removed and discarded, thus forcing exploration of the search space by favouring younger architectures that represent new settings evolved by prior acquired knowledge.</p><p>Inherently, higher P values represent a higher degree of exploration of the search space, while higher S values represent higher exploitation by increasing the probability of the best architectures in the population being selected as parents for the next generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Zero-proxy Estimator</head><p>The goal of scoring architectures at initialisation stage is to provide information about the search space without incurring in the high cost of actually training them, thus allowing guiding the search to optimal settings. For this, we use a zero-proxy estimator based on Jacobian covariance. This allows us to quickly evaluate if an architecture is good without requiring any training, thus allowing the selection of a generated architecture to be added to the population with more confidence that the search is being correctly guided. To do this, we can define a linear mapping, w i = g(x i ), which maps the input x i ? R D , through the network, g(x i ), where x i represents an image that belongs to a batch X, and D is the input dimension <ref type="bibr" target="#b31">[32]</ref>. Then, the Jacobian of the linear map can be computed using:</p><formula xml:id="formula_1">J i = )g(x i ) )x i<label>(2)</label></formula><p>This allows us to evaluate the architecture's behaviour for di erent images by calculating J i for di erent data points, g(x i ), of a single batch X, i ? 1, 5 , N:</p><formula xml:id="formula_2">J = ? )g(x 1 ) )x 1 )g(x 2 ) )x 2 5 )g(x N ) )x N ? ?<label>(3)</label></formula><p>J contains information about the architecture's output with respect to the input for several images. We can split this into classes and evaluate how an architecture models complex functions at initialisation stage and its e ect on images that belong to the same class. To do that, we split J into several sets, where each set, M k , contains all J i that belong to the same class k. Then, we can calculate a per-class correlation matrix, ? M k , using the obtained sets, M k , where k = 1, ...K.</p><p>Individual correlation matrices provide information about how a single architecture treats images for each class. However, di erent correlation matrices might yield di erent sizes, as the number of images per class di er. To be able to compare di erent correlation matrices, they are individually evaluated:</p><formula xml:id="formula_3">E k = h n n l n n j ? N i=1 ? N j=1 log(?(? Mk ) i,j ? + t), if K f ? ? N i=1 ? N j=1 log(?(? Mc ) i,j ?+t) #? Mk , otherwise<label>(4)</label></formula><p>where t is a small-constant with the value of 1 ? 10 *5 , and K is the number of classes in batch X, and # represents the number of elements.  Finally, an architecture is scored based on the individual evaluations of the correlation matrices by:</p><formula xml:id="formula_4">z = h n l n j ? K w=1 ?e w ?, if K f ? ? K i=1 ? K j=i+1 ?e i *e j ? #e , otherwise<label>(5)</label></formula><p>where e contains all the correlation matrices' scores. The final score is dependant on the number of classes present in X, as data sets with a higher number of classes commonly have more noise, which is mitigated by conducting a normalized pair-wise di erence. We empirically defined ? = 100, based on the search space and data sets used. We can then use z to rank the generated architectures, providing an e cient mechanism of di erentiating between bad and good architectures, thus allowing the search to be guided towards better settings without compromising the search cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Search Spaces</head><p>To evaluate the e ectiveness of the proposed NAS algorithm, we utilise three di erent search spaces: NAS-Bench-101 <ref type="bibr" target="#b50">[51]</ref>, NAS-Bench-201 <ref type="bibr" target="#b29">[30]</ref> and TransNAS-Bench-101 <ref type="bibr" target="#b51">[52]</ref> benchmarks. These benchmarks were designed to have tractable NAS search spaces with metadata for the training of thousands of architectures within those search spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NAS-Bench-101</head><p>is a cell-based search space consisting of 423,624 neural networks that have been trained, with three di erent initialisations, on CIFAR-10 for 108 epochs each. In NAS-Bench-101 search space there are three possible operations: 1 ? 1 and 3 ? 3 convolution and 3 ? 3 max pooling. Convolution operations are combined with batch normalization and ReLU operations to create a Conv-BN-ReLU pattern. To form entire architectures, each cell is initially stacked 3 times, followed by a max-pooling layer that serves the purpose of halving the image height and width, and doubling the number of channels. This pattern is repeated 3 times and followed by a global average pooling and a final classification layer with a softmax function.</p><p>NAS-Bench-201 fixes the search space as a cell-based design with 5 possible operations: zeroize, skip connection, 1 ? 1 and 3 ? 3 convolution, and 3 ? 3 average pooling layer. The cell design comprises six edges and four nodes, where an edge represents a possible operation through two nodes. By fixing the cell size and the operation pool, the search space comprises 5 6 = 15625 possible cells. To form entire networks, the cells are replicated in an outer-defined skeleton. NAS-Bench-201 provides information regarding the training and performance of all possible networks in the search space in three di erent data sets: CIFAR-10, CIFAR-100 and ImageNet16-120, thus proposing a controlled setting that allows di erent NAS methods to be fairly compared, as they are forced to use the search space, training procedures and hyper-parameters.</p><p>TransNAS-Bench-101 is a benchmark that provides architecture's performances across seven vision tasks including classification, regression, pixel-level prediction and selfsupervised tasks. The 7 tasks of this benchmark are: object classification, scene classification, autoenconding, surface normal, semantic segmentation, room layout and jigsaw. By having multiple tasks that are queryable with the same input, this benchmark provides the opportunity to evaluate NAS transferability between di erent tasks. There are two types of search space in this benchmark, i.e., the widely-studied cell-based search space containing 4096 architectures and macro skeleton search space based on residual blocks containing 3256 architectures. Possible operations are: zeroize, <ref type="table">Table 2</ref> Comparison of manually designed networks and several search methods evaluated using the NAS-Bench-201 benchmark. Performance is shown in terms of accuracy (%) with mean?std, on CIFAR-10, CIFAR-100 and ImageNet-16-120. Search times are the mean time required to search for cells in CIFAR-10. Search time includes the time taken to train networks as part of the process where applicable. skip connection, 1?1 and 3?3 convolution. Transnas-Bench-101 provides information regarding the training and performance of all possible networks in the search space using the same training protocols and hyper-parameters within each task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results and Discussion</head><p>First, we evaluate the proposed method on NAS-Bench-101. For this, we fixed P _S_C = 10_5_200, following standard settings used and assessed by prior works <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b43">44]</ref>, and directly compare it against random search and REA <ref type="bibr" target="#b43">[44]</ref>. In <ref type="table" target="#tab_0">Table 1</ref> we present this comparison in terms of search cost, in seconds, and mean test accuracy and standard deviation, calculated from executing GEA and REA 50 times. From the results, it is clear that GEA outperforms REA and heavily improves when compared to RS. GEA is highly e cient, requiring only approximately 0.3 GPU days to execute each run. The results show that the guiding mechanism can improve the search, promoting regions that yield better architectures in terms of accuracy.</p><p>Then, we evaluate GEA using the NAS-Bench-201 search space. The first experiment in this search space was to directly compare GEA with REA for a di erent number of generations/cycles, C. This also allows the evaluation of the importance of C, which is the main parameter that inherently defines the time required for the search procedure. Higher C values will take longer to finish. More, C establishes the number of architectures that are evaluated: C ? P architectures (P per cycle) are generated and evaluated using the zero-proxy estimation method to provide information about the search space, from which C architectures (1 per cycle) are selected and trained. The results are expressed as the mean test accuracy and standard deviation as colored areas, obtained by the best architecture found by each method for di erent C values over 25 di erent runs, and are presented in <ref type="figure" target="#fig_3">Figure 4</ref>. In this experiment, the P _S used to allow a fair comparison was set to P _S = 10_5, following the typical settings used by prior works <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b43">44]</ref>. The results show that across all data sets, GEA consistently outperforms REA, and is capable of converging to better results even for small numbers of C. These results demonstrate that the search method converges more quickly to regions of the search space that contain better architectures by leveraging the guided mechanism. Also, on ImageNet16-120, the noisier data set on NAS-Bench-201, the result from the T-test analysis was ? = 0.033, thus showing statistical significance between the results obtained by GEA when compared to REA. Note that for our proposed method, GEA, P value means that at any given time of the search, the population is equal to 10 architectures and that from the pool of parents, 5 architectures are sampled with replacement to select the parent of the generated architectures at a given cycle. The sampled parent generates P architectures through mutation per cycle, which are evaluated using the zero-proxy estimator, wherein only the top-scoring architecture is selected to integrate the population. By selecting S &gt; 1 architectures to have the opportunity of being a parent, we are leveraging the intrinsic exploitation characteristics of the evolutionary strategy, whereas by generating P architectures, we are forcing exploitation that guides the search more e ectively.</p><p>In <ref type="table">Table 2</ref> we further compare GEA, using P _S_C = 10_5_200, against other state-of-the-art methods on the NAS-Bench-201 search space, using as evaluation metrics the mean accuracy, standard deviation, and search time in seconds, across the 3 data sets. GEA consistently outperforms both weight sharing and non-weight sharing NAS <ref type="table">Table 3</ref> Performance comparison of different NAS methods on TransNAS-Bench-101. The first block shows the results for directly searching on each task. The second block shows the transferred versions of different methods, which are pretrained on the least time-consuming task, i.e., Jigsaw. The final row shows the possible best result in each task. methods, achieving state-of-the-art results in all three data sets. Moreover, GEA is extremely e cient in terms of search time, requiring only 0.3 GPU days to complete the search. Even though GEA evaluates C ? P architectures with the zero-proxy estimator and further evaluates C architectures by partially training them, it requires a similar search time as REA under the same settings and considerably less than most weight sharing methods. Lower standard deviation also indicates that GEA is precise and capable of generating high performant architectures, which is especially valid in ImageNet16-120, a data set with low-resolution images and high levels of noise, in which GEA considerably outperforms existing NAS methods. Finally, we evaluate GEA on all 7 tasks from TransNASbench-101. Evaluating GEA on several tasks contributes to validating its generability and transferability across di erent problems, which is where NAS methods commonly fail <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b58">59]</ref>. For this, we conducted two di erent experiments: i) directly searching on each task independently; and ii) perform transfer search. For the latter, we followed common procedures <ref type="bibr" target="#b51">[52]</ref>, where we first search on jigsaw and use the final population as initialisation for the evolution when searching on the other tasks. The results for both experiments are shown in <ref type="table">Table 3</ref>. From the results shown, it is possible to see that: first, directly searching on each task is an e ective approach, where GEA is capable of achieving an higher mean performance, of 25 runs, higher than any other NAS method in all tasks. Also, when looking only at the best result, GEA is capable of achieving the best possible results in TransNAS-Bench-101, which means that GEA is capable of generating the most optimal architecture for each task. The same behaviours are present when transferring the knowledge from jigsaw to other tasks, where GEA-t achieves state-of-the-art results on all tasks. When compared to directly searching on each task, GEA-t has a slight improvement only on classification tasks, meaning that GEA does not require prior information to achieve state-of-the-art performances when compared to other NAS methods.</p><p>The obtained results in all the 3 benchmarks, which account to 11 di erent data sets, show that an evolutionary strategy, coupled with a mechanism to quickly evaluate architectures to guide the search, can achieve state-of-the-art results while still having competitive search times. Despite the complexity of search spaces and severe di culty in obtaining their global information, the results show that guiding mechanisms powered by scoring architectures at initialisation stages have the advantage of acquiring preliminary information regarding in which direction the search should evolve. Therefore, GEA can quickly converge to better results by avoiding local minima, while still being e cient in terms of the required time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Studies</head><p>This section extends the study about the importance of di erent parameters on GEA. The results, in terms of mean validation accuracy and standard deviation in NAS-Bench-201 CIFAR-10, can be seen in <ref type="table">Table 4</ref>.</p><p>First, we look into the importance of the parameter S by incrementally increasing its value from 1 to 10, and instead of randomly sampling S architectures, replacing the pool <ref type="table">Table 4</ref> Ablation studies for the number of parent candidates, S, the population size, P , and the regularization mechanism to remove individuals from the population. Results are shown in mean validation accuracy (%) and standard deviation from 5 runs in NAS-Bench-201 CIFAR-10 data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter</head><p>Value Mean Validation Accuracy (%) S of candidates, by simply selecting architectures from the population pool with highest and lowest fitnesses. For this, P and C were fixed to 10 and 200 respectively. From <ref type="table">Table 4</ref>, a clear pattern can be seen, where the best results are obtained when S is higher. Logically, sampling the lowest scoring individual to be the parent of the next generation yields the worst results, as this forces the evolution to follow the worstknown settings. P = 10 achieved a better mean validation accuracy than sampling the highest scoring individual. We justify that this is due to the fact that by having a high enough P value, it allows that most of the time, one of the best architectures is chosen to be parent, while at the same time, it promotes exploration of the search space by not using the best-known setting yet. A visual representation of the evolution of the best architecture for the di erent parameter values, over 5 di erent runs, can be seen in <ref type="figure" target="#fig_4">Figure 5</ref>. We also evaluate the importance of the population size, P . Similarly to S, we incrementally increase P from 1 to 10. From <ref type="table">Table 4</ref>, it is possible to see that higher values of P achieve better results than lower values, and the best results are obtained with P = 5. This is because a smaller population size promotes exploitation, as the candidates sampled to be parents are more often among the best individuals, thus leading the search to better regions of the search space. In <ref type="figure" target="#fig_5">Figure 6</ref> it is possible to see the evolution of the best architecture found by GEA for each P value evaluated over 5 di erent runs.</p><p>Finally, we evaluated the importance of the regularization mechanism that removes individuals from the population. For this, we assessed the already discussed elimination by age by removing the oldest individual in the population and evaluated the results if the best (highest fitness) and the   worst (lowest fitness) individuals were removed. From <ref type="table">Table  4</ref>, it is clear that removing the best individual is the worst possible strategy, as it forces the search to ignore the bestknown settings so far. Then, comparing removing the worst and the oldest, the best results are yielded when the oldest individual is removed, as it promotes further exploration of the search space. The results shown in <ref type="figure" target="#fig_6">Figure 7</ref> for the evolution of the di erent regularization mechanisms clearly show that removing the oldest individuals yields the best results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>This paper proposes GEA, a guided evolution strategy for neural architecture search by leveraging zero-proxy estimation of untrained architectures. GEA forces exploitation of the most performant architectures by descendant generation and an exploration of the search space by conducting mutations. GEA guides the evolution by generating several architectures in each generation and evaluating them at the initialisation stage using a zero-proxy estimator, where only the highest-scoring architecture is trained and kept for the next generation. The generation of multiple architectures from an existing one in the population at each generation allows GEA to constantly extract knowledge concerning the search space without compromising the search itself, resulting in state-of-the-art performances in all data sets of NAS-Bench-101, NAS-Bench-201 and TransNAS-Bench-101 benchmarks.</p><p>The proposed guided NAS approach can be extended to multiple strategies, where the search method can be further improved by incorporating new regularisation and mutation mechanisms. Also, the components of the guiding mechanism can easily be transferred to other evolutionary algorithms, allowing existing NAS evolutionary methods to be further improved.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of one iteration of GEA. Architectures are represented with varying bar's length and colors to illustrate their diversity. The process shows the sampling of several candidates, parent selection, offspring generation and evaluation and top scoring architecture training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>GEA is summarised in Algorithm 1 .</head><label>1</label><figDesc>In detail, GEA starts by randomly generating C architectures from the search space of possible architectures, A. The architectures that belong to the search space have equal probabilities of being randomly sampled. Sampled architectures are then evaluated</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Example of mutating one operation of a cell using the NAS-Bench-201 search space: operation Identity becomes Conv. 3 ? 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Mean accuracy and standard deviation over 25 runs of the proposed method, GEA, and direct comparison with REA for different cycles (C) across CIFAR-10, CIFAR-100 and ImageNet16-120 data sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Mean validation accuracy (%) throughout the evolution for different parent sampling, S, schemes using NAS-Bench-201 CIFAR-10 for 5 runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Mean validation accuracy (%) throughout the evolution for different population sizes, P , using NAS-Bench-201 CIFAR-10 for 5 runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Mean validation accuracy (%) throughout the evolution for different regularization schemes using NAS-Bench-201 CIFAR-10 for 5 runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1 end for while</head><label>1</label><figDesc>Guided Evolution population } empty queue . Population. history } ? . Models history. while #population &lt; C do . Initialize population. model.arch } RANDOMARCHITECTURE() model.accuracy } ZEROPROXY(model.arch) add model to right of population . Force model age end while drop the C * P worst individuals from population for model ? population do model.accuracy } TRAINANDEVAL(model.arch) add model to history</figDesc><table><row><cell></cell><cell>Oldest</cell></row><row><cell>model. end while return highest-accuracy model in history performant.</cell><cell>. Most</cell></row></table><note>#history &lt; C do sample } S random candidates from the population (with replacement) parent } highest-accuracy model in sample generation } ? while #generation &lt; P do child.arch } MUTATE(parent.arch) child.accuracy } ZEROPROXY(child.arch) add child to generation end while top_child } highest-performant model in generation top_child.accuracy } TRAINANDEVAL(top_child.arch) add top_child to right of population add top_child to history remove dead from left of population .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 Mean</head><label>1</label><figDesc></figDesc><table><row><cell>Method</cell><cell>Search Time (s) ?</cell><cell>Mean Test Accuracy (%)R</cell></row><row><cell>S</cell><cell>N/A</cell><cell>90.38?5.51</cell></row><row><cell>REA</cell><cell>26676.49</cell><cell>93.12?0.48</cell></row><row><cell>GEA (ours)</cell><cell>30128.32</cell><cell>93.99?0.25</cell></row></table><note>test accuracy (%) and standard deviation across 50 runs in NAS-Bench-101 CIFAR-10 data set. Evaluation for REA and GEA was done with P/S/C=10/5/200.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Table adapted from<ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>.</figDesc><table><row><cell>Method</cell><cell>Search Time (s)?</cell><cell cols="6">CIFAR-10 Val. Acc (%)~Test Acc. (%)~Val. Acc (%)~Test Acc. (%)~Val. Acc (%)~Test Acc. (%)M CIFAR-100 ImageNet-16-120</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>anually designed</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ResNet</cell><cell>-</cell><cell>90.83</cell><cell>93.97</cell><cell>70.42</cell><cell>70.86</cell><cell>44.53</cell><cell>43.63</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Weight sharing</cell><cell></cell><cell></cell><cell></cell></row><row><cell>RSPS</cell><cell>7587</cell><cell>84.16?1.69</cell><cell>87.66?1.69</cell><cell>59.00?4.60</cell><cell>58.33?4.34</cell><cell>31.56?3.28</cell><cell>31.14?3.88</cell></row><row><cell>DARTS-V1</cell><cell>10890</cell><cell>39.77?0.00</cell><cell>54.30?0.00</cell><cell>15.03?0.00</cell><cell>15.61?0.00</cell><cell>16.43?0.00</cell><cell>16.32?0.00</cell></row><row><cell>DARTS-V2</cell><cell>29902</cell><cell>39.77?0.00</cell><cell>54.30?0.00</cell><cell>15.03?0.00</cell><cell>15.61?0.00</cell><cell>16.43?0.00</cell><cell>16.32?0.00</cell></row><row><cell>GDAS</cell><cell>28926</cell><cell>90.00?0.21</cell><cell>93.51?0.13</cell><cell>71.14?0.27</cell><cell>70.61?0.26</cell><cell>41.70?1.26</cell><cell>41.84?0.90</cell></row><row><cell>SETN</cell><cell>31010</cell><cell>82.25?5.17</cell><cell>86.19?4.63</cell><cell>56.86?7.59</cell><cell>56.87?7.77</cell><cell>32.54?3.63</cell><cell>31.90?4.07</cell></row><row><cell>ENAS</cell><cell>13315</cell><cell>39.77?0.00</cell><cell>54.30?0.00</cell><cell>15.03?0.00</cell><cell>15.61?0.00</cell><cell>16.43?0.00</cell><cell>16.32?0.00</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Non-weight sharing</cell><cell></cell><cell></cell><cell></cell></row><row><cell>RS</cell><cell>12000</cell><cell>90.93?0.36</cell><cell>93.70?0.36</cell><cell>70.93?1.09</cell><cell>71.04?1.07</cell><cell>44.45?1.10</cell><cell>44.57?1.25</cell></row><row><cell>REINFORCE</cell><cell>12000</cell><cell>91.09?0.37</cell><cell>93.85?0.37</cell><cell>71.61?1.12</cell><cell>71.71?1.09</cell><cell>45.05?1.02</cell><cell>45.24?1.18</cell></row><row><cell>BOHB</cell><cell>12000</cell><cell>90.82?0.53</cell><cell>93.61?0.52</cell><cell>70.74?1.29</cell><cell>70.85?1.28</cell><cell>44.26?1.36</cell><cell>44.42?1.49</cell></row><row><cell>REA ?</cell><cell>26070</cell><cell>91.22?0.25</cell><cell>93.97?0.31</cell><cell>72.36?1.07</cell><cell>72.14?0.86</cell><cell>45.09?0.92</cell><cell>45.55?1.02</cell></row><row><cell>GEA (ours) ?</cell><cell>26911</cell><cell>91.26?0.20</cell><cell>93.99?0.23</cell><cell>72.62?0.77</cell><cell>72.36?0.66</cell><cell>45.97?0.72</cell><cell>46.</cell></row></table><note>04?0.67 ? Results of 25 runs using the same settings: P _S_C = 10_5_200, using a single 1080Ti GPU.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Table adapted from<ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53]</ref>. Results provided for the best run only.</figDesc><table><row><cell></cell><cell>Tasks</cell><cell>Cls. Object</cell><cell>Cls. Scene</cell><cell cols="4">Autoencoding Surf. Normal Sem. Segment. Room Layout</cell><cell>Jigsaw</cell></row><row><cell></cell><cell>Metric</cell><cell cols="6">Acc. (%)~Acc. (%)~SSIM~SSIM~mIoU~L2 loss ?</cell><cell>Acc. (%)R</cell></row><row><cell></cell><cell>S [54]</cell><cell>45.16?0.4</cell><cell>54.41?0.3</cell><cell>55.94?0.8</cell><cell>56.85?0.6</cell><cell>25.21?0.4</cell><cell>61.48?0.8</cell><cell>94.47?0.3</cell></row><row><cell></cell><cell>REA [44]</cell><cell>45.39?0.2</cell><cell>54.62?0.2</cell><cell>56.96?0.1</cell><cell>57.22?0.3</cell><cell>25.52?0.3</cell><cell>61.75?0.8</cell><cell>94.62?0.3</cell></row><row><cell>Direct Search</cell><cell>PPO [55] DT BONAS [56] ? weakNAS [57] ? Arch-Graph-single [53] ?</cell><cell>45.19?0.3 42.03?5.0 45.50 45.66 45.48</cell><cell>54.37?0.2 49.80?8.6 54.56 54.72 54.70</cell><cell>55.83?0.7 51.20?3.3 56.73 56.77 56.52</cell><cell>56.90?0.6 55.03?2.7 57.46 57.21 57.53</cell><cell>25.24?0.3 22.45?3.2 25.32 25.90 25.71</cell><cell>61.38?0.7 66.98?2.3 61.10 60.31 61.05</cell><cell>94.46?0.3 88.95?9.1 94.81 94.63 94.66</cell></row><row><cell></cell><cell>GEA (Ours)</cell><cell>45.98?0.2</cell><cell>54.85?0.1</cell><cell>57.11?0.3</cell><cell>58.33?1.0</cell><cell>25.95?0.2</cell><cell>59.93?0.5</cell><cell>94.96?0.2</cell></row><row><cell></cell><cell>GEA-Best (Ours) ?</cell><cell>46.32</cell><cell>54.94</cell><cell>57.72</cell><cell>59.62</cell><cell>26.27</cell><cell>59.38</cell><cell>95.37</cell></row><row><cell></cell><cell>REA-t [44]</cell><cell>45.51?0.3</cell><cell>54.61?0.2</cell><cell>56.52?0.6</cell><cell>57.20?0.7</cell><cell>25.46?0.4</cell><cell>61.04?1.0</cell><cell>-</cell></row><row><cell></cell><cell>PPO-t [55]</cell><cell>44.81?0.6</cell><cell>54.15?0.5</cell><cell>55.70?1.5</cell><cell>56.60?0.7</cell><cell>24.89?0.5</cell><cell>62.01?1.0</cell><cell>-</cell></row><row><cell>Transfer Search</cell><cell>CATCH [58] BONAS-t [56] ? weakNAS-t [57] ? Arch-Graph-zero [53] ? Arch-Graph [53] ? GEA-t (Ours)</cell><cell>45.27?0.5 45.38 45.29 45.64 45.81 46.03?0.3</cell><cell>54.38?0.2 54.57 54.78 54.80 54.90 54.86?0.1</cell><cell>56.13?0.7 56.18 56.90 56.61 56.58 56.99?0.3</cell><cell>56.99?0.6 57.24 57.19 57.90 58.27 58.21?0.9</cell><cell>25.38?0.4 25.24 25.41 25.73 25.69 25.88?0.3</cell><cell>60.70?0.7 60.93 60.70 60.21 60.08 59.85?0.5</cell><cell>------</cell></row><row><cell></cell><cell>GEA-t-Best (Ours) ?</cell><cell>46.32</cell><cell>54.94</cell><cell>57.72</cell><cell>59.62</cell><cell>26.27</cell><cell>59.38</cell><cell>-</cell></row><row><cell></cell><cell>Global Best</cell><cell>46.32</cell><cell>54.94</cell><cell>57.72</cell><cell>59.62</cell><cell>26.27</cell><cell>59.38</cell><cell>95.37</cell></row><row><cell>?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by 'FCT -Funda??o para a Ci?ncia e Tecnologia' through the research grants '2020.04588.BD' and 'UI/BD/150765/2020', partially supported by NOVA LINCS (UIDB/04516/2020) with the financial support of FCT, through national funds and CENTRO-01-0247-FEDER-113023 -DeepNeuronic.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data availability</head><p>The data used in the paper is publically available datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Competing Interest</head><p>The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">Deep learning: methods and applications, Foundations and Trends in Signal Processing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Deep learning</title>
		<imprint>
			<publisher>MIT press Cambridge</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey on deep learning techniques for image and video semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garcia-Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Orts-Escolano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oprea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Villena-Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martinez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Garcia-Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="41" to="65" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<editor>M. Lapata, P. Blunsom, A. Koller</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A survey of the recent architectures of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sohail</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Zahoora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Qureshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Imagenet classification with deep convolutional neural networks</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
	<note>Going deeper with convolutions</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Densely connected convolutional networks</title>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1251" to="1258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<editor>K. Chaudhuri, R. Salakhutdinov</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<title level="m">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural architecture search: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A survey on neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wistuba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pedapati</surname></persName>
		</author>
		<idno>CoRR abs/1905.01392</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Auto-classifier: A robust defect detector based on an automl head</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="137" to="149" />
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">An automl-based approach to multimodal image sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaspar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Alexandre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cordeiro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>IJCNN</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Esperan?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<title level="m">Neural architecture generator optimization</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, H. Lin</editor>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2203.05508</idno>
		<title level="m">Towards less constrained macro-neural architecture search</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A review of neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baymurzina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Golikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Burtsev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">474</biblScope>
			<biblScope unit="page" from="82" to="93" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progressive neural architecture search</title>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<title level="m">Learning transferable architectures for scalable image recognition, CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Understanding architectures learnt by cellbased neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations, ICLR, OpenReview.net</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Esperan?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gabillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01051</idno>
		<title level="m">Manas: Multi-agent neural architecture search</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A neural architecture generator for e cient search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">486</biblScope>
			<biblScope unit="page" from="189" to="199" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">How powerful are performance predictors in neural architecture search?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">DARTS: Di erentiable Architecture Search</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">E cient neural architecture search via parameters sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">PC-DARTS: partial channel connections for memory-e cient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Esperan?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<title level="m">Nas evaluation is frustratingly hard</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">EPE-NAS: E cient Performance Estimation Without Training for Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Alirezazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICANN</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Crowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Architecture Search without Training</title>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Evaluating e cient performance estimators of neural architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Practical block-wise neural network architecture generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural architecture tuning with policy adaptation</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">485</biblScope>
			<biblScope unit="page" from="196" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Searching for a robust neural architecture in four gpu hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="1761" to="1770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Random search and reproducibility for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<editor>UAI, PMLR</editor>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="367" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">One-Shot Neural Architecture Search via Self-Evaluated Template Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Understanding and robustifying di erentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Evolving neural networks through augmenting topologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="99" to="127" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Large-scale evolution of image classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L</forename><surname>Suematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<editor>D. Precup, Y. W. Teh</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">E cient multi-objective neural architecture search via lamarckian evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Regularized Evolution for Image Classifier Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="4780" to="4789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hierarchical Representations for E cient Architecture Search</title>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A survey on evolutionary neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks Learn. Syst</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.03856</idno>
		<title level="m">Benchenas: A benchmarking platform for evolutionary neural architecture search</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">NPENAS: neural predictor guided evolution for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<idno>CoRR abs/2003.12857</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Teacher guided architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bashivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Dicarlo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Landmark regularization: Ranking guided super-net training in neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranftl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<title level="m">NAS-Bench-101: Towards Reproducible Neural Architecture Search</title>
		<imprint>
			<publisher>ICML</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Transnas-bench-101: Improving transferability and generalizability of cross-task neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Archgraph: Acyclic architecture relation predictor for task-transferable neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<idno>CoRR abs/2204.05941</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Klimov</surname></persName>
		</author>
		<idno>CoRR abs/1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Bridging the gap between sample-based and one-shot neural architecture search with BONAS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, H. Lin</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<title level="m">Stronger NAS with weaker predictors</title>
		<imprint>
			<publisher>NeurIPS</publisher>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">CATCH: context-based meta reinforcement learning for transferrable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">On redundancy and diversity in cell-based neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Esperan?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
