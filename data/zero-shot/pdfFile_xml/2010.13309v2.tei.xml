<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DECENTRALIZING FEATURE EXTRACTION WITH QUANTUM CONVOLUTIONAL NEURAL NETWORK FOR AUTOMATIC SPEECH RECOGNITION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao-Han</forename><surname>Huck</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Qi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chi</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Brookhaven National Laboratory</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pin-Yu</forename><surname>Chen</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">IBM Research</orgName>
								<orgName type="institution" key="instit2">Yorktown Heights</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabato</forename><forename type="middle">Marco</forename><surname>Siniscalchi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Faculty of Computer and Telecommunication Engineering</orgName>
								<orgName type="institution">University of Enna</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Electronic Systems</orgName>
								<orgName type="institution">NTNU</orgName>
								<address>
									<settlement>Trondheim</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoli</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DECENTRALIZING FEATURE EXTRACTION WITH QUANTUM CONVOLUTIONAL NEURAL NETWORK FOR AUTOMATIC SPEECH RECOGNITION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Acoustic Modeling</term>
					<term>Quantum Machine Learn- ing</term>
					<term>Automatic Speech Recognition</term>
					<term>and Federated Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a novel decentralized feature extraction approach in federated learning to address privacy-preservation issues for speech recognition. It is built upon a quantum convolutional neural network (QCNN) composed of a quantum circuit encoder for feature extraction, and a recurrent neural network (RNN) based end-to-end acoustic model (AM). To enhance model parameter protection in a decentralized architecture, an input speech is first up-streamed to a quantum computing server to extract Mel-spectrogram, and the corresponding convolutional features are encoded using a quantum circuit algorithm with random parameters. The encoded features are then down-streamed to the local RNN model for the final recognition. The proposed decentralized framework takes advantage of the quantum learning progress to secure models and to avoid privacy leakage attacks. Testing on the Google Speech Commands Dataset, the proposed QCNN encoder attains a competitive accuracy of 95.12% in a decentralized model, which is better than the previous architectures using centralized RNN models with convolutional features. We conduct an in-depth study of different quantum circuit encoder architectures to provide insights into designing QCNNbased feature extractors. Neural saliency analyses demonstrate a high correlation between the proposed QCNN features, class activation maps, and the input Mel-spectrogram. We provide an implementation 1 for future studies.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>With the increasing concern about acoustic data privacy issues <ref type="bibr" target="#b0">[1]</ref>, it is essential to design new automatic speech recognition (ASR) architectures satisfying the requirements of new privacy-preservation regulations, e.g., GDPR <ref type="bibr" target="#b1">[2]</ref>. Vertical federated learning (VFL) <ref type="bibr" target="#b2">[3]</ref> is one potential strategy for data protection by decentralizing an endto-end deep learning <ref type="bibr" target="#b3">[4]</ref> framework and separating feature extraction from the ASR inference engine. With recent advances in commercial quantum technology <ref type="bibr" target="#b4">[5]</ref>, quantum machine learning (QML) <ref type="bibr" target="#b5">[6]</ref> becomes an ideal building block for VFL owing to its advantages on parameter encryption and isolation. To do so, the input to QML often represented by classical bits, needs to be first encoded into quantum states based on qubits. Next, approximation algorithms (e.g., quantum branching programs <ref type="bibr" target="#b6">[7]</ref>) are applied to quantum devices based  <ref type="figure">Fig. 1</ref>: Proposed quantum machine learning for acoustic modeling (QML-AM) architecture in a vertical federated learning progress including (a) a quantum convolution layer on Noisy Intermediate-Scale Quantum (NISQ) servers or cloud API; and (b) a local model (e.g., second-pass model <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>) for speech recognition tasks. on a quantum circuit <ref type="bibr" target="#b7">[8]</ref> with noise tolerance. To implement our proposed approach, we utilize a state-of-the-art noisy intermediatescale quantum (NISQ) <ref type="bibr" target="#b8">[9]</ref> platform (5 to 50 qubits) for academic and commercial applications <ref type="bibr" target="#b9">[10]</ref>. It can be set up on accessible quantum servers from cloud-based computing providers <ref type="bibr" target="#b4">[5]</ref>.</p><p>As shown in <ref type="figure">Fig. 1</ref>, we propose a decentralized acoustic modeling (AM) scheme to design a quantum convolutional neural network (QCNN) <ref type="bibr" target="#b12">[13]</ref> by combining a variational quantum circuit (VQC) learning paradigm <ref type="bibr" target="#b5">[6]</ref> and a deep neural network <ref type="bibr" target="#b13">[14]</ref> (DNN). VQC refers to a quantum algorithm with a flexible designing accessibility, which is resistant to noise <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref> and adapted to NISQ hardware with light or no requirements for quantum error correction. Based on the advantages of VQC under VFL, a quantum-enhanced data processing scheme can be realized with fewer entangled encoded qubits <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b6">7]</ref> to assure model parameters protection and lower computational complexity. As shown in <ref type="table">Table 1</ref>, to the best of the authors' knowledge, this is the first work to combine quantum circuits and DNNs and build a new QCNN <ref type="bibr" target="#b12">[13]</ref> for ASR. To provide secure data pipeline and reliable quantum computing, we introduce the VFL architecture for decentralized ASR tasks, where remote NISQ cloud servers are used to generate quantum-based features, and ASR decoding is performed with a local model <ref type="bibr" target="#b11">[12]</ref>. We refer to our decentralized quantum-based ASR system to as QCNN-ASR. Evaluated on the Google Speech Commands dataset with machine noises in- <ref type="table">Table 1</ref>: An overview of machine learning approaches and related key properties. CQ stands for a hybrid classical-quantum (CQ) <ref type="bibr" target="#b14">[15]</ref> model using in this paper. QA stands for quantum advantages <ref type="bibr" target="#b7">[8]</ref>, which are related to computational memory and parameter protection. VQC indicates the variational quantum circuit. VFL means vertical federated leaning <ref type="bibr" target="#b2">[3]</ref>. DNN stands for deep neural network <ref type="bibr" target="#b3">[4]</ref>   <ref type="bibr" target="#b5">[6]</ref> has been shown advantages in terms of lower memory storage, secured model parameters encryption, and good feature representation capabilities <ref type="bibr" target="#b7">[8]</ref>. There are several variants (e.g., adiabatic quantum computation <ref type="bibr" target="#b8">[9]</ref>, and quantum circuit learning <ref type="bibr" target="#b15">[16]</ref>). In this work, we use the hybrid classical-quantum algorithm <ref type="bibr" target="#b12">[13]</ref>, where the input signals are given in a purely classical format (aka, numerical format, e.g., digital image), and a quantum algorithm is employed in the feature learning phase. Quantum circuit learning is regarded as the most accessible and reproducible QML for signal processing <ref type="bibr" target="#b14">[15]</ref>, such as supervised learning in the design of quantum support vector machine <ref type="bibr" target="#b7">[8]</ref>. Indeed, it has been widely used, and it consists only of quantum logic gates with a possibility of deferring an error correction <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b15">16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Deep Learning with Variational Quantum Circuit</head><p>In the NISQ era <ref type="bibr" target="#b9">[10]</ref>, quantum computing devices are not errorcorrected, and they are therefore not fault-tolerant. Such a constraint limits the potential applications on NISQ technology, especially for large quantum circuit depth, and a large number of qubits. However, Mitarai et al.'s seminal work <ref type="bibr" target="#b5">[6]</ref> describes a framework to build machine learning models on NISQ. The key idea is to employ VQC <ref type="bibr" target="#b16">[17]</ref>, which are subject to an iterative optimization processes, so that the effects of noise in the NISQ devices can potentially be absorbed into these learned circuit parameters. Recent litterature reports about several successful machine learning applications based on VQC, for instance, deep reinforcement learning <ref type="bibr" target="#b17">[18]</ref>, and function approximation <ref type="bibr" target="#b5">[6]</ref>. VQCs are also used in constructing quantum machine learning models capable of handling sequential patterns, such as the dynamics of of certain physical systems <ref type="bibr" target="#b18">[19]</ref>. It should be noted that the input dimension of the input in <ref type="bibr" target="#b18">[19]</ref> is rather limited <ref type="bibr" target="#b17">[18]</ref> because of stringent requirements of currently available quantum simulators, or real quantum devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Quantum Learning and Decentralized Speech Processing</head><p>Although quantum technology is quite new, there have been some attempts in exploiting it for speech processing. For example, Li et al. <ref type="bibr" target="#b19">[20]</ref> proposed a speech recognition system with quantum backpropagation (QBP) simulated by fuzzy logic computing. However, QBP is not using the qubit directly in a real-world quantum device, and the approaches hardly demonstrates the quantum advantages inherent in this computing scheme. Moreover, the QBP solution can be complicated to large-scale ASR tasks with parameters protection.</p><p>From a system perspective, these accessible quantum advantages from VQL, including encryption and randomized encoding, are prominent requirements for federated learning systems, such as distributed ASR. Cloud computing-based federated architectures <ref type="bibr" target="#b2">[3]</ref> have been proven the most effective solutions for industrial applications, demonstrating quantum advantages using commercial NISQ servers <ref type="bibr" target="#b4">[5]</ref>. More recent works on federated keyword spotting <ref type="bibr" target="#b0">[1]</ref>, distributed ASR <ref type="bibr" target="#b20">[21]</ref>, improved lite audio-visual processing for local inference <ref type="bibr" target="#b21">[22]</ref>, and federated n-gram language <ref type="bibr" target="#b10">[11]</ref> marked the the importance of privacy-preserving learning under the requirement of acoustic and language data protection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DESIGNING QUANTUM CONVOLUTIONAL NEURAL NETWORKS FOR SPEECH RECOGNITION</head><p>In this section, we present our framework showing how to design a federated architecture based QCNN composed of quantum computing and deep learning for speech recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Speech Processing under Vertical Federated Learning</head><p>We consider a federated learning scenario for speech processing, where the ASR system includes two blocks deployed between a local user, and a cloud server or application interface (API), as shown in <ref type="figure">Fig. 1</ref>. An input speech signal, xi, is collected at the local user and up-streamed to a cloud server where Mel spectrogram feature vectors are extracted, ui. Mel spectrogram features are the input of a quantum circuit layer, Q, that learns and encodes patterns:</p><formula xml:id="formula_0">fi = Q(ui, e, q, d), where ui = Mel-Spectrogram(xi). (1)</formula><p>In Eq. <ref type="formula">(1)</ref>, the computation process of a quantum neural layer, Q, depends on the encoding initialization e, the quantum circuit parameters, q, and the decoding measurement d. The encoded features, fi, will be down-streamed back to the local user and used for training the ASR system, more specifically the acoustic model (AM). Proposed decentralized-VFL speech processing model reduces the risk of parameter leakages <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b10">11]</ref> from attackers, and avoids privacy issues under GDPR, with its architecture-wise advantages <ref type="bibr" target="#b23">[24]</ref> on encryption <ref type="bibr" target="#b15">[16]</ref> and without accessing the data directly <ref type="bibr" target="#b2">[3]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Quantum Convolutional Layer</head><p>Motivated by using VQC as a convolution filter with a quantum kernel, QCNN <ref type="bibr" target="#b12">[13]</ref> was recently proposed to extend CNN's properties to the quantum domain for image processing on a digital simulator and requires only fewer qubits to construct a convolution kernel during the QML progress. A QCNN consists of several quantum convolutional filters, and each quantum convolutional filter transforms input data using a quantum circuit that can be designed in a structured or a randomized fashion. <ref type="figure" target="#fig_1">Figure 2</ref> (a) show our implementation of a quantum convolutional layer. The quantum convolutional filter is consists of (i) the encoding function e(?), (ii) the decoding operation d(?), and (iii) the quantum circuit q(?). In detail, the following steps are performed to obtain the output of a quantum convolutional layer:</p><p>? The 2D Mel-spectrogram input vectors are chunked into several 2 ? 2 patches, and the n th patch is fed into the quantum circuit and encoded into intial quantum states, Ix[n] = e(ui[n]).</p><p>? The initial quantum states go through the quantum circuit with the operator q(?), and generate Ox[n] = q(Ix[n]).</p><p>? The outputs after applying the quantum circuit are necessarily measured by projecting the qubits onto a set of quantum state basis that spans all of the possible quantum states and quantum operations. Thus we get the desired output value, fx,n = d(Ox[n]). More details refer to the implementation 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Random Quantum Circuit</head><p>We deploy a random quantum circuit to realize a simple circuit U in which the circuit design is randomly generated per QCNN model for parameter protection. An example of random quantum circuit is shown in <ref type="figure" target="#fig_1">Figure 2</ref> (b), where the quantum gates Rx, Ry and Rz and CNOT are applied. The classical vectors are initially encoded into a quantum state ?0 = |0000 , and the encoded quantum states go through the quantum circuit U for the following phases as:</p><formula xml:id="formula_1">Phase 1: ?1 = Ry|0 Ry|0 Ry|0 Ry|0 . Phase 2: ?2 = (RxRy|0 )CNOT(Ry|0 )Ry|0 RzRy|0 . Phase 3: ?3 = CNOT((RxRy|0 ))CNOT(Ry|0 )Ry|0 RzRy|0 . Phase 4: ?4 = RxRy?3</formula><p>Besides, since random quantum circuit may involve many CNOT gates which bring about many unexpected noisy signals under the current non error-corrected quantum devices and the connectivity of physical qubits, we limit the number of qubits to small numbers to avoid exceeding the noise tolerance capabilities of VQC. In the simulation on CPU, we use PennyLane <ref type="bibr" target="#b6">[7]</ref>, which is an opensource programming software for differentiable programming of quantum computers, to generate the random quantum circuit, and we build the random quantum circuit based on the Qiskit <ref type="bibr" target="#b24">[25]</ref> for simulation with the noise model from IBM quantum machines with 5 and 15 qubits, which is advanced than simulation only results <ref type="bibr" target="#b12">[13]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Attention Recurrent Neural Networks</head><p>We use a benchmark deep attention recurrent neural network (RNN) <ref type="bibr" target="#b13">[14]</ref> model from <ref type="bibr" target="#b25">[26]</ref> as our baseline architecture for a local model (e.g., second-pass models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>) in the VFL setting. The model is composed of two layers of bi-directional long short-term memory <ref type="bibr" target="#b13">[14]</ref> and a self-attention encoder <ref type="bibr" target="#b26">[27]</ref> (dubbed RNN Att ).</p><p>In <ref type="bibr" target="#b25">[26]</ref>, this RNN model has been reported the best results over the other DNN based solutions included DS-CNN <ref type="bibr" target="#b27">[28]</ref> and ResNet <ref type="bibr" target="#b28">[29]</ref> for spoken word recognition.</p><p>To reduce architecture-wise variants on our experiments, we conduct ablation studies and propose an advanced attention RNN model with a U-Net encoder <ref type="bibr" target="#b29">[30]</ref> (denoted as RNN UAtt ). As shown in <ref type="figure" target="#fig_2">Fig. 3</ref>, a series of multi-scale convolution layers (with a channel size of 8-16-8) will apply on quantum-encoded (quanv) or neural convolution-encoded (conv) features to improve generalization of acoustic by learning scale-free representations <ref type="bibr" target="#b29">[30]</ref>. We use RNN Att and RNN UAtt in our experiments to evaluate the advantages of using the proposed QCNN model. As shown in <ref type="figure" target="#fig_2">Fig 3 (b)</ref>, we provide a loss calculation layer on the RNN backbone for our local model. For spoken word recognition, we use the cross-entropy loss for classification. The loss layer could further be replaced by connectionist temporal classification (CTC) loss <ref type="bibr" target="#b30">[31]</ref> for a large-scale continuous speech recognition task in our future study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>As initial assessment of the viability our novel proposed framework, we have selected a limited-vocabulary yet reasonably challenging speech recognition task, namely the Google Speech Command-V1 <ref type="bibr" target="#b28">[29]</ref>. For spoken word recognition, we use the ten-classes setting that includes the following frequent speech commands <ref type="bibr" target="#b1">2</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Encoded Acoustic Features from Quantum Device</head><p>The IBM Qiskit quantum computing tool <ref type="bibr" target="#b24">[25]</ref> is used to simulate the quantum convolution. We first use Qiskit to collect compiling noises from two different quantum computers. We then load those recorded noise to the Pennylane-Qiskit extension in order to simulate noisy quantum circuit experiments for virtualization. According to previous investigations <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18]</ref>, the proposed noisy quantum device setup can be complied with NISQ directly and attains results close to those obtained using NISQ directly . The chosen setup preserves quantum advantages on randomization and parameter isolation. Visualization of Acoustic Features. To better understand the nature of the encoded representation of our acoustic speech features, we visualize the encoded features and acoustic patterns extracted from different encoders. <ref type="figure" target="#fig_3">Fig. 4</ref> shows QCNN-encoded results with a 2?2 kernel (in panel (c)), which seems to better relate to the acoustic pattern shown in the Mel spectrogram shown in panel (a), since it well captures energy patterns in both high and low-frequency regions. The latter becomes more evident by comparing panel (c) with the features encoded with a 3?3 kernel given in panel <ref type="bibr">(d)</ref>. Finally, the neural network-based convolution layer reported in panel (b) shows similar results with those in panel (c), but it presents a lower intensity in the high-frequency regions. We will discuss its relationship between recognition performance later in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Performance of Spoken-Word Recognition</head><p>We conduct experiments on the spoken-word recognition task and compared the improved performance from an additional quantum convolution layer with a 2?2 kernel (4 qubits) and a neural convolution layer with a 2?2 kernel in <ref type="table" target="#tab_3">Table 2</ref>. From the experiments, the recognition models with additional quantum convolution show better accuracy than the baseline models <ref type="bibr" target="#b25">[26]</ref>. The modified model with a U-Net encoder, RNN UAtt , achieves the best performance of 95.12?0.18% on the evaluation data, which is better than the reproduced RNN Att baseline (94.21?0.30%) for the recognition setup. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">A Study on QCNN Architectures</head><p>Next we experiment with various new QCNN <ref type="bibr" target="#b12">[13]</ref> architectures for ASR with different combinations of quantum encoders and neural acoustic models. First, we study the quantum convolution encoder with different kernel sizes. From previous works <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18]</ref>, the current commercial NISQ devices would be challenging to provide reproducible and stable results with a size of qubits larger than 15. We thus design our quantum convolutional encoders under this limitation with a kernel size of 1?1 (1 qubit), 2?2 (4 qubits), and 3?3 (9 qubits). We select two open source neural AMs as the local model, DS-CNN <ref type="bibr" target="#b27">[28]</ref>, and ResNet <ref type="bibr" target="#b28">[29]</ref>, from the previous works testing on the Google Speech Commands dataset. As shown in the bar charts in <ref type="figure">Fig. 5</ref>, QCNNs with the 2?2 kernel show better accuracy and lower deviations than all other models tested. QCNN attains 1.21% and 1.47% relative improvements over DS-CNN and ResNet baseline, respectively. On the other hand, QCNNs with the 3?3 kernel show the worst accuracy when compared with other configurations. Increasing the kernel size does not always guarantee improved performances in the design of QCNN for the evaluation. The encoded features obtained with a 3?3 quantum kernel used to train AMs, as shown in <ref type="figure" target="#fig_3">Fig. 4(d)</ref>, are often too sparse and not as discriminative when compared to those obtained with 1?1 and 2?2 quantum kernels, as indicated in <ref type="figure" target="#fig_3">Fig. 4(b)</ref> and <ref type="figure" target="#fig_3">Fig. 4(c</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">A Saliency Study by Acoustic Class Activation Mapping</head><p>We use a benchmark neural saliency technique by class activation mapping (CAM) <ref type="bibr" target="#b31">[32]</ref> over different neural acoustic models to highlight the responding weighted features that activate the current output prediction. As shown in <ref type="figure" target="#fig_4">Fig. 6</ref>, QCNN (b) learns much more correlated and richer acoustic features than RNN with a convolution layer and baseline model <ref type="bibr" target="#b25">[26]</ref>. According to the CAM displays, the activated hidden neurons learn to identify related low-frequency patterns when making the ASR prediction from an utterance "on."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>In this paper, we propose a new feature extraction approach to decentralized speech processing to be used in vertical federated learning that facilitates model parameter protection and preserves interpretable acoustic feature learning via quantum convolution. The proposed QCNN models show competitive recognition results for spoken-term recognition with stable performance from quantum machines when learning compared with classical DNN based AM models with the same convolutional kernel size. Our future work includes incorporating QCNN into continuous ASR. Although the proposed VFL based ASR architecture fulfilling some data protection requirements by decentralizing prediction models, more statistical privacy measurements <ref type="bibr" target="#b23">[24]</ref> will be deployed to enhance the proposed QCNN models from the other privacy perspectives <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b0">1]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>1 https://github.com/huckiyang/QuantumSpeech-QCNN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>The proposed variational quantum circuit for 2 ? 2 QCNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>The proposed QCNN architecture for ASR tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>: ['left', 'go', 'yes', 'down', 'up', 'on', 'right', 'no', 'off', 'stop'], with a total of 11,165 training examples, and 6,500 testing examples with the background white noise setup [29]. The Mel-scale spectrogram features are extracted from the input speech using the Librosa library; this step takes place in the NISQ server. The input Mel-scale feature is actually a 60-band Mel-scale, and 1024 discrete Fourier transform points into the quantum circuit as the required VFL setting. The experiments with the local model are carried out with Tensorflow, which is used to implement DNNs and visualization. (a) Input Mel-Spectrogram (b) 2x2 Neural-Conv Encoded (c) 2x2 Quantum-Conv Encoded (d) 3x3 Quantum-Conv Encoded Visualization of the encoded features from different types of convolution layers. The audio transcription is "yes" of the input.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 :</head><label>6</label><figDesc>Interpretable neural saliency results by class activation mapping [32] over (a) Mel spectrogram features with audio transcription of "on"; (b) a 2?2 quantum convolution layer followed by RNN UAtt ; (c) a well-trained 2?2 neural convolution layer followed by RNN UAtt , and (d) baseline RNN UAtt .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparisons of spoken-term recognition on Google Commands dataset with the noise setting<ref type="bibr" target="#b28">[29]</ref> for classification accuracy (Acc) ? standard deviation. The additional convolution (conv) and quantum convolution (quanv) layer have the same 2?2 kernel size.</figDesc><table><row><cell>Model</cell><cell>Acc. (?)</cell><cell>Parameters (Memory) (?)</cell></row><row><cell>RNNAtt [26]</cell><cell cols="2">94.21?0.30 170,915 (32-bits)</cell></row><row><cell>Conv + RNNAtt</cell><cell cols="2">94.32?0.26 174,975 (32-bits)</cell></row><row><cell>Quanv + RNNAtt</cell><cell cols="2">94.75?0.17 174,955 (32-bits) + 4 (qubits)</cell></row><row><cell>RNNUAtt</cell><cell cols="2">94.72?0.23 176,535 (32-bits)</cell></row><row><cell>Conv + RNNUAtt</cell><cell cols="2">94.74?0.25 180,595 (32-bits)</cell></row><row><cell cols="3">Quanv + RNNUAtt 95.12?0.18 180,575 (32-bits) + 4 (qubits)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>), respectively.</figDesc><table><row><cell></cell><cell>105 110</cell><cell>1x1 kr</cell><cell>2x2 kr</cell><cell cols="2">3x3 kr</cell><cell>baseline</cell></row><row><cell>Val. Accuracy (%)</cell><cell>80 85 90 95 100</cell><cell>80.43 95.12 93.55 94.72</cell><cell cols="2">81.61 94.41 93.42 93.28</cell><cell>81.53 94.48 93.21 93.11</cell></row><row><cell></cell><cell>75</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>70</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>65</cell><cell>RNN-UAtt</cell><cell>DS-CNN</cell><cell></cell><cell>ResNet</cell></row><row><cell cols="6">Fig. 5: Performance studies of different quantum kernel size (dubbed</cell></row><row><cell cols="6">kr) with DNN acoustic models for designing QCNN models.</cell></row><row><cell></cell><cell cols="3">(a) Input Mel-Spectrogram</cell><cell cols="2">(b) Quanv + RNN (UAtt)</cell></row><row><cell></cell><cell></cell><cell>(c) Conv + RNN (UAtt)</cell><cell></cell><cell cols="2">(d) Baseline RNN (UAtt)</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://ai.googleblog.com/2017/08/launching-speech-commandsdataset.html</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Federated learning for keyword spotting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gisselbrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dureau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6341" to="6345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The eu general data protection regulation (gdpr)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Voigt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Von</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bussche</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Springer International Publishing</publisher>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
	<note>A Practical Guide. 1st Ed</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Federated machine learning: Concept and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology (TIST)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">New types of deep neural network learning for speech recognition and related applications: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="8599" to="8603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Commercialize quantum technologies in five years</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohseni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boixo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Denchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Babbush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Smelyanskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martinis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">543</biblScope>
			<biblScope unit="issue">7644</biblScope>
			<biblScope unit="page" from="171" to="174" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Quantum circuit learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mitarai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Negoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kitagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review A</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">32309</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Pennylane: Automatic differentiation of hybrid quantum-classical computations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bergholm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Izaac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gogolin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mckiernan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Killoran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.04968</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Supervised learning with quantum-enhanced feature spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Havl??ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>C?rcoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Temme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Harrow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kandala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Gambetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">567</biblScope>
			<biblScope unit="issue">7747</biblScope>
			<biblScope unit="page" from="209" to="212" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Quantum computation by adiabatic evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Farhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldstone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sipser</surname></persName>
		</author>
		<idno>quant- ph/0001106</idno>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Quantum computing in the nisq era and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quantum</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">79</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Federated learning of n-gram language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mathews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Allauzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Beaufays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03432</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Multi-task language modeling for improving speech recognition of rare words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gandhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Filimonov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bulyko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.11715</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Quanvolutional neural networks: powering image recognition with quantum circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shakya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Quantum Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Quantum machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Biamonte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wittek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pancotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rebentrost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">549</biblScope>
			<biblScope unit="issue">7671</biblScope>
			<biblScope unit="page" from="195" to="202" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Quantum circuit complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-C</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1993 IEEE 34th Annual Foundations of Computer Science</title>
		<meeting>1993 IEEE 34th Annual Foundations of Computer Science</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="352" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Parameterized quantum circuits as machine learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Benedetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fiorentini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quantum Science and Technology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">43001</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Variational quantum circuits for deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-S</forename><surname>Goan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="141" to="148" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Quantum long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><forename type="middle">L</forename><surname>Fang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.01783</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Quantum neural network in speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1267" to="1270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Submodular rank aggregation on score-based permutations for distributed automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tejedor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3517" to="3521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Improved lite audio-visual speech enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-Y</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.13222</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unifying leakage models: From probing attacks to noisy leakage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Duc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dziembowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Faust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual International Conference on the Theory and Applications of Cryptographic Techniques</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="423" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The reusable holdout: Preserving validity in adaptive data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="issue">6248</biblScope>
			<biblScope unit="page" from="636" to="638" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Qiskit: An opensource framework for quantum computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Aleksandrowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barkoutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ben-Haim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cabrera-Hern?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carballo-Franquis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Accessed on: Mar</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A neural attention model for speech command recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>De Andrade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Leo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L D S</forename><surname>Viana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bernkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.08929</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Hello edge: Keyword spotting on microcontrollers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Suda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.07128</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Speech commands: A dataset for limited-vocabulary speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03209</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Characterizing speech adversarial examples using self-attention u-net enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3107" to="3111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fern?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="369" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2921" to="2929" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
