<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">UQuAD1.0: Development of an Urdu Question Answering Training Data for Machine Reading Comprehension</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samreen</forename><surname>Kazi</surname></persName>
							<email>sakazi@iba.edu.pk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics &amp; Computer Science Institute of Business Administration</orgName>
								<address>
									<settlement>Karachi</settlement>
									<country key="PK">Pakistan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakeel</forename><surname>Khoja</surname></persName>
							<email>skhoja@iba.edu.pk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics &amp; Computer Science Institute of Business Administration</orgName>
								<address>
									<settlement>Karachi</settlement>
									<country key="PK">Pakistan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">UQuAD1.0: Development of an Urdu Question Answering Training Data for Machine Reading Comprehension</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years, low-resource Machine Reading Comprehension (MRC) has made significant progress, with models getting remarkable performance on various language datasets. However, none of these models have been customized for the Urdu language. This work explores the semi-automated creation of the Urdu Question Answering Dataset (UQuAD1.0) by combining machine-translated SQuAD with human-generated samples derived from Wikipedia articles and Urdu RC worksheets from Cambridge O-level books. UQuAD1.0 is a large-scale Urdu dataset intended for extractive machine reading comprehension tasks consisting of 49k question Answers pairs in question, passage, and answer format. In UQuAD1.0, 45000 pairs of QA were generated by machine translation of the original SQuAD1.0 and approximately 4000 pairs via crowdsourcing. In this study, we used two types of MRC models: rule-based baseline and advanced Transformer-based models. However, we have discovered that the latter outperforms the others; thus, we have decided to concentrate solely on Transformer-based architectures. Using XLMRoBERTa and multi-lingual BERT, we acquire an F1 score of 0.66 and 0.63, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Text comprehension and question answering remain difficult task for machines that requires large-scale resources for training. The scarcity of annotated datasets in low-resource Asian languages is one of the primary reasons the development of language-specific Question Answering models is behind, particularly in the case of the Urdu language. Some techniques for dataset creation for low-resource languages transfer English resources in order to do NLP tasks. In response to increased demand and a dearth of standard datasets in Urdu, we introduce UQuAD1.0 (Urdu Question Answering Dataset): a large-scale question-answering dataset built for Urdu MRC. We gathered 4K Urdu QA pairs via crowdsourcing and combined them with 45k Urdu translated SQuAD <ref type="bibr" target="#b0">[1]</ref> tuples. The study includes statistics on the distribution of answers and questions, along with the types of questions. By releasing training data publicly for reading comprehension tasks, UQuAD1.0 contributes to multi-lingual language processing research. While machine translation (MT) for languages with minimal resources has proven to be a challenging task <ref type="bibr" target="#b1">[2]</ref>  <ref type="bibr" target="#b2">[3]</ref>, the level of difficulty grows furthermore when translating between two morphologically rich and morphologically poor languages <ref type="bibr" target="#b3">[4]</ref>  <ref type="bibr" target="#b4">[5]</ref>. For that, we have developed the following research questions:</p><p>? RQ1: Can QA resources for other languages be created just by translating English resources?</p><p>? RQ2: Can time and effort be saved when manually annotating QA materials in other languages by utilizing existing resources in English? ? RQ3: Is it possible to learn Urdu RC using pre-trained multi-lingual architectures that have been trained in a variety of languages? ? RQ4: Is it possible to evaluate a model based on its language understanding capability?</p><p>In RQ1, we look at MT, or Machine-Translated Squad resource. MT should be enough to train an Urdu-QA system equivalent to SQuAD-trained even with flawless translation. However, there are two issues: <ref type="bibr" target="#b0">(1)</ref> Translation shifts or loses the position of the answer span. <ref type="bibr">(</ref>2) The quality of QA pairs varies. Without overcoming these obstacles, F1 performance using our best performing model is 12.49, demonstrating the weakness of this technique. We determined from the results of RQ1 that MT performance is low, so it is appropriate to create language-specific (Urdu) resources for QA. As a result, we built the small Urdu MRC benchmark dataset using the same crowdsourcing technique that was used to build the English SQuAD, with the following contributions:: <ref type="bibr" target="#b0">1)</ref> Including a variety of question types: To evaluate different aspects of the MRC model's language understanding capability, we provide different question types based on Bloom's taxonomy.</p><p>2) Avoiding lexical shortcuts: By imposing lexical and syntactic variety while creating query similar to benchmark SQuAD dataset. <ref type="bibr" target="#b2">3)</ref> Our data coverage level consists of Urdu Wikipedia articles and Tafheem (RC) worksheets of Cambridge O-level books.</p><p>Although our manually annotated dataset came from a translated resource, it needed a significant amount of time and resources to educate employees in examining and repairing translated samples. It also addressed our RQ2 that manual annotation takes the same amount of time and effort. To answer RQ3, we fine-tuned an Urdu QA system using small crowdsourced data by humans and large translated resources with a multi-lingual Transformer-based architecture, achieving an F1 score of 0.66. Finally, for RQ4, we will evaluate the model's language comprehension capabilities by examining the types of questions it can answer and their associated accuracy.</p><p>This research discusses related work in section 2, followed by dataset construction and statistics in section 3. Later on, models are described in section 4, followed by Section 5, showing the experiments and results. Finally, Section 6 presents the conclusion and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>A task where the system must answer questions about a document is called machine reading comprehension (MRC). This technique acquired significant acceptance following the publication of a large-scale Reading Comprehension (RC) dataset termed SQuAD <ref type="bibr" target="#b0">[1]</ref> containing Over 100,000 questions on popular Wikipedia articles. The broad use of SQuAD has resulted in the formation of other related datasets. For instance, TriviaQA <ref type="bibr" target="#b5">[6]</ref> comprises 96k questions and answers regarding trivia games, which were discovered on the Internet and documents con-training the answers. The Natural Questions corpus is a set of questions <ref type="bibr" target="#b6">[7]</ref> that is almost three times the size of SQuAD, and the questions were extracted from Google search logs. MS MARCO <ref type="bibr" target="#b8">[8]</ref> has one million queries extracted from Bing Search.</p><p>Unfortunately, there are very few similar MRC datasets for other languages, necessitating the development of multi-lingual MRC for low-resource languages, XSQuAD <ref type="bibr" target="#b9">[9]</ref> dataset was built to meet this demand. It contains 40 paragraphs and 1190 question-answer pairs from SQuAD that have been translated into ten languages. Arabic and Hindi are also included in XSQuaD, but not Urdu. In order to address the unavailability of datasets other than English RC, significant efforts have been made in recent years to develop datasets in low-resource languages for Reading Comprehension, for example, SberQuAD <ref type="bibr" target="#b10">[10]</ref>, a dataset similar to SQuAD for the Russian language, was recently created using the same technique as SQuAD. Additionally, <ref type="bibr" target="#b11">[11]</ref> offered a Bulgarian dataset, <ref type="bibr" target="#b12">[12]</ref> presented a Tibetan dataset, <ref type="bibr" target="#b13">[13]</ref> generated an Arabic Reading Comprehension Dataset (ARCD) to fill the gap of MRC in other languages. Also, SQuAD-it <ref type="bibr" target="#b14">[14]</ref>, a semi-automatic translation of the SQuAD dataset into Italian, is a huge dataset for question answering processes in Italian containing 60k question/answer pairs. <ref type="bibr" target="#b15">[15]</ref> released FQuAD: French Question Answering Dataset in two versions with 25k and 60k samples. <ref type="bibr" target="#b16">[16]</ref> Introduced HindiRC consists of only 127 questions from 24 paragraphs, manually annotated by humans. Another variation of synthetic dataset translated from SQuAD 1.1 for Hindi reading comprehension by <ref type="bibr" target="#b17">[17]</ref> consists of over 18k questions. The absence of native language annotated datasets other than English is one of the primary reasons language-specific Question Answering models take longer to develop.</p><p>As previously stated in the literature review, Hindi and Arabic are two low-resource languages that have evolved rapidly in MRC, with the research community giving them the attention they deserve in recent years. Although Urdu shares many characteristics with Arabic, Persian, and Hindi, such as the lack of capitalization, compound words, similar morphology, and free word order <ref type="bibr" target="#b4">[5]</ref>, Urdu still struggles to make initial studies in NLP. These languages are among the most widely spoken globally, with 170 million Urdu speakers, 490 million Hindi speakers, and 255 million Arabic speakers worldwide. These low-resource languages are highly sought after in realworld applications such as human-robot interaction, question answering, recommendations, and particular search queries. It has a knock-on impact on every business because robots that comprehend questions and react with appropriate information may boost efficiency and save time. Unfortunately, Arabic and Hindi do not have monolingual big-size MRC datasets to create stateof-the-art RC models, but they are making progress in this area by experimenting with alternate methodologies. On the other hand, the Urdu research community lags behind its close allies, as it lacks even a single dataset in the Nastaliq script.</p><p>To the best of our knowledge, the MRC contains no contributions in Urdu. To address the scarcity of Urdu language comprehension data, we present UQuAD1.0, an Urdu QA dataset for reading comprehension consisting of a total of 49k tuples (Question, paragraph, and Answer). Our research complements previous efforts by annotating small resources while utilizing large resources generated for another language. From a model architecture standpoint, most existing state-of-theart models for reading comprehension rely on transformer-based architectures that use the selfattention mechanism to weigh the significance of each component of the passage data differently and achieve good performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">UQuAD1.0 Dataset</head><p>UQuAD dataset consists of two main parts: a large-scale Machine Translated (MT) part and a small-scale manually annotated part using a crowdsourced approach. Both parts will be presented in detail in sections 3.1 and 3.2. General statistics about each portion are presented in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Machine Translated UQuAD1.0</head><p>To address RQ1, we examine the difficulty of retaining answer spans from English to Urdu. We identify the following three examples as shown in Appendix A based on Google Translate of English SQuAD tuples into Urdu:</p><p>? Exact matching (36%): English answer spans are translated into exact Urdu terms.</p><p>? Synonym's matching (17%): The Urdu answer spans are paraphrased versions of the Urdu passage's terms.</p><p>? Unpreserved Spans (47%): Google Translation cannot retain answer spans throughout translation due to a language barrier or translation inaccuracy.</p><p>We were able to collect 53% of the UQuAD dataset using the first two approaches. However, we had to delete 47% of the data due to answer span issues. It is clear from the last example in Appendix A that a feminine pronoun is referred to as a male throughout the phrase, and in other cases, the answer was not kept between paragraph and answer owing to translation discrepancies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2</head><p>Crowd-Source UQuAD1.0</p><p>The main challenge in training QA systems is poorly translated QA pairs. Example 3 in Appendix A shows that machine translations cannot find the correct answer span in a large portion of translated. We thus build small-scale language-specific human-generated resources for fine-tuning QA systems. The advantage of resource is near perfect precision, with the disadvantage of being labor-intensive. Similar to the SQuAD1.0 collection process, we crowdsourced over 4k questionanswer pairs. The data generation procedures for this dataset are generally the same as SQuAD1.0. However, we exploited unique aspects of the Urdu language, such as extensive vocabulary usage and diversity of question types as per Bloom's taxonomy (Appendix B), to enrich and diversify this dataset. For the question-answer creation process, we recruited volunteers from different cities so that everyone had their distinct style of questioning, which added more variety to the dataset. We used a dedicated user interface (UI) guided by SQuAD guidelines to build human-generated QA pairs. We took a sample of 100 Urdu Wikipedia pages and extracted paragraphs of considerable length without graphics. The 100 articles resulted in 1972 paragraphs covering various topics from politics, religion, education, and music, as reflected in <ref type="table" target="#tab_1">Table 2</ref>. Human annotators utilized the UI depicted in <ref type="figure" target="#fig_0">Figure  1</ref> to read a text, enter questions, choose types of questions specific to Bloom's taxonomy, and then highlight the spans containing answers. The practice of generating questions by copying and pasting content from Wikipedia was restricted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">UQuAD Question and Answer Types Analysis</head><p>To increase the difficulty of this dataset, we limit MRC models from adopting simple techniques based on fundamental word matching. Additionally, rather than focusing exclusively on keywords, our goal is to generate questions that can be addressed by examining the entire passage. Not all questions are equally challenging. Some questions are simple to answer, while others may need much thinking. Bloom <ref type="bibr" target="#b18">[18]</ref> provides us with a taxonomy to assist in framing queries at various thinking levels. It divides cognitive abilities into six categories, ranging from low-level ability to high-level ability that requires deeper cognitive instruction. Each question is complicated in its own way, and comprehending and correctly replying to each demand a separate set of cognitive talents. In <ref type="figure" target="#fig_4">figure 5</ref>.3, we identified the types of reasoning required to solve Bloom's taxonomybased question and presented the results of a manual assessment of 200 questions drawn from the test set. The most commonly requested question type accounts for 26.4% of all inquiries that fall under the category of Remember, which we may query using lexical variants or by rearranging synonyms. Analyze questions, which account for 19.6% of all questions, require the collection of evidence from multiple sentences. 2.9% of questions fall into the comprehend category, which interprets the message provided in the question using the various cues listed in column 3 of Appendix 2. Finally, in the external knowledge category, we checked if the response was not in the text or if the response area was erroneously picked owing to the worker's error. Similar to SQuAD dataset, we establish five forms of reasoning necessary to answer 200 questions from the test set of UQuAD, summarized in <ref type="figure" target="#fig_4">Figure 5</ref>.3. The most often requested inquiry type constitutes 27% of test data and involves rearranging the syntax or altering the phrasing of the supporting phrase. Questions from passages employing a synonym and global knowledge account for 20% and 10%. 13% of questions need proof from several sentences. On average, 10% of questions featured a deduction for a sentence's options that satisfy the question's requirements. Finally, 20% of questions were asked based on information outside the paragraph or were picked erroneously owing to a human error. For answers, we categorize UQuAD answers into six groups, shown in <ref type="table" target="#tab_2">Table 3</ref>. It results in 18% object responses, followed by person, date, and place. Description and reasoning questions account for 17.4% and 8.3%, respectively. We conclude that UQuAD1.0 has more Date and Person classes than SQuAD1.0, but other classes are relatively equivalent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UQuAD (All) UQuAD (train) UQuAD (test)</head><p>Number   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Models</head><p>We investigate the performance of three models: a baseline approach based on sliding window <ref type="bibr" target="#b19">[19]</ref> and two multi-lingual Transformer-based models BERT <ref type="bibr" target="#b20">[20]</ref> and XLMRoberta <ref type="bibr" target="#b21">[21]</ref>. The Sliding window approach was first introduced in the MCTest paper, and it solves the answer extraction problem in a rule-based manner without any training data needed. BERT is a powerful pre-trained model that recently obtained state-of-the-art performance on various NLP tasks. We use the multi-lingual pre-trained model released by Google to fine-tune the BERT model for the UQuAD1.0 task without applying additional language-specific NLP techniques. The Third model used is XLM-Roberta, a multi-lingual pre-trained transformer model from common Crawl trained on 100 languages, including Urdu. XLM-Roberta outperformed previous multi-lingual models such as mBERT and XLM on a variety of downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Sliding Window Baseline</head><p>We picked the sliding window as the baseline approach since it is also utilized in the benchmark SQuAD work and also because it demonstrates that matching term frequency or simple word matching between question and context cannot address the RC problem. For a given (paragraph, question), the sliding window approach works as follows:</p><p>1) Tokenize P-Q-A Tuple: converts each Paragraph-Question-Answer tuple to a set of tokens using a dedicated Urdu tokenizer from Stanford Stanza Library.</p><p>2) Generate Candidate Answers: generate a list of text spans of input paragraph. They are treated as candidate answers.</p><p>3) Score Candidate Answers (SW+D): Score each candidate's answer using Sliding Window and Distance features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Compute Final Score:</head><p>for each candidate answer. Final score = sliding window scoredistance score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Predict Answer</head><p>: The candidate answer with the highest score is the answer predicted by the model.</p><p>Since UQuAD is not a multi-choice question dataset, we had to generate candidate answers from scratch. For that, we first generate all possible text spans from the passage with a threshold on the maximum length of candidate answers. Then we only keep answers that have the highest unigram and bigram overlap score with the related question. The sliding window and distance-based scores of each candidate answer are computed using the algorithms in <ref type="figure" target="#fig_2">Figure 3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Transformer models: XLMRoberta and mBERT</head><p>In this work, the performance of transformer-based models for machine-reading comprehension is examined. Models built on top of the Transformer architecture <ref type="bibr" target="#b23">[22]</ref> account for the vast majority of state-of-the-art performance in a variety of natural language processing tasks. In the absence of pre-trained Urdu monolingual models, we leverage the transfer learning concept inherent in these models to fine-tune the current pre-trained models for question answering on the UQuAD dataset. We examined various such models and found out that two of them outperform all others in our experiments: multi-lingual BERT (mBERT) and XLM-RoBERTa. They already incorporated knowledge of 104 and 100 languages, respectively, including Urdu.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Train/Validation/Test split</head><p>We created two sets of annotated QA pairs, one for training (80%) and one for testing (20%), with no overlap of passages or articles. Statistics on both portions are presented in <ref type="table">Table 1</ref>. The training part was furthermore split into 80% for actual training and 20% for validation. We use 5-fold crossvalidation for the better significance of the performance results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Data Preprocessing</head><p>While mBERT and XLMRoBERTa are distinct models, their overall fine-tuning process using the Transformers library is similar, demonstrating the API's potential. There-fore, we describe in the following paragraphs the common foundation for both models. We begin by preprocessing the whole dataset to eliminate any noise or inconsistency introduced during data gathering. We eliminate instances that exhibit one or more of the following:</p><p>? The paragraph does not have an answer span.</p><p>? Index of incorrect responses (i.e., paragraph text at answer index is different from answer text).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>The index of the response is -1.</p><p>We then determine the model based on each response's start/end indices in the resulting data. We know the answer's placement in terms of its character index inside the paragraph, but we require its location in terms of the model's internal tokenization system. To do this, we proceed as follows for each (Paragraph, Question, Answer) tuple: <ref type="bibr" target="#b0">1)</ref> Tokenize the response to ascertain the number of tokens it contains. <ref type="bibr" target="#b1">2)</ref> In the associated paragraph, replace the response with a list of the model's mask tokens (i.e., [MASK] for mBERT and &lt;mask&gt; for XLM-RoBERTa), according to the number of tokens in the answer. Following that, tokenize the result.</p><p>3) Determine the start/end indices of the response in the tokenized paragraph by locating the mask tokens in the encoded result. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Fine-Tuning Process</head><p>The maximum input sequence length (max_len) at which samples will be truncated is a small but essential step. It is essential for successful fine-tuning because using the longest input sequence as the threshold would slow down the training process and potentially cause memory overflow, resulting in Out Of Memory (OOM) failures. Both the maximum length and batch size must fit inside the memory constraints of our GPU. As a result, there is a tradeoff between data loss, memory usage, and training speed. To do this, we calculate data loss as a percentage of the maximum length value and tolerate up to 2% data loss. Then we choose a threshold that considers all three variables (i.e., data loss, training speed, memory usage). Finally, we load the pre-trained model, set its hyperparameters (learning rate, optimizer, batch size), and begin fine-tuning the model using the previously encoded UQuAD training data. For each model, we trained two submodels using the same architecture: one to predict the response start index and the other to predict the answer end index. <ref type="table" target="#tab_4">Table 4</ref> presents the values of the hyperparameters used during fine-tuning. A maximum input sequence length of 384 and batch size of 16 is the highest combination the available GPU (i.e., Tesla T4) could handle without memory issues, with data loss smaller than 2% and acceptable speed ( 1h30min per epoch). We use Adam optimizer <ref type="bibr" target="#b25">[23]</ref> (more specifically, the AdamW variant and a dynamic learning rate that decreases linearly over training steps, with a number of warmup steps=0. The validation set is a randomly sampled 20% of the training dataset used to tune hyperparameters. The number of epochs was tuned by plotting the training and validation loss for different numbers of epochs (ref <ref type="figure" target="#fig_3">Figure 4)</ref>. During fine-tuning, the training loss keeps decreasing while the validation initially decreases then starts increasing after several epochs. It reflects the start of over-fitting. We choose the previous epoch as the best epoch. The remaining hyperparameters values were chosen according to the standard values recommended by the model's authors in their papers. We furthermore investigate changes in a set of hyperparameters values without performance improvement.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Hyperparameters</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Model Evaluation</head><p>In many aspects, the MRC work is comparable to a human reading comprehension task in terms of complexity. As a result, MRC model evaluation can take the same form: the model responds to paragraph queries and is assessed by comparing the model's replies to the right ones. This gives an answer to RQ3 about the model's capability of learning RC. We may compare the model's output to the right answer and assign it a score of 1 if they are identical and 0 if they are not. This metric is called Exact Match. This, on the other hand, will consider answers that are partially accurate as wrong responses. Even if the model's output is incredibly near to the correct answer, the exact match score will still be zero if the correct answer is "KotAdu city" and the model output is "KotAdu " the exact match score will still be zero.</p><p>Consequently, the F1 metric, which is the harmonic mean of the accuracy and recall, is often used for extracting responses. Precision and recall of a model are measured by the proportion of words in the model's output that appear in the correct response, and recall is measured by the proportion of words in the correct response that appear in the model's output. Precision is measured by the proportion of words in the correct response in the model's output. The F1 measure can only give a partial score when the model's output is only partially correct due to this limitation. <ref type="figure" target="#fig_4">Figure 5</ref> provides an example of calculating the EM and F1 scores and explains how to do so. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>We assess the performance of the three models on the UQuAD test set 23% of the questions in the test set to feature more than one possible answer, which provides greater versatility when assessing the model, as the same question may have many answers, which may occur in a variety of locations across the paragraph. The evaluation is carried out using two widely used measures for Machine Reading Comprehension: Accuracy/Exact Match (EM) metric and F1 score. The F1 score indicates the average overlap between the predicted response and the true answer, whereas the EM represents the proportion of predicted answers precisely matching accurate answers. While the Sliding Window base model achieved decent performance on English SQuAD (i.e., F1 score of 0.2), its application to Urdu did not have good results. The model achieved a very low accuracy of 4% and an F1 score of 0.03. Given its lexical particularities, this rule-based algorithm focusing primarily on matching words and distance between them is underperforming when applied to the Urdu language. When testing the Transformer-based models XLMRoBERTa and mBERT, we select the answer start index with the highest probability in the dedicated sub-model (i.e., the submodel that predicts the answer start index).</p><p>Similarly, we take the predicted response end-index from the dedicated sub-model. Since each sub-model was trained independently of the other, we evaluate its performance individually. The final model performance is the average of both sub-models performances. Both XLMRoBERTa and mBERT achieved excellent performance with F1 scores of 0.66 and 0.63, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sliding window mBERT XLM-RoBERTa</head><p>F1 3% 63% 66%</p><p>Exact Match 4% 66% 36% <ref type="table">Table 5</ref>: Models Performance Results using EM and F1 score However, their Exact Match scores are significantly lower, and this is due to the model predicting answers with a high level of words intersection but slightly away from an exact match. For example, a 5words predicted answer of which four words match precisely the answer is considered a wrong answer and accounts for 0 in the EM, while the F1 score that uses word-based evaluation will be high. We investigate this aspect by calculating the percentage of predicted answers in the actual answers and vice-versa. We found for XLMRoBERTa (resp. mBERT) that 47% (resp. 50%) of the predicted answers are in the associated accurate answers, and 66% (i.e., 17%) of the actual answers are in the associated predicted answers. It also compares the whole answers with the same words order; dropping the words order results in higher percentages, thus the high F1 scores achieved by the models. <ref type="table">Table 5</ref> summarizes the performance evaluation findings-the high performance of the transformer-based model's semantic aspects of Urdu at a broader level. Also, the self-attention mechanism helps memorize relevant parts of the paragraphs that are key to extracting the final answer. Both XLMRoBERTa and mBERT were pre-trained on text corpora of millions of documents from different languages. This transfer learning process reduces the finetuning time and required data volume and benefits the model from understanding general aspects of different languages that might apply in a wide range of use cases, especially for relatively similar languages such as Arabic and Hindi share a large set of common characteristics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">MRC Performance stratified by a question and answer types</head><p>This part will assess the language comprehension power and limitations of our most accurate model, XLM-RoBERTa, using three criteria: Urdu Question Difficulty, named-entities, and question type (who, what, when, where, and which). The proportion of accurately predicted responses (i.e., an exact match between predicted and real answers) for each question (resp. answer) type is shown in <ref type="figure">Figure 6</ref>(a) (resp. (b)). We only display question/answer types for which there are more than ten occurrences in the test set in both charts. We may see in (a) that performance on "What" questions is poorer than on other WH questions. It corresponds with our understanding because the "what" question is not as explicit as "Where" for the place, "When" for the date, and "Who" for an individual. The "Which" Question likewise received a poor score. In (b), the model gets 97% percent of the country answers correct. We anticipate that this is due to the transfer learning process, as the countries would have been met repeatedly during pre-training in multiple languages.</p><p>Moreover, because they were few as compared to dates and locations, the model quickly grasped them. When compared to others, performance on organization and person sorts of answers is relatively poor. A thorough error analysis of these questions reveals that the model can comprehend the context of the question and provide a sentence-containing answer despite being "ambiguous questions" in nature. While the model's forecast for "Exact Match" question types is essentially true even although the term "services" is not retrieved, even though the question words are paraphrases of context terms, the model was able to provide an accurate solution to the "Synonym Matching Questions." As seen in Appendix C, it was able to connect the word "legislative process" to the "governing body" through the use of word knowledge. For anaphorabased questions, the model cannot distinguish the antecedent "Chaudhry Aitzaz Ahsan" from the subsequent "He. " An interesting approach would be to test if the model can handle multisentence reasoning challenges and cataphora resolution issues in the absence of relevant training samples. The overall results are compelling and correspond to the model's predicted behavior. However, this is far from a thorough exploration of the model's comprehension, and a more indepth examination of the model's explainability might provide fascinating results. It provides question annotations on test set based on three distinct groupings: wh questions, named entities, and Bloom's taxonomy. We fine-tuned a baseline model on the test set to get an F1 score of 0.66 and an exact match ratio of 0.36 . After thoroughly evaluating the model's result, we concluded that the model was unable to handle descriptive and anaphora-related questions. Further study should be conducted to discover the model's limitations and develop specialized additions that are particular to the Urdu language. In order to bridge the performance gap between training state-of-the-art models in Urdu MRC, we are making baseline systems and data public. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Examples of Translation Categories From English SQuAD to</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>UQuAD UI for adding new data points</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Examples of UQuAD reasoning abilities Similar to SQuAD, we manually categorized 200 tuples into one or more above groups. The Crowdsourced solution is underlined, and words relating to the reasoning type are highlighted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Sliding Window and Distance-based Algorithms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Tuning number of epochs for mBERT. After epoch two, the validation loss starts increasing while the training loss keeps decreasing (over-fitting). The optimal number of epochs is 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Evaluation example using Exact Match and F1 score</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 : 2 )</head><label>62</label><figDesc>XLMRoBERTa Performance per Question/Answer Type 6. Conclusion and Future Work This study proposes UQuAD1.0, a new large-scale, open-domain Urdu machine reading comprehension (MRC) dataset that is intended to address real-world MRC problems of Urdu-low resource language. UQuAD provides the following advantages over datasets from other lowresource languages akin to Urdu: (1) Data sources: Automatic translation of original SQuAD1.0, human-generated questions and answers from Wikipedia pages, and Cambridge O-level books (Diverse Question Groups:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>UQuAD1.0: Distribution of Wikipedia Articles</figDesc><table><row><cell>Description</cell><cell cols="2">Reason Person Place</cell><cell>Date</cell><cell cols="2">Object Time</cell></row><row><cell>17.4%</cell><cell>8.3%</cell><cell>21.3% 11%</cell><cell>25%</cell><cell>18%</cell><cell>12%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>UQuAD1.0 Main Answer Types Distribution</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Hyperparameters values used during Fine-tuning</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>??? ???? ??? ????? ???? ??? ???? ??? ??? ??? A:born??? ????? ??? ???? ??? ???? ??? ??? ??? ??? ??????? ?????? ???? ????? ??? Appendix B Types of questions based on Bloom's taxonomy in UQuAD Dataset Category Definition Question Cues Question Example</head><label></label><figDesc>??? ??? ??? ??? ??? ??? ??? ??? ??? ????? ????? ??? ??? ???? ???? ???? ??? ??? ??? ??? ??? ??? ??? ???? ???? ??? ???? ???? ???? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???? ???? ???? ??? ??? ??? ??? ??? ???? ??? ??? ??? ??? ??? ??? ???? ??? ??? ??? ??? ??? ??? ??? ???? ???? ??? ??? ??? ????? ??? ??? ???? ??? ???? ??? ??? ??? ??? ??? ??? ??? ???? ??? ??? ??? ??? ????? ??? ??? ???? ??? ????? ??? ???? ??? ???? ??? ??? ??? ??? ???? ???? ??? ??? ??? ??? ??? ????? ???? ???? ??? ???? ???? ????? ??? ??? ??? ??? ???? ???? ??? ??? ???? ??? ?????? ??? ??? ??? ??? ?????? ????? ??? ???? ???? ??? ??? ??? What did Ghulam Ishaq Khan do before entering politics? ??? ???? ??? ??? ????? ???? ??? ??? ??? ??? ???? ??? ???? ??? ??? ??? ????? ??? ???? ??? ??? ???? ??? ???? ??? ??? ??? ????? ??? ??? ????? ??? ??? ???? ???? ??? ??? ??? ????? ??? ???? ??? ???? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???? ? ??? ????? ???? ??? ??? ??? ????? ? ??? ??? ??? 9110 ????? ???? ???? ???? ???? ??? ??? ??? ??? ???? ???? ?????? ????? ??? ??? ??? ??? ??? ??? ???? ??? ??? ??? ??? ???? ???? ??? ???? ???? ???? ??? ??? ? ???? ??? ??? ???? ??? ???? ???? ????? ??? ??? ???? ??? ???? ? ?????? ???? ???? ????? ??? ??? ??? ??? ????? ??? ???? ??? ??? ??? ???? ???? ????? ????? ??? ??? ??? ??? ???? ?????? ???? ???? ?????? ?????? ??? ???? ??? ??? ????? ??? ????? ???? ???? ???? ???? ??? ??? ??? ??? ???? ??? ??? ???? ?????? ???? ???? ??? ??? ??? ??? ??? ???? ???? ??? ???? ???? ???? ???? ??? ??? ??? ??? ??? ??? ? ??? ???? ??? ???? ??? ??? ???? ???? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???? ( 2002 ? ??? ??? ??? ??? ??? ??? ??? ??? ??? ????? ???? ???? ??? ???? ?????? ??? ??? ??? ???? ??? ??? ??? ??? ??? ????? ??? ??? ??? ??? ? ???? ??? ??? ??? ??? ???? ??? ??? ???? ) ???? ??? ????? ??? ??? ??? ????? ??? ???? ??? ??? ??? ??? ?????? ???? ???? ??? ???? ??? ???? ??? 900 ????? ???"? ???? ???? ??? ?"??? ???? ??? ???? ???? ??? ???? ??? ???? ??? ??? ???? ???? ??? ??? ???? ??"? ????? ??? ??? ??? ??? ??? " . In what city and state was Beyonce born and raised? ??? ??? ??? ????? ???? ????? ???? ??? ???? ??? ???? ??? ??? ???? and raised in Houston, Texas ???? ??? ??? ??? ??? ? ??? ??? ??? ??? ??? ?????? ??? ???? ??? ?????? ??? ?????? ??? ??? ??? ??? ??? ??? ???? ? ???? ??? ???? ??? ????? ??? ??? ??? ???? ??? ??? ??? ???? ??? ???? ??? ??? ??? ??? ??? B'Day (2006) ??? ??? ??? ??? ??? ? ??? ??? ??? ????? ??? "D?j? Vu" ?" ????? ???"? ??? ??? ??? ??? ???? ??? ???? ??? ??? ??"? ????? ??? ?????? ??? ??? ?"?? ( ???? ???? ??? ??? ???? ??? ??? ???? ??? ??? ??? ??? 2002 ????????? ??? ?????? ??? ????? ??? ??????? ??? ??? ??? ) ( ???? ??? ??? ??? ??? ??? ??? ??? ???? ????? ? 2002 ( ??? ??? ??? ???? ???? ????? ) 2001 ??? ??? ??? ??? ) ??? ????? ????? ??????? ????? ??? ???? ??? ??? ??? ??? ??? ???? ??? ??? ??? ??? ????? ?????? ??? ???? ??? ???? ???? ??? ??? ????? ????? ??? ???? ???? ??? ???? ??? ???? ??? ???? ??? ??? ??? ??? ???? ( ?????? ??? ???? 2002 ??? ???? ??? ... ??? ??? ??? ??? ???? ? ??? ???? ??? ????? ??? ??? ???? ???? ??? ??? ??? ??? ??? ??? ????? ??? ???? ???? ??? ??? ??? ???? ??? ??? ??? ) ( ???? ??? ??? ??? 2002 ??? ???? ??? ??? ??? ???? ???? ??? ??? ??? ??? ???? ??? ??? ???? ???? ??? ??? ??? ??? ??? ??? ???? ???? ??? ??? ??? ??? ? ??? ??? ??? ??? ???? ??? ??? ???? ) Fierce (2008), which saw the birth of her alter-ego Sasha Fierce and earned a record-setting six Grammy Awards in 2010, including Song of the Year for "Single Ladies (Put a Ring on It)". ????? ???? ??? ??? ??? ???? ??? ??? ??? ??? ??? ??? ????? ??? ???? 2090 ?(??? ??? ??? ??? ???? ??? ??? ??? ???? " ??? ??? ??? ??? ??? ? ?????? ???? ???? ??? ???? ??? ??? ??? ??? ??? ???? ??? ??? ??? ??? ??? ???? ??? ??? ??? ??? ???? ??? ???? ??)"? ??? ??? ??? ???? ??? ???? ??? ??? ???? ??? ??? ???? ??? ??? ??? ??? 2090 ????? ???? ??? ??? ??? ???? ??? ??? ??? ??? ??? ???? ??? ??? ???? ???? ??? ??? ???? ??? ??? ??? ??? ???? ???? ??? ??? ??? ??? ????? ??? ??? ??? ??? ??? ??? ???? ??? ???? ???? ??? ??? ??? ??? ???? ??? ???? ??? ??? ??? ??? 4 ( 2099 ??? ??? ??? ? ??? ??? ??? ???? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???? ??? ) ??? 9120 ? ??? ??? ??? ???? ??? ???? ???? ???? 9120 ????? ???? ??? ???? 9110 ???? ??? ??? ????? ??? ???? ????? ???? ??? ???? ???? ???? ??? ???? ??? ??? ???? ???? ??? ??? ????? ???? ??? ??? ??? ??? ???? ???? ( ??? ???? ??? ??? ??? ???? ??? ??? ????? ??? ???? ????? ??? ???? ??? ?????? 2092 ???? ???? ????? ?????? ????? ????? ??? ??? ??? ???? ??? ??? ??? ??? ???? ???? ???? ? ) ???? ??? ??? ??? ??? ??? ??? ??? ??? ???? ??? ??? ??? ???? ??? ???? ??? ??? ???? ??? ??? ??? ???? ??? ???? ???? ????? ??? ???? Q:For what movie did Beyonce receive her first Golden Globe nomination? ????:? ??? ??? ??? ??? ???????? ??? ???? ????? ??? ??????? ???? ??? ??? ??? ???? ???? ??? ??? ??? ???? ??? ??? ??? ???? ??? ??? ????? ??? ???? ??? ??? ??? ???? ??? ???? ??? ??? ???? ??? ???? ????? ???? ???? ??? ??? ??? ???? ??? ????? ???? ??? ??? ??? ???? ???? ???? ???? ??? ??? ???? ??? ???? ??? ??? ???? ??? ??? ??? ????? ??? ??? ???? ???? ???? ????? ??? ???? ??? ??? ???? ???? ??? ??? ??? ????? ??? ???? ??? ??? ???? ????? ??? ??? ???? ??? ??? ??? ??? ???? ??? ??? ??? ???? ???? ???? ??? ??? ???? ??? ?????? 94 ???? ??? ??? ??? ??? ??? ?????? ??? ???? ???? ??? ??? ???? ??? ??? ??? ??? ??? ???? ??????? ??? ??? ???? ??? ???? ??? ????? ??? ??? ???? ????? ??? ??? ??? ??? ??? ??? ??? ???? ??? ??? ???? ??? ??? ??? ??? ??? ??? ???? ??? ??? ??? ???? ??? ???? ??? ???? ???? ??? ???? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???? ??? ???? ??? ????? ??? ??? ???? ????? ??? ???? ????? ???? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???? ??? ???? ??? ??? ???? ??? ???? ?????? ??? ??? ??? ???? ??? ??? ???? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ?????? ??? ???? ??? ??? ????? ???? ????? ???? ??? ??? ?????? ??? ??? ??? ??? ???? ??? ???? ???? ???? ??? ??? ??? ??? ???? ??? ??? ??? ??? ??? ????? ??? ??? ??? ???? ??? ??? ???? ???? ???? ???? ????? ???? ??? ??? ??? ????? ??? ??????? ???? ??? ??? ???? ???? ??? ??? ????? ????? ??? ?????? ??? ??? ???? ????? ??? ???? ??? ??? ???? ??? ??? ??? ???? ???? ????? ???? ??? ???/? ??? ??? ??? ??? ???? ??? ??? ???? ???? ??? ???? ??? ????? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???? ????? ???? ???? ??? ??? ???? ????? ???? ??? ???? ??? ??? ??? ??? ??? ????? ???? ??? ???? ??? ??? ??? ??? ??? ???? ??????? ??? ??? ????? ??? ???? ????? ????? ???? ???? ???? ???? ??? ??? ??? ????? ??? ????? ??? ???? ??? ???? ???? ???? ???? ??? ???? ??? ??? ???? ??? ??? ???? ???? ???? ????? ???? ???? ???? ??? ??? ???? ??? ??? ??? ??? ???? ???? ????? ??? ???? ??? ??? ??? ??? ???? ???? ??? ???? ???? ???? ???? ??? ??? ??? ??? ??? ??? ??? ???? ??? ??? ??? ???? ???? ??? ??? ??? ??? ???? ??? ??? ??? ???? ??? ??? ???? ???? ???? ??? ???? ???? ???? ???? ???? ??? ??? ??? ??? ??? ??? ???? ???? ???? ???? ??? ???? ??? ?????? ??? ??? ??? ??? ??? ??? ??? ???? ??? ???? ????? ????? ????? ??? ??? ???? ??? ??? ???? ???? ??? ??? ??? ??? ????? ??? ??? ???? ??? ??? ???? ???? ??? ???? ??? ??? ???? ???? ??? ??? ???? ??? ???? ??? ??? ???? ???? ??? ??? ??? ??? ???? ????? ???? ??? ??? ???? ???? ???? ??? ??? ??? ??? ??? ???? ??? ???? ???? ???? ??? ??? ???? ???? ????? ??? ???? ??? ??? ??? ????? ???? ????? ????? ???? ??? ??? ??? ??? ???? ??? ??? ??? ??? ????? ??? ??? ? ???? ??? ??? ????? ???? ???? ????? ???? ??? ??? ??? ????? ??? ??? ???? ??? ??? ??? ???? ??? ???? ??? ???? ??? ???? ??? ???? ??? ??? ??? ??? ??? ???? ??? ??? ??? ???? ??? ???? ??? ??? ??? ???? ??? ???? ??? ??? ???? ??? ??? ??? ??? ???? ????? ??? ???? ???? ??? ???? ????? ???? ??? ???? ??? ??? ?????? ??? ??? ???? ??? ??? ??? ??? ??? ??? ??? ??? ???? ??? ??? ???? ??? ??? ??? ??? ????? ????? ???? ????? ??? ??? ??? ??? ??? ??? ??? ???? ??? ??? ??? ???? ???? ??? ??? ???? ???? ???? ?????? ??? ???? ??? ??? ??? ??? ??? ??? ??? ??? ???? ??? ??? ???? ???? ??? ??? ?????? ??? ??? ???? ??? ????? ???? ??? ??? ??? ??? ??? ???? ??? ??? ????? ???? ??? ??? ??? ??? ???? ??? ??? ??? ???? ??? ??? ??? ??? ??? ??? ??? ???? ??? ????? ???? ??? ??? ???? ??? ???? ??? ???? ???? ????? ? ??? ???? ???? ???? ??? ??? ??? ???? ????? ??? ??? ??? ???? ???? ???? ????? ? ??? ??? ??? ??? ? ????? ??? ??? ????? ??? ??? ??? ??? ??? ????? ??? ?????? ??? ???? ?????? ??? ???? ????? ??? ??? ??? ???? ??? ??? ????? ??? ??? ???? ??? ??? ???? ??? ??? ????? ??? ???? ??? ????? ??? ??? ??? ???? ???? ??? ??? ???? ???? ??? ??? ??? ??? ???? ???? ??? ??? ??? ??? ???????? ??? ??? ???? ???? ???? ??? ??? ??? ????? ???? ??? ??? ??? ??? ??? ??? ???? ???? ??? ??? ??? ???? ??? ??? ??? ??? ??? ???? ????? ???? ??? ??? ??? ??? ??? ???? ??? ??? ????? ????? ????? ???? ??? ???? ??? ???? ????? ???? ???? ??? ??? ???? ??? ???? ????????? ??? ???? ???? ??? ??? ???? ????? ????? ??? ??? ??? ??? ??? ???? ??? ??? ???? ???? ??? ??? ???? ???? ???? ??? ???? ????? ??? ???? ??? ??? ??? ??? ??? ??? ??? ???? ??? ???? ???? ??? ???? ???? ??? ??? ??? ????? ???? ??? ???? ????? ??? ???? ??? ??? ???? ??? ??? ???? ???? ???"? ??? ??? ??? ??? ??? ?"??? ??? ??? ??? ???? ??? ??? ??? ????? ??? ??? ??? ??? ??? ???? ??? ??? ????? ??? ??? ??? ??? ???? ??? ??? ???? ??? ??? ???? ????? ??? ???? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???? ????? ???? ??? ??? ???? ? ??? ???? ??? ???? ? ??? ???? ???? ? ? ??? ????? ??? ??? ???? ??? ???? ???? ??? ???? ??? ??? ????? ??? ??? ??? ???? ????? ???? ???? ???? ??? ??? ????? ???? ??? ???? ??? ??? ???? ??? ??? ??? ??? ??? ???? ????? ??? ???? ??? ???? ??? ??? ??? ??? ??? ???? ??? ??? ??? ????? ??? ????? ????? ???? ????? ??? ??? ??? ??? ??? ??? ???? ???? ????? ???? ??? ??? ??? ??? ??? ??? ????? ??? ??? ??? ??? ??? ???? ??? ??? ??? ????? ??? ???? ??? ??? ??? ??? ???? ??? ??? ??? ??? ??? ??? ??? ??? ???? ??? ??? ??? ??? ???? ??? ??? ??? ??? ??? ??? ????? ??? ??? ???? ??? ??? ???? ??? ??? ??? ??? ??? ???? ??? ??? ??? ??? ???? ???? ????? ??? ???? ????? ???? ???? ??? ????? ???? ??? ??? ??? ??? ????? ??? ????? ??? ???? ??? ??? ??? ??? ??? ???? ????? ??? ???? ??? ????? ??? ??? ??? ??????? ??? ???? ???? ???? ??? ??? ??? ??? ??? ???? ???? ??? ??? ??? ??? ??? ??? ????? ??? ??? ??? ??? ??? ???? ???? ????? ??? ??? ??? ??? ???? ???? ??? ???? ??? ??? ????? ??? ?????? ??? ??? ??? ??? ??? ????? ???? ??? ??? ??? ??? ??? ??? ???? ???? ??? ??? ????? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???? ??? ???? ??? ??? ??? ??? ???? ??? ??? ??? ??? ???? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???? ?????? ??? ??? ???? ??? ???? ???? ?????? ??? ??? ??? ??? ????? ???? ??? ??? ??? ???? ??? ??? ??? ??? ???? ??? ???? ???? ???? ??? ????? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???? ???? ??? ????? ???? ??? ??? ???? ??? ???? ????</figDesc><table><row><cell>Analyse</cell><cell>Dividing document</cell><cell></cell></row><row><cell></cell><cell>into its constituent parts to identify how</cell><cell></cell><cell>Urdu</cell></row><row><cell cols="3">English Beyonc? took a hiatus from music in 2010 and parts are related to each other and</cell><cell>Urdu Translation</cell></row><row><cell cols="4">Type1:Exact Match P:Ghulam Ishaq Khan Bangash (February 22, 1915 -October 27, 2006) was a former President of Pakistan. He served in government positions long before he entered politics. He was born into a Pashtun family in Ismail Khel, a village in Bannu District. He belonged to the Bangash tribe of Pashtuns. After his primary education, he graduated from Peshawar with a degree in Chemistry and Botany. Joined the Indian Civil Service in 1940 ??? ???? ??? A: Services in government positions ???? ???? ????? 2002 ??)? ???? ??? ???? ??? ??? ???? ??? ??? ??? ??????? ????? ????? ???? ??? ??? ???? ??? 22 ???? ??? ???? ??? ??? ??? ??????? ??? 9191 ??? ??? ??? ????? ??? ??? 22 ( ???? ??? ??? ??? ??? ????? ??? ??? ????? ??? ????? ??? ??? ??? ??? ???? ??? ???? ??? ??? ??? ????? ??? ???? ???? ??? ??? ??? ???? ???? ???? ??? ??? ??? ???? ???? ??? ??? ???? ???? ??? ??? ??? ??????? ????? ????? Type2: Synonymy Matching P: Beyonc? is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she done in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyonc?'s debut album, Dangerously in Love (2003), which proven her as a solo artist worldwide, received five Grammy Awards and featured the Billboard Hot 100 number-one singles "Crazy in Love" and "Baby Boy". ???? ???? ??? took over management of her career; her fourth album 4 (2011) was subsequently mellower in tone, exploring 1970s funk, 1980s pop, and 1990s soul. Her critically acclaimed fifth studio album, Beyonc? (2013), was distinguished from previous releases by its experimental production and exploration of darker themes. A: Dreamgirls ???? ??? ??? Remember overall material and Recalling factual information from long term memory like dates, event etc. ? ???? ???? ? ???? ?????? ????? ??? ???? ???? ??? ??? ??? ??? ???? ???? ??? ??? ??? ??? ??? ?????? ??? ???????? ???? its purpose. Evaluate Judging, critiquing and checking according to certain criteria. ???? ??? Understand Interpret the instructional messages like oral, written, and graphical. ??????? ??? ????? ??? ??? ????? ??? ??? ??? ??? ??? ? ???? ??? ??? ?????? ??? ??? ????? ??? ??? ??? ???? ????? ???? ??????? ???? ???? ??? ??? ??? ????? ???? ??? ???? ???? ??? ??? ????? ??? ????? ???? Implementing or in real life scenario. ???? ??? ??? ???? ??? ????? ??? ??? executing procedures ???? ????? ???? ???? ???? Create Combining element to generate novel coherent whole or producing an original ???? ??? Apply product.</cell></row><row><cell cols="2">Type3: Unpreserved Span</cell><cell cols="2">? ???? ???? ??? ????? ??? ??? ? ??? ????</cell></row><row><cell cols="4">P: Following the disbandment of Destiny's Child ???? ??? ???? ???? in June 2005, she released her second solo album, B'Day (2006), which contained hits "D?j? Vu", ???? ???? ???? ??? ?????? ??? ???</cell><cell>01 20</cell><cell>???? ???</cell></row><row><cell cols="3">"Irreplaceable", and "Beautiful Liar". Beyonc?</cell></row><row><cell cols="3">also ventured into acting, with a Golden Globe-</cell></row><row><cell cols="3">nominated performance in Dreamgirls (2006), and</cell></row><row><cell cols="3">starring roles in The Pink Panther (2006) and</cell></row><row><cell cols="3">Obsessed (2009). Her marriage to rapper Jay Z</cell></row><row><cell cols="3">and portrayal of Etta James in Cadillac Records</cell></row><row><cell cols="3">(2008) influenced her third album, I Am... Sasha</cell></row></table><note>Q:???? ??? ??? ??? ??? ???? ??? ??? ??? ??? ? ??? ??? ??? ??? ??? ??? ???? ??? ??? ????? ?????? ????? ?????? ??? ????? ??? ???? ????? ? ???? ??? ??? ???? ??? ??? ? ???? ????? ??? ???? ??? ????? ??? ???? ???? ??? ???? ??? ????? ???? ??? ??? ??? ??? ???Q:??</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to acknowledge their crowd-working and translation team for their work on the UQuAD1.0 dataset. The authors would also like to thank Dr. Hassan Sajjad, Hamza Lebbar, Furqan Shaikh, and the anonymous reviewers for their feedback and comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C Qualitative results of the top-performing model on different question groups</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">&apos;am i not answering your questions properly?&apos;clarification, adequacy and responsiveness in semi-structured telephone and face-toface interviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Drew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sainsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Qualitative research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="106" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Transfer learning for low-resource neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.02201</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Arabic preprocessing schemes for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sadat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers</title>
		<meeting>the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="49" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Urdu language processing: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Daud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Che</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="279" to="311" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.03551</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Parikh</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="466" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ms Marco: A human-generated machine reading comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ma-Jumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoCo@ NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">On the cross-lingual transferability of monolingual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.11856</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sberquad-Russian reading comprehension dataset: Description and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Efimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chertok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Boytsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Braslavski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Beyond English-only reading comprehension: Experiments in zero-shot multi-lingual transfer for Bulgarian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardalov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Koychev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.01519</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Construction of high-quality Tibetan dataset for machine-reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Chinese National Conference on Computational Linguistics</title>
		<meeting>the 20th Chinese National Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="208" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mozannar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Hajal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Maamary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajj</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05394</idno>
		<title level="m">Neural Arabic question answering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural learning for question answering in Italian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zelenanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Italian Association for Artificial Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="389" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Fquad: French question answering dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hoffschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Belblidia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brendl?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vidal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hindirc: A dataset for reading comprehension in Hindi</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Anuranjana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mamidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">0th International Conference on Computational Linguistics and Intelligent Text</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A deep neural network framework for English Hindi question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ekbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">cloze procedure&quot;: A new tool for measuring readability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journalism Quarterly</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="415" to="433" />
			<date type="published" when="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mctest: A challenge dataset for the opendomain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="193" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wen-Zek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Guzm?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02116</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Huggingface&apos;s transformers: State-ofthe-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
