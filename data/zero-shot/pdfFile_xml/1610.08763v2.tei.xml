<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CoType: Joint Extraction of Typed Entities and Relations with Knowledge Bases</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeqiu</forename><surname>Wu</surname></persName>
							<email>zeqiuwu1@illinois.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>He</surname></persName>
							<email>wenqihe3@illinois.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
							<email>mengqu2@illinois.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><forename type="middle">R</forename><surname>Voss</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Computational &amp; Information Sciences Directorate</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="laboratory">Army Research Laboratory</orgName>
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
								<address>
									<settlement>Adelphi</settlement>
									<region>MD</region>
									<country>USA, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Heng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Tarek</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Abdelzaher</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
							<email>hanj@illinois.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CoType: Joint Extraction of Typed Entities and Relations with Knowledge Bases</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3038912.3052708</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Extracting entities and relations for types of interest from text is important for understanding massive text corpora. Traditionally, systems of entity relation extraction have relied on human-annotated corpora for training and adopted an incremental pipeline. Such systems require additional human expertise to be ported to a new domain, and are vulnerable to errors cascading down the pipeline. In this paper, we investigate joint extraction of typed entities and relations with labeled data heuristically obtained from knowledge bases (i.e., distant supervision). As our algorithm for type labeling via distant supervision is context-agnostic, noisy training data poses unique challenges for the task. We propose a novel domainindependent framework, called COTYPE, that runs a data-driven text segmentation algorithm to extract entity mentions, and jointly embeds entity mentions, relation mentions, text features and type labels into two low-dimensional spaces (for entity and relation mentions respectively), where, in each space, objects whose types are close will also have similar representations. COTYPE, then using these learned embeddings, estimates the types of test (unlinkable) mentions. We formulate a joint optimization problem to learn embeddings from text corpora and knowledge bases, adopting a novel partial-label loss function for noisy labeled data and introducing an object "translation" function to capture the cross-constraints of entities and relations on each other. Experiments on three public datasets demonstrate the effectiveness of COTYPE across different domains (e.g., news, biomedical), with an average of 25% improvement in F1 score compared to the next best method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The extraction of entities and their relations is critical to understanding massive text corpora. Identifying the token spans in text that constitute entity mentions and assigning types (e.g., <ref type="bibr">person, company)</ref> to these spans as well as to the relations between entity mentions (e.g., employed_by) are key to structuring content from text corpora for further analytics. For example, when an extraction system finds a "produce" relation between "company" and "product" entities in news articles, it supports answering ques- <ref type="figure" target="#fig_6">Figure 1</ref>: Current systems find relations (Barack Obama, United States) mentioned in sentences S1-S3 and assign the same relation types (entity types) to all relation mentions (entity mentions), when only some types are correct for context (highlighted in blue font).</p><p>tions like "what products does company X produce?". Once extracted, such structured information is used in many ways, e.g., as primitives in information extraction, knowledge base population <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b51">52]</ref>, and question-answering systems <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b2">3]</ref>. Traditional systems for relation extraction <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b16">17]</ref> partition the process into several subtasks and solve them incrementally (i.e., detecting entities from text, labeling their types and then extracting their relations). Such systems treat the subtasks independently and so may propagate errors across subtasks in the process. Recent studies <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b43">44]</ref> focus on joint extraction methods to capture the inhereent linguistic dependencies between relations and entity arguments (e.g., the types of entity arguments help determine their relation type, and vice versa) to resolve error propagation.</p><p>A major challenge in joint extraction of typed entities and relations is to design domain-independent systems that will apply to text corpora from different domains in the absence of humanannotated, domain data. The process of manually labeling a training set with a large number of entity and relation types is too expensive and error-prone. The rapid emergence of large, domainspecific text corpora (e.g., news, scientific publications, social media content) calls for methods that can jointly extract entities and relations of target types with minimal or no human supervision.</p><p>Towards this goal, there are broadly two kinds of efforts: weak supervision and distant supervision. Weak supervision <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b12">13]</ref> relies on a small set of manually-specified seed instances (or patterns) that are applied in bootstrapping learning to identify more instances of each type. This assumes seeds are unambiguous and sufficiently frequent in the corpus, which requires careful seed se-arXiv:1610.08763v2 [cs.CL] 2 Jun 2017 Dataset NYT <ref type="bibr" target="#b42">[43]</ref> Wiki-KBP <ref type="bibr" target="#b11">[12]</ref>, BioInfer <ref type="bibr" target="#b38">[39]</ref> # of entity  <ref type="table" target="#tab_7">Table 1</ref>: A study of type label noise. <ref type="bibr" target="#b0">(1)</ref>: %entity mentions with multiple sibling entity types (e.g., actor, singer) in the given entity type hierarchy; <ref type="bibr" target="#b1">(2)</ref>: %relation mentions with multiple relation types, for the three experiment datasets. lection by human <ref type="bibr" target="#b1">[2]</ref>. Distant supervision <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b48">49]</ref> generates training data automatically by aligning texts and a knowledge base (KB) (see <ref type="figure" target="#fig_6">Fig. 1</ref>). The typical workflow is: (1) detect entity mentions in text; <ref type="bibr" target="#b1">(2)</ref> map detected entity mentions to entities in KB;</p><p>(3) assign, to the candidate type set of each entity mention, all KB types of its KB-mapped entity; (4) assign, to the candidate type set of each entity mention pair, all KB relation types between their KB-mapped entities. The automatically labeled training corpus is then used to infer types of the remaining candidate entity mentions and relation mentions (i.e., unlinkable candidate mentions).</p><p>In this paper, we study the problem of joint extraction of typed entities and relations with distant supervision. Given a domainspecific corpus and a set of target entity and relation types from a KB, we aim to detect relation mentions (together with their entity arguments) from text, and categorize each in context by target types or Not-Target-Type (None), with distant supervision. Current distant supervision methods focus on solving the subtasks separately (e.g., extracting typed entities or relations), and encounter the following limitations when handling the joint extraction task. ? Domain Restriction: They rely on pre-trained named entity recognizers (or noun phrase chunker) to detect entity mentions. These tools are usually designed for a few general types (e.g., person, location, organization) and require additional human labors to work on specific domains (e.g., scientific publications). ? Error Propagation: In current extraction pipelines, incorrect entity types generated in entity recognition and typing step serve as features in the relation extraction step (i.e., errors are propagated from upstream components to downstream ones). Cross-task dependencies are ignored in most existing methods. ? Label Noise: In distant supervision, the context-agnostic mapping from relation (entity) mentions to KB relations (entities) may bring false positive type labels (i.e., label noise) into the automatically labeled training corpora and results in inaccurate models.</p><p>In <ref type="figure" target="#fig_6">Fig. 1</ref>, for example, all KB relations between entities Barack Obama and United States (e.g., born_in, president_of) are assigned to the relation mention in sentence S1 (while only born_in is correct within the context). Similarly, all KB types for Barack Obama (e.g., politician, artist) are assigned to the mention "Obama" in S1 (while only person is true). Label noise becomes an impediment to learn effective type classifiers. The larger the target type set, the more severe the degree of label noise (see <ref type="table" target="#tab_7">Table 1</ref>).</p><p>We approach the joint extraction task as follows: (1) Design a domain-agnostic text segmentation algorithm to detect candidate entity mentions with distant supervision and minimal linguistic assumption (i.e., assuming part-of-speech (POS) tagged corpus is given <ref type="bibr" target="#b21">[22]</ref>). (2) Model the mutual constraints between the types of the relation mentions and the types of their entity arguments, to enable feedbacks between the two subtasks. (3) Model the true type labels in a candidate type set as latent variables and require only the "best" type (progressively estimated as we learn the model) to be relevant to the mention-this is a less limiting requirement compared with existing multi-label classifiers that assume "every" candidate type is relevant to the mention.</p><p>To integrate these elements of our approach, a novel framework, COTYPE, is proposed. It first runs POS-constrained text segmentation using positive examples from KB to mine quality entity men-tions, and forms candidate relation mentions (Sec. 3.1). Then CO-TYPE performs entity linking to map candidate relation (entity) mentions to KB relations (entities) and obtain the KB types. We formulate a global objective to jointly model (1) corpus-level cooccurrences between linkable relation (entity) mentions and text features extracted from their local contexts; (2) associations between mentions and their KB-mapped type labels; and (3) interactions between relation mentions and their entity arguments. In particular, we design a novel partial-label loss to model the noisy mention-label associations in a robust way, and adopt translationbased objective to capture the entity-relation interactions. Minimizing the objective yields two low-dimensional spaces (for entity and relation mentions, respectively), where, in each space, objects whose types are semantically close also have similar representation (see Sec. 3.2). With the learned embeddings, we can efficiently estimate the types for the remaining unlinkable relation mentions and their entity arguments (see Sec. 3.3).</p><p>The major contributions of this paper are as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND AND PROBLEM</head><p>The input to our proposed COTYPE framework is a POS-tagged text corpus D, a knowledge bases ? (e.g., Freebase <ref type="bibr" target="#b3">[4]</ref>), a target entity type hierarchy Y and a target relation type set R. The target type set Y (set R) covers a subset of entity (relation) types that the users are interested in from ?, i.e., Y ? Y ? and R ? R ? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity and Relation</head><p>Mention. An entity mention (denoted by m) is a token span in text which represents an entity e. A relation instance r(e 1 , e 2 , . . . , en) denotes some type of relation r ? R between multiple entities. In this work, we focus on binary relations, i.e., r(e1, e2). We define a relation mention (denoted by z) for some relation instance r(e 1 , e 2 ) as a (ordered) pair of entities mentions of e1 and e2 in a sentence s, and represent a relation mention with entity mentions m1 and m2 in sentence s as z = (m 1 , m 2 , s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge Bases and Target Types. A KB with a set of entities E ? contains human-curated facts on both relation instances</head><formula xml:id="formula_0">I ? = {r(e 1 , e 2 )} ? R ? ?E ? ? E ? , and entity-type facts T ? = {(e, y)} ? E ? ? Y ? .</formula><p>Target entity type hierarchy is a tree where nodes represent entity types of interests from the set Y ? . An entity mention may have multiple types, which together constitute one type-path (not required to end at a leaf) in the given type hierarchy. In existing studies, several entity type hierarchies are manually constructed using Freebase <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b14">15]</ref> or WordNet <ref type="bibr" target="#b54">[55]</ref>. Target relation type set is a set of relation types of interests from the set R ? .</p><p>Automatically Labeled Training Data. Let M = {m i } N i=1 denote the set of entity mentions extracted from corpus D. Distant supervision maps M to KB entities E ? with an entity disambiguation system <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b19">20]</ref> and heuristically assign type labels to the mapped mentions. In practice, only a small number of entity mentions in set M can be mapped to entities in E ? (i.e., linkable entity mentions, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Barack Obama is the 44th and current President of the United States</head><p>Presi dent Clinton and Obama at tended the funeral of former Israeli Prime Mi ni ster, and were scheduled t o fl y back to the US together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Corpus</head><p>Automatically Labeled Training Data Relation Mention: ("Barack Obama", "US", S1)  denoted by M L ). As reported in <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b24">25]</ref>, the ratios of M L over M are usually lower than 50% in domain-specific corpora. Between any two linkable entity mentions m1 and m2 in a sentence, a relation mention zi is formed if there exists one or more KB relations between their KB-mapped entities e1 and e2. Relations between e1 and e2 in KB are then associated to zi to form its candidate relation type set R i , i.e., R i = {r | r(e 1 , e 2 ) ? R ? }. In a similar way, types of e1 and e2 in KB are associated with m1 and m2 respectively, to form their candidate entity type sets Y i,1 and</p><formula xml:id="formula_1">Y i,2 , where Y i,x = {y | (ex, y) ? Y ? }. Let Z L = {z i } N L i=1</formula><p>denote the set of extracted relation mentions that can be mapped to KB. Formally, we represent the automatically labeled training corpus for the joint extraction task, denoted as D L , using a set of tuples</p><formula xml:id="formula_2">D L = {(z i , R i , Y i,1 , Y i,2 )} N L i=1</formula><p>. Problem Description. By pairing up entity mentions (from set M) within each sentence in D, we generate a set of candidate relation mentions, denoted as Z. Set Z consists of (1) linkable relation mentions Z L , (2) unlinkable (true) relation mentions, and (3) false relation mention (i.e., no target relation expressed between).</p><p>Let Z U denote the set of unlabeled relation mentions in (2) and (3) (i.e., Z U = Z \ Z L ). Our main task is to determine the relation type label (from the set R ?{None}) for each relation mention in set Z U , and the entity type labels (either a single type-path in Y or None) for each entity mention argument in z ? Z U , using the automatically labeled corpus D L . Formally, we define the joint extraction of typed entities and relations task as follows. DEFINITION 1 (PROBLEM DEFINITION). Given a POS-tagged corpus D, a KB ?, a target entity type hierarchy Y ? Y ? and a target relation type set R ? R ? , the joint extraction task aims to (1) detect entity mentions M from D; (2) generate training data D L with KB ?; and (3) estimate a relation type r * ? R ?{None} for each test relation mention z ? Z U and a single type-path Y * ? Y (or None) for each entity mention in z, using D L and its context s.</p><p>Non-goals. This work relies on an entity linking system <ref type="bibr" target="#b28">[29]</ref> to provide disambiguation function, but we do not address their limits here (e.g., label noise introduced by wrongly mapped KB entities). We also assume human-curated target type hierarchies are given (It is out of the scope of this study to generate the type hierarchy).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE COTYPE FRAMEWORK</head><p>This section lays out the proposed framework. The joint extraction task poses two unique challenges. First, type association in distant supervision between linkable entity (relation) mentions and their KB-mapped entities (relations) is context-agnostic-the candidate type sets {R i , Y i,1 , Y i,2 } contain "false" types. Supervised learning <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b15">16]</ref> may generate models biased to the incorrect type labels <ref type="bibr" target="#b41">[42]</ref>. Second, there exists dependencies between relation mentions and their entity arguments (e.g., type correlation). Current systems formulates the task as a cascading supervised learning problem and may suffer from error propagation.</p><p>Our solution casts the type prediction task as weakly-supervised learning (to model the relatedness between mentions and their candidate types in contexts) and uses relational learning to capture interactions between relation mentions and their entity mention argument jointly, based on the redundant text signals in a large corpus.</p><p>Specifically, COTYPE leverages partial-label learning <ref type="bibr" target="#b36">[37]</ref> to faithfully model mention-type association using text features extracted from mentions' local contexts. It uses the translation embeddingbased objective <ref type="bibr" target="#b4">[5]</ref> to model the mutual type dependencies between relation mentions and their entity (mention) arguments.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Candidate Generation</head><p>Entity Mention Detection. Traditional entity recognition systems <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b33">34]</ref> rely on a set of linguistic features (e.g., dependency parse structures of a sentence) to train sequence labeling models (for a few common entity types). However, sequence labeling models trained on automatically labeled corpus D L may not be effective, as distant supervision only annotates a small number of entity mentions in D L (thus generates a lot of "false negative" token tags). To address domain restriction, we develop a distantly-supervised text segmentation algorithm for domain-agnostic entity detection. By using quality examples from KB as guidance, it partitions sentences into segments of entity mentions and words, by incorporating <ref type="formula">(1)</ref> corpus-level concordance statistics; (2) sentence-level lexical signals; and (3) grammatical constraints (i.e., POS tag patterns). We extend the methdology used in <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b10">11]</ref> to model the segment quality (i.e., "how likely a candidate segment is an entity mention")  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>NYT Wiki-KBP BioInfer FIGER segmenter <ref type="bibr" target="#b25">[26]</ref> 0.751 0.814 0.652 Our Approach 0.837 0.833 0.785 <ref type="table">Table 2</ref>: Comparison of F1 scores on entity mention detection.</p><p>as a combination of phrase quality and POS pattern quality, and use positive examples in D L to estimate the segment quality. The workflow is as follows: (1) mine frequent contiguous patterns for both word sequence and POS tag sequence up to a fixed length from POS-tagged corpus D; (2) extract features including corpuslevel concordance and sentence-level lexical signals to train two random forest classifiers <ref type="bibr" target="#b26">[27]</ref>, for estimating quality of candidate phrase and candidate POS pattern; (3) find the best segmentation of D using the estimated segment quality scores (see Eq. <ref type="formula">(1)</ref>); and <ref type="formula" target="#formula_9">(4)</ref> compute rectified features using the segmented corpus and repeat steps (2)-(4) until the result converges.</p><formula xml:id="formula_3">p bt+1, c | bt = p bt+1 ? bt ? p c | bt+1 ? bt ? Q(c) (1)</formula><p>Specifically, we find the best segmentation S d for each document d (in D) by maximizing the "joint segmentation quality", de-</p><formula xml:id="formula_4">fined as D d log p(S d , d) = D d |d| t=1 log p b (d) t+1 , c (d) | b (d) t , where p b (d) t+1 , c (d) | b (d) t denote the probability that segment c (c) (with starting index b (d)</formula><p>t+1 and ending index in document d) is a good entity mention, as defined in Eq. (1). The first term in Eq. (1) is a segment length prior, the second term measures how likely segment c is generated given a length (b t+1 ? bt) (to be estimated), and the third term denotes the segment quality. In this work, we define function Q(c) as the equally weighted combination of the phrase quality score and POS pattern quality score for candidate segment c, which is estimated in step <ref type="bibr" target="#b1">(2)</ref>. The joint probability can be efficiently maximize using Viterbi Training with time complexity linear to the corpus size <ref type="bibr" target="#b26">[27]</ref>. The segmentation result provides us a set of candidate entity mentions, forming the set M. <ref type="table">Table 2</ref> compares our entity detection module with a sequence labeling model <ref type="bibr" target="#b25">[26]</ref> (linear-chain CRF) trained on the labeled corpus D L in terms of F1 score. <ref type="figure" target="#fig_2">Fig. 3</ref> show the high/low quality POS patterns learned using entity names found in D L as examples. Relation Mention Generation. We follow the procedure introduced in Sec. 2 to generate the set of candidate relation mentions Z from the detected candidate entity mentions M: for each pair of entity mentions (ma, m b ) found in sentence s, we form two candidate relation mentions z 1 = (ma, m b , s) and z 2 = (m b , ma, s). Distant supervision is then applied on Z to generate the set of KBmapped relation mentions Z L . Similar to <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b20">21]</ref>, we sample 30% unlinkable relation mentions between two KB-mapped entity mentions (from set M L ) in a sentence as examples for modeling None relation label, and sample 30% unlinkable entity mentions (from set M \ M L ) to model None entity label. These negative examples, together with type labels for mentions in Z L , form the automatically labeled data D L for the task. Text Feature Extraction. To capture the shallow syntax and distributional semantics of a relation (or entity) mention, we extract various lexical features from both mention itself (e.g., head token) and its context s (e.g., bigram), in the POS-tagged corpus. <ref type="table" target="#tab_6">Table 3</ref> Feature Description Example Entity mention (EM) head Syntactic head token of each entity mention "HEAD_EM1_Obama" Entity Mention Token Tokens in each entity mention "TKN_EM1_Barack" Tokens between two EMs Each token between two EMs "was", "elected", "President", "of ", "the" Part-of-speech (POS) tag POS tags of tokens between two EMs "VBD", "VBN", "NNP", "IN", "DT" Collocations Bigrams in left/right 3-word window of each EM "Honolulu native", "native Barack", ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity mention order</head><p>Whether EM 1 is before EM 2 "EM1_BEFORE_EM2" Entity mention distance Number of tokens between the two EMs "EM_DISTANCE_5" Entity mention context Unigrams before and after each EM "native", "was", "the", "in" Special pattern Occurrence of pattern "em1_in_em2" "PATTERN_NULL" Brown cluster (learned on D)</p><p>Brown cluster ID for each token "8_1101111", "12_111011111111" lists the set of text features for relation mention, which is similar to those used in <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b6">7]</ref> (excluding the dependency parse-based features and entity type features). We use the same set of features for entity mentions as those used in <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b25">26]</ref>. We denote the set of</p><formula xml:id="formula_5">Mz (Mm) unique features extracted of relation mentions Z L (entity mentions in Z L ) as Fz = {f j } Mz j=1 and Fm = {f j } Mm j=1 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Joint Entity and Relation Embedding</head><p>This section formulates a joint optimization problem for embedding different kinds of interactions between linkable relation mentions Z L , linkable entity mentions M L , entity and relation type labels {R, Y} and text features {Fz, Fm} into a d-dimensional relation vector space and a d-dimensional entity vector space. In each space, objects whose types are close to each other should have similar representation (e.g., see the 3rd col. in <ref type="figure" target="#fig_0">Fig. 2</ref>).</p><p>As the extracted objects and the interactions between them form a heterogeneous graph (see the 2nd col. in <ref type="figure" target="#fig_0">Fig. 2</ref>), a simple solution is to embed the whole graph into a single low-dimensional space <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b40">41]</ref>. However, such a solution encounters several problems: (1) False types in candidate type sets (i.e., false mention-type links in the graph) negatively impact the ability of the model to determine mention's true types; and (2) a single embedding space cannot capture the differences in entity and relation types (i.e., strong link between a relation mention and its entity mention argument does not imply that they have similar types).</p><p>In our solution, we propose a novel global objective, which extends a margin-based rank loss <ref type="bibr" target="#b36">[37]</ref> to model noisy mention-type associations and leverages the second-order proximity idea <ref type="bibr" target="#b49">[50]</ref> to model corpus-level mention-feature co-occurrences. In particular, to capture the entity-relation interactions, we adopt a translationbased embedding loss <ref type="bibr" target="#b4">[5]</ref> to bridge the vector spaces of entity mentions and relation mentions.</p><p>Modeling Types of Relation Mentions. We consider both mentionfeature co-occurrences and mention-type associations in the modeling of relation types for relation mentions in set Z L .</p><p>Intuitively, two relation mentions sharing many text features (i.e., with similar distribution over the set of text features Fm) likely have similar relation types; and text features co-occurring with many relation mentions in the corpus tend to represent close type semantics. We propose the following hypothesis to guide our modeling of corpus-level mention-feature co-occurrences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HYPOTHESIS 1 (MENTION-FEATURE CO-OCCURRENCE).</head><p>Two entity mentions tend to share similar types (close to each other in the embedding space) if they share many text features in the corpus, and the converse way also holds.</p><p>For example, in column 2 of <ref type="figure" target="#fig_0">Fig. 2</ref>, ("Barack Obama", "US", S1) and ("Barack Obama", "United States", S3) share multiple features including context word "president" and first entity mention argument "Barack Obama", and thus they are likely of the same relation type (i.e., president_of).</p><p>Formally, let vectors z i , c j ? R d represent relation mention z i ? Z L and text feature f j ? Fz in the d-dimensional relation embedding space. Similar to the distributional hypothesis <ref type="bibr" target="#b29">[30]</ref> in text corpora, we apply second-order proximity <ref type="bibr" target="#b49">[50]</ref> to model the idea that objects with similar distribution over neighbors are similar to each other as follows.</p><formula xml:id="formula_6">LZF = ? z i ?Z L f j ?Fz wij ? log p(fj|zi),<label>(2)</label></formula><p>where</p><formula xml:id="formula_7">p(f j |z i ) = exp(z T i c j ) f ?Fz exp(z T i c j )</formula><p>denotes the probability of f j generated by z i , and w ij is the co-occurrence frequency between (z i , f j ) in corpus D. Function L ZF in Eq. (2) enforces the conditional probability specified by embeddings, i.e., p(?|z i ) to be close to the empirical distribution.</p><p>To perform efficient optimization by avoiding summation over all features, we adopt negative sampling strategy <ref type="bibr" target="#b29">[30]</ref> to sample multiple false features for each (z i , f j ), according to some noise distribution Pn(f ) ? D 3/4 f <ref type="bibr" target="#b29">[30]</ref> (with D f denotes the number of relation mentions co-occurring with f ). Term log p(f j |z i ) in Eq. <ref type="formula" target="#formula_6">(2)</ref> is replaced with the term as follows.</p><formula xml:id="formula_8">log ?(z T i cj) + V v=1 E f j ?Pn(f ) log ?(?z T i c j ) ,<label>(3)</label></formula><p>where ?(x) = 1/ 1 + exp(?x) is the sigmoid function. The first term in Eq. (3) models the observed co-occurrence, and the second term models the Z negative feature samples. In D L , each relation mention z i is heuristically associated with a set of candidate types R i . Existing embedding methods rely on either the local consistent assumption <ref type="bibr" target="#b18">[19]</ref> (i.e., objects strongly connected tend to be similar) or the distributional assumption <ref type="bibr" target="#b29">[30]</ref> (i.e., objects sharing similar neighbors tend to be similar) to model object associations. However, some associations between z i and r ? R i are "false" associations and adopting the above assumptions may incorrectly yield mentions of different types having similar vector representations. For example, in <ref type="figure" target="#fig_6">Fig. 1</ref>, mentions ("Obama", "USA", S1) and ("Obama", "US", S2) have several candidate types in common (thus high distributional similarity), but their true types are different (i.e., born_in vs. travel_to).</p><p>We specify the likelihood of "whether the association between a relation mention and its candidate entity type being true" as the relevance between these two kinds of objects (measured by the similarity between their current estimated embedding vectors). To impose such idea, we model the associations between each linkable relation mention z i (in set Z L ) and its noisy candidate relation type set R i based on the following hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HYPOTHESIS 2 (PARTIAL-LABEL ASSOCIATION).</head><p>A relation mention's embedding vector should be more similar (closer in the low-dimensional space) to its "most relevant" candidate type, than to any other non-candidate type.</p><p>Specifically, we use vector r k ? R d to represent relation type r k ? R in the embedding space. The similarity between (z i , r k ) is defined as the dot product of their embedding vectors, i.e., ?(z i , r k ) = z T i r k . We extend the margin-based loss in <ref type="bibr" target="#b36">[37]</ref> and define a partiallabel loss i for each relation mention z i ? M L as follows.</p><formula xml:id="formula_9">i = max 0, 1 ? max r?R i ?(zi, r) ? max r ?R i ?(zi, r ) .<label>(4)</label></formula><p>The intuition behind Eq. (4) is that: for relation mention z i , the maximum similarity score associated with its candidate type set R i should be greater than the maximum similarity score associated with any other non-candidate types R i = R \ R i . Minimizing i forces z i to be embedded closer to the most "relevant" type in R i , than to any other non-candidate types in R i . This contrasts sharply with multi-label learning <ref type="bibr" target="#b25">[26]</ref>, where m i is embedded closer to every candidate type than any other non-candidate type. To faithfully model the types of relation mentions, we integrate the modeling of mention-feature co-occurrences and mention-type associations by the following objective.</p><formula xml:id="formula_10">OZ = LZF + N L i=1 i + ? 2 N L i=1 zi 2 2 + ? 2 Kr k=1 r k 2 2 ,<label>(5)</label></formula><p>where tuning parameter ? &gt; 0 on the regularization terms is used to control the scale of the embedding vectors. By doing so, text features, as complements to mention's candidate types, also participate in modeling the relation mention embeddings, and help identify a mention's most relevant type-mentiontype relevance is progressively estimated during model learning. For example, in the left column of <ref type="figure" target="#fig_3">Fig. 4</ref>, context words "president"helps infer that relation type president_of is more relevant (i.e., higher similarity between the embedding vectors) to relation mention ("Mr. Obama", "USA", S2), than type born_in does.</p><p>Modeling Types of Entity Mentions. In a way similar to the modeling of types for relation mentions, we follow Hypotheses 1 and 2 to model types of entity mentions. In <ref type="figure" target="#fig_0">Fig. 2 (col. 2)</ref>, for example, entity mentions "S1_Barack Obama" and "S3_Barack Obama" share multiple text features in the corpus, including head token "Obama" and context word "president", and thus tend to share the same entity types like politician and person (i.e., Hypothesis 1). Meanwhile, entity mentions "S1_Barack Obama" and "S2_Obama" have the same candidate entity types but share very few text features in common. This implies that likely their true type labels are different. Relevance between entity mentions and their true type labels should be progressively estimated based on the text features extracted from their local contexts (i.e., Hypothesis 2).</p><p>Formally, let vectors m i , c j , y k ? R d represent entity mention m i ? M L , text features (for entity mentions) f j ? Fm, and entity type y k ? Y in a d-dimensional entity embedding space, respectively. We model the corpus-level co-occurrences between entity mentions and text features by second-order proximity as follows.</p><formula xml:id="formula_11">LMF = ? m i ?M L f j ?Fm wij ? log p(fj|mi),<label>(6)</label></formula><p>where the conditional probability term log p(f j |m i ) is defined as</p><formula xml:id="formula_12">log p(f j |m i ) = log ?(m T i c j )+ V v=1 E f j ?Pn(f ) log ?(?m T i c j )</formula><p>. By integrating the term L M F with partial-label loss i = max 0, 1? max y?Y i ?(m i , y) ? max y ?Y i ?(m i , y ) for N L unique linkable entity mentions (in set M L ), we define the objective function for modeling types of entity mentions as follows.</p><formula xml:id="formula_13">OM = LMF + N L i=1 i + ? 2 N L i=1 mi 2 2 + ? 2 Ky k=1 y k 2 2 .<label>(7)</label></formula><p>Minimizing the objective O M yields an entity embedding space where, in that space, objects (e.g., entity mentions, text features) close to each other will have similar types.</p><p>Modeling Entity-Relation Interactions. In reality, there exists different kinds of interactions between a relation mention z = (m 1 , m 2 , s) and its entity mention arguments m 1 and m 2 . One major kind of interactions is the correlation between relation and entity types of these objects-entity types of the two entity mentions provide good hints for determining the relation type of the relation mention, and vice versa. For example, in <ref type="figure" target="#fig_3">Fig. 4 (right column)</ref>, knowing that entity mention "S4_US" is of type location (instead of organization) helps determine that relation mention ("Obama", "US", S4) is more likely of relation type travel_to, rather than relation types like president_of or citizen_of. Intuitively, entity types of the entity mention arguments pose constraints on the search space for the relation types of the relation mention (e.g., it is unlikely to find a author_of relation between a organization entity and a location entity). The proposed Hypotheses 1 and 2 model types of relation mentions and entity mentions by learning an entity embedding space and a relation embedding space, respectively. The correlations between entity and relation types (and their embedding spaces) motivates us to model entity-relation interactions based on the following hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HYPOTHESIS 3 (ENTITY-RELATION INTERACTION).</head><p>For a relation mention z = (m1, m2, s), embedding vector of m1 should be a nearest neighbor of the embedding vector of m2 plus the embedding vector of relation mention z.</p><p>Given the embedding vectors of any two members in {z, m 1 , m 2 }, say z and m 1 , Hypothesis 3 forces the "m 1 + z ? m 2 ". This helps regularize the learning of vector m 2 (which represents the type semantics of entity mention m2) in addition to the information encoded by objective O M in Eq. <ref type="bibr" target="#b6">(7)</ref>. Such a "translating operation" between embedding vectors in a low-dimensional space has been proven effective in embedding entities and relations in a structured knowledge baes <ref type="bibr" target="#b4">[5]</ref>. We extend this idea to model the type correlations (and mutual constraints) between embedding vectors of entity mentions and embedding vectors of relation mentions, which are modeled in two different low-dimensional spaces.</p><p>Specifically, we define error function for the triple of a relation mention and its two entity mention arguments (z, m1, m2) using -2 norm: ? (z) = m 1 + z ? m 2 2 2 . A small value on ? (z) indicates that the embedding vectors of (z, m1, m2) do capture the type constraints. To enforce small errors between linkable relation mentions (in set Z L ) and their entity mention arguments, we use margin-based loss <ref type="bibr" target="#b4">[5]</ref> to formulate a objective function as follows.</p><formula xml:id="formula_14">OZM = z i ?Z L V v=1 max 0, 1 + ? (zi) ? ? (zv) ,<label>(8)</label></formula><p>where {zv} V v=1 are negative samples for z, i.e., zv is randomly sampled from the negative sample set <ref type="bibr" target="#b4">[5]</ref>. The intuition behind Eq. (8) is simple (see also the right col. in <ref type="figure" target="#fig_3">Fig. 4)</ref>: embedding vectors for a relation mention and its entity mentions are modeled in the way that, the translating error ? between them should be smaller than the translating error of any negative sample.</p><formula xml:id="formula_15">{(z , m 1 , m 2 )} ? {(z, m 1 , m 2 )} ? {(z, m 1 , m 2 )} with z ? Z L and m ? M L</formula><p>A Joint Optimization Problem. Our goal is to embed all the available information for relation and entity mentions, relation and entity type labels, and text features into a d-dimensional entity space and a d-dimensional relation space, following the three proposed hypotheses. An intuitive solution is to collectively minimize the three objectives O Z O M and O ZM , as the embedding vectors of entity and relation mentions are shared across them. To achieve the </p><formula xml:id="formula_16">O = OM + OZ + OZM .<label>(9)</label></formula><p>Optimizing the global objective O in Eq. (9) enables the learning of entity and relation embeddings to be mutually influenced, such that, errors in each component can be constrained and corrected by the other. The joint embedding learning also helps the algorithm to find the true types for each mention, besides using text features.</p><p>In Eq. (9), one can also minimize the weighted combination of the three objectives {O Z , O M , O ZM } to model the importance of different signals, where weights could be manually determined or automatically learned from data. We leave this as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Model Learning and Type Inference</head><p>The joint optimization problem in Eq. (9) can be solved in multiple ways. One solution is to first learn entity mention embeddings by minimizing O M , then apply the learned embeddings to optimize O M Z + O Z . However, such a solution does not fully exploit the entity-relation interactions in providing mutual feedbacks between the learning of entity mention embeddings and the learning of relation mention embeddings (see COTYPE-TWOSTEP in Sec. 4).</p><p>We design a stochastic sub-gradient descent algorithm <ref type="bibr" target="#b45">[46]</ref> based on edge sampling strategy <ref type="bibr" target="#b49">[50]</ref>, to efficiently solve Eq. (9). In each iteration, we alternatively sample from each of the three objectives {O Z , O M , O ZM } a batch of edges (e.g., (z i , f j )) and their negative samples, and update each embedding vector based on the derivatives. Algorithm 1 summarizes the model learning process of CO-TYPE. The proof procedure in <ref type="bibr" target="#b45">[46]</ref> can be adopted to prove convergence of the proposed algorithm (to the local minimum). Type Inference. With the learned embeddings of features and types in relation space (i.e., {c i }, {r k }) and entity space (i.e., {c i }, {y k }), we can perform nearest neighbor search in the target relation type set R, or a top-down search on the target entity type hierarchy Y, to estimate the relation type (or the entity type-path) for each (unlinkable) test relation mention z ? Z U (test entity mention m ? M \ M L ). Specifically, on the entity type hierarchy, we start from the tree's root and recursively find the best type among the children types by measuring the cosine similarity between entity type embedding and the vector representation of m in our learned entity embedding space. By extracting text features from m's local context (denoted by set Fm(m)), we represent m in the learned entity embedding space using the vector m = f j ?Fm(m) c j . Similarly, for test relation mention z, we represent it in our learned relation embedding space by z = f j ?Fz (z) c j where Fz(z) is the set of  text features extracted from z's local context s. The search process stops when we reach to a leaf type on the type hierarchy, or the similarity score is below a pre-defined threshold ? &gt; 0. If the search process returns an empty type-path (or type set), we output the predicted type label as None for the mention. Computational Complexity Analysis. Let E be the total number of objects in COTYPE (entity and relation mentions, text features and type labels). By alias table method <ref type="bibr" target="#b49">[50]</ref>, setting up alias tables takes O(E) time for all the objects, and sampling a negative example takes constant time. In each iteration of Algorithm 1, optimization with negative sampling (i.e., optimizing second-order proximity and translating objective) takes O(dV ), and optimization with partial-label loss takes O dV (| R | + |Y|) time. Similar to <ref type="bibr" target="#b49">[50]</ref>, we find the number of iterations for Algorithm 1 to converge is usually proportional to the number of object interactions extracted from D (e.g., unique mention-feature pairs and mention-type associations), denoted as R. Therefore, the overall time complexity of COTYPE is O dRV (| R | + |Y|) (as R ? E), which is linear to the total number of object interactions R in the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Preparation and Experiment Setting</head><p>Our experiments use three public datasets 1 from different domains. (1) NYT <ref type="bibr" target="#b42">[43]</ref>: The training corpus consists of 1.18M sentences sampled from ?294k 1987-2007 New York Times news articles. 395 sentences are manually annotated by authors of <ref type="bibr" target="#b20">[21]</ref> to form the test data; (2) Wiki-KBP <ref type="bibr" target="#b25">[26]</ref>: It uses 1.5M sentences sampled from ?780k Wikipedia articles <ref type="bibr" target="#b25">[26]</ref> as training corpus and 14k manually annotated sentences from 2013 KBP slot filling assessment results <ref type="bibr" target="#b11">[12]</ref> as test data. (3) BioInfer [39]: It consists of 1,530 manually annotated biomedical paper abstracts as test data and 100k sampled PubMed paper abstracts as training corpus. Statistics of the datasets are shown in <ref type="table" target="#tab_9">Table 4</ref>. Automatically Labeled Training Corpora. The NYT training corpus has been heuristically labeled using distant supervision following the procedure in <ref type="bibr" target="#b42">[43]</ref>. For Wiki-KBP and BioInfer training corpora, we utilized DBpedia Spotlight 2 , a state-of-the-art entity disambiguation tool, to map the detected entity mentions M to Freebase entities. We then followed the procedure introduced in Secs. 2 and 3.1 to obtain candidate entity and relation types, and constructed the training data D L . For target types, we discard the relation/entity types which cannot be mapped to Freebase from the test data while keeping the Freebase entity/relation types (not found in test data) in the training data (see <ref type="table" target="#tab_9">Table 4</ref> for the type statistics). Feature Generation. <ref type="table" target="#tab_6">Table 3</ref> lists the set of text features of relation mentions used in our experiments. We followed <ref type="bibr" target="#b25">[26]</ref> to generate text features for entity mentions. Dependency parse-based features were excluded as only POS-tagged corpus is given as input. We used a 6-word window to extract context features for each mention (3 words on the left and the right). We applied the Stanford</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NYT</head><p>Wiki-KBP BioInfer</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-F1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ma-F1</head><p>Mi-F1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-F1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ma-F1</head><p>Mi-F1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-F1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ma-F1</head><p>Mi-F1 FIGER <ref type="bibr" target="#b25">[26]</ref> 0.40 0.51 0.46 0.29 0.56 0.54 0.69 0.71 0.71 Google <ref type="bibr" target="#b14">[15]</ref> 0.38 0.57 0.52 0.30 0.50 0.38 0.69 0.72 0.65 HYENA <ref type="bibr" target="#b54">[55]</ref> 0.44 0.49 0.50 0.26 0.43 0.39 0.52 0.54 0.56 DeepWalk <ref type="bibr" target="#b37">[38]</ref> 0.49 0.54 0.53 0.21 0.42 0.39 0.58 0.59 0.61 WSABIE <ref type="bibr" target="#b53">[54]</ref> 0.53 0.57 0.58 0.35 0.55 0.50 0.64 0.66 0.65 PLE <ref type="bibr" target="#b41">[42]</ref> 0.56 0.60 0.61 0.37 0.57 0.53 0.70 0.71 0.72 CoType 0.60 0.65 0.66 0.39 0.61 0.57 0.74 0.76 0.75 <ref type="table">Table 5</ref>: Performance comparison of entity recognition and typing (using strict, micro and macro metrics <ref type="bibr" target="#b25">[26]</ref>) on the three datasets.</p><p>CoreNLP tool <ref type="bibr" target="#b27">[28]</ref> to get POS tags. Brown clusters were derived for each corpus using public implementation <ref type="bibr" target="#b2">3</ref> . The same kinds of features were used in all the compared methods in our experiments.</p><p>Evaluation Sets. For all three datasets, we used the provided training/test set partitions of the corpora. In each dataset, relation mentions in sentences are manually annotated with their relation types and the entity mention arguments are labeled with entity type-paths (see <ref type="table" target="#tab_9">Table 4</ref> for the statistics of test data). We further created a validation set by randomly sampling 10% mentions from each test set and used the remaining part to form the evaluation set.</p><p>Compared Methods. We compared COTYPE with its variants which model parts of the proposed hypotheses. Several state-of-the-art relation extraction methods (e.g., supervised, embedding, neural network) were also implemented (or tested using their published codes): (1) DS+Perceptron <ref type="bibr" target="#b25">[26]</ref>: adopts multi-label learning on automatically labeled training data D L . (2) DS+Kernel <ref type="bibr" target="#b32">[33]</ref>: applies bag-of-feature kernel <ref type="bibr" target="#b32">[33]</ref> to train a SVM classifier using D L ; (3) DS+Logistic <ref type="bibr" target="#b30">[31]</ref>: trains a multi-class logistic classifier 4 on D L ; (4) DeepWalk <ref type="bibr" target="#b37">[38]</ref>: embeds mention-feature co-occurrences and mention-type associations as a homogeneous network (with binary edges); (5) LINE <ref type="bibr" target="#b49">[50]</ref>: uses second-order proximity model with edge sampling on a feature-type bipartite graph (where edge weight w jk is the number of relation mentions having feature fj and type r k ); (6) MultiR <ref type="bibr" target="#b20">[21]</ref>: is a state-of-the-art distant supervision method, which models noisy label in D L by multi-instance multi-label learning; (7) FCM <ref type="bibr" target="#b15">[16]</ref>: adopts neural language model to perform compositional embedding; (8) DS-Joint <ref type="bibr" target="#b23">[24]</ref>: jointly extract entity and relation mentions using structured perceptron on human-annotated sentences. We used D L to train the model. For COTYPE, besides the proposed model, CoType, we compare (1) CoType-RM: This variant only optimize objective O Z to learning feature and type embeddings for relation mentions; and (2) CoType-TwoStep: It first optimizes O M , then use the learned entity mention embedding {m i } to initialize the minimization of O Z + O ZM -it represents a "pipeline" extraction diagram.</p><p>To test the performance on entity recognition and typing, we also compare with several entity recognition systems, including a supervised method HYENA <ref type="bibr" target="#b54">[55]</ref>, distant supervision methods (FIGER <ref type="bibr" target="#b25">[26]</ref>, Google <ref type="bibr" target="#b14">[15]</ref>, WSABIE <ref type="bibr" target="#b53">[54]</ref>), and a noise-robust approach PLE <ref type="bibr" target="#b41">[42]</ref>. Parameter Settings. In our testing of COTYPE and its variants, we set ? = 0.025, ? = 0.35 and ? = 10 ?4 based on the analysis on validation sets. For convergence criterion, we stopped the loop in Algorithm 1 if the relative change of O in Eq. (9) is smaller than 10 ?4 . For fair comparison, the dimensionality of embeddings d was set to 50 and the number of negative samples V was set to 5 for all embedding methods, as used in <ref type="bibr" target="#b49">[50]</ref>. For other tuning parameters in the compared methods, we tuned them on validation sets and picked the values which lead to the best performance.</p><p>Evaluation Metrics. For entity recognition and typing, we to use strict, micro, and macro F1 scores, as used in <ref type="bibr" target="#b25">[26]</ref>, for evaluating both detected entity mention boundaries and predicted entity types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NYT</head><p>Wiki-KBP BioInfer DS+Perceptron <ref type="bibr" target="#b25">[26]</ref> 0.641 0.543 0.470 DS+Kernel <ref type="bibr" target="#b32">[33]</ref> 0.632 0.535 0.419 DeepWalk <ref type="bibr" target="#b37">[38]</ref> 0.580 0.613 0.408 LINE <ref type="bibr" target="#b49">[50]</ref> 0.765 0.617 0.557 DS+Logistic <ref type="bibr" target="#b30">[31]</ref> 0.771 0.646 0.543 MultiR <ref type="bibr" target="#b20">[21]</ref> 0.693 0.633 0.501 FCM <ref type="bibr" target="#b15">[16]</ref> 0  <ref type="table">Table 6</ref>: Performance comparison on relation classification accuracy over ground-truth relation mentions on the three datasets.</p><p>We consider two settings in evaluation of relation extraction. For relation classification, ground-truth relation mentions are given and None label is excluded. We focus on testing type classification accuracy. For relation extraction, we adopt standard Precision (P), Recall (R) and F1 score <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b1">2]</ref>. Note that all our evaluations are sentence-level (i.e., context-dependent), as discussed in <ref type="bibr" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiments and Performance Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Performance on Entity Recognition and Typing.</head><p>Among the compared methods, only FIGER <ref type="bibr" target="#b25">[26]</ref> can detect entity mention. We apply our detection results (i.e., M) as input for other methods. <ref type="table">Table 5</ref> summarizes the comparison results on the three datasets.</p><p>Overall, COTYPE outperforms others on all metrics on all three datasets (e.g., it obtains a 8% improvement on Micro-F1 over the next best method on NYT dataset). Such performance gains mainly come from (1) a more robust way of modeling noisy candidate types (as compared to supervised method and distant supervision methods which ignore label noise issue); and (2) the joint embedding of entity and relation mentions in a mutually enhancing way (vs. the noise-robust method PLE <ref type="bibr" target="#b41">[42]</ref>). This demonstrates the effectiveness of enforcing Hypothesis 3 in COTYPE framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Performance on Relation Classification.</head><p>To test the effectiveness of the learned embeddings in representing type semantics of relation mentions, we compare with other methods on classifying the ground-truth relation mention in the evaluation set by target types R. <ref type="table">Table 6</ref> summarizes the classification accuracy. COTYPE achieves superior accuracy compared to all other methods and variants (e.g., obtains over 10% enhancement on both the NYT and BioInfer datasets over the next best method). All compared methods (except for MultiR) simply treat D L as "perfectly labeled" when training models. The improvement of COTYPE-RM validates the importance on careful modeling of label noise (i.e., Hypothesis 2). Comparing COTYPE-RM with MultiR, superior performance of COTYPE-RM demonstrates the effectiveness of partial-label loss over multi-instance learning. Finally, COTYPE outperforms COTYPE-RM and COTYPE-TWOSTEP validates that the propose translation-based embedding objective is effective in capturing entity-relation cross-constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Performance on Relation Extraction.</head><p>To test the domain independence of COTYPE framework, we conduct evaluations on the end-to-end relation extraction. As only MultiR and DS-Joint are able to detection entity and relation mentions in their own framework, we apply our detection results to other compared methods. <ref type="table" target="#tab_14">Table 7</ref> shows the evaluation results as well as runtime of different methods. In particular, results at each method's highest F1 score point are reported, after tuning the threshold for each method for determining whether a test mention is None or some target type.</p><p>Overall, COTYPE outperforms all other methods on F1 score on all three datasets. We observe that DS-Joint and MultiR suffer from low recall, since their entity detection modules do not work well on D L (where many tokens have false negative tags). This demonstrates the effectiveness of the proposed domain-agnostic text segmentation algorithm (see Sec. 3.1). We found that the incremental diagram of learning embedding (i.e., COTYPE-TWOSTEP) brings only marginal improvement. In contrast, COTYPE adopts a "joint modeling" diagram following Hypothesis 3 and achieves significant improvement. In <ref type="figure" target="#fig_4">Fig. 5</ref>, precision-recall curves on NYT and BioInfer datasets further show that COTYPE can still achieve descent precision with good recall preserved. 4. Scalability. In addition to the runtime shown in <ref type="table" target="#tab_14">Table 7</ref>, <ref type="figure" target="#fig_5">Fig. 6(a</ref>     <ref type="figure" target="#fig_5">Fig. 6(b)</ref> shows the performance trend on Bioinfer dataset when varying the sampling ratio (subset of relation mentions randomly sampled from the training set). F1 scores of all three methods improves as the sampling ratio increases. CoType performs best in all cases, which demonstrates its robust performance across corpora of various size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Study the effect of entity type error in relation classification.</head><p>To investigate the "error propagation" issue of incremental pipeline, we test the changes of relation classification performance by <ref type="bibr" target="#b0">(1)</ref> training models without entity types as features; (2) using entity types predicted by FIGER <ref type="bibr" target="#b25">[26]</ref> as features; and (3) using groundtruth ("perfect") entity types as features. <ref type="figure" target="#fig_7">Fig. 7</ref> summarize the accuracy of COTYPE, its variants and the compared methods. We observe only marginal improvement when using FIGER-predicted types but significant improvement when using ground-truth entity types-this validates the error propagation issue. Moreover, we find that COTYPE achieves an accuracy close to that of the next best method (i.e., DS + Logistic + Gold entity type). This demonstrates the effectiveness of our proposed joint entity and relation embedding.</p><p>NYT <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b20">21]</ref> Wiki-KBP <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">26]</ref>    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RELATED WORK</head><p>Entity and Relation Extraction. There have been extensive studies on extracting typed entities and relations in text (i.e., contextdependent extraction). Most existing work follows an incremental diagram-they first perform entity recognition and typing <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b39">40]</ref> to extract typed entity mentions, and then solve relation extraction <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17]</ref> to identify relation mentions of target types. Work along both lines can be categorized in terms of the degree of supervision. While supervised entity recognition systems <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b33">34]</ref> focus on a few common entity types, weakly-supervised methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b35">36]</ref> and distantly-supervised methods <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b25">26]</ref> use large text corpus and a small set of seeds (or a knowledge base) to induce patterns or to train models, and thus can apply to different domains without additional human annotation labor. For relation extraction, similarly, weak supervision <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13]</ref> and distant supervision <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b30">31]</ref> approaches are proposed to address the domain restriction issue in traditional supervised systems <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b16">17]</ref>. However, such a "pipeline" diagram ignores the dependencies between different sub tasks and may suffer from error propagation between the tasks. Recent studies try to integrate entity extraction with relation extraction by performing global sequence labeling for both entities and relations <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b0">1]</ref>, incorporating type constraints between relations and their arguments <ref type="bibr" target="#b43">[44]</ref>, or modeling factor graphs <ref type="bibr" target="#b46">[47]</ref>. However, these methods require human-annotated corpora (cleaned and general) for model training and rely on existing entity detectors to provide entity mentions. By contrast, the COTYPE framework runs domain-agnostic segmentation algorithm to mine entity mentions and adopts a label noise-robust objective to train models using distant supervision. In particular, <ref type="bibr" target="#b0">[1]</ref> integrates entity classification with relation extraction using distant supervision but it ignores label noise issue in the automatically labeled training corpora.</p><p>COTYPE combines the best of two worlds-it leverages the noisy distant supervision in a robust way to address domain restriction (vs. existing joint extraction methods <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b31">32]</ref>), and models entityrelation interactions jointly with other signals to resolve error propagation (vs. current distant supervision methods <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b30">31]</ref>).</p><p>Learning Embeddings and Noisy Labels. Our proposed framework incorporates embedding techniques used in modeling words and phrases in large text corpora <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b44">45]</ref> ,and nodes and links in graphs/networks <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b37">38]</ref>. Theses methods assume links are all Text Blake Edwards, a prolific filmmaker who kept alive the tradition of slapstick comedy, died Wednesday of pneumonia at a hospital in Santa Monica.</p><p>Anderson is survived by his wife Carol, sons Lee and Albert, daughter Shirley Englebrecht and nine grandchildren.</p><p>MultiR <ref type="bibr" target="#b20">[21]</ref> r * : person:country_of_birth,  correct (in unsupervised setting) or labels are all true (in supervised setting). COTYPE seeks to model the true links and labels in the embedding process (e.g., see our comparisons with LINE <ref type="bibr" target="#b49">[50]</ref>, DeepWalk <ref type="bibr" target="#b37">[38]</ref> and FCM <ref type="bibr" target="#b15">[16]</ref> in Sec. 4.2). Different from embedding structured KB entities and relations <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b50">51]</ref>, our task focuses on embedding entity and relation mentions in unstructured contexts.</p><formula xml:id="formula_17">Y</formula><p>In the context of modeling noisy labels, our work is related to partial-label learning <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b36">37]</ref> and multi-label multi-instance learning <ref type="bibr" target="#b48">[49]</ref>, which deals with the problem where each training instance is associated with a set of noisy candidate labels (whereonly one is correct). Unlike these formulations, our joint extraction problem deals with both classification with noisy labels and modeling of entity-relation interactions. In Sec 4.2, we compare our fullfledged model with its variants COTYPE-EM and COTYPE-RM to validate the Hypothesis on entity-relation interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>This paper studies domain-independent, joint extraction of typed entities and relations in text with distant supervision. The proposed COTYPE framework runs domain-agnostic segmentation algorithm to mine entity mentions, and formulates the joint entity and relation mention typing problem as a global embedding problem. We design a noise-robust objective to faithfully model noisy type label, and capture the mutual dependencies between entity and relation. Experiment results demonstrate the effectiveness and robustness of COTYPE on text corpora of different domains. Interesting future work includes incorporating pseudo feedback idea <ref type="bibr" target="#b52">[53]</ref> to reduce false negative type labels in the training data, modeling type correlation in the given type hierarchy <ref type="bibr" target="#b41">[42]</ref>, and performing type inference for test entity mention and relation mentions jointly.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>RelationFigure 2 :</head><label>2</label><figDesc>Mention: ("Obama", "Dreams of My Father", S2) Types of Entity 1: {person, politician, artist, author}, Entity 2Framework Overview of COTYPE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Framework Overview.</head><label></label><figDesc>We propose a embedding-based framework with distant supervision (see also Fig. 2) as follows: 1. Run POS-constrained text segmentation algorithm on POS-tagged corpus D using positive examples obtained from KB, to detect candidate entity mentions M (Sec. 3.1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Example POS tag patterns learned using KB examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Partial-Figure 4 :</head><label>4</label><figDesc>Label Loss for Modeling Noisy Types sentence S3: "Barack Obama is the 44 th and current president of the United States" "President Clinton and Obama at tended the funeral of former Israeli Prime Minister, and were scheduled to fly back to the US together." Illustrations of the partial-label associations, Hypothesis 2 (the left col.), and the entity-relation interactions, Hypothesis 3 (the right col.).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Precision-recall curves of relation extraction on NYT and BioInfer datasets. Similar trend is also observed on the Wiki-KBP dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>(a) Scalability study on COTYPE and the compared methods; and (b) Performance changes of relation extraction with respect to sampling ratio of relation mentions on the Bioinfer dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>4.3 Case Study 1 .</head><label>1</label><figDesc>Example output on news articles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Study of entity type error propagation on the BioInfer dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Candidate Generation &amp; Distant Supervision Modeling Automatically-Labeled Training Corpus Joint Entity and Relation Embedding Mention Feature Type S2_Obama author politician ("Obama", "US", S4) S1_Barack Obama Entity Mention Embedding Space CONTEXT_ president president_of author_of (Barack Obama, US, S1) BETWEEN_ president BETWEEN_ book Relation Mention Embedding Space Entity and Relation Type Inference politician artist person root art person location organizationof Obama reading from his book "Dreams of My Father" has been shared out of context.</head><label></label><figDesc></figDesc><table><row><cell>ID</cell><cell>Sentence</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>S1</cell><cell>US presi dent Barack Obama visit China today.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>S2</cell><cell>A cl ip</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>S3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>S4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Target Entity</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Type Hierarchy</cell><cell></cell><cell></cell><cell></cell><cell>...</cell></row><row><cell></cell><cell>film</cell><cell>book</cell><cell>artist</cell><cell>...</cell><cell>...</cell><cell>...</cell></row><row><cell></cell><cell></cell><cell>actor</cell><cell>author</cell><cell>politician</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Types of Entity 1: {person, politician, artist, author}, Entity 2: {ORG, LOC} Relation Types: {president_of</head><label></label><figDesc>, born_in, citizen_of, travel_to}</figDesc><table><row><cell>...</cell><cell>...</cell></row><row><cell></cell><cell>Relation Mention: ("Barack Obama", "United S tates", S3)</cell></row><row><cell></cell><cell>Types of Entity 1: {person, politician, artist, author}, Entity 2: {ORG, LOC}</cell></row><row><cell></cell><cell>Relation Types: {president_of , born_in, citizen_of, travel_to}</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Text features for relation mentions used in this work [17, 43] (excluding dependency parse-based features and entity type features). ("Barack Obama", "United States") is used as an example relation mention from the sentence "Honolulu native Barack Obama was elected President of the United States on March 20 in 2008.".</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Algorithm 1 :</head><label>1</label><figDesc>Model Learning of COTYPE Input: labeled training corpus D L , text features {Fz , Fm}, regularization parameter ?, learning rate ?, number of negative samples V , dim. d Output: relation/entity mention embeddings {z i }/{m i }, feature embeddings {c j }, {c j }, relation/entity type embedding {y k }/{r k } 1 Initialize: vectors {z i },{m i },{c j },{c j },{y k },{r k } as random vectors 2 while O in Eq. (9) not converge do 3 for objective in {O Z , O M } do Sample a mention-feature co-occurrence w ij ; draw V negative samples; update {z, c} based on L ZF , or {m, c } based on L M F 5 Sample a mention z i (or m i ); get its candidate types R i (or Y i ); draw V negative samples; update z and {r} based on O Z ? L ZF , or m and {y} based on O M ? L M F L ; draw V negative samples; update {z i , m 1 , m 2 } based on O ZM 8 end goal, we formulate a joint optimization problem as follows. min {z i },{c j },{r k },{m i },{c j },{y k }</figDesc><table><row><cell>6</cell><cell>end</cell></row><row><cell>7</cell><cell>Sample a relation mention z i = (m 1 , m 2 ) ? Z</cell></row></table><note>4</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Statistics of the datasets in our experiments.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8</head><label>8</label><figDesc>shows the output of COTYPE, MultiR and Logistic on two news sentences from the Wiki-KBP dataset. CoType extracts more relation mentions (e.g., children), and predict entity/relation types with better accuracy. Also, COTYPE can jointly extract typed entity and relation mentions while other methods cannot (or need to do it incrementally).</figDesc><table /><note>2. Testing the effect of training corpus size.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 7 :</head><label>7</label><figDesc>Performance comparison on end-to-end relation extraction (at the highest F1 point) on the three datasets.</figDesc><table><row><cell></cell><cell>0.9</cell><cell></cell><cell></cell><cell></cell><cell cols="13">Performance Comparison on Relation Classification</cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell cols="7">No entity type feature</cell><cell></cell><cell cols="5">w/ FIGER entity type</cell><cell></cell><cell cols="2">w/ gold entity type</cell></row><row><cell>Accuracy</cell><cell>0.7 0.3 0.4 0.5 0.6</cell><cell>0.46</cell><cell>0.47</cell><cell>0.49</cell><cell>0.5</cell><cell>0.53</cell><cell>0.55</cell><cell>0.55</cell><cell>0.58</cell><cell>0.6</cell><cell>0.54</cell><cell>0.56</cell><cell>0.62</cell><cell>0.57</cell><cell>0.58</cell><cell>0.63</cell><cell>0.58</cell><cell>0.62</cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell cols="2">FCM</cell><cell></cell><cell cols="3">MultiR</cell><cell cols="2">LINE</cell><cell></cell><cell cols="3">DS+Logistic</cell><cell cols="4">CoType-RM CoType-TwoStep</cell><cell>CoType</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 8 :</head><label>8</label><figDesc>Example output of COTYPE and the compared methods on two news sentences from the Wiki-KBP dataset.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Codes and datasets used in this paper can be downloaded at: https: //github.com/shanzhenren/CoType.2 http://spotlight.dbpedia.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/percyliang/brown-cluster<ref type="bibr" target="#b3">4</ref> We use liblinear package from https://github.com/cjlin1/liblinear</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">ACKNOWLEDGMENTS</head><p>Research was sponsored in part by the U.S. Army Research Lab. under Cooperative Agreement No. W911NF-09-2-0053 (NSCTA), National Science Foundation IIS-1017362, IIS-1320617, and IIS-1354329, HDTRA1-10-1-0120, and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov). The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Extracting relations between non-standard entities using distant supervision and imitation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maynard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A review of relation extraction. Literature review for Language and Statistics II</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Badaskar</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Finding the right facts in the crowd: factoid question answering over social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to extract relations from the web using minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploiting background knowledge for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning from partial labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1501" to="1536" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dependency tree kernels for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Knowledge vault: A web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Scalable topical phrase mining from text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>El-Kishky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>VLDB</publisher>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="305" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Linguistic resources for 2013 knowledge base population evaluations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Getman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Analysis Conference (TAC)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Web-scale information extraction in knowitall:(preliminary results)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-M</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Context-dependent fine-grained entity type tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lazic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huynh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.1820</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improved relation extraction with feature-rich compositional embedding models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exploring various knowledge in relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guodong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Min</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improved pattern learning for bootstrapped entity extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CONLL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Locality preserving projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robust disambiguation of named entities in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bordino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>F?rstenau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Taneva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Knowledge-based weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mining for unambiguous instances to adapt part-of-speech taggers to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>S?gaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fine-grained named entity recognition and relation extraction for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-G</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-G</forename><surname>Jang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Incremental joint extraction of entity mentions and relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">No noun phrase left behind: detecting and typing unlinkable entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fine-grained entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Mining quality phrases from massive text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
		<title level="m">The stanford corenlp natural language processing toolkit. ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dbpedia spotlight: shedding light on the web of documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garc?a-Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">I-Semantics</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Modeling joint entity and relation extraction with table representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Subsequence kernels for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Bunescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A survey of named entity recognition and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nadeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lingvisticae Investigationes</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Noisy or-based model for relation extraction using distant supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nagesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fine-grained semantic typing of emerging entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tylenda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Classification with partial labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bioinfer: a corpus for information extraction in the biomedical domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heimonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bj?rne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>J?rvinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salakoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Clustype: effective entity recognition and typing by relation phrase-based clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>El-Kishky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Label noise reduction in entity typing by heterogeneous partial-label embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Global inference for entity and relation identification via a linear programming formulation. Introduction to statistical relational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="553" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A word embedding approach to predicting the compositionality of multiword expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Salehi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pegasos: Primal estimated sub-gradient solver for svm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cotter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical programming</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="3" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Joint inference of entities, relations, and coreference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Automated Knowledge Base Construction</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Open domain question answering via semantic enrichment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Representing text for joint embedding of text and knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Knowledge base completion via search-based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Filling knowledge base gaps for distant supervision of relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Le Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Embedding methods for fine grained entity type classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lazic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Hyena: Hierarchical type classification for entity names</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
