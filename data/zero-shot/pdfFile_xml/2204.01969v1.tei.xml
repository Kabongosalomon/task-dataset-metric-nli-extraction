<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Region Rebalance for Long-Tailed Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Region Rebalance for Long-Tailed Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T07:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we study the problem of class imbalance in semantic segmentation. We first investigate and identify the main challenges of addressing this issue through pixel rebalance. Then a simple and yet effective region rebalance scheme is derived based on our analysis. In our solution, pixel features belonging to the same class are grouped into region features, and a rebalanced region classifier is applied via an auxiliary region rebalance branch during training. To verify the flexibility and effectiveness of our method, we apply the region rebalance module into various semantic segmentation methods, such as Deeplabv3+, OCRNet, and Swin. Our strategy achieves consistent improvement on the challenging ADE20K and COCO-Stuff benchmark. In particular, with the proposed region rebalance scheme, stateof-the-art BEIT receives +0.7% gain in terms of mIoU on the ADE20K val set.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep neural networks (DNNs) like convolutional neural networks <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50]</ref> and vision transformers <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b37">38]</ref> have achieved great success in various computer vision tasks, including image classification <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50]</ref>, object detection <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref> and semantic segmentation <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b60">61]</ref>. Most previous studies focus on curated data with annotations, such as ImageNet, that are balanced over different classes. In contrast, real-world data often exhibit a long-tailed distribution where a small number of head classes contain many instances while most other classes have relatively few instances. As shown in <ref type="bibr" target="#b21">[22]</ref>, addressing the long-tailed distribution problem is the key to large vocabulary vision recognition tasks.</p><p>With the increasing attention on the long-tailed distribution problem, various advanced methods have been developed for long-tailed image classification <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b17">18]</ref> and instance segmentation <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr">56]</ref>. For example, Cao et al. <ref type="bibr" target="#b8">[9]</ref> and Ren et al. <ref type="bibr" target="#b42">[43]</ref> provide theoretical foundation on the optimal margins  <ref type="figure">Figure 1</ref>: Illustrating the improvements with our region rebalance: incorporating our region rebalance scheme leads to +1.21%, +1.61%, +1.22%, and +0.7% gains for OCRNet, DeepLabv3+, Swin, and BEIT on the ADE20K val set, respectively.</p><p>for long-tailed image classification. For long-tailed instance segmentation, most effort tackles the problem based on the Mask-RCNN framework <ref type="bibr" target="#b23">[24]</ref> and conducts class rebalance in the proposal classification. Without much prior longtailed study for semantic segmentation yet, we focus our work in this direction.</p><p>To address the long-tailed semantic segmentation problem, we first apply the well-known long-tailed image classification method to the semantic segmentation task. With the balanced softmax strategy <ref type="bibr" target="#b42">[43]</ref> to rebalance the pixel classification, we observe that it does not work well for the major evaluation metric of IoU.</p><p>From an investigation of this, we identify two major challenges in conducting pixel rebalance: (i) Pixel rebalance mainly improves pixel accuracy but not IoU. We empirically observe that applying the pixel rebalance strategy even harms IoU performance and argue that inconsistency between the training objective, i.e., pixel cross-entropy, and our inference target, i.e., IoU, leads to this phenomenon. (ii) Neighboring pixels are highly correlated. In long-tailed image classification, rebalance can be effectively guided by class frequency because image samples are independent and identically distributed (i.i.d.). In contrast, pixel samples are not i.i.d. due to correlation among neighboring pixels in an image. As a result, class frequency in the pixel domain is an unsuitable guide for rebalancing.</p><p>In this work, we propose to overcome the non-i.i.d. issue of pixel rebalance by gathering correlated pixels into regions and performing rebalance based on regions. We refer to this method for dealing with the class imbalance in semantic segmentation as Region Rebalance. In this approach, we introduce an auxiliary region classification branch where pixel features of the same class/region are averaged and fed into a rebalanced region classifier, as shown in <ref type="figure">Figure 2</ref>. With this additional training target, the pixel features are encouraged to lie in a more balanced classification space with regard to uncorrelated pixel samples. We note that the region rebalance branch is used only for training and is removed for inference.</p><p>An incidental benefit of this approach is that popular benchmark datasets, including ADE20K and COCO-Stuff164K, exhibit less class imbalance in the region domain than in the pixel domain, as later analyzed in Sec. 3.3.2. Because of this property, rebalancing in the region domain can be accomplished relatively more effectively.</p><p>We apply our region rebalance strategy to various semantic segmentation methods e.g., PSPNet <ref type="bibr" target="#b61">[62]</ref>, OCR-Net <ref type="bibr" target="#b60">[61]</ref>, DeepLabv3+ <ref type="bibr" target="#b14">[15]</ref>, Swin <ref type="bibr" target="#b37">[38]</ref>, and BEIT <ref type="bibr" target="#b2">[3]</ref>, and conduct experiments on two challenging semantic segmentation benchmarks, namely ADE20K <ref type="bibr" target="#b65">[66]</ref> and COCO-Stuff164K <ref type="bibr" target="#b7">[8]</ref>, to verify the effectiveness of our method. The results are reported in <ref type="figure">Figure 1</ref>. Our code will be made publicly available. The key contributions are summarized as follows:</p><p>? We investigate the class imbalance problem that exists in semantic segmentation and identify the main challenges of pixel rebalance.</p><p>? We propose a simple yet effective region rebalance scheme and validate the effectiveness of our method across various semantic segmentation methods. Notably, our method yields a +0.7% improvement for BEIT <ref type="bibr" target="#b2">[3]</ref>, setting a new performance record on ADE20K val at the time of submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Long-tailed Image Classification</head><p>In the area of long-tailed image classification, the most popular methods for dealing with imbalanced data can be categorized into re-weighting/re-sampling methods <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b28">29]</ref> or one-stage/two-stage methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>Re-weighting/Re-sampling. Re-sampling approaches are based on either over-sampling low-frequency classes or under-sampling high-frequency classes. Over-sampling <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7]</ref> usually suffers from heavy over-fitting to lowfrequency classes. For under-sampling <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b5">6]</ref>, it inevitably leads to degradation of CNN generalization ability because a large portion of the high-frequency class data is discarded. Re-weighting <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b28">29]</ref> loss functions is an alternative to rebalancing and is accomplished by enlarging weights on more challenging or sparse classes. However, re-weighting makes CNNs difficult to optimize when training on large-scale data. One-stage/Two-stage. Since the deferred re-weighting and re-sampling strategies proposed by Cao et al. <ref type="bibr" target="#b9">[10]</ref>, it was further observed by Kang et al. <ref type="bibr" target="#b30">[31]</ref> and Zhou et al. <ref type="bibr" target="#b64">[65]</ref> that re-weighting and re-sampling could benefit classifier learning but hurt representation learning. Based on this, many two-stage methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b63">64]</ref> were developed.</p><p>The two-stage design contradicts the push towards endto-end learning that has been prevalent in the deep learning era. Through a causal inference framework, Tang et al. <ref type="bibr" target="#b52">[53]</ref> revealed the harmful causal effects of SGD momentum on long-tailed classification. Ren et al. <ref type="bibr" target="#b42">[43]</ref> extended LDAM <ref type="bibr" target="#b9">[10]</ref> and theoretically obtained the optimal margins for multi-class image classification. Cui et al. <ref type="bibr" target="#b18">[19]</ref> proposed a residual learning mechanism to address this issue. Recently, contrastive learning has also been introduced for long-tailed image classification <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Long-tailed Instance Segmentation</head><p>With the great progress in long-tailed image classification <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b17">18]</ref>, many researchers have started to explore the long-tailed phenomenon in instance segmentation. Many algorithms <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr">56]</ref> have been developed to address this issue.</p><p>Tan et al. <ref type="bibr" target="#b50">[51]</ref> observed that each positive sample of one category could be seen as a negative sample for other categories, causing the tail categories to receive more discouraging gradients. Based on this, they proposed to simply ignore those gradients for rare categories. Li et al. <ref type="bibr" target="#b33">[34]</ref> proposed balanced group softmax (BAGS) for balancing the classifier within a detection framework through group-wise training. BAGS implicitly modulates the training process for the head and tail classes and ensures that all classes are trained sufficiently. <ref type="bibr">Wang et al. [56]</ref> proposed the Seesaw loss to dynamically rebalance gradients of positive and negative samples for each category, further improving performance. <ref type="figure">Figure 2</ref>: Illustrating the region rebalance scheme for semantic segmentation: The region rebalance branch is indicated by the tan-colored box. We introduce the region rebalance branch (w/o any other changes to the semantic segmentation network and pixel classifier) to handle the class imbalance problem during training and remove it during evaluation.</p><p>Many approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b45">46]</ref> combine upsampled high-level feature maps and low-level feature maps to capture global information and recover sharp object boundaries. A large receptive field also plays an important role in semantic segmentation. Several methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b59">60]</ref> have proposed dilated or atrous convolutions to enlarge the field of filters and incorporate larger context. For better global information, recent work <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b61">62]</ref> adopted spatial pyramid pooling to capture multi-scale contextual information. Along with atrous spatial pyramid pooling and an effective decoder module, Deeplabv3+ <ref type="bibr" target="#b14">[15]</ref> features a simple and effective encoder-decoder architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Method</head><p>First, we analyze the challenges of conducting pixel rebalance for semantic segmentation. Second, we present the details of our proposed region rebalance scheme and explain how region rebalance helps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Challenges of Pixel Rebalance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Higher Pixel Accuracy ? Higher IoU?</head><p>In the image classification task, minimizing the crossentropy loss essentially maximizes the probability of the ground truth label during the training phase, which is consistent with the top-1 accuracy evaluation metric during inference. Therefore, we can expect more balanced class accuracy via incorporating rebalance strategies.</p><p>For semantic segmentation, we typically use pixel crossentropy as a proxy to indirectly optimize Intersection-over-Union (IoU). However, pixel cross-entropy inherently maximizes pixel accuracy (Acc). This misalignment between the training objective and target evaluation metric IoU inspires us to explore what would happen when rebalancing with pixel cross-entropy in semantic segmentation.</p><p>Theoretical analysis. In order to study how pixel rebalance affects IoU, we examine the connections between IoU and Acc. We use TP, FN and FP to denote true positives, false negatives, and false positives, respectively. Eq. (1) presents the formula for IoU, while Eq. (2) is for Acc. By combining these two equations in Eq. (3), we can see that 1 IoU is a linear function of 1 Acc , with FP TP as a constant. In this sense, it is reasonable to optimize IoU with pixel cross-entropy.</p><formula xml:id="formula_0">IoU = TP TP + FN + FP ,<label>(1)</label></formula><formula xml:id="formula_1">Acc = TP TP + FN ,<label>(2)</label></formula><formula xml:id="formula_2">1 IoU = 1 Acc + FP TP .<label>(3)</label></formula><p>When rebalancing with pixel cross-entropy, Acc of lowfrequency classes is expected to improve. However, according to Remark 1, a higher Acc does not always mean a higher IoU. Even worse, we empirically observe that Remark 1 is usually not satisfied for pixel rebalancing as shown in the following case study.</p><p>Remark 1 (Condition for IoU improvement) With pixel rebalance, suppose the Acc of class y is improved from A to (1 + K)A, then it must satisfy FP r -(1 + K) ? FP ? K? n y to guarantee IoU improvements, where FP r denotes false positives after the rebalance while FP is false positives beforehand. n y is the pixel frequency for class y. K ? 0. Proof See the Supplementary Material.</p><p>A Case Study. To rebalance with pixel cross-entropy, we conduct experiments on ADE20K with balanced softmax <ref type="bibr" target="#b42">[43]</ref>, a state-of-the-art method for long-tailed image classification. As shown in <ref type="table" target="#tab_1">Table 1</ref>, the overall mIoU becomes worse after rebalance, dropping from 43.95 to 38.57, despite significant improvements in overall mAcc.</p><p>To understand whether the overall mIoU degradation is caused by over-rebalance, i.e., IoU of high-frequency       </p><formula xml:id="formula_3">?Acc y = Acc rebalance y ? Acc baseline y .<label>(4)</label></formula><p>As shown in <ref type="figure" target="#fig_2">Figure 3</ref> (b) and (c), after pixel rebalance with balanced softmax, IoU decreases while Acc increases for low-frequency classes. This case study shows that pixel rebalance can improve Acc while failing to meet the IoU improvement condition of Remark 1, which implies that pixel rebalance improves lowfrequency Acc largely through an increase of FP, which is harmful to IoU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Accuracy vs. Frequency</head><p>An important prior for rebalancing in long-tailed image classification is that images are nearly i.i.d., which makes class accuracy positively related to the number of images in the corresponding classes as shown in <ref type="figure" target="#fig_5">Figure 4</ref> (a).</p><p>Under this case, to encourage the optimization process to be more friendly to low-frequency classes in training, it would be sensible to re-weight the cross-entropy loss with a factor that is inversely proportional to class frequency, like in <ref type="bibr" target="#b19">[20]</ref>. Moreover, Cao et al. <ref type="bibr" target="#b9">[10]</ref> and Ren et al. <ref type="bibr" target="#b42">[43]</ref> theoretically reveal the close relationship between the optimal margin and class frequency, further indicating the importance of class frequency statistics for conducting rebalance.</p><p>However, the situation is different for the semantic segmentation task. Pixels within the same region of an image usually belong to the same object or stuff and are thus highly correlated. Since pixels are not i.i.d., the class pixel frequency is an unsuitable factor for rebalancing. This conclusion is supported empirically in <ref type="figure" target="#fig_5">Figure 4</ref> (b), where class Dataset</p><formula xml:id="formula_5">? X,Y (%) CIFAR-100 75.9 ADE20K-pixel 35.0 ADE20K-region 41.3</formula><p>accuracy is shown to have much weaker correlation with class pixel frequency compared to class image frequency in image classification, shown in <ref type="figure" target="#fig_5">Figure 4</ref> (a).</p><p>To quantify the correlation between class accuracy and frequency, we calculate the Pearson correlation coefficient <ref type="bibr" target="#b3">[4]</ref>:</p><formula xml:id="formula_6">? X,Y = Cov(X, Y ) ?(X)?(Y ) = E[(X ? ?(X))(Y ? ?(Y ))] ?(X)?(Y ) ,<label>(6)</label></formula><p>where ?(.), ?(.), Cov(.) and E(.) are functions for mean, standard deviation, covariance and expectation. <ref type="table" target="#tab_2">Table 2</ref> lists the Pearson coefficients between class accuracy and image frequency on CIFAR-100, pixel frequency on ADE20K, and region frequency on ADE20K, respectively. The correlations between class accuracy and image frequency, region frequency, pixel frequency decrease step by step. Region frequency has a stronger correlation with class accuracy than pixel frequency, as it eliminates the effects of correlations among neighboring pixels. The weak relationship between class accuracy and pixel frequency causes pixel frequency to be less informative for rebalancing, which adds to the challenge of rebalancing in semantic segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Region Rebalance Framework</head><p>Due to the issues discussed in Sec. 3.1, we propose to rebalance at the region level instead of the pixel level, through a Region Rebalance (RR) training strategy. The region rebalance method relieves the class imbalance issue with an auxiliary region classification branch by encouraging features to lie in a more balanced region classification space. Moreover, rebalance methods from long-tailed image classification can be readily employed to solve the region imbalance problem. This involves no extra cost for testing because the region rebalance branch is removed during inference.</p><p>The region rebalance framework shown in <ref type="figure">Figure 2</ref> contains two components: (i) An auxiliary region classification branch to ease the class imbalance problem and (ii) Enhanced rebalance with techniques in long-tailed image classification for solving region imbalance. The overall loss functions in the following are deployed:</p><formula xml:id="formula_7">F(i) = x?D 1 if i ? x gt otherwise 0,<label>(7)</label></formula><formula xml:id="formula_8">L reg = 1 |R| r?R ? log( F(r y )e ry k?Y F(k)e r k ),<label>(8)</label></formula><formula xml:id="formula_9">L all = L pixel + ?L reg ,<label>(9)</label></formula><p>where D is the dataset, R contains all the extracted regions, r y is the ground truth label of region r, r i represents the region logit corresponding to class i, F(i) denotes the region frequency of class i, Y is the label space, L reg is the region loss, while L pixel represents pixel cross-entropy loss.</p><p>In the region classification branch, we group pixels belonging to the same class into region features by averaging the pixel features according to the ground-truth region map. Then the extracted region features are fed into a region classifier. Further, we enhance the rebalance using a technique <ref type="bibr" target="#b42">[43]</ref> borrowed from the long-tailed image classification community to tackle the region imbalance problem. The deployed region loss is shown in Eq. (8), and we use a hyper-parameter ? to control the strength of rebalance, shown in Eq. (9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Analysis of Our Method</head><p>The misalignment between the training objective, i.e., pixel cross-entropy, and evaluation metric IoU at inference is problematic for direct pixel rebalance as analyzed in Sec. 3.1. The proposed method instead relieves class imbalance via region rebalance. To clarify the mechanism of our region rebalance method, we analyze it in comparison to pixel rebalance. In addition, we discuss differences in imbalance reflected by dataset statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Region Rebalance vs. Pixel Rebalance</head><p>On one hand, region rebalance gathers pixel features of the same class into region features, and then region classification follows. The "gather" operation essentially removes the effect of correlation among pixels in a region. As demonstrated in <ref type="table" target="#tab_2">Table 2</ref>, region frequency has a stronger correlation with class accuracy than pixel frequency, further indicating its greater suitability for rebalancing. Besides, the "gather" operation reduces data class imbalance and thus is good for rebalancing as analyzed in Sec. 3.3.2.</p><p>On the other hand, we empirically observe that region rebalance is more aligned with the IoU metric. As studied in Sec. 3.1.1, pixel rebalance promotes higher Acc while failing to improve IoU because of an increase in FP.</p><p>Such behavior can be understood by considering the situation that two very different objects/stuff can still have similar local pixel features. With pixel rebalance, we attach more importance to pixels of low-frequency classes, and in consequence, corresponding similar pixels in other classes <ref type="bibr" target="#b29">30</ref>   are more likely to become FP. In contrast, objects/stuff are more distinguishable at the region level due to features that are more global. Though more importance is also attached to regions of low-frequency classes with region rebalance, it will be much harder to predict other class objects/stuff as FP. More visual evidence is discussed in our supplementary file. We leave more theoretical analysis to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Datasets Statistics</head><p>Semantic segmentation datasets suffer from both pixel level and region level data imbalance. However, we observe that the degree of pixel imbalance is more serious than that of region imbalance as shown in <ref type="figure" target="#fig_6">Figure 5</ref>. We collect statistics from the most popular semantic segmentation benchmarks in <ref type="figure" target="#fig_6">Figure 5b</ref>. Following convention <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b38">39]</ref>, we calculate the imbalance factor (IF) as ? = Nmax Nmin , where N max and N min are the numbers of training samples for the most frequent class and the least frequent class.</p><p>As shown in <ref type="figure" target="#fig_6">Figure 5b</ref>, for ADE20K, the pixel imbalance factor (PIF) is nearly 3 times the region imbalance factor (RIF). For COCO-Stuff164K, PIF is nearly 5 times RIF. As our method relieves the class imbalance issue via region rebalancing, it conveniently benefits from less imbalance than pixel rebalance would, and this in turn promotes more effective rebalancing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>To evaluate the effectiveness of our method, we conduct experiments on the most popular benchmarks in semantic segmentation, i.e., ADE20K <ref type="bibr" target="#b65">[66]</ref> and COCO-Stuff164K <ref type="bibr" target="#b7">[8]</ref>. By inserting the proposed region rebalance method into UperNet, PSPNet, Deeplabv3+, and OCRNet, clear improvements are obtained. We also test the region rebalance method on popular transformer neural networks, specifically Swin transformer <ref type="bibr" target="#b37">[38]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>We implement the proposed region rebalance method in the mmsegmentation codebase <ref type="bibr" target="#b15">[16]</ref> and follow the commonly used training settings for each dataset. More details are described in the following.</p><p>For backbones, we use CNN-based ResNet-50c and ResNet-101c, which replace the first 7?7 convolution layer in the original ResNet-50 and ResNet-101 with three consecutive 3 ? 3 convolutions. Both are popular in the semantic segmentation community <ref type="bibr" target="#b61">[62]</ref>. For OCRNet, we adopt HRNet-W18 and HRNet-W48 <ref type="bibr" target="#b54">[55]</ref>. For transformer-based neural networks, we adopt the popular Swin transformer <ref type="bibr" target="#b37">[38]</ref> and BEIT <ref type="bibr" target="#b2">[3]</ref>. BEIT achieves the most recent stateof-the-art performance on the ADE20K validation set. " ?" in <ref type="table" target="#tab_5">Tables 3 and 4</ref> indicates models that are pretrained on ImageNet-22K.</p><p>With CNN-based models, we use SGD and the poly learning rate schedule <ref type="bibr" target="#b61">[62]</ref> with an initial learning rate of 1e ? 2 and a weight decay of 1e ? 4. If not stated otherwise, we use a crop size of 512 ? 512, a batch size of 16, and train all models for 160K iterations on ADE20K and 320K iterations on COCO-Stuff164K. For Swin transformer and BEIT, we use their default optimizer, learning rate setup and training schedule.</p><p>In the training phase, the standard random scale jittering between 0.5 and 2.0, random horizontal flipping, random cropping, as well as random color jittering are used as data </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Main Results</head><p>Comparison on ADE20K. To show the flexibility of our region rebalance module, we experiment on ADE20K with various semantic segmentation methods, e.g., PSPNet, UperNet, OCRNet, and Deeplabv3+. As shown in <ref type="table" target="#tab_5">Table 3</ref>, plugging the region rebalance module into those methods leads to significant improvements. Specifically, for ResNet-101 or HRNet-W48, after training with Region Rebalance, there are 1.26%, 0.80%, 1.21% and 1.61% gains for Uper-Net, PSPNet, OCRNet, and Deeplabv3+ respectively. To further show the effectiveness of the proposed region rebalance method, we experiment with Swin transformer and BEIT. For CNN-based models, we achieve 47.96 mIoU with ResNet-101, surpassing the baseline by 1.61. With BEIT, the state-of-the-art is improved from 57.0 mIoU to 57.7 mIoU.</p><p>Comparison on COCO-Stuff164K. On the large-scale COCO-Stuff164K dataset, we again demonstrate the flexibility of our region rebalance module. The experimental results are summarized in <ref type="table" target="#tab_6">Table 4</ref>. Equipped with the region rebalance module in training, CNN-based models, i.e., ResNet-50, HRNet-W18, ResNet-101 and HRNet-W48, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Experiments</head><p>Ablation of region rebalance components. To verify the usefulness of both components in our region rebalance method, we conduct the following ablations on top of the baseline: I. only with an auxiliary region classification branch; II. further inserting a rebalance mechanism, i.e., balanced softmax <ref type="bibr" target="#b42">[43]</ref>. We plot the experimental results in <ref type="figure" target="#fig_11">Figure 7</ref>.</p><p>With the two components applied in training, we observe consistent improvements on ADE20K and the largescale COCO-Stuff164K. Additionally, an interesting phenomenon is observed: with only component I, deep models already enjoy significant gains on COCO-Stuff164K. The reason behind this may be that there is a much larger ratio between the pixel imbalance factor (PIF) and region imbalance factor (RIF) on COCO-Stuff164K than on ADE20K, as shown in <ref type="table" target="#tab_7">Table 5b</ref>. From this point of view, when adopting I, models are given stronger regularization and the out-    <ref type="figure">Figure 6</ref>: Illustrating the category-wise improvements with our region rebalance method: The IoUs of most lowfrequency classes are improved when the proposed region rebalance method is adopted in training. Class indexes are sorted in descending order by the number of pixels belonging to the same class.   put features are encouraged to be more balanced.</p><p>Improvements on low-frequency classes. To further examine the rebalancing effects of our proposed region rebalance method, we plot the class ?IoU between the baseline model and the model trained with the region rebalance method. <ref type="figure" target="#fig_2">Figure 3 (a)</ref> shows the results on ADE20K with ResNet-50 and Deeplabv3+. We also validate the rebalance effects on COCO-Stuff164K with different semantic segmentation methods, i.e., Deeplabv3+, OCRNet, and Uper-Net, as shown in <ref type="figure">Figure 6</ref>. We observe that the IoU of most low-frequency classes is enhanced. For example, the IoU of class "shower" is improved from 0 to 6.14 in ADE20K.</p><p>Ablation of hyper-parameter ?. In Eq. (9), we introduce the hyper-parameter ? for weighting between pixel loss and region loss. All experimental results in <ref type="table" target="#tab_5">Tables 3 and 4</ref> are reported for the same ? = 0.3.</p><p>To show the sensitivity of our region rebalance method Ablation on Dice loss. Though some IoU-based loss functions, e.g., Dice Loss <ref type="bibr" target="#b40">[41]</ref>, have been developed, we empirically observe that pixel cross-entropy is still necessary in training for high performance. An ablation on the Dice loss is conducted on ADE20K with ResNet-50 and Deeplabv3+, and the results are reported in <ref type="table" target="#tab_8">Table 6</ref>. With just the Dice Loss itself, the model achieves only 1.14 mIoU. This huge performance degradation implies that the pixel crossentropy is still a necessary part and the challenges in Sec. 3.1 will still exist when we conduct pixel rebalance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we investigate the imbalance phenomenon in semantic segmentation and identified two major challenges in conducting pixel rebalance, i.e., (i) misalignment between the training objective and the IoU evaluation metric at inference, and (ii) correlations among pixels within the same object/stuff cause class frequency to be less effective for rebalancing. With our analysis, we propose to gather correlated pixels into regions and rebalance within the context of region classification. The proposed region rebalance method leads to strong improvements across different semantic segmentation methods, e.g., OCRNet, DeepLabv3+, UperNet, and PSPNet. Experimental results on ADE20K and the large-scale COCO-Stuff164K verify the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proof of Remark 1</head><p>Before the pixel rebalance, for one low-frequency class y, we suppose its Acc and IoU are Acc = TP TP + FN ,</p><formula xml:id="formula_10">IoU = TP TP + FN + FP .<label>(10)</label></formula><p>With the pixel rebalance, we expect the Acc is improved to Acc ? (1 + K). Then the class Acc and IoU become</p><formula xml:id="formula_12">Acc r = TP ? (1 + K) TP ? (1 + K) + FN ? K ? TP = TP ? (1 + K) TP + FN ,<label>(12)</label></formula><p>IoU r = TP ? (1 + K) TP ? (1 + K) + FN ? K ? TP + FP r = TP ? (1 + K) TP + FN + FP r .</p><p>Taking the reciprocal of IoU r and IoU, we obtain </p><formula xml:id="formula_14">1 IoU r = TP ? (1 + K) + FN ? K ? TP + FP r TP ? (1 + K) = 1 + FN ? K ? TP + FP r TP ? (1 + K) ,<label>(14)</label></formula><p>To guarantee IoU ? IoU r , it should satisfy:</p><formula xml:id="formula_16">FN ? K ? TP + FP r ? (F N + F P ) ? (1 + K) ?? FP r ? (1 + K) ? FP ? K ? (TP + FN) = K ? n y ,<label>(16)</label></formula><p>where n y is the pixel frequency of class y.  C. How Does FP TP Make Effects on IoU and Acc?</p><p>As analyzed in Sec. 3.1, we examine the connections between IoU and Acc, i.e.,</p><formula xml:id="formula_17">1 IoU = 1 Acc + FP TP .<label>(17)</label></formula><p>To understand the role of FP TP , we plot the curves with respect to IoU and Acc with various constant value b = FP TP shown in <ref type="figure" target="#fig_14">Figure 8</ref>. We observe that, when b = FP TP is a smaller value around 0.0, e.g., b ? [0, 1], optimizing Acc is equal to optimizing IoU <ref type="figure" target="#fig_14">(Figure 8a</ref>). However, demonstrated by <ref type="figure" target="#fig_14">Figure 8b</ref>, when b = FP TP is a larger value, e.g., b ? 3, optimizing Acc will have little effect on IoU, especially when Acc has already achieved a high value, e.g., Acc = 0.6. This is just the reason that Acc is improved while IoU even decrease for low-frequency classes compared to the baseline in Sec. 3.1.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Visual Evidence for Region Rebalance vs. Pixel Rebalance</head><p>As demonstrated in Sec. 3.1.1, pixel rebalance improves Acc meanwhile increases FP significantly for low-frequency classes. As a result, IoU can not benefit from the pixel rebalance. In contrast, the proposed region rebalance is more aligned with the IoU metric. This phenomenon can be understood by considering the situation that two very different objects or stuff can still have similar local pixel features. Conducting pixel rebalance make it easy to let these similar pixels of other classes to be FP. Taking it into consideration that objects/stuff are more distinguishable at the region level because of the global features, predicting other class objects/stuff as FP will be much harder. We give visual evidence to our intuitive reasoning in <ref type="figure" target="#fig_15">Figure 9</ref>. As shown in highlighted regions with rectangle, pixels having similar texture with other object/stuff or around objects/stuff boundary are more likely to be FP with pixel rebalance. Region rebalance relieves this issue by using global region features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Quantitative Visualization Comparisons on ADE20K and COCO-Stuff164K</head><p>In this section, we demonstrate the advantages of region rebalance with quantitative visualizations on ADE20K and COCOStuff164K shwon in <ref type="figure" target="#fig_16">Figures 10, 11</ref> and 12.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>?IoU after rebalancing with our Region Rebalance method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>?IoU after pixel rebalance with balanced softmax<ref type="bibr" target="#b42">[43]</ref> ?Acc after pixel rebalance with balanced softmax<ref type="bibr" target="#b42">[43]</ref> Comparison between baseline and pixel rebalance with balanced softmax. Classes are sorted in descending order of pixel numbers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>20</head><label>20</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(c) Region accuracy on ADE20K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Class accuracy is positively correlated with class image frequency in image classification, while class accuracy has weak correlations with class pixel frequency due to correlations among neighboring pixels. Class indexes are sorted in descending order according to the number of images, pixels, or regions in the classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Comparison between pixel imbalance and region imbalance: (a) Histogram statistics of pixel/region frequency over sorted class indexes on ADE20K (left) and COCO-Stuff164K (right). (b) Numerical comparisons of pixel imbalance factor (PIF) and region imbalance factor (RIF). It can be seen that there is less region imbalance than pixel imbalance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>OCRNet w/ HRNet-W48.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>UperNet w/ ResNet-101.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 :</head><label>7</label><figDesc>Ablations for our region rebalance components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>FP) ? (1 + K) TP ? (1 + K).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>The effects of FP TP on IoU and Acc. with b = FP TP ? [0, 5].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 8 :</head><label>8</label><figDesc>The effects of FP TP on IoU and Acc.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 9 :</head><label>9</label><figDesc>Visualization comparisons between pixel rebalance and region rebalance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 10 :</head><label>10</label><figDesc>Visualization comparisons between baseline and region rebalance on ADE20K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 11 :</head><label>11</label><figDesc>Visualization comparisons between baseline and region rebalance on ADE20K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 12 :</head><label>12</label><figDesc>Visualization comparisons between baseline and region rebalance on COCO-Stuff164K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Pixel rebalance with balanced softmax<ref type="bibr" target="#b42">[43]</ref> and re-weighting on ADE20K. ResNet-50 and Deeplabv3+ are adopted. * denotes that region frequency prior is used for rebalance. IoU of low-frequency classes improves, we plot ?IoU and ?Acc for each class y. The ?IoU and ?Acc are calculated by ?IoU y = IoU rebalance</figDesc><table><row><cell>Method</cell><cell>mIoU(s.s.)</cell></row><row><cell>Baseline</cell><cell>43.95</cell></row><row><cell>Re-weighting</cell><cell>37.86</cell></row><row><cell>balancedsoftmax</cell><cell>38.57</cell></row><row><cell>balancedsoftmax*</cell><cell>40.66</cell></row><row><cell>RR (Ours)</cell><cell>45.02</cell></row><row><cell>classes drops a lot though</cell><cell></cell></row></table><note>y ? IoU baseliney ,</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Pearson coefficients between class frequency and accuracy.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>ADE20K [66] is a challenging dataset often used to validate transformer-based neural networks on down-stream tasks such as semantic segmentation. It contains 22K densely annotated images with 150 fine-grained semantic concepts. The training and validation sets consist of 20K and 2K images, respectively. COCO-Stuff164K. COCO-Stuff164K [8] is a large-scale scene understanding benchmark that can be used for evaluating semantic segmentation, object detection, and image captioning. It includes all 164K images from COCO 2017. The training and validation sets contain 118K and 5K images, respectively. It covers 171 classes: 80 thing classes and 91 stuff classes.</figDesc><table><row><cell>and BEIT [3].</cell></row><row><cell>4.1. Datasets</cell></row><row><cell>ADE20K.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Performance on ADE20K.</figDesc><table><row><cell>Method</cell><cell cols="3">Backbone mIoU(s.s.) mIoU(m.s.)</cell></row><row><cell>OCRNet</cell><cell cols="2">HRNet-W18 39.32</cell><cell>40.80</cell></row><row><cell>OCRNet-RR</cell><cell cols="3">HRNet-W18 41.80 43.55(+2.75)</cell></row><row><cell>UPerNet</cell><cell>ResNet-50</cell><cell>42.05</cell><cell>42.78</cell></row><row><cell>UPerNet-RR</cell><cell>ResNet-50</cell><cell cols="2">43.27 44.03(+1.25)</cell></row><row><cell>PSPNet</cell><cell>ResNet-50</cell><cell>42.48</cell><cell>43.44</cell></row><row><cell>PSPNet-RR</cell><cell>ResNet-50</cell><cell cols="2">42.83 44.26(+0.82)</cell></row><row><cell>DeepLabv3+</cell><cell>ResNet-50</cell><cell>43.95</cell><cell>44.93</cell></row><row><cell cols="2">DeepLabv3+-RR ResNet-50</cell><cell cols="2">45.02 46.03(+1.10)</cell></row><row><cell>OCRNet</cell><cell cols="2">HRNet-W48 43.25</cell><cell>44.88</cell></row><row><cell>OCRNet-RR</cell><cell cols="3">HRNet-W48 44.50 46.09(+1.21)</cell></row><row><cell>UperNet</cell><cell>ResNet-101</cell><cell>43.82</cell><cell>44.85</cell></row><row><cell>UperNet-RR</cell><cell>ResNet-101</cell><cell cols="2">44.78 46.11(+1.26)</cell></row><row><cell>PSPNet</cell><cell>ResNet-101</cell><cell>44.39</cell><cell>45.35</cell></row><row><cell>PSPNet-RR</cell><cell>ResNet-101</cell><cell cols="2">44.65 46.15(+0.80)</cell></row><row><cell>DeepLabv3+</cell><cell>ResNet-101</cell><cell>45.47</cell><cell>46.35</cell></row><row><cell cols="2">DeepLabv3+-RR ResNet-101</cell><cell cols="2">46.67 47.96(+1.61)</cell></row><row><cell>UperNet</cell><cell>Swin-T</cell><cell>44.51</cell><cell>45.81</cell></row><row><cell>UperNet-RR</cell><cell>Swin-T</cell><cell cols="2">45.02 46.45(+0.64)</cell></row><row><cell>UperNet</cell><cell>Swin-B ?</cell><cell>50.04</cell><cell>51.66</cell></row><row><cell>UperNet-RR</cell><cell>Swin-B ?</cell><cell cols="2">51.20 52.88(+1.22)</cell></row><row><cell>UperNet</cell><cell>BEIT-L</cell><cell>56.7</cell><cell>57.0</cell></row><row><cell>UperNet-RR</cell><cell>BEIT-L</cell><cell>57.2</cell><cell>57.7(+0.70)</cell></row><row><cell cols="4">augmentations [16]. For inference, we report the perfor-</cell></row><row><cell cols="4">mance of both single scale (s.s.) inference and multi-scale</cell></row><row><cell cols="4">(m.s.) inference with horizontal flips and scales of 0.5, 0.75,</cell></row><row><cell cols="2">1.0, 1.25, 1.5, 1.75.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Performance on COCOStuff-164K.</figDesc><table><row><cell>Method</cell><cell cols="3">Backbone mIoU(s.s.) mIoU(m.s.)</cell></row><row><cell>OCRNet</cell><cell cols="2">HRNet-W18 31.58</cell><cell>32.34</cell></row><row><cell>OCRNet-RR</cell><cell cols="3">HRNet-W18 37.98 38.78(+6.44)</cell></row><row><cell>UperNet</cell><cell>ResNet-50</cell><cell>39.86</cell><cell>40.26</cell></row><row><cell>UperNet-RR</cell><cell>ResNet-50</cell><cell cols="2">41.20 41.73(+1.47)</cell></row><row><cell>PSPNet</cell><cell>ResNet-50</cell><cell>40.53</cell><cell>40.75</cell></row><row><cell>PSPNet-RR</cell><cell>ResNet-50</cell><cell cols="2">41.92 42.34(+1.95)</cell></row><row><cell>DeepLabv3+</cell><cell>ResNet-50</cell><cell>40.85</cell><cell>41.49</cell></row><row><cell cols="2">DeepLabv3+-RR ResNet-50</cell><cell cols="2">42.66 43.47(+1.89)</cell></row><row><cell>OCRNet</cell><cell cols="2">HRNet-W48 40.40</cell><cell>41.66</cell></row><row><cell>OCRNet-RR</cell><cell cols="3">HRNet-W48 41.83 43.29(+1.36)</cell></row><row><cell>UperNet</cell><cell>ResNet-101</cell><cell>41.15</cell><cell>41.51</cell></row><row><cell>UperNet-RR</cell><cell>ResNet-101</cell><cell cols="2">42.30 42.78(+1.27)</cell></row><row><cell>PSPNet</cell><cell>ResNet-101</cell><cell>41.95</cell><cell>42.42</cell></row><row><cell>PSPNet-RR</cell><cell>ResNet-101</cell><cell cols="2">43.40 43.85(+1.43)</cell></row><row><cell>DeepLabv3+</cell><cell>ResNet-101</cell><cell>42.39</cell><cell>42.96</cell></row><row><cell cols="2">DeepLabv3+-RR ResNet-101</cell><cell cols="2">43.93 44.62(+1.66)</cell></row><row><cell>UperNet</cell><cell>Swin-T</cell><cell>43.83</cell><cell>44.58</cell></row><row><cell>UperNet-RR</cell><cell>Swin-T</cell><cell cols="2">44.45 45.18(+0.60)</cell></row><row><cell>UperNet</cell><cell>Swin-B ?</cell><cell>47.67</cell><cell>48.57</cell></row><row><cell>UperNet-RR</cell><cell>Swin-B ?</cell><cell cols="2">48.21 49.20(+0.63)</cell></row><row><cell cols="4">surpass their baselines by a large margin. Specifically, with</cell></row><row><cell cols="4">HRNet-18 and OCRNet, our trained model outperforms the</cell></row><row><cell cols="4">baseline by 6.44 mIoU. With the large CNN-based ResNet-</cell></row><row><cell cols="4">101 and Deeplabv3+, our model achieves 44.62 mIoU, sur-</cell></row><row><cell cols="3">passing the baseline by 1.66 mIoU.</cell><cell></cell></row><row><cell cols="4">We also verify the effectiveness of the region rebal-</cell></row><row><cell cols="4">ance module with Swin transformer on COCO-Stuff164K.</cell></row><row><cell cols="4">Experimental results with Swin-T and Swin-B show clear</cell></row><row><cell cols="4">improvements after rebalancing with our region rebalance</cell></row><row><cell cols="2">method in the training phase.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Ablation on hyper-parameter ?.</figDesc><table><row><cell>Hyper-parameter ?</cell><cell>mIoU(s.s.)</cell></row><row><cell>? = 0.0 (baseline)</cell><cell>43.95</cell></row><row><cell>? = 0.1</cell><cell>44.61</cell></row><row><cell>? = 0.2</cell><cell>44.85</cell></row><row><cell>? = 0.3</cell><cell>45.02</cell></row><row><cell>? = 0.4</cell><cell>44.64</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Ablation on Dice loss. values, we conduct an ablation with ResNet-50 and Deeplabv3+ on ADE20K.Table 5lists the experimental results, showing that the performance is not affected substantially by the value of ? within the range [0.1,0.3].</figDesc><table><row><cell>Method</cell><cell>mIoU(s.s.)</cell></row><row><cell>Baseline (cross-entropy)</cell><cell>43.95</cell></row><row><cell>Dice Loss</cell><cell>1.14</cell></row><row><cell>Dice Loss + cross-entropy</cell><cell>44.12</cell></row><row><cell>RR (Ours)</cell><cell>45.02</cell></row><row><cell>to different ?</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Gated feedback refinement network for dense image labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrigank</forename><surname>Md Amirul Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rochan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangbo</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.08254</idno>
		<title level="m">Beit: Bert pre-training of image transformers</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Yiteng Huang, and Israel Cohen. Pearson correlation coefficient. In Noise reduction in speech processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Benesty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A systematic study of the class imbalance problem in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuto</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej A</forename><surname>Mazurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A systematic study of the class imbalance problem in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuto</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><forename type="middle">A</forename><surname>Mazurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">What is the effect of importance weighting in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cocostuff: Thing and stuff classes in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning imbalanced datasets with labeldistribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning imbalanced datasets with labeldistribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SMOTE: Synthetic minority oversampling technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">W</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">O</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Philip</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semantic image segmentation with deep convolutional nets and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Rethinking atrous convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05587</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">MMSegmentation: Openmmlab semantic segmentation toolbox and benchmark</title>
		<ptr target="https://github.com/open-mmlab/mmsegmentation,2020" />
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Reslt: Residual learning for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.10633</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Parametric contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<title level="m">Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">LVIS: A dataset for large vocabulary instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning from imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibo</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Edwardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Piotr Doll?r, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning deep representation for imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep imbalanced learning for face recognition and attribute prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Change</forename><surname>Loy Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning deep representation for imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rethinking classbalanced methods for long-tailed visual recognition from a domain adaptation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The class imbalance problem: A systematic study. Intelligent Data Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathalie</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaju</forename><surname>Stephen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.09217</idno>
		<title level="m">Jiashi Feng, and Yannis Kalantidis. Decoupling representation and classifier for long-tailed recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Overcoming classifier imbalance for long-tail object detection with balanced group softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jintao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Refinenet: Multi-path refinement networks for highresolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Path aggregation network for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifang</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">V-net: Fully convolutional neural networks for volumetric medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fausto</forename><surname>Milletari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seyed-Ahmad</forename><surname>Ahmadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Full-resolution residual networks for semantic segmentation in street scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Pohlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Mathias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Balanced meta-softmax for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunjun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunan</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Bin Yang, and Raquel Urtasun. Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Relay backpropagation for effective learning of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Meta-weight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Equalization loss for long-tailed object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingru</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changbao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Longtailed classification by keeping the good and removing the bad momentum causal effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2020</title>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Longtailed classification by keeping the good and removing the bad momentum causal effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Training data-efficient image transformers &amp; distillation through attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaorui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Seesaw loss for longtailed instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Long-tailed recognition by routing diverse distribution-aware experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LCLR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Unified perceptual parsing for scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tete</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Objectcontextual representations for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Towards good practices for recognition &amp; detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR workshops</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Improving calibration for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Min</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.02413</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Scene parsing through ade20k dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adela</forename><surname>Barriuso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Experiments on COCO-Stuff10K for Semantic Segmentation COCO-Stuff10K, which includes 10K images from the COCO training set, is a subset of COCO-Stuff164K. The training and validation sets consist of 9K and 1K images, respectively. It also covers 171 classes. The experimental results are reported in Table 7. Employing our region rebalance module in training yields 1.18 mIoU and 1.19 mIoU improvements separately when compared with the baselines</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note>Region Rebalance for Long-Tailed Semantic Segmentation Supplementary Material A</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Method Backbone mIoU(s.s.) mIoU(m.s.)</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
