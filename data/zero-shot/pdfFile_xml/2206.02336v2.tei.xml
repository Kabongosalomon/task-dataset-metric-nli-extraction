<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On the Advance of Making Language Models Better Reasoners</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifei</forename><surname>Li</surname></persName>
							<email>yifeili@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University ? Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
							<affiliation key="aff0">
								<orgName type="institution">Peking University ? Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeqi</forename><surname>Lin</surname></persName>
							<email>zeqi.lin@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University ? Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhuo</forename><surname>Zhang</surname></persName>
							<email>shizzhang@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University ? Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Fu</surname></persName>
							<email>qifu@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University ? Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Chen</surname></persName>
							<email>bei.chen@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University ? Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
							<email>jlou@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University ? Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
							<email>wzchen@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University ? Microsoft Corporation</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">On the Advance of Making Language Models Better Reasoners</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models such as GPT-3 and PaLM have shown remarkable performance in few-shot learning. However, they still struggle with reasoning tasks such as the arithmetic benchmark GSM8K. Recent advances deliberately guide the language model to generate a chain of reasoning steps before producing the final answer, successfully boosting the GSM8K benchmark from 17.9% to 58.1% in terms of problem solving rate. In this paper, we propose a new approach, DIVERSE (Diverse Verifier on Reasoning Step), to further advance their reasoning capability. DIVERSE first explores different prompts to enhance the diversity in reasoning paths. Second, DIVERSE introduces a verifier to distinguish good answers from bad answers for a better weighted voting. Finally, DIVERSE verifies the correctness of each single step rather than all the steps in a whole. We conduct extensive experiments using the latest language model code-davinci-002 and demonstrate that DI-VERSE can achieve new state-of-the-art performance on six out of eight reasoning benchmarks (e.g., GSM8K 74.4% ? 83.2%), outperforming the PaLM model with 540B parameters.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large-scale pretrained language models have recently exhibit exceptional performance in either few-shot learning with prompt <ref type="bibr" target="#b41">(Radford et al., 2019;</ref><ref type="bibr" target="#b28">Le Scao and Rush, 2021;</ref><ref type="bibr" target="#b23">Jin et al., 2022)</ref> or fine-tuning <ref type="bibr" target="#b19">(Houlsby et al., 2019;</ref><ref type="bibr" target="#b20">Hu et al., 2021;</ref><ref type="bibr" target="#b16">He et al., 2022)</ref>. Gigantic models such as the GPT-3 with 175B parameters <ref type="bibr">(Brown et al., 2020)</ref> and the PaLM with 540B parameters <ref type="bibr" target="#b7">(Chowdhery et al., 2022)</ref> continue to demonstrate their remarkable * Work was done during an internship at Microsoft Research Asia. Experiments were conducted by the second author.</p><p>performance on a variety of tasks using the fewshot paradigm. However, as illustrated by <ref type="bibr">Cobbe et al. (2021)</ref>, all these models are still struggling to produce reasonable performance in various reasoning tasks, often requiring multiple steps to produce correct answers.</p><p>Recent progresses <ref type="bibr" target="#b51">(Wei et al., 2022;</ref><ref type="bibr">Kojima et al., 2022;</ref><ref type="bibr" target="#b27">Lampinen et al., 2022)</ref> point out that large pretrained language models have already built in reasoning capabilities although they need design specific prompts to unleash their power. For example, <ref type="bibr" target="#b51">Wei et al. (2022)</ref> proposes the insertion of multi-step reasoning paths before generating the final answers, calling their approach chain-of-thought reasoning. Using the GSM8K <ref type="bibr">(Cobbe et al., 2021)</ref> arithmetic benchmark as an example, their prompting technique improves the accuracy from 17.9% to 58.1%. As a follow-up, <ref type="bibr">Wang et al. (2022c)</ref> continues to introduce a voting mechanism to produce a more accurate answer and boost the performance of GSM8K to 74.4% with the help of the PaLM model containing 540 billion parameters <ref type="bibr" target="#b7">(Chowdhery et al., 2022)</ref>. Built on top of all these successes, this paper is a continuation of this line of research, with the focus on advancing the reasoning capabilities using gigantic language models in following three areas.</p><p>First, motivated by "people think differently, while different thoughts often lead to the same correct answer", <ref type="bibr">Wang et al. (2022c)</ref> proposed self-consistency, i.e., sampling different reasoning paths from the language model, then returning the most consistent final answer by majority voting. We continue to advocate the ideas of diversity and "All Roads Lead to Rome". However, besides using sampling with a single prompt to produce multiple reasoning paths, we propose to introduce the diversity in the prompt as a complementary solution to produce a higher degree of diversity.</p><p>Second, when generating a reasoning path, causal language models have no mechanism to cor-arXiv:2206.02336v2 [cs.CL] 7 Jun 2022</p><p>Prompt &amp; Samples Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot? A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5. ... Q: Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder for $2 per egg. How much does she make every day? A:</p><p>[Sample 1] She has 16 -3 -4 = 9 eggs left. So she makes 2 * 9 =18 per day. The answer is 18. ( ) [Sample 2] This means she uses 3 + 4 = 7 eggs every day. So in total she sells 7 * 2 =14 per day. The answer is 14. ( ) [Sample 3] She eats 3 for breakfast, so she has 16 -3 = 13 left. Then she bakes muffins, so 13 -4 = 9 eggs left. She makes 9 * $2 = $18. The answer is 18. ( ) <ref type="figure">Figure 1</ref>: Prompting large language models to generate different reasoning paths, then selecting the final answer via majority voting <ref type="bibr">(Wang et al., 2022c).</ref> rect previous errors in earlier steps which quickly leads to disorientated results. <ref type="bibr">Cobbe et al. (2021)</ref> proposes using a verifier to judge the correctness of each reasoning path, thereby improving the GSM8K accuracy from 33% to 57%. Inspired by their success, we introduce the verifier mechanism to guide the voting mechanism in <ref type="bibr">Wang et al. (2022c)</ref>. In other words, we believe "not all reasoning paths are equal or good" and use the verifier to score the votes.</p><p>Third, as an answer is generated based on the reasoning of multiple steps, when a correct answer is generated, we conjecture all the steps are contributing to the final correctness. However, when a wrong answer is generated, it does not mean all the steps are wrong or contribute to the wrongness. In other words, some steps could still be correct but some follow-up off-course steps result in a final wrong answer. With this motivation, we design a mechanism to assign a fine-grained label to each step and propose a step-aware verifier and attribute the correctness to each single step.</p><p>Based on the three key insights, we name this novel method as DIVERSE (diverse verifier on reasoning step). We conduct extensive experiments with analysis using three OpenAI lan- <ref type="bibr">[STRATEGYQA]</ref> Yes or no: Could a llama birth twice during War in <ref type="bibr">Vietnam (1945-46)</ref>? The War in Vietnam was 6 months. The gestation period for a llama is 11 months. So a llama could not give birth twice during the War in Vietnam. The answer is no.</p><p>[CLUTRR] Roy was eating lunch with his son John and his wife Mary. What kind of relative is John to Mary? John is the son of Roy. Roy is the husband of Mary. Thus, John is the son of Mary. The answer is son. guage models (davinci, text-davinci-002, and codedavinci-002) on eight tasks requiring different reasoning skills (arithmetic reasoning, commonsense reasoning, and inductive reasoning). Experimental results clearly demonstrate that DI-VERSE can bring significant and consistent improvements on these datasets, comparing to recent state-of-the-art (SOTA) works. Furthermore, DIVERSE also empowers code-davinci-002 to achieve new state-of-the-art results on 6 of the 8 benchmarks 1 : GSM8K (74.4% ? 83.2%), AsDiv (81.9% ? 88.7%), MultiArith (99.3% ? 99.8%), SVAMP(86.6% ? 87.0%), SingleEq (79.5% ? 94.9%), and CLUTRR (67.0% ? 95.9%). We will make our data publicly available at https: //github.com/microsoft/DiVeRSe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>Prompting. Prompting means prepending a few exemplars to the task input x and generating the output y from the pretrained language model:</p><formula xml:id="formula_0">p(y|C, x) = |y| t=1 p LM (y t |C, x, y &lt;t ),<label>(1)</label></formula><p>where C is the concatenation of K exemplars:</p><formula xml:id="formula_1">C = (x 1 , y 1 ); (x 2 , y 2 ); ...; (x K , y K ). (2)</formula><p>We denote prompt as the concatenation of the exemplars C and the input x.</p><p>Reasoning Paths. For reasoning tasks that aim to generate an answer y for a question x, <ref type="bibr" target="#b51">Wei et al. (2022)</ref> proposed the insertion of a reasoning path z before generating the answer y: where z i is a text reasoning path of how the answer y i is reasoned step-by-step for question x i . Then, during inference, a reasoning path z will be generated before the answer y: <ref type="figure">Figure 1</ref> demonstrates this idea in arithmetic reasoning (GSM8K), and <ref type="table" target="#tab_0">Table 1</ref> demonstrates this idea in commonsense reasoning (StrategyQA) and inductive reasoning (CLUTRR).</p><formula xml:id="formula_2">C = (x 1 , z 1 , y 1 ); ...; (x K , z K , y K ),<label>(3)</label></formula><formula xml:id="formula_3">p(y|C , x) = p(z|C , x) ? p(y|C , x, z). (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Diverse Verifier on Reasoning</head><p>Step <ref type="figure" target="#fig_0">Figure 2</ref> shows the overview of DIVERSE. The key insights are three-fold: (1) leveraging diverse prompts to induce more diverse reasoning paths from the language models (Section 3.1); (2) training a voting verifier to better derive the final answers from multiple reasoning paths (Section 3.2);</p><p>(3) leveraging step correctness to further boost the voting verifier (Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Diverse Prompts</head><p>Reasoning can be boosted by exploiting diverse reasoning paths, just as "All Roads lead to Rome". <ref type="bibr">Wang et al. (2022c)</ref> proposed to generate different reasoning paths from language models by sampling decoding. However, it uses a fixed collection of exemplars for all prompts. These fixed exemplars may bias the generation, thus limiting the diversity of the generated reasoning paths.</p><p>To mitigate this, we propose to provide M 1 different prompts for each question, then sample M 2 reasoning paths for each prompt. Therefore, we get M = M 1 ? M 2 diverse reasoning paths for each question. Our main experiments use M 1 = 5 and M 2 = 20.</p><p>A critical issue is how to provide diverse prompts 2 . Supposing that there is an exemplar base E, we can sample K exemplars from it to construct a prompt, and repeat this M 1 times independently to construct M 1 prompts with diverse exemplars.</p><p>For scenarios that do not have sufficient exemplars (i.e., |E| &lt; K * M 1 ), we propose to bootstrap the diversity of prompts by "selfteaching", i.e., generating pseudo reasoning paths from a few exemplars and some question, answer pairs without reasoning paths 3 . Suppose that D is a dataset without reasoning paths, consisting of (x, y * ) pairs. Given the small exemplar base E, for each (x, y * ) ? D, we can use prompting to generate a reasoning path z and the predicted answer y. We define the pseudo exemplar base E as:</p><formula xml:id="formula_4">E = {(x, z, y)|(x, y * ) ? D, y = y * },<label>(5)</label></formula><p>then E ? E can be regarded as the new exemplar base for generating diverse prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Voting Verifier</head><p>Wang et al. (2022c) uses majority voting to conclude the agreement? of different reasoning paths:</p><formula xml:id="formula_5">y = arg max y M i=1 1 y i =y ,<label>(6)</label></formula><p>where y i represents the answer of the i-th reasoning path, and 1 y i =y is an indicator function that returns 1 (or 0) if y i = y (or not). This vanilla method has its limitations when reasonable minority solutions are overwhelmed by disorientated majority solutions.</p><p>Verifier. Sample-then-rank is a widely-used strategy in sequence-to-sequence generation <ref type="bibr">Cobbe et al., 2021)</ref>, i.e., generating multiple candidate output sequences, leveraging a verifier to rank them, then taking the top-ranked sequence as the final result. This strategy can be easily applied in our scenario. Concretely, we can define the final answer? as:</p><formula xml:id="formula_6">y = arg max y i f (x i , z i , y i ),<label>(7)</label></formula><p>where f (?) is the verifier. Without loss of generality, we implement the verifier as a binary classifier based on deberta-v3-large :</p><formula xml:id="formula_7">f (x i , z i , y i )</formula><p>is the predicted probability of the positive label, given the concatenation of x i , z i , and y i as the text input. The verifier is trained through steps as follows:</p><p>1. Initialize the train setD as ?.</p><p>2. For each (x, z, y) in the exemplar base E (or E?E ), we prompt the language model to gen-</p><formula xml:id="formula_8">erate diverse results (z 1 , y 1 ), ..., (z M , y M ). We add (x, z i , y i ), 1 toD if y i = y, other- wise we add (x, z i , y i ), 0 toD.</formula><p>3. Train the verifier f (?) with the loss function:</p><formula xml:id="formula_9">L 0 = |D| i=1 BCE(label i , f (input i )),<label>(8)</label></formula><p>where BCE means binary cross-entropy loss, input i , label i represents the i-th item inD.</p><p>Voting Verifier. We propose voting verifier, which combines the advantages of voting and verifier. Concretely, we combine Equation 6 and Equation 7 to a new version:</p><formula xml:id="formula_10">y = arg max y M i=1 1 y i =y ? f (x i , z i , y i ). (9)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Step-aware Voting Verifier</head><p>Each reasoning path consists of several steps. When a reasoning path gives an incorrect answer, we conjecture not all the steps are contributing to the final wrongness. With this motivation, we propose to extend the voting verifier to a step-aware voting verifier by introducing an extended loss function: Figure 3: How we get the step-level labels. Sample 2 is incorrect, but its first step is correct. The reason is: the intermediate result <ref type="formula" target="#formula_6">(7)</ref> matches with the first step of Sample 1, a correct reasoning path.</p><formula xml:id="formula_11">L = L 0 + ? ? L 1 , L 1 = |D| i=1 |S i | j=1 BCE(label i,j , f (input i , j)),<label>(10)</label></formula><p>where ? is a hyperparameter to combine L 0 and the step-level auxiliary loss L 1 ;</p><formula xml:id="formula_12">S i,1 , S i,2 , ..., S i,|S i | are mutiple steps in z i ; label i,j represents whether S i,j is correct or not; f (input i , j)</formula><p>represents the probability of the positive label for S i,j 4 . A critical issue is how to get the step-level labels (i.e., label i,j ) for negative training data with wrong answers. We propose to address this issue through a "cross-validation" method. <ref type="figure">Figure 3</ref> demonstrates an example of this idea. Concretely: label i,j = 1 if and only if ?1 ? k ? |D|(k = i) and c ? j, s.t. label k = 1 and S k,1 , ..., S k,c "supports" S i,1 , ..., S i,c . In different tasks, "supports" can be defined differently: for arithmetic tasks, it means the set of intermediate results of S k,1 , ..., S k,c is the same as that of S i,1 , ..., S i,c ; for other tasks, it means: ?1 ? r ? c, S k,r and S i,r are semantically equivalent 5 .  <ref type="bibr" target="#b42">(Roy and Roth, 2015)</ref>, SVAMP <ref type="bibr" target="#b38">(Patel et al., 2021)</ref>, and GSM8K <ref type="bibr">(Cobbe et al., 2021)</ref>.</p><p>Commonsense Reasoning. Following <ref type="bibr">Wang et al. (2022c)</ref>, we use CommonsenseQA <ref type="bibr" target="#b46">(Talmor et al., 2019)</ref> and StrategyQA <ref type="bibr" target="#b15">(Geva et al., 2021)</ref>.</p><p>Inductive Reasoning. The definition of the term "inductive learning" could be stated as: given a   training set of objects whose classes are known, find a rule for predicting the class of an unseen object as a function of its attribute values (Quinlan, 1990). We use CLUTRR <ref type="bibr" target="#b45">(Sinha et al., 2019)</ref>, a diagnostic benchmark for inductive reasoning from text, requiring natural language understanding (NLU) systems to infer kinship relations between characters in short stories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Details</head><p>Language Models. We use three OpenAI language models: davinci, text-davinci-002 and codedavinci-002. We use the default parameters except a temperature of 0.5 for sampling decoding.</p><p>Exemplars. For arithmetic/commonsense/inductive reasoning, each prompt contains 5/7/7 exemplars. For DIVERSE, each question has 5 different prompts, and 20 reasoning paths are sampled from the language model for each prompt. For arithmetic reasoning, the exemplars are randomly sampled from the training dataset of GSM8K; for CLUTRR, the exemplars are sampled from its training dataset, with reasoning paths synthesized by handcraft rules; for StrategyQA and Common-senseQA, we construct 1, 000 pseudo exemplars by "self-teaching" (Section 3.1) from the 7 "seed" exemplars provided by <ref type="bibr" target="#b51">Wei et al. (2022)</ref>.</p><p>Datasets without Reasoning Paths. For each task, we sample 1, 000 question, answer pairs from the training dataset to train the verifier.</p><p>Verifier. We fine-tune deberta-v3-large  with learning rate 1 ? 10 ?5 and batch size 128. For the step-aware verifier, we select the best ? among 0.0/0.1/0.2/0.3. <ref type="table">Table 2</ref> shows the overall experimental results. We mainly compare DIVERSE with two baselines: (1) greedily decoding a single reasoning path <ref type="bibr" target="#b51">(Wei et al., 2022)</ref>, referred to as Greedy Decode;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Main Results</head><p>(2) sampling decoding 100 reasoning paths, then select the final answer via majority voting <ref type="bibr">(Wang et al., 2022c)</ref>, referred to as Self-Consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Effectiveness</head><p>Experimental results clearly demonstrate that DI-VERSE can bring significant and consistent improvements over recent strong baselines. The improvements are across different models (davinci, text-davinci-002 and code-davinci-002) as well as different reasoning skills (eight tasks for three reasoning skills). Taking GSM8K as an example, compared to Greedy Decoding and Self-Consistency, DIVERSE brings improvements of 22.2%/12.0% on davinci, 33.1%/12.0% on text-davinci-002, and 27.0%/5.6% on code-davinci-002. Compared to Self-Consistency, DIVERSE achieves average improvements of 5.6%/5.1%/54.3% on the three reasoning skills, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Comparing to Previous SOTAs</head><p>In <ref type="table">Table 2</ref>, we also compare DIVERSE with: (1) previous SOTA results based on fine-tuning;</p><p>(2) recent SOTA results <ref type="bibr" target="#b51">(Wei et al., 2022)</ref> based on PaLM <ref type="bibr" target="#b7">(Chowdhery et al., 2022)</ref>, a gigantic lan-guage model with 540 billion parameters 6 . On all the five arithmetic reasoning tasks, DI-VERSE (with code-davinci-002) achieves new SOTA results, with an average improvement of 6.2%. On the two commonsense reasoning tasks, the performance of DIVERSE is slightly lower (?2.2%) than that of PaLM-based self-consistency. We speculate that the reason might be: these two commonsense reasoning tasks are multiple choice tasks rather than open-ended generation tasks, resulting in more false-positive exemplars in the pseudo exemplar base (Section 3.1). Details will be discussed in Section 5.3. Regarding inductive reasoning, DIVERSE achieves a surprisingly good performance of 95.9% on the CLUTRR task, outperforming (+28.9%) the previous SOTA result with fine-tuning <ref type="bibr">(Sinha et al., 2019) 7</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Noises in Multiple Choice Tasks</head><p>In our experimental setup, StrategyQA and Com-monsenseQA are a bit more challenging than other tasks, as they use pseudo exemplars generated through "self-teaching" (Section 3.1).</p><p>"Self-teaching" may lead to bad exemplars, whose reasoning paths are invalid but happen to yield answers coinciding with the ground truth. Questions in StrategyQA and CommonsenseQA are two-choice and four-choice questions, respectively. Therefore, such noise would be more serious in StrategyQA than in CommonsenseQA. This somehow explains why DIVERSE can achieve comparable performance (?0.8%) as the PaLMbased SOTA on CommonsenseQA, while it sees a 3.9% performance decline to PaLM on Strate-gyQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Ablations</head><p>We also conduct ablation experiments and analysis to investigate the keys to the success of DIVERSE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Diverse Prompts vs. Sampling Decoding</head><p>To evaluate the effectiveness of diverse prompts, we compare M 1 = 5, M 2 = 20 with M 1 = 1, M 2 = 100 (i.e., sampling decoding used by selfconsistency), both of which use majority voting.     <ref type="table" target="#tab_5">Table 3</ref> shows that, the performance is significantly and consistently boosted, by introducing diverse prompts as a complementary solution to produce higher degree of diversity.</p><p>We also conduct more experiments with different M 1 , M 2 (M 1 ? M 2 = 100) settings on GSM8K to further investigate the impact of diverse prompts. <ref type="table" target="#tab_6">Table 4</ref> shows the results. We show neither pure diverse prompts nor pure sampling decoding is the best setup. In other words, we need to combine diverse prompts with sampling decoding as a complementary solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">The Power of Voting Verifier</head><p>We compare three algorithms to conclude the agreement from diverse reasoning paths: majority voting, verifier, and voting verifier. <ref type="table" target="#tab_8">Table 5</ref> shows the results. Comparing to majority voting, our voting verifier can significantly and consistently boost the reasoning performance across different tasks and different language models. Verifier without voting often outperforms majority voting, but extending it to voting verifier can further boost the performance.   <ref type="table">Table 6</ref>: The effectiveness of step-aware voting verifier, with M 1 , M 2 = 5, 20 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">The Impact of</head><p>Step-aware Voting Verifier <ref type="table">Table 6</ref> compares the performance of DIVERSE with / without step-level information in its voting verifier. We observe that, extending the voting verifier to a step-aware version can bring performance gains in most of the experiments. For code-davinci-002 on GSM8K, the step-aware version leads to slightly performance drop. We conjecture codedavinci-002 is more powerful and can generate higher quality reasoning paths for GSM8K, thus reducing the necessity of step-level information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">How Many Diverse Outputs Do We</head><p>Need? <ref type="figure" target="#fig_4">Figure 4</ref> compares the accuracy at different M . For each question, we generate 100 reasoning paths, then sample M reasoning paths from them to generate the final answer. We observe that: (1) more reasoning paths lead to better performance, but marginal effects start to appear at M ? 50;</p><p>(2) DIVERSE performs significantly and consistently better than self-consistency at different M values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">How Many Training Data Do We Need?</head><p>DIVERSE requires a dataset without reasoning paths for training the verifier. <ref type="figure" target="#fig_5">Figure 5</ref> shows how the size of this dataset affects the performance. We observe that: the performance is only reduced by about 2%, even if the size of training data is cut by 75% (from 1, 000 to 250). With the same reasoning paths, voting verifier performs better than majority voting, while verifier without voting causes significant performance drops.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">The Impact of the Number of Exemplars</head><p>We conduct experiments for k = 3/5/8 (k means how many exemplars are used in each prompt) on GSM8K. <ref type="figure" target="#fig_6">Figure 6</ref> shows the results. We observe that: using 8 exemplars in each prompt can further boost the accuracy of GSM8K to 83.2%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Reasoning Skills. Researchers in the literature have proposed many benchmarks requiring various reasoning skills, including commonsense reasoning <ref type="bibr" target="#b57">(Zellers et al., 2018;</ref><ref type="bibr" target="#b46">Talmor et al., 2019;</ref><ref type="bibr" target="#b3">Bhagavatula et al., 2019;</ref><ref type="bibr" target="#b15">Geva et al., 2021)</ref> numerical reasoning <ref type="bibr" target="#b12">(Dua et al., 2019)</ref>, multi-hop reasoning <ref type="bibr" target="#b53">(Yang et al., 2018)</ref>, arithmetic reasoning <ref type="bibr" target="#b25">(Koncel-Kedziorski et al., 2015;</ref><ref type="bibr" target="#b42">Roy and Roth, 2015;</ref><ref type="bibr" target="#b34">Miao et al., 2020;</ref><ref type="bibr" target="#b38">Patel et al., 2021;</ref><ref type="bibr">Cobbe et al., 2021)</ref>, logical reasoning <ref type="bibr" target="#b31">(Liu et al., 2020;</ref><ref type="bibr" target="#b55">Yu et al., 2020)</ref>, inductive reasoning <ref type="bibr" target="#b45">(Sinha et al., 2019)</ref> and tabular reasoning . Reasoning with Symbolic Systems. Much research in the literature enhances the reasoning capabilities of machine learning systems by exploiting symbolic systems, including knowledge graphs <ref type="bibr" target="#b35">(Mihaylov and Frank, 2018;</ref><ref type="bibr" target="#b2">Bauer et al., 2018;</ref><ref type="bibr" target="#b26">Kundu et al., 2019;</ref><ref type="bibr" target="#b29">Lin et al., 2019;</ref><ref type="bibr" target="#b11">Ding et al., 2019;</ref><ref type="bibr" target="#b49">Wang et al., 2022b)</ref>, or question taxonomies <ref type="bibr" target="#b12">(Dua et al., 2019;</ref><ref type="bibr" target="#b0">Andor et al., 2019;</ref><ref type="bibr" target="#b22">Hu et al., 2019b;</ref><ref type="bibr" target="#b47">Wang et al., 2022a)</ref>. Although these methods work well on specific benchmarks, they usually require domain-specific designs and human efforts, thus limiting the generalizability.</p><p>Reasoning via Language Models. This line of work aims to address reasoning tasks in a general sequence-to-sequence manner, empowered by reasoning-aware pre-training or fine-tuning of language models. For example, <ref type="bibr" target="#b10">Deng et al. (2021)</ref> proposed to train the language model with crawled data from the internet; <ref type="bibr" target="#b1">Asai and Hajishirzi (2020)</ref> proposed a logic-guided data augmentation method to pre-train the language model; Shen et al. <ref type="formula" target="#formula_0">(2021)</ref>  Reasoning via Prompting Gigantic Language Models. Gigantic language models like GPT-3 <ref type="bibr">(Brown et al., 2020)</ref> have demonstrated impressive few-shot learning capabilities in many tasks and have attracted many research interests on making gigantic language models better few-shot learners <ref type="bibr" target="#b58">(Zhao et al., 2021;</ref><ref type="bibr" target="#b18">Holtzman et al., 2021;</ref><ref type="bibr" target="#b36">Min et al., 2021;</ref><ref type="bibr" target="#b30">Liu et al., 2022;</ref><ref type="bibr" target="#b43">Rubin et al., 2021;</ref><ref type="bibr" target="#b37">Min et al., 2022)</ref>. However, these methods struggle to address tasks requiring reasoning skills. To mitigate this, recently there is a line of research that focuses on unleashing the reasoning capabilities of gigantic language models via better prompting strategies. <ref type="bibr" target="#b51">Wei et al. (2022)</ref> proposed chainof-thought reasoning, of which the key insight is the insertion of multi-step reasoning paths before generating the final answers; <ref type="bibr">Wang et al. (2022c)</ref> proposed to improve chain-of-thought reasoning via self-consistency, of which the key insight is to conclude the most consistent answer from different reasoning paths sampled from the language model; ; <ref type="bibr" target="#b27">Creswell et al. (2022)</ref> proposed to leverage gigantic language models to decompose questions into sub-questions, thereby addressing them in an iterative manner; <ref type="bibr">Kojima et al. (2022)</ref> proposed that gigantic language models can even be good zero-shot reasoners, by designing prompts that can induce language models to do reasoning step-by-step; Lampinen et al. <ref type="formula">(2022)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Future Work</head><p>We introduce DIVERSE, an effective and general method to make large language models better reasoners. As a continuation of the line of research that prompting language models using multi-step reasoning paths, the key insights of DIVERSE are three-fold: diverse prompts, voting verifier, and step-level correctness. Experimental results clearly show that DIVERSE can bring significant and consistent improvements. For example, with codedavinci-002, DIVERSE achieves new state-of-theart results in most of the reasoning tasks, outperforming the 540B PaLM model combined with previous prompting approaches. There are many directions for our future works. (1) As discussed in Section 5.3, we will continue to investigate how to reduce or recognize false positive pseudo exemplars. (2) We plan to investigate mechanisms to produce better diverse prompts than simple sampling. (3) We will extend DIVERSE to other tasks and continue to design better prompting techniques to elicit the power of gigantic language models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Our proposed method, DIVERSE (Diverse Verifier on Reasoning Step).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Arithmetic Reasoning. Following Wang et al. (2022c), we use AsDiv (Miao et al., 2020), Sin-gleEq (Koncel-Kedziorski et al., 2015), MultiArith</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>2: The comparison of DIVERSE, Greedy Decode and Self-Consistency. The previous SOTA results (fine-tuned on non-gigantic pretrained transformers) are: a: Cobbe et al. (2021), b: Miao et al. (2020), c: Roy and Roth (2015), d: Pi et al. (2022), e: Hu et al. (2019a), f : Xu et al. (2021), g: Chowdhery et al. (2022), h: Sinha et al.(2019). The parameter number of either text-davinci-002 or code-davinci-002 is hidden to us.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>M</head><label></label><figDesc>1 , M 2 GSM8K M 1 = 1, M 2 = 100 76.7 M 1 = 5, M 2 = 20 80.0 M 1 = 10, M 2 = 10 79.8 M 1 = 100, M 2 = 1 73.0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>GSM8K accuracy at different M values (how many reasoning paths are used for each question).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>DIVERSE performance (code-davinci-002) on GSM8K with different sizes of the training dataset (without labeled reasoning paths).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>DIVERSE performance (code-davinci-002) on GSM8K when each prompt contains 3/5/8 exemplars.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>proposed building a prompt by selecting examples and explanations together, thus substantially improving performance over selecting examples alone. Despite their great successes, these works come with their limitations. This paper is a continuation of this line of research, focusing on diverse verifier on reasoning steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Besides arithmetic reasoning, we also investigate commonsense and inductive reasoning.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>[</head><label></label><figDesc>Sample 1] She uses 3 + 4 = 7 eggs every day. So she has 16 -7 = 9 eggs left. So she makes $2 * 9 = $18 per day. The answer is 18.[Sample 2] This means 3 + 4 = 7 eggs are used every day. So in total she sells 7 * $2 = $14 per day. The answer is $14.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: The effectiveness of diverse prompts ( 5, 20 )</cell></row><row><cell>compared to pure sampling decoding (Wang et al.,</cell></row><row><cell>2022c), under majority voting.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>GSM8K majority voting results for different M</figDesc><table /><note>1 , M 2 settings on code-davinci-002.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>The effectiveness of voting verifier. All exepriments in this table use M 1 , M 2 = 5, 20 .</figDesc><table><row><cell></cell><cell cols="2">GSM8K CommonsenseQA</cell></row><row><cell>davinci:</cell><cell></cell><cell></cell></row><row><cell>DIVERSE (without step)</cell><cell>30.6</cell><cell>75.0</cell></row><row><cell>DIVERSE (with step)</cell><cell>30.9</cell><cell>76.0</cell></row><row><cell>text-davinci-002:</cell><cell></cell><cell></cell></row><row><cell>DIVERSE (without step)</cell><cell>68.9</cell><cell>79.2</cell></row><row><cell>DIVERSE (with step)</cell><cell>70.2</cell><cell>79.8</cell></row><row><cell>code-davinci-002:</cell><cell></cell><cell></cell></row><row><cell>DIVERSE (without step)</cell><cell>82.3</cell><cell>78.8</cell></row><row><cell>DIVERSE (with step)</cell><cell>81.5</cell><cell>79.9</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Most of the previous SOTA results were achieved by selfconsistency on PaLM-540B<ref type="bibr" target="#b7">(Chowdhery et al., 2022)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2"> Wang et al. (2022c)  tried an ensemble-based approach,</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">i.e., to permutate exemplars in the original prompt. However, this strategy does not increase the diversity in terms of exemplars.3 This is motivated by<ref type="bibr" target="#b56">Zelikman et al. (2022)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Concretely, f (input i , j) is predicted from the hidden state of the last token of Si,j in DEBERTA-V3-LARGE, just like token classification tasks.5  We do the judgements via an off-the-shelf natural language inference model, roberta-Large-mnli<ref type="bibr" target="#b32">(Liu et al., 2019)</ref>: S k,r is semantically equivalent to Si,r, if and only if roberta-Large-mnli predicts that S k,r entails Si,r, and Si,r entails S k,r .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">DIVERSE can also be applied to PaLM. However, we cannot conduct the experiments, as PaLM is not publicly available.7  <ref type="bibr" target="#b45">Sinha et al. (2019)</ref> also introduced a method with 100% accuracy. We do not take it into the comparison, as this method requires a domain-specific system with complicated rules to extract a knowledge graph for each input text.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Giving BERT a calculator: Finding operations and arguments with reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Andor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Pitler</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1609</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5947" to="5952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Logicguided data augmentation and regularization for consistent question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.499</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5642" to="5650" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Commonsense for generative multi-hop question answering tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1454</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4220" to="4230" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Abductive commonsense reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Ronan Le Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rashkin</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1908.05739</idno>
		<editor>Doug Downey, Scott Wen-tau Yih, and Yejin Choi</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Zero-shot transfer learning with synthesized data for multidomain dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Campagna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Foryciarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrad</forename><surname>Moradshahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><surname>Lam</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.12</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="122" to="132" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">HybridQA: A dataset of multi-hop question answering over tabular and textual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwen</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.91</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1026" to="1036" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gehrmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<title level="m">Palm: Scaling language modeling with pathways</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<title level="m">Christopher Hesse, and John Schulman. 2021. Training verifiers to solve math word problems</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">and Irina Higgins. 2022. Selection-inference: Exploiting large language models for interpretable logical reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonia</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Shanahan</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2205.09712</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ReasonBERT: Pretrained to reason with distant supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alyssa</forename><surname>Lees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">You</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.494</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online and Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6112" to="6127" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cognitive graph for multi-hop reading comprehension at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1259</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2694" to="2703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1246</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2368" to="2378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Scalable multi-hop relational reasoning for knowledge-aware question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyue</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peifeng</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2005.00646</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Injecting numerical reasoning skills into language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mor</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.89</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="946" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mor</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="346" to="361" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards a unified view of parameter-efficient transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junxian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunting</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deberta: Decodingenhanced bert with disentangled attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2104.08315</idno>
		<title level="m">Surface form competition: Why the highest probability answer isn&apos;t always right</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Parameter-efficient transfer learning for nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruna</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>De Laroussilhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Attariyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2790" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyuan</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhi</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shean</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09685</idno>
		<title level="m">Lora: Low-rank adaptation of large language models</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A multi-type multi-span network for reading comprehension that requires discrete reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1596" to="1606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A multi-type multi-span network for reading comprehension that requires discrete reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1170</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1596" to="1606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A good prompt is worth millions of parameters: Low-resource prompt-based learning for vision-language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woojeong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2763" to="2775" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reid</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2205.11916</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Parsing algebraic word problems into equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siena</forename><surname>Dumas Ang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="585" to="597" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exploiting explicit paths for multi-hop reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Souvik</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1263</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2737" to="2747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishita</forename><surname>Andrew K Lampinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Stephanie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kory</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Henry</forename><surname>Matthewson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonia</forename><surname>Tessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><forename type="middle">X</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02329</idno>
		<title level="m">Can language models learn from explanations in context? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">How many data points is a prompt worth?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander M</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2627" to="2636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">KagNet: Knowledge-aware graph networks for commonsense reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyue</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1282</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2829" to="2839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">What makes good in-context examples for GPT-3?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinghan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</title>
		<meeting><address><addrLine>Dublin</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022" />
			<biblScope unit="page" from="100" to="114" />
		</imprint>
	</monogr>
	<note>Proceedings of Deep Learning Inside Out</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Logiqa: A challenge dataset for machine reading comprehension with logical reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leyang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanmeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yile</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2007.08124</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alastair</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2104.08786</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A diverse corpus for evaluating and developing english math word problem solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shen-Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao-Chun</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keh-Yih</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="975" to="984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Knowledgeable reader: Enhancing cloze-style reading comprehension with external commonsense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1076</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="821" to="832" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Metaicl: Learning to learn in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2110.15943</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Rethinking the role of demonstrations: What makes in-context learning work?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxi</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2202.12837</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Are nlp models really able to solve simple math word problems?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkil</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satwik</forename><surname>Bhattamishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navin</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2080" to="2094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morteza</forename><surname>Ziyadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeqi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11473</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>and Weizhu Chen. 2022. Reasoning like program executors</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning logical definitions from relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="239" to="266" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Solving general arithmetic word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhro</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1743" to="1752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Learning to retrieve prompts for in-context learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ohad</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2112.08633</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Generate &amp; rank: A multi-task framework for math word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2269" to="2279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Clutrr: A diagnostic benchmark for inductive reasoning from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koustuv</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shagun</forename><surname>Sodhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William L</forename><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4506" to="4515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Commonsenseqa: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4149" to="4158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Logic-driven context extension and data augmentation for logical reasoning of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanjun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022" />
			<biblScope unit="page" from="1619" to="1629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Improving natural language inference using external knowledge in the science questions domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kapanipathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Musa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ibrahim</forename><surname>Talamadupula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Abdelaziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achille</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bassem</forename><surname>Fokoue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Makni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mattei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Witbrock</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33017208</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting>the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>AAAI&apos;19/IAAI&apos;19/EAAI&apos;19</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Multi-level recommendation reasoning over knowledge graphs with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunpeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjie</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Web Conference 2022</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Aakanksha Chowdhery, and Denny Zhou. 2022c. Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2203.11171</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11903</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Human parity on commonsenseqa: Augmenting self-attention with external attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.03254</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">HotpotQA: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1259</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Turning tables: Generating examples from semistructured tables for endowing language models with reasoning skills</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Ori Yoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6016" to="6031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Reclor: A reading comprehension dataset requiring logical reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanfei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2002.04326</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Zelikman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah D</forename><surname>Goodman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.14465</idno>
		<title level="m">Star: Bootstrapping reasoning with reasoning</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">SWAG: A large-scale adversarial dataset for grounded commonsense inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1009</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Calibrate before use: Improving few-shot performance of language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><forename type="middle">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2102.09690</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Least-to-most prompting enables complex reasoning in large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Sch?rli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2205.10625</idno>
		<editor>Quoc Le, and Ed Chi. 2022</editor>
		<imprint>
			<publisher>Olivier Bousquet</publisher>
		</imprint>
	</monogr>
	<note>Dale Schuurmans</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengbin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqiang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youcheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2105.07624</idno>
		<title level="m">Jiancheng Lv, Fuli Feng, and Tat-Seng Chua. 2021. Tat-qa: A question answering benchmark on a hybrid of tabular and textual content in finance</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
