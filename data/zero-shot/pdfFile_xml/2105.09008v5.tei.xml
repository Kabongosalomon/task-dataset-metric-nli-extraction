<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Novel lightweight Convolutional Neural Network -ExquisiteNetV2</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyh-Yaw</forename><surname>Jou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Yen</forename><surname>Su</surname></persName>
						</author>
						<title level="a" type="main">A Novel lightweight Convolutional Neural Network -ExquisiteNetV2</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the paper of ExquisiteNetV1, the ability of classification of ExquisiteNetV1 is worse than DenseNet.</p><p>In this article, we propose a faster and better model ExquisiteNetV2. We conduct many experiments to evaluate its performance. We test ExquisiteNetV2, ExquisiteNetV1 and other 9 well-known models on 16 credible datasets including Cifar-10 under the same condition. According to the experimental results, ExquisiteNetV2 gets the highest classification accuracy over half of the datasets. Important of all, ExquisiteNetV2 has fewest amounts of parameters. Besides, in most instances, ExquisiteNetV2 has fastest computing speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Architecture</head><p>ExquisiteNetV2 mainly consists of 4 types of blocks, namely DFSEBV2 block (DFSEB[1] version 2), ME block[1], FCT block and EVE block. Besides, we design a new kind of SE block <ref type="bibr" target="#b1">[2]</ref>, that is, SE-LN block.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. EVE Block</head><p>Complete name is extreme-value-expansion block.</p><p>In the research of ExquisiteNetV1 <ref type="bibr" target="#b0">[1]</ref>, we found using max pooling will get better accuracy than using depthwise convolution with its stride set to 2. We are very curious about why max pooling also work well despite it discard the 75% features when downsampling.</p><p>According to <ref type="figure" target="#fig_0">Fig 1,</ref> after applying max/min pooling to a cute Corgi image, we can find that the result image of max pooling look brighter and the one of min pooling look darker. It is reasonable because max/min pooling will only retain big/small pixel values. Important of all, we can find that despite max/min pooling will discard 75% feature, the both result images still look much like original image, in other words, the feature retained by max/min pooling might still be able to represent the original feature.</p><p>To make ME block of ExquisiteNetV1 be able to retain more feature when downsampling, we combine a min pooling layer into ME block. So the amount of discard feature down to 50%. Because revised ME block retains the extreme feature, we rename it as EVE block. The architecture of EVE block is shown in <ref type="figure" target="#fig_1">Fig 2.</ref> We also make a try to combine average pooling layer into EVE block to retain more feature. However, after adding the average pooling layer into EVE block, the accuracy become worse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Max pool</head><p>Min pool  The feature in the raw image is the most important so we should try to retain feature of raw image as many as possible.</p><p>In order to retain all feature of raw image, we combine the EVE block with a 4?4 depthwise conv and use FCT as input block of ExquisiteNetV2. The architecture of FCT block is shown in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. SE-LN Block</head><p>Complete name is SE-Layer-Normalization block. SE block include 2 fully-connected layer, we use layer normalization to replace these 2 fully-connected layer for decrease amount of parameters. The amounts of parameters of layer normalization is much fewer than ones of 2 fullyconnected layer <ref type="bibr" target="#b2">[3]</ref>. The architecture of SE-LN block is shown in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. DFSEBV2 Block</head><p>We delete one SE block and replace the other SE blcok into SE-LN block so the amounts of parameters is fewer than DFSEBV1. Besides, we change some activation. The architecture of DFSEBV2 block is shown in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. ExquisiteNetV2</head><p>We show the architecture in <ref type="table" target="#tab_0">Table.</ref> 1.</p><p>We only replace the first and second ME block in ExquisiteNetV1 with FCT and EVE block. One reason is that the amounts of parameters in ME block is fewer than FCT or EVE block, the other reason is that we think the raw feature is the most important so we only use FCT or EVE block in the front part of model. Besides, we change the pointwise conv in ExquisiteNetV1 into depthwise conv. The amounts of parameters of ExquisiteNetV2 is fewer than ExquisiteNetV1.</p><p>The parameters of each model is shown on <ref type="table" target="#tab_0">Table.</ref> . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">DTD</head><p>It is a texture dataset. The resolution of every image range from 300?300~640?640.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Leukemia</head><p>This dataset is used to recognize whether the children have Leukemia. <ref type="table">Training set  10661  Test set  1867  Classes  2</ref> 5. RAF-DB Every image is human's facial expression. There are 2 sets in the original dataset, one is basic, the other is compound. We train and test on basic.  7. Fruits-360</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table. 5 the information of Leukemia</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original Use in experiment</head><p>The size of training set is so big that we randomly sample 30 images from every class. The size of training set is so big that we randomly sample 50 images from every class. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Stanford Online Products</head><p>The size of training set is so big that we randomly sample 300 images from every class. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Caltech256</head><p>The name is "256", but there is actually 257 classes in the dataset. The 257th class is "clutter". We think the 257th class is so unclear that we delete this class. The original dataset is not divide into training set and test set, so we divide each class into 10 equal parts. One of the parts is used as training set, the rest are test set. 11. STL-10</p><p>The dataset is inspired from CIFAR-10 <ref type="bibr" target="#b18">[19]</ref>. Because the resolution of the image in CIFAR-10 is too low(32?32) <ref type="bibr" target="#b18">[19]</ref>, the images in STL-10 are all 96?96.      <ref type="bibr" target="#b20">[21]</ref>, the other is SGD <ref type="bibr" target="#b21">[22]</ref>. 9. We have set random seed so the images are read in the same order by each model 10. Batch size is 50 (cifar-10 is 64) 11. Initial learning rate is 0.05 and the factor is 0.1. If the training loss is not improved for consecutive 5 epochs, the learning rate will be multiplied by factor. Training loss is the average loss of each image in the training set. 12. To avoid the overfitting phenomenon, we add the Dropout layer before the last fully-connected layer into each model. 13. End condition is training loss &lt; 0.01 or total epochs reach 150. The reason why we design this way is that it is difficult to make training loss lower than 0.01 for some models. 14. We have test whether the SE-LN block is able to replace the SE block. We set the decrease ratio of each SE block to 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Classification Results</head><p>We test many models, namely SE-ResNet18 <ref type="bibr" target="#b1">[2]</ref>, MobileNetV3-Large, EfficientNet-b0, DenseNet121, ResNet18, ResNet50, ShuffleNetV2, GhostNet[23]~ <ref type="bibr" target="#b27">[28]</ref>. "LN-" means the all SE blocks in the original model are replaced by SE-LN blocks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Analysis</head><p>From <ref type="table" target="#tab_0">Table.</ref> , we can learn the parameters of LN-ExquisiteNetV2 is fewest. From <ref type="figure">Fig. ,</ref> we can learn that as long as the batch size is bigger than 10, the LN-ExquisiteNetV2 is the fastest. The speed is calculated from how long for every model to classify the test set of RAF-DB.</p><p>From <ref type="table" target="#tab_0">Table.</ref> to <ref type="table" target="#tab_0">Table.</ref> , we can learn that SGD is more suitable to ExquisiteNetV2. LN-ExquisiteNetV2 gets first place on 8 datasets when the optimizer is RangerVA and gets first place on 10 datasets when the optimizer is SGD. Besides, LN-ExquisiteNetV2 is much better than state-of-the-art models on some datasets. From <ref type="table" target="#tab_0">Table.</ref> , the average ranking of LN-ExquisiteNetV2 is very near 1, it can be seen that LN-ExquisiteNetV2 has strong ability of classification.</p><p>However, SE-LN block seems to be only suitable for ExquisiteNet especially ExquisiteNetV2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Result on Cifar-10</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Object Detection</head><p>YoloV5 is one of good object detection models <ref type="bibr" target="#b28">[29]</ref>. YoloV5 contains 4 different size, namely YoloV5s, YoloV5m, YoloV5l, YoloV5x. We combine ExquisiteNetV2 with YoloV5 and test it on Face Mask dataset <ref type="bibr" target="#b29">[30]</ref>. Face Mask dataset is originally not divide into training set and test set so we choose image No. 0~49 as test set, the rest is training set.</p><p>From <ref type="table" target="#tab_0">Table.</ref> , we can learn ExquisiteNetv2-Yolov5 has fastest computing speed and fewest parameters. The ability of detecting objects of ExquisiteNetV2-YoloV5 is better than Yolov5m but the parameters of ExquisiteNetv2-Yolov5 is 20 M less than Yolov5m. The FPS is test on nvidia Geforce 3060, the size of image is 320x320. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>ExquisiteNetV2 has outstanding ability of analyzing data, fast computing speed, few parameters compared with state-ofthe-art models. However, ExquisiteNetV2 is not good at analyzing the very low resolution images. Important of all, according to the experimental results, the performance of ExquisiteNetV2 completely beat ExquisiteNetV1.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>EVE blockB. FCT BlockComplete name is Feature-Concentrator block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Fig 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3</head><label>3</label><figDesc>FCT block</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Fig 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4</head><label>4</label><figDesc>SE-LN block</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Fig 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5</head><label>5</label><figDesc>DFSEBV2 block</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table . 1</head><label>.</label><figDesc>Architecture of ExquisiteNetV2</figDesc><table><row><cell>Input</cell><cell>Operator</cell><cell>Out Channels</cell></row><row><cell>224 2 ? 3</cell><cell>FCT</cell><cell>12</cell></row><row><cell>112 2 ? 12</cell><cell>DFSEBV2</cell><cell>12</cell></row><row><cell>112 2 ? 12</cell><cell>EVE</cell><cell>48</cell></row><row><cell>56 2 ? 48</cell><cell>DFSEBV2</cell><cell>48</cell></row><row><cell>56 2 ? 48</cell><cell>ME</cell><cell>96</cell></row><row><cell>28 2 ? 96</cell><cell>DFSEBV2</cell><cell>96</cell></row><row><cell>28 2 ? 96</cell><cell>ME</cell><cell>192</cell></row><row><cell>14 2 ? 192</cell><cell>DFSEBV2</cell><cell>192</cell></row><row><cell>14 2 ? 192</cell><cell>ME</cell><cell>384</cell></row><row><cell>7 2 ? 384</cell><cell>DFSEBV2</cell><cell>384</cell></row><row><cell>7 2 ?384</cell><cell>Depthwise Conv</cell><cell>384</cell></row><row><cell>7 2 ?384</cell><cell>Hard Swish</cell><cell>384</cell></row><row><cell>7 2 ?384</cell><cell>Average pooling</cell><cell>384</cell></row><row><cell>1 2 ?384</cell><cell>Dropout</cell><cell>384</cell></row><row><cell>1 2 ?384</cell><cell>FC</cell><cell>-</cell></row><row><cell></cell><cell>Dataset</cell><cell></cell></row><row><cell cols="3">We choose 16 credible datasets in the experiment, namely</cell></row><row><cell cols="3">DTD, Chest X-Ray, OCT, Leukemia, RAF-DB, SUN397,</cell></row><row><cell cols="3">Fruits-360, Food-101, Stanford Online Products, Caltech256,</cell></row><row><cell cols="3">STL-10, Birds-2011, VGG Flowers, Plant SeedlingsV2,</cell></row><row><cell cols="2">Synthetic Digits and Cifar-10 [4]-[18].</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table .</head><label>.</label><figDesc></figDesc><table><row><cell cols="2">2 the information of DTD</cell></row><row><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>1880</cell></row><row><cell>Test set</cell><cell>1880</cell></row><row><cell>Classes</cell><cell>47</cell></row><row><cell>2. Chest X-Ray</cell><cell></cell></row><row><cell cols="2">This dataset is used to recognize whether the children have</cell></row><row><cell>the lung disease.</cell><cell></cell></row><row><cell cols="2">Table. 3 the information of Chest X-Ray</cell></row><row><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>5232</cell></row><row><cell>Test set</cell><cell>624</cell></row><row><cell>Classes</cell><cell>2</cell></row><row><cell>3. OCT</cell><cell></cell></row><row><cell cols="2">OCT is Optical Coherence Tomograph. The classes are</cell></row><row><cell cols="2">diabetic macular edema, choroidal neovascularization, drusen</cell></row><row><cell cols="2">and normal. The size of training set is so big that we randomly</cell></row><row><cell>sample 250 images from every class.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table .</head><label>.</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">4 the information of OCT</cell></row><row><cell></cell><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>207130</cell><cell>1000</cell></row><row><cell>Test set</cell><cell cols="2">1000</cell></row><row><cell>Classes</cell><cell>4</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table . 6</head><label>.</label><figDesc>the information of RAF-DB</figDesc><table><row><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>12271</cell></row><row><cell>Test set</cell><cell>3068</cell></row><row><cell>Classes</cell><cell>7</cell></row><row><cell>6. SUN397</cell><cell></cell></row><row><cell cols="2">The dataset contains various scene images.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table .</head><label>.</label><figDesc></figDesc><table><row><cell cols="2">7 the information of SUN397</cell></row><row><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>19850</cell></row><row><cell>Test set</cell><cell>19850</cell></row><row><cell>Classes</cell><cell>397</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table . 8</head><label>.</label><figDesc>the information of Fruits-360</figDesc><table><row><cell></cell><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>67692</cell><cell>3930</cell></row><row><cell>Test set</cell><cell></cell><cell>22688</cell></row><row><cell>Classes</cell><cell></cell><cell>131</cell></row><row><cell>8. Food-101</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table . 9</head><label>.</label><figDesc>the information of Food-101</figDesc><table><row><cell></cell><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>75750</cell><cell>5050</cell></row><row><cell>Test set</cell><cell></cell><cell>25250</cell></row><row><cell>Classes</cell><cell></cell><cell>101</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table . 10</head><label>.</label><figDesc>the information of Stanford Online Products</figDesc><table><row><cell></cell><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>59551</cell><cell>3600</cell></row><row><cell>Test set</cell><cell cols="2">60502</cell></row><row><cell>Classes</cell><cell>12</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table .</head><label>.</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">11 the information of Caltech256</cell></row><row><cell></cell><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>30607</cell><cell>2881</cell></row><row><cell>Test set</cell><cell></cell><cell>26899</cell></row><row><cell>Classes</cell><cell>257</cell><cell>256</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table . 12</head><label>.</label><figDesc>the information of STL-10</figDesc><table><row><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>5000</cell></row><row><cell>Test set</cell><cell>8000</cell></row><row><cell>Classes</cell><cell>10</cell></row><row><cell>12. Birds-2011</cell><cell></cell></row><row><cell cols="2">The dataset includes various bird species.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table .</head><label>.</label><figDesc></figDesc><table><row><cell cols="2">13 the information of Birds-2011</cell></row><row><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>5794</cell></row><row><cell>Test set</cell><cell>5994</cell></row><row><cell>Classes</cell><cell>200</cell></row><row><cell>13. VGG Flowers</cell><cell></cell></row><row><cell cols="2">The dataset includes various flower species.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table .</head><label>.</label><figDesc>Plant SeedlingsV2The dataset contains 12 kinds of crop seed. Because the original dataset is not divide into training set and test set, so we divide each class into 2 equal parts. One is used as training set, the other is test set.Table.15 the information of Plant SeedlingsV2</figDesc><table><row><cell cols="3">14 the information of VGG Flowers</cell></row><row><cell></cell><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell cols="2">1020</cell></row><row><cell>Test set</cell><cell cols="2">6149</cell></row><row><cell>Classes</cell><cell cols="2">102</cell></row><row><cell cols="2">14. Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>5539</cell><cell>2766</cell></row><row><cell>Test set</cell><cell></cell><cell>2773</cell></row><row><cell>Classes</cell><cell>12</cell><cell></cell></row><row><cell>15. Synthetic Digits</cell><cell></cell><cell></cell></row><row><cell cols="3">Every image in this dataset is RGB and their background is</cell></row><row><cell>complicated.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table . 16</head><label>.</label><figDesc>the information of Synthetic Digits</figDesc><table><row><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>10000</cell></row><row><cell>Test set</cell><cell>2000</cell></row><row><cell>Classes</cell><cell>10</cell></row></table><note>16. Cifar-10 Every image is 32x32. Many paper use this dataset as benchmark. We randomly split 10000 image from training set as validation set.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table . 17</head><label>.</label><figDesc>the information of Synthetic Digits To make the experimental result being objective, we test each model under the same conditions. The conditions are shown below. 1. Program is run on Ubuntu 16.04 2. Accelerator is GeForce RTX 2080 Ti 3. Every image is converted to RGB 4. Every image is resized to 224?224 5. Every pixel value in image is scaled into [0,1] 6. Each dataset is not augmented (only cifar-10 augment) 7. Every model is trained without pretrained weight, each weight in each layer is initialized by Pytorch default method.</figDesc><table><row><cell>Original</cell><cell>Use in experiment</cell></row><row><cell>Training set</cell><cell>50000</cell></row><row><cell>Test set</cell><cell>10000</cell></row><row><cell>Classes</cell><cell>10</cell></row><row><cell cols="2">Experiment and Analysis</cell></row><row><cell>A. Settings</cell><cell></cell></row></table><note>8. Every model is test with 2 different optimizer respectively. One is RangerVA</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table .</head><label>.</label><figDesc></figDesc><table><row><cell>ResNet18 SE-Resnet18</cell><cell></cell><cell>37.10 43.03</cell><cell cols="2">92.82 93.36</cell><cell>99.00 99.05</cell><cell cols="2">MobileNetV3-L ShuffleNetV2 SE-ExquisiteNetV2</cell><cell cols="3">15.21 91.83 87.60 14.79 89.42 81.20 41.31 24.07 70.66</cell><cell>74.77 72.79 36.90</cell></row><row><cell>LN-Resnet18 GhostNet</cell><cell></cell><cell>39.81 17.52</cell><cell cols="2">94.66 90.59</cell><cell>97.80 98.45</cell><cell>ResNet50 ResNet18 LN-ExquisiteNetV2</cell><cell></cell><cell cols="3">19.31 88.62 89.80 24.41 90.38 88.50 40.68 24.89 72.20</cell><cell>70.59 71.93 39.26</cell></row><row><cell cols="2">SE-ExquisiteNetV1</cell><cell>50.56</cell><cell cols="2">95.24</cell><cell>98.80</cell><cell>SE-Resnet18</cell><cell></cell><cell></cell><cell cols="2">27.55 90.71 87.10</cell><cell>71.34</cell></row><row><cell cols="2">LN-ExquisiteNetV1</cell><cell>49.86</cell><cell cols="2">94.59</cell><cell>99.05</cell><cell cols="5">LN-Resnet18 Table. 26 Test Acc SGD(IV) 27.55 87.34 85.80</cell><cell>72.25</cell></row><row><cell cols="2">SE-ExquisiteNetV2</cell><cell>54.95</cell><cell cols="2">95.56</cell><cell>99.50</cell><cell>GhostNet</cell><cell></cell><cell></cell><cell cols="2">13.72 91.35 80.00 Optimizer: SGD</cell><cell>73.54</cell></row><row><cell cols="2">LN-ExquisiteNetV2</cell><cell>55.47</cell><cell cols="2">95.64</cell><cell>99.50</cell><cell cols="5">SE-ExquisiteNetV1 32.61 89.34 83.60 Acc (%)</cell><cell>76.43</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">LN-ExquisiteNetV1 33.40 89.90 83.60 Flower Seed</cell><cell>78.04 Synthetic</cell></row><row><cell cols="5">Table. 23 Test Acc SGD(I)</cell><cell></cell><cell cols="5">SE-ExquisiteNetV2 42.66 92.15 88.40</cell><cell>80.66 Digits</cell></row><row><cell></cell><cell></cell><cell cols="2">Optimizer: SGD</cell><cell></cell><cell></cell><cell cols="5">LN-ExquisiteNetV2 40.80 91.51 90.10 DenseNet121 38.75 95.13</cell><cell>82.43 98.20</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Acc (%)</cell><cell></cell><cell cols="2">EfficientNet-b0</cell><cell></cell><cell></cell><cell>23.45</cell><cell>89.51</cell><cell>99.65</cell></row><row><cell></cell><cell></cell><cell cols="4">DTD Chest OCT Leukemia</cell><cell cols="5">Table. 20 Test Acc RangerVA(II) MobileNetV3-L 17.79 88.28</cell><cell>99.80</cell></row><row><cell>DenseNet121</cell><cell></cell><cell cols="3">26.28 87.98 90.10</cell><cell>72.52</cell><cell>ShuffleNetV2</cell><cell cols="4">Optimizer: RangerVA 17.30 88.17</cell><cell>98.70</cell></row><row><cell>EfficientNet-b0</cell><cell></cell><cell cols="3">14.31 88.62 79.70</cell><cell>71.02</cell><cell>ResNet50</cell><cell></cell><cell></cell><cell></cell><cell>23.11</cell><cell>Acc (%) 88.82</cell><cell>98.15</cell></row><row><cell>MobileNetV3-L</cell><cell></cell><cell cols="3">12.93 89.26 85.80</cell><cell>71.67</cell><cell>ResNet18</cell><cell></cell><cell></cell><cell cols="2">RAF SUN397 36.61 93.22 Fruit</cell><cell>Food 98.35</cell></row><row><cell>ShuffleNetV2</cell><cell></cell><cell cols="3">13.99 89.58 74.20</cell><cell>71.13</cell><cell>DenseNet121 SE-Resnet18</cell><cell></cell><cell></cell><cell cols="2">70.57 42.10</cell><cell>36.89</cell><cell>98.26 93.54</cell><cell>19.14 98.40</cell></row><row><cell>ResNet50</cell><cell></cell><cell cols="3">18.46 89.26 63.90</cell><cell>71.45</cell><cell>EfficientNet-b0 LN-Resnet18</cell><cell></cell><cell></cell><cell cols="2">69.98 39.75</cell><cell>26.67</cell><cell>94.03 94.34</cell><cell>10.42 97.75</cell></row><row><cell>ResNet18</cell><cell></cell><cell cols="3">24.04 90.71 86.00</cell><cell>71.24</cell><cell cols="2">MobileNetV3-L GhostNet</cell><cell></cell><cell cols="2">68.25 16.96</cell><cell>26.34</cell><cell>94.42 88.21</cell><cell>10.80 99.30</cell></row><row><cell>SE-Resnet18</cell><cell cols="4">18 parameters of each model 26.28 92.63 83.90</cell><cell>72.79</cell><cell cols="3">ShuffleNetV2 SE-ExquisiteNetV1</cell><cell cols="2">66.17 50.22</cell><cell>26.82</cell><cell>93.34 95.35</cell><cell>10.53 98.75</cell></row><row><cell cols="6">(when the last FC layer contains 1000 output channels) LN-Resnet18 25.96 88.46 85.30 73.06</cell><cell cols="3">ResNet50 LN-ExquisiteNetV1</cell><cell cols="2">65.68 48.41</cell><cell>28.27</cell><cell>96.05 94.66</cell><cell>12.36 99.30</cell></row><row><cell>GhostNet</cell><cell></cell><cell cols="4">Parameters (M) 11.33 90.22 79.70 70.86</cell><cell cols="3">ResNet18 SE-ExquisiteNetV2</cell><cell cols="2">68.35 53.88</cell><cell>28.14</cell><cell>96.87 96.21</cell><cell>14.81 99.05</cell></row><row><cell cols="5">DenseNet121 SE-ExquisiteNetV1 33.56 90.54 78.70 7.9788</cell><cell>75.63</cell><cell cols="3">SE-Resnet18 LN-ExquisiteNetV2</cell><cell cols="2">68.74 56.01</cell><cell>28.38</cell><cell>98.08 96.72</cell><cell>18.22 99.40</cell></row><row><cell cols="5">EfficientNet-b0 LN-ExquisiteNetV1 35.16 91.35 81.80 5.3</cell><cell>78.04</cell><cell>LN-Resnet18</cell><cell></cell><cell></cell><cell cols="2">67.21</cell><cell>27.88</cell><cell>97.28</cell><cell>15.63</cell></row><row><cell cols="5">MobileNetV3-L SE-ExquisiteNetV2 42.23 91.83 88.80 5.483</cell><cell>80.61</cell><cell cols="5">GhostNet Table. 27 the average ranking of each model on 15 datasets 67.41 29.50 93.57 7.61</cell></row><row><cell cols="5">ShuffleNetV2 LN-ExquisiteNetV2 42.77 93.11 88.20 7.3939</cell><cell>83.07</cell><cell cols="5">SE-ExquisiteNetV1 67.99 RangerVA 30.04</cell><cell>97.95 SGD 24.60</cell></row><row><cell cols="2">ResNet50</cell><cell></cell><cell></cell><cell>25.557</cell><cell></cell><cell cols="5">LN-ExquisiteNetV1 65.87 DenseNet121 4.1333 28.77</cell><cell>97.95 4.6666 24.88</cell></row><row><cell cols="5">ResNet18 Table. 24 Test Acc SGD(II) 11.6895</cell><cell></cell><cell cols="5">SE-ExquisiteNetV2 69.49 EfficientNet-b0</cell><cell>33.67 8.4</cell><cell>98.01</cell><cell>9.4</cell><cell>26.54</cell></row><row><cell cols="2">SE-Resnet18</cell><cell cols="2">Optimizer: SGD</cell><cell>12.1515</cell><cell></cell><cell cols="5">LN-ExquisiteNetV2 70.08 MobileNetV3-L 8.3333 34.44</cell><cell>98.10 8.6666 28.07</cell></row><row><cell cols="2">LN-Resnet18</cell><cell></cell><cell cols="2">11.6933 Acc (%)</cell><cell></cell><cell>ShuffleNetV2</cell><cell></cell><cell></cell><cell></cell><cell>11.1333</cell><cell>11.4666</cell></row><row><cell cols="5">GhostNet SqueezeNet SE-ExquisiteNetV1 LN-ExquisiteNetV1 SE-ExquisiteNetV2 RAF SUN397 Fruit 5.1825 1.2354 1.5618 1.3329 1.0285 DenseNet121 68.35 37.01 97.88 EfficientNet-b0 67.89 23.63 93.73 MobileNetV3-L 68.32 25.07 95.83 ShuffleNetV2 59.62 20.94 91.34</cell><cell>Food 20.72 8.55 10.28 8.56</cell><cell cols="5">Table. 21 Test Acc RangerVA(III) Optimizer: RangerVA Acc (%) Online Caltech256 STL10 Birds DenseNet121 38.25 20.09 72.89 38.66 ResNet50 9.3333 10.2 ResNet18 8.0000 7.6666 SE-Resnet18 6.8666 6 LN-Resnet18 8.2666 7.4666 GhostNet 10.6666 11</cell></row><row><cell cols="3">LN-ExquisiteNetV2 ResNet50 58.74 ResNet18 65.61 SE-Resnet18 68.32 LN-Resnet18 66.40</cell><cell>26.77 27.29 27.91 27.57</cell><cell>0.8993 95.96 95.83 97.81 96.93</cell><cell>11.83 13.98 15.01 16.00</cell><cell cols="4">EfficientNet-b0 MobileNetV3-L 36.12 33.62 ShuffleNetV2 29.87 ResNet50 30.45 SE-ExquisiteNetV1 LN-ExquisiteNetV1 SE-ExquisiteNetV2 LN-ExquisiteNetV2</cell><cell>13.65 14.44 13.01 15.09 5.4666 5.6666 2.5333 1.5333</cell><cell>67.33 67.30 59.74 60.88 4.8 4.8 2.4666 24.19 18.27 24.27 25.58 1.4</cell></row><row><cell>GhostNet</cell><cell></cell><cell>66.33</cell><cell>24.69</cell><cell>91.73</cell><cell>5.97</cell><cell>ResNet18</cell><cell></cell><cell cols="2">33.65</cell><cell>17.99</cell><cell>66.88</cell><cell>26.88</cell></row><row><cell cols="3">SE-ExquisiteNetV1 64.05</cell><cell>32.45</cell><cell>98.15</cell><cell>26.70</cell><cell>SE-Resnet18</cell><cell></cell><cell cols="2">34.57</cell><cell>18.22</cell><cell>67.2</cell><cell>27.69</cell></row><row><cell cols="3">LN-ExquisiteNetV1 62.09</cell><cell>32.38</cell><cell>98.07</cell><cell>19.83</cell><cell>LN-Resnet18</cell><cell></cell><cell cols="2">35.00</cell><cell>17.89</cell><cell>67.74</cell><cell>27.93</cell></row><row><cell cols="3">SE-ExquisiteNetV2 69.20</cell><cell>34.97</cell><cell>97.88</cell><cell>27.21</cell><cell>GhostNet</cell><cell></cell><cell cols="2">30.10</cell><cell>11.22</cell><cell>66.84</cell><cell>17.98</cell></row><row><cell cols="3">LN-ExquisiteNetV2 69.10</cell><cell>34.88</cell><cell>98.33</cell><cell>28.16</cell><cell>SE-ExquisiteNetV1</cell><cell></cell><cell cols="2">37.58</cell><cell>20.91</cell><cell>70.74</cell><cell>35.65</cell></row><row><cell cols="5">Table. 25 Test Acc SGD(III) Optimizer: SGD</cell><cell></cell><cell>LN-ExquisiteNetV1</cell><cell></cell><cell cols="2">38.93</cell><cell>20.48</cell><cell>69.43</cell><cell>33.73</cell></row><row><cell>DenseNet121 EfficientNet-b0</cell><cell cols="5">Acc (%) Online Caltech256 STL10 Birds 34.02 19.10 71.31 38.54 32.85 13.33 66.10 20.37</cell><cell>SE-ExquisiteNetV2 LN-ExquisiteNetV2</cell><cell></cell><cell cols="2">41.58 43.13</cell><cell>25.06 25.19</cell><cell>72.24 73.05</cell><cell>37.04 39.07</cell></row><row><cell cols="6">Fig. 6 classifiacation speed of models with different batch size MobileNetV3-L 32.99 13.07 64.88 18.69 ShuffleNetV2 27.49 11.64 57.20 16.10 ResNet50 27.30 14.36 57.94 25.59 ResNet18 34.38 17.83 66.79 26.88</cell><cell cols="5">Table. 22 Test Acc RangerVA(IV) Optimizer: RangerVA Acc (%)</cell></row><row><cell cols="6">Table. 19 Test Acc RangerVA(I) Optimizer: RangerVA Acc (%) DTD Chest OCT Leukemia DenseNet121 27.71 90.06 91.50 SE-Resnet18 34.93 19.00 65.84 30.23 LN-Resnet18 32.91 17.32 67.15 27.39 GhostNet 25.66 10.00 61.45 13.96 SE-ExquisiteNetV1 38.20 20.12 69.46 36.22 75.68 EfficientNet-b0 16.97 91.51 87.60 72.52 LN-ExquisiteNetV1 38.07 20.94 68.87 33.03</cell><cell cols="2">DenseNet121 EfficientNet-b0 MobileNetV3-L ShuffleNetV2 ResNet50</cell><cell></cell><cell cols="2">Flower 40.23 29.74 26.26 19.48 28.70</cell><cell>Seed 94.95 92.32 90.23 88.71 89.76</cell><cell>Synthetic Digits 98.30 99.50 99.55 99.45 99.65</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table .</head><label>.</label><figDesc></figDesc><table><row><cell></cell><cell>28 Cifar-10 result of ExquisiteNetV2</cell></row><row><cell></cell><cell>(Train without pretrained weight)</cell></row><row><cell>Val Acc(%)</cell><cell>93.29</cell></row><row><cell>Test Acc(%)</cell><cell>92.52</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table .</head><label>.</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">29 result of object detection</cell><cell></cell></row><row><cell></cell><cell>mAP 0.5</cell><cell>Parameter (M)</cell><cell>FPS</cell></row><row><cell>Yolov5s</cell><cell>0.9308</cell><cell>7.07</cell><cell>172</cell></row><row><cell>Yolov5m</cell><cell>0.9474</cell><cell>21.06</cell><cell></cell></row><row><cell>Yolov5l</cell><cell>0.9739</cell><cell>46.64</cell><cell></cell></row><row><cell>Yolov5x</cell><cell>0.9691</cell><cell>87.26</cell><cell></cell></row><row><cell>ExquisiteNetv2 -Yolov5</cell><cell>0.9434</cell><cell>0.95</cell><cell>208</cell></row><row><cell cols="3">Fig. 7 result on the test set of Face Mask</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Efficient Convolutional Neural Network for Pest Recognition-ExquisiteNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE Eurasia Conference on IOT, Communication and Engineering (ECICE)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="216" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Squeeze-and-Excitation Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Albanie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2019.2913372</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">42</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Layer normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Describing Textures in the Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conf. on CVPR</title>
		<meeting>the IEEE Conf. on CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large Dataset of Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Michael</surname></persName>
		</author>
		<idno type="DOI">10.17632/rscbjbr9sj.3</idno>
	</analytic>
	<monogr>
		<title level="j">Mendeley Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">ALL Challenge dataset of ISBI 2019. The Cancer Imaging Archive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;amp;</forename><forename type="middle">R</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="DOI">10.7937/tcia.2019.dc64i46r</idno>
		<ptr target="https://doi.org/10.7937/tcia.2019.dc64i46r" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reliable Crowdsourcing and Deep Locality-Preserving Learning for Expression Recognition in the Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junping</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE CVPR</title>
		<imprint>
			<biblScope unit="page" from="2584" to="2593" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SUN Database: Large-scale Scene Recognition from Abbey to Zoo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE CVPR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fruit recognition from images using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oltean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Univ. Sapientiae, Informatica</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="42" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Food-101 --Mining Discriminative Components with Random Forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Matthieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Luc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep Metric Learning via Lifted Structured Feature Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The Caltech 256</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note type="report_type">Caltech Technical Report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An Analysis of Single Layer Networks in Unsupervised Feature Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning Multiple Layers of Features from Tiny Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
	</analytic>
	<monogr>
		<title level="m">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automated flower classification over a large number of classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M-E</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing</title>
		<meeting>the Indian Conference on Computer Vision, Graphics and Image Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A public image database for benchmark of plant seedling classification algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Giselsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>J?rgensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dyrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Midtiby</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05458</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Prasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Subhankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Saumik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Umapada</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.10108</idno>
		<title level="m">Effects of Degradations on Deep Neural Network Architectures</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning Multiple Layers of Features from Tiny Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Gradient centralization: A new optimization technique for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.01461</idno>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Stochastic Approximation Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Monro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="407" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Searching for mobilenetv3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno>abs/1905.02244</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11946</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>abs/1608.06993</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2016.90</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE CVPR</title>
		<imprint>
			<biblScope unit="page" from="770" to="778" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Shufflenet V2: practical guidelines for efficient CNN architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno>abs/1807.11164</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.11907</idno>
		<title level="m">GhostNet: More Features from Cheap Operations</title>
		<imprint>
			<date type="published" when="2019-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">YoloV5</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ultralytics</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4679653</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Mask Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Misc</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/andrewmvd/face-mask-detection" />
		<imprint/>
	</monogr>
	<note>Make ML</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
