<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Correlated Input-Dependent Label Noise in Large-Scale Image Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Collier</surname></persName>
							<email>markcollier@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Ai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basil</forename><forename type="middle">Mustafa</forename><surname>Google</surname></persName>
							<email>basilm@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efi</forename><surname>Kokiopoulou</surname></persName>
							<email>kokiopou@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Ai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodolphe</forename><surname>Jenatton</surname></persName>
							<email>rjenatton@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Ai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Berent</surname></persName>
							<email>jberent@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Ai</surname></persName>
						</author>
						<title level="a" type="main">Correlated Input-Dependent Label Noise in Large-Scale Image Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large scale image classification datasets often contain noisy labels. We take a principled probabilistic approach to modelling input-dependent, also known as heteroscedastic, label noise in these datasets. We place a multivariate Normal distributed latent variable on the final hidden layer of a neural network classifier. The covariance matrix of this latent variable, models the aleatoric uncertainty due to label noise. We demonstrate that the learned covariance structure captures known sources of label noise between semantically similar and co-occurring classes. Compared to standard neural network training and other baselines, we show significantly improved accuracy on Imagenet ILSVRC 2012 79.3% (+ 2.6%), Imagenet-21k 47.0% (+ 1.1%) and JFT 64.7% (+ 1.6%). We set a new state-of-the-art result on WebVision 1.0 with 76.6% top-1 accuracy. These datasets range from over 1M to over 300M training examples and from 1k classes to more than 21k classes. Our method is simple to use, and we provide an implementation that is a drop-in replacement for the final fully-connected layer in a deep classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2105.10305v1 [cs.LG] 19 May 2021</head><p>representations which transfer better to the 19 datasets from the Visual Task Adaptation Benchmark (VTAB) <ref type="bibr" target="#b46">[47]</ref>.</p><p>Contributions. In summary our contributions are:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">A new method which models inter-class correlated label</head><p>noise and scales to large-scale datasets.</p><p>2. We evaluate our method on four large-scale image classification datasets, showing significantly improved performance compared to standard neural network training and diagonal covariance methods.</p><p>3. We demonstrate that the learned covariance matrices model correlations between semantically similar or commonly co-occurring classes.</p><p>4. On VTAB our method learns more general representations which transfer better to 19 downstream tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image classification datasets with many classes and large training sets often have noisy labels <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b29">30]</ref>. For example, Imagenet contains many visually similar classes that are hard for human annotators to distinguish <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b1">2]</ref>. Datasets such as WebVision where labels are generated automatically by looking at co-occuring text to images on the Web, contain label noise as this automated process is not 100% reliable <ref type="bibr" target="#b29">[30]</ref>.</p><p>A wide range of techniques for classification under label noise already exist <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b17">18]</ref>. When an image is mis-labeled it is more likely that it gets confused with other related classes, rather than a random class <ref type="bibr" target="#b1">[2]</ref>. Therefore it is important to take inter-class correlation into account when modelling label noise in image classification. EntleBucher (right). Two visually similar Imagenet classes our method learns have highly correlated label noise (average validation set covariance of -0.24) given only the standard Imagenet ILSVRC12 training labels.</p><p>We take a principled probabilistic approach to modelling label noise. We assume a generative process for noisy labels with a multivariate Normal distributed latent variable at the final hidden layer of a neural network classifier. The mean and covariance parameters of this Normal distribution are input-dependent (aka heteroscedastic), being computed from a shared representation of the input image. By modelling the inter-class noise correlations our method can learn which class pairs are substitutes or commonly co-occur, resulting in noisy labels. See <ref type="figure" target="#fig_0">Fig. (1)</ref> for an example of two Imagenet classes which our model learns have correlated label noise.</p><p>We evaluate our method on four large-scale image classification datasets, Imagenet ILSVRC12 and Imagenet-21k <ref type="bibr" target="#b9">[10]</ref>, WebVision 1.0 <ref type="bibr" target="#b29">[30]</ref> and JFT <ref type="bibr" target="#b20">[21]</ref>. These datasets range from over 1M training examples (ILSVRC12) to 300M training examples (JFT) and from 1k classes (ILSVRC12 &amp; WebVision) to over 21k classes (Imagenet-21k). We demonstrate improved accuracy and negative log-likelihood on all datasets relative to (a) standard neural network training, (b) methods which only model the diagonal of the covariance matrix and (c) methods from the noisy labels literature.</p><p>We evaluate the effect of our probabilistic label noise model on the representations learned by the network. We show that our method, when pre-trained on JFT, learns image</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head><p>In many datasets label noise is not uniform across the input space, some types of examples have more noise than others. We build upon prior work on probabilistic modelling of noisy labels <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b8">9]</ref> by assuming a heteroscedastic latent variable generative process for our labels. This generative process leads to two main challenges while computing its resulting likelihood: (a) the intractable marginalization over the latent variables which we estimate via Monte Carlo integration and (b) an arg max in the generative process which we approximate with a temperature parameterized softmax.</p><p>Generative process. Suppose there is some latent vector of utility u(x) ? R K , where K is the number of classes associated with each input x. This utility is the sum of a deterministic reference utility ?(x) and an unobserved stochastic component . A label is generated by sampling from the utility and taking the arg max, i.e. class c is the label if its associated utility is greater than the utility for all other classes ?? y = arg max j? <ref type="bibr">[K]</ref>  </p><p>This generative process follows prior work in the econometrics, noisy labels and Gaussian Processes literature <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b44">45]</ref>, discussed further in ?3. First note that if we choose each stochastic component to be distributed standard Gumbel independently, j ? i.i.d. G(0, 1) ?j, then the predictive probabilities p c have a closed form solution that is precisely the popular softmax cross-entropy model used in training neural network classification models <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b8">9]</ref>:</p><formula xml:id="formula_1">p c = P (arg max j?[K] u j (x) = c) = exp(? c ) K j=1 exp(? j ) ?? j ? i.i.d. G(0, 1) ?j (2)</formula><p>In other words, this generative process with Gumbel noise distribution is already an implicit standard assumption when training neural network classifiers. In <ref type="bibr" target="#b1">(2)</ref>, the independence and identical assumptions on the noise component is however too restrictive for applications with noisy labels: 1. Identical: for a particular input x some classes may have more noise than others, e.g., given an Imagenet image of a dog there may be high levels of noise on various different dog breeds but we may have high confidence that elephant classes are not present. Hence we need the level of noise to vary per class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Independence: if one class has a high level of noise other related classes may have high/low levels of noise.</p><p>In the above example there may be correlations in the noise levels between different dog breeds.</p><p>Our method breaks both the independence and identical assumptions by assuming that the noise term (x) is distributed multivariate Normal, (x) ? N (0, ?(x)). Computing an input-dependent covariance matrix enables modelling of inter-class label noise correlations on a per image basis. We discuss more formally in Appendix C how going beyond an independent and identical noise model can lead to improved predictions in the presence of label noise. However it also raises a number of challenges;</p><p>First there is now no closed form solution for the predictive probabilities, Eq. (1). In order to address this, we transform the computation into an expectation and approximate using Monte Carlo estimation, Eq. (3).</p><p>Second, notice that the Monte Carlo estimate of Eq. (1) involves computing an arg max which makes gradient based optimization infeasible. We approximate the arg max with a temperature parameterized softmax ? , Eq. (3).</p><formula xml:id="formula_2">p c = P (arg max j?[K] u j (x) = c) = E ?N (0,?(x)) 1 arg max j?[K] u j (x) = c = E ?N (0,?(x)) ( lim ? ?0 softmax ? u(x)) c ? E ?N (0,?(x)) (softmax ? u(x)) c , ? &gt; 0 ? 1 S S i=1 (softmax ? u (i) (x)) c , u (i) (x) ? N (?(x), ?(x)).<label>(3)</label></formula><p>The notation (u(x)) c denotes the c th entry of u(x) and S is the number of MC samples. In the zero temperature limit this approximation is exact, but for non-zero temperatures ? controls a bias-variance trade-off. At lower temperatures the approximation is closer to the assumed generative process but the gradient variance is higher and vice versa. In practice ? is a hyperparameter that must be selected on a validation set. This approximation is similar to the Gumbel-softmax/Concrete distribution <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b30">31]</ref>. A similar derivation can be given in the multilabel classification case in which a temperature parameterized sigmoid is used as a smooth approximation to the hard 1 function for each class, see Appendix A. We analyze the effect of modelling inter-class correlations by taking a Taylor series approximation to Eq. 3 in Appendix C.</p><p>Efficient parametrization of the covariance matrix. ?(x) is a K ? K matrix which is a function of input x. The memory and computational resources required to compute the full ?(x) matrix are impractical for the large-scale image classification datasets used in this paper (with K up to 21k classes). We make a low-rank approximation to</p><formula xml:id="formula_3">?(x) = V (x)V (x) where V (x) is a K ? R matrix, R &lt;&lt; K.</formula><p>To ensure the positive semi-definiteness of the covariance matrix, we compute a K dimensional vector d 2 (x) which we add to the diagonal of V (x)V (x) . In order to sample from our noise distribution we first</p><formula xml:id="formula_4">sample K ? N (0 K , I K?K ), R ? N (0 R , I R?R ), then = d(x) K + V (x) R ,</formula><p>where denotes element-wise multiplication.</p><p>In practice we typically compute V (x) as an affine transformation of a shared representation of x computed by a deep neural network. Suppose that the dimension of this representation is D, then the number of parameters required to compute V (x) is O(DKR). For some datasets with many classes this is still impractically large. For example Imagenet-21k has 21,843 classes and in the below experiments we use R = 50 and a ResNet-152 which has a final layer representation with D = 2048. So computing V (x) requires over 2.2B parameters, which dwarfs the total number of parameters in the rest of the network.</p><p>In order to further reduce the parameter and computational requirements of our method we introduce a parameterefficient version which we use for datasets where the number of classes is too large (Imagenet-21k and JFT). We param-</p><formula xml:id="formula_5">eterize V (x) = v(x)1 R V where v(x)</formula><p>is a vector of dimension R, 1 R is a vector of ones of dimension R and V is a K ?R matrix of learnable parameters which is not a function of x. Sampling the correlated noise component can be</p><formula xml:id="formula_6">simplified, V (x) R = (v(x)1 K V ) R = v(x) (V R ).</formula><p>The total parameter count of this parameter-efficient version is O(DK + KR) which typically reduces the memory and computational requirements dramatically for large-scale generate S standard normal samples</p><formula xml:id="formula_7">K ? N (0 K , I K?K ), R ? N (0 R , I R?R ); if is-parameter-efficient then compute heteroscedastic low-rank component v(x) := W v r(x) + b v ; load homoscedastic low-rank component V ; U (x) := ?(x) + d(x) K + v(x) V R ; else compute low-rank parameters V (x) = W V r(x) + b V ; V (x) := reshape(V (x), [K, R]); U (x) := ?(x) + d(x) K + V (x) R ; end p c = mean(softmax ? U (x), axis = 1)[c]</formula><p>image classification datasets. For example, for Imagenet-21k the number of parameters required to compute V (x) is 44.8M , a 50? reduction. See Algorithm 1 for a full specification of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Heteroscedastic modelling</head><p>Heteroscedastic regression. Heteroscedastic regression is common in the Gaussian Processes <ref type="bibr" target="#b44">[45]</ref> and econometrics literature <ref type="bibr" target="#b41">[42]</ref>. Bishop and Quazaz <ref type="bibr" target="#b2">[3]</ref> introduced a heteroscedastic regression model where a neural network outputs the mean and variance parameters of a Gaussian likelihood: y ? N (?(x), ?(x) 2 ). The negative log-likelihood of the model is particularly amenable to interpretation, Eq. (4).</p><formula xml:id="formula_8">1 N N i=1 1 2?(x i ) 2 (y i ? ?(x i )) 2 + 1 2 log ?(x i ) 2 . (4)</formula><p>We see that the squared error loss term for each example is weighted inversely to the predicted variance for that example, downweighting the importance of that example's label and providing robustness to noisy labels. This heteroscedastic regression model has recently been applied to pixel-wise depth regression <ref type="bibr" target="#b24">[25]</ref> and in deep ensembles <ref type="bibr" target="#b27">[28]</ref>.</p><p>Heteroscedastic classification -diagonal covariance. Kendall and Gal <ref type="bibr" target="#b24">[25]</ref> extend the heteroscedastic regression model to classification by placing a multivariate Normal Closest to our methodology is the approach developed by Collier et al. <ref type="bibr" target="#b8">[9]</ref> which we next describe. The authors reinterpret the method of Kendall and Gal <ref type="bibr" target="#b24">[25]</ref> as an instance of the generative framework we follow in Eq. (1). They show that this connects the method to the discrete choice modelling econometrics literature where the temperature parameterized softmax smoothing function is known as the logit-smoothed accept-reject simulator <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b4">5]</ref>. The authors demonstrate that the softmax temperature does indeed control a biasvariance trade-off and that tuning the temperature results in different training dynamics, qualitatively improved predictions and significantly improved performance on image classification and image segmentation tasks. Both Kendall and Gal <ref type="bibr" target="#b24">[25]</ref> and Collier et al. <ref type="bibr" target="#b8">[9]</ref> always use a diagonal covariance matrix for the latent distribution.</p><p>The latent variable approach to heteroscedastic classification is also standard in the Gaussian Processes literature <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b44">45]</ref>. A diagonal covariance matrix is used and a GP prior is placed on mean and log variance parameters. Again exact inference on the likelihood is intractable and different approximate inference methods are used <ref type="bibr" target="#b19">[20]</ref>.</p><p>Heteroscedastic segmentation -full covariance. Monteiro et al. <ref type="bibr" target="#b32">[33]</ref> introduce Stochastic Segmentation Networks, a method for modelling spatially correlated label noise in image segmentation. Similar to Kendall and Gal <ref type="bibr" target="#b24">[25]</ref> they place a multivariate Normal distribution over the softmax logits in an image segmentation network, but share a lowrank approximation to the full covariance matrix across all the pixels in the image, capturing spatially correlated noise. Unlike our method, Stochastic Segmentation Networks are a) only applied to medical image segmentation datasets, b) do not recognise the softmax as a temperature parameterized smoothing function w.r.t. an assumed generative process and therefore always implicitly use a softmax temperature of 1.0 and c) do not have a parameter-efficient version of the method to enable scaling to large output vocabularies.</p><p>Discussion. Our method combines the best of this prior work and enables scaling to large-scale image classification datasets. We follow Collier et al. <ref type="bibr" target="#b8">[9]</ref> in assuming the generative process in Eq. (1). This gives the benefits of connecting the work to the existing discrete choice modelling econometrics literature and theory. However unlike Collier et al. <ref type="bibr" target="#b8">[9]</ref> we use a low-rank approximation to a full (non-diagonal) covariance matrix in the latent distribution. In the below experiments, we demonstrate that our combination of (a) recognizing the importance of the softmax temperature in controlling a bias-variance trade-off and (b) modelling the inter-class noise correlations yields significantly improved performance compared with individually using (a) or (b). Our parameter-efficient method also enables scaling up correlated heteroscedastic noise models to a scale unprecedented by previous work e.g. Imagenet-21k and JFT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Noisy labels</head><p>We provide a brief overview of some recent methods for training with noisy labels. Bootstrapping <ref type="bibr" target="#b35">[36]</ref> sets the target label to be a linear combination of the ground truth label and the current model's predictions. MentorNet <ref type="bibr" target="#b22">[23]</ref> uses an auxiliary neural network, the MentorNet to output a scalar weighting for each potentially noisy example. Men-torMix <ref type="bibr" target="#b23">[24]</ref> adds mixup regularization <ref type="bibr" target="#b47">[48]</ref> to the MentorNet approach. Co-teaching <ref type="bibr" target="#b17">[18]</ref> jointly trains two neural networks. Each network makes predictions on a mini-batch and the small loss samples are then fed to the other network for learning. It is assumed that small loss examples are more likely to have clean labels. Cao et al. <ref type="bibr" target="#b5">[6]</ref> propose a heteroscedastic adaptive regularization scheme which increases the regularization strength on high noise examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Our main experiment is to evaluate our method on four large-scale image classification datasets and show significant performance improvements over baseline methods. We also provide qualitative analysis of the learned covariance matrices in ?4.1. We analyse the effect of our method on the representations learned by the network in ?4.2. Finally, in ?4.3 we combine our method with Deep Ensembles <ref type="bibr" target="#b27">[28]</ref> to yield a method with full predictive uncertainty.  We provide code which implements our method as a TensorFlow Keras layer <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8]</ref>, in the supplementary material. The layer is a drop-in replacement for the final layer of a classifier, requiring only a simple one line code change from:</p><formula xml:id="formula_9">logits = tf.keras.layers.Dense(...)(x) to logits = MCSoftmaxDenseFA(...)(x).logits</formula><p>No other changes, including to the loss function are required.</p><p>Imagenet ILSVRC12. <ref type="table">Table 1</ref> shows the results on Imagenet ILSVRC12, a dataset of over 1.2M training images with 1k classes. ILSVRC12 is known to have noisy labels <ref type="bibr" target="#b1">[2]</ref>. Only one class can be present for each image. We train a ResNet-152 <ref type="bibr" target="#b18">[19]</ref> for 90 and 270 epochs (further details in Appendix B). Hyperparameters are tuned on a validation set of 50,000 examples that we split off from the training set. As is standard, we report results on the official ILSVRC12 validation set. For our method we use a softmax temperature of 0.9 and covariance matrix rank of 15.</p><p>When trained for 270 epochs our method has a validation set top-1 accuracy of 79.3% statistically significantly better than the baseline models based on an unpaired twotailed t-test. We compare to a homoscedastic baseline (standard neural network training), against which our method improves the top-1 accuracy by 2.6%. Compared to the diagonal covariance method we see a smaller improvement of 0.6% for top-1 accuracy, suggesting that much of the gain is from the diagonal covariance matrix entries, but that the offdiagonal terms give further improvements. We note that we are the first to evaluate the heteroscedastic diagonal model on ILSVRC12. A sensitivity analysis to the number of MC samples is provided in Appendix D. An ablation study equalizing the number of parameters in the heteroscedastic and homoscedastic models is provided in Appendix E.</p><p>Prior work has shown that neural networks fit cleanly labelled data points first and then fit examples with noisy labels <ref type="bibr" target="#b26">[27]</ref>. The purpose of the 90 epoch ablation is to demonstrate the heteroscedastic models gain more from longer training schedules than the homoscedastic model. By overfitting less to noisy labels the heteroscedastic models can be trained for longer e.g., only our heteroscedastic sees improved top-5 accuracy from training for 270 epochs while the increase in top-1 accuracy from the longer training schedule increases from 0.2% from the homoscedastic model, to 0.4% for the diagonal covariance heteroscedastic model to 0.8% for our model. This demonstrates that despite the parameter count of the heteroscedastic models being higher than the homoscedastic models, the additional parameters do not lead to more overfitting, see Appendix E.</p><p>WebVision. WebVision 1.0 <ref type="bibr" target="#b29">[30]</ref> is a popular benchmark for noisy label techniques with the same 1,000 classes as Imagenet ILSVRC12. Labels are gathered through a noisy automated process based on co-occuring text with the images which are scraped from the Web. The training set consists of 2.4M examples and we report results on the validation set, as is standard, which has 50,000 examples.</p><p>Following other approaches in the literature <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b5">6]</ref> we use a InceptionResNet-v2 architecture <ref type="bibr" target="#b39">[40]</ref> with the same softmax temperature and covariance matrix rank as the above ILSVRC12 experiments. Other hyperparameters are taken from Jiang et al. <ref type="bibr" target="#b23">[24]</ref>, however we adopt a longer training schedule of 95 epochs. Following previous methods we report top-1 and top-5 accuracy on both the WebVision validation set and on the ILSVRC12 validation set. For the methods we implement we also report negative log-likelihood.</p><p>Our method achieves a new state-of-the-art on WebVision 1.0 with top-1 accuracy of 76.6% and top-5 accuracy of 92.1% on the WebVision validation set. See <ref type="table" target="#tab_2">Table 2</ref>   Multilabel datasets. We can also apply our method to multilabel datasets which may have more than one class in each image. The same latent variable formulation can be used but with temperature parameterized sigmoid smoothing function (see Appendix A). Imagenet-21k and JFT are two large-scale multilabel image classification datasets. Imagenet-21k is a larger version of the standard ILSVRC-2012 Imagenet benchmark <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b8">9]</ref>. It has over 12.8 million training images with 21,843 classes. No standard train/test split is provided, so we use 4% of the dataset as a validation set and a further 4% as the test set.</p><p>JFT-300M <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b25">26</ref>] is a dataset introduced by Hinton et al. <ref type="bibr" target="#b20">[21]</ref> with over 300M training images and validation and test sets with 50,000 images. JFT has over 17k classes and each image can have more than one class (average 1.89 per image). The labels were collected automatically, with 20% of them estimated to be noisy <ref type="bibr" target="#b38">[39]</ref>.</p><p>For Imagenet-21k we train a Resnet-152 <ref type="bibr" target="#b18">[19]</ref> for 90 epochs. Whereas for JFT we train a Resnet-50 <ref type="bibr" target="#b18">[19]</ref> for 30 epochs. Further experimental setup details in Appendix B. Sigmoid temperature of 0.15 is used for the heteroscedastic methods. For our method the covariance matrix rank is set to 50 and as the number of classes is large for both datasets, we use the parameter-efficient version of our method, ?2. <ref type="table" target="#tab_4">Table 3</ref> shows the test set results for Imagenet-21k and JFT. Global average precision (gAP), the average precision over all classes, is the metric of interest. The diagonal covariance heteroscedastic method with tuned sigmoid temperature provides gains over standard neural network training and modelling the full covariance martix provides further impovements in gAP for both datasets. On Imagenet-21k the additional improvement from modelling the full covariance matrix is more marginal than for JFT. We include an ablation to demonstrate the importance of the smoothing function temperature parameter. For both datasets, the performance of the diagonal method is significantly degraded at ? = 1.0, which corresponds to the model of Kendall and Gal <ref type="bibr" target="#b24">[25]</ref>, compared to ? * = 0.15. We note that Collier et al. <ref type="bibr" target="#b8">[9]</ref> have already empirically demonstrated the temperature controls a bias-variance trade-off in the training dynamics of the diagonal covariance heteroscedastic model.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Qualitative analysis of learned covariances</head><p>We can examine cases where our heteroscedastic model makes the correct prediction but the standard homoscedastic model is incorrect. Particularly we are interested in understanding whether there is structure in the covariance matrix of our method which helps explain the correct prediction. Note that we can reconstruct the full covariance matrix as</p><formula xml:id="formula_10">?(x) = diag(d(x) 2 ) + V (x)V (x) .</formula><p>In <ref type="table" target="#tab_8">Table 5</ref>  diction has the highest absolute covariance with the correct class and the heteroscedastic prediction is correct but the homoscedastic prediction is incorrect. We see that these cases broadly fall in two categories which can easily contribute to noisy labels; 1) substitutes, e.g., a castle and a palace are two easily confused classes and 2) co-occurrence, e.g., a computer keyboard and a space bar are likely to occur in the same image but which one is considered the most prominent class by the annotator may be unclear.</p><p>In <ref type="table" target="#tab_6">Table 4</ref> we look at the class pairs with the highest absolute covariance averaged over the ILSVRC12 validation set. We compute the average covariance matrix over the 50,000 validation set images and extract the top-10 entries by absolute value. The class pairs, all are substitutes for each other or commonly co-occur. There are just under 1M possible class pairs, it is remarkable that the average covariance matrix exhibits such clear and consistent structure.</p><p>We now conduct a simple analysis to show that the above examples are not anecdotal but that the learned covariance matrices are structured. For one homoscedastic and one heteroscedastic model selected from the previous Imagenet ILSVRC12 experiments there are 3,565 out of 50,000 validation set images where our model makes a correct prediction but the homoscedastic model is incorrect. <ref type="figure" target="#fig_3">Figure  (2)</ref> shows a histogram of the rank of the sorted absolute covariance between the homoscedastic prediction and the correct class. Clearly the class the homoscedastic model has incorrectly predicted, is much more likely to have a high absolute covariance to the correct class in our learned covariance matrix. Assuming that the incorrect homoscedastic prediction is sometimes a plausible label then we see that the heteroscedastic model has learned to associate the noise on the correct class with the noise on plausible alternatives. This is consistent with our analysis of the 2nd order Taylor series approximation to our model's log-likelihood, Appendix C. We expect to see covariances of commonly confused class pairs to be strengthened during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Transfer of learned image representations</head><p>Often large-scale image classification datasets are used to pre-train representations which are fine-tuned on smaller specialized datasets <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b34">35]</ref>. We wish to evaluate the  We test the JFT models on the VTAB <ref type="bibr" target="#b46">[47]</ref>. VTAB consists of 19 unseen downstream classification datasets which cover a variety of visual domains and tasks. We evaluate using the VTAB 1K protocol, where each model is fine-tuned on only 1000 datapoints for each downstream dataset. For all 19 datasets the fine-tuned model is homoscedastic, i.e., the heteroscedastic output layer is only ever used for upstream pre-training. The output layer of the network is removed and replaced with a untrained homoscedastic output layer for fine-tuning. For downstream fine-tuning we use the standard hyperparameters and data augmentation settings specified by Kolesnikov et al. <ref type="bibr" target="#b25">[26]</ref>. The VTAB 1K score is an average of the accuracy on all 19 datasets. <ref type="table" target="#tab_10">Table 6</ref> shows VTAB 1K scores. Our parameter-efficient heteroscedastic model, which captures correlations in the JFT label noise, improves the VTAB 1K score by 0.88% over the homoscedastic baseline and by 0.22% over the heteroscedastic diagonal model. We stress that the downstream models are trained without a heteroscedastic output layer, so our experiment demonstrates that a model trained upstream on JFT with a heteroscedastic output layer learns representations which transfer better than a homoscedastic or a heteroscedastic diagonal model.  Our method estimates heteroscedastic aleatoric uncertainty i.e., input-dependent fundamental label noise in the data. Most approaches in the Bayesian neural networks literature focus on estimating epistemic uncertainty over the network's parameters <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b27">28]</ref>. Our method can be easily combined with many of these methods, giving an estimate of full predictive uncertainty. We successfully combine our method with Deep Ensembles <ref type="bibr" target="#b27">[28]</ref>, a method inspired by Bayesian approaches, that compares favorably in uncertainty modelling benchmarks <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b16">17]</ref>. To form a deep heteroscedastic ensemble we train each ensemble member with our heteroscedastic layer and average the predictions of the ensemble members, as in a standard (homoscedastic) Deep Ensemble.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Deep Ensembles for Full Predictive Uncertainty</head><p>A ResNet-50 <ref type="bibr" target="#b18">[19]</ref> trained on Imagenet ILSVRC12 is a standard uncertainty quantification benchmark <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b42">43]</ref>. We train our method and a standard homoscedastic method using 4 different random seeds. We then create an ensemble of each method. We use rank 15 covariance matrices and softmax temperature of 1.5 for the heteroscedastic method and train for 180 epochs. Homoscedastic models are trained for 90 epochs as this maximizes validation set log-likelihood. <ref type="table" target="#tab_12">Table 7</ref> shows the results. We also report expected calibration error <ref type="bibr" target="#b14">[15]</ref>, a standard metric for uncertainty benchmarks which measures how calibrated a network's predictions are independent of its performance.</p><p>Going from a single homoscedastic model to a ensemble of homoscedastic models provides a substantial improvement in all metrics as does going from a single homoscedastic to our heteroscedastic model. However the best top-1 accuracy, negative log-likelihood and ECE are achieved by a Deep Ensemble of heteroscedastic models. The improvement in top-1 accuracy for the heteroscedastic ensemble (79.5%) compared to the homoscedastic model (76.1%) is greater than the combined gains from ensembling homoscedastic models and the heteroscedastic single model, perhaps due to additional diversity of the ensemble members. Code to reproduce these results and a leaderboard of methods is available publicly 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have introduced a new probabilistic method for deep classification under input-dependent label noise. Our method models inter-class correlations in the label noise. We show that the learned correlations correspond to known sources of label noise such as two classes being visually similar or co-occurring. The proposed method scales to very largescale datasets and we see significant gains on Imagenet ILSVRC12, Imagenet-21k and JFT. We set a new state-ofthe-art top-1 accuracy on WebVision. The representations learned by our model on JFT transfer better when fine-tuned on 19 datasets from the VTAB. We combine our method with Deep Ensembles, giving a method for full predictive uncertainty estimation and see substantially improved accuracy, log-likelihood and expected calibration error on ILSVRC12.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multilabel classification</head><p>The extension to the multilabel case is simple. Each label is treated independently conditional on the latent u, the arg max is replaced with the 1 indicator function which can be approximated with a temperature parameterized sigmoid.</p><formula xml:id="formula_11">p c = P (y c = 1|x) = P (1 {u(x) c &gt; 0}) = E ?N (0,?(x)) [1 {u(x) c &gt; 0}] = E ?N (0,?(x)) lim ? ?0 sigmoid ? u(x) c ? E ?N (0,?(x)) sigmoid ? u(x) c , ? &gt; 0 ? 1 S S i=1 sigmoid ? u (i) (x) c , u (i) (x) ? N (?(x), ?(x)).<label>(5)</label></formula><p>B. Experimental details Imagenet ILSVRC12. We train a ResNet-152v2 <ref type="bibr" target="#b18">[19]</ref> for 90 and 270 epochs. Stochastic gradient descent with momentum factor = 0.9 and initial learning rate of 0.1 is used as the optimizer. The learning rate is decayed by a factor of 10? at For all heteroscedastic models the optimal sigmoid temperature of 0.9 is tuned on the validation set. A rank 15 low-rank approximation to the covariance matrix is used for our method. 10,000 MC samples are used at train and eval time for the heteroscedastic methods.</p><p>WebVision 1.0. We train an Inception-ResNetv2 <ref type="bibr" target="#b39">[40]</ref> for 95 epochs. A distributed asynchronized stochastic gradient descent optimizer with momentum factor = 0.9 and initial learning rate of 0.1 is used. The learning rate is decayed by a factor of 10? at 40, and 80 epochs. During the first 2 epochs the learning rate follows a linear warm-up schedule. L2 regularization with weight 4 ? 10 ?5 is used. Efficientnet <ref type="bibr" target="#b40">[41]</ref> preprocessing is used during training. Models are trained on 32 NVIDIA v100 GPUs with a per GPU batch size of 64. For all heteroscedastic models the optimal softmax temperature of 0.9 is chosen based on the Imagenet ILSVRC12 optimal hyperparamters. A rank 15 low-rank approximation to the covariance matrix is used for our method. 1,000 MC sam-ples are used at train and eval time for the heteroscedastic methods.</p><p>Imagenet-21k. We train a ResNet-152v2 <ref type="bibr" target="#b18">[19]</ref> for 90 epochs. Stochastic gradient descent with momentum factor = 0.9 and initial learning rate of 0.1 is used as the optimizer. The learning rate is decayed by a factor of 10? at 30, 60 and 80 epochs. During the first 5000 steps the learning rate follows a linear warm-up schedule. L2 regularization with weight 1 ? 10 ?2 is used for the parameters mapping from the shared representation space to the low-rank covariance matrix, L2 regularization with weight 3 ? 10 Gradients are clipped to a maximum L2 of 1.0. For all heteroscedastic models the optimal sigmoid temperature of 0.15 is chosen based on the Imagenet-21k optimal hyperparamters. A rank 50 low-rank approximation to the covariance matrix is used for our method. 1,000 MC samples are used at train and eval time for the heteroscedastic methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Analysis of the effect of the covariance matrix on the log-likelihood</head><p>We examine the effect of the covariance on the loglikelihood of our method, particularly in contrast to the homoscedastic log-likeihood. We make a 2 nd order Taylor series approximation to the log-likelihood of our method and show that the approximation decomposes into a term which corresponds to the homoscedastic log-likelihood and 2 nd order term which depends on the covariance matrix. We first examine the case when the covariance matrix is diagonal and then turn to the full covariance case.</p><p>For brevity denote the softmax(u) k = exp(u k ) j exp(uj ) as s k (u) which will sometimes abbreviate to s k when the softmax argument is clear. For simplicity we drop the dependence on the softmax temperature.</p><p>2 nd order Taylor series approximation. The second order Taylor series approximation to a single sample of the heteroscedastic output layer is given in Eq. <ref type="bibr" target="#b5">(6)</ref>.</p><formula xml:id="formula_12">s k (W x + V ) ? s k (W x) + ?s k (W x) V + 1 2 V ? 2 s k (W x)V<label>(6)</label></formula><p>where, ? N (0 K , I K?K ).</p><p>Marginalizing over , the second term vanishes as E [ ] = 0. Hence the second order Taylor series approximation to the likelihood is:</p><formula xml:id="formula_13">E [s k (W x + V )] ? s k (W x) + 1 2 tr(? 2 s k (W x)V V )<label>(7)</label></formula><p>Lemma C.1 The Hessian of s k , Hs k , has the following structure:</p><formula xml:id="formula_14">? ? ? ? ? ? ? ? ? ? ? ? . . . ? ? ? ? ? ? ? ? ? s k (1 ? s k )(1 ? 2s k ) ? ? ? ?s j s k (1 ? 2s k ) ? ? ? . . . . . . 2s k s i s j ?s j s k (1 ? 2s k ) ? ? ? ?s k s j (1 ? 2s j ) ? ? ? ? ? ? ? ? ? . . . ? ? ? ? ? ? ? ? ? ? ? ?</formula><p>Proof. Note that the first derivative of the s k falls into two cases:</p><formula xml:id="formula_15">?s k (u) ?u k = ?s k s j k = j s k (1 ? s k ) k = j.<label>(8)</label></formula><p>The second derivatives breakdown into four cases:</p><formula xml:id="formula_16">Case 1: k = j, ? 2 s k (u) ?uj u k = ?s j s k (1 ? 2s k ) Case 2: ? 2 s k (u) ? 2 u k = s k (1 ? s k )(1 ? 2s k ) Case 3: i, j = k, i = j, ? 2 s k (u) ?uiuj = 2s k s i s j Case 4: j = k, ? 2 s k (u) ? 2 uj = ?s k s j (1 ? 2s j )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Diagonal covariance</head><p>Henceforth references to s k correspond to s k (W x). First, assume that the covariance matrix V V is diagonal with entries ? 2 1 , ..., ? 2 j , ..., ? 2 K .</p><p>Substituting into Eq. (9) we get a special case of the approximate likelihood for the diagonal covariance case:</p><formula xml:id="formula_17">E [s k (W x + V )] ? s k (1 ? 1 2 K j =k s j (1 ? 2s j )? 2 j + 1 2 (1 ? s k )(1 ? 2s k )? 2 k )<label>(9)</label></formula><p>With log(1 + t) ? t the log-likelihood can be approximated as:</p><formula xml:id="formula_18">log E [s k (W x + V )] ? log(s k ) ? 1 2 K j =k s j (1 ? 2s j )? 2 j + 1 2 (1 ? s k )(1 ? 2s k )? 2 k<label>(10)</label></formula><p>The log s k = log s k (W x) term in Eq. <ref type="formula" target="#formula_0">(10)</ref> is precisely the standard log-likelihood term of a homoscedastic model so the remaining 1</p><formula xml:id="formula_19">2 K j =k ?s j (1 ? 2s j )? 2 j + 1 2 (1 ? s k )(1 ? 2s k )? 2</formula><p>k term accounts for the approximate effect of the diagonal covariance on the heteroscedastic log-likelihood relative to the homoscedastic model.</p><p>Note that: <ref type="figure" target="#fig_5">Fig. 3</ref> shows these derivatives. We see that when we observe a label y = k, then to maximize the log-likelihood, if s j &gt; 0.5 i.e., we are incorrectly classifying the example then the gradient forces ? 2 j to increase and vice versa, if s j &lt; 0.5 the gradient encourages ? 2 k to decrease. In this way a noisy label y = k which may be confused with class j can be explained away by a high ? 2 j term. Likewise if s k &gt; 0.5 i.e., we are correctly classifying the example then the gradient forces ? 2 k to reduce and vice versa, when s k &lt; 0.5 the gradient encourages ? 2 k to increase. Again the ? 2 k allows the model to explain away a noisy label y = k if the model assigns low probability to that label. Interpreting the terms of the Taylor series relies on the 2nd order approximation being a reasonable approximation to the full method. We evaluate the efficacy of the approximation in the diagonal covariance case by training a ResNet-152 for 270 epochs using the 2nd order Taylor series approximation Eq. 9. All hyperparameters are equivalent to those in the main paper. See <ref type="table" target="#tab_15">Table 8</ref> for results. The deterministic approximate method recovers 1.5% of the 2% gains in top-1 accuracy seen by the full stochastic method. This is evidence that the Taylor series approximation is a reasonable approximation to the full method.</p><formula xml:id="formula_20">? ?? 2 j 1 2 K j =k ?s j (1 ? 2s j )? 2 j + 1 2 (1 ? s k )(1 ? 2s k )? 2 k ? ?s j (1 ? 2s j )<label>(11)</label></formula><formula xml:id="formula_21">? ?? 2 k 1 2 K j =k ?s j (1 ? 2s j )? 2 j + 1 2 (1 ? s k )(1 ? 2s k )? 2 k ? (1 ? s k )(1 ? 2s k )<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Top-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Full covariance</head><p>If we allow a full covariance matrix ? = V V then the approximate log-likelihood again breaks down into two terms, the first corresponding to the homoscedastic loglikelihood and the second corresponding to the effect of the heteroscedastic covariance matrix:</p><formula xml:id="formula_22">log E [s k (W x + V )] ? log(s k ) 1 2 K i =j,i,j =k 2s i s j ? ij + 1 2 K j =k ?s j (1 ? 2s k )? jk + 1 2 K j =k ?s j (1 ? 2s j )? jj + 1 2 (1 ? s k )(1 ? 2s k )? kk<label>(13)</label></formula><p>The diagonal covariance terms ? kk and ? jj have the same interpretation to the additional terms in the diagonal covariance log-likelihood Eq. (10). So we will focus on the offdiagonal terms 1</p><formula xml:id="formula_23">2 K i =j,i,j =k 2s i s j ? ij + 1 2 K j =k ?s j (1 ? 2s k )? jk . ? ??ij 1 2 K i =j,i,j =k 2s i s j ? ij ? s i s j ,</formula><p>so covariance matrix entries are encouraged to be large and positive when the product s i s j is large i.e., when both classes i and j are assigned high probability by the homoscedastic term despite y = k. Classes i and j are encouraged to have a co-occurrence noise pattern.</p><p>Likewise, we note the derivative of the 1</p><formula xml:id="formula_24">2 K j =k ?s j (1 ? 2s k )? jk term w.r.t. ? jk , ? ?? jk 1 2 K j =k ?s j (1 ? 2s k )? jk ? ?s j (1 ? 2s k ).</formula><p>We see that to maximize the log-likelihood ? jk is encouraged to be large and positive when both s j and s k are large (top right corner of <ref type="figure">Figure 4</ref>) and highly negative when either s j or s k is large and the other is small. So when we observe a label y = k and classes j and k are assigned high probability then these classes are encouraged to have positively correlated noise i.e. to have a co-occurrence noise pattern. And when only one of the classes j or k has a high probability then the two classes are encouraged to have a substitution pattern in the noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Sensitivity to number of MC samples</head><p>We test the sensitivity of our method to the number of MC samples. In <ref type="table">Table 9</ref> we vary the number of training and test MC samples on Imagenet ILSVRC12, using the same experimental setup as ResNet-152 270 epoch results in the main paper. As expected increasing the number of MC samples improves performance monotonically; however there are diminishing returns beyond 100 samples.  <ref type="table">Table 9</ref>: Sensitivity of ResNet-152 trained for 270 epochs on ILSVRC12 to the number of MC samples. <ref type="figure">Figure 4</ref>: Heatmap of the derivatives of K j =k ?s j (1 ? 2s k )? jk w.r.t. ? jk . This is the effect of a small change in ? jk when j = k on the approximate log-likelihood, up to a constant multiplier, in the full covariance case. If the model is not predicting a high probability for (erroneous) class j, then there is no change to the noise term between j and the correct class k. Otherwise, the model learns anticorrelations or correlations between them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Equalizing the parameter count</head><p>Our method adds additional parameters to the network. We investigate in this section whether the quality gains of our method are due to these additional parameters. The homoscedastic ResNet-152 model for ILSVRC12 has 60,185,128 parameters as compared to the full heteroscedastic method with 15 factors: 92,969,128. By equalizing the number of parameters for the homoscedastic model, we demonstrate that the gains from the heteroscedastic method are not primarily due to the additional parameters.</p><p>In particular we add an additional Dense + ReLU layer with 11,500 output units before the logits layer in a ResNet-152. This brings the total parameter count of the homoscedastic model to 93,200,628. However these additional parameters only lead to a +0.4% increase in Top-1 accuracy, as opposed to +2.6% with the full heteroscedastic method, <ref type="table" target="#tab_17">Table 10</ref>. Therefore the gains we observe from using our method on Imagenet ILSVRC are due primarily to the noise modelling and not the increase in parameter count.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Training on ILSVRC12 with a sigmoid link function</head><p>Prior work argues that ILSVRC12 is in reality a multilabelled dataset i.e. contains multiple objects per images, but that we force it to be a multiclass classification by assigning one of these objects as the "primary" object <ref type="bibr" target="#b1">[2]</ref>. The</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Top-1 Acc Homoscedastic 76.7 Homoscedastic equal params 77.1 Het. Full (ours) 79.3 authors then show that training a homoscedastic model on ILSVRC12 with the sigmoid output activation i.e. as if the ILSVRC12 labels were multilabelled leads to performance improvements. However from a probabilsitic point of view this is an unsatisfying solution. Using a sigmoid link function may yield improved accuracy but the network does not yield a valid probability distribution over the ILSVRC12 labels.</p><p>We have seen that the off-diagonal covariance matrix entries can model substitution patterns between co-occurring objects in a single image. We argue that the gains observed by Beyer et al. <ref type="bibr" target="#b1">[2]</ref> can be understood as arising from the misspecification of the homoscedastic model, due to the i.i.d. additive noise assumption.</p><p>In <ref type="table" target="#tab_19">Table 11</ref> we reproduce the gains from using the sigmoid link function for the homoscedastic model seeing the top-1 accuracy increase from 76.7% to 78.2%. However if we now train heteroscedastic model with the sigmoid link function, we see no significant gain compared to training the heteroscedastic model with a softmax link function. Thus the heteroscedastic noise model explains away the sigmoid effect. Removing the i.i.d. additive noise assumption has yielded a highly performant model which outputs a valid and well calibrated probability distribution over the observed labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Top-1 Acc  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Spot the difference? An Appenzeller (left) and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>u j (x): u(x) = ?(x) + p c = P (y = c|x) = P (arg max j?[K] u j (x) = c) = 1 arg max j?[K] u j (x) = c p( )d</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 :</head><label>1</label><figDesc>Computing p c Input: Boolean is-parameter-efficient = { true/false}; compute shared representation r(x) := f ? (x); compute mean parameter ?(x) := W ? r(x) + b ? ; compute diagonal correction d(x) := W d r(x) + b d ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Histogram of the sorted rank of the absolute covariance between the ground truth class and the homoscedastic model's predicted class for ILSVRC12 validation set examples which the heteroscedastic model predicted correctly and the homoscedastic model did not.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>30 ,</head><label>30</label><figDesc>60 and 80 epochs for the 90 epoch training and 90, 180 and 240 epochs for the 270 epoch training. During the first 5 epochs the learning rate follows a linear warm-up schedule. L2 regularization with weight 10 ?3 is used. Standard data augmentation is used during training, an Inception crop followed by resizing to 224 ? 224 and left-right horizontal flipping. All inputs are scaled to the [?1, 1] range. Models are trained on 4 ? 4 Google Cloud TPUv3s with a batch size of 1,024.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Behaviour of the coefficients that multiply the uncertainty factors in the second and third terms of the approximate likelihood, Eq. (10).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>? (?0.22) 76.7 ? (?0.13) 93.0 ? (?0.16) 92.9 ? (?0.12) 0.98 ? (?0.010) 1.08 ? (?0.007) Het. Diag [9] 78.3 ? (?0.06) 78.7 ? (?0.09) 94.0 ? (?0.06) 94.0 ? (?0.08) 0.88 ? (?0.003) 0.95 ? (?0.008) Het. Full (ours) 78.5 (?0.06)</figDesc><table><row><cell>Method</cell><cell cols="2">Top-1 Acc</cell><cell cols="2">Top-5 Acc</cell><cell cols="2">NLL</cell></row><row><cell></cell><cell>90 epochs</cell><cell>270 epochs</cell><cell>90 epochs</cell><cell>270 epochs</cell><cell>90 epochs</cell><cell>270 epochs</cell></row><row><cell cols="3">Homoscedastic 76.5  79.3 (?0.10)</cell><cell>94.3 (?0.03)</cell><cell>94.5 (?0.11)</cell><cell>0.86 (?0.002)</cell><cell>0.92 (?0.006)</cell></row><row><cell cols="7">Table 1: Results of ResNet-152 trained on ILSVRC12. For heteroscedastic models ?  *  = 0.9. Top-1 and top-5 accuracy and</cell></row><row><cell cols="7">negative log-likelihood ? 1 standard deviation is reported. 5 runs from different random seeds are used.  ? p &lt; 0.05.</cell></row><row><cell cols="4">distribution with diagonal covariance matrix over the soft-</cell><cell></cell><cell></cell></row><row><cell cols="4">max logits in a neural network classifier. They find that</cell><cell></cell><cell></cell></row><row><cell cols="4">the method improves performance on image segmentation</cell><cell></cell><cell></cell></row><row><cell cols="3">datasets which have noisy labels at object boundaries.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>? (?0.07) 91.2 ? (?0.07) 1.03 ? (?0.006) 67.0 ? (?0.08) 86.0 ? (?0.11) 1.49 ? (?0.008) Het. Diag [9] 76.2 ? (?0.15) 91.4 ? (?0.08) 1.01 ? (?0.002) 67.3 ? (?0.10) 86.1 ? (?0.07) 1.47 ? (?0.004)</figDesc><table><row><cell>Method</cell><cell></cell><cell>Webvision</cell><cell></cell><cell></cell><cell>ILSVRC12</cell><cell></cell></row><row><cell></cell><cell>Top-1 Acc</cell><cell>Top-5 Acc</cell><cell>NLL</cell><cell>Top-1 Acc</cell><cell>Top-5 Acc</cell><cell>NLL</cell></row><row><cell>Lee et al. [29]</cell><cell>69.1</cell><cell>86.7</cell><cell>-</cell><cell>61.0</cell><cell>82.0</cell><cell>-</cell></row><row><cell>Jiang et al. [23]</cell><cell>72.6</cell><cell>88.9</cell><cell>-</cell><cell>64.2</cell><cell>84.8</cell><cell>-</cell></row><row><cell>Guo et al. [16]</cell><cell>72.1</cell><cell>89.2</cell><cell>-</cell><cell>64.8</cell><cell>84.9</cell><cell>-</cell></row><row><cell>Saxena et al. [37]</cell><cell>67.5</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Jiang et al. [24]</cell><cell>74.3</cell><cell>90.5</cell><cell>-</cell><cell>67.5</cell><cell>87.2</cell><cell>-</cell></row><row><cell>Cao et al. [6]</cell><cell>75.0</cell><cell>90.6</cell><cell>-</cell><cell>67.1</cell><cell>86.7</cell><cell>-</cell></row><row><cell cols="2">Homoscedastic 76.1  Het. Full (ours) 76.6 (?0.13)</cell><cell>92.1 (?0.09)</cell><cell>0.98 (?0.004)</cell><cell>68.6 (?0.17)</cell><cell>87.1 (?0.13)</cell><cell>1.41 (?0.010)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>WebVision 1.0 results. For het. models, ? * = 0.9. Top-1 and top-5 accuracy and negative log-likelihood ?1 standard deviation is reported for both the WebVision and ILSVRC12 validation sets. 5 runs from different random seeds are used for the homo/heteroscedastic methods, all other results are taken from the literature. ? p-value &lt; 0.05.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>? (?0.14) 3.65 ? (?0.010) 63.1 ? (?0.22) 20.12 ? (?0.090) Heteroscedastic Diag ? = 1.0 [9] 45.9 ? (?0.06) 3.64 ? (?0.003) 63.1 ? (?0.03) 19.95 ? (?0.022) Heteroscedastic Diag ? * = 0.15 [9] 46.8 ? (?0.04) 3.63 (?0.002) 64.1 ? (?0.07) 19.61 ? (?0.030) Heteroscedastic PE ? * = 0.15 (ours) 47.0 (?0.08) 3.62 (?0.005) 64.7 (?0.06) 19.34 (?0.026)</figDesc><table><row><cell>Method</cell><cell>Imagenet-21k gAP Imagenet-21k NLL</cell><cell>JFT gAP</cell><cell>JFT NLL</cell></row><row><cell>Homoscedastic</cell><cell>45.9</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>for</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Imagenet-21k and JFT results for heteroscedastic and homoscedastic models. Heteroscedastic PE, is the parameterefficient version of our method. The test set global average prevision (gAP) and negative log-likelihood ? 1 standard deviation is reported. 5 runs from different random seeds are used. ? p-value &lt; 0.05.</figDesc><table /><note>detailed results. Our method improves upon the best pre- viously published WebVision top-1 accuracy by 1.6% and by 1.1% over the best published ILSVRC12 top-1 accuracy, when training on WebVision. Our baseline homoscedastic and diagonal heteroscedastic methods are strong relative to the previously published WebVision results, perhaps due to our longer than typical 95 epoch training schedule. We note however there is no standard training schedule for WebVi- sion and our experiments showed that none of the models converge with shorter training schedules.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Class pairs with the top-10 absolute covariance, averaged over the ILSVRC12 validation set.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>: 8 ILSVRC12 test set examples where the het-</cell></row><row><cell>eroscedastic model is correct, the homoscedastic model</cell></row><row><cell>is incorrect and the absolute covariance between the het-</cell></row><row><cell>eroscedastic and homoscedastic prediction is the largest of</cell></row><row><cell>all classes to the heteroscedastic prediction.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>VTAB 1K score Homoscedastic 70.46 ? ? 0.5 Heteroscedastic Diag 71.12 ? 0.19 Heteroscedastic PE 71.34 ? 0.23</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>VTAB 1K score ? 1 standard deviation for ResNet50 models pre-trained on JFT and fine-tuned on 19 diverse image classification datasets. ? p-value &lt; 0.05.</figDesc><table><row><cell>transferability of the representations learned by our model.</cell></row><row><cell>We hypothesize that by overfitting less to noisy labels and</cell></row><row><cell>learning a better model of the upstream pre-training distribu-</cell></row><row><cell>tion, our method should learn more general representations.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>Deep Ensemble results ResNet-50 on Imagenet ILSVRC12. For heteroscedastic models, ?</figDesc><table /><note>* = 1.5.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 8 :</head><label>8</label><figDesc>Efficacy of 2nd order Taylor series approximation in diagonal covariance case for ResNet-152 trained on ILSVRC12 for 270 epochs.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 10 :</head><label>10</label><figDesc>Equalizing homoscedastic parameter count for ResNet-152 trained on ILSVRC12 for 270 epochs.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 11 :</head><label>11</label><figDesc>Training a ResNet-152 on ILSVRC12 with softmax vs. sigmoid link function.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/google/uncertaintybaselines/tree/master/baselines/imagenet</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} symposium on operating systems design and implementation ({OSDI} 16)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Xiaohua Zhai, and A?ron van den Oord</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>H?naff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kolesnikov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07159</idno>
	</analytic>
	<monogr>
		<title level="m">Are we done with imagenet? arXiv preprint</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Regression with input-dependent noise: A bayesian treatment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cazhaow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Quazaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="347" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Weight uncertainty in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Cornebise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1613" to="1622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Multinomial probit with a logit kernel and a general parametric specification of the covariatice structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Akiwand Denis</forename><surname>Bolduc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
		<respStmt>
			<orgName>MIT Working Paper</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Heteroskedastic and imbalanced deep learning with adaptive regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.15766</idno>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A simple probabilistic method for deep classification underinput-dependent label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Collier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basil</forename><surname>Mustafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efi</forename><surname>Kokiopoulou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Berent</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.06778</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josip</forename><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Romijnders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander D&amp;apos;</forename><surname>Amour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.08558</idno>
		<title level="m">Sylvain Gelly, Neil Houlsby, Xiaohua Zhai, and Mario Lucic. On robustness and transferability of convolutional neural networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghassen</forename><surname>Michael W Dusenberry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeming</forename><surname>Jerfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yian</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.07186</idno>
		<title level="m">Efficient and scalable bayesian neural nets with rank-1 factors</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dropout as a bayesian approximation: Representing model uncertainty in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1050" to="1059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Concrete dropout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Hron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3581" to="3590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1321" to="1330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Curriculumnet: Weakly supervised learning from large-scale web images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenfan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengke</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinglong</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Evaluating scalable bayesian deep learning methods for robust computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Fredrik K Gustafsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">B</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="318" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Coteaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingrui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mind the nuisance: Gaussian process classification using privileged noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hern?ndez-Lobato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktoriia</forename><surname>Sharmanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Christoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Novi</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Quadrianto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1503.02531.1" />
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Categorical reparameterization with gumbel-softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1611.01144.3" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Learning Representations</title>
		<meeting>the 5th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<title level="m">MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels. International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Beyond synthetic noise: Deep learning on controlled noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mason</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">What uncertainties do we need in bayesian deep learning for computer vision?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="5574" to="5584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Big transfer (bit): General visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.11370</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devansh</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maxinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tegan</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asja</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Simple and scalable predictive uncertainty estimation using deep ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="6402" to="6413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cleannet: Transfer learning for scalable image classifier training with label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuang-Huei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjun</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirikur</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<title level="m">Webvision database: Visual learning and understanding from web data</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The concrete distribution: A continuous relaxation of discrete random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Chris J Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1611.00712.3" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Learning Representations</title>
		<meeting>the 5th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A method of simulated moments for estimation of discrete response models without numerical integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Mcfadden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica: Journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="995" to="1026" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo?c</forename><forename type="middle">Le</forename><surname>Folgoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Coelho De Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Van Der Wilk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06015</idno>
		<title level="m">Stochastic segmentation networks: Modelling spatially correlated aleatoric uncertainty</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Bayesian learning for neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Transfusion: Understanding transfer learning for medical imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3347" to="3357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Data parameters: A new family of parameters for learning a differentiable curriculum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreyas</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Decoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Can you trust your model&apos;s uncertainty? evaluating predictive uncertainty under dataset shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Ovadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Fertig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="13969" to="13980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Revisiting unreasonable effectiveness of data in deep learning era</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, AAAI&apos;17</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence, AAAI&apos;17</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Discrete choice methods with simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kenneth E Train</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge university press</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Combining ensembles and data augmentation can harm your calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeming</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghassen</forename><surname>Jerfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Dusenberry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.09875</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Wenzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bastiaan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Veeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linh</forename><surname>Swi?tkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Mandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Snoek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.02405</idno>
		<title level="m">Tim Salimans, Rodolphe Jenatton, and Sebastian Nowozin. How good is the bayes posterior in deep neural networks really? arXiv preprint</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Gaussian processes for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><forename type="middle">Edward</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rasmussen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>MIT press</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Bayesian deep learning and a probabilistic perspective of generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08791</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Sylvain Gelly, and Neil Houlsby. A large-scale study of representation learning with the visual task adaptation benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Ruyssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Riquelme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josip</forename><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><forename type="middle">Susano</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
