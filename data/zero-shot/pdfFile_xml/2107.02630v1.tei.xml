<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. XX, NO. XX, MONTH YEAR 1 Hyperspectral Pansharpening Based on Improved Deep Image Prior and Residual Reconstruction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wele</forename><surname>Gedara</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Chaminda</forename><surname>Bandara</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Jeya</forename><forename type="middle">Maria</forename><surname>Jose Valanarasu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Senior Member, IEEE</roleName><forename type="first">Vishal</forename><forename type="middle">M Patel</forename></persName>
						</author>
						<title level="a" type="main">IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. XX, NO. XX, MONTH YEAR 1 Hyperspectral Pansharpening Based on Improved Deep Image Prior and Residual Reconstruction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Hyperspectral pansharpening</term>
					<term>Hyperspectral image fusion</term>
					<term>Deep Image Prior</term>
					<term>Spatial and Spectral constraints</term>
					<term>Over-complete representations</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hyperspectral pansharpening aims to synthesize a low-resolution hyperspectral image (LR-HSI) with a registered panchromatic image (PAN) to generate an enhanced HSI with high spectral and spatial resolution. Recently proposed HS pansharpening methods have obtained remarkable results using deep convolutional networks (ConvNets), which typically consist of three steps: (1) up-sampling the LR-HSI, (2) predicting the residual image via a ConvNet, and (3) obtaining the final fused HSI by adding the outputs from first and second steps. Recent methods have leveraged Deep Image Prior (DIP) to up-sample the LR-HSI due to its excellent ability to preserve both spatial and spectral information, without learning from large data sets. However, we observed that the quality of up-sampled HSIs can be further improved by introducing an additional spatialdomain constraint to the conventional spectral-domain energy function. We define our spatial-domain constraint as the L1 distance between the predicted PAN image and the actual PAN image. To estimate the PAN image of the up-sampled HSI, we also propose a learnable spectral response function (SRF). Moreover, we noticed that the residual image between the upsampled HSI and the reference HSI mainly consists of edge information and very fine structures. In order to accurately estimate fine information, we propose a novel over-complete network, called HyperKite, which focuses on learning high-level features by constraining the receptive from increasing in the deep layers. We perform experiments on three HSI datasets to demonstrate the superiority of our DIP-HyperKite over the stateof-the-art pansharpening methods. The deployment codes, pretrained models, and final fusion outputs of our DIP-HyperKite and the methods used for the comparisons will be publicly made available at https://github.com/wgcban/DIP-HyperKite.git</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>H YPERSPECTRAL images (HSIs) with a large number of spectral bands have gained immense attention in the field of remote sensing due to its applications in broad research areas such as classification <ref type="bibr" target="#b0">[1]</ref>, unmixing <ref type="bibr" target="#b1">[2]</ref>, anomaly detection <ref type="bibr" target="#b2">[3]</ref>, change detection <ref type="bibr" target="#b3">[4]</ref>, etc. However, due to the limited incident energy available when capturing an image, hyperspectral imaging systems face trade-offs between spectral resolution, spatial resolution, and signal-to-noise ratio (SNR) <ref type="bibr" target="#b4">[5]</ref>. For this reason, hyperspectral imaging systems can provide images with high spectral resolution but with low spatial resolution. In contrast, multispectral imaging systems Wele Gedara Chaminda Bandara, Jeya Maria Jose Valanarasu and, Vishal M. Patel are with Whiting School of Engineering, The Johns Hopkins University, 3400 North Charles Street, Baltimore, MD 21218-2608 USA (email: wbandar1@jhu.edu; jvalana1@jhu.edu; vpatel36@jhu.edu).</p><p>can provide data with high spatial resolution but with fewer spectral bands (e.g., panchromatic images or multispectral images(MSIs) with three or four spectral bands). Low spatial resolution in HSIs leads to relatively poor performance in some practical remote sensing applications, such as road topology extraction <ref type="bibr" target="#b5">[6]</ref>, and spectral unmixing <ref type="bibr" target="#b6">[7]</ref>. Therefore, full-resolution HSIs with high spatial and spectral resolution are desired. One way to obtain such ideal HSIs is to fuse high spectral resolution HSIs with high spatial resolution PAN/MSIs. This fusion process is called HS pansharpening in the remote sensing literature, which is indeed a form of super-resolution.</p><p>Traditional pansharpening methods can be mainly divided into four classes <ref type="bibr" target="#b4">[5]</ref>: (1) component substitution (CS), <ref type="bibr" target="#b1">(2)</ref> multi-resolution analysis (MRA), (3) Bayesian, and (4) matrix factorization. Component substitution methods rely on substituting the spatial component of the HSI with the MSI/PAN image. The family of CS contains algorithms such as Gram-Schmidt adaptive (GSA) <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, principal component analysis (PCA) <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b11">[12]</ref>, and intensity-hue-saturation (IHS) <ref type="bibr" target="#b12">[13]</ref>. Even though the CS methods usually generate pansharpened HSIs with accurate spatial information, sometimes they suffer from critical spectral distortions. The MRA approaches are based on injecting the spatial details obtained through the multi-scale decomposition of the MSI/PAN image into the HSI. In order to extract the spatial details from the PAN image, several algorithms have been proposed in the literature, such as decimated wavelet transform (DWT) <ref type="bibr" target="#b13">[14]</ref>, undecimated wavelet transform (UDWT) <ref type="bibr" target="#b14">[15]</ref>, smoothing filter-based intensity modulation (SFIM) <ref type="bibr" target="#b15">[16]</ref>, modulation transfer function with generalized Laplacian pyramid (MTF-GLP) <ref type="bibr" target="#b16">[17]</ref>, and MTF-GLP with high-pass modulation (MTF-GLP-HPM) <ref type="bibr" target="#b17">[18]</ref>. In contrast to the CS methods, the MRA family performs better in spectral preservation, but is more sensitive to registration errors which may cause critical distortions in the spatial domain. Due to these inherent advantages and disadvantages of CS and MRA approaches, there have been works which attempted to combine both CS and MRA methods. One of the representatives of hybrid CS and MRA algorithm is guided filter PCA (GFPCA) <ref type="bibr" target="#b18">[19]</ref>. The Bayesianbased methods also provide a convenient way to regularize the fusion methods by modeling the posterior distribution of the target HSI provided that the LR-HSI and MSI/PAN image. Examples of the algorithms based on the Bayesian inference framework include convex regularization under a Bayesian framework (abbreviated as Hysure) <ref type="bibr" target="#b19">[20]</ref>, naive Bayesian Gaussian prior (abbreviated as BF) <ref type="bibr" target="#b20">[21]</ref>, and sparsity promoted arXiv:2107.02630v1 [cs.CV] 6 Jul 2021</p><p>Gaussian prior (abbreviated as BFS) <ref type="bibr" target="#b21">[22]</ref>. Finally, the coupled non-negative matrix factorization (abbreviated as CNMF) is one of the examples for matrix factorization-based methods, which regularizes the fusion problem by using the priors of spectral unmixing <ref type="bibr" target="#b22">[23]</ref>. However, the fusion performance of traditional pansharpening approaches is generally limited due to their inadequate representation ability. In addition, the algorithms mentioned above may result in severe quality degradation when the assumptions do not align with a particular dataset. Furthermore, most traditional pansharpening approaches typically reach the optimal solution through an iterative process, which is time-consuming and inefficient.</p><p>Recently, deep learning (DL) models based on convolutional neural networks (ConvNets) have also been introduced for the HS pansharpening problem due to ConvNets' excellent ability to learn high-level features automatically. ConvNet-based HS pansharpening methods generally consist of three steps, 1) Up-sampling step: Up-sampling the LR-HSI to the spatial resolution of the PAN image, 2) Residual reconstruction step: Concatenating the upsampled HSI and PAN image along the spectral dimension and passing it through a residual learning network to learn the residual image, 3) Final fusion step: Obtaining the final fused HSI by adding the up-sampled HSI and the residual image.</p><p>There have been many methods proposed to up-sample LR-HSI to the spatial resolution of PAN. In the earliest studies, nearest-neighbor and bicubic interpolation were the famous methods to perform up-sampling. However, the methods mentioned above conduct upsampling on each band of the LR-HSI successively, thus ignoring the high spectral correlation of HSIs which may lead to spectral distortions <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. In order to minimize the spectral distortion, data-driven up-sampling techniques (i.e., deep super-resolution networks) have also been utilized in HS pansharpening. The LapSRN <ref type="bibr" target="#b25">[26]</ref> network is an example of such a data-driven super-resolution method, which progressively super-resolves a LR image in a coarseto-fine manner in a Laplacian pyramid framework. However, the LapSRN method requires a large number of images for training which is impractical in the HS domain due to the limited number of datasets available to the public. A remedy to the problem mentioned above was proposed by Ulyanov et al. <ref type="bibr" target="#b24">[25]</ref> where they proposed a deep learning-based superresolution framework called deep image prior (DIP). The proposed method uses a randomly initialized ConvNet to upsample an image, using its structure as an image prior, similar to bicubic upsampling. However, this method does not require any training but produces much cleaner results with sharper edges. Motivated by the super-resolution performance of DIP in the RGB domain, researchers have applied DIP to the HS pansharpening problem <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b26">[27]</ref> and achieved impressive results. However, we observed that the energy function defined in HS DIP up-sampling directly applies the energy function formulated for the RGB DIP process, where they only impose spectral-domain constraint by computing the L 1 distance between the down-sampled version of the target up-sampled HSI and the LR-HSI. However, the existing HS DIP methods do not impose any spatial-domain constraint by utilizing the available PAN image. We address this issue by introducing an additional spatial-domain constraint to the HS DIP process as our first contribution.</p><p>For residual reconstruction, various ConvNet architectures have been proposed in the literature to accurately predict the residual component between the up-sampled HSI and the reference HSI with less spectral and spatial distortion. Among those, Giuseppe et al. <ref type="bibr" target="#b27">[28]</ref> was the first to introduce simple three-layer ConvNet architecture for the residual learning. Further, Lin et al. <ref type="bibr" target="#b28">[29]</ref> improved the spatial and spectral prediction capability of Giuseppe's work (abbreviated as HyperPNN) by introducing spectral and spatial prediction modules. To further enhance the representational power of ConvNets, attention mechanisms <ref type="bibr" target="#b29">[30]</ref> have also been introduced. Among those, Zheng et al. <ref type="bibr" target="#b23">[24]</ref> proposed a spatial and spectral attention mechanism (abbreviated as DHP-DARN) for the residual learning in which they cascade several channel-spatial-attention residual blocks to adaptively learn more informative channel-wise and spatial-domain features simultaneously. More recently, Xu et al. <ref type="bibr" target="#b30">[31]</ref> proposed a design (abbreviated as SDPNet) based on two encoder-decoder networks to extract deep-level features from two types of source images with densely connected blocks to strengthen feature propagation. However, we experimentally observed that most of the existing residual learning methods fail when predicting the high-frequency information, such as edges and delicate structures in the residual image. The main reason for this observation is due to the fact that the increasing receptive field of the network in the deep layers. Motivated by this observation, we introduce an over-complete network, called HyperKite, for residual reconstruction task as our second contribution, which constrains the receptive field from increasing in deep layers thus extracting more high-frequency information.</p><p>The main contributions of this paper are summarized as follows:</p><p>1) A novel spatial constraint is introduced for the DIP upsampling process. To the best of our knowledge, this is the first study that integrates both spatial and spectral constraints to the DIP up-sampling. The proposed spatial constraint significantly improves the spatial and spectral performance measures of the up-sampled HSIs. 2) An over-complete network, called HyperKite, is proposed for the residual reconstruction, which is highly capable of extracting high-frequency information of the residual image by appropriately constraining the receptive field of the network. 3) We conduct extensive experiments to clearly demonstrate the improvements brought in from our contributions to the HS pansharpening. We compared the fusion performance of DIP-HyperKite with both conventional and deep learning-based approaches. The deployment codes, pre-trained models, and final fusion results of our DIP-HyperKite as well as the comparison methods in the results and discussion will be publicly made available at https://github.com/wgcban/DIP-HyperKite.git.</p><p>The rest of this paper is organized as follows. Section II provides some basics DIP and over-complete representations.</p><p>In Section III the proposed DIP-HyperKite is described in detail. Section IV describes the datasets and performance metrics that we used in the experiments. In Section V, the experimental results and discussions of different data sets are presented. Finally, the conclusions are drawn in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK A. DIP for HSI up-sampling</head><p>Generally, ConvNets have an excellent ability to learn realistic image priors from a large amount of visual data, placing them in leading positions on the benchmarks of various image processing tasks <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>. Contrary to the general opinion on deep networks that they require large data to capture image priors, DIP <ref type="bibr" target="#b24">[25]</ref> has shown that a randomly initialized network can capture low-level image statistics before any training. Concretely, in HS pansharpening, DIP can generate the upsampled HSI x dip of the LR-HSI y with spatial up-sampling factor ? by taking a fixed randomly initialized vector z as the input, and utilizing the deep network as a parametric function x dip = f ? (z). Next, the network is optimized over its parameters ? to obtain the up-sampled HSI x dip as follows:</p><formula xml:id="formula_0">x dip = min xdip Q(x dip ; y) + R(x dip ),<label>(1)</label></formula><p>where Q(x dip ; y) is an energy function that controls the fidelity toward the LR-HSI y, and R(x dip ) is a regularization function based on prior knowledge. In <ref type="bibr" target="#b24">[25]</ref>, it has been shown that the regularization term R(x dip ) can be implicitly substituted by the deep network. Therefore, the minimization problem in (1) has simplified to optimizing the network over its parameters ? as follows:</p><formula xml:id="formula_1">? * = arg min ? Q(x dip ; y) s.t. x dip = f ? (z),<label>(2)</label></formula><p>where ? * denotes the optimal set of parameters of the network. Furthermore, the most straightforward and commonly utilized energy function in HS pansharpening is that the L 1 distance <ref type="bibr" target="#b28">[29]</ref> between the down-sampled version of the up-sampled HSI x dip and the LR-HSI y as follows:</p><formula xml:id="formula_2">Q(x dip ; y) = d(x dip ) ? y 1 s.t. x dip = f ? (z),<label>(3)</label></formula><p>where d(?) denotes the down-sampling operator by a factor of ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Over-complete ConvNets</head><p>Most of the current architectures in deep learning are "encoder-decoder" <ref type="bibr" target="#b33">[34]</ref>- <ref type="bibr" target="#b35">[36]</ref> based. Here, the encoder translates the high-dimensional input to a low-dimensional latent space while the decoder learns to take the latent lowdimensional representation back to a high-dimensional output. These type of architectures learn low-level features at their initial layers and high-level features at their deeper layers. These are termed under-complete networks as the input is taken to a lower spatial dimension in the latent space.</p><p>In signal processing, over-complete dictionaries are widely used for their highly robust characteristic <ref type="bibr" target="#b36">[37]</ref>. The number of basis functions here are more than the number of input signal samples which enables a higher flexibility for capturing structure in data. In <ref type="bibr" target="#b37">[38]</ref>, over-complete auto-encoders were found to be better feature extractors for denoising when compared to under-complete auto-encoders. In an over-complete network <ref type="bibr" target="#b38">[39]</ref>, the encoder takes the input data to a higher spatial dimension unlike a traditional encoder. This is achieved by using an upsampling layer after every convolutional layer in the encoder. Using upsampling layers in the encoder causes the receptive field to be constrained in the deep layers. This causes the deep layers in the network to learn more finecontext high-frequency information when compared to undercomplete networks. Increase in receptive field for an overcomplete network can be generalized in an i th layer as follows:</p><formula xml:id="formula_3">RF (w.r.t I) = 1 2 2(i?1) ? k ? k,<label>(4)</label></formula><p>where the initial receptive field of the conv filter is assumed to be k ? k on the image I. This phenomenon has been visualized in <ref type="figure" target="#fig_0">Fig 1.</ref> As shown in <ref type="figure" target="#fig_0">Figure 1</ref> (b), by employing an upsampling layer after every convolutional layer in the encoder, the over-complete network restricts the receptive field size to a smaller region which forces the network to learn very fine edges as it tries to focus heavily on smaller regions. This is completely different from the conventional over-complete architectures where they perform downsampling after each convolution block which makes the network to focus on a much larger region in the input as shown in <ref type="figure" target="#fig_0">Figure 1</ref> (a). Over-complete networks in deep learning is a new topic and was initially proposed for medical image segmentation of small anatomy <ref type="bibr" target="#b38">[39]</ref>. It has since been successfully extended to solve fine-context requiring tasks like fine edge segmentation of 3D volumes <ref type="bibr" target="#b39">[40]</ref>, deep subspace clustering <ref type="bibr" target="#b40">[41]</ref>, MRI reconstruction <ref type="bibr" target="#b41">[42]</ref>, adversarial defense against videos <ref type="bibr" target="#b42">[43]</ref> and image restoration problems like single image de-raining <ref type="bibr" target="#b43">[44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHODOLOGY</head><p>The overall flowchart of the proposed DIP-HyperKite for HS pansharpening is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. As can be seen from <ref type="figure" target="#fig_1">Figure 2</ref> the proposed method consists of two main steps. In the first step, the LR-HSI y ? R l?w?h with w ? h pixels and l spectral bands is up-sampled to the spatial resolution of the PAN image p ? R 1??w??h , where ? denotes the ratio</p><p>Step (i):</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DIP Network</head><p>Step (ii): between spatial resolution of p and y. We denote the output from the DIP process as x dip ? R l??w??h . In the second step, we train an over-complete deep network which takes upsampled HSI x dip and the corresponding PAN images p as inputs to predict the residual component x res between the upsampled HSI x dip and the reference HSI x ref .</p><formula xml:id="formula_4">C Over-complete Network: KiteNet C Concatenation Element-wise addition</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Up-sampling via DIP</head><p>As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, the low resolution HSI y is upsampled to the spatial resolution of the PAN image p using the DIP. This recently introduced DIP method is different from the other existing up-sampling techniques such as bicubic interpolation, and LapSNR <ref type="bibr" target="#b44">[45]</ref>. The main advantage of DIP over these conventional methods is that it does not require a large dataset for training. In other words, for each LR image y, the DIP network takes a fixed random tensor z as an input and optimize the network parameters ? by minimizing the loss function Q which is defined in terms of the output up-sampled image x dip and available LR-HSI y as given in <ref type="bibr" target="#b2">(3)</ref>. In contrast, the LapSRN network utilized in <ref type="bibr" target="#b45">[46]</ref> is highly relied upon the RGB image datasets and the knowledge adaptation techniques. Furthermore, the bicubic and LapSNR methods up-sample each band in the HSI separately; thus ignoring the high spatial correlation between the spectral bands, which results in the loss of spatial details. Although the DIP method is capable of producing high-quality upsampling images compared to the other existing methods, it only utilizes the information from the LR-HSI y, thus only imposing constraint on the spectral domain. However, we observed that the quality of the sampled HSIs can be further improved by incorporating an additional spatial constraint in the loss function using the available PAN image p. In the next section we explain our novel spatial+spectral loss function.</p><p>1) Proposed spatial+spectral energy function for HS DIP: As we discussed in Section II-A, the energy function given in  <ref type="figure">Fig. 3</ref>. The proposed learnable spectral response function s, and the computational procedure of evaluating the spatial loss term Q spatial . We take the up-sampled HSI x dip as the input, and feed it in to a Global Average Pooling (GAP) layer, which yielding a vector with a single entry for each spectral band. Then we pass it through a gating mechanism by forming a bottleneck with two fully-connected (FC) layers (1 ? 1 convolutions) around the non-linearity to learn the spectral response of each band. Next, we apply a Softmax activation function to obtain normalized spectral response s, and then take the channel-wise multiplication followed by channel averaging to obtain the estimated PAN imagep. Finally, we compute the the L 1 distance between the estimated PAN imagep and the reference PAN image p to obtain the spatial loss Q spatial .</p><p>(3) enforces a constraint only in spectral domain by defining the L 1 distance between up-sampled HSI x dip and the LR HSI y. Instead, we propose a loss function (denoted by Q ss ) for HS DIP, which enforces the constraints in both spatial and spectral domains as follows:</p><formula xml:id="formula_5">Q ss = d(x dip ) ? y 1 spectral energy +? ? ? i??l s[i] x dip [i] ? ? ? p 1 spatial energy ,<label>(5)</label></formula><p>where s ? R 1?l denotes the spectral response function,</p><formula xml:id="formula_6">s[i] (scalar) is the spectral response of i-th band, x[i] ? R h?w is the i-th band image of the up-sampled HSI x dip ,</formula><p>is the element-wise multiplication, and ? is a regularization constant. The first term in (5) enforces the spectral constraint on x as in (3), and the additional second term enforces the constraint in spatial domain on x dip by utilizing the available PAN image p.</p><p>In the simplest case, the spectral response function can be approximated as the average across all spectral bands (i.e. <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>. In this scenario, the spatial loss term in <ref type="bibr" target="#b4">(5)</ref> enforces that the average across all the spectral bands in up-sampled HSI x dip to be close as possible to the PAN image p, thus assuming a flat (i.e. uniform) spectral response. However, in general, this assumption is not valid as spectral response varies with wavelength coverage and different spectral bands describe the same semantic information across a wide spectral range with varying quality (i.e. PSNR) <ref type="bibr" target="#b48">[49]</ref>.</p><formula xml:id="formula_7">s[i] = 1/l; ?i ? [1, l])</formula><p>A recent attempt <ref type="bibr" target="#b48">[49]</ref> estimate the spectral response function s by utilizing the larger eigenvalue of the structure tensor (ST) matrix (originally proposed in Harris corner detection algorithm <ref type="bibr" target="#b49">[50]</ref>). However, this method cannot be directly utilized in an end-to-end deep learning network due to the difficulties encountered while performing back-propagation In addition, it is highly computationally complex as it requires to compute derivatives of each band image along both xand y-directions at each iteration of learning as part of constructing the structure tensor matrix. Instead, we propose a computationally lightweight and learnable spectral response function which can be easily integrated into the spatial loss term in <ref type="bibr" target="#b4">(5)</ref> and can be simultaneously learned with DIP.</p><p>In this part we describe our novel way of estimating the spectral response function which is computationally lightweight, differentiable, and can be easily integrated into the existing DIP learning process. The overall computational procedure of estimating the spectral response function and thereby evaluating the spatial energy that we introduced for the DIP process in (5) is graphically depicted in <ref type="figure">Figure 3</ref>. First, we assume that the spectral response is proportional to the ratio of information in each spectral band. The next problem arises with this assumption is how do we quantify the information embedded in each spectral band. Motivated by recently proposed Squeeze-and-Excitation networks, we utilize global average pooling to quantify the global information present in each band. Formally, a statistic q ? R 1?l which quantifies the informative features in each spectral band is generated by shrinking the up-sampled HSI x dip through its spatial dimensions h ? w such that the i-th element in q is </p><formula xml:id="formula_8">q(i) = 1 h ? w h h =1 w w=1 x i (w,h).<label>(6)</label></formula><p>Next, we use a simple gating mechanism to capture the dependencies among spectral bands using the band-wise descriptor q that we obtained in the previous step. We parameterize the spectral response function s by forming a bottleneck with two fully-connected (FC) layers around the non-linearity as follows:</p><formula xml:id="formula_9">s = ?(w 2 ?(w 1 q)),<label>(7)</label></formula><p>where ? is the Sigmoid activation function, ? is the ReLU non-linearity, and w 1 , w 2 are the learnable weight matrices.</p><p>Here, we use Sigmoid activation to guarantee that the spectral responses of all the bands sump up to one.</p><p>2) DIP network: <ref type="figure" target="#fig_4">Figure 4</ref> illustrates a U-Net like deep network that we used for the DIP method. The DIP network includes five down-sampling blocks d[i], five upsampling blocks u[i], and five skip-connection blocks sk[i] (i = 1, 2, .., 5). We use stride convolutions as the down-sampling operator, bilinear up-sampling as the upsampling operator, and Lanczos2 as non-linearity. We initialize the input noise vector with uniform noise between 0 and 0.1. The <ref type="table" target="#tab_0">Table I</ref> tabulates the values of all the hyperparameters of DIP network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Residual learning via over-complete HyperKite</head><p>Our motivation to design an over-complete network for the residual learning task emerged after observing the residual images between DIP up-sampled image x dip and reference HSI x ref as visualized in <ref type="figure">Figure 5</ref>. As we can see from <ref type="figure">Figure 5</ref>, the residual images correspond to different wavelength band   mainly consists of boundary information like edges and other high-frequency components. In order to accurately capture this fine information, we design an over-complete HyperKite for the residual learning as shown in <ref type="figure" target="#fig_5">Figure 6</ref>. The proposed HyperKite consists of an Initial Feature Extraction Network (IFEN), a High-dimensional Feature Mapping Network (HDFMN), and a Final Residual Reconstruction Network (FRRN). The input to the HyperKite x in is obtained by concatenating the up-sampled HSI x dip and the PAN image p along the spectral dimension (denoted as [x dip , p]). The HyperKite starts with the IFEN layer, where one 3 ? 3 convolutional layer is applied followed by Batch Normalization (BN) and LeakyReLU non-linearity to extract initial feature representation as:</p><formula xml:id="formula_10">F D1 = f IFEN (x in )<label>(8)</label></formula><p>where f IFEN (?) denotes the 3 ? 3 convolution followed by LeakyReLU and batch normalization, F D1 denotes the extracted features transformed from x in in D 1 ? R n[0]??w??h dimensional pixel-space, and n[0] is the number of filters in the convolutional layer. <ref type="figure" target="#fig_6">Figure 7</ref> (a) shows six example feature maps of F D1 for the 20-th patch of the Pavia Center dataset that we will introduce in Section IV. As we can see from the figure, the initial feature extraction network f IFEN (?) extract low-level feature of the input x in . In order to capture high-level features that that required for the residual learning, we successively transform the output of IFEN into three higher-dimensional pixel-spaces by utilizing the "bilinear" upsampling denoted as D 2 ? R 2?w?2?h , D 4 ? R 4?w?4?h , and D 8 ? R 8?w?8?h . Then we perform 3 ? 3 convolution followed by BN and LeakyReLU to extract meaningful highlevel features at each higher-dimensional space as,</p><formula xml:id="formula_11">F D2 = f D2 (? F D1 ) (9) F D4 = f D4 (? F D2 ) (10) F D8 = f D8 (? F D4 )<label>(11)</label></formula><p>where ? denotes the "bilinear" interpolation by a factor of 2, f Dd (?) : d ? {2, 4, 8} denotes the 3 ? 3 convolution layer followed by BN and LeakyReLU at the d-th higherdimensional feature space. Next, we successively transform the extracted high-level features to the original dimensional space D 1 by employing "bilinear" downsampling and skip connections. Formally, we can define the operations of HDFMN as,</p><formula xml:id="formula_12">F D4 = f D4 (? F 8 ? F 4 )<label>(12)</label></formula><formula xml:id="formula_13">F D2 = f D2 (? F D4 ? F 2 )<label>(13)</label></formula><formula xml:id="formula_14">F D1 =? F D4 ,<label>(14)</label></formula><p>where ? denotes the "bilinear" downsampling by a factor of 2, ? denotes the feature concatenation operator, f Dd (?) : d ?  <ref type="table" target="#tab_0">Table II.</ref> {0, 2, 4} denotes the 3 ? 3 convolution followed by BN and LeakyReLU at the d-th dimensional feature space, and F Dd is the most relevant high-level features obtained at D d ? {0, 2, 4} space. After flowing through all the downsampling layers (decoder blocks), a 3 ? 3 convolutional layer is employed to recover the spectral dimension, and reconstruct the residual image x red as:</p><formula xml:id="formula_15">x res = f FRNN ( F D1 ? F D1 )<label>(15)</label></formula><p>where f FRNN denotes the 3 ? 3 convolutional layer followed by BN and LeakyReLU employed at FRNN. After carrying out DIP up-sampling and residual prediction of our DIP-HyperKite, the DIP up-sampled HSIs x dip and x res are created. Finally, we can obtain the fused HSI x by using x dip and x res as:</p><formula xml:id="formula_16">x = x res + x dip .<label>(16)</label></formula><p>To this end, we utilize L 1 loss to optimize HyperKite, which has been demonstrated as a superior choice for remote sensing image SR <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b28">[29]</ref> and also experimentally verified to be effective for improving the fusion accuracy. For the </p><formula xml:id="formula_17">training set {x k in , x k ref } L where x k in is the k-th input, x k</formula><formula xml:id="formula_18">L(?) = 1 L L k=1 L k=1 f HyperKite (x k in ) ? x k res 1 .<label>(17)</label></formula><p>Moreover, all the parameter details of our proposed Hy-perKite are summarized in <ref type="table" target="#tab_0">Table II</ref>. We train our network in Pytorch framework using an NVIDIA Quadro 8000 GPU. We use Adam optimizer with a learning rate of 0.001, weight decay of 0.0001 and momentum 0.9 to train HyperKite. We use a batch size of 4 and train the network for 2500 epcochs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL SETTINGS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>To evaluate the performance of our proposed DIP-HyperKite for HS pansharpening, we conduct a series of experiments on three HS data sets, which are described in detail below.</p><p>1) Pavia Center dataset: The Pavia Center scene was captured by the ROSIS camera <ref type="bibr" target="#b50">[51]</ref>. The original HSI consists of 115 spectral bands spanning from 430 to 960 nm. The spatial size of the original image is 1096 ? 1096 pixels, where a single pixel is equivalent to geometric resolution of 1.3?1.3 m 2 . The thirteen noisy spectral bands in the original HSI were discarded, thus resulting in a HSI with 102 spectral bands spanning from 430 to 860 nm. In addition, a rectangular area of size 1096 ? 381 pixels with no information at the center of the original HSI was also discarded, and the resulting "twopart" image with size of 1096 ? 715 ? 102 was used for the experiments. Following the same experimental procedure outlined in <ref type="bibr" target="#b23">[24]</ref>, we also used only the top-left corner of the HSI with size of 960 ? 640 ? 102, and partitioned it into 24 cubic patches of size 160 ? 160 ? 102 with no overlap, which constituted the reference images (x ref ) of Pavia Center data set. In order to generate PAN images (p) and LR-HSIs (y) corresponding to each HR-HSI, we utilize Wald's protocol <ref type="bibr" target="#b51">[52]</ref>. Following the Wald's protocol, we generate PAN images (p) of size 160 ? 160 by averaging first 61 spectral bands of HR reference HSI. In order to generate LR-HSIs of size 40 ? 40 ? 102, we spatially blurred the HR reference HSI with an 8 ? 8 Gaussian filter, and then downsampled the result. The scaling factor (?) was set to 4 for the Pavia Center dataset. We randomly select 17 cubic patches for the training, and the rest of the seven patches forms the testing set of the Pavia Center dataset.</p><p>2) Botswana dataset: The Botswana scene was acquired by the Hyperion sensor on the NASA's Earth Observing 1 (EO-1) satellite. The original Botswana HSI consists of 242 spectral bands spanning from 400 to 2500 nm with spectral resolution of 10 nm. The spatial size of the original Botswana image is 1496 ? 256 pixels. We remove the uncalibrated and noisy spectral bands in the original image, thus resulting in a HSI with 145 spectral bands. Following the same experimental procedure outlined in <ref type="bibr" target="#b23">[24]</ref>, we also use only the top-left corner of the HSI with size of 1200 ? 240 ? 145, and partitioned it into 20 cubic patches of size 120 ? 120 with no overlap, which constitute the reference images x ref of the Botswana dataset. In order to generate PAN images p and the LR-HSIs y corresponding to each HR reference image, we follow the Wald's protocol. We generate PAN images p of size 120 ? 120 by averaging first 31 spectral bands of HR-HSI. To generate LR-HSIs y, we spatially blur the HR-HSI with an 8 ? 8 window, and perform down-sampling. For the Botswana dataset, we set the down-sampling factor ? to 3. We randomly select 14 cubic patches for training, and the rest of the patches are utilized for testing.</p><p>3) Chikusei dataset <ref type="bibr" target="#b52">[53]</ref>: The Chikusei scene was captured by the Headwall Hyperspec-VNIR-C imaging sensor over the agricultural and urban areas in Chikusei, Japan. The original Chikusei HSI consists of 128 spectral bands spanning from 363 to 1018 nm. The spatial size of the Chikusei HSI is 2517 ? 2335 pixels, where a single pixel is equivalent to geometric resolution of 2.5?2.5 m 2 . We used top-left corner of the HSI with size of 2304 ? 2304 ? 128, and partitioned it into 81 cubic patches of size 256?256?128 with no overlap, which constituted the reference images x ref of Chikusei dataset. Following the Wald's protocol, we generate PAN images of size 256 ? 256 by averaging first 65 spectral bands of high resolution HSI. To generate LR-HSIs y, we spatially blur the HR-HSI with an 8 ? 8 window, and perform down-sampling. For the Chikusei dataset, we set the down-sampling factor ? to 4. We randomly select 61 cubic patches for training, and the rest of the patches are utilized for testing.</p><p>Note: The standard deviation (?) of the Gaussian filter that we use to generate LR-HSIs is calculated as ? = 0.4247? <ref type="bibr" target="#b53">[54]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance measures</head><p>In order to evaluate the quality of the proposed pansharpening method, we use different image quality measures. Following <ref type="bibr" target="#b23">[24]</ref>, we use Cross-Correlation (CC), Spectral Angle Mapping (SAM), Root Mean Square Error (RMSE), Errur Relative Globale Adimensionnelle Desynthese (ERGAS), and Peak Signal to Noise Ratio (PSNR). These measures have been widely used in the HSI processing community and are appropriate for evaluating fusion in spectral and spatial resolutions.</p><p>1) Cross-Correlation (CC): The CC metric characterizes the geometric distortion, and is defined as:</p><formula xml:id="formula_19">CC(x, x ref ) = 1 l l i=1 CCS(x i , x i ref )<label>(18)</label></formula><p>where, CCS denotes the cross-correlation for a single-band image as follows:</p><formula xml:id="formula_20">CCS(A, B) = n j=1 (A j ? ? A )(B j ? ? B ) n j=1 (A j ? ? A ) 2 n j=1 (B j ? ? B ) 2<label>(19)</label></formula><p>where, ? A = 1 n n j=1 A j is the sample mean of A. The ideal value of CC is 1.0, which indicates that the two HSIs are highly correlated.</p><p>2) SAM: SAM is a spectral measure which is defined as:</p><formula xml:id="formula_21">SAM(x, x ref ) = 1 n n j=1 SAM(x j , x refj ),<label>(20)</label></formula><p>where given the vectors a, b ? R l ,</p><formula xml:id="formula_22">SAM(a, b) = arccos &lt; a, b &gt; a b ,<label>(21)</label></formula><p>where &lt; a, b &gt; denotes the inner product between a and b, and ? is the L 2 norm. The SAM is a measure of the spectral shape preservation. The SAM values reported in our experiments are in degrees and thus belongs to (?90, 90]. The optimal value of SAM is 0.0. The values of SAM reported in our experiments have obtained by averaging the values for all image pixels.</p><p>3) RSNR/ RMSE: The reconstruction SNR (RSNR) or root mean square error (RMSE) is related to the difference between the reference and fuse images, which is defined as follows:  <ref type="figure">Fig. 8</ref>. The variation of CC, SAM, RMSE, ERGAS, and PSNR with the regularization constant ? in our spectral+spectral energy function Qss for Pavia Center dataset. We select ? = 0.8 as the optimal value of regularization constant for the Pavia Center dataset by considering all the performance metrics.</p><formula xml:id="formula_23">RMSE(x, x ref ) = 1 n ? l x ? x ref 2 F ,<label>(22)</label></formula><formula xml:id="formula_24">RSNR(x, x ref ) = 10 log 10 x ref 2 F x ? x ref 2 F .<label>(23)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) ERGAS:</head><p>Relative dimensionless global error in synthesis (ERGAS) calculates the amount of spectral distortion in the image. The ERGAS measure is defined as:</p><formula xml:id="formula_25">ERGAS = 100 1 d 2 1 l l i=1 RMSE(i) ? i ,<label>(24)</label></formula><p>where d is the ratio between the linear resolution of the PAN image and the HSIs. defined as: </p><formula xml:id="formula_26">d = PAN linear spatial resolution HS linear spatial resolution ,<label>(25)</label></formula><formula xml:id="formula_27">RMSE i = x i ?x i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULTS AND DISCUSSION</head><p>This section presents the results of our proposed DIP-HyperKite for HS pansharpening, and compares it with the state-of-the-art methods on the Pavia Center, Botswana, and Chikusei datasets. For better clarity, we divide this section into two parts. In the first part (section V-A), we highlight the contribution from our proposed spatial+spectral energy function for the DIP up-sampling process and compare it with available state-of-the-art up-sampling techniques such as nearest-neighbor, bicubic, LapSRN, and DIP with only spectral loss. In the second part (section V-B), we present the final fusion results that we obtain from our proposed HyperKite network and compare it with classical and deeplearning-based pansharpening approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Effect of the proposed spatial+spectral energy function for the DIP up-sampling process</head><p>As we discussed in Section III-A, the recently proposed pansharpening methods such as DHP-DARN <ref type="bibr" target="#b23">[24]</ref> and DHP <ref type="bibr" target="#b26">[27]</ref> utilized the DIP process to up-sample the LR-HSI instead of using the nearest-neighbor, bicubic, or LapSRN techniques due to its excellent performance. However, we have observed that the quality of up-sampled HSI can be further improved by carefully redesigning the loss function used in the DIP optimization. Instead of only utilizing spectral constraint in the DIP loss function, we derived a novel loss function with spectral and spatial constraints. This section demonstrates the performance improvement brought by our proposed spa-tial+spectral loss function to the DIP up-sampling process. We compare DIP with the proposed spatial+spectral loss against the DIP with spectral loss only. Furthermore, to make the analysis more comprehensive, we also added a conventional up-sampling techniques used in the HS pansharpening domain, such as nearest-neighbor, and bicubic. Further, motivated by the experimental discussion in <ref type="bibr" target="#b23">[24]</ref>, we also added the results from LapSRN <ref type="bibr" target="#b25">[26]</ref>, which is trained on a large amount of RGB images.   1) Tuning the hyperparameter ? in our spatial+spectral energy function: We start our discussion with the effect of the regularization constant ? in our proposed spatial+spectral loss function as defined in <ref type="bibr" target="#b4">(5)</ref>. The variation of CC, SAM, RMSE, ERGAS and PSNR values when varying the regularization parameter ? from 0.0 to 1.0 for the Pavia Center, Botswana and Chikusei datasets are shown in <ref type="figure">Figure 8</ref>, <ref type="figure">Figure  9</ref>, and <ref type="figure" target="#fig_0">Figure 10</ref>, respectively. As can be seen from these figures, as the value of the regularization constant ? increases, the performance metrics also begin to improve, then hit a saturation point, and then degrade, for all three data sets. Therefore, we carefully select the regularization constant ? for each dataset by considering all the performance metrics. For example, consider the variation of the performance metrics with the regularization constant ? for the Pavia Center dataset which is shown in <ref type="figure">Figure 8</ref>. As we can see, when the value of the regularization constant increases from 0.0 to 0.8, we can see that CC, RMSE, ERGAS, and PSNR start to improve, and when ? increases beyond 0.8 the performance metrics start to degrade. Therefore, we set ? = 0.8 as the optimal value of the regularization constant of our proposed spatial+spectral energy term for the Pavia Center dataset. The variation in performance metrics with the regularization parameter ? for the Botswana and Chikusei datasets are also shown in <ref type="figure">Figure  9</ref> and <ref type="figure" target="#fig_0">Figure 10</ref>, respectively. Following the same analysis we described for the Pavia Center dataset, we select ? = 0.8 as the optimal value of the regularization constant for the Botswana and Chikusei datasets. Note that the performance improvement bringing from our proposed spatial+spectral loss function for the DIP upsampling process. Under the optimal regularization constant (? = 0.8), our spatial+spectral energy function improves the quality of up-sampled HSIs over the spectral loss (equivalent to ? = 0 point in <ref type="figure">Figure 8</ref>, 9, and 10) in-terms of CC, RMSE, ERGAS, and PSNR metrics by 6.64%, 37.8%, 63.4%, 37.3%, and 19.5%, respectively for the Pavia Center dataset. For the Botswana dataset, our proposed loss function improves CC, SAM, RMSE, ERGAS, and PSNR metrics over the DIP with spectral loss by 3.3%, 4.2%, 19.1%, 14.7%, 7.0%, and 5.2%, respectively. Similarly for the Chikusei dataset, our method improves CC, RMSE, ERGAS, and PSNR metrics compared to DIP with spectral loss by 1.8%, 26.3%, 22.9%, 26.2%, and 8.9%, respectively.</p><p>Discussion on the regularization constant ?: Let us first consider the case where the regularization constant ? is set to zero. This is equivalent to the case where we only have the spectral constraint. In this case, the DIP network The RGB image is generated by utilizing the 10-th, 30-th, and 60-th bands of the HSI for blue, green and red bands, respectively. minimizes the distance between the down-sampled version of the up-sampled HSI and the LR-HSI. Since the down-sampling operator acts as a low-pass filter in the frequency domain, what DIP network actually minimizes is that the distance between the low-pass version of the up-sampled HSI and the LR-HSI. Because of this reason, the up-sampled HSI from the DIP network trained only with spectral constraint lacks the high frequency components such as edge information and fine structures. Now let us consider the case where we have both spatial and spectral constraint in the DIP loss function. As we described in Section III-A, we combined the spatial and spectral constraints via regularization parameter ?. The value of ? controls the fidelity of the predicted PAN image towards the actual PAN image. Since the predicted PAN image and the up-sampled HSI are coupled via spectral response function, to make the predicted PAN image close as possible to the actual PAN image, the DIP network tries to predict some of the high-frequency components such as edges and fine structures in the PAN image, while maintaining the lowpass version of the up-sampled HSI close to the LR-HSI. Therefore, the regularization constant what actually controls is the amount of high-frequency components fused from PAN image to the up-sampled HSI. This explain the observation that we made from <ref type="figure">Figure 8</ref>, <ref type="figure">Figure 9</ref>, and <ref type="figure" target="#fig_0">Figure 10</ref>, where when the value of the regularization parameter increases the DIP network embed some of the high-frequency information to the up-sampled HSI, which ultimately helps to improve the quality of the up-sampled image. However, when the value of the regularization constant is large, the spatial loss term starts to dominate the loss function, and resulting in drop of spectral-domain performance metrics such as SAM and ERGAS. Therefore, we can achieve high-quality up-sampled HSIs by appropriately controlling the regularization parameter in spatial+spectral energy function.</p><formula xml:id="formula_28">(a) (b) (c) (d) (e) (f) (g)</formula><p>2) Comparison of DIP with the proposed spatial+spectral loss with state-of-the-art up-sampling techniques: In the previous section, we determined the optimal value of the regularization constant ? for our proposed spatial+spectral loss function for the three datasets. In this section, we compare DIP with our spatial+spectral loss against DIP with only spectral loss, and other commonly used up-sampling techniques such as nearest neighbor, bicubic, and LapSRN, both qualitatively and quantitatively. <ref type="table" target="#tab_0">Table III</ref> summarizes the quantitative results of nearestneighbor, bicubic, LapSRN, and DIP up-sampling methods for the Pavia Center dataset. For this dataset, our proposed DIP method improves the quality of up-sampled images in terms of CC, SAM, RSNR, ERGAS, and PSNR performance measures by 6.6%, 37.3%, 63.4% 37.3%, and 19.5%, respectively. We have also noticed that this improvement is accompanied by a drop in the SAM index which is around 1.8% compared to the DIP with spectral loss. This fall in the SAM index is not that significant compared to the improvements we have achieved in terms of all other performance measures. Further, we can cross-verify these quantitative results with qualitative results that we have shown in <ref type="figure" target="#fig_0">Figure 11</ref> for the Pavia Center dataset. We can see that the DIP up-sampled images with our proposed spatial+spectral constraint looks much more closer to the reference image, and have predicted very fine structures and edges compared to other upsampling methods.</p><p>We also summarize the quantitative results for different up-sampling methods for the Botswana dataset in <ref type="table" target="#tab_0">Table IV</ref>. As we can see, DIP with the proposed spatial+spectral loss improves the quality of up-sampled images in terms of all the performance metrics by a significant margin: CC value increased by 0.4%, SAM value reduced by 4.3%, RMSE value reduced by 14.0%, RSNR value improved by 11.2%, ERGAS value reduced by 1.7%, and PSNR value value increased by 5.2%. Also, we can verify these quantitative results with the qualitative results shown in <ref type="figure" target="#fig_0">Figure 12</ref> for the Botswana dataset. Similar to the qualitative results that we have observed for the Pavia Center dataset, we can see the the up-sampled images using DIP with our proposed spatial+spectral loss is much more closer to the reference HSI.</p><p>Finally, we summarize the quantitative results for different  <ref type="figure" target="#fig_0">Figure 13</ref> for the Chikusei dataset. From the qualitative results also we can see that DIP with our spatial+spectral constraint is able to predict very fine structures and edges more accurately than the other methods. In summary, we have shown that the DIP method with our proposed spatial+spectral constraints outperforms the state-ofthe-art up-sampling methods with a significant margin in all the datasets that we have considered in this study. In the next section, we present final fusion results and compare them with state-of-the-art pansharpening algorithms, qualitatively and quantitatively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Final fusion results:</head><p>In this section we compare final fusion results from our DIP-HyperKite with the state-of-the-art pansharpening approaches such as PCA <ref type="bibr" target="#b10">[11]</ref>, GFPCA <ref type="bibr" target="#b18">[19]</ref>, BF <ref type="bibr" target="#b20">[21]</ref>, BFS <ref type="bibr" target="#b21">[22]</ref>, SFIM <ref type="bibr" target="#b15">[16]</ref>, GS <ref type="bibr" target="#b8">[9]</ref>, GSA <ref type="bibr" target="#b8">[9]</ref>, MTF-GLP-HPM <ref type="bibr" target="#b17">[18]</ref>, CNMF <ref type="bibr" target="#b22">[23]</ref>, MTF-GLP <ref type="bibr" target="#b16">[17]</ref>, HySure <ref type="bibr" target="#b19">[20]</ref>, HyperPNN <ref type="bibr" target="#b28">[29]</ref>, and DHP-DARN <ref type="bibr" target="#b23">[24]</ref> for Pavia Center, Botswana, and Chikusei datasets.</p><p>a) Final Fusion results on the Pavia Center dataset: The average quantitative results for different pansharpening approaches on the testing set of the Pavia Center dataset are shown in <ref type="table" target="#tab_0">Table VI</ref>. As can be seen from <ref type="table" target="#tab_0">Table VI, our</ref> proposed HyperKite achieves the highest CC value compared to all the other pansharpening approaches that we have considered in this study. A higher CC value indicates that the fused HSI is closer to the actual HSI with less geometric distortion. Furthermore, our proposed DIP-HyperKite achieved the smallest values for SAM, RMSE, and ERGAS performance measures, indicating the best fusion performance over the other pansharpening approaches. Especially the smallest SAM and ERGAS indicate that our DIP-HyperKite can fuse HSIs with less spectral distortion than the state-of-the-art methods. In addition, our DIP-HyperKite improved the PSNR metric by 3.6% over the state-of-the-art value. To further verify the fusion quality of our proposed DIP-HyperKite, we present qualitative results in <ref type="figure" target="#fig_0">Figure 14</ref> for the Pavia Center dataset. To better highlight the fusion quality between different pansharpening approaches, we have shown the error plots along with the RGB composite image for each fused HSI. According to the figure, the error maps corresponding to our DIP-HyperKite are much purple than the other pansharpening approaches, indicating minor fusion error. This is mainly because of the ability of our HyperKite network to predict very fine structures and edges by constraining the receptive field of the deep network. b) Final Fusion results on the Botswana dataset: The <ref type="table" target="#tab_0">Table VII</ref> summarizes the average quantitative results of different fusion methods on the Botswana dataset. Similar to the Pavia Center dataset, we can see that our DIP-HyperKite outperforms all the other HS pansharpening approaches by a considerable margin. Concretely, our DIP-HyperKite has improved the CC by 1.03%, and PSNR by 3.71%. In addition, our method has reduced the SAM by 9.68%, RMSE by 8.57%, and ERGAS by 10.85%. Furthermore, we have shown qualitative results related to different pansharpening approaches on Botswana dataset in <ref type="figure" target="#fig_0">Figure 15</ref>. By observing the RGB images and error plots in <ref type="figure" target="#fig_0">Figure 15</ref>, we can see that the fusion results related to our method are much closer to reference image than the other pansharpening approaches. c) Final Fusion results on the Chikusei dataset: In this section, we compare the qualitative and quantitative results on the Chikusei dataset. The average quantitative results of different pansharpening approaches on the Chikusei dataset is listed in <ref type="table" target="#tab_0">Table VIII</ref>. Similar to the results we have observed for the other two datasets, for this dataset also our proposed DIP-HyperKite outperforms all the pansharpening approaches that we considered for the analysis. Our pansharpening method improves the CC, SAM, RMSE, RSNR, ERGAS, and PSNR performance measures over the state-of-the-art results by 1.45%, 19.0%, 6.67%, 0.67%, 18.5%, and 0.90%, respectively. To further highlight the fusion quality of our method we present the qualitative results of selected panshaprpening approaches for the Chikusei dataset is shown in <ref type="figure" target="#fig_0">Figure 16</ref>. By observing the RGB composite image and the error maps we can clearly see that the fusion quality of the proposed DIP-HyperKite is higher than the other pansharpening approaches.</p><p>VI. CONCLUSION In this paper, we have presented a novel approach for HS pansharpening, which mainly consists of three steps: (1) Upsampling the LR-HSI via DIP, (2) Predicting the residual image via over-complete HyperKite, and (3) Obtaining the final fused HSI by summation. The previously proposed DIP methods for HS up-sampling only impose a constraint in the spectral-domain by utilizing LR-HSI. To better preserve both spatial and spectral information, we first exploited an additional spatial constraint to DIP by utilizing the available PAN image, thereby introduced both spatial and spectral constraints to the DIP. The comprehensive experiments conducted on three HS datasets showed that our proposed spatial+spectral loss function significantly improved the quality of up-sampled HSIs in CC, RMSE, RSNR, SAM, ERGAS, and PSNR performance measures. Next, in the residual prediction task, we have shown that the residual component between up-sampled HSI and the reference HSI primarily consists of edge information and very fine structures. Motivated by this observation, we proposed a novel over-complete deep-learning network for the residual prediction task. In contrast to the conventional under-complete representations, we have shown that our over-complete network is competent to focus on high-level features such as edges and fine structures by constraining the receptive field of the network. Finally, the fused HSI is obtained by adding the residual HSI and the up-sampled HSI. The comprehensive experiments conducted on three HS datasets demonstrated the superiority of our DIP-HyperKite over the other state-of-theart results in terms of qualitative and quantitative evaluations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>(a) Effect of under-complete ConvNet on receptive field where the deeper layers focus on a larger region of the input thus extracting highlevel/low-frequency information. (b) Effect of over-complete ConvNet on receptive field where the deeper layers focus on a much smaller region in the input thus extracting low level/high-frequency information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>The overall flowchart of our proposed DIP-HyperKite for HS pansharpening. In the first step, we up-sample the LR-HSI y via DIP process to obtain the up-sampled HSI x dip . The DIP process takes a fixed noise tensor z as input for a given LR-HSI y, and produces the up-sampled HSI x dip by optimizing the proposed spatial+spectral energy function Qss over the DIP network parameters ?. In the second step, we take the up-sampled HSI x dip and the PAN image p as inputs to predict the residual component xres using our proposed over-complete network -HyperKite. Finally, the predicted residual image xres is added to the up-sampled HSI x dip to obtain the pansharpened HSI x.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>The DIP network utilized for the up-sampling process. The DIP network is a U-Net like network which consists of five down-sampling blocks d[i], five upsampling blocks u[i], and five skip-connection blocks sk[i] (i =1, 2, .., 5). The values of all the hyperparameters of DIP network is summarized in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>The proposed HyperKite architecture for the residual prediction task. We denote the kernel size and the number of filters associated with each convolution block (shown in red color box) as k[?] and n[?], respectively. The values of all hyperparameters for HyperKite is summarized in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Visualization of filter responses of HyperKite. (a) Feature maps from the first layer of encoder. (b) Feature maps from the second layer of encoder. (c) Feature maps from the third layer of encoder. (d) Feature maps from the third layer of encoder. By restricting the receptive field, HyperKite is able to focus on edges and smaller regions. Zoom in recommended.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>,</head><label></label><figDesc>and ? i i the sample mean of the i-th band of x ref . The ideal value of ERGAS is 0. 5) Peak Signal to Noise Ratio (PSNR): PSNR also assess the fusion quality of each bans, and the average PSNR is calculated aspixel value in the ith band of x ref . A larger value of PSNR indicates a higher reconstruction quality in spatial information of the fusion result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>The variation of CC, SAM, RMSE, ERGAS, and PSNR with the regularization constant ? in our spectral+spectral energy function Qss for Botswana dataset. We select ? = 0.8 as the optimal value of regularization constant for the Botswana dataset by considering all the performance metrics. The variation of CC, SAM, RMSE, ERGAS, and PSNR with the regularization constant ? in our spectral+spectral energy function Qss for Chikusei dataset. We select ? = 0.8 as the optimal value of regularization constant for the Chikusei dataset by considering all the performance metrics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Up-sampled images of 1-st patch (in 1-st row) and 11-th patch (in 2-nd row) of Pavia Center dataset. (a) LR-HSI. (b) Nearest-neighbor. (c) Bicubic. (d) LapSRN [26]. (e) DIP with only spectral energy [24]. (f) DIP with our spatial+spectral energy (Qss; ? = 0.8). (g) Reference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .</head><label>12</label><figDesc>Up-sampled images of 12-th (in first row) and 14-th (in second row) patch of Botswana dataset. (a) LR-HSI. (b) Nearest-neighbor. (c) Bicubic. (d) LapSRN [26]. (e) DIP with only spectral energy [24]. (f) DIP with our spatial+spectral energy (Qss; ? = 0.8). (g) Reference. The RGB image is generated by utilizing the 10-th, 35-th, and 61-th bands of the HSI for blue, green and red bands, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 .</head><label>13</label><figDesc>Up-sampled images of 37-th (in first row) and 50-th (in second row) patch of Chikusei dataset. (a) LR-HSI. (b) Nearest-neighbor. (c) Bicubic. (d) LapSRN<ref type="bibr" target="#b25">[26]</ref>. (e) DIP with only spectral energy<ref type="bibr" target="#b23">[24]</ref>. (f) DIP with our spatial+spectral energy (Qss (? = 0.8). (g) Reference. The RGB image is generated by utilizing the 12-th, 20-th, and 29-th bands for blue, green and red bands, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 14 .</head><label>14</label><figDesc>Visual results generated by different pansharpening algorithms for the first (in first and second column), third (in third and fourth column), 12-th (in fifth and sixth column), 20-th (in seventh and eight column), 21-st (in nine and tenth column) patches of the Pavia Center dataset. (a) SFIM<ref type="bibr" target="#b15">[16]</ref>. (b) GS<ref type="bibr" target="#b8">[9]</ref>. (c) GSA<ref type="bibr" target="#b8">[9]</ref>. (d) MTF-GLP-HPM<ref type="bibr" target="#b17">[18]</ref>. (e) CNMF<ref type="bibr" target="#b22">[23]</ref>. (f) MTF-GLP<ref type="bibr" target="#b16">[17]</ref>. (g) HySure<ref type="bibr" target="#b19">[20]</ref>. (h) HyperPNN<ref type="bibr" target="#b28">[29]</ref>. (i) DHP-DARN<ref type="bibr" target="#b23">[24]</ref>. (j) DIP-HyperKite (ours). (k) Reference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 15 .</head><label>15</label><figDesc>Visual results generated by different pansharpening algorithms for the first (in first and second column), fourth (in third and fourth column), 12-th (in fifth and sixth column), 16-th (in seventh and eight column), 19-st (in nine and tenth column) patches of the Botswana dataset. (a) SFIM<ref type="bibr" target="#b15">[16]</ref>. (b) GS<ref type="bibr" target="#b8">[9]</ref>. (c) GSA<ref type="bibr" target="#b8">[9]</ref>. (d) MTF-GLP-HPM<ref type="bibr" target="#b17">[18]</ref>. (e) CNMF<ref type="bibr" target="#b22">[23]</ref>. (f) MTF-GLP<ref type="bibr" target="#b16">[17]</ref>. (g) HySure<ref type="bibr" target="#b19">[20]</ref>. (h) HyperPNN<ref type="bibr" target="#b28">[29]</ref>. (i) DHP-DARN<ref type="bibr" target="#b23">[24]</ref>. (j) DIP-HyperKite (ours). (k) Reference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 16 .</head><label>16</label><figDesc>Visual results generated by different pansharpening algorithms for the fifth (in first and second column), 13-th (in third and fourth column), 16-th (in fifth and sixth column), 27-th (in seventh and eight column), 32-nd (in nine and tenth column) patches of the Chikusei dataset. (a) SFIM<ref type="bibr" target="#b15">[16]</ref>. (b) BF<ref type="bibr" target="#b20">[21]</ref>. (c) GSA<ref type="bibr" target="#b8">[9]</ref>. (d) MTF-GLP-HPM<ref type="bibr" target="#b17">[18]</ref>. (e) BFS<ref type="bibr" target="#b21">[22]</ref>. (f) MTF-GLP<ref type="bibr" target="#b16">[17]</ref>.(g) HySure<ref type="bibr" target="#b19">[20]</ref>. (h) HyperPNN<ref type="bibr" target="#b28">[29]</ref>. (i) DHP-DARN<ref type="bibr" target="#b23">[24]</ref>. (j) DIP-HyperKite (ours). (k) Reference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I HYPERPARAMETER</head><label>I</label><figDesc>VALUES OF THE DIP NETWORK.</figDesc><table><row><cell>Hyperparameter</cell><cell>Value</cell></row><row><cell>z</cell><cell>R 32??h??w ? U (0, 0.1)</cell></row><row><cell>n d = nu</cell><cell>[128, 128, 128, 128, 128]</cell></row><row><cell>k d = ku</cell><cell>[3, 3, 3, 3, 3]</cell></row><row><cell>ns</cell><cell>[4, 4, 4, 4, 4]</cell></row><row><cell>ks</cell><cell>[1, 1, 1, 1, 1]</cell></row><row><cell>Optimizer</cell><cell>Adam</cell></row><row><cell cols="2">Number of iterations 1300</cell></row><row><cell>Learning rate</cell><cell>0.001</cell></row><row><cell>Weight decay</cell><cell>0.0001</cell></row><row><cell>Momentum</cell><cell>0.9</cell></row><row><cell>Batch size</cell><cell>4</cell></row><row><cell>LeakyReLU slope</cell><cell>0.2</cell></row><row><cell></cell><cell>TABLE II</cell></row><row><cell cols="2">HYPERPARAMETER VALUES OF HYPERKITE</cell></row><row><cell>Hyperparameter</cell><cell>Value</cell></row><row><cell>n</cell><cell>[32, 64, 128, 128, 64, 32, l]</cell></row><row><cell>k</cell><cell>[3, 3, 3, 3, 3, 3, 3]</cell></row><row><cell>Optimizer</cell><cell>Adam</cell></row><row><cell>Num it</cell><cell>2500</cell></row><row><cell>Learning rate</cell><cell>0.001</cell></row><row><cell>Weight decay</cell><cell>0.0001</cell></row><row><cell>Momentum</cell><cell>0.9</cell></row><row><cell>Batch size</cell><cell>4</cell></row><row><cell cols="2">LeakyReLU slope 0.2</cell></row><row><cell>calculated as:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table I .</head><label>I</label><figDesc>Fig. 5. We observed that the residual component xres (see third column) between up-sampled HSI x dip (see first column) and the reference HSI x ref (see second column) mainly consists of boundary information and very fine structures. To support this observation we show the residual component xres for three different wavelength bands (i.e. band 10, band 52, and band 100) in the Pavia Center data set which will be introduced in Section IV-A. This observation motivated us to use an over-complete network for the residual learning task, which is highly capable of learning low-level features such as fine edges and structures by transforming the input image into a higher dimension. We recommend that readers zoom in on this image to get a closeup view.</figDesc><table><row><cell>Band 10</cell><cell>Band 10</cell><cell>Band 10</cell></row><row><cell>Band 52</cell><cell>Band 52</cell><cell>Band 52</cell></row><row><cell>Band 100</cell><cell>Band 100</cell><cell>Band 100</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>ref is the corresponding reference HSI, and L is the total number of training HSIs in the training set. The L 1 loss function utilized for HyperKite training can be defined as follows:</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III AVERAGE</head><label>III</label><figDesc>QUANTITATIVE RESULTS FOR DIFFERENT UP-SAMPLING TECHNIQUES ON THE PAVIA CENTER DATASET.</figDesc><table><row><cell></cell><cell>CC</cell><cell cols="5">SAM RMSE RSNR ERGAS PSNR</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell>?10 ?1</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell></row><row><cell>Nearest-neighbor</cell><cell cols="2">0.809 7.70</cell><cell>1.22</cell><cell>9.63</cell><cell>19.97</cell><cell>19.65</cell></row><row><cell>Bicubic</cell><cell cols="2">0.840 7.45</cell><cell>1.13</cell><cell cols="2">11.26 18.48</cell><cell>20.36</cell></row><row><cell>LapSRN [26]</cell><cell cols="2">0.843 7.37</cell><cell>1.12</cell><cell cols="2">11.56 18.16</cell><cell>20.49</cell></row><row><cell cols="3">DIP+spectral [24] 0.844 8.04</cell><cell>0.94</cell><cell cols="2">14.91 15.42</cell><cell>21.89</cell></row><row><cell>DIP+Qss (ours)</cell><cell cols="2">0.900 8.18</cell><cell>0.58</cell><cell cols="2">24.36 9.66</cell><cell>26.15</cell></row><row><cell></cell><cell>(+6.6%)</cell><cell>-</cell><cell>(-37.8%)</cell><cell>(+63.4%)</cell><cell>(-37.3%)</cell><cell>(+19.5%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV AVERAGE</head><label>IV</label><figDesc>QUANTITATIVE RESULTS FOR DIFFERENT UP-SAMPLING TECHNIQUES ON THE BOTSWANA DATASET.</figDesc><table><row><cell></cell><cell>CC</cell><cell cols="5">SAM RMSE RSNR ERGAS PSNR</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell>?10 ?2</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell></row><row><cell>Nearest-neighbor</cell><cell cols="2">0.854 2.52</cell><cell>7.87</cell><cell cols="2">29.03 9.08</cell><cell>28.87</cell></row><row><cell>Bicubic</cell><cell cols="2">0.852 2.42</cell><cell>7.67</cell><cell cols="2">29.60 8.77</cell><cell>29.17</cell></row><row><cell>LapSRN [26]</cell><cell cols="2">0.858 2.47</cell><cell>6.27</cell><cell cols="2">34.01 8.27</cell><cell>29.01</cell></row><row><cell cols="3">DIP+spectral [24] 0.833 2.40</cell><cell>6.66</cell><cell cols="2">32.91 8.75</cell><cell>29.75</cell></row><row><cell>DIP+Qss (ours)</cell><cell cols="2">0.861 2.30</cell><cell>5.39</cell><cell cols="2">37.80 8.13</cell><cell>31.28</cell></row><row><cell></cell><cell>(+0.4%)</cell><cell>(-4.2%)</cell><cell>(-14.0%)</cell><cell>(+11.2%)</cell><cell>(-1.7%)</cell><cell>(+5.2%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V AVERAGE</head><label>V</label><figDesc>QUANTITATIVE RESULTS FOR DIFFERENT UP-SAMPLING TECHNIQUES ON THE CHIKUSEI DATASET.</figDesc><table><row><cell></cell><cell>CC</cell><cell cols="5">SAM RMSE RSNR ERGAS PSNR</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell>?10 ?2</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell></row><row><cell>Nearest-neighbor</cell><cell cols="2">0.861 4.05</cell><cell>9.99</cell><cell cols="2">18.26 17.03</cell><cell>23.73</cell></row><row><cell>Bicubic</cell><cell cols="2">0.884 3.86</cell><cell>0.093</cell><cell cols="2">20.07 15.75</cell><cell>24.52</cell></row><row><cell>LapSRN [26]</cell><cell cols="2">0.885 3.75</cell><cell>8.53</cell><cell cols="2">21.37 14.33</cell><cell>25.06</cell></row><row><cell cols="3">DIP+spectral [24] 0.869 4.64</cell><cell>7.54</cell><cell cols="2">24.16 13.80</cell><cell>25.75</cell></row><row><cell>DIP+Qss(ours)</cell><cell cols="2">0.885 5.05</cell><cell>5.56</cell><cell cols="2">29.69 10.18</cell><cell>28.06</cell></row><row><cell></cell><cell>(+0.1%)</cell><cell>-</cell><cell>(-26.3%)</cell><cell>(+22.9%)</cell><cell>(-26.2%)</cell><cell>(+8.9%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI THE</head><label>VI</label><figDesc>AVERAGE QUANTITATIVE RESULTS ON THE PAVIA CENTER DATASET. Chikusei dataset inTable V. In this case also, the performance of DIP up-sampled images with our proposed spatial+spectral loss outperforms five out of six performance measures that we considered for the analysis. As we can see from theTable V, our DIP method has increased the value of CC by 0.1%, has decreased the value of RMSE by 26.3%, has increased the RSNR by 22.9%, has decreased the ERGAS by 26.2%, and has increased the PSNR by 8.9% over the state-of-the-art results. Similar to the Pavia Center dataset, in this dataset also we have observed that the drop in SAM index; however this is negligible compared to the performance gained in terms of the other quantitative measures. Furthermore, following the similar trend with other datasets, we have included the qualitative results in</figDesc><table><row><cell></cell><cell>CC</cell><cell cols="5">SAM RMSE RSNR ERGAS PSNR</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell>?10 ?2</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell></row><row><cell>PCA [11]</cell><cell cols="2">0.845 8.92</cell><cell>3.45</cell><cell cols="2">34.32 6.64</cell><cell>31.26</cell></row><row><cell>GFPCA [19]</cell><cell cols="2">0.902 8.31</cell><cell>3.98</cell><cell cols="2">29.34 7.44</cell><cell>29.09</cell></row><row><cell>BF [21]</cell><cell cols="2">0.918 9.60</cell><cell>3.44</cell><cell cols="2">31.99 6.63</cell><cell>30.22</cell></row><row><cell>BFS [22]</cell><cell cols="2">0.925 8.10</cell><cell>3.05</cell><cell cols="2">34.37 6.00</cell><cell>31.09</cell></row><row><cell>SFIM [16]</cell><cell cols="2">0.946 6.76</cell><cell>2.55</cell><cell cols="2">37.47 5.43</cell><cell>32.61</cell></row><row><cell>GS [9]</cell><cell cols="2">0.961 6.62</cell><cell>2.55</cell><cell cols="2">38.08 4.95</cell><cell>32.93</cell></row><row><cell>GSA [9]</cell><cell cols="2">0.950 7.15</cell><cell>2.34</cell><cell cols="2">39.60 4.70</cell><cell>33.52</cell></row><row><cell>MTF-GLP-HPM [18]</cell><cell cols="2">0.955 6.81</cell><cell>2.25</cell><cell cols="2">40.70 4.77</cell><cell>33.97</cell></row><row><cell>CNMF [23]</cell><cell cols="2">0.960 6.64</cell><cell>2.20</cell><cell cols="2">40.79 4.39</cell><cell>34.14</cell></row><row><cell>MTF-GLP [17]</cell><cell cols="2">0.956 6.55</cell><cell>2.20</cell><cell cols="2">40.70 4.45</cell><cell>34.12</cell></row><row><cell>HySure [20]</cell><cell cols="2">0.966 6.13</cell><cell>1.80</cell><cell cols="2">44.60 3.77</cell><cell>35.91</cell></row><row><cell>HyperPNN [29]</cell><cell cols="2">0.967 6.09</cell><cell>1.67</cell><cell cols="2">48.62 3.82</cell><cell>36.70</cell></row><row><cell>DHP-DARN [24]</cell><cell cols="2">0.969 6.43</cell><cell>1.56</cell><cell cols="2">49.17 3.95</cell><cell>37.30</cell></row><row><cell>DIP-HyperKite (ours)</cell><cell cols="2">0.980 5.61</cell><cell>1.29</cell><cell cols="2">51.72 2.85</cell><cell>38.65</cell></row><row><cell cols="3">upsampling methods for the</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VII THE</head><label>VII</label><figDesc>AVERAGE QUANTITATIVE RESULTS ON THE BOTSWANA DATASET.</figDesc><table><row><cell></cell><cell>CC</cell><cell cols="5">SAM RMSE RSNR ERGAS PSNR</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell>?10 ?2</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell></row><row><cell>PCA [11]</cell><cell cols="2">0.946 2.22</cell><cell>1.74</cell><cell cols="2">57.10 2.89</cell><cell>28.17</cell></row><row><cell>GFPCA [19]</cell><cell cols="2">0.925 2.48</cell><cell>1.97</cell><cell cols="2">53.81 3.18</cell><cell>26.75</cell></row><row><cell>BF [21]</cell><cell cols="2">0.919 2.41</cell><cell>1.86</cell><cell cols="2">55.43 3.37</cell><cell>26.88</cell></row><row><cell>BFS [22]</cell><cell cols="2">0.918 2.39</cell><cell>1.85</cell><cell cols="2">55.52 3.38</cell><cell>26.91</cell></row><row><cell>SFIM [16]</cell><cell cols="2">0.890 3.31</cell><cell>2.56</cell><cell cols="2">48.30 2.98</cell><cell>27.27</cell></row><row><cell>GS [9]</cell><cell cols="2">0.949 2.17</cell><cell>1.68</cell><cell cols="2">57.55 2.74</cell><cell>28.32</cell></row><row><cell>GSA [9]</cell><cell cols="2">0.964 1.86</cell><cell>1.28</cell><cell cols="2">63.02 2.16</cell><cell>30.78</cell></row><row><cell>MGH [18]</cell><cell cols="2">0.962 1.90</cell><cell>1.33</cell><cell cols="2">62.23 2.15</cell><cell>30.47</cell></row><row><cell>CNMF [23]</cell><cell cols="2">0.951 2.28</cell><cell>1.38</cell><cell cols="2">60.90 2.48</cell><cell>29.63</cell></row><row><cell>MG [17]</cell><cell cols="2">0.963 1.88</cell><cell>1.32</cell><cell cols="2">62.23 2.16</cell><cell>30.45</cell></row><row><cell>HySure [20]</cell><cell cols="2">0.963 1.93</cell><cell>1.19</cell><cell cols="2">63.80 2.12</cell><cell>30.97</cell></row><row><cell>HyperPNN [29]</cell><cell cols="2">0.957 1.92</cell><cell>1.06</cell><cell cols="2">66.22 2.40</cell><cell>29.00</cell></row><row><cell>DHP-DARN [24]</cell><cell cols="2">0.954 1.91</cell><cell>1.05</cell><cell cols="2">66.22 2.35</cell><cell>29.98</cell></row><row><cell>DIP-HyperKite (ours)</cell><cell cols="2">0.974 1.68</cell><cell>0.96</cell><cell cols="2">67.98 1.89</cell><cell>32.12</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE VIII</cell><cell></cell><cell></cell></row><row><cell cols="7">THE AVERAGE QUANTITATIVE RESULTS ON THE CHIKUSEI DATASET.</cell></row><row><cell></cell><cell>CC</cell><cell cols="5">SAM RMSE RSNR ERGAS PSNR</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell>?10 ?2</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell><cell>(?)</cell></row><row><cell>PCA [11]</cell><cell cols="2">0.297 9.99</cell><cell>4.47</cell><cell cols="2">17.86 16.70</cell><cell>30.96</cell></row><row><cell>GFPCA [19]</cell><cell cols="2">0.883 4.76</cell><cell>1.98</cell><cell cols="2">34.22 7.00</cell><cell>37.05</cell></row><row><cell>BF [21]</cell><cell cols="2">0.903 5.15</cell><cell>1.94</cell><cell cols="2">34.40 6.62</cell><cell>37.89</cell></row><row><cell>BFS [22]</cell><cell cols="2">0.917 4.69</cell><cell>1.72</cell><cell cols="2">36.84 6.39</cell><cell>37.99</cell></row><row><cell>SFIM [16]</cell><cell cols="2">0.928 3.79</cell><cell>1.43</cell><cell cols="2">40.51 6.43</cell><cell>39.55</cell></row><row><cell>GS [9]</cell><cell cols="2">0.733 5.64</cell><cell>2.96</cell><cell cols="2">26.37 8.17</cell><cell>35.13</cell></row><row><cell>GSA [9]</cell><cell cols="2">0.943 3.52</cell><cell>1.42</cell><cell cols="2">40.73 4.30</cell><cell>41.38</cell></row><row><cell>MTF-GLP-HPM [18]</cell><cell cols="2">0.929 3.82</cell><cell>1.45</cell><cell cols="2">39.38 6.40</cell><cell>39.85</cell></row><row><cell>CNMF [23]</cell><cell cols="2">0.900 4.72</cell><cell>1.91</cell><cell cols="2">36.73 5.75</cell><cell>39.65</cell></row><row><cell>MTF-GLP [17]</cell><cell cols="2">0.938 3.81</cell><cell>1.52</cell><cell cols="2">39.38 4.41</cell><cell>41.05</cell></row><row><cell>HySure [20]</cell><cell cols="2">0.960 2.98</cell><cell>1.13</cell><cell cols="2">45.24 3.69</cell><cell>43.14</cell></row><row><cell>HyperPNN [29]</cell><cell cols="2">0.946 3.97</cell><cell>1.11</cell><cell cols="2">46.55 4.77</cell><cell>41.57</cell></row><row><cell>DHP-DARN [24]</cell><cell cols="2">0.953 3.60</cell><cell>1.05</cell><cell cols="2">46.66 4.44</cell><cell>42.24</cell></row><row><cell>DIP-HyperKite (ours)</cell><cell cols="2">0.974 2.85</cell><cell>1.03</cell><cell cols="2">46.97 3.62</cell><cell>43.53</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Advanced spectral classifiers for hyperspectral images: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ghamisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Magazine</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="32" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A review of nonlinear hyperspectral unmixing methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Heylen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Parente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1844" to="1868" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A tutorial overview of anomaly detection in hyperspectral images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Matteoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Diani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corsini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Aerospace and Electronic Systems Magazine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="5" to="28" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A review of change detection in multitemporal hyperspectral images: Current techniques, applications, and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marinelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bovolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Magazine</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="140" to="158" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hyperspectral pansharpening: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Loncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>De Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Briottet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dobigeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fabre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Licciardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simoes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and remote sensing magazine</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="27" to="46" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Road extraction based on fuzzy logic and mathematical morphology from pan-sharpened ikonos images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohammadzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tavakoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Valadan Zoej</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The photogrammetric record</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">113</biblScope>
			<biblScope unit="page" from="44" to="60" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Image fusion and spectral unmixing of hyperspectral images for spatial improvement of classification maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Licciardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Villa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE International Geoscience and Remote Sensing Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="7290" to="7293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Process for enhancing the spatial resolution of multispectral imagery using pan-sharpening</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Laben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V</forename><surname>Brower</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-04" />
			<biblScope unit="page">875</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving component substitution pansharpening through multivariate regression of ms + pan data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Aiazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baronti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Selva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3230" to="3239" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An efficient pan-sharpening method via a combined adaptive pca approach and contourlets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Younan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on geoscience and remote sensing</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1323" to="1335" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Extracting spectral contrast in landsat thematic mapper image data using selective principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kwarteng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chavez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogramm. Eng. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="339" to="348" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A critical comparison among pansharpening algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vivone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Alparone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garzelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Licciardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Restaino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2565" to="2586" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A new look at ihs-like image fusion methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-M</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Shyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information fusion</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="177" to="186" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A theory for multiresolution signal decomposition: the wavelet representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fundamental Papers in Wavelet Theory</title>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="494" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The stationary wavelet transform and some statistical applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Nason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Silverman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wavelets and statistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="281" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Smoothing filter-based intensity modulation: A spectral preserve image fusion technique for improving spatial details</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="3461" to="3472" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Context-driven fusion of high spatial and spectral resolution images based on oversampled multiresolution analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Aiazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Alparone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baronti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garzelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on geoscience and remote sensing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2300" to="2312" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mtftailored multiscale fusion of high-resolution ms and pan imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Aiazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Alparone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baronti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garzelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Selva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogrammetric Engineering &amp; Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="591" to="596" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Fusion of thermal infrared hyperspectral and vis rgb data using guided filter and supervised fusion graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Van Coillie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gautama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pizurica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Philips</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A convex formulation for hyperspectral image superresolution via subspace-based regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simoes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3373" to="3388" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bayesian fusion of multiband images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dobigeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Tourneret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1117" to="1127" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hyperspectral and multispectral image fusion based on a sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dobigeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Tourneret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3658" to="3668" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Coupled nonnegative matrix factorization unmixing for hyperspectral and multispectral data fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yokoya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yairi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iwasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="528" to="537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hyperspectral pansharpening using deep prior and dual attention residual network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="8059" to="8076" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep image prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ulyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9446" to="9454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep laplacian pyramid networks for fast and accurate super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="624" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep hyperspectral prior: Singleimage denoising, inpainting, super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Hardeberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3844" to="3851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pansharpening by convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Masi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cozzolino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Verdoliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Scarpa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">594</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hyperpnn: Hyperspectral pansharpening via spectrally predictive convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3092" to="3100" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hyperspectral image super-resolution by band attention through adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4304" to="4318" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sdpnet: A deep network for pan-sharpening with enhanced information representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="4120" to="4134" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Image denoising: Can plain neural networks compete with bm3d</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2392" to="2399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning overcomplete representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Lewicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="337" to="365" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Kiu-net: Towards accurate segmentation of biomedical images using over-complete representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M J</forename><surname>Valanarasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">A</forename><surname>Sindagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hacihaliloglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="363" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Kiu-net: Overcomplete convolutional architectures for biomedical image and volumetric segmentation</title>
		<idno type="arXiv">arXiv:2010.01663</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Overcomplete deep subspace clustering networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M J</forename><surname>Valanarasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="746" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Over-and-under complete convolutional rnn for mri reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M J</forename><surname>Valanarasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Overcomplete representations against adversarial videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-Y</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M J</forename><surname>Valanarasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.04262</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Exploring overcomplete representations for single image deraining using cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yasarla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M J</forename><surname>Valanarasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep laplacian pyramid networks for fast and accurate super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="624" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Ddlps: Detail-based deep laplacian pansharpening for hyperspectral imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="8011" to="8025" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A convex formulation for hyperspectral image superresolution via subspace-based regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sim?es</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3373" to="3388" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Fast fusion of multi-band images based on solving a sylvester equation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dobigeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Tourneret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4109" to="4121" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Hyperspectral pansharpening with deep priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1529" to="1543" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A combined corner and edge detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stephens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Alvey vision conference</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1988" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="10" to="5244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Hysens-dais 7915/rosis imaging spectrometers at dlr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Holzwarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Habermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hausold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thiemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Strobl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd EARSeL workshop on imaging spectroscopy</title>
		<meeting>the 3rd EARSeL workshop on imaging spectroscopy</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Fusion of satellite images in urban area: Assessing the quality of resulting images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 18th International Conference on Geoinformatics</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Airborne hyperspectral data over chikusei</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yokoya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iwasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Space Appl. Lab., Univ. Tokyo</title>
		<imprint>
			<date type="published" when="2016-05-27" />
		</imprint>
	</monogr>
	<note>Tech. Rep. SAL-</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Before joining the Johns Hopkins, he worked as a graduate research student in the Department of Electrical and Electronic Engineering at the University of Peradeniya, Sri Lanka, for an NSFfunded project from 2019 to 2020. He graduated from the University of Peradeniya with first-class honors in Electrical and Electronic Engineering in 2019. His research interests include computer vision and image processing with applications in remote sensing, and hyperspectral image processing. Jeya Maria Jose Valanarasu (Student Member, IEEE) is Ph.D. student in the Department of Electrical and Computer Engineering (ECE) at Johns Hopkins University, USA. Prior to joining Hopkins, he graduated from NIT Trichy, India in 2019 with a Bachelor&apos;s degree in Instrumentation and Control Engineering. He also spent some time working in the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wele Gedara Chaminda Bandara (Student Member, IEEE) is a Ph.D. student in the</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>Institut national polytechnique de Toulouse (INPT ; Department of Electrical and Computer Engineering (ECE) at the Johns Hopkins University, USA ; Biomedical Engineering Department at National University of Singapore (NUS</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
	<note>) as a visiting research intern. His research interests include image/3D segmentation, image enhancement, and image-to-image translation for computer vision and medical imaging tasks</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Prior to joining Hopkins, he was an A. Walter Tyson Assistant Professor in the Department of ECE at Rutgers University and a member of the research faculty at the University of Maryland Institute for Advanced Computer Studies (UMIACS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">two Best Student Paper Awards at IAPR ICPR 2018, and Best Poster Awards at BTAS 2015 and 2016. He is an Associate Editor of the IEEE Signal Processing Magazine, Pattern Recognition Journal, and serves on the Machine Learning for Signal Processing</title>
		<meeting><address><addrLine>College Park, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>Department of Electrical and Computer Engineering (ECE) at Johns Hopkins University ; D. in Electrical Engineering from the University of Maryland ; Pi Mu Epsilon, and Phi Beta Kappa</orgName>
		</respStmt>
	</monogr>
	<note>He has received a number of awards including the 2021 NSF CAREER Award, the 2016 ONR Young Investigator Award, the 2016 Jimmy Lin Award for Invention, A. Walter Tyson Assistant Professorship Award. He serves as the vice president of conferences for the IEEE Biometrics Council. He is a member of Eta Kappa Nu</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
