<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Adversarial Disentangling for Specific Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianyu</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiqi</forename><surname>Gu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Feng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangliang</forename><surname>Cheng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuequan</forename><surname>Lu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhuang</forename><surname>Ma</surname></persName>
						</author>
						<title level="a" type="main">Self-Adversarial Disentangling for Specific Domain Adaptation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Domain Adaptation</term>
					<term>Semantic Segmentation</term>
					<term>Object Detection</term>
					<term>Autonomous Driving</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Domain adaptation aims to bridge the domain shifts between the source and target domains. These shifts may span different dimensions such as fog, rainfall, etc. However, recent methods typically do not consider explicit prior knowledge on a specific dimension, thus leading to less desired adaptation performance. In this paper, we study a practical setting called Specific Domain Adaptation (SDA) that aligns the source and target domains in a demanded-specific dimension. Within this setting, we observe the intra-domain gap induced by different domainness (i.e., numerical magnitudes of this dimension) is crucial when adapting to a specific domain. To address the problem, we propose a novel Self-Adversarial Disentangling (SAD) framework. In particular, given a specific dimension, we first enrich the source domain by introducing a domainness creator with providing additional supervisory signals. Guided by the created domainness, we design a self-adversarial regularizer and two loss functions to jointly disentangle the latent representations into domainness-specific and domainness-invariant features, thus mitigating the intra-domain gap. Our method can be easily taken as a plug-and-play framework and does not introduce any extra costs in the inference time. We achieve consistent improvements over state-of-the-art methods in both object detection and semantic segmentation tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. . and semantic segmentation <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b45">[45]</ref>, aiming to reduce the domain shifts between the source and the target domains. The domain shifts may span different dimensions such as fog, rainfall, Field of View (FoV), etc. A practical scenario is to align the source and the target domain in a demanded specific dimension, e.g., from sunny images to foggy images. However, existing methods can hardly handle such cases elegantly. This is mainly because they do not consider any explicit prior knowledge about the specific domain shifts. As a result, the model will lack a clear target dimension and will be optimized without the aforementioned prior knowledge. This under-constrained training process limits the performance when adapting the model to a specific dimension. Meanwhile, the intra-domain gaps, which commonly exist among the domains in the same dimension but with different domainness, are taken out of consideration in previous research. As shown in <ref type="figure" target="#fig_1">Fig. 1, different</ref> domainness values indicate different numerical magnitudes of a specific domain dimension. Narrowing such intra-domain gaps is crucial when adapting to a specific dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dimension -invariant</head><p>In this paper, we refer to the above explained problem as Specific Domain Adaptation (SDA), a realistic and practical setting for domain adaptation. It targets to generalize a model across a specific domain dimension, e.g., different FoVs (FoV dimension), and the model can be broadly applied in real-world applications. For example, in autonomous driving, the models trained on the sunny days should have the ability to generalize to the specific rainy or foggy scenarios.</p><p>To address the above SDA, we propose an innovative method, referred to as Self-Adversarial Disentangling (SAD). It tackles the problem by disentangling the latent representations into domainness-invariant features and domainnessspecific features in a specific dimension. In contrast to domaininvariant feature that involves some noise factors, domainnessinvariant feature means the feature is irrelevant to the domainness magnitude in the target domain. The advantage of transferring domainness-invariant features is that we can capture the generalizations across different domainness to narrow the intra-domain gaps, which is on a more fine-grained level than directly transferring domain-invariant features.</p><p>Our framework consists of two key components, i.e., Domainness Creator (DC) and Self-Adversarial Regularizer (SAR), for domainness generation and disentanglement, respectively. According to the given domain shift, we firstly enrich the source domain with DC. It not only diversifies the source domain but also provides additional supervisory signals for the following feature disentangling. Guided by the domainness, we design the SAR, and introduce a domainnessspecific loss and a domainness-invariant loss for SAR to jointly supervise the disentangling of the latent representations into domainness-specific and -invariant features. With the domainness-specific loss, our SAR can classify the predicted domainness with supervisory signals from DC. Penalized by the domainness-invariant loss, our SAR can fully learn domainness-invariant representations. Thus, we can mitigate the intra-domain gap induced by different domainness. To sum up, our SAD framework works in a disentangling sense, which enables the model to learn domainness-invariant feature in an adversarial manner, i.e., two opposite loss functions.</p><p>Our method is applicable and flexible in most real-world cases. We verified the proposed method under various domain dimensions, including cross-fog (Cityscapes <ref type="bibr" target="#b46">[46]</ref> to Foggy Cityscapes <ref type="bibr" target="#b47">[47]</ref>, Cityscapes <ref type="bibr" target="#b46">[46]</ref> to RTTS <ref type="bibr" target="#b48">[48]</ref>, Cityscapes <ref type="bibr" target="#b46">[46]</ref> to Foggy Zurich++ <ref type="bibr" target="#b47">[47]</ref>, <ref type="bibr" target="#b49">[49]</ref>), cross-rain (Cityscapes <ref type="bibr" target="#b46">[46]</ref> to RainCityscapes <ref type="bibr" target="#b50">[50]</ref>) and cross-FoV adaptation (Virtual KITTI <ref type="bibr" target="#b51">[51]</ref> to CKITTI <ref type="bibr" target="#b46">[46]</ref>, <ref type="bibr" target="#b52">[52]</ref>). The target domain has either single or multiple domainness values. Extensive experiments prove the impressive generalization abilities of our method. Without bells and whistles, our method yields remarkable improvements over existing methods in both object detection and semantic segmentation. In particular, we achieve 3.4% ? 6.4% gains on synthetic datasets and improvements of up to 2.6% on real datasets. We achieve 45.2% mAP on the widely-used benchmark of Cityscapes <ref type="bibr" target="#b46">[46]</ref> to Foggy Cityscapes <ref type="bibr" target="#b47">[47]</ref>.</p><p>The contributions of this paper are summarized as follows. 1) We study the problem of specific domain adaptation (SDA), a realistic and practical setting for domain adaptation. We propose a novel self-adversarial disentangling framework by leveraging the explicit prior domain knowledge to learn the domainness-invariant features. 2) We present a domainness creator for specifically enriching the source domain and providing explicit supervisory signals. 3) We design a self-adversarial regularizer to mitigate the intra-domain gaps. We also introduce one domainness-specific loss and a domainnessinvariant loss to facilitate the training. 4) We conduct comprehensive experiments to demonstrate the effectiveness of our method on both object detection and semantic segmentation. It is simple to integrate our method into any existing approaches as a plug-and-play framework which does not introduce any extra costs during the inference phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Unsupervised Domain Adaptation. UDA aims to generalize the model learned from the labeled source domain to another unlabeled target domain. In the field of UDA, a group of approaches has shown promising results in object detection <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b21">[22]</ref> and semantic segmentation <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b45">[45]</ref>, <ref type="bibr" target="#b53">[53]</ref>, <ref type="bibr" target="#b54">[54]</ref>. The current mainstream approaches of these two tasks include adversarial learning <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b29">[29]</ref>, <ref type="bibr" target="#b55">[55]</ref>, selftraining <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b41">[41]</ref>, <ref type="bibr" target="#b42">[42]</ref>, <ref type="bibr" target="#b56">[56]</ref> and self-ensembling <ref type="bibr" target="#b39">[39]</ref>, <ref type="bibr" target="#b54">[54]</ref>, <ref type="bibr" target="#b57">[57]</ref>- <ref type="bibr" target="#b63">[63]</ref>. Despite the gratifying progress, little attention has been paid to perform domain adaptation in a specifically demanded dimension by introducing any explicit prior knowledge about the domain shifts except <ref type="bibr" target="#b18">[19]</ref>. Prior DA <ref type="bibr" target="#b18">[19]</ref> is the only work that builds on a similar motivation with us by using the weather-specific prior knowledge obtained from the image formation. However, it designed a prior-adversarial loss and acts in a completely different manner from ours. Prior DA <ref type="bibr" target="#b18">[19]</ref> only explored the weather prior on the cross-fog and cross-rain scenarios. We follow the same setting as <ref type="bibr" target="#b18">[19]</ref> by knowing the domain dimension in advance, which is fully fair in experimental comparison. Domain Diversification. Domain Diversification (DD) aims to diversify the source domain to various distinctive domains with random augmentation. Kim et al. <ref type="bibr" target="#b64">[64]</ref> designed a DD-MRL method by using GAN <ref type="bibr" target="#b65">[65]</ref> to diversify the source domain. Similarly, DRPC <ref type="bibr" target="#b66">[66]</ref> and LTIR <ref type="bibr" target="#b27">[28]</ref> proposed to diversify the texture of the source images and to learn texture-invariant representations. Our method differs from these methods in several aspects. Firstly, they require large computation costs and cannot be trained end-to-end during the adaptation procedure. Instead, our method is light-weighted and online with a transformation algorithm in DC. Secondly, the GAN-based approaches tend to produce artifacts for urban-scene datasets, leading to severe semantic inconsistency. In contrast, we do not use any feature interpolation operation in the reconstruction and merely use a simple yet very effective parameter modeling. Disentangled Learning. Disentangled learning has been widely studied in other communities, e.g., image translation <ref type="bibr" target="#b67">[67]</ref>, <ref type="bibr" target="#b68">[68]</ref>, few-shot learning <ref type="bibr" target="#b69">[69]</ref>, <ref type="bibr" target="#b70">[70]</ref>. Overview of the proposed Self-Adversarial Disentangling (SAD). Our Domainness Creator (DC) not only generates a diversified source image with random domainness, but also provides additional supervisory signals d gt for guiding the selfadversarial learning. The encoder E spf and E inv are to extract the domainness-specific representations z spf and the domainnessinvariant representations z inv , respectively. With the guidance of the generated domainness, E spf , E inv and SAR (Self-Adversarial Regularizer) work in an adversarial manner, i.e., two opposite loss functions, to disentangle the latent representations into z spf and z inv .</p><p>Nevertheless, these methods can hardly capture the generalizations across different domainness within the same target domain to narrow down the intra-domain gap. Multi Domain-invariant Representation Learning. The most relevant work to ours in the filed of UDA is multi domain-invariant representation learning (MRL) <ref type="bibr" target="#b64">[64]</ref>. MRL applies a multi-domain discriminator to learn indistinguishable features among different domains. Similarly, Wang et al. <ref type="bibr" target="#b72">[72]</ref> proposed a multi-domain discriminator that models the encoding-conditioned domain index distribution to tackle the continuously indexed domain adaptation (CIDA). Our method is quite different from these methods. Firstly, these approaches do not leverage the prior domain knowledge in a specific dimension to facilitate the multi-domain representation learning.</p><p>In contrast, we model a specific dimension in domain shift and leverage the generated domainness as supervisory signals to guide the feature learning. Secondly, the multi-domain discriminators are not actually reconstructing the domainness values, and they neglect the intra-domain gaps within the target domain induced by different domainness. Instead, guided by the domainness-invariant and domainness-specific loss functions, our SAR works in a completely different manner to narrow the intra-domain gaps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHODOLOGY</head><p>We focus on the problem of Specific Domain Adaptation (SDA) in both object detection and semantic segmentation, where we have access to the source data X S with labels Y S and the target data X T without labels. <ref type="figure">Fig. 2</ref> shows the overview of our framework. Our core idea is to disentangle the latent representation into domainness-invariant feature and domainness-specific feature in a specific dimension. The target domain has either single or multiple domainness values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Domainness Creator</head><p>We design Domainness Creator (DC) as a transformation algorithm for images. DC receives a source image X S as the input and outputs a processed imageX S by adding a random domainness in a specific dimension. Meanwhile, DC provides a supervisory signal, i.e.,, the label of the domainness value d gt , for guiding the self-adversarial learning. Due to the variations of domainness values enabled by DC, a model trained on the domainness-diversified dataset will be able to learn the domainness-invariant representations for feature alignment. d gt is a number, e.g., F oV x is 40 ? . F oV x denotes the FoV in the x axis. Example of DC in FoV dimension. Taking FoV as an example, we show the process of FoV transformation given a selected F oV x in <ref type="figure" target="#fig_3">Fig. 3</ref>, where O is the optical center of the camera and F is the focal point. OF denotes the focal length. M N and P Q represent the original width and the new width before and after the transformation:</p><formula xml:id="formula_0">X S = DC(X S ), F OV x = ?M F N ? ?P F Q<label>(1)</label></formula><p>where F oV x is reduced from ?M F N to ?P F Q during the process and the domainness label is denoted as d gt = ?P F Q.</p><p>If the dimension is fog thickness for DC, we follow the algorithms in <ref type="bibr" target="#b47">[47]</ref> to diversify the source image. Remark 1: The intuitions between DC and data augmentation are totally different. Data augmentation only diversifies the source images, while the proposed DC provides supervision signals to guide the training of SAR, which is the critical part of the method. DC indeed helps the disentanglement of learning the domainness-invariant representations. We also prove that the two components are complementary in the experiment part. Remark 2: Difference from existing GAN-based domain diversification. Compared to previous domain diversification <ref type="bibr" target="#b64">[64]</ref> and domain randomization <ref type="bibr" target="#b66">[66]</ref> approaches, we do not use GAN-based architecture to produce translated images in our implementations. The main reasons are reflected in two aspects. Firstly, these methods require large computation resources, especially for the urban-scene images, and they cannot be trained in an end-to-end manner. Secondly, the reconstruction of the feature encodings will inevitably lead to pixel-wise distortions and semantic inconsistency. In comparison, our transformation in DC is online and allows end-toend training, because we do not use any feature interpolation operation and just use a simple yet effective mathematically modeled transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Self-Adversarial Regularizer</head><p>Guided by the generated domainness, SAR is designed to disentangle the latent representations into the domainnessspecific feature z spf and the domainness-invariant feature z inv , in order to mitigate the intra-domain gap. E spf and E inv denote the domainness-specific encoder and domainnessinvariant encoder, respectively. The dimensions of z spf and z inv are both C * H * W , where C is 19/11 for segmentation, and 512/1024 for detection, respectively. Intra-domain adaptation. As shown in <ref type="figure">Fig. 2</ref>, the processed imageX S is fed into the encoder E spf and E inv to get the latent feature map z spf and z inv . Either z spf or z inv is forwarded into SAR to get the domainness value d spf and d inv for once. SAR is supervised by the designed domainnessspecific loss L spf and domainness-invariant loss L inv together (see below for the design of these two losses). With the former loss L spf , our SAR could classify the predicted domainness d spf with supervisory signals d gt from DC. Penalized by the latter loss L inv , our SAR could fully learn domainnessinvariant representations, thus mitigating the intra-domain gap induced by different domainness. In essence, the encoders and SAR are complementary and work in an adversarial manner (i.e., two opposite losses) to perform the specific domain adaptation. We illustrate the network details and the two loss fuctions below. Network architecture of SAR. Note that we use the same SAR architecture for both detection and segmentation tasks. Our SAR only takes one feature map z spf or z inv at a time as input. After that, we downsample the whole feature map to predict domainness value, and then flatten the downsampled feature map. Then after two fully-connected layers with a relu activation, we get the domainness value d spf or d inv , as shown in <ref type="figure">Fig. 2</ref>. In practice, we use ROI Align <ref type="bibr" target="#b73">[73]</ref> to downsample the whole feature map to predict domainness value. We discretize the continuous domainness values into N numbers (representing N ranges) for better experimental results. d spf , d inv are one-hot vectors with N dimensions. y U is a N dimensional vector of the uniform distribution. Domainness-specific loss.</p><p>On one hand, with the generated domainness d gt as a supervisory signal, SAR needs to enhance its discriminativity for classifying the diversified images with different domainness more accurately. We define the domainness-specific loss L spf as a cross-entropy loss for optimizing the features from the encoder E spf :</p><formula xml:id="formula_1">L spf = ? N i=1 d i gt log(d i spf ),<label>(2)</label></formula><p>where d gt is now used as the one-hot vector of generated domainness and d spf is the predicted domainness value of SAR. Domainness-invariant loss. On the other hand, SAR needs to maximize the discrepancy between the domainness-invariant feature z inv and the domainness-specific feature z spf . We define the domainness-invariant loss L inv as the KL-divergence between the predicted domainness d inv and a uniform distribution:</p><formula xml:id="formula_2">z inv ? E inv X S = q S d inv |X S , L inv = KL q S d inv |X S p (x) ,<label>(3)</label></formula><p>where x is sampled from a uniform distribution y U , p(x) is the probability of x, and q S denotes the distribution of domainness d inv . By jointly minimizing the domainness-invariant loss L inv and the domainness-specific loss L spf in two inverse directions, SAR can fully learn the domainness-invariant features which capture the generalizations across different domainness, thus narrowing the intra-domain gap. Remark 1: Whether the parameters of E spf and E inv are shared or not. E spf and E inv are two encoders that use the same architecture but do not share the weights, because they are penalized by different loss functions. The former is penalized by L spf , and the latter is under the guidance of L inv , L adv (adversarial loss, Eq. (4)) and L task (task loss, Eq. <ref type="formula" target="#formula_5">(6)</ref>). Remark 2: Comparing with GAN architecture. Existing GAN-based architectures utilized the multi-domain discriminators <ref type="bibr" target="#b64">[64]</ref>, <ref type="bibr" target="#b72">[72]</ref> to distinguish the domainness (they called domain index in their work). In the adversarial framework, these discriminators are not actually predicting the domainness d inv , but making the latent encodings z inv unable to predict d inv . Due to the fact that it is trained in an adversarial way, the encoder will transform the input X before outputting encoding z inv , thereby removing the information related to domainness d inv . However, the encoder can not fully learn the domainnessinvariant feature due to the lack of prior knowledge about the domain shifts. In comparison, our proposed framework acts in a completely different manner. Firstly, we use two separate encoders E spf and E inv , the former for extracting the domainness-specific feature z spf and the latter for extracting the domainness-invariant features z inv . Secondly, with the guidance of the generated domainness d gt as supervisory signals, our SAR is truly reconstructing the domainness, aiming to distinguish the domainness accurately; Thirdly, our SAD framework works in two opposite directions in a disentangling sense, which enables the model to learn domainness-invariant features to alleviate the intra-domain gap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. End-to-End Training and Inference</head><p>In this section, we will briefly introduce the inter-domain adaptation, the task loss and formulate an overall loss function for end-to-end training. Then we will explain the inference phase.</p><p>Inter-domain adaptation. Without loss of generality, we employ an adversarial framework <ref type="bibr" target="#b74">[74]</ref> for the inter-domain adaptation. As shown in <ref type="figure">Fig. 2</ref>, the processed source images X S and X T are fed into the encoder E inv . Then, E inv is encouraged to learn z inv . The latent encodings should confuse a domain discriminator D in distinguishing the features extracted between the source and target domains. This is achieved by min-maximizing an adversarial loss:</p><formula xml:id="formula_3">L adv = ? E x?p(x S ) [log(D(E inv (x)))] ? E x?p(x T ) [log(1 ? D(E inv (x)))],<label>(4)</label></formula><p>Task loss. In this work, taking Faster-RCNN <ref type="bibr" target="#b2">[3]</ref> as an example, we use Region Proposal Network (RPN) to generate Region of Interests (RoIs). It then localizes and classifies the regions to obtain semantic labels and locations. The task network is optimized with a multi-task loss function:</p><formula xml:id="formula_4">L task = L rpn + ? cls L cls + ? reg L reg ,<label>(5)</label></formula><p>where the RPN loss L rpn , classification loss L cls and regression loss L reg remain the same as <ref type="bibr" target="#b2">[3]</ref>. The loss weights ? cls and ? reg are set to 1.0 by default. Total loss. During training, all the models are jointly trained with the backbone in an end-to-end manner. The total loss L total is the weighted sum of the aforementioned loss functions:</p><formula xml:id="formula_5">L total = L task + ? adv L adv + L inv + ? spf L spf ,<label>(6)</label></formula><p>where ? adv and ? spf are the weighting coefficients for the loss L adv and L spf , respectively. We use the original weighting ratio in <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b29">[29]</ref>, <ref type="bibr" target="#b30">[30]</ref> to balance L task and L adv . Inference phase. In the inference phase, we only need a domainness-invariant encoder E inv with a task network T to make predictions. In other words, all other modules including DC, SAR and E spf are removed in the inference stage, leading to no extra costs in prediction. Besides, our method can be plugged into various existing cross-domain detection/segmentation methods. Thus, our framework is flexible and generalizable, and it does not depend on specific UDA frameworks for feature alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section, we firstly evaluate our framework on object detection under various domain dimensions, including crossfog adaptation, cross-rain adaptation and cross-FoV adaptation. In addition, we extend our method to the semantic segmentation to verify its scalability and applicability. Finally, we conduct ablation studies to validate each component of our method. Our method is applicable and flexible in most realworld cases, and we proved it with thorough experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>Cityscapes ? Foggy Cityscapes. This is a widely-used benchmark for cross-domain object detection. Cityscapes <ref type="bibr" target="#b46">[46]</ref> is a dataset focused on autonomous driving, which consists of 2,975 images in the training set, and 500 images in the validation set. Foggy Cityscapes <ref type="bibr" target="#b47">[47]</ref> is a synthetic foggy dataset which simulates fog on real scenes. The annotations and data split in Foggy Cityscapes are inherited from Cityscapes. Cityscapes ? RTTS. RTTS <ref type="bibr" target="#b48">[48]</ref> is the largest available dataset for object detection under real-world hazy conditions. It contains 4,807 unannotated and 4,322 annotated real-world hazy images covering most traffic and driving scenarios with 7 kinds of fogs. Cityscapes ? Foggy Zurich++.</p><p>Foggy Zurich++ is a real-world dataset collected in foggy-weather conditions for segmentation. We use all the unannotated 3,768 images of Foggy Zurich <ref type="bibr" target="#b47">[47]</ref> as the training set and mix the validation set of Foggy Driving <ref type="bibr" target="#b49">[49]</ref> and Foggy Zurich <ref type="bibr" target="#b47">[47]</ref>. Following <ref type="bibr" target="#b46">[46]</ref>, Foggy Zurich++ is labeled with 19 classes. Cityscapes ? RainCityscapes. RainCityscapes <ref type="bibr" target="#b50">[50]</ref> renders Cityscapes images with synthetic rain. Each clear image is rendered with 12 types of rain patterns, including 4 types of drop sizes which we use as our domainness. The annotations are the same as those of Cityscapes. We use this benchmark in cross-domain detection. VKITTI ? CKITTI.</p><p>We use this benchmark in both detection and segmentation. Virtual KITTI <ref type="bibr" target="#b51">[51]</ref> is a photorealistic synthetic dataset, which contains 21,260 images. It is designed to mimic the conditions of KITTI dataset and has similar scene layouts, camera viewpoints and image resolution to KITTI dataset. CKITTI is a real-world dataset depicting several urban driving scenarios with 5 different kinds of FoVs, which is a mixed dataset of Cityscapes <ref type="bibr" target="#b46">[46]</ref> and KITTI <ref type="bibr" target="#b52">[52]</ref>. We use the 10,456 images as the training set and 700 images as the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation Details</head><p>Object detection. In our implementation, we follow the training protocol <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b15">[16]</ref> of the Faster-RCNN network. We resize the images of both the source and target  domain to 600-pixel height in all experiments as suggested by <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b15">[16]</ref>. Following the aforementioned papers, we use the VGG16 [77] model pre-trained on ImageNet <ref type="bibr" target="#b78">[78]</ref> as a backbone of DA-Faster <ref type="bibr" target="#b8">[9]</ref>, SWDA <ref type="bibr" target="#b9">[10]</ref> and SCL <ref type="bibr" target="#b15">[16]</ref>, and the ResNet50 <ref type="bibr" target="#b79">[79]</ref> as the backbone of GPA <ref type="bibr" target="#b12">[13]</ref>. We set the learning rate to 0.001 for the first 50k iterations and 0.0001 for the rest iterations. The other parameters are set by following the original papers <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b15">[16]</ref>. Semantic segmentation. Following common UDA protocols <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b29">[29]</ref>, <ref type="bibr" target="#b30">[30]</ref>, we employ the DeepLab-v2 <ref type="bibr" target="#b4">[5]</ref> with ResNet 101 backbone <ref type="bibr" target="#b79">[79]</ref> in our implementation. The backbone is pre-trained on ImageNet <ref type="bibr" target="#b78">[78]</ref>. We reproduce the famous AdaptSegNet <ref type="bibr" target="#b25">[26]</ref>, CLAN <ref type="bibr" target="#b29">[29]</ref> and SIM <ref type="bibr" target="#b30">[30]</ref> as our baselines. For our DeepLab-v2 network, we use Adam as the optimizer. The initial learning rate is 2.5?10 ?4 , which is then decreased using polynomial decay with an exponent of 0.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Domain Adaptation for Object Detection</head><p>In this section, we present the results in three dimensions, i.e., cross-fog, cross-rain and cross-FoV adaptation, to show the effectiveness of our approach. We achieve 3.4% ? 6.4% gains on synthetic datasets and improvements of up to 2.6% on real datasets. Cross-fog adaptation. To validate the generalization capability on the cross-fog adaptation, we perform two experiments, where the target domain includes single and multiple domainness values, respectively. Single domainness within the target domain: In this experiment, we adapt from Cityscapes <ref type="bibr" target="#b46">[46]</ref> to Foggy-Cityscapes <ref type="bibr" target="#b47">[47]</ref>. Table I (a) presents the comparison results with the state-of-the-art cross-domain detection methods on eight categories. Source-only indicates the baseline Faster RCNN <ref type="bibr" target="#b2">[3]</ref> is trained with only source domain data. From the table, we can observe that our method (with GPA <ref type="bibr" target="#b12">[13]</ref>) could outperform the state-of-the-arts by 5.7%. The published Prior-DA <ref type="bibr" target="#b18">[19]</ref> builds on a similar motivation as ours by using the weather-specific prior knowledge obtained from the image formation. It designed a prior-adversarial loss and acts in a completely different manner. Also, <ref type="bibr" target="#b18">[19]</ref> knows the dimension in advance, which fully proves our fairness of this setting. Our method outperforms Prior-DA <ref type="bibr" target="#b18">[19]</ref> by 5.9%.</p><p>Taking a closer look at per-category performance in <ref type="table" target="#tab_0">Table  I (</ref>  <ref type="figure" target="#fig_1">[13]</ref>). The bounding boxes are colored based on the detector confidence using the shown color map. As we can see from the results, the proposed method is able to produce high confidence predictions and is able to detect more objects in the images.  gories. This phenomenon illustrates the effectiveness of Self-Adversarial Disentangling among different classes during the cross-domain detection.</p><p>Multiple domainness within the target domain: In this experiment, we adapt from Cityscapes <ref type="bibr" target="#b46">[46]</ref> to RTTS dataset <ref type="bibr" target="#b48">[48]</ref>. Multi-domainness means there exist 7 kinds of fogs in RTTS dataset. The comparison results with the state-of-the-arts are reported in <ref type="table" target="#tab_0">Table I (b)</ref>. As for the image dehazing approaches which dehaze the target domain and then trasfer the domain knowledge, DCPDN <ref type="bibr" target="#b75">[75]</ref> improves the Faster RCNN performance by 1%. However, Grid-Dehaze <ref type="bibr" target="#b76">[76]</ref> does not help the Faster RCNN baseline and results in even worse performance.</p><p>Table I (b) shows that our method can effectively boost the performance by integrating it into DA-Faster RCNN <ref type="bibr" target="#b8">[9]</ref> and SWDA <ref type="bibr" target="#b9">[10]</ref>. We can successfully boost the mAP by 2.0% and 2.0%, respectively. The benefits of our approach lie in two aspects: (1) our method can be easily adopted as a plugand-play framework which enables end-to-end training and no extra costs during the inference time.</p><p>(2) Our approach can not only address the single domainness problem but also tackle more complicated scenarios where multiple domainness exist in the target domain.</p><p>Cross-FoV adaptation. To validate the generalization capability of the proposed method, we also conduct an experiment on the FoV dimension adapting from Virtual KITTI <ref type="bibr" target="#b51">[51]</ref> to CKITTI <ref type="bibr" target="#b46">[46]</ref>, <ref type="bibr" target="#b52">[52]</ref>. The adaptation results are reported in <ref type="table" target="#tab_0">Table I</ref> (c). Despite the 5 different FoVs in the dataset, our method can always achieve a certain improvement. By plugging into the current state-of-the-art methods, i.e., DA-Faster <ref type="bibr" target="#b8">[9]</ref>, SWDA <ref type="bibr" target="#b9">[10]</ref>, SCL <ref type="bibr" target="#b15">[16]</ref>, our method brings 2.6%, 1.7% and 1.8% increase, respectively. Cross-rain adaptation.</p><p>We conduct experiments from Cityscapes <ref type="bibr" target="#b46">[46]</ref> to RainCityscapes <ref type="bibr" target="#b50">[50]</ref>. <ref type="table" target="#tab_0">Table II</ref> shows the results of adapting the model between different rain scenarios. We reproduce DA-Faster RCNN <ref type="bibr" target="#b8">[9]</ref>, SWDA <ref type="bibr" target="#b9">[10]</ref> and SCL <ref type="bibr" target="#b15">[16]</ref> in the same setting. We can see that our method significantly improves the mAP by 6.4%, 3.4% and 4.2% through integrating it into the existing UDA methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Domain Adaptation for Semantic Segmentation</head><p>In addition to the above experiments on cross-domain object detection, we also conduct experiments on cross-domain semantic segmentation, to show the scability of our method. In specific, we conduct the cross-FoV adaptation and cross-fog adaptation on semantic segmentation. Cross-fog adaptation. In this experiment, we adapt from Cityscapes <ref type="bibr" target="#b46">[46]</ref> to Foggy Zurich++ <ref type="bibr" target="#b47">[47]</ref>, <ref type="bibr" target="#b49">[49]</ref> to perform the cross-fog adaptation, where multiple thickness of fogs exist in the target domain. As shown in <ref type="table" target="#tab_0">Table IV</ref>, our method outperforms the state-of-the-art methods <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b29">[29]</ref>, <ref type="bibr" target="#b30">[30]</ref> by 5.8%, 4.7% and 4.1%, respectively.</p><p>Our method can handle the cases where a domainness value is never seen in the training stage and we have verified it with experiments. As shown in <ref type="table" target="#tab_0">Table IV</ref>, the Foggy Zurich++ has the real fog rather than the synthetic fog, which means the domainness in the validation set is unknown and does not appear in the training set. Our method works well on this dataset, which proves its generalization ability. Cross-FoV adaptation. In this experiment, we perform the specific domain adaptation given the FoV gap. We choose Virtual KITTI <ref type="bibr" target="#b51">[51]</ref> as the source domain and CKITTI <ref type="bibr" target="#b46">[46]</ref>, <ref type="bibr" target="#b52">[52]</ref> as the target domain. The comparison results are listed in <ref type="table" target="#tab_0">Table III</ref>. Compared with the AdaptSegNet <ref type="bibr" target="#b25">[26]</ref>, CLAN <ref type="bibr" target="#b29">[29]</ref> and SIM <ref type="bibr" target="#b30">[30]</ref>, our method respectively yields an increase of 1.8%, 1.1% and 1.8%, which indicates the effectiveness of the proposed SAD in the semantic segmentation task and shows its good scalability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Ablation Studies</head><p>In this section, we perform ablation experiments to investigate the effect of each component and provide more insights of our method. Comparisons to the related work. <ref type="table" target="#tab_4">Table V</ref> shows the comparisons to the relevant work <ref type="bibr" target="#b64">[64]</ref>, <ref type="bibr" target="#b72">[72]</ref> from Cityscapes <ref type="bibr" target="#b46">[46]</ref> to Foggy Zurich++ <ref type="bibr" target="#b47">[47]</ref>, <ref type="bibr" target="#b49">[49]</ref> under the same baseline. When using MRL <ref type="bibr" target="#b64">[64]</ref> or CIDA <ref type="bibr" target="#b72">[72]</ref> as the adaptor, it merely   The main reasons are twofold. (1) Previous GAN-based methods <ref type="bibr" target="#b64">[64]</ref>, <ref type="bibr" target="#b72">[72]</ref> do not utilize supervisory signals d gt from DC to fully learn the domainness-invariant feature. (2) They neglect the intra-domain gap induced by different domainness. Instead, our method not only leverages the prior supervisory signals but also mitigates the intra-domain gap across different domainness. Incorporating DC and SAR into the same framework boosts the mIoU by 5.8% over the baseline. This confirms the effectiveness of our proposed DC and SAR, and addresses the aforementioned claim in Section III-B that our SAD framework is superior to GAN.</p><p>Effects of different components. <ref type="table" target="#tab_0">Table VI</ref> summarizes the effects of different design components on Cityscapes <ref type="bibr" target="#b46">[46]</ref> ? Foggy Cityscapes <ref type="bibr" target="#b47">[47]</ref>. The GPA <ref type="bibr" target="#b12">[13]</ref> baseline is 39.5%. By adding the DC and SAR sequentially, we boost the mAP with an additional +3.0% and +2.7%, achieving 42.5% and 45.2%,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) FoV x = 40?(b) FoV x = 55?(c) FoV x = 70?(d) FoV x = 80?F</head><p>ig. 6: Examples of diversified source images produced by our Domainness Creator with different F oV x s.  respectively. These improvements in object detection show the effects of individual components of our proposed approach. It also reveals that these two components are complementary and together they significantly promote the performance. Effects of loss functions. <ref type="table" target="#tab_0">Table VII</ref> shows the ablation of the domainnness-specific loss L spf when adapting from Virtual KITTI to CKITTI for segmentation. The full framework with both DC and SAR can achieve 35.2 % mIoU. By removing the domainness-specific loss L spf during the training process, the overall performance will drop by 1%.</p><p>In addition, domainnness-invariant loss L inv is critical for learning the domainnesss-invariant representations in the intradomain adaptation, and cannot be removed. This shows that our SAR (the regularizer) needs to be trained under the guidance of both loss functions, i.e., L spf and L inv . Therefore, we cannot remove any of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Parameter Analysis</head><p>In this section, we investigate the sensitivity of the hyperparameter ? spf which balances the domain adaptation process. In <ref type="figure" target="#fig_7">Fig. 7</ref>, we plot the performance curve of models trained with different ? spf values on the setting of Cityscapes ? Foggy Cityscapes in object detection task. The highest mAP on target domain is achieved when the value of ? spf is around 0.1, which means that this weight among different loss functions benefits domain adaptation the most. We simply set the same ? spf = 0.1 in all experiments, to show the robustness of our method in different settings. Note that we use the original weighting ratio in <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b29">[29]</ref>, <ref type="bibr" target="#b30">[30]</ref> to balance L task and L adv . <ref type="figure" target="#fig_4">Fig. 4</ref> visualizes the qualitative results of cross-domain object detection on two benchmarks, Cityscapes <ref type="bibr" target="#b46">[46]</ref> ? Foggy Cityscapes <ref type="bibr" target="#b47">[47]</ref> and Cityscapes <ref type="bibr" target="#b46">[46]</ref> ? RTTS <ref type="bibr" target="#b48">[48]</ref>, respectively. As we can see from the pictures, the proposed method is able to produce high confidence predictions and is able to detect more objects when plugging into the current state-ofthe-art methods, e.g., GPA and SWDA <ref type="bibr" target="#b9">[10]</ref>. <ref type="figure" target="#fig_6">Fig. 5</ref> shows the qualitative results of cross-domain semantic segmentation from Virtual KITTI dataset <ref type="bibr" target="#b51">[51]</ref> to CKITTI <ref type="bibr" target="#b46">[46]</ref>, <ref type="bibr" target="#b52">[52]</ref>. With the aid of our proposed Self-Adversarial Disentangling framework, the models are able to produce correct predictions at a high level of confidence, e.g., plugging it into AdaptSegNet <ref type="bibr" target="#b25">[26]</ref>. As we can see from the figures, our method enables good performance on most categories, e.g., 'vegetation', 'terrain', 'car', 'truck', and 'traffic sign' classes. <ref type="figure">Fig. 6</ref> shows the output results of Domainness Creator when receiving a source image at a time given the FoV gap. We get a series of diversified images with different F oV xs. From left to right it displays the processed image with F oV x of 40 ? , 55 ? , 70 ? and 80 ? , respectively. Due to the increased variations of domainness, a model trained on this domainness-diversified dataset is able to learn the domainness-invariant representation for feature alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Qualitative Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we studied specific domain adaptation and proposed self-adversarial disentangling to learn the domainnessinvariant feature in a specific dimension. The domainness creator aims to enrich the source domain and to provide additional supervisory signals for fully learning the domainness-invariant feature. The self-adversarial regularizer and two losses are introduced to narrow the intra-domain gap induced by different domainness. Extensive experiments validate our method on object detection and semantic segmentation under various domain-shift settings. Our method can be easily integrated into state-of-the-art architectures to attain considerable performance gains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>(a) Previous UDA methods do not leverage explicit prior knowledge to perform domain adaptation on a demandspecific dimension, and (b) they can not generalize well to a target domain with different unknown domainness. (c) Our method narrows the intra-domain gap induced by different domainness. Different domainness indicate the different numerical magnitudes of a specific domain dimension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>A few works have recently extended it into domain adaptation by disentangling the latent representations into domain-specific and domaininvariant features to realize effective domain alignment. Liu et al. proposed a model of cross-domain representation disentanglement (CDRD) [71] based on the GAN [65] framework. Chang et al. designed a domain invariant structure extraction (DISE) framework<ref type="bibr" target="#b31">[31]</ref> to disentangle the latent encodings into the domain-invariant structure and domain-specific texture representations for domain-adaptive semantic segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>The F oV x transform. O is the optical center of the camera and F is the focal point. OF is the focal length, M N and P Q represent the original width and the new width before and after the transformation, respectively. F oV x is reduced from ?M F N to ?P F Q after the process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>a), our approach achieves the highest AP on those cate-Qualitative results of cross-domain object detection in the Cityscapes<ref type="bibr" target="#b46">[46]</ref> ? Foggy Cityscapes<ref type="bibr" target="#b47">[47]</ref> set-up. The two columns plot (a) the predictions of GPA<ref type="bibr" target="#b12">[13]</ref> baseline, (b) the predictions of Ours (with GPA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>Qualitative results of cross-domain semantic segmentation in Virtual KITTI [51] ? CKITTI [46], [52] (11 classes) set-up. The four columns plot (a) RGB input images, (b) ground truth, (c) the predictions of AdaptsegNet [26] baseline and (d) the predictions of Ours (with AdaptsegNet [26]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 :</head><label>7</label><figDesc>Parameter analysis on the hyper-parameter ? spf .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Cross-fog (a,b) and cross-FoV (c) adaptation of object detection.(a) Cityscapes to Foggy Cityscapes (single-domainness).</figDesc><table><row><cell>Methods</cell><cell></cell><cell>Venue</cell><cell></cell><cell cols="2">person rider</cell><cell>car</cell><cell>truck</cell><cell>bus</cell><cell cols="3">train motor bicycle</cell><cell>mAP</cell></row><row><cell>Source-Only [3]</cell><cell></cell><cell cols="2">NeurIPS'15</cell><cell>26.9</cell><cell>38.2</cell><cell>35.6</cell><cell>18.3</cell><cell>32.4</cell><cell>9.6</cell><cell>25.8</cell><cell>28.6</cell><cell>26.9</cell></row><row><cell>DA-Faster [9]</cell><cell></cell><cell>CVPR'18</cell><cell></cell><cell>29.2</cell><cell>40.4</cell><cell>43.4</cell><cell>19.7</cell><cell>38.3</cell><cell>28.5</cell><cell>23.7</cell><cell>32.7</cell><cell>32.0</cell></row><row><cell>SCDA [12]</cell><cell></cell><cell>CVPR'19</cell><cell></cell><cell>33.5</cell><cell>38.0</cell><cell>48.5</cell><cell>26.5</cell><cell>39.0</cell><cell>23.3</cell><cell>28.0</cell><cell>33.6</cell><cell>33.8</cell></row><row><cell>DD-MRL [64]</cell><cell></cell><cell>CVPR'19</cell><cell></cell><cell>31.8</cell><cell>40.5</cell><cell>51.0</cell><cell>20.9</cell><cell>41.8</cell><cell>34.3</cell><cell>26.6</cell><cell>32.4</cell><cell>34.9</cell></row><row><cell>MAF [11]</cell><cell></cell><cell>ICCV'19</cell><cell></cell><cell>28.2</cell><cell>39.5</cell><cell>43.9</cell><cell>23.8</cell><cell>39.9</cell><cell>33.3</cell><cell>29.2</cell><cell>33.9</cell><cell>34.0</cell></row><row><cell>ART-PSA [21]</cell><cell></cell><cell>CVPR'20</cell><cell></cell><cell>34.0</cell><cell>46.9</cell><cell>52.1</cell><cell>30.8</cell><cell>43.2</cell><cell>29.9</cell><cell>34.7</cell><cell>37.4</cell><cell>38.6</cell></row><row><cell>ICR-CCR [15]</cell><cell></cell><cell>CVPR'20</cell><cell></cell><cell>32.9</cell><cell>43.8</cell><cell>49.2</cell><cell>27.2</cell><cell>45.1</cell><cell>36.4</cell><cell>30.3</cell><cell>34.6</cell><cell>37.4</cell></row><row><cell>CST [20]</cell><cell></cell><cell>ECCV'20</cell><cell></cell><cell>32.7</cell><cell>44.4</cell><cell>50.1</cell><cell>21.7</cell><cell>45.6</cell><cell>25.4</cell><cell>30.1</cell><cell>36.8</cell><cell>35.9</cell></row><row><cell>ATF [18]</cell><cell></cell><cell>ECCV'20</cell><cell></cell><cell>34.6</cell><cell>47.0</cell><cell>50.0</cell><cell>23.7</cell><cell>43.3</cell><cell>38.7</cell><cell>33.4</cell><cell>38.8</cell><cell>38.7</cell></row><row><cell>Prior DA [19]</cell><cell></cell><cell>ECCV'20</cell><cell></cell><cell>36.4</cell><cell>47.3</cell><cell>51.7</cell><cell>22.8</cell><cell>47.6</cell><cell>34.1</cell><cell>36.0</cell><cell>38.7</cell><cell>39.3</cell></row><row><cell>GPA [13]</cell><cell></cell><cell>CVPR'20</cell><cell></cell><cell>32.9</cell><cell>46.7</cell><cell>54.1</cell><cell>24.7</cell><cell>45.7</cell><cell>41.1</cell><cell>32.4</cell><cell>38.7</cell><cell>39.5</cell></row><row><cell cols="2">Ours (with GPA [13])</cell><cell>-</cell><cell></cell><cell>38.3</cell><cell>47.2</cell><cell>58.8</cell><cell>34.9</cell><cell>57.7</cell><cell>48.3</cell><cell>35.7</cell><cell>42.0</cell><cell>45.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">(c) Virtual KITTI to CKITTI (multi-</cell></row><row><cell cols="7">(b) Cityscapes to RTTS (multi-domainness).</cell><cell></cell><cell cols="2">domainness)</cell><cell></cell></row><row><cell>Methods</cell><cell>car</cell><cell>bus</cell><cell cols="4">person motor bicycle</cell><cell>mAP</cell><cell></cell><cell cols="2">Comparisons</cell><cell>Car AP</cell><cell>Gain</cell></row><row><cell>Source-Only DCPDN [75]</cell><cell cols="2">39.8 11.7 39.5 12.9</cell><cell></cell><cell>46.6 48.7</cell><cell>19.0 19.7</cell><cell>37.0 37.5</cell><cell>30.9 31.6</cell><cell></cell><cell cols="2">DA-Faster [9] Ours (with [9])</cell><cell>45.1 47.7</cell><cell>2.6</cell></row><row><cell>Grid-Dehaze [76] DA-Faster [9] SWDA [10]</cell><cell cols="2">25.4 10.9 43.7 16.0 44.2 16.6</cell><cell></cell><cell>29.7 42.5 40.1</cell><cell>13.0 18.3 23.2</cell><cell>21.4 32.8 41.3</cell><cell>20.0 30.7 33.1</cell><cell cols="3">SWDA [10] Ours (with [10])</cell><cell>49.0 50.7</cell><cell>1.7</cell></row><row><cell>Ours (with [9]) Ours (with [10])</cell><cell cols="2">45.0 15.9 47.0 16.6</cell><cell></cell><cell>42.0 41.5</cell><cell>22.2 27.2</cell><cell>38.4 43.2</cell><cell>32.7 35.1</cell><cell cols="3">SCL [16] Ours (with [16])</cell><cell>49.5 51.3</cell><cell>1.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Cross-rain adaptation of object detection from Cityscapes to RainCityscapes (multi-domainness).</figDesc><table><row><cell>Methods</cell><cell cols="2">person rider</cell><cell>car</cell><cell>truck</cell><cell>bus</cell><cell cols="2">motor bicycle</cell><cell>mAP</cell><cell>Gain</cell></row><row><cell>DA-Faster [9] Ours (with DA-Faster [9])</cell><cell>22.9 26.3</cell><cell>55.2 60.1</cell><cell>43.4 52.6</cell><cell>3.9 13.0</cell><cell>58.8 60.3</cell><cell>15.2 27.0</cell><cell>30.0 34.9</cell><cell>32.8 39.2</cell><cell>6.4</cell></row><row><cell>SWDA [10] Ours (with SWDA [10])</cell><cell>23.8 25.9</cell><cell>52.1 56.0</cell><cell>46.4 52.5</cell><cell>9.6 8.1</cell><cell>68.2 56.0</cell><cell>16.0 29.4</cell><cell>32.8 33.1</cell><cell>35.6 39.0</cell><cell>3.4</cell></row><row><cell>SCL [16] Ours (with SCL [16])</cell><cell>27.0 29.3</cell><cell>57.9 61.0</cell><cell>50.3 52.7</cell><cell>10.0 19.2</cell><cell>67.9 68.2</cell><cell>13.9 26.2</cell><cell>33.9 34.1</cell><cell>37.3 41.5</cell><cell>4.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>Cross-FoV adaptation of semantic segmentation from Virtual KITTI to CKITTI (multi-domainness).</figDesc><table><row><cell>Method</cell><cell>road</cell><cell>building</cell><cell>pole</cell><cell>light</cell><cell>sign</cell><cell>vegetation</cell><cell>terrain</cell><cell>sky</cell><cell>car</cell><cell>truck</cell><cell>guard rail</cell><cell>11 mIoU</cell><cell>Gain</cell></row><row><cell>AdaptSegNet [26] Ours (with AdaptSegNet [26])</cell><cell>88.0 88.4</cell><cell>80.6 81.0</cell><cell cols="9">11.1 17.4 28.4 80.3 29.2 85.2 82.1 29.7 27.5 9.7 18.9 30.5 80.9 39.1 86.2 83.6 32.6 27.5</cell><cell>50.8 52.6</cell><cell>1.8</cell></row><row><cell>CLAN [29] Ours (with CLAN [29])</cell><cell>88.2 88.1</cell><cell>80.0 79.9</cell><cell>6.0 9.9</cell><cell cols="8">17.9 26.7 79.3 36.1 85.7 82.4 28.5 12.3 19.6 25.3 80.2 38.5 85.9 82.5 29.2 16.4</cell><cell>49.4 50.5</cell><cell>1.1</cell></row><row><cell>SIM [30] Ours (with SIM [30])</cell><cell>87.3 86.7</cell><cell cols="10">81.2 81.9 15.7 16.3 16.1 28.3 81.6 37.6 87.2 82.6 29.3 18.3 17.7 31.7 82.3 48.2 86.6 81.9 32.3 20.4</cell><cell>51.4 53.2</cell><cell>1.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV</head><label>IV</label><figDesc></figDesc><table><row><cell cols="3">: Cross-Fog adaptation of semantic segmentation</cell></row><row><cell cols="3">from Cityscapes to Foggy Zurich++ (multi-domainness).</cell></row><row><cell>Method</cell><cell>mIoU</cell><cell>Gain</cell></row><row><cell>AdaptSegNet [26] Ours (with AdaptSegNet [26])</cell><cell>29.4 35.2</cell><cell>5.8</cell></row><row><cell>CLAN [29] Ours (with CLAN [29])</cell><cell>26.8 31.5</cell><cell>4.7</cell></row><row><cell>SIM [30] Ours (with SIM [30])</cell><cell>27.0 31.1</cell><cell>4.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V :</head><label>V</label><figDesc>Ablation on Cityscapes to Foggy Zurich++.</figDesc><table><row><cell>Baseline</cell><cell>Diversificator</cell><cell>Adaptor</cell><cell>mIoU</cell><cell>Gain</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>29.4</cell><cell>-</cell></row><row><cell></cell><cell>-</cell><cell>MRL [64]</cell><cell>29.9</cell><cell>0.5</cell></row><row><cell></cell><cell>-</cell><cell>CIDA [72]</cell><cell>30.0</cell><cell>0.6</cell></row><row><cell></cell><cell>-</cell><cell>Ours (SAR)</cell><cell>30.8</cell><cell>1.4</cell></row><row><cell>[26]</cell><cell>DD [64] Ours (DC)</cell><cell>--</cell><cell>32.3 33.5</cell><cell>2.9 4.1</cell></row><row><cell></cell><cell>DD [64]</cell><cell>MRL [64]</cell><cell>33.7</cell><cell>4.3</cell></row><row><cell></cell><cell>Ours (DC)</cell><cell>MRL [64]</cell><cell>34.0</cell><cell>4.6</cell></row><row><cell></cell><cell>Ours (DC)</cell><cell>CIDA [72]</cell><cell>34.2</cell><cell>4.8</cell></row><row><cell></cell><cell>Ours (DC)</cell><cell>Ours (SAR)</cell><cell>35.2</cell><cell>5.8</cell></row></table><note>achieves a limited improvement of 0.5% or 0.6%. In contrast, SAR contributes to the performance gain of 1.4%. The diver- sificator, e.g., GAN-based DD [64] only brings 2.9% gain over the baseline, while our DC boosts the baseline by 4.1%.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI :</head><label>VI</label><figDesc>Ablation on Cityscapes to Foggy Cityscapes.</figDesc><table><row><cell cols="3">GPA [13] DC SAR</cell><cell>mAP</cell><cell>Gain</cell></row><row><cell>? ? ?</cell><cell>? ?</cell><cell>?</cell><cell>39.5 42.5 45.2</cell><cell>-3.0 5.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VII :</head><label>VII</label><figDesc>Ablation of the domainnness-specific loss L spf .</figDesc><table><row><cell>Abaltions</cell><cell>mIoU</cell></row><row><cell>baseline(AdaptSegNet [26])</cell><cell>29.4</cell></row><row><cell>Ours (w/o L spf )</cell><cell>34.0</cell></row><row><cell>Ours (w L spf )</cell><cell>35.2</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Faster r-cnn: Towards realtime object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Encoderdecoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Dmt: Dynamic mutual training for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08514</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Domain adaptive faster r-cnn for object detection in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sakaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3339" to="3348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Strong-weak distribution alignment for adaptive object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6956" to="6965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-adversarial faster-rcnn for unrestricted object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6668" to="6677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adapting object detectors via selective cross-domain alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="687" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cross-domain detection via graph-induced prototype alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="355" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Harmonizing transferability and discriminability for adapting object detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8869" to="8878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploring categorical regularization for domain adaptive object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Scl: Towards accurate domain adaptive object detection via gradient detach based stacked complementary losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Maheshwari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02559</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Every pixel matters: Center-aware feature alignment for domain adaptive object detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Y.</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="733" to="748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Domain adaptive object detection via asymmetric tri-way faster-rcnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="309" to="324" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XXIV 16</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Prior-based domain adaptive object detection for hazy and rainy conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">A</forename><surname>Sindagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Oza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yasarla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="763" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Collaborative training between region proposal localization and classification for domain adaptive object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="86" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cross-domain object detection through coarse-to-fine feature adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pit: Position-invariant transform for cross-fov domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Affinity space adaptation for semantic segmentation across domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2549" to="2561" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Categorylevel adversarial adaptation for semantic segmentation using purified features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1989" to="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7472" to="7481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6936" to="6945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning texture invariant representation for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Byun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="975" to="987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2507" to="2516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Differential treatment for stuff and things: A simple unsupervised domain adaptation method for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12" to="635" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">All about structure: Adapting structural information across domains for boosting semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1900" to="1909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fda: Fourier domain adaptation for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4085" to="4095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stochastic classifiers for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9111" to="9120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Phase consistent ecological domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sundaramoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9011" to="9020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Unsupervised intradomain adaptation for semantic segmentation through self-supervision,&quot; in Unsupervised Intra-domain Adaptation for Semantic Segmentation through Self-Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rameau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3764" to="3773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An adversarial perturbation oriented domain adaptation approach for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">620</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Classes matter: A fine-grained adversarial approach to cross-domain semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">12359</biblScope>
			<biblScope unit="page" from="642" to="659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">DADA: depthaware domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7363" to="7372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Self-ensembling with gan-based data augmentation for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6830" to="6840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Significance-aware information bottleneck for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6778" to="6787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Confidence regularized self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5982" to="5991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="289" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Penalizing top performers: Conservative loss for semantic segmentation adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="568" to="583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Domain adaptation for structured output via discriminative patch representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Labelfree regional consistency for image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Semantic foggy scene understanding with synthetic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sakaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="973" to="992" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Benchmarking single-image dehazing and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="492" to="505" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Model adaptation with synthetic and real data for semantic dense foggy scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sakaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="687" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Depth-attentional features for single-image rain removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8022" to="8031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Virtual worlds as proxy for multi-object tracking analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cabon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4340" to="4349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Vision meets robotics: The kitti dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJR</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1231" to="1237" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Context-aware mixup for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.03557</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Uncertainty-aware consistency regularization for cross-domain semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08878</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2517" to="2526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Semi-supervised semantic segmentation via dynamic self-training and classbalanced curriculum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08514</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Self-ensembling for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for medical imaging segmentation with selfensembling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Perone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ballester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Barros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen-Adad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Classmix: Segmentation-based data augmentation for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tranheden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Svensson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1369" to="1378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Dacs: Domain adaptation via cross-domain mixed sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tranheden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Svensson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1379" to="1389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Pixmatch: Unsupervised domain adaptation via pixelwise consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Melas-Kyriazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Manrai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">445</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Self-supervised augmentation consistency for adapting semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Araslanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Selfensembling attention networks: Addressing domain shift for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5581" to="5588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Diversify and match: A domain adaptive representation learning paradigm for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">465</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Generative adversarial nets</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Domain randomization and pyramid consistency: Simulationto-real generalization without accessing target domain data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2100" to="2110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Multimodal unsupervised image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision</title>
		<meeting>the European conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="172" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Diverse image-to-image translation via disentangled representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="35" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Learning deep disentangled embeddings with the f-statistic loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ridgeway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Adapted deep embeddings: A synthesis of methods for k-shot inductive transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ridgeway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Detach and adapt: Learning cross-domain disentangled deep representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8867" to="8876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Continuously indexed domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Katabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1180" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Densely connected pyramid dehazing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3194" to="3203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Griddehazenet: Attentionbased multi-scale network for image dehazing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7314" to="7323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Before that, he received a B.Sc. degree in Jilin University in 2019. His current research interests focus on computer vision, scene understanding</title>
		<imprint/>
		<respStmt>
			<orgName>Qianyu Zhou is currently pursuing his Ph.D. degree in the Department of Computer Science and Engineering, Shanghai Jiao Tong University</orgName>
		</respStmt>
	</monogr>
	<note>domain adaptation</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Qiqi Gu received a B.E. degree in Shanghai Jiao Tong University in 2015 and is now a second-year master student in Department of</title>
		<imprint/>
		<respStmt>
			<orgName>Computer Science and Engineering, Shanghai Jiao Tong University</orgName>
		</respStmt>
	</monogr>
	<note>Her current research interests focus on domain adaptation of object detection and semantic segmentation</note>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
				<title level="m">Jiangmiao Pang is currently a Postdoctoral Research Fellow at Multimedia Laboratory, the Chinese University of Hong Kong. He obtained his Ph.D. degree from Zhejiang University in 2021. His research interests include computer vision and robotics</title>
		<imprint/>
	</monogr>
	<note>especially their applications in autonomous driving</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Before that, he received a B.E. degree in information se</title>
	</analytic>
	<monogr>
		<title level="m">2020. His current research interests focus on pattern recognition with limited human supervision</title>
		<meeting><address><addrLine>Weihai, China</addrLine></address></meeting>
		<imprint/>
		<respStmt>
			<orgName>Department of Computer Science and Engineering, Shanghai Jiao Tong University ; Harbin Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note>Zhengyang Feng is currently pursuing his M.Sc. degree in the</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Chinese Academy of Sciences, China, and he received his Ph.D. degree with national laboratory of pattern recognition (NLPR) from the Institute of Automation</title>
	</analytic>
	<monogr>
		<title level="j">Chinese Academy of Sciences</title>
		<imprint/>
	</monogr>
	<note>His research interests include autonomous driving, scene understanding. domain adaptation and remote sensing image processing</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">His research interests mainly fall into the category of visual computing, for example, geometry modeling, processing and analysis, animation/simulation, 2D data processing and analysis</title>
		<ptr target="http://www.xuequanlu.com" />
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
		<respStmt>
			<orgName>Xuequan Lu is an Assistant Professor at the School of Information Technology, Deakin University</orgName>
		</respStmt>
	</monogr>
	<note>Australia. He spent more than two years as a Research Fellow in Singapore. Prior to that, he earned his Ph.D at Zhejiang University (China</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Currently her team works on developing algorithms for autonomous driving, scene understanding, remote sensing, etc. She got her Ph.D. degree in Computer Science and Engineering Department in the Chinese University of Hong Kong in 2015 under the supervision of Prof. Jiaya Jia. Before that, she received the B. Eng degree from Zhejiang University in 2011</title>
	</analytic>
	<monogr>
		<title level="m">She has served regularly on the organization committees of numerous conferences</title>
		<imprint/>
	</monogr>
	<note>Jianping Shi is an Executive Research Director at SenseTime. such as Area Chair of CVPR 2020, ICCV 2019, etc</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
