<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Observation-Centric SORT: Rethinking SORT for Robust Multi-Object Tracking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinkun</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinshuo</forename><surname>Weng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rawal</forename><surname>Khirodkar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<settlement>Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Shanghai AI Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Kitani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Observation-Centric SORT: Rethinking SORT for Robust Multi-Object Tracking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-Object Tracking (MOT) has rapidly progressed with the development of object detection and reidentification. However, motion modeling, which facilitates object association by forecasting short-term trajectories with past observations, has been relatively underexplored in recent years. Current motion models in MOT typically assume that the object motion is linear in a small time window and needs continuous observations, so these methods are sensitive to occlusions and non-linear motion and require high frame-rate videos. In this work, we show that a simple motion model can obtain state-of-theart tracking performance without other cues like appearance. We emphasize the role of "observation" when recovering tracks from being lost and reducing the error accumulated by linear motion models during the lost period. We thus name the proposed method as Observation-Centric SORT, OC-SORT for short. It remains simple, online, and real-time but improves robustness over occlusion and nonlinear motion. It achieves 63.2 and 62.1 HOTA on MOT17 and MOT20, respectively, surpassing all published methods. It also sets new states of the art on KITTI Pedestrian Tracking and DanceTrack where the object motion is highly non-linear. The code and model are available at https://github.com/noahcao/OC_SORT.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>We aim to develop a motion model-based multi-object tracking method robust to occlusion and non-linear object motion. We are motivated by the fact that most of the common errors during occlusion or non-linear motion, are caused by using models that assume linear motion. In contrast to object detection and re-identification, motion models have been relatively under-explored in recent years. We believe that more work is needed to develop motion models. We recognize some limitations of the linear motion model in video multi-object tracking and find that we can achieve more advanced performance by addressing these limitations and without using other cues such as visual appearance.  <ref type="figure">Figure 1</ref>. Samples from video dancetrack0088 at frame 558, 560, 562 and 565 respectively. SORT and OC-SORT use the same detection results. On the third frame, SORT encounters an ID switch for the backflip target while ours not.</p><p>A widely used motion model-based MOT algorithm is SORT <ref type="bibr" target="#b4">[5]</ref>, which uses a Kalman filter (KF) to estimate object motion. As KF has a linear motion assumption, SORT is more applicable to high frame rate videos where the object motion between consecutive frames can be approximated as linear. However, some challenges may distort its estimation processes, such as occlusions and non-linear object motion. Prior work introduces other cues such as appearance features to tackle these challenges. In the contrast, we present a different perspective that, instead of being centric to estimations, being conditioned on observations can improve the robustness of KF when estimations are unreliable. Such an observation-centric design achieves state-ofthe-art performance on modern MOT benchmarks in a pure motion-based fashion.</p><p>We begin with rethinking SORT and recognizing its three limitations: (1) although the object motion might be approximately linear, the use of high frame rate data can also amplify the sensitivity to state noise. Specifically, between consecutive frames of a high frame-rate video, the noise of displacement of object can be of the same magnitude as the actual object displacement, leading to the estimated object velocity by KF suffering from a large variance; (2) the object state noises can further be accumulated through the time when there is no new object observation (from detection) matched to existing tracklets due to occlusion or non-linear motion. We prove that the error accumulation of object position estimates by KF is of square-order with respect to time in such cases; <ref type="bibr" target="#b2">(3)</ref> SORT is estimationcentric, meaning that it heavily relies on KF state estimation and uses observations only as auxiliary information. However, we believe that the development of modern object detectors has made observations more reliable than ever, so we should make our tracker focus more on the observations. To tackle these limitations, we argue that observations can provide strong evidence to estimate the momentum of a trajectory and to recover a track from being lost. To reach the goal, we propose three innovations: <ref type="bibr" target="#b0">(1)</ref> we design an Observation-centric Online Smoothing (OOS) strategy to alleviate the error accumulation in KF due to lack of observations. In the frame that an inactive track is re-associated to an observation again, we first build a virtual trajectory for this object, starting from its last observation before being un-tracked and ending at the newly matched observation. Along this virtual trajectory, we then smooth the KF parameters to obtain a better estimation of the object position; <ref type="bibr" target="#b1">(2)</ref> we propose to incorporate the direction consistency of tracklets in the cost matrix for better matching between tracklets and observations. The design is motivated by the momentum of trajectories in the linear motion assumption so we call it Observation-Centric Momentum (OCM). We also provide analytical proof in the appendix that estimating the direction between two points with a large time window can reduce sensitivity to noises; (3) To deal with the case of objects being un-tracked due to occlusion in a short time window, we also propose to recover them by associating their last observations with the new observations, which we refer to as Observation-Centric Recovery (OCR).</p><p>The proposed method, named as Observation-Centric SORT or OC-SORT in short, remains simple, online, realtime and significantly improves robustness over occlusion and non-linear motion. Our contributions are summarized as the following: (1) we recognize, analytically and empirically, three limitations of SORT: sensitive to state noises, error accumulation over time, being estimation-centric; <ref type="bibr" target="#b1">(2)</ref> we propose OC-SORT for robust tracking under occlusion and non-linear motion with three innovations: OOS, OCM, and OCR; (3) our OC-SORT achieves new state-of-the-art performance on modern MOT benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Motion Models. Many recent multi-object tracking algorithms <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b77">78,</ref><ref type="bibr" target="#b79">80]</ref> use motion models. Typically, these motion models use Bayesian estimation <ref type="bibr" target="#b36">[37]</ref> to predict the next state by maximizing a posterior estimation. As one of the most classic motion models, the Kalman filter (KF) <ref type="bibr" target="#b31">[32]</ref>, is a recursive Bayes filter that follows a typical predict-update cycle. The true state is assumed to be an unobserved Markov process, and the measurements are observations of a hidden Markov model <ref type="bibr" target="#b45">[46]</ref>. Given that the linear motion assumption limits KF, following works like Extended KF <ref type="bibr" target="#b54">[55]</ref> and Unscented KF <ref type="bibr" target="#b29">[30]</ref> were proposed to handle non-linear motion with first-order and third-order Taylor approximation. However, these still rely on approximating the Gaussian prior assumed by KF. On the other hand, particle filters <ref type="bibr" target="#b22">[23]</ref> deal with the non-linear motion by sampling-based posterior estimation but require exponential order of computation. In Bayesian Estimation, filtering uses only past data while smoothing uses both past and future data for estimation. Fixed-lag smoother <ref type="bibr" target="#b0">[1]</ref> and fixed-interval smoother <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b47">48]</ref> are studied to improve sequential data fitting after having built the whole trajectory.</p><p>Multi-object Tracking is traditionally approached from probabilistic perspectives, such as joint probabilistic association <ref type="bibr" target="#b1">[2]</ref>. On the other hand, modern video object tracking is usually driven by object detection <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b80">81]</ref>. SORT <ref type="bibr" target="#b4">[5]</ref> adopts the Kalman filter for motion-based multiobject tracking given observations from deep detectors. Advances in deep visual representations <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b53">54]</ref> led to Deep-SORT <ref type="bibr" target="#b69">[70]</ref>, which introduces deep visual features into object association in the framework of SORT. Appearancebased object matching <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b78">79]</ref> has also become popular, but falls short in many cases, especially when scenes are crowded and objects are represented coarsely (e.g bounding boxes), or object appearance is not distinguishable. Recently, Transformers <ref type="bibr" target="#b62">[63]</ref> have been used in MOT <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b76">77]</ref> to learn deep representations with both visual information and trajectory encoded. These methods show good results but still fall short in many cases, especially for online tracking and under occlusion, leaving significant room for improvement in motion-based multi-object tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Rethinking SORT</head><p>In this section, we provide the review of SORT <ref type="bibr" target="#b4">[5]</ref> and Kalman filter that SORT uses for motion modeling. We recognize some limitations of them which become significant with occlusion or non-linear object motion. These limitations motivate the improvement we propose in this work. the estimated state on the previous time step and the current measurement for the state estimation for the new time step. The filter maintains two variables, the posterior state estimate x, and the posterior estimate covariance matrix P of the state. In the task of object tracking, where no active control is sent, we describe the process of KF with other parameters such as the state transition model F, the observation model H, the process noise Q and the observation noise R. At each step t, KF predicts the prior estimate of state x and the covariance state matrix P b?</p><formula xml:id="formula_0">x t|t?1 = F txt?1|t?1 , P t|t?1 = F t P t?1|t?1 F t + Q t .<label>(1)</label></formula><p>If an observation z t is given on this step, KF calculate the posteriors with the following update rules:</p><formula xml:id="formula_1">K t = P t|t?1 H t (H t P t|t?1 H t + R t ) ?1 , x t|t =x t|t?1 + K t (z t ? H txt|t?1 ), P t|t = (I ? K t H t )P t|t?1 .<label>(2)</label></formula><p>In practice, we often have no observation on some time steps, e.g. if the target object is occluded in multi-object tracking. In such cases, we cannot na?vely use the KF update rules. To address this, a way is to simply re-use the current estimates for the next time step. The intuition here is to trust the motion model predictions when no observations are available to supervise them. However, we will see this mechanism can cause issues in MOT.</p><p>SORT <ref type="bibr" target="#b4">[5]</ref> is a multi-object tracker built on KF based motion model. The KF's state x in SORT is a seven-tuple, x = [u, v, s, r,u,v,?] , where (u, v) is the 2D coordinates of the object center in the image. s is the bounding box scale (area) and r is the bounding box aspect ratio. The aspect ratio r is assumed to be constant. The other three variables,u, v and? are the associated time derivative. The observation is a bounding box z = [u, v, w, h, c] with object center position (u, v), object width w and height h and the detection confidence c respectively. SORT assumes linear motion of the target object so the transition model is</p><formula xml:id="formula_2">F = ? ? I 4?4 I 3?3 0 1?3 0 3?4 I 3?3 ? ? ,<label>(3)</label></formula><p>making the position on consecutive steps as</p><formula xml:id="formula_3">u t+1 = u t +u t ?t, v t+1 = v t +v t ?t.<label>(4)</label></formula><p>When the time difference between two steps ?t is consistent over the transition, e.g. , constant frame rate, we can set ?t = 1. In general, when the video frame rate is high, SORT also works well under tracking scenarios with nonlinear object motion (e.g. dancing, fencing, wrestling). This is because the motion of the target object can be well approximated as linear within short time intervals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Limitations of SORT</head><p>In this section, we identify three main limitations of SORT which are connected. This analysis lays the foundation of our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Sensitive to State Noise</head><p>We show that SORT is sensitive to the noise from KF's states. To begin with, it is reasonable to assume that the estimated object center position follows u ? N (? u , ? 2 u ) and v ? N (? v , ? 2 v ). Then, if we assume the state noises are independent on different steps, following Eq. 3, the estimated object speed between two time-steps t and t + ?t i?</p><formula xml:id="formula_4">u = u t+?t ? u t ?t ,v = v t+?t ? v t ?t ,<label>(5)</label></formula><p>making the noise of estimated speed ?u ? N (0,</p><formula xml:id="formula_5">2? 2 u (?t) 2 ), ?v ? N (0, 2? 2 v (?t) 2 )</formula><p>. So estimating speed between consecutive frames, i.e. ?t = 1, maximizes the noise.</p><p>Moreover, for most multi-object tracking scenarios, the target object displacement is only a few pixels between consecutive frames. For instance, the average displacement is 1.93 pixels and 0.65 pixels along image width and height for the MOT17 <ref type="bibr" target="#b42">[43]</ref> training dataset. In such a case, even if the estimated position has a shift of only a few pixes, it causes significant variance to the estimated speed. In general, the variance of speed estimation can be of the same magnitude as the speed itself or even bigger. In most cases, this will not make a massive impact as the shift is only of few pixels from the ground truth on the next time step and the supervision provided by the observation corrects the estimates from KF motion model. However, we will see the sensitivity introduces significant problems in practice because of the error accumulation across multiple time-steps when no observation is available for KF update.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Temporal Error Magnification</head><p>For analysis above in Eq. 5, we assume the position estimation is independent on each time step. This is reasonable for object detections but not for KF estimates because the state estimates for later steps rely on the previous states. The effect is usually minor because KF can use observation to supervise state estimates in the update stage. However, when no observations are provided to KF, it recursively updates parameters only based on its own predictions. Consider a track is occluded between t and t+T and the noise of speed estimate follows ?u t ? N (0, 2? 2 u ), ?v t ? N (0, 2? 2 v ) for SORT. Till the step t + T , the estimated position is The target #1 is lost on the frame t+1 because of occlusion. But on the next frame, it is recovered by referring to its observation of the frame t by OCR. It being re-tracked triggers OOS from t to t+2 for the parameters of its KF.</p><formula xml:id="formula_6">u t+T = u t + Tu t , v t+T = v t + Tv t ,<label>(6)</label></formula><formula xml:id="formula_7">whose noise follows ? u t+T ? N (0, 2T 2 ? 2 u ) and ? v t+T ? N (0, 2T 2 ? 2 v )</formula><p>. So without the supervision from observation, the estimates from linear motion assumption of KF results in square-order error accumulation with respect to time. Given ? v and ? u is of the same magnitude as object displacement between consecutive frames, the noise of final object position (u t+T , v t+T ) is of the same magnitude as the object size. For instance, the size of pedestrians close to camera on MOT17 is around 50 ? 300 pixels. So even assuming the variance of position estimates to be around 1 pixel, 10-frame occlusion can accumulate a shift of final position estimates as large a the object size. Such error magnification leads to major when the scenes are crowded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Estimation-Centric</head><p>The aforementioned limitations are due to two fundamental drawbacks of the KF, i) the noise from state estimates, and ii) the error accumulation when using a hidden Markov process to construct a trajectory. They reveal a fundamental risk: that KF is designed to be estimation-centric. The external observations serve only to assist in the propagation of KF trajectory. A key difference between state estimates and observations is that we can assume that the observations by a object detector in each frame are affected by i.i.d. noise ? z ? N (0, ? 2 ). Recent object detectors use object appearance in the image <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b53">54]</ref>, which is ignored by KF when making estimates. In practice, we can expect ? &lt; ? u and ? &lt; ? v . Additionally, the variance will not be accumulated with time. Therefore, a robust multi-object tracker under occlusion should give more importance to the observations than the KF's state estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Observation-Centric SORT</head><p>In this section, we introduce the proposed Observation-Centric Sort (OC-SORT). To address the limitations discussed above, we use the momentum of the object moving into the association stage and develop a pipeline with less noise and more robustness over occlusion and nonlinear motion. The key is to design a tracker which is observation-centric in contrast to the estimation-centric SORT. If a track is recovered from being untracked, we use an Observation-centric Online Smoothing (OOS) strategy to counter the accumulated error during the untracked period. OC-SORT also adds an Observation-Centric Momentum (OCM) term in the association cost. We additionally design Observation-Centric Recovery (OCR) to search for lost objects around its last observation. The three innovations come as a bundle instead of being one-to-one mapped to the three limitations of SORT discussed above. Please refer to Algorithm 1 in Appendix for the pseudo-code of OC-SORT. The pipeline is shown in <ref type="figure" target="#fig_1">Fig. 2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Observation-centric Online Smoothing (OOS)</head><p>Once a track is associated to an observation again after a period of being untracked, we perform online smoothing over the parameters back to the period of being lost through The target is occluded between the second and the third time step and the tracker finds it back at the third step. Yellow boxes are observations by the detector. White stars are the estimated centers without OOS. Yellow stars are the estimated centers fixed by OOS. The gray star on the fourth step is the estimated center without OOS and fails to match to observations. a virtual trajectory of observations. This can fix the accumulated error during the time interval. For example, we denote the last observation before being untracked as z t1 and the observation triggering the re-association as z t2 . Then the virtual trajectory can be generated with different hypotheses and denoted a?</p><formula xml:id="formula_8">z t = T raj virtual (z t1 , z t2 , t), t 1 &lt; t &lt; t 2 .<label>(7)</label></formula><p>Along this virtual trajectory, we can start from the status at t 1 to back check the filter parameters by alternating between the prediction (Eq 1) and update (Eq 2) stages. Given the supervision of the virtual observation trajectory, error raised in state estimation would not be accumulated any more. The refreshed state estimates follo?</p><formula xml:id="formula_9">x t = F txt?1 + K t (? t ? H t F txt?1 ).<label>(8)</label></formula><p>This operation is not Bayesian smoothing <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b47">48]</ref> as it only uses data up to the current time step and does not change previous tracking results. Furthermore, it performs on observation trajectory instead of filter parameter space or estimates. As they are different in both design and objectives, we call this process "online smoothing".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Observation-Centric Momentum (OCM)</head><p>The linear motion model assumes a consistent velocity direction. However, this assumption often does not hold due to the non-linear motion of objects and state noise. In a reasonably short time, we can approximate the motion as linear but the noise still prevents us from leveraging the consistency of velocity direction. We propose a way to reduce the noise and add the velocity consistency (momentum) term into the cost matrix. Given N existing tracks and M detections, the association cost is</p><formula xml:id="formula_10">C(X, Z) = C IoU (X, Z) + ?C v (X, Z, V),<label>(9)</label></formula><p>whereX ? R N ?7 and Z ? R M ?5 are the sets of estimated object states and observations. V ? R N contains the directions of existing tracks calculated by two previous observations of time difference ?t. C IoU (?, ?) calculates the negative pairwise IoU (Intersection over Union) and C v (?, ?) calculates the consistency of i) track directions and ii) direction formed by a track's historical observation and the new observations. ? is a weighting factor. We use observations associated to a track for direction calculation to avoid error accumulation in estimated states, but there is still a choice about which two observations we should choose. We reach a result that, under the linear-motion model, the noise scale is proportional to the time difference of the two observation points. The proof is analytical and provided in Appendix. But the trajectory is usually only linear by approximation within a short time interval, so the time difference should be held not too large to avoid the collapse of linear approximation. This requires a trade-off in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Observation-Centric Recovery (OCR)</head><p>In general, a broken track usually stems from observation loss (unreliable detector or occlusion) or non-linear motion. In an observation-centric perspective, a conservative degradation of extending SORT to non-linear to recover lost targets is to check the location where it becomes untracked. From an intuitive standpoint, this is analogous to re-identifying an object with no trajectory prior, whose position can be thought of as following a Gaussian distribution with the position of its last-time presence as the mean and the variance growing with respect to the time of its being lost. For multi-object tracking in online fashion, we propose a conservative alternative rather. As the global optimum can be only achieved with an accurate non-linear hypothesis and global assignment. We name it Observation-Centric Recovery to trust the observation instead of the estimates distorted by propagation over time. Once a track is still untracked after the normal association stage, we try to associate the last observation of this track to the observations on the new-coming time step. We note this process is heuristic and local that can handle the case of object stopping or being occluded for a reasonable time interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In this section, we provide experiments to demonstrate the efficiency of OC-SORT on multiple datasets, especially DanceTrack <ref type="bibr" target="#b58">[59]</ref> where objects are in heavy occlusion, frequent crossover, and non-linear motion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Setup</head><p>We introduce the setup of our experiments in this part, which is designed to prove the robustness of OC-SORT for tracking with occlusion and non-linear motion.</p><p>Datasets. We evaluate our method on multiple multiobject tracking datasets like MOT17 <ref type="bibr" target="#b42">[43]</ref>, MOT20 <ref type="bibr" target="#b13">[14]</ref>, KITTI <ref type="bibr" target="#b20">[21]</ref> and DanceTrack <ref type="bibr" target="#b58">[59]</ref>. MOT17 <ref type="bibr" target="#b42">[43]</ref> and MOT20 <ref type="bibr" target="#b13">[14]</ref> are for pedestrian tracking, whose motions are nearly linear. But the scenes in MOT20 are more crowded in comparison to MOT17. KITTI <ref type="bibr" target="#b20">[21]</ref> is for pedestrian and car tracking with a relatively low frame rate of 10FPS. Dance-Track <ref type="bibr" target="#b58">[59]</ref> is a recently proposed dataset for human tracking which encourages multi-object tracking studies with better association instead of detection. In this dataset, object localization is easy but the object motion is highly nonlinear. Further, the objects have a close appearance, severe occlusion, and frequent crossovers. These present a big challenge to both motion-based and appearance-matchingbased tracking algorithms. Considering our goal is to improve tracking robustness in occlusion and non-linear object motion, we would like to emphasize the comparison between OC-SORT and previous methods on DanceTrack in the following experiments. Implementations. For a fair comparison, we directly apply the object detections from existing baselines. For MOT17, MOT20, and DanceTrack, we use the publicly available YOLOX <ref type="bibr" target="#b19">[20]</ref> detector weights by ByteTrack <ref type="bibr" target="#b77">[78]</ref>. For KITTI <ref type="bibr" target="#b20">[21]</ref>, we use the detections from PermaTrack <ref type="bibr" target="#b61">[62]</ref> publicly available in the official release. The methods using the same object detections are placed at the bottom of each table. For OOS, we generate the virtual trajectory during occlusion using a constant velocity assumption. Therefore, Eq. 7 in Section 4 is adopted a?</p><formula xml:id="formula_11">z t = z t1 + t ? t 1 t 2 ? t 1 (z t2 ? z t1 ), t 1 &lt; t &lt; t 2 .<label>(10)</label></formula><p>For OCM, the velocity direction is calculated using the observations three-time-steps apart, i.e. ?t = 3. The direction difference is measured by the absolute difference of angles in radians. We set ? = 0.2 in Eq. 9. Further, similar to the common practice of SORT, we set the detection confidence threshold at 0.4 for MOT20 and 0.6 for other datasets. The IoU threshold during association is 0.3. For results on MOT17 and MOT20 private settings, following ByteTrack, we use linear interpolation. For other datasets, "Ours" indicates online OC-SORT, and "Ours + Linear Interp" indicates boosting the online output by linear interpolation.</p><p>Metrics. We use HOTA <ref type="bibr" target="#b39">[40]</ref> as the main metric. In contrast to MOTA <ref type="bibr" target="#b42">[43]</ref>, HOTA maintains a balance between the accuracy of object detection and association. We also report association metrics, such as IDF1 and AssA, and the raw statistics such as ID switch (IDs) and Fragments (Frag.). If a method does not report some metrics in the paper, we use its results from benchmarks' official leaderboards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Benchmark Results</head><p>MOT17 and MOT20. We report OC-SORT's performance on MOT17 and MOT20 in <ref type="table">Table 1</ref> and <ref type="table">Table 2</ref> using the private detections. As can be seen, OC-SORT achieves comparable performance to other state-of-the-art methods.</p><p>Our gains are especially significant on MOT20 under severe pedestrian occlusion, setting a state-of-the-art HOTA of 62.1. Note, our method is designed to be simple for better generalization so we do not use adaptive detection thresholds used in some baselines. However, we still inherit its linear interpolation for a fair comparison. Although we use the same object detectors as baselines, there is still some variance in detections. Therefore, we also report with the public detections on MOT17/MOT20 in <ref type="table">Table 3</ref> and <ref type="table">Table 4</ref>. In addition, we use the commonly adopted detection filtering <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b79">80]</ref>. Similar to private detections, OC-SORT outperforms the prior art using the public detections. Again, our HOTA gains are significant on the crowded MOT20.</p><p>DanceTrack. To evaluate OC-SORT under challenging non-linear object motion, we report results on the Dance-Track in <ref type="table">Table 5</ref>. Following the same trend, OC-SORT sets a new state-of-the-art, outperforming the baselines by a great margin under non-linear object motions. Note, the detection metrics like MOTA and DetA of OC-SORT are also much higher than the results on previous datasets. On the other hand, though OC-SORT has significantly better association performance, the association metrics such as HOTA, IDF1, and AssA are still lower than its results on previous datasets. This suggests that the difficulty of tracking objects on DanceTrack is majorly due to object association. We compare the tracking results of SORT and OC-SORT under extreme non-linear situations in <ref type="figure">Fig.1</ref> and more samples are available in <ref type="figure" target="#fig_6">Fig. 5</ref> in the Appendix. Further, we visualize output trajectories by OC-SORT and SORT on randomly selected DanceTrack videos clips in <ref type="figure">Fig. 6</ref> in the appendix where we show the comparison of trajectories output by SORT and OC-SORT in a longer time segment (100 frames) in diverse situations. As we focus on improving multi-object tracking in occlusion and non-linear motion cases, the results on DanceTrack are strong evidence of the efficiency of OC-SORT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KITTI.</head><p>In <ref type="table">Table 6</ref> we report results on the KITTI dataset. For fairness, we evaluate the weights released by Per- Then, we run OC-SORT over its detections. As initializing SORT's track requires continuous tracking across several frames ("minimum hits"), we observe that the results not recorded during the track initialization make a significant difference. To address this, we design head padding (HP) post-processing by writing these entries back after finishing the online tracking stage. The results on KITTI show an essential shortcoming of OC-SORT that it highly relies on the IoU matching for the association. As a result, when the object velocity is high, or the frame rate is low, the IoU of object bounding boxes between consecutive frames can be very low or even zero. This phenomenon poses a significant challenge to our method. Note, in contrast to the baseline car tracking performance, OC-SORT improves the pedestrian tracking performance to a new state-of-the-art. We believe the results shown on multiple benchmarks have demonstrated the efficiency of our proposed OC-SORT. We note that we use a shared parameter stack for different datasets, carefully tuning the parameters might further boost the performance. For example, ?t in OCM can be sensitive to different datasets and the adaptive detection threshold is also proved useful when adapting to a new dataset <ref type="bibr" target="#b77">[78]</ref>. Other metrics such as GIoU <ref type="bibr" target="#b51">[52]</ref> can also be potential for association.</p><p>Besides the association performance discussed above, we also care about the inference speed of tracking algorithms. As different methods may have different detectors and running environments, it is hard to compare them directly. Therefore, we only report the inference speed of OC-SORT. On the KITTI dataset, given the detections, our method runs at 793 FPS on an Intel i9-9980XE CPU @ 3.00GHz. Further, adding linear interpolation post-processing makes the inference speed 709 FPS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Ablation Study</head><p>Component Ablation. We ablate the contribution of each proposed module in OC-SORT on the validation sets of MOT17 and DanceTrack datasets in <ref type="table">Table 7</ref>. The splitting of the MOT17 validation set follows the common practice following CenterTrack <ref type="bibr" target="#b79">[80]</ref>. We use the official validation set of DanceTrack. The results prove the efficiency of each of the three OC-SORT modules on both datasets.</p><p>Virtual Trajectory in OOS. We have multiple empirical hypotheses for choosing the virtual trajectory in Observation-centric Online Smoothing. For simplicity, we follow the naive hypothesis of constant speed in Eq 10. There are also other alternatives like constant acceleration, regression-based fitting such as Linear Regression (LR) or Gaussian Process Regression (GPR), and Near Constant Acceleration Model (NCAM) <ref type="bibr" target="#b28">[29]</ref>. As discussed previously, GPR is expected to introduce non-linear robustness into OOS. For GPR, we use the RBF kernel <ref type="bibr" target="#b9">[10]</ref> k(x, x ) = exp ? ||x?x || 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>50</head><p>. We provide more studies about the setting of the kernel in Appendix. The results in <ref type="table">Table 8</ref> show that the local hypotheses such as Constant Speed/Acceleration perform much better. On the other hand, both LR and GPR show poor performance. As the virtual trajectory generation happens in an online fashion, it is hard to get a reliable fit using only limited historical data as the future trajectory is unavailable.</p><p>?t in OCM. As discussed in Section 4, there is a trade-off introduced by choosing an optimal time difference ?t in OCM. A large ?t has better robustness over the noise under the linear motion assumption. The proof of this statement  <ref type="table">Table 10</ref>. Ablation study about the interpolation post-processing. is provided in the appendix. However, in practice, a large ?t is likely to discourage approximating object motion as linear. We, therefore, study the influence of varying ?t in <ref type="table" target="#tab_4">Table 9</ref>. Our results agree with our analysis that increasing ?t from ?t = 1 can boost the association performance until a bottleneck. It is believed from relieving the impact of noise in direction estimation. Keeping increasing ?t higher than the bottleneck instead hurts the performance. It likely results from the challenge of maintaining approximation of linear motion in a longer time interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MOT17-val</head><p>Interpolation as post-processing. Although we focus on developing an online tracking algorithm, we are also interested in whether post-process can further optimize the tracking results in diverse conditions. Despite the failure of GPR in online tracking in <ref type="table">Table 8</ref>, we continue to study if GPR is better suited for interpolation in <ref type="table">Table 10</ref>. We compare GPR with the widely-used linear interpolation. The maximum gap for interpolation is set as 20 frames and we use the same kernel for GPR as mentioned above. The results suggest that the GPR's non-linear interpolation is simply not efficient. We think this is due to limited data points which results in an inaccurate fit of the object trajectory. Further, the variance in regressor predictions introduces extra noise. Although GPR interpolation decreases the performance on MOT17-val significantly, its negative influence on DanceTrack is relatively minor where the object motion is more non-linear. We believe how to fit object trajectory with non-linear hypothesis still requires more study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Limitations</head><p>Our experiments reveal some limitations of OC-SORT. For example, when the video is of low frame rate or the object motion is fast, as cars in KITTI, the proposed method falls short in matching objects by only using IoU and trajectory direction consistency. Nevertheless, SORT also has the same limitation. Adding other cues such as center distance <ref type="bibr" target="#b79">[80]</ref> or appearance similarity has been demonstrated <ref type="bibr" target="#b69">[70]</ref> efficient to solve this. Besides, our method is still built upon the classic Kalman filters without a fundamental extension for non-linear object motion and the unsuccessful attempt of the Gaussian Process warns the difficulty of extending SORT fully to non-linear object motion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We analyze the popular motion-based SORT tracker and point out its limitations from the use of Kalman filter. These limitations play even bigger roles when the tracker fails to gain observations for supervision -likely caused by unreliable detection, occlusion, or fast and non-linear target object motion. To address these issues, we propose Observation-Centric SORT (OC-SORT). OC-SORT is robust to occlusion and non-linear object motion while still being simple, online, and realtime. Our proposed method is motivated by both analytical and empirical findings and focuses on leveraging observations more confidently in the interaction with Kalman filter. In our experiments on multiple popular tracking datasets, OC-SORT significantly outperforms the state of the art. Our gains are especially significant for multi-object tracking under severe occlusion and on objects with dramatic non-linear motion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Velocity Direction Variance in OCM</head><p>In this section, we work on the setting of linear motion with noisy states. We provide the proof that, the trajectory direction estimation has smaller variance if the two states we use for the estimation have a larger time difference. We assume the motion model is x t = f (t) + where is gaussian noise and the ground-truth center position of the target is (? ut , ? vt ) at time step t. Then, estimated on two steps t 1 and t 2 , the true motion direction between these two points is</p><formula xml:id="formula_12">? = arctan( ? vt 1 ? ? vt 2 ? ut 1 ? ? ut 2 ),<label>(11)</label></formula><p>which is a constant if our estimation incurs zero noise. And</p><formula xml:id="formula_13">we have ? vt 1 ? ? vt 2 ? t 1 ? t 2 , ? ut 1 ? ? ut 2 ? t 1 ? t 2 .</formula><p>As the detection results do not suffer from the error accumulation due to propagating along markov process as Kalman filter does, we can assume the states from observation suffers some i.i.d. noise, i.e., u t ? N (? ut , ? 2 u ) and v t ? N (? vt , ? 2 v ). We now analyze the noise of the estimated? = vt 1 ?vt 2 ut 1 ?ut 2 by two observations on the trajectory. Because the function of arctan(?) is monotone over the whole real field, we can study tan? instead which simplifies the analysis. We denote w = u t1 ? u t2 , y = v t1 ? v t2 , and z = y w , first we can see that y and w jointly form a Gaussian distribution:</p><formula xml:id="formula_14">y w ? N ? y ? w , ? 2 y ?? y ? w ?? y ? w ? 2 w ,<label>(12)</label></formula><p>where ? y = ? vt 1 ? ? vt2 , ? w = ? ut 1 ? ? ut 2 , ? w = ? 2? u and ? y = ? 2? v , and ? is the correlation coefficient between y and w. We can actually derive a closed-form solution of the probability density function <ref type="bibr" target="#b24">[25]</ref> of z as</p><formula xml:id="formula_15">p(z) = g(z)e g(z) 2 ??r(z) 2 2? 2 r(z) 2 ? 2?? w ? y r(z) 3 ? g(z) ?r(z) ? ? ? g(z) ?r(z) + ?e ?2?/? ?? w ? y r(z) 2 (13) where r(z) = z 2 ? 2 y ? 2?z ? y ? w + 1 ? 2 w , g(z) = ? y z ? 2 y ? ?(? y + ? w z) ? y ? w + ? w ? 2 w , ? = ? 2 w + ? 2 y ? 2 y ? 2?? y ? w ? w ? y , ? = 1 ? ? 2 ,<label>(14)</label></formula><p>and ? is the cumulative distribution function of the standard normal. Without loss of generality, we can assume ? w &gt; 0 and ? y &gt; 0 because negative ground-truth displacements  . We set ? y and z as two variables. It shows that under different settings of true velocity direction, when ? y is smaller, the probability of estimated value with significant shift from the true value is higher. As ? y is proportional to the time difference of the two selected observations under linear motion assumption, it relates to the case that the two steps for velocity direction estimation has shorter time difference. enjoy the same property. This solution has good property that larger ? w or ? y makes the probability density at the true value, i.e. ? z = ?y ?w , higher, and the tails decay more rapidly. So the estimation of arctan?, also ?, has smaller noise when ? w or ? y is larger. Under the assumption of linear motion, we thus should select two observations with large temporal difference to estimate the direction.</p><p>It is reasonable to assume the noise of detection along u-axis and v-axis are independent so ? = 0. And when representing the center position in pixel, it is also moderate to assume ? w = ? y = 1 (also for the ease of presentation). Then, with different true value of ? z = ?y ?w , the visualizations of p(z) over z and ? y are shown in <ref type="figure" target="#fig_5">Figure 4</ref>. The visualization demonstrates our analysis above. Moreover, it shows that when the value of ? y or ? w is small, the cluster peak of the distribution at ? z is not significant anymore, as the noise ? y and ? w can be dominant. Considering the visualization shows that happens when ? y is close to ? y , this can actually happen when we estimate the speed by observations from two consecutive frames because the variance of observation can be close to the absolute displacement of object motion. This makes another support to our analysis in the main paper about the sensitivity to state estimation noise. <ref type="table">Table 11</ref>. Ablation study about using Gaussian Process Regression for object trajectory interpolation. LI indicates Linear Interpolation, which is used to interpolate the trajectory before smoothing the trajectory by GPR. MT indicates Median Trick for kernel choice in regression. L ? is the length of trajectory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MOT17-val</head><p>DanceTrack-val </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Interpolation by Gaussian Progress Regression</head><p>From the analysis in the main paper, the failure of SORT can mainly result from occlusion (lack of observations) or the non-linear motion of objects (the break of linear-motion assumption). So the question arises naturally whether we can extend SORT free of the linear-motion assumption or at least more robust when it breaks.</p><p>One way is to extend from KF to non-linear filters, such as EKF <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b54">55]</ref> and UKF <ref type="bibr" target="#b29">[30]</ref>. However, for real-world online tracking, they can be hard to be adopted as they need knowledge about motion pattern or still rely on the techniques fragile to non-linear pattern, such as linearization <ref type="bibr" target="#b30">[31]</ref>. Another choice is to gain the knowledge beyond linearality by regressing previous trajectory, such as combing Gaussian Process (GP) <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b68">69]</ref>: given a observation z and a kernel function k(?, ?), GP defines gaussian functions with mean ? z and variance ? z as</p><formula xml:id="formula_16">? z = k [K + ? 2 I] ?1 y, ? z = k(z , z ) ? k [K + ? 2 I] ?1 k ,<label>(15)</label></formula><p>where k is the kernel matrix between the input and training data and K is the kernel matrix over training data, y is the output of data. In the main paper, we show a primary study of using Gaussian Process Regression (GPR) in online generation of the virtual trajectory in OOS and in offline interpolation. But neither of them successfully boosts the tracking performance. In this section, We investigate in detail the chance of combining GPR and SORT for multiobject tracking for interpolation as some designs are worth more study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Choice of Kernel Function in Gaussian Process</head><p>The kernel function is a key variable of GPR. There is not a generally efficient guideline to choose the kernel for Gaussian Process Regression though some basic observations are available <ref type="bibr" target="#b14">[15]</ref>. When there is no additional knowledge about the time sequential data to fit, the RBF kernel is one of the most common choices:</p><formula xml:id="formula_17">k(x, x ) = ? 2 exp ? ||x ? x|| 2 2l 2 ,<label>(16)</label></formula><p>where l is the lengthscale of the data to be fit. It determines the length of the "wiggles" of the target function. ? 2 is the output variance that determines the average distance of the function away from its mean. This is usually just a scale factor <ref type="bibr" target="#b14">[15]</ref>. GPR is considered sensitive to l in some situations. So we conduct an ablation study over it in the offline interpolation to see if we can use GPR to outperform the linear interpolation widely used in multi-object tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. GPR for Offline Interpolation</head><p>In the main paper, we present the use of GPR in online virtual trajectory fitting <ref type="table">(Table 8</ref>) and offline interpolation ( <ref type="table">Table 10)</ref> where we use l 2 = 25 and ? = 1 for the kernel in Eq. 16. Further, we make a more thorough study of the setting of GPR. We follow the settings of experiments in the main paper that only trajectories longer than 30 frames are put into interpolation. And the interpolation is only applied to the gap shorter than 20 frames. We conduct the experiments on the validation set of MOT17 and DanceTrack.</p><p>For the value of l, we try fixed values, i.e. l = 1 and l = 5 (2l 2 = 50), value adaptive to trajectory length, i.e.  <ref type="bibr" target="#b60">[61]</ref>. Our method uses the detections from HeadHunter <ref type="bibr" target="#b60">[61]</ref> or Fair-MOT <ref type="bibr" target="#b78">[79]</ref>   <ref type="bibr" target="#b18">[19]</ref>. The training data is a series of quaternary [u, v, w, h], normalized to zero-mean before being fed into training. The results are shown in <ref type="table">Table 11</ref>. Linear interpolation is simple but builds a strong baseline as it can stably improve the tracking performance concerning multiple metrics. Directly using GPR to interpolate the missing points hurts the performance and the results of GPR are not sensitive to the setting of l.</p><p>There are two reasons preventing GPR from accurately interpolating missing segments. First, the trajectory is usually limited to at most hundreds of steps, providing very limited data points for GPR training to converge. Besides, the missing intermediate data points make the data series discontinuous, causing a huge challenge. We can fix the second issue by interpolating the trajectory with Linear Interpolation (LI) first and then smoothing the interpolated steps by GPR. This outperforms LI on DanceTrack but still regrades over LI on MOT17. This is likely promoted by the non-linear motion on DanceTrack. By fixing the missing data issue of GPR, GPR can have more accurate trajectory fitting over LI for the non-linear trajectory cases. But considering the outperforming from GPR is still minor compared with the Linear Interpolation-only version and GPR requires much heavier computation overhead, we do not recommend using such a practice in most multi-object tracking tasks. More careful and deeper study is still required on this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results for Head Tracking</head><p>When considering tracking in the crowd, focusing on only a part of the object can be beneficial as it usually suffers less from occlusion than the full body. This line of study is conducted over hand tracking <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b52">53]</ref>, human pose <ref type="bibr" target="#b72">[73]</ref> and head tracking <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b60">61]</ref> for a while. Moreover, with the knowledge of more fine-grained part trajectory, it can be useful in downstream tasks, such as action recognition <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref> and forecasting <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36]</ref>. As we are interested in the multi-object tracking in the crowd, we also evaluate the proposed OC-SORT on a recently proposed human head tracking dataset CroHD <ref type="bibr" target="#b60">[61]</ref>.</p><p>To make a fair comparison on only the association performance, we adopt OC-SORT by directing using the detections from existing tracking algorithms. The results are shown in <ref type="table" target="#tab_0">Table 12</ref>. The detections of FairMOT <ref type="bibr" target="#b78">[79]</ref> and HeadHunter <ref type="bibr" target="#b60">[61]</ref> are extracted from their tracking results downloaded from the official leaderboard 1 . We use the same parameters for OC-SORT as on the other datasets we evaluate on. The results suggest a significant tracking performance improvement compared with the previous methods <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b78">79]</ref> for human body part tracking. But considering the tracking performance is still relatively low (HOTA=40) which is highly related to the tiny size of head targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Pseudo-code of OC-SORT</head><p>The pseudo-code of OC-SORT is provided in Algorithm. 1 for reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. More Results on DanceTrack</head><p>To gain more intuition about the improvement of OC-SORT over SORT, we provide more comparisons. In <ref type="figure">Fig</ref> As DanceTrack <ref type="bibr" target="#b58">[59]</ref> is proposed to emphasize association algorithm so the object detection is relatively easy on it. We train to use the YOLOX <ref type="bibr" target="#b19">[20]</ref> trained from the MOT17 training set to provide detections on DanceTrack and find the tracking performance of OC-SORT is already higher than baselines. The results are shown in <ref type="table" target="#tab_8">Table 13</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) SORT (b) The proposed OC-SORT</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>A visual illustration of our proposed method, OC-SORT. On each frame, red boxes are detections, orange boxes are active tracks, blue boxes are untracked tracks, dashed boxes are the estimates from KF. During association OCM is used to add the velocity consistency cost.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Example of how Observation-centric Online Smoothing reduces the error accumulation when a track is broken.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>(</head><label></label><figDesc>a) ?z = 0.1 (b) ?z = 0.5 (c) ?z = 2 (d) ?z = 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>The probability density of z = tan? under different true value of z, i.e. ? z = ?y ?w</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>- ure 5 ,</head><label>5</label><figDesc>we show more samples where SORT suffers from ID switch or Fragmentation caused by non-linear motion or occlusion but OC-SORT survives. Furthermore, in Figure 6, we show more samples of trajectory visualizations from SORT and OC-SORT on DanceTrack-val set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Results on MOT17 test set with the private detections. ByteTrack and Ours use the same detections. Results on MOT20 test set with the private detections. ByteTrack and Ours use the same detections.</figDesc><table><row><cell>Tracker</cell><cell cols="5">HOTA? MOTA? IDF1? FP(10 4 )? FN(10 4 )?</cell><cell>IDs?</cell><cell cols="3">Frag? AssA? AssR?</cell></row><row><cell>FairMOT [79]</cell><cell>59.3</cell><cell>73.7</cell><cell>72.3</cell><cell>2.75</cell><cell>11.7</cell><cell cols="2">3,303 8,073</cell><cell>58.0</cell><cell>63.6</cell></row><row><cell>TransCt [74]</cell><cell>54.5</cell><cell>73.2</cell><cell>62.2</cell><cell>2.31</cell><cell>12.4</cell><cell cols="2">4,614 9,519</cell><cell>49.7</cell><cell>54.2</cell></row><row><cell>TransTrk [60]</cell><cell>54.1</cell><cell>75.2</cell><cell>63.5</cell><cell>5.02</cell><cell>8.64</cell><cell cols="2">3,603 4,872</cell><cell>47.9</cell><cell>57.1</cell></row><row><cell>Semi-TCL [38]</cell><cell>59.8</cell><cell>73.3</cell><cell>73.2</cell><cell>2.29</cell><cell>12.5</cell><cell cols="2">2,790 8,010</cell><cell>59.4</cell><cell>64.7</cell></row><row><cell>CSTrack [39]</cell><cell>59.3</cell><cell>74.9</cell><cell>72.6</cell><cell>2.38</cell><cell>11.4</cell><cell cols="2">3,567 7,668</cell><cell>57.9</cell><cell>63.2</cell></row><row><cell>GRTU [66]</cell><cell>62.0</cell><cell>74.9</cell><cell>75.0</cell><cell>3.20</cell><cell>10.8</cell><cell cols="2">1,812 1,824</cell><cell>62.1</cell><cell>65.8</cell></row><row><cell>QDTrack [44]</cell><cell>53.9</cell><cell>68.7</cell><cell>66.3</cell><cell>2.66</cell><cell>14.66</cell><cell cols="2">3,378 8,091</cell><cell>52.7</cell><cell>57.2</cell></row><row><cell>MAA [58]</cell><cell>62.0</cell><cell>79.4</cell><cell>75.9</cell><cell>3.73</cell><cell>7.77</cell><cell cols="2">1,452 2,202</cell><cell>60.2</cell><cell>67.3</cell></row><row><cell>MOTR [77]</cell><cell>57.2</cell><cell>71.9</cell><cell>68.4</cell><cell>2.11</cell><cell>13.6</cell><cell cols="2">2,115 3,897</cell><cell>55.8</cell><cell>59.2</cell></row><row><cell>ReMOT [75]</cell><cell>59.7</cell><cell>77.0</cell><cell>72.0</cell><cell>3.32</cell><cell>9.36</cell><cell cols="2">2,853 5,304</cell><cell>57.1</cell><cell>61.7</cell></row><row><cell>PermaTr [62]</cell><cell>55.5</cell><cell>73.8</cell><cell>68.9</cell><cell>2.90</cell><cell>11.5</cell><cell cols="2">3,699 6,132</cell><cell>53.1</cell><cell>59.8</cell></row><row><cell>TransMOT [12]</cell><cell>61.7</cell><cell>76.7</cell><cell>75.1</cell><cell>3.62</cell><cell>9.32</cell><cell cols="2">2,346 7,719</cell><cell>59.9</cell><cell>66.5</cell></row><row><cell>ByteTrack [78]</cell><cell>63.1</cell><cell>80.3</cell><cell>77.3</cell><cell>2.55</cell><cell>8.37</cell><cell cols="2">2,196 2,277</cell><cell>62.0</cell><cell>68.2</cell></row><row><cell>Ours</cell><cell>63.2</cell><cell>78.0</cell><cell>77.5</cell><cell>1.51</cell><cell>10.8</cell><cell cols="2">1,950 2,040</cell><cell>63.2</cell><cell>67.5</cell></row><row><cell>Tracker</cell><cell cols="5">HOTA? MOTA? IDF1? FP(10 4 )? FN(10 4 )?</cell><cell>IDs?</cell><cell>Frag?</cell><cell cols="2">AssA? AssR?</cell></row><row><cell>FairMOT [79]</cell><cell>54.6</cell><cell>61.8</cell><cell>67.3</cell><cell>10.3</cell><cell>8.89</cell><cell>5,243</cell><cell>7,874</cell><cell>54.7</cell><cell>60.7</cell></row><row><cell>TransCt [74]</cell><cell>43.5</cell><cell>58.5</cell><cell>49.6</cell><cell>6.42</cell><cell>14.6</cell><cell>4,695</cell><cell>9,581</cell><cell>37.0</cell><cell>45.1</cell></row><row><cell>TransTrk [60]</cell><cell>48.5</cell><cell>65.0</cell><cell>59.4</cell><cell>2.72</cell><cell>15.0</cell><cell cols="2">3,608 11,352</cell><cell>45.2</cell><cell>51.9</cell></row><row><cell>Semi-TCL [38]</cell><cell>55.3</cell><cell>65.2</cell><cell>70.1</cell><cell>6.12</cell><cell>11.5</cell><cell>4,139</cell><cell>8,508</cell><cell>56.3</cell><cell>60.9</cell></row><row><cell>CSTrack [39]</cell><cell>54.0</cell><cell>66.6</cell><cell>68.6</cell><cell>2.54</cell><cell>14.4</cell><cell>3,196</cell><cell>7,632</cell><cell>54.0</cell><cell>57.6</cell></row><row><cell>GSDT [67]</cell><cell>53.6</cell><cell>67.1</cell><cell>67.5</cell><cell>3.19</cell><cell>13.5</cell><cell>3,131</cell><cell>9,875</cell><cell>52.7</cell><cell>58.5</cell></row><row><cell>RelationT [76]</cell><cell>56.5</cell><cell>67.2</cell><cell>70.5</cell><cell>6.11</cell><cell>10.5</cell><cell>4,243</cell><cell>8,236</cell><cell>55.8</cell><cell>66.1</cell></row><row><cell>MAA [58]</cell><cell>57.3</cell><cell>73.9</cell><cell>71.2</cell><cell>2.49</cell><cell>10.9</cell><cell>1,331</cell><cell>1,450</cell><cell>55.1</cell><cell>61.1</cell></row><row><cell>ReMOT [75]</cell><cell>61.2</cell><cell>77.4</cell><cell>73.1</cell><cell>2.83</cell><cell>8.67</cell><cell>1,789</cell><cell>2,121</cell><cell>58.7</cell><cell>63.1</cell></row><row><cell>TransMOT [12]</cell><cell>61.9</cell><cell>77.5</cell><cell>75.2</cell><cell>3.42</cell><cell>8.08</cell><cell>1,615</cell><cell>2,421</cell><cell>60.1</cell><cell>66.3</cell></row><row><cell>ByteTrack [78]</cell><cell>61.3</cell><cell>77.8</cell><cell>75.2</cell><cell>2.62</cell><cell>8.76</cell><cell>1,223</cell><cell>1,460</cell><cell>59.6</cell><cell>66.2</cell></row><row><cell>Ours</cell><cell>62.1</cell><cell>75.5</cell><cell>75.9</cell><cell>1.80</cell><cell>10.8</cell><cell>913</cell><cell>1,198</cell><cell>62.0</cell><cell>67.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .Table 4 .</head><label>34</label><figDesc>Results on MOT17 test set with the public detections. Results on MOT20 test set with the public detections.</figDesc><table><row><cell>Tracker</cell><cell cols="5">HOTA? MOTA? IDF1? FP(10 4 )? FN(10 4 )?</cell><cell>IDs?</cell><cell cols="3">Frag? AssA? AssR?</cell></row><row><cell>CenterTrack [80]</cell><cell>-</cell><cell>61.5</cell><cell>59.6</cell><cell>1.41</cell><cell>20.1</cell><cell>2,583</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>QDTrack [44]</cell><cell>-</cell><cell>64.6</cell><cell>65.1</cell><cell>1.41</cell><cell>18.3</cell><cell>2,652</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Lif T [26]</cell><cell>51.3</cell><cell>60.5</cell><cell>65.6</cell><cell>1.50</cell><cell>20.7</cell><cell cols="2">1,189 3,476</cell><cell>54.7</cell><cell>59.0</cell></row><row><cell>TransCt [74]</cell><cell>51.4</cell><cell>68.8</cell><cell>61.4</cell><cell>2.29</cell><cell>14.9</cell><cell cols="2">4,102 8,468</cell><cell>47.7</cell><cell>52.8</cell></row><row><cell>ApLift [27]</cell><cell>51.1</cell><cell>60.5</cell><cell>65.6</cell><cell>3.06</cell><cell>19.1</cell><cell cols="2">1,709 2,672</cell><cell>53.5</cell><cell>59.6</cell></row><row><cell>TMOH [56]</cell><cell>50.4</cell><cell>62.1</cell><cell>62.8</cell><cell>11.0</cell><cell>20.1</cell><cell cols="2">1,897 4,622</cell><cell>50.9</cell><cell>54.8</cell></row><row><cell>MPTC [57]</cell><cell>51.7</cell><cell>62.6</cell><cell>65.8</cell><cell>0.88</cell><cell>19.8</cell><cell cols="2">4,074 5,534</cell><cell>53.1</cell><cell>57.6</cell></row><row><cell>LPC MOT [13]</cell><cell>51.5</cell><cell>59.0</cell><cell>66.8</cell><cell>2.31</cell><cell>20.7</cell><cell cols="2">1,122 1,943</cell><cell>56.0</cell><cell>62.7</cell></row><row><cell>TrackFormer [41]</cell><cell>-</cell><cell>62.5</cell><cell>60.7</cell><cell>3.28</cell><cell>17.5</cell><cell>2,540</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Ours</cell><cell>52.4</cell><cell>58.2</cell><cell>65.1</cell><cell>0.44</cell><cell>23.0</cell><cell>784</cell><cell>2,006</cell><cell>57.6</cell><cell>63.5</cell></row><row><cell>Ours + Linear Interp</cell><cell>52.9</cell><cell>59.4</cell><cell>65.7</cell><cell>0.66</cell><cell>22.2</cell><cell>801</cell><cell>1,030</cell><cell>57.5</cell><cell>63.9</cell></row><row><cell>Tracker</cell><cell cols="5">HOTA? MOTA? IDF1? FP(10 4 )? FN(10 4 )?</cell><cell>IDs?</cell><cell>Frag?</cell><cell cols="2">AssA? AssR?</cell></row><row><cell>SORT20 [5]</cell><cell>36.1</cell><cell>42.7</cell><cell>45.1</cell><cell>2.75</cell><cell>26.5</cell><cell cols="2">4,470 17,798</cell><cell>35.9</cell><cell>39.4</cell></row><row><cell>MPNTrack [7]</cell><cell>46.8</cell><cell>57.6</cell><cell>59.1</cell><cell>17.0</cell><cell>20.1</cell><cell>1,210</cell><cell>1,420</cell><cell>47.3</cell><cell>52.7</cell></row><row><cell>TransCt [74]</cell><cell>43.5</cell><cell>61.0</cell><cell>49.8</cell><cell>4.92</cell><cell>14.8</cell><cell>4,493</cell><cell>8,950</cell><cell>36.1</cell><cell>44.5</cell></row><row><cell>Sp Con [65]</cell><cell>42.5</cell><cell>54.6</cell><cell>53.4</cell><cell>0.95</cell><cell>22.4</cell><cell>1,674</cell><cell>2,455</cell><cell>41.4</cell><cell>48.2</cell></row><row><cell>ApLift [27]</cell><cell>46.6</cell><cell>58.9</cell><cell>56.5</cell><cell>1.77</cell><cell>19.3</cell><cell>2,241</cell><cell>2,112</cell><cell>45.2</cell><cell>48.1</cell></row><row><cell>TMOH [56]</cell><cell>48.9</cell><cell>60.1</cell><cell>61.2</cell><cell>3.80</cell><cell>16.6</cell><cell>2,342</cell><cell>4,320</cell><cell>48.4</cell><cell>52.9</cell></row><row><cell>MPTC [57]</cell><cell>48.5</cell><cell>60.6</cell><cell>59.7</cell><cell>4.53</cell><cell>15.4</cell><cell>4,533</cell><cell>5,163</cell><cell>46.5</cell><cell>51.6</cell></row><row><cell>LPC MOT [13]</cell><cell>49.0</cell><cell>56.3</cell><cell>62.5</cell><cell>1.17</cell><cell>21.3</cell><cell>1,562</cell><cell>1,865</cell><cell>52.4</cell><cell>54.7</cell></row><row><cell>Ours</cell><cell>54.3</cell><cell>59.9</cell><cell>67.0</cell><cell>0.44</cell><cell>20.2</cell><cell>554</cell><cell>2,345</cell><cell>59.5</cell><cell>65.1</cell></row><row><cell>Ours + Linear Interp</cell><cell>55.2</cell><cell>61.7</cell><cell>67.9</cell><cell>0.57</cell><cell>19.2</cell><cell>508</cell><cell>805</cell><cell>59.8</cell><cell>65.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5 .Table 6 .</head><label>56</label><figDesc>Results on DanceTrack test set. Methods in the bottom block use the same detections. Results on KITTI test set. HP indicates adding the lost detections during initializing tracks.</figDesc><table><row><cell></cell><cell>Tracker</cell><cell></cell><cell cols="6">HOTA? DetA? AssA? MOTA? IDF1?</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">CenterTrack [80]</cell><cell>41.8</cell><cell>78.1</cell><cell></cell><cell>22.6</cell><cell>86.8</cell><cell>35.7</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">FairMOT [79]</cell><cell>39.7</cell><cell>66.7</cell><cell></cell><cell>23.8</cell><cell>82.2</cell><cell>40.8</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">QDTrack [44]</cell><cell>45.7</cell><cell>72.1</cell><cell></cell><cell>29.2</cell><cell>83.0</cell><cell>44.8</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">TransTrk [60]</cell><cell>45.5</cell><cell>75.9</cell><cell></cell><cell>27.5</cell><cell>88.4</cell><cell>45.2</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">TraDes [71]</cell><cell>43.3</cell><cell>74.5</cell><cell></cell><cell>25.4</cell><cell>86.2</cell><cell>41.2</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">MOTR [77]</cell><cell>48.4</cell><cell>71.8</cell><cell></cell><cell>32.7</cell><cell>79.2</cell><cell>46.1</cell><cell></cell><cell></cell></row><row><cell></cell><cell>SORT [5]</cell><cell></cell><cell>47.9</cell><cell>72.0</cell><cell></cell><cell>31.2</cell><cell>91.8</cell><cell>50.8</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">DeepSORT [70]</cell><cell>45.6</cell><cell>71.0</cell><cell></cell><cell>29.7</cell><cell>87.8</cell><cell>47.9</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">ByteTrack [78]</cell><cell>47.3</cell><cell>71.6</cell><cell></cell><cell>31.4</cell><cell>89.5</cell><cell>52.5</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Ours</cell><cell></cell><cell>55.1</cell><cell>80.3</cell><cell></cell><cell>38.0</cell><cell>89.4</cell><cell>54.2</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Ours + Linaer Interp</cell><cell>55.7</cell><cell>81.7</cell><cell></cell><cell>38.3</cell><cell>92.0</cell><cell>54.6</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Our method uses the</cell></row><row><cell cols="2">same detections as PermaTr [62]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Car</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Pedestrian</cell><cell></cell><cell></cell></row><row><cell>Tracker</cell><cell cols="3">HOTA? MOTA? AssA?</cell><cell>IDs?</cell><cell cols="4">Frag? HOTA? MOTA? AssA?</cell><cell>IDs?</cell><cell>Frag?</cell></row><row><cell>IMMDP [72]</cell><cell>68.66</cell><cell>82.75</cell><cell>69.76</cell><cell>211</cell><cell>201</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>AB3D [68]</cell><cell>69.99</cell><cell>83.61</cell><cell>69.33</cell><cell>113</cell><cell>206</cell><cell>37.81</cell><cell>38.13</cell><cell>44.33</cell><cell>181</cell><cell>879</cell></row><row><cell>SMAT [22]</cell><cell>71.88</cell><cell>83.64</cell><cell>72.13</cell><cell>198</cell><cell>294</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>TrackMPNN [47]</cell><cell>72.30</cell><cell>87.33</cell><cell>70.63</cell><cell>481</cell><cell>237</cell><cell>39.40</cell><cell>52.10</cell><cell>35.45</cell><cell>626</cell><cell>669</cell></row><row><cell>MPNTrack [7]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>45.26</cell><cell>46.23</cell><cell>47.28</cell><cell>397</cell><cell>1,078</cell></row><row><cell>CenterTr [80]</cell><cell>73.02</cell><cell>88.83</cell><cell>71.20</cell><cell>254</cell><cell>227</cell><cell>40.35</cell><cell>53.84</cell><cell>36.93</cell><cell>425</cell><cell>618</cell></row><row><cell>QD-3DT [28]</cell><cell>72.77</cell><cell>85.94</cell><cell>72.19</cell><cell>206</cell><cell>525</cell><cell>41.08</cell><cell>51.77</cell><cell>38.82</cell><cell>717</cell><cell>1,194</cell></row><row><cell>QDTrack [44]</cell><cell>68.45</cell><cell>84.93</cell><cell>65.49</cell><cell>313</cell><cell>567</cell><cell>41.12</cell><cell>55.55</cell><cell>38.10</cell><cell>487</cell><cell>951</cell></row><row><cell>LGM [64]</cell><cell>73.14</cell><cell>87.60</cell><cell>72.31</cell><cell>448</cell><cell>164</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Eager [33]</cell><cell>74.39</cell><cell>87.82</cell><cell>74.16</cell><cell>239</cell><cell>390</cell><cell>39.38</cell><cell>49.82</cell><cell>38.72</cell><cell>496</cell><cell>1,410</cell></row><row><cell>TuSimple [11]</cell><cell>71.55</cell><cell>86.31</cell><cell>71.11</cell><cell>292</cell><cell>220</cell><cell>45.88</cell><cell>57.61</cell><cell>47.62</cell><cell>246</cell><cell>651</cell></row><row><cell>PermaTr [62]</cell><cell>77.42</cell><cell>90.85</cell><cell>77.66</cell><cell>275</cell><cell>271</cell><cell>47.43</cell><cell>65.05</cell><cell>43.66</cell><cell>483</cell><cell>703</cell></row><row><cell>Ours</cell><cell>74.64</cell><cell>87.81</cell><cell>74.52</cell><cell>257</cell><cell>320</cell><cell>52.95</cell><cell>62.00</cell><cell>57.81</cell><cell>181</cell><cell>598</cell></row><row><cell>Ours + HP</cell><cell>76.54</cell><cell>90.28</cell><cell>76.39</cell><cell>250</cell><cell>280</cell><cell>54.69</cell><cell>65.14</cell><cell>59.08</cell><cell>204</cell><cell>609</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 7 .Table 8 .</head><label>78</label><figDesc>Ablation study on MOT17 val set and DanceTrack-val set. Ablation study on the trajectory hypothesis used in OOS.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">MOT17-val</cell><cell></cell><cell></cell><cell cols="2">DanceTrack-val</cell><cell></cell></row><row><cell cols="9">OOS OCM OCR HOTA? AssA? MOTA? IDF1? HOTA? AssA? MOTA? IDF1?</cell></row><row><cell></cell><cell>64.9</cell><cell>66.8</cell><cell>74.6</cell><cell>76.9</cell><cell>47.8</cell><cell>31.0</cell><cell>88.2</cell><cell>48.3</cell></row><row><cell></cell><cell>66.3</cell><cell>68.0</cell><cell>74.7</cell><cell>77.2</cell><cell>48.5</cell><cell>32.2</cell><cell>87.2</cell><cell>49.8</cell></row><row><cell></cell><cell>66.4</cell><cell>69.0</cell><cell>74.6</cell><cell>77.8</cell><cell>52.1</cell><cell>35.0</cell><cell>87.3</cell><cell>50.6</cell></row><row><cell></cell><cell>66.5</cell><cell>68.9</cell><cell>74.9</cell><cell>77.7</cell><cell>52.1</cell><cell>35.3</cell><cell>87.3</cell><cell>51.6</cell></row><row><cell></cell><cell></cell><cell cols="2">MOT17-val</cell><cell></cell><cell></cell><cell cols="2">DanceTrack-val</cell><cell></cell></row><row><cell></cell><cell cols="8">HOTA? AssA? MOTA? IDF1? HOTA? AssA? MOTA? IDF1?</cell></row><row><cell>Const. Speed</cell><cell>66.5</cell><cell>68.9</cell><cell>74.9</cell><cell>77.7</cell><cell>52.1</cell><cell>35.3</cell><cell>87.3</cell><cell>51.6</cell></row><row><cell>GPR</cell><cell>63.1</cell><cell>65.2</cell><cell>74.0</cell><cell>75.7</cell><cell>49.5</cell><cell>33.7</cell><cell>86.7</cell><cell>49.6</cell></row><row><cell>Linear Regression</cell><cell>64.3</cell><cell>66.5</cell><cell>74.2</cell><cell>76.0</cell><cell>49.3</cell><cell>33.4</cell><cell>86.2</cell><cell>49.2</cell></row><row><cell>Const. Acceleration</cell><cell>66.2</cell><cell>67.9</cell><cell>74.7</cell><cell>77.4</cell><cell>51.3</cell><cell>34.8</cell><cell>87.0</cell><cell>50.9</cell></row></table><note>maTr [62] and report its performance in the table as well.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 9 .</head><label>9</label><figDesc>Influence of choice of ?t for estimating direction in OCM.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">MOT17-val</cell><cell></cell><cell></cell><cell cols="2">DanceTrack-val</cell><cell></cell></row><row><cell></cell><cell cols="8">HOTA? AssA? MOTA? IDF1? HOTA? AssA? MOTA? IDF1?</cell></row><row><cell>?t = 1</cell><cell>66.1</cell><cell>67.5</cell><cell>74.9</cell><cell>76.9</cell><cell>51.3</cell><cell>34.3</cell><cell>87.1</cell><cell>51.3</cell></row><row><cell>?t = 2</cell><cell>66.3</cell><cell>68.0</cell><cell>75.0</cell><cell>77.3</cell><cell>52.2</cell><cell>35.4</cell><cell>87.2</cell><cell>51.4</cell></row><row><cell>?t = 3</cell><cell>66.5</cell><cell>68.9</cell><cell>74.9</cell><cell>77.7</cell><cell>52.1</cell><cell>35.3</cell><cell>87.3</cell><cell>51.6</cell></row><row><cell>?t = 6</cell><cell>66.0</cell><cell>67.5</cell><cell>74.6</cell><cell>76.9</cell><cell>52.1</cell><cell>35.4</cell><cell>87.4</cell><cell>51.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 12 .</head><label>12</label><figDesc>Results on CroHD Head Tracking dataset</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 13 .</head><label>13</label><figDesc>to generate new tracks. Tracker HOTA? MOTA? IDF1? FP(10 4 )? FN(10 4 )? Results on DanceTrack test set. "Ours (MOT17)" uses the YOLOX detector trained on MOT17-training set.</figDesc><table><row><cell>IDs?</cell><cell>Frag?</cell></row></table><note>l = L ? and l = 1000/L ? , and the value output by Median Trick (MT)</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://motchallenge.net/results/Head Tracking 21/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgement</head><p>We thank Yuda Song for his generous help to improve the mathematical analysis and the writing quality. We thank Yifu Zhang for providing the code of ByteTrack. We also appreciate Rohan Choudhury for proofreading.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Algorithm 1: Pseudo-code of OCSORT.</p><p>Input: Detections Z = {z i k |1 ? k ? T, 1 ? i ? N k }; Kalman Filter KF; threshold to remove untracked tracks t expire Output: The set of tracks T = {? i } 1 Initialization: T ? ? and KF; 2 for timestep t ? 1 : T do / * Step 1: match track prediction with observations * / </p><p>Linear assignment by Hungarians with cost C remain   <ref type="figure">Figure 5</ref>. More samples where SORT suffers from the fragmentation and ID switch of tracks from occlusion or non-linear motion but OC-SORT survives. To be precise, the issue happens on the objects by SORT at: (a) #322 ? #324; (c) ID switch between #672 and #673, later #673 being lost; (e) #760 ? #761; (g) #871 ? #872; (i) #1063 ? #1090, then ID switch with #1081; (k) #1295 ? #1309. We select samples from diverse scenes, including street dance, classic dance and gymnastics. Best viewed in color and zoom in. We also provide the corresponding video segments at the https: //github.com/noahcao/OC_SORT .  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Optimal filtering. Courier Corporation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">O</forename><surname>Brian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John B</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The probabilistic data association filter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaakov</forename><surname>Bar-Shalom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Daum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Control Systems Magazine</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="82" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Motion regularization for model-based head tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irfan</forename><surname>Essa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 13th International Conference on Pattern Recognition</title>
		<meeting>13th International Conference on Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Tracking without bells and whistles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Meinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taixe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="941" to="951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Simple online and realtime tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongyuan</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lionel</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Upcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE international conference on image processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3464" to="3468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Factorization methods for discrete sequential estimation. Courier Corporation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bierman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning a neural solver for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Bras?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taix?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="6247" to="6257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cross-domain adaptation for animal pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinkun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Hao-Shu Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Argoverse: 3d tracking and forecasting with rich maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Fang</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patsorn</forename><surname>Sangkloy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jagjeet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slawomir</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Hartnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Training and testing lowdegree polynomial data mappings via linear svm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin-Wen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Near-online multi-target tracking with aggregated local flow descriptor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3029" to="3037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Transmot: Spatial-temporal graph transformer for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanzeng</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.00194</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning a proposal classifier for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renliang</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangping</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2443" to="2452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Dendorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.09003</idno>
		<title level="m">Mot20: A benchmark for multi object tracking in crowded scenes</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Automatic model construction with Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">15</biblScope>
		</imprint>
		<respStmt>
			<orgName>University of Cambridge</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pairwise body-part attention for recognizing human-object interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinkun</forename><surname>Hao-Shu Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The optimum linear smoother as a combination of two optimum linear filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on automatic control</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hough forests for object detection, tracking, and action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Large sample analysis of the median heuristic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Garreau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wittawat</forename><surname>Jitkrittum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Motonobu</forename><surname>Kanagawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07269</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songtao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yolox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.08430</idno>
		<title level="m">Exceeding yolo series in 2021</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Vision meets robotics: The kitti dataset. The International</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Smat: Smart multiple affinity metrics for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><forename type="middle">Franco</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andres</forename><surname>Ospina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Calvez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image Analysis and Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="48" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Particle filters for positioning, navigation, and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fredrik</forename><surname>Gustafsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fredrik</forename><surname>Gunnarsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niclas</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urban</forename><surname>Forssell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Jansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rickard</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P-J</forename><surname>Nordlund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on signal processing</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="425" to="437" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On the ratio of two correlated normal random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinkley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Lifted disjoint paths with application in multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Hornakova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Swoboda</surname></persName>
		</author>
		<idno>PMLR, 2020. 7</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="4364" to="4375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Making higher order mot scalable: An efficient approximate solver for lifted disjoint paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Hornakova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Swoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Rolinek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Henschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6330" to="6340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hou-Ning</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yung-Hsu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.07351</idno>
		<title level="m">Monocular quasi-dense 3d object tracking</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Stochastic processes and filtering theory. Courier Corporation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jazwinski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">In Signal processing, sensor fusion, and target recognition VI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Julier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeffrey K Uhlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">3068</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note>New extension of the kalman filter to nonlinear systems</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unscented filtering and nonlinear estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Julier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeffrey K Uhlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Contributions to the theory of optimal control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolf</forename><forename type="middle">Emil</forename><surname>Kalman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bol. soc. mat. mexicana</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Eagermot: 3d multi-object tracking via sensor fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljo?a</forename><surname>O?ep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taix?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="11315" to="11321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Activity forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">Andrew</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Gp-bayesfilters: Bayesian filtering using gaussian process prediction and observation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autonomous Robots</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Human trajectory forecasting in crowds: A deep learning perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parth</forename><surname>Kothari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Kreiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Theory of point estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Erich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Casella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingze</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.02396</idno>
		<title level="m">Semi-tcl: Semi-supervised track contrastive representation learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Rethinking the competition between detection and reid in multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyong</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiao</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12138</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Hota: A higher order metric for evaluating multiobject tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Luiten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljosa</forename><surname>Osep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Dendorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="548" to="578" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Trackformer: Multi-object tracking with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Meinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taixe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.02702</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dynamics based 3d skeletal hand tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Melax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Keselman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sterling</forename><surname>Orsten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</title>
		<meeting>the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="184" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Schindler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.00831</idno>
		<title level="m">Mot16: A benchmark for multi-object tracking</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Quasi-dense similarity learning for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlu</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haofeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="164" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Detecting heads using feature refine net and cascaded multi-scale architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dezhi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zikai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zirong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zirui</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lele</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianwen</forename><surname>Jin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.09256</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">An introduction to hidden markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biinghwang</forename><surname>Juang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="4" to="16" />
		</imprint>
	</monogr>
	<note>ieee assp magazine</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Trackmpnn: A message passing graph neural architecture for multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Rangesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Maheshwari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mez</forename><surname>Gebre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhesh</forename><surname>Mhatre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vahid</forename><surname>Ramezani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan M</forename><surname>Trivedi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.04206</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Maximum likelihood estimates of linear dynamic systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Herbert E Rauch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charlotte</forename><forename type="middle">T</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Striebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIAA journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santosh</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">An introduction to gaussian processes for the kalman filter expert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Reece</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th International Conference on Information Fusion</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Generalized intersection over union: A metric and a loss for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Accurate, robust, and flexible real-time hand tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toby</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cem</forename><surname>Keskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duncan</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Leichter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Vinnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd annual ACM conference on human factors in computing systems</title>
		<meeting>the 33rd annual ACM conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Application of statistical filter theory to the optimal estimation of position and velocity on board a circumlunar vehicle. National Aeronautics and Space Administration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard A</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcgee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Improving multiple pedestrian tracking by track management and occlusion handling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Beyerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10958" to="10967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Multi-pedestrian tracking with clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Beyerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 17th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Modelling ambiguous assignments for multi-person tracking in crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Beyerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Dancetrack: Multi-object tracking in uniform appearance and diverse motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinkun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.14690</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinkun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rufeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Transtrack</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15460</idno>
		<title level="m">Multiple object tracking with transformer</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Tracking pedestrian heads in dense crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramana</forename><surname>Sundararaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cedric De Almeida</forename><surname>Braga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Pettre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Learning to track with object permanence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Tokmakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfram</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Attention is all you need. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Track without appearance: Learn box and tracklet embedding with local and global motion patterns for vehicle tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaoang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renshu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuozhu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingli</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenq-Neng</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9876" to="9886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Split and connect: A universal tracklet booster for multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaoang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renshu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeng-Neng</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A general recurrent tracking framework without real data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13219" to="13228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Joint object detection and multi-object tracking with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinshuo</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13708" to="13715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">3d multi-object tracking: A baseline and new evaluation metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinshuo</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianren</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Kitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10359" to="10366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Gaussian processes for regression. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Rasmussen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Simple online and realtime tracking with a deep association metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolai</forename><surname>Wojke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietrich</forename><surname>Paulus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE international conference on image processing (ICIP)</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Track to detect and segment: An online multi-object tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiale</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangchen</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="12352" to="12361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Learning to track: Online multi-object tracking by decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4705" to="4713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliang</forename><surname>Xiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiefeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghong</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.00977</idno>
		<title level="m">Pose flow: Efficient online pose tracking</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Ban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Delorme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Rus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier Alameda-Pineda</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2103.15145</idno>
		<title level="m">Transcenter: Transformers with dense queries for multiple-object tracking</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Remot: A model-agnostic refinement for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sakriani</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Relationtrack: Relation-aware multiple object tracking with decoupled representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">En</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoling</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoudong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.04322</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Motr: End-to-end multiple-object tracking with transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangao</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiancai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.03247</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Bytetrack: Multi-object tracking by associating every detection box</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.06864</idno>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Fairmot: On the fairness of detection and re-identification in multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Tracking objects as points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07850</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Objects as points. arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
