<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Tapas Nayak, Navonil Majumder, and Soujanya Poria. 2021. Aspect Sentiment Triplet Extraction Using Reinforcement Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>ACM</publisher>
				<availability status="unknown"><p>Copyright ACM</p>
				</availability>
				<date>November 1-5, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samson</forename><forename type="middle">Yu</forename><surname>Bai</surname></persName>
							<email>samson_yu@sutd.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="institution">IIT KGP</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Singapore</roleName><forename type="first">Jian</forename><surname>Sutd</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IIT KGP</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapas</forename><surname>Nayak</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">SUTD</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
							<email>navonil_majumder@sutd.edu.sg</email>
							<affiliation key="aff2">
								<orgName type="department">Soujanya Poria SUTD</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Tapas Nayak, Navonil Majumder, and Soujanya Poria. 2021. Aspect Sentiment Triplet Extraction Using Reinforcement Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 30th ACM Int&apos;l Conf. on Information and Knowledge Management (CIKM &apos;21)</title>
						<meeting>the 30th ACM Int&apos;l Conf. on Information and Knowledge Management (CIKM &apos;21)						</meeting>
						<imprint>
							<publisher>ACM</publisher>
							<date type="published">November 1-5, 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/XXXXXX.XXXXXX</idno>
					<note>New York, NY, USA, 5 pages. https://</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting triplets of aspect terms, their associated sentiments, and the opinion terms that provide evidence for the expressed sentiments. Previous approaches to ASTE usually simultaneously extract all three components or first identify the aspect and opinion terms, then pair them up to predict their sentiment polarities. In this work, we present a novel paradigm, ASTE-RL, by regarding the aspect and opinion terms as arguments of the expressed sentiment in a hierarchical reinforcement learning (RL) framework. We first focus on sentiments expressed in a sentence, then identify the target aspect and opinion terms for that sentiment. This takes into account the mutual interactions among the triplet's components while improving exploration and sample efficiency. Furthermore, this hierarchical RL setup enables us to deal with multiple and overlapping triplets. In our experiments, we evaluate our model on existing datasets from laptop and restaurant domains and show that it achieves state-ofthe-art performance. The implementation of this work is publicly available at https://github.com/declare-lab/ASTE-RL.</p><p>We divide our framework ASTE-RL into three components: 1) aspect-oriented sentiment classification, 2) opinion term extraction and 3) aspect term extraction. For the sentiment classification component, the sentiment is expressed towards the aspect term, and has four possible labels:</p><p>= {none, positive, negative, neutral}. Our opinion and aspect extraction components are sequence labeling models with a BIO tagging scheme <ref type="bibr" target="#b16">[17]</ref>. With this BIO</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Aspect-based sentiment analysis (ABSA) or target-based sentiment analysis (TBSA) is an important research area in natural language processing (NLP) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15]</ref>. It consists of various fine-grained sentiment analysis tasks <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>, with the three most fundamental being aspect/target term extraction, opinion term extraction and aspect/target term sentiment classification. Aspect Sentiment Triplet Extraction (ASTE) is a relatively new subtask of ABSA introduced by Li et al. <ref type="bibr" target="#b8">[9]</ref>, Peng et al. <ref type="bibr" target="#b13">[14]</ref>. In ASTE, the task is to extract triplets containing aspect terms, their associated sentiment polarities, and the opinion terms that express those sentiments. A sentence may contain multiple such triplets where the aspect terms or opinion Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CIKM '21, November 1-5, 2021, Virtual Event, Australia. ? 2021 Association for Computing Machinery. ACM ISBN 978-1-4503-8446-9/21/11. . . $15.00 https://doi.org/10.1145/XXXXXX.XXXXXX terms across triplets may overlap with each other. We include an example of such triplets in <ref type="table" target="#tab_0">Table 1</ref>. Existing methods, such as, CMLA+ <ref type="bibr" target="#b21">[22]</ref>, RINANTE+ <ref type="bibr" target="#b1">[2]</ref>, Liunified-R <ref type="bibr" target="#b8">[9]</ref>, WhatHowWhy <ref type="bibr" target="#b13">[14]</ref>, OTE-MTL <ref type="bibr" target="#b26">[27]</ref>, GTS <ref type="bibr" target="#b24">[25]</ref>, JET <ref type="bibr" target="#b25">[26]</ref>, TOP <ref type="bibr" target="#b5">[6]</ref> and BMRC <ref type="bibr" target="#b0">[1]</ref> are mainly divided into simultaneous and sequential methods. Early works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref> usually employ a two-staged approach where they simultaneously extract aspect terms with sentiments and opinion terms. These triplets are subsequently decoded through triplet classification or pairwise matching. Recent works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6]</ref> have shifted towards a more multistage, restrictive and sequential process during the extraction stage that can potentially capture more mutual dependencies and correlations among the triplet's components while forgoing the triplet decoding stage.</p><p>In this work, we tackle the ASTE task using a novel paradigm ASTE-RL where we consider the aspect and opinion terms as arguments of the sentiments expressed in a sentence. Previous approaches usually simultaneously extract all three components or first identify the aspect and opinion terms, then pair them up to predict their sentiment polarities. Unlike previous approaches, we propose a hierarchical reinforcement learning (RL) framework <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b20">21]</ref> where we first consider the sentiment polarities, then identify their associated opinion and aspect terms using separate RL processes. This process is repeated to extract all triplets present in a sentence. With this hierarchical RL setup, the model handle multiple triplets and overlapping triplets, and model interactions between the three components effectively. Inspired by the recent success of the multi-turn machine reading comprehension (MRC) framework <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10]</ref>, we incorporate ideas to further improve mutual interactions. scheme, we have three different labels to tag an input sequence for the opinion/aspect terms: , = {B, I, O}. For a given sentence = { 1 , 2 , ..., } with tokens, ASTE-RL aims to output a set of labels {( , , ) | | } where | | is the number of labels, = { 1 , 2 , ..., } represents the tagging labels for the opinion term in a predicted triplet, = { 1 , 2 , ..., } represents the tagging labels for the aspect term, and = { } represents the sentiment polarity.</p><p>The three components are structured in a two-level hierarchy <ref type="bibr" target="#b20">[21]</ref>. In the higher level, we have the sentiment indicator. During the sequential scan of a sentence, an agent will decide at each position in a sentence at the token if it has gathered sufficient information to mark the position as indicative of a sentiment that is expressed towards an aspect term. If not, the agent will mark it as none. Otherwise, it will mark it as either positive, negative or neutral. In the latter case, the agent launches two subtasks in the lower level for the opinion and aspect extractions to identify the terms as arguments of the sentiment and engages in sequence labeling. Upon completion, the agent will return to the high-level sentiment indication process and continue the sequential scan of the sentence. This process is well-suited to be formulated as a semi-Markov decision process <ref type="bibr" target="#b19">[20]</ref>: 1) a high-level RL process that detects a sentiment indicator in a sentence; 2) two low-level RL processes that identify the opinion and aspect terms separately for the corresponding sentiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Aspect-Oriented Sentiment Classification with High-Level RL</head><p>The high-level RL policy aims to detect the aspect-oriented sentiments in a sentence. This can be seen as a RL policy over options, where options are high-level actions <ref type="bibr" target="#b19">[20]</ref>.</p><p>Option: The option o is selected from = {none, positive, negative, neutral} where none indicates no sentiment indicated towards any aspect term.</p><p>State: The state s at each time step is represented by: 1) the current hidden state h , 2) the current part-of-speech (POS) tag p , 3) the sentiment polarity vector v , and 4) the high-level state for the previous time step s ?1 . To obtain p for each token in a sentence, we pass the sentence into the spaCy (https://spacy.io/) POS tagger. The sentiment polarity vector v is the embedding of the latest option o ? where o ? ? none. Both the POS tag and sentiment embeddings are learned parameters in the model. Hence, the state s is formally represented by:</p><formula xml:id="formula_0">s = (W [h ; p ; v ; s ?1 ]),<label>(1)</label></formula><p>where (?) is a non-linear function implemented by a MLP. The hidden state h is obtained from a pre-trained BERT model <ref type="bibr" target="#b2">[3]</ref> with Whole Word Masking and fine-tuned on the SQuAD v1.1 training set <ref type="bibr" target="#b15">[16]</ref>. Specifically, we first combine the query "Which tokens indicate sentiments relating pairs of aspect spans and opinion spans?" and the review sentence into the BERT tokenizer to get a final input = {[ ], 1 , ..., | | , [ ], 1 , 2 , ..., }. We then pass this input into the BERT model, and h represents the output vector from the BERT model that corresponds to the token . The initial state s 0 is initialized as: s 0 = 0.</p><p>Policy: The stochastic policy for sentiment detection specifies a probability distribution over the options:</p><formula xml:id="formula_1">o ? (o |s ) = (W s ).<label>(2)</label></formula><p>Reward: At every time step, when o is executed, the intermediate reward r provided by the environment follows this:</p><formula xml:id="formula_2">r = ? ? ? ? ? ? ? ? ? 1, if o t in 0, if o t = none ?1, if o t not in .<label>(3)</label></formula><p>If a sentiment that is expressed towards an aspect term is detected at a time step (i.e. o ? none), the agent will launch two subtasks as low-level RL processes. When the subtasks are completed, the agent will return to the high-level RL process. Otherwise, the agent continues its sequential scan of until the last option o about the last word of is sampled. When all options are sampled (i.e. at the end of the combined hierarchical RL process), there is a final reward r for the high-level process: r = 1 ( ) where 1 is the harmonic mean of the precision and recall in terms of the sentiment(s) in a sentence .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Opinion and Aspect Extractions with</head><p>Low-Level RL Every time the high-level policy detects an aspect-oriented sentiment, two low-level policies , will extract the corresponding opinion and aspect terms respectively and separately for the sentiment. In this subsection, we will generalize the RL elements such that they apply for both low-level RL processes, unless otherwise stated.</p><p>Action: The action at every time step is to assign a tag to the current word. The action a is selected from , = {B, I, O}, following a BIO tagging scheme. The B/I symbols represent the beginning and inside of an opinion/aspect term respectively, while the O symbol represents the unmarked label.</p><p>State: Similar to the high-level policy, the state s at each time step is represented by: 1) the current hidden state h , 2) the current POS tag p , 3) the opinion/aspect tag vector v , , 4) the low-level state for the previous time step s ?1 . To enhance the interactions between the sentiment and its associated opinion/aspect terms, we add a context vector v ? to the state s at each time step , using the sentiment state representation assigned to the latest option o ? :</p><formula xml:id="formula_3">v ? = (W ? s ? ).<label>(4)</label></formula><p>We also add the output vector from the BERT model for the <ref type="bibr">[CLS]</ref> token, while computing the output vectors for the hidden states. Hence, the state s is formally represented by:</p><formula xml:id="formula_4">s = (W [h ; p ; v , ; s ?1 ; v ? ; h ]).<label>(5)</label></formula><p>Note that the representations used to compute the first low-level states for the opinion and aspect extractions are different. The representation used to compute the first low-level state for opinion term extraction s , 1 is initialized using s ? as: s , 0 = (W 0 s ? ). The representation used to compute the first low-level state for aspect term extraction s , 1 is initialized using s , as: s , 0 = s , . These initializations help us capture interactions between the triplet's components. (?) is a non-linear function implemented by a MLP, while (?) and (?) are linear functions that are implemented by a single linear layer. The hidden state h is obtained in the same way as in the high-level RL process. However, the queries are changed. The query is "What is the opinion span for the o ? sentiment indicated at ? ?" for opinion term extraction and "What is the aspect span for the o ? sentiment indicated at ? ?" for aspect term extraction.</p><p>Policy: The stochastic policy for opinion/aspect extraction specifies a probability distribution over the actions given the lowlevel state s and the high-level option o ? that launches the current subtask:</p><formula xml:id="formula_5">a ? (a |s ; o ? ) = (W [o ? ]s ).<label>(6)</label></formula><p>Reward: At every time step, when a is executed, the intermediate reward is computed as the prediction error over the gold labels:</p><formula xml:id="formula_6">= ,</formula><p>if tag is predicted correctly ?0.5, otherwise,</p><p>where ? 0 and depends on the aspect/opinion tag type. This enables the model to learn a policy that emphasizes the prediction of B and I tags and avoids only predicting O tags in a trivial manner. When all actions are sampled, there is a final reward for the low-level processes, represented by:</p><formula xml:id="formula_8">= 1,</formula><p>if all tags are predicted correctly ?1, otherwise.</p><p>There will also be negative rewards in the cases where the lowlevel processes produce impossible predictions, namely cases where there are no or more than one B tag present, and no or more than one opinion/aspect term identified for each predicted triplet. Note that the low-level rewards are non-zero only in the case where the option o ? from the high-level process is correctly predicted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Hierarchical Policy Learning</head><p>We learn the high-level policy by maximizing the expected total reward at each time step as the agent samples trajectories following the high-level policies . Likewise, we learn the low-level policies by maximizing the expected total reward at each time step as the agent samples trajectories following the low-level policies , . We then optimize all policies using policy gradient methods <ref type="bibr" target="#b18">[19]</ref> with the REINFORCE algorithm <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b22">23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Training Procedure</head><p>We pre-train our ASTE-RL models for 40 epochs with a learning rate of 2e-5. During pre-training, we give our model the ground-truth options or actions at every time step to limit the exploration of the agent due to the high-dimensional state space in our setup. This prevents the agent from exploring too many unreasonable cases, e.g. an I tag preceding a B tag, and learning too slowly. We then fine-tune the best model (chosen based on the Dev 1 score) with RL policy for 15 epochs with a learning rate of 5e-6. We sample 5 trajectories for each data point during RL fine-tuning. We initialize the BERT parameters from pre-trained weights <ref type="bibr" target="#b2">[3]</ref> and update them during training for this task. We set the dimension of sentiment polarity and opinion/aspect tag embeddings at 300. For POS embeddings, we set the dimension at 25. We randomly initialize these embeddings and update them during training. We set the state vector dimension for s and s at 300. We apply dropout <ref type="bibr" target="#b17">[18]</ref> after the non-linear activations in (?) and (?) during training and set the dropout rate at 0.5. We train our models in mini-batches of size 16 and optimize the model parameters using the Adam optimizer <ref type="bibr" target="#b6">[7]</ref>. We use the ASTE-Data-V2 dataset 1 curated by Xu et al. <ref type="bibr" target="#b25">[26]</ref> to show the effectiveness of ASTE-RL in two different domains of English reviews, namely the laptop and restaurant domains. 14Rest, 15Rest, 16Rest are the datasets of the restaurant domain and 14Lap is of the laptop domain. We include the statistics of the four datasets in ASTE-Data-V2 in <ref type="table" target="#tab_1">Table 2</ref>, where #sentence represents the number of sentences, and #positive, #negative, and #neutral represent the numbers of triplets with positive, negative, and neutral sentiment polarities respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS AND ANALYSIS 3.1 Datasets &amp; Evaluation Metrics</head><p>We process the sentences with BERT's WordPiece tokenizer <ref type="bibr" target="#b23">[24]</ref> to make them work for ASTE-RL. Since the WordPiece tokenization may break down the tokens in the original dataset into subwords, we need to align the opinion/aspect term annotations and our BIO tagging scheme. We tag every token that corresponds to the opinion/aspect term tokens in the original annotations with I, except for the first token, which we tag with B.</p><p>We follow the evaluation metrics of Xu et al. <ref type="bibr" target="#b25">[26]</ref> for our experiments. An extracted triplet is correct if the entire aspect term, opinion term, and sentiment polarity match with a ground-truth triplet. We report precision, recall and F 1 score based on this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baselines</head><p>We compare the performance of ASTE-RL against the following baselines: (i) WhatHowWhy: Peng et al. <ref type="bibr" target="#b13">[14]</ref> proposed a multilayer LSTM neural architecture for co-extraction of aspect terms with sentiments, and opinion terms, with a Graph Convolutional Network <ref type="bibr" target="#b7">[8]</ref> component to capture dependency information to enhance the co-extraction. (ii) OTE-MTL: Zhang et al. <ref type="bibr" target="#b26">[27]</ref> proposed a multi-task learning framework to jointly extract aspect and opinion terms while parsing word-level sentiment dependencies, before conducting a triplet decoding process. We use results from Huang et al. <ref type="bibr" target="#b5">[6]</ref> for OTE-MTL's performance on ASTE-Data-V2. (iii) GTS: Wu et al. <ref type="bibr" target="#b24">[25]</ref> proposed an end-to-end grid tagging framework and a grid inference strategy to exploit mutual indication between opinion factors. We use results from Huang et al. <ref type="bibr" target="#b5">[6]</ref> for GTS' performance on ASTE-Data-V2, and report them for two variants: bidirectional LSTM (BiLSTM) and BERT. (iv) JET: Xu et al. <ref type="bibr" target="#b25">[26]</ref> proposed a position-aware tagging scheme for triplet extraction. They encode information about sentiment polarities and distances between the start position of aspect term and the opinion term's start and end positions (JET ) or vice versa (JET ). We report the results for two variants: BiLSTM and BERT. (v) TOP:</p><p>Huang et al. <ref type="bibr" target="#b5">[6]</ref> proposed a two-stage method to enhance correlations between aspect and opinion terms. Aspect and opinion terms are first extracted with sequence labeling, and artificial tags are added to each pair to establish correlation. A sentiment polarity is then identified for each pair using the resulting representations. (vi) BMRC: Chen et al. <ref type="bibr" target="#b0">[1]</ref> proposed a transformation of the ASTE task into a multi-turn MRC task and a bidirectional MRC framework to address it. They use non-restrictive, restrictive and sentiment classification queries in a three-turn process to extract triplets. We train and test BMRC on ASTE-Data-V2 over 5 runs with different random seeds. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experimental Results</head><p>The experimental results are shown in <ref type="table" target="#tab_2">Table 3</ref>. We observe that BERT-based models (their results are in the row above ASTE-RL's results in <ref type="table" target="#tab_2">Table 3</ref>) generally perform better than the non-BERT models. Hence, we only experiment with BERT for our ASTE-RL model. We select our best model for each dataset based on its Dev 1 score. For reproducibility, we report the testing results averaged over 5 runs with different random seeds. ASTE-RL outperforms existing baselines on all four datasets, and significantly outperforms existing baselines on the 15Rest dataset. When compared to the second-best performance for each dataset, we observe an average improvement of 1.68% 1 score across all four datasets, and an improvement of 3.93% on 15Rest. We also observe that our model strikes a balance between the TOP and BMRC models in terms of precision and recall, and hypothesize that this balance can be flexibly shifted depending on to fit dataset requirements, if we generalize r = ( ), where ( ) is the weighted harmonic mean of precision and recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Effect of RL Fine-tuning</head><p>In <ref type="table" target="#tab_2">Table 3</ref>, we report our results for ASTE-RL without the RL fine tuning step. In this setting, we pre-train our ASTE-RL for 40 epochs as usual and after that we run for another 15 epochs with a learning rate of 5e-6 (as used in RL fine-tuning step). As compared to the RL fine-tuning setting with multinomial sampling, this setting has lower 1 scores with an average decrease of 0.51% over 5 runs with different random seeds. In this setting, our model achieves slightly higher recall, but precision is significantly lower across all four datasets. This might be because multinomial sampling encourages more exploration after the initial pre-training of 40 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Analysis on Multiple &amp; Overlapping Triplet Extraction</head><p>We show the results of ASTE-RL and BMRC in complex situations where there are multiple and overlapping triplets in a sentence in <ref type="table">Table 4</ref>. For the multiple triplet scenario, we observe that there is a performance increase for 14Rest, 15Rest and 16Rest and a decrease for 14Lap as compared to the case where only one triplet is present in a sentence. For the overlapping triplet scenario, we observe a performance increase for for 15Rest and a decrease for 14Lap, 14Rest and 16Rest.</p><p>In general, we observe that ASTE-RL can handle multiple and overlapping triplets in a sentence consistently well due to its hierarchical RL setup, as compared to BMRC. There is a total 1 decrease of 4.76% for multiple triplet extraction for ASTE-RL across all four datasets as compared to 16.21% for BMRC, and a total 1 decrease for overlapping triplet extraction of 16.16% for ASTE-RL as compared to 34.38% for BMRC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>In this work, we propose a novel ASTE-RL model based on hierarchical reinforcement learning (RL) paradigm for aspect sentiment triplet extraction (ASTE). In this paradigm, we treat the aspect and opinion terms as arguments of the sentiment polarities. We decompose the ASTE task into a hierarchy of three subtasks: high-level sentiment polarity extraction, and low-level opinion and aspect term extractions. This approach is good at modeling the interactions between the three tasks and handling multiple and overlapping triplets. We incorporate the multi-turn MRC elements in our model to further improve these interactions. Our proposed model achieves state-of-the-art performance on four challenging datasets for the ASTE task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>An Example of ASTE Triplets Present in a Sentence</figDesc><table><row><cell>Sentence</cell><cell>Appetizers are excellent ; you can make a great ( but slightly expensive ) meal out of them .</cell></row><row><cell></cell><cell>[Aspect ; Opinion ; Sentiment]</cell></row><row><cell>Triplets</cell><cell>(1) Appetizer ; excellent ; positive (2) meal ; great ; positive</cell></row><row><cell></cell><cell>(3) meal ; slightly expensive ; negative</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>ASTE-Data-V2 Dataset Statistics</figDesc><table><row><cell></cell><cell></cell><cell>14Lap</cell><cell></cell><cell></cell><cell>14Rest</cell><cell></cell><cell></cell><cell>15Rest</cell><cell></cell><cell></cell><cell>16Rest</cell><cell></cell></row><row><cell></cell><cell cols="12">Train Dev Test Train Dev Test Train Dev Test Train Dev Test</cell></row><row><cell>#sentence</cell><cell>906</cell><cell cols="5">219 328 1266 310 492</cell><cell>605</cell><cell cols="2">148 322</cell><cell>857</cell><cell cols="2">210 326</cell></row><row><cell>#positive</cell><cell>817</cell><cell cols="5">169 364 1692 404 773</cell><cell>783</cell><cell cols="5">185 317 1015 252 407</cell></row><row><cell>#negative</cell><cell>517</cell><cell cols="2">141 116</cell><cell>480</cell><cell cols="2">119 155</cell><cell>205</cell><cell>53</cell><cell>143</cell><cell>329</cell><cell>76</cell><cell>78</cell></row><row><cell>#neutral</cell><cell>126</cell><cell>36</cell><cell>63</cell><cell>166</cell><cell>54</cell><cell>66</cell><cell>25</cell><cell>11</cell><cell>25</cell><cell>50</cell><cell>11</cell><cell>29</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results of ASTE-RL and Previous Methods on the ASTE-Data-V2 Dataset</figDesc><table><row><cell></cell><cell></cell><cell cols="2">14Lap</cell><cell></cell><cell></cell><cell cols="2">14Rest</cell><cell></cell><cell></cell><cell cols="2">15Rest</cell><cell></cell><cell>16Rest</cell></row><row><cell>Model</cell><cell cols="2">Dev 1 Prec</cell><cell>Rec</cell><cell>1</cell><cell cols="2">Dev 1 Prec</cell><cell>Rec</cell><cell>1</cell><cell cols="2">Dev 1 Prec</cell><cell>Rec</cell><cell>1</cell><cell>Dev 1 Prec</cell><cell>Rec</cell><cell>1</cell></row><row><cell>WhatHowWhy [14]</cell><cell>-</cell><cell cols="3">37.38 50.38 42.87</cell><cell>-</cell><cell cols="3">43.24 63.66 51.46</cell><cell>-</cell><cell cols="3">48.07 57.51 52.32</cell><cell>-</cell><cell>46.96 64.24 54.21</cell></row><row><cell>OTE-MTL [27]</cell><cell>-</cell><cell cols="3">54.26 41.07 46.75</cell><cell>-</cell><cell cols="3">63.07 58.25 60.56</cell><cell>-</cell><cell cols="3">60.88 42.68 50.18</cell><cell>-</cell><cell>65.65 54.28 59.42</cell></row><row><cell>GTSBiLSTM [25]</cell><cell>-</cell><cell cols="3">58.02 40.11 47.43</cell><cell>-</cell><cell cols="3">71.41 53.00 60.84</cell><cell>-</cell><cell cols="3">64.57 44.33 52.57</cell><cell>-</cell><cell>70.17 55.95 62.26</cell></row><row><cell>JET BiLSTM [26]</cell><cell>48.26</cell><cell cols="3">54.84 34.44 42.31</cell><cell>53.14</cell><cell cols="3">66.76 49.09 56.58</cell><cell>55.06</cell><cell cols="3">59.77 42.27 49.52</cell><cell>58.45</cell><cell>63.59 50.97 56.59</cell></row><row><cell>JET BiLSTM [26]</cell><cell>45.83</cell><cell cols="3">55.98 35.36 43.34</cell><cell>53.54</cell><cell cols="3">61.50 55.13 58.14</cell><cell>60.97</cell><cell cols="3">64.37 44.33 52.50</cell><cell>60.90</cell><cell>70.94 57.00 63.21</cell></row><row><cell>GTSBERT [25]</cell><cell>-</cell><cell cols="3">57.12 53.42 55.21</cell><cell>-</cell><cell cols="3">71.76 59.09 64.81</cell><cell>-</cell><cell cols="3">54.71 55.05 54.88</cell><cell>-</cell><cell>65.89 66.27 66.08</cell></row><row><cell>JET BERT [26]</cell><cell>50.40</cell><cell cols="3">53.53 43.28 47.86</cell><cell>56.00</cell><cell cols="3">63.44 54.12 58.41</cell><cell>59.86</cell><cell cols="3">68.20 42.89 52.66</cell><cell>60.67</cell><cell>65.28 51.95 57.85</cell></row><row><cell>JET BERT [26]</cell><cell>48.84</cell><cell cols="3">55.39 47.33 51.04</cell><cell>56.89</cell><cell cols="3">70.56 55.94 62.40</cell><cell>64.78</cell><cell cols="3">64.45 51.96 57.53</cell><cell>63.75</cell><cell>70.42 58.37 63.83</cell></row><row><cell>TOP [6]</cell><cell>-</cell><cell cols="3">57.84 59.33 58.58</cell><cell>-</cell><cell cols="3">63.59 73.44 68.16</cell><cell>-</cell><cell cols="3">54.53 63.30 58.59</cell><cell>-</cell><cell>63.57 71.98 67.52</cell></row><row><cell>BMRC [1]</cell><cell>56.08</cell><cell cols="3">65.91 52.15 58.18</cell><cell>62.83</cell><cell cols="3">72.17 65.43 68.64</cell><cell>72.47</cell><cell cols="3">62.48 55.55 58.79</cell><cell>70.91</cell><cell>69.87 65.68 67.35</cell></row><row><cell>ASTE-RL</cell><cell>58.14</cell><cell cols="3">64.80 54.99 59.50</cell><cell>64.40</cell><cell cols="3">70.60 68.65 69.61</cell><cell>74.01</cell><cell cols="3">65.45 60.29 62.72</cell><cell>72.11</cell><cell>67.21 69.69 68.41</cell></row><row><cell>-Pre-training only</cell><cell>57.35</cell><cell cols="3">62.00 55.84 58.73</cell><cell>64.50</cell><cell cols="3">69.70 69.23 69.47</cell><cell>72.84</cell><cell cols="3">63.31 61.61 62.44</cell><cell>71.50</cell><cell>64.76 70.74 67.57</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 : 1</head><label>41</label><figDesc>Scores for Multiple and Overlapping Triplets</figDesc><table><row><cell>14Lap</cell><cell>14Rest</cell><cell>15Rest</cell><cell>16Rest</cell></row><row><cell cols="4">ASTE-RL BMRC ASTE-RL BMRC ASTE-RL BMRC ASTE-RL BMRC</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/xuuuluuu/SemEval-Triplet-data</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This project is supported by the DSO grant no. RTDST190702 awarded to SUTD titled Complex Question Answering.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Bidirectional Machine Reading Comprehension for Aspect Sentiment Triplet Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaowei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuelin</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.07665</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/P19-1520" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Actionet: An Interactive End-To-End Platform For Task-Based Data Collection And Augmentation In 3D Environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafei</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samson</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><forename type="middle">Li</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheston</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1566" to="1570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafei</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samson</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><forename type="middle">Li</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheston</forename><surname>Tan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.04918</idno>
		<title level="m">A Survey of Embodied AI: From Simulators to Research Tasks</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianzhe</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicong</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.08549</idno>
		<title level="m">Dawei Yin, and Houfeng Wang. 2021. First Target and Opinion then Polarity: Enhancing Target-opinion Correlation for Aspect Sentiment Triplet Extraction</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Unified Model for Opinion Target Extraction and Target Sentiment Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33016714</idno>
		<ptr target="https://doi.org/10.1609/aaai.v33i01.33016714" />
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Entity-Relation Extraction as Multi-Turn Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiayu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arianna</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duo</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1129</idno>
		<ptr target="https://doi.org/10.18653/v1/P19-1129" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1340" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Sentiment analysis and opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Synthesis lectures on human language technologies</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Sentiment analysis and subjectivity. Handbook of natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sentiment analysis: Capturing favorability using natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuya</forename><surname>Nasukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeonghee</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd international conference on Knowledge capture</title>
		<meeting>the 2nd international conference on Knowledge capture</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Knowing what, how and why: A near complete solution for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
		<ptr target="https://aaai.org/ojs/index.php/AAAI/article/view/6383" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<idno type="DOI">10.1109/TAFFC.2020.3038167</idno>
		<ptr target="https://doi.org/10.1109/TAFFC.2020.3038167" />
		<title level="m">Beneath the Tip of the Iceberg: Current Challenges and New Directions in Sentiment Analysis Research. IEEE Transactions on Affective Computing 01</title>
		<imprint>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="1" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Text chunking using transformation-based learning. In Natural language processing using very large corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell P</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marcus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="157" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Satinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yishay</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPs</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="1057" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Richard S Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satinder</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A hierarchical framework for relation extraction with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichi</forename><surname>Takanobu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiexi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33017072</idno>
		<ptr target="https://doi.org/10.1609/aaai.v33i01.33017072" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Coupled Multi-Layer Attentions for Co-Extraction of Aspect and Opinion Terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokui</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
		<ptr target="http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14441" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Grid Tagging Scheme for Aspect-oriented Fine-grained Opinion Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengcan</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.04640</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Position-Aware Tagging for Aspect Sentiment Triplet Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.183</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.emnlp-main.183" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A Multi-task Learning Framework for Opinion Triplet Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuchi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.01512</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
