<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Siamese BERT-based Model for Web Search Relevance Ranking Evaluated on a New Czech Dataset</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mat?j</forename><surname>Koci?n</surname></persName>
							<email>tmatej.kocian@firma.seznam.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Seznam.cz</orgName>
								<address>
									<settlement>Prague</settlement>
									<region>Czechia</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>N?plava</surname></persName>
							<email>jakub.naplava@firma.seznam.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Seznam.cz</orgName>
								<address>
									<settlement>Prague</settlement>
									<region>Czechia</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel?tancl</surname></persName>
							<email>daniel.stancl@firma.seznam.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Seznam.cz</orgName>
								<address>
									<settlement>Prague</settlement>
									<region>Czechia</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladim?r</forename><surname>Kadlec</surname></persName>
							<email>vladimir.kadlecu@firma.seznam.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Seznam.cz</orgName>
								<address>
									<settlement>Prague</settlement>
									<region>Czechia</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Siamese BERT-based Model for Web Search Relevance Ranking Evaluated on a New Czech Dataset</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>This paper was accepted to IAAI 2022. Please reference it instead once published.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Web search engines focus on serving highly relevant results within hundreds of milliseconds. Pre-trained language transformer models such as BERT are therefore hard to use in this scenario due to their high computational demands. We present our real-time approach to the document ranking problem leveraging a BERT-based siamese architecture. The model is already deployed in a commercial search engine and it improves production performance by more than 3%. For further research and evaluation, we release DaReCzech, a unique data set of 1.6 million Czech user query-document pairs with manually assigned relevance levels. We also release Small-E-Czech, an Electra-small language model pretrained on a large Czech corpus. We believe this data will support endeavours both of search relevance and multilingualfocused research communities.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Web search engines are used by billions of people every day. Powered by results of decades of information retrieval research, they help find the documents people are looking for or directly answer their questions.</p><p>While basic query-document matching according to whether the documents contain all the words from the query might be sufficient for small document collections, the ever increasing quantity of documents available on the web makes it usually impossible for the user to go through all results that match given query words. Moreover, because of query-document vocabulary mismatch <ref type="bibr" target="#b23">(Zhao and Callan 2010)</ref> and multiple possible word meanings, simple matching might exclude relevant documents. Therefore, there is a need for sophisticated natural language understanding (NLU) and document ranking methods. As the tasks might be intuitive for humans but difficult to describe algorithmically, such methods are usually based on machine learning utilizing examples provided by human annotators.</p><p>A popular document ranking model option is a Gradient Boosted Regression Trees (GBRT) ranker <ref type="bibr" target="#b24">(Zheng et al. 2007)</ref>. It allows to easily and robustly combine hundreds of ranking features ranging from classical ones like BM25 <ref type="bibr" target="#b15">(Robertson and Walker 1994)</ref> or PageRank <ref type="bibr" target="#b12">(Page et al. 1999</ref>) to outputs of other statistical models. A number of features deal with the relevance of a document text to the query, which is basically a natural language processing (NLP) task.</p><p>Recently, the NLP community embraced BERT <ref type="bibr" target="#b6">(Devlin et al. 2018</ref>) inspired by the influential transformer architecture <ref type="bibr" target="#b19">(Vaswani et al. 2017)</ref>. While BERT variants reach SoTA performance on many NLP tasks, they are computationally demanding and thus difficult to deploy in a search engine that strives to deliver results to users under a second.</p><p>In this work, we create a new text relevance model based on Electra-small <ref type="bibr" target="#b3">(Clark et al. 2020</ref>) (a variant of BERT) that improves relevance ranking while being sufficiently fast. We use the siamese architecture <ref type="bibr" target="#b14">(Reimers and Gurevych 2019)</ref> that allows us to precompute document embeddings and compare them with a query embedding at search time. We discuss several methods to compute the relevance score from the query and the document embeddings and propose a new neural-based interaction module.</p><p>Most relevance research published so far deals with English queries and documents. We are interested in model performance on Czech data. To this end, we pretrain an Electrasmall model on a Czech corpus and fine-tune it for relevance ranking on a Czech query-document dataset, which we also release to facilitate further research in this area.</p><p>Our main contributions are:</p><p>? We develop and train an Electra-based siamese model for relevance ranking that has also been deployed in a search engine, where it improves performance by 3.8%.</p><p>? We release DaReCzech 1 , a large Czech relevance dataset with real user queries and relevance annotations provided by human experts.</p><p>? We release Small-E-Czech 2 , an Electra-small model pretrained on a Czech corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>This section provides an overview of related work. It describes transformer models, model compression and siamese transformers. The section is concluded with reviews of existing datasets for document ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transformer models</head><p>Transformer model architecture, introduced by <ref type="bibr" target="#b19">Vaswani et al. (2017)</ref>, brought a revolution into NLP. They proposed an encoder-decoder model, intended for sequence transduction, based on a multi-head self-attention mechanism that enabled to learn long-term dependencies. <ref type="bibr" target="#b6">Devlin et al. (2018)</ref> introduced BERT, which was a novel encoder-only language model pre-trained on a large text corpus through masked tokens and next sentence prediction. Subsequently, the model was fine-tuned on a plethora of NLU tasks and reached SoTA results. Here, we rely on Electra <ref type="bibr" target="#b3">(Clark et al. 2020)</ref>, which shares its architecture with BERT, but it promises more efficient pre-training and it has been demonstrated that it can be trained in a smaller configuration than the one known as BERT-base (14M vs 110M parameters) without a dramatic drop in performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge Distillation and Model Compression</head><p>Knowledge distillation is a technique for transferring knowledge from large or ensemble models (teachers) to their smaller or single counterparts (students) <ref type="bibr" target="#b1">(Bucil?, Caruana, and Niculescu-Mizil 2006)</ref>. Current transformers, though SoTA, are prohibitively slow to use in some settings, such as real-time web search. Therefore, many works have been dedicated to distilling knowledge to more compact models, e.g. <ref type="bibr" target="#b16">Sanh et al. (2019)</ref> introduced DistilBERT, a compressed model with 6 layers, which resulted in 2.5?speedup while retaining 97% of the performance of BERT-base.</p><p>During our work, we also distilled smaller variants of our Electra model having promising results. Although they provided us with a single-digit speed-up, calculating all querydocument embeddings during online serving was still infeasible and we thus focus on siamese models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Siamese Transformers</head><p>Siamese architecture <ref type="bibr" target="#b14">(Reimers and Gurevych 2019)</ref> is an orthogonal approach to speeding up online inference by offline pre-computation of document embeddings. In this setting, the model is separately fed two texts to obtain their embeddings. Subsequently, these two vectors are compared using e.g. cosine similarity to estimate a similarity score.</p><p>This approach was proved to be proficient in a first-stage document retrieval. <ref type="bibr" target="#b22">Zhan et al. (2020)</ref> computed the document relevance to a query as the scalar product of their embeddings and showed their BERT-based solution beat four traditional IR baselines.</p><p>Similar approach with some additional adjustments was considered for ColBERT with likewise promising results <ref type="bibr" target="#b9">(Khattab and Zaharia 2020)</ref>. There, the similarity between a query and a document is evaluated over a bag of embeddings (i.e. there are multiple vectors for a query or a document). This, however, leads to high memory requirements as all embedding vectors need to be stored. <ref type="bibr" target="#b11">Lu, Jiao, and Zhang (2020)</ref> presented TwinBERT, which is likely the closest work to ours. In that work, they first obtained query and document embeddings through <ref type="bibr">[CLS]</ref> retrieved from the last BERT's layer. Afterwards, they compared the embeddings using an interaction module which took an element-wise maximum of two embedding vectors and ran it through a residual fully-connected layer followed by a logistic regression layer to obtain the relevance score.</p><p>Our work differs from <ref type="bibr" target="#b11">Lu, Jiao, and Zhang (2020)</ref> in several aspects. (1) We use Electra instead of BERT due to more efficient pre-training. (2) We explore a deeper structure for the embedding interaction module. (3) We evaluate our model in the scenario of a web search instead of a sponsored search. (4) We fully focus on Czech, which is a much less resource-rich language than English. We release the manually annotated dataset to further support this research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Review of Existing Datasets</head><p>To the best of our knowledge, there is no annotated dataset in Czech for relevance ranking. Also, many datasets for document retrieval tasks were collected several years ago and are therefore outdated. The non-exhaustive review of some of the most prominent datasets is provided below.</p><p>The dataset most related to ours is MS MARCO <ref type="bibr" target="#b0">(Bajaj et al. 2016)</ref>. This dataset contains a collection of 1 M user queries, together with 8.8 M passages retrieved from 3.6 M web documents obtained by the Bing search engine. In contrast to ours, all data are in English. Another dataset based on the Bing search logs is ORCAS <ref type="bibr" target="#b5">(Craswell et al. 2020)</ref> containing 20 M query-document pairs, although it lacks annotations for any relevance task.</p><p>TREC2009 Web Track (Clarke, Craswell, and Soboroff 2009) overviewed retrieval techniques, and was based on a large corpus of 10 billion web pages in 10 languages crawled in 2009 called ClueWeb2009. 3 TREC2009 consists of several tasks including ad-hoc search where the aim was to provide a list of most relevant documents for unseen topics.</p><p>Another two datasets (US and Asian versions) were published by Yahoo for a learning-to-rank challenge <ref type="bibr" target="#b2">(Chapelle and Chang 2011)</ref>. They consist of annotated querydocument pairs accompanied with relevance labels. All queries originate from real Yahoo search logs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem and Data</head><p>For performance reasons, the document index currently has about 200 shards on 100 machines and the relevance ranking in the search engine consists of several stages (similar to those described by <ref type="bibr" target="#b21">Yin et al. (2016)</ref>, see <ref type="figure">Figure 1</ref> for an illustration). First, the retrieval stage selects documents containing all words from the original query or its enhanced variants (generated by typo correction, declension, etc.). Then the so-called Stage-1 selects about 20 000 candidate documents using a GBRT ranker with fast features <ref type="bibr">(PageRank,</ref><ref type="bibr">BM25 variants,</ref><ref type="bibr">etc.)</ref>. In our research, we focus on Stage-2, which selects top 10 documents, again using a GBRT ranker. In addition to the features from Stage-1, Stage-2 uses also more complex ones (text relevance utilizing distances of query words matches in the document, etc.), totalling to more than 500 features. Finally, the top 10 documents are reordered by Stage-3.</p><p>We improve Stage-2 by adding a new feature to the GBRT ranker. This is not easy as the ranking features have been tuned for years, and such efforts often result in negligible improvements.</p><p>The quality of the ranker is periodically evaluated on a set of about 2 500 queries sampled from the past 3-month period of the query log. For each query, top 10 results are retrieved and their relevance is evaluated by human annotators. As the order of the top 10 results might be changed by Stage-3, we primarily measure Precision@10 (P@10), i.e. the ratio of relevant documents among the top 10.</p><p>After a new evaluation query set is sampled, the annotated query-document pairs from the last set are added to an old data pool and can be used for training and preliminary testing of models. Note there are much fewer annotated documents per query in the data pool than ca. 20 000 candidates available in production Stage-2. Generally, these annotated documents must have been deemed relevant by a previously evaluated model. A substantially different model that would be able to bring new relevant documents to the top in production is thus at a disadvantage. We hence consider our test set only as an approximation of the final evaluation.</p><p>Another problem with old data is that documents might have changed (or their relation to the world, e.g. in case of current events, shifted word meanings, user expectations, etc.) and thus the relevance annotations might be outdated. This is the reason why the GBRT rankers are usually trained only on a recent subset of the old data pool. The rest can then be used for text features training, the rationale being that text content relevance might be less ephemeral.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DaReCzech</head><p>DaReCzech is a new Czech dataset for text relevance ranking that we created from the old data pool. It is divided into four parts: Train-big comprising more than 1.4 M querydocument pairs (intended for training of a (neural) text relevance model used as a feature in the GBRT model), Train-small (97 k records, intended for GBRT training), Dev (41 k records) and Test (64 k records), which contains the newest annotations. There is no intersection between querydocument pairs in the training, development and test data. The basic statistics of the dataset are presented in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>Each dataset record contains a query, a URL, a document title, a document representation and a relevance label. The queries are real user queries with some typos corrected. A document representation consists of three parts:</p><p>? Title -document title words that were classified by an internal model of the search engine as words corresponding to that particular document, as opposed to words corresponding to the whole web site (usually domain name or description). It is lowercased. ? URL -a preprocessed document URL, with % sequences decoded, plus signs converted to spaces and some parts (matching the regex (https?:\/\/(www\.)?|[-_\t])) removed. ? Body Text Extract (BTE) -document body filtered with an internal model of the search engine, i.e. supposedly without headers, menus, etc. The processed parts are then prepended with identifiers and concatenated: title: &lt;title&gt; url: &lt;url&gt; bte: &lt;bte&gt;.</p><p>The relevance labels were mapped from the original annotations as follows: (1) Useful: 1, (2) A little useful: 0.5 (0.75 for Test), (3) Almost not useful: 0.5 (0.25 for Test and Trainbig), (4) Not useful: 0. Note that because we track P@10, i.e. the ratio of useful (label ? 0.5) documents among top 10, the exact values of other mapped annotations are less important on Dev and Test set.</p><p>For an example dataset record, see <ref type="table" target="#tab_2">Table 2</ref>. Some documents have empty bodies or titles, either because they did not contain any text in these fields or they were not indexed at the time of dumping the data from the search engine database. We dropped empty documents from the training set, as initial experiments showed this helps the fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Czech Corpus for Language Model Pretraining</head><p>For self-supervised LM pretraining, we use an in-house Czech corpus (253 GB) that is once a year generated from documents downloaded by the search engine crawler. During the corpus generation, document language is detected, non-Czech, duplicate, SPAM and too short texts are dropped and the remainder is cleaned and lowercased. Doc repr. title: news for fresh fathers a week of paid leave after the birth of offspring url: seznamzpravy.cz/clanek/news for fresh fathers a week of paid leave after the birth of offspring 41487?autoplay=1 bte: News for fresh fathers: a week of paid leave after the birth of the offspring The involvement of fathers is intended to help the mother at the critical stage of the six-week period. And at the same time strengthen the relationship between the child and the parents. Is paternity leave one of the last government coalition's pre-election gifts? (. . . ) Title news for fresh fathers a week of paid leave after the birth of offspring </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline GBRT Ranker</head><p>Relevance ranking in Stage-2 is done by a GBRT ranker using hundreds of features. The exact list changes over time as new features are implemented and old systems are turned off. In our work, we tried to improve a baseline model with 575 features. Examples of the most influential include:</p><p>? dynamic text relevance -scores depending on distances between matches of query words in the document, averaged across different generated query variants, ? PageRank, ? logistic regression using a query and title words as features, ? Okapi BM25 and its several variants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Architecture</head><p>The core of our system is a Czech Electra model pretrained on the web corpus gathered by the search engine crawler. On top of this model, we build two alternative architectures: First, the query-doc model, which uses a simple linear layer to transform the output of Electra's [CLS] token into a single number describing the relevance between the concatenated query and document. Second, the siamese model, which uses the underlying Electra model to compute query and document embeddings. These embeddings are further compared using cosine similarity or a small feed-forward network that outputs the final relevance score.</p><p>The query-doc model has a clear advantage over the siamese model as it can directly compare subwords of both the document and the query. The siamese model, on the other hand, has to encode all information about a query or a document in a vector of a limited size and compare these later. Nonetheless, at inference time, when the best document should be selected for a query, all query-document pairs need to be evaluated by the whole model for the querydoc approach. This turned out to be computationally infeasible even in Stage-2 as 20 000 document embeddings would have to be computed for each query.</p><p>In this section, we first describe the query-doc model and the siamese model architectures. We then elaborate on a set of improvements applied to the latter model to decrease the gap between the performance of these two systems while keeping the latency low. Finally, we describe the training details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query-Doc Model</head><p>The query-doc model follows the original approach for sequence classification <ref type="bibr" target="#b6">(Devlin et al. 2018</ref>) by adding an additional linear layer on top of the Electra embedding for the artificial [CLS] token. We add a sigmoid activation to project scores between 0 and 1. The input to this model is a single sequence: a tokenized query and a document representation separated by the special [SEP] token. The model outputs a number predicting the document relevance for the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Siamese Model</head><p>The siamese model utilizes an underlying Electra model to compute embeddings separately for a query and a document. Similarly to <ref type="bibr" target="#b14">Reimers and Gurevych (2019)</ref>, we experimented with three strategies of whole token sequence embedding computation: mean or maximum of all output vectors or the output for the [CLS] token. We found the [CLS] token to work best. The embeddings are then compared using cosine distance serving as a relevance proxy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Improving the Siamese Model</head><p>Custom Interaction Module Cosine similarity has proven to be an effective and fast way to compare embed- dings (Reimers and Gurevych 2019), but its simplicity might limit performance. Therefore, similarly to <ref type="bibr" target="#b8">Karpukhin et al. (2020)</ref>, we define a feed-forward network that compares the embeddings and returns a relevance score. The small size of the network ensures that it still remains fast enough.</p><p>Following <ref type="bibr" target="#b11">Lu, Jiao, and Zhang (2020)</ref>, the input to our interaction module is an embedding epqq of a query q and an embedding epdq of a document d, each being of dimension n " 256. First, we compute the element-wise maximum of the input embeddings m " maxpepqq, epdqq. This is processed by two fully-connected layers inspired by the fully-connected block in the transformer model. The first layer maps the input vector to a space with twice as many dimensions and is followed by dropout (drop probability 0.25) and GELU activation <ref type="bibr" target="#b7">(Hendrycks and Gimpel 2016)</ref>. The second layer maps the vector back to the original space and again applies GELU. We also use a residual connection circumventing the nonlinearity:</p><formula xml:id="formula_0">h 1 " Dropout 0.25 pGELUpW 1 mqq, h 2 " GELUpW 2 h 1 q`m,</formula><p>where W 1 P R 2n?n and W 2 P R n?2n are learnable weight matrices. The output h 2 of this residual block is concatenated with cosine similarity and Euclidean distance between the query and document embeddings. We found that this improves the stability of training.</p><p>h 3 " rh 2 , cospepqq, epdqq, }epqq?epdq}s</p><p>Finally, a linear layer with a tanh activation is used to produce the final relevance score:</p><formula xml:id="formula_1">r " tanhpw out?h3 q,</formula><p>where w out P R n`2 is a learnable weight vector.</p><p>Considering Multiple Electra Layers Tenney, Das, and Pavlick (2019) have shown that different tasks benefit more from different layers of BERT. Following the approach of Kondratyuk and Straka (2019), we do not use only the lastlayer embedding of the [CLS] token, but learn a weighted combination of all layer outputs for this token and take that as the embedding of the input sequence.</p><p>Learning with a Teacher The query-doc model performs better than the siamese one, but is impractical to deploy due to its computational demands. Therefore, we use a variant of knowledge distillation to bridge this gap in quality. Specifically, for each training sample, we compute the prediction of the query-doc (teacher) model, average it with the original label and use the result as a training label for the siamese (student) model.</p><p>Initialization from the Teacher. We initialize the student model weights with the fine-tuned teacher weights.</p><p>Ensemble Ensembling multiple models (i.e. combining their outputs) proves to improve results at the cost of increased inference time <ref type="bibr">(Dietterich 2000)</ref>. Having a fast enough siamese model, we found out that having two models in an ensemble is a viable option. To diversify the models, only the random seed was changed when training the second one. This affected the initialization of the interaction module weights, the order of training samples and dropout.</p><p>We tried combining outputs of the models by taking either the mean or the maximum prediction and found the former to work better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pretraining Small-E-Czech</head><p>An internal 253 GB Czech web corpus was used for unsupervised pretraining. The texts are tokenized into subwords with a standard BERT WordPiece tokenizer <ref type="bibr" target="#b17">(Schuster and Nakajima 2012)</ref>. The tokenizer is trained on a subset of the corpus and its vocabulary size is limited to 30 522 items.</p><p>The Electra model is pre-trained using the official code 4 in the Electra-small configuration. We train the model for 4 M training steps, which took ca. 20 days on a single GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Details</head><p>We train our model on the Train-big set and select the best checkpoint using early-stopping on the Dev set. Subsequently, we train a GBRT ranker on the Train-small set with our model output as an additional feature and evaluate both on the Test set. All input texts are lowercased to match the pretraining corpus.</p><p>We use Adam optimizer with learning rate 5?10?5 without any warmup or learning rate decay to optimize weights of the Electra model and a custom interaction module if present. We use MSE loss for the query-doc and the siamese models. We also experimented with other loss functions such as triplet loss, but found them to perform worse.</p><p>We cap each sentence at 128 tokens and train with batches of size 256. For siamese models, we map the labels into r?1, 1s to match the model output range.</p><p>For knowledge distillation, our loss function is a mean of MSE between student and teacher prediction (soft labels) and conventional MSE with respect to (hard) gold labels. Otherwise, all training parameters remain the same.</p><p>We code our experiments using PyTorch <ref type="bibr" target="#b13">(Paszke et al. 2019</ref>) and the Transformers library <ref type="bibr" target="#b20">(Wolf et al. 2020)</ref>.</p><p>The GBRT ranker is trained using the Catboost library with 1 500 trees of depth 6, RMSE loss function and early stopping on 100 iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In this section, we present the results of training our querydoc and siamese models. We train each model 4 times with different random seeds (affecting the initialization of the custom interaction module if present and the dropouts), select the best checkpoint for each run on the development set and report the mean and the standard deviation of the 4 runs on the test set.</p><p>We report two types of results -the first one labeled as Standalone for the respective model being used alone for ranking; and the second one labeled as with GBRT for the respective model being used as an additional feature for a GBRT ranker that already utilizes hundreds of existing features. Note that we use the Train-big data to train the neural models and, subsequently, the Train-small data to train the GBRT ranker with the exception of the production search engine baseline that is trained on the entire Train-big data.</p><p>We evaluate the models in two scenarios: (1) on the new DaReCzech dataset, (2) in a production setting. <ref type="table" target="#tab_4">Table 3</ref> presents an evaluation on DaReCzech dataset. In the top part, we show results of baselines -the random ranking, BM25 and the production GBRT ranker (Search engine baseline), and P@10 achievable by ideal ranking (Oracle).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DaReCzech</head><p>The query-doc model outperforms the baseline results by a large margin, achieving P@10 46.3 and GBRT P@10 46.93. These results set the upper bound for the siamese model as the query-doc approach may compare tokens of both query and document directly.</p><p>Despite its relative simplicity, the feature from the Siamese-Cosine model helps the GBRT ranker by ca. 0.3 percent, but is not very competitive when used alone, and even with the GBRT ranker it lags behind the query-doc approach. When the cosine distance is replaced with a more sophisticated neural based interaction module, the performance improves, and this modification appears as the strongest one.</p><p>Using a weighted combination of multiple Electra layers instead of the last layer output seems to improve the performance. However, we found that this may be due to our choice of the interaction module. When the weighting is  used with the simplest model with the cosine similarity, it increases its performance only by ca. 0.2. Both knowledge distillation from a query-doc teacher and weight initialization from the teacher help the model.</p><p>All described improvements to the baseline model proved to be effective. Their combination and the final ensembling reduced the gap between the siamese and the querydoc model greatly. Moreover, we can see that already our best non-ensemble siamese model has better performance (45.26) than the baseline production GBRT ranker (45.14). When we add the ensemble output to the features and retrain the GBRT ranker, its P@10 increases by 1.48 to 46.61.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real Traffic</head><p>Model evaluation on a fixed test set is cheap and stable, but does not take into account the multitude of documents retrieved for a query in production from which the model can select the top 10. To account for this, 3 000 queries were sampled from the search log. Top 10 documents were retrieved for each using the original GBRT ranker and the new GBRT ranker utilizing new Electra ensemble signals as additional features. The query-documents pairs were then assigned relevance levels by human experts. The new features increased P@10 of the model by 3.8% (relative).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Studies</head><p>In this section, we present several ablation studies. First, we inspect the importance of individual document parts. We then explore the effect of training data volume on model performance. Third, we study different interaction modules. Fourth, we evaluate a different initialization of the underlying Electra model and also experiment with bigger underlying models. Finally, we present model quantization results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document Representation</head><p>The document is represented using its title, URL and BTE. To explore the individual effects of these parts on model performance, we trained a different siamese model on each part. No teacher was used during the training, because this would require training the teacher on the respective data part as well, i.e. we used +weighted CLS model configuration from <ref type="table" target="#tab_4">Table 3</ref>. The testing was then performed on the test set comprising only the respective data part. The results of this experiment are displayed in <ref type="table" target="#tab_6">Table 4</ref>. We can see that BTE contains the most useful information, but all data parts are useful, as the respective models are significantly better than the random baseline of 37.9 P@10 (see <ref type="table" target="#tab_0">Table 1</ref>).</p><p>Moreover, we conducted an experiment where the individual data parts are added incrementally, i.e. title, URL and BTE. The results are shown in <ref type="table" target="#tab_7">Table 5</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Data Volume</head><p>We inspect the effect of the number of training samples on model performance in <ref type="figure">Figure 3</ref>. Specifically, for each predefined training set size, we randomly sample this amount of data from the training set and train a siamese model on it. We do not use a teacher and run each experiment four times to account for the randomness in sampling. The results show that the performance increases with the number of training samples, both of the model alone and the GBRT ranker using model output as an additional feature, while the gap between them decreases. The effect on performance slowly levels off, but the model might still benefit from more data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interaction Module Variants</head><p>As we already discussed in Section Custom Interaction Module, the interaction module comparing two embeddings and returning a single relevance score may be cosine similarity or a feed-forward neural network. The final interaction module we use is a result of several preliminary experiments. We compare here five different architectures:</p><p>? Cosine -compares the query and document embedding using cosine similarity ? Single Hidden -a neural network mapping the query and document embeddings into a vector of size 3, concatenating it with their Euclidean distance and cosine similarity and finally using a simple feed forward layer with sigmoid activation to obtain the relevance score  <ref type="figure">Figure 3</ref>: Precision@10 of the model when trained only on a subset of the training data of particular size. We report the performance of the sole model and also of the GBRT ranker using the model output as an additional feature.</p><p>? TwinBERT interaction module as proposed by <ref type="bibr" target="#b11">Lu, Jiao, and Zhang (2020)</ref>  able 6: Performance of the systems utilizing different interaction modules. Speed-up measurements regard the sole siamese model, not the GBRT. <ref type="table">Table 6</ref> presents results and also relative speed-ups of the considered interaction modules. We can see that the better the model quality, the worse the model speed. The simplest cosine similarity is the fastest way to compare embeddings, but it performs the worst. On the other hand, our final interaction module surpasses the performance of all other approaches, but is the slowest one. Still, depending on the document length, using the custom metric on top of the precomputed embeddings is roughly 1000?faster than running the entire query-doc model.</p><p>Two other noteworthy points are that using the Euclidean and cosine distances as additional features provides a slight gain in the final score, and that our final model surpasses the original TwinBERT interaction module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Base Models</head><p>We decided to use Electra-small model due to its small size and high performance. Apart from the Electra-small model pretrained on Czech web documents, we experimented with three other base models:</p><p>? Electra-small model with the same vocabulary but initialized randomly ? mBERT <ref type="bibr" target="#b6">(Devlin et al. 2018</ref>  <ref type="table">Table 7</ref>: Precision@10 of using different underlying BERTbased models. We report both results when trained in the query-doc and in the siamese mode. For simplicity, siamese models are trained with cosine similarity and without a teacher.</p><p>We trained all models in the query-doc setting. As can be seen in <ref type="table">Table 7</ref>, the RobeCzech model performs the best, but is ca. 10?bigger than our Electra-small model. We can also see that despite the relatively large finetuning dataset, the pretraining on monolingual data is still beneficial as the pretrained model outperforms the not-pretrained model.</p><p>In the siamese mode, we trained all models except for mBERT which we omitted as RobeCzech provided better results in the query-doc setting. We use only cosine similarity as the embedding interaction module. Although the results show a big performance gap between Electra-small models and RobeCzech model, we think that the RobeCzech model would require more tuning of the learning rate schedule and other hyperparameters to fully exploit its capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ONNX and Quantization</head><p>Apart from using siamese architecture and an Electra-small variant, we tried to speed up our model using ONNX runtime 5 and model quantization (Polino, Pascanu, and Alistarh 2018), i.e. reducing the precision of the computation. While our approach allows to precompute document embeddings offline, there are billions of documents in the database and generating embeddings can thus take a lot of time. We measured different combinations of ONNX conversion and quantization of the embedding module or the interaction module in Python using one thread on a CPU with one AVX-512 FMA unit. The results are in <ref type="table">Table 8</ref>. The interaction 5 https://github.com/microsoft/onnxruntime module running on ONNX with UINT8 model quantization is about 1.9?faster than the Pytorch version, while the difference in quality is small. As for the embedding model, the difference in both speed and quality is bigger.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Size Effect on Response Times</head><p>The query evaluation time depends on many factors, making it complicated to evaluate meaningfully. To give rough estimates, the query preprocessing phase gets prolonged by 10 ms on average when using the new Electra-small model. If we replaced it with a BERT-base model, the query embedding generation would take ca. 64 ms instead of 10 ms.</p><p>The retrieval and ranking phase used to take about 133 ms. With our new feature included, the computation takes about 136 ms (+3 ms) on average. Replacing Electra-small embeddings of size 256 with BERT-base embeddings of size 768 is expected to slow down the ranking stage to 143 ms (+10 ms).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this work, we presented a strong and fast variant of a siamese model for relevance ranking based on an Electra language model. We described and evaluated a set of improvements to the baseline siamese model and showed their effect on overall model performance. The model was successfully deployed as an additional feature for a GBRT ranker in a commercial search engine and led to a substantial improvement of 3.8% in quality.</p><p>Moreover, we released Small-E-Czech, a pretrained Electra-small model, and DaReCzech, a new dataset for text relevance ranking in Czech. The dataset consists of more than 1.6 M annotated query-documents pairs, which makes it one of the largest available datasets for this task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>The final siamese model. The tokenized query and document are inputted to Electra separately (tokens W Q i and W D i ), embeddings from their [CLS] tokens are compared using a custom interaction module. The module comprises a 2-layer feed-forward network and Euclidean distance and cosine similarity, followed by a linear transformation and hyperbolic-tangent non-linearity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>able 8 :</head><label>8</label><figDesc>Effect of model quantization on quality and speed. Relative speed-up values shown in the top part refer to the interaction module execution time and values in the bottom part refer to the embedding model execution times.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>DaReCzech statistics. We report the number of words (whitespace separated) per extracted document body and title, number of annotated documents per query, and P@10 and Discounted Cumulative Gain (DCG) for random ranking (100 runs average) and ideal (oracle) ranking. For number of words and documents we report the mean and 0.25 and 0.75 quantiles.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Words per query</cell><cell cols="3">Words per doc</cell><cell cols="3">Words per title</cell><cell cols="3">Docs per query</cell><cell>Random</cell><cell>Oracle</cell></row><row><cell>Dataset</cell><cell></cell><cell cols="4">#records 1 ?4 avg</cell><cell cols="2">3 ?4 1 ?4</cell><cell>avg</cell><cell cols="3">3 ?4 1 ?4 avg</cell><cell>3 ?4</cell><cell>1 ?4</cell><cell>avg</cell><cell cols="2">3 ?4 P@10 DCG P@10 DCG</cell></row><row><cell>Train-big</cell><cell></cell><cell cols="2">1 431 730</cell><cell>2</cell><cell>2.9</cell><cell>4</cell><cell cols="3">7 533.8 392</cell><cell>3</cell><cell>5.4</cell><cell>8</cell><cell>3</cell><cell>8.1</cell><cell>7</cell><cell>18.1</cell><cell>1.2</cell><cell>22.1</cell><cell>1.5</cell></row><row><cell cols="2">Train-small</cell><cell cols="2">97 386</cell><cell>2</cell><cell>3.0</cell><cell>4</cell><cell cols="3">1 300.3 198</cell><cell>2</cell><cell>4.5</cell><cell cols="4">6 37 52.6 65</cell><cell>36.2</cell><cell>6.9</cell><cell>82.2</cell><cell>8.2</cell></row><row><cell>Dev</cell><cell></cell><cell cols="2">41 220</cell><cell>2</cell><cell>2.9</cell><cell>4</cell><cell cols="3">2 310.7 218</cell><cell>2</cell><cell>4.5</cell><cell cols="4">6 36 52.0 66</cell><cell>34.9</cell><cell>6.7</cell><cell>80.4</cell><cell>8.0</cell></row><row><cell>Test</cell><cell></cell><cell cols="2">64 466</cell><cell>2</cell><cell>2.9</cell><cell>4</cell><cell cols="3">4 371.9 322</cell><cell>2</cell><cell>5.1</cell><cell>7</cell><cell cols="3">7 27.8 43</cell><cell>37.9</cell><cell>3.2</cell><cell>59.3</cell><cell>4.0</cell></row><row><cell>?ery Index</cell><cell>Retrieval</cell><cell>Matched docs</cell><cell>Stage-1</cell><cell>docs 20 k</cell><cell>Stage-2</cell><cell>10 docs</cell><cell>Stage-3</cell><cell>10 docs sorted</cell><cell>SERP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">Figure 1: Ranking schema of the search engine. Indexed</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">documents that match given query are evaluated by Stage-1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">ranking model and top documents are sent to Stage-2, which</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>we focus on. Stage-2 ranking model selects top 10 docu- ments and sends them to Stage-3, which determines their final ordering on the search engine result page.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>/www.seznamzpravy.cz/clanek/novinka-pro-cerstve-otce-tyden-placene-dovolene-po-narozeni-potomka-41487?autoplay=1 Doc repr. title: novinka pro?erstv? otce t?den placen? dovolen? po narozen? potomka url: seznamzpravy.cz/clanek/novinka pro cerstve otce tyden placene dovolene po narozeni potomka 41487?autoplay=1 bte: Novinka pro?erstv? otce: t?den placen? dovolen? po narozen? potomka Zapojen? otc? m? pomoci matce v kritick? f?zi?estined?l?. A z?rove? pos?lit vztah mezi d?t?tem a rodi?i. Pat?? otcovsk? do ranku p?edvolebn?ch d?rk? minul? vl?dn? koalice? (. . . )</figDesc><table><row><cell>Field</cell><cell>Value</cell></row><row><cell>Query</cell><cell>volno otec po porodu</cell></row><row><cell cols="2">URL https:/Title novinka pro?erstv? otce t?den placen? dovolen? po narozen? potomka seznam zpr?vy</cell></row><row><cell>Label</cell><cell>1.0</cell></row><row><cell></cell><cell>English translation</cell></row><row><cell>Query</cell><cell>father's leave after childbirth</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Example dataset record with an English translation. The document representation was slightly shortened.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Results on DaReCzech. For each model / additive improvement, we report Precision@10 of the model and the GBRT ranker with the model output as an additional feature.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>.</figDesc><table><row><cell></cell><cell cols="2">Precision@10</cell></row><row><cell>Model</cell><cell>Standalone</cell><cell>with GBRT</cell></row><row><cell>Title</cell><cell cols="2">42.73?0.09 45.46?0.08</cell></row><row><cell>URL</cell><cell cols="2">41.40?0.63 45.37?0.15</cell></row><row><cell>BTE</cell><cell cols="2">43.75?0.46 45.76?0.10</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Effect of using only a single data part (no teacher).</figDesc><table><row><cell></cell><cell cols="2">Precision@10</cell></row><row><cell>Model</cell><cell>Standalone</cell><cell>with GBRT</cell></row><row><cell>Title</cell><cell cols="2">42.73?0.09 45.46?0.08</cell></row><row><cell cols="3">+ URL 43.74?0.37 45.84?0.17</cell></row><row><cell cols="3">+ BTE 44.72?0.39 46.02?0.18</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Effect of using different subsets of document parts (cumulative, no teacher).</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/Seznam/DaReCzech 2 https://huggingface.co/Seznam/small-e-czech</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://lemurproject.org/clueweb09/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/google-research/electra</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the developers and product managers who helped to put our prototype into production. Namely, Jaroslav Gratz, Ale? Ku??k, Daniel M?sz?ros, Martina Pomik?lkov?, Jakub?m?d and Petr Vondr??ek. We also thank the annotators who annotated the DaReCzech dataset and Ond?ej Du?ek and the anonymous reviewers for their valuable comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268</idno>
		<title level="m">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Association for Computing Machinery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bucil?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;06</title>
		<meeting>the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="535" to="541" />
		</imprint>
	</monogr>
	<note>Model Compression. ISBN 1595933395</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Yahoo! learning to rank challenge overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the learning to rank challenge</title>
		<meeting>the learning to rank challenge</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Overview of the trec 2009 web track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>WATERLOO UNIV (ONTARIO</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ORCAS: 20 Million Clicked Query-Document Pairs for Analyzing Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Billerbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management, CIKM &apos;20</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management, CIKM &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2983" to="2989" />
		</imprint>
	</monogr>
	<note>: Association for Computing Machinery. ISBN 9781450368599</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<idno>978-3-540-45014-6</idno>
	</analytic>
	<monogr>
		<title level="m">Multiple Classifier Systems</title>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Ensemble Methods in Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno>abs/1606.08415</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dense Passage Retrieval for Open-Domain Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6769" to="6781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Colbert: Efficient and effective passage search via contextualized late interaction over bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">75 Languages, 1 Model: Parsing Universal Dependencies Universally</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kondratyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2779" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">TwinBERT: Distilling knowledge to twin-structured BERT models for efficient retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06275</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The PageRank Citation Ranking: Bringing Order to the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<idno>number = SIDL-WP- 1999-0120</idno>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note type="report_type">Stanford InfoLab. Previous</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-Performance Deep Learning Library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Alistarh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wallach, H.; Larochelle, H.; Beygelzimer, A.; d&apos;Alch?-Buc</title>
		<editor>F.</editor>
		<editor>Fox, E.</editor>
		<editor>and Garnett, R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc. Polino</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
	<note>International Conference on Learning Representations</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3973" to="3983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;94</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Japanese and korean voice search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>N?plava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Strakov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Samuel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.11314</idno>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="5149" to="5152" />
		</imprint>
	</monogr>
	<note>RobeCzech: Czech RoBERTa, a monolingual contextualized language representation model</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BERT Rediscovers the Classical NLP Pipeline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tenney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4593" to="4601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-Art Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Online: Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ranking Relevance in Yahoo Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Nobata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Langlois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="323" to="332" />
		</imprint>
	</monogr>
	<note>ISBN 9781450342322</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.15498</idno>
		<title level="m">RepBERT: Contextualized Text Embeddings for First-Stage Retrieval</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Term Necessity Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM International Conference on Information and Knowledge Management, CIKM &apos;10</title>
		<meeting>the 19th ACM International Conference on Information and Knowledge Management, CIKM &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="259" to="268" />
		</imprint>
	</monogr>
	<note>ISBN 9781450300995</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A general boosting method and its application to learning ranking functions for web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 20: Proceedings of the 2007 Conference</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
