<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Domain Adaptation for Semantic Segmentation via Low-level Edge Information Transfer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongruixuan</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Wuhan University Wuhan</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wu</surname></persName>
							<email>chen.wu@whu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Wuhan University Wuhan</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghao</forename><surname>Xu</surname></persName>
							<email>yonghaoxu@ieee.org</email>
							<affiliation key="aff2">
								<orgName type="institution">Wuhan University Wuhan</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Du</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Wuhan University Wuhan</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Domain Adaptation for Semantic Segmentation via Low-level Edge Information Transfer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS ? Computing methodologies ? Transfer learning</term>
					<term>Image seg- mentation</term>
					<term>Scene understanding</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unsupervised domain adaptation for semantic segmentation aims to make models trained on synthetic data (source domain) adapt to real images (target domain). Previous feature-level adversarial learning methods only consider adapting models on the high-level semantic features. However, the large domain gap between source and target domains in the high-level semantic features makes accurate adaptation difficult. In this paper, we present the first attempt at explicitly using low-level edge information, which has a small interdomain gap, to guide the transfer of semantic information. To this end, a semantic-edge domain adaptation architecture is proposed, which uses an independent edge stream to process edge information, thereby generating high-quality semantic boundaries over the target domain. Then, an edge consistency loss is presented to align target semantic predictions with produced semantic boundaries. Moreover, we further propose two entropy reweighting methods for semantic adversarial learning and self-supervised learning, respectively, which can further enhance the adaptation performance of our architecture. Comprehensive experiments on two UDA benchmark datasets demonstrate the superiority of our architecture compared with state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Semantic segmentation is a fundamental task in image processing, which aims to assign semantic labels to all pixels in a given image. Obtaining precise semantic segmentation results is significant for many vision-based applications <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b54">55]</ref>. Nowadays, deep learning-based models, especially convolutional neural networks (CNNs) <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, have achieved promising progress in semantic segmentation. To train a good segmentation network, a large number of fully annotated images are often required. Nevertheless, collecting large-scale datasets with accurate pixel-level annotation is time-consuming <ref type="bibr" target="#b8">[9]</ref>. To reduce labeling consumption, an alternative way is utilizing synthetic images with precise pixel-level annotations to train the deep models. These synthetic images and corresponding annotations can be automatically generated by game engines, such as Grand Theft Auto V (GTAV) <ref type="bibr" target="#b33">[34]</ref>. However, due to the large domain gap caused by the appearance difference between synthetic images and real images, the models trained on the synthetic images (source domain) inevitably face severe performance degradation on the real-world image datasets (target domain).</p><p>To address this issue, unsupervised domain adaptation (UDA) methods have been introduced to reduce the domain gap between labeled source domain and unlabeled target domain. In terms of the semantic segmentation task, adversarial learning-based UDA approaches demonstrate good efficiency in aligning domain gaps in the feature-level <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b50">51]</ref>. All of these methods align high-level feature distributions of different domains since highlevel features contain abundant semantic category information. However, the large inter-domain gap in the high-level semantic representations makes the accurate alignment difficult. As pointed by Luo et al. <ref type="bibr" target="#b30">[31]</ref>, directly aligning the high-level semantic features may lead to negative transfer and damage the adaptation performance in the originally well-aligned regions. To address this issue, they propose a local score alignment map to guide the transfer of semantic information.  <ref type="figure">Figure 1</ref>: We propose to explicitly use low-level edge information with a small inter-domain gap for UDA in semantic segmentation. Compared with high-level semantic information, low-level edge information is easier to adapt; thus high-quality edge maps can be produced over the target domain. Since the edge information can reflect the boundaries of semantic category, it can be used to guide the transfer of semantic information.</p><p>In this paper, we provide a different viewpoint for addressing this issue. As argued in <ref type="bibr" target="#b29">[30]</ref>, in contrast to deep feature representations with large domain gaps and poor transferability, feature representations extracted by shallow convolutional layers are often general. Then, according to the visualization results of CNN reported in <ref type="bibr" target="#b51">[52]</ref>, the feature representations extracted by CNN show strong hierarchical nature and the shallow layers highly respond to lowlevel edge and color information. Based on these arguments and observations, we argue that low-level edge feature representations have a smaller inter-domain gap in comparison with high-level semantic features. Intuitively, it could be also observed that although the synthetic image and real-world image are quite different in appearance, the object shapes of the same category are very similar. Moreover, there exists a strong interaction between the edge information and the semantic information: the edge information can reflect the boundaries of semantic category.</p><p>Consequently, as shown in <ref type="figure">Figure 1</ref>, we treat low-level edge information as the transferable factor that could be used to facilitate transfer for high-level semantic information. Specifically, we present a semantic-edge domain adaptation (SEDA) architecture consisting of a semantic stream and an edge stream. In our architecture, the edge information is decoupled from the mainstream semantic network and is explicitly processed by an independent stream. The semantic stream adopts the existing entropy adversarial learning method as the basis. To better adapt hard target images, we present an entropy reweighting method to assign larger weights to harder images. For edge stream, we train it with the source semantic boundaries and adapt the source and target edge features through adversarial learning. An edge consistency loss function is applied to encourage the semantic segmentation predictions to correctly align with the semantic boundaries. As the target results with more accurate boundaries are obtained, we use self-supervised learning (SL) to further fit the distribution of target domain. Furthermore, to overcome the issues of standard self-supervised learning, an uncertainty-adaptive self-supervised learning (UASL) is presented. The contributions of our work can be concluded as follows:</p><p>(1) This paper proposes a semantic-edge domain adaptation architecture, which presents the first attempt at explicitly using edge information that has a small inter-domain gap for facilitating the transfer of high-level semantic information. (2) Two entropy-based reweighting methods are proposed to improve adversarial learning and self-supervised learning, enabling our architecture to learn better domain-invariant representations. (3) Experiments on two challenging benchmark adaptation tasks demonstrate that the proposed method can obtain better results than existing state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Semantic Segmentation</head><p>Semantic segmentation is one of the most challenging computer vision tasks, which aims to predict pixel-level semantic labels for a given image. Following the work in <ref type="bibr" target="#b28">[29]</ref>, it has become mainstream to use fully convolutional network (FCN) architecture for tackling the semantic segmentation task, and many effective models have been presented <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b55">56]</ref>. Besides, some probability graph models like conditional random filed <ref type="bibr" target="#b19">[20]</ref> are used as an effective post-processing method for improving performance. More recently, some work introduces multi-task learning into semantic segmentation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b36">37]</ref>, which combines networks for complementary tasks to improve semantic segmentation accuracy. Nevertheless, to train these semantic segmentation models, numerous real-world images with pixel-level annotations are required, which are usually difficult to collect. An alternative way is to train these models with photo-realistic synthetic data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">UDA for Semantic Segmentation</head><p>Unsupervised domain adaptation aims to align the domain distribution shift between labeled source data and unlabeled target data <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59]</ref>. A very attractive application of UDA is using photo-realistic synthetic data to train semantic segmentation models, and a variety of methods have been presented, which can be broadly divided into three types: adversarial learning based approach <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43]</ref>, image translation approach <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b53">54]</ref>, and self-supervised learning approach <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b59">60]</ref>. Adversarial learning methods involve two networks. A generative network predicts the segmentation maps for the input source or target images. Another discriminator network takes the feature maps from generative network and tries to predict the domain type of feature maps, while generative network tries to fool the discriminator. By iteratively repeating this process, the two domains would have a similar distribution. In <ref type="bibr" target="#b14">[15]</ref>, the adversarial approach for first applied to UDA for semantic segmentation. In <ref type="bibr" target="#b40">[41]</ref>, adversarial learning is performed to match the entropy maps of two domains. In <ref type="bibr" target="#b30">[31]</ref>, a local alignment score map is designed to evaluate the category-level alignment degree for guiding the transfer of semantic features. In <ref type="bibr" target="#b50">[51]</ref>, an attention-based discriminator network is presented to adaptively measure the hard-adapted semantic features.</p><p>Image translation methods directly apply adversarial models or style transfer approaches to transform the source images into target-style images for aligning the domain gap. In <ref type="bibr" target="#b13">[14]</ref>, CycleGAN <ref type="bibr" target="#b56">[57]</ref> is used to transform the synthetic images of the source domain to the style of the target images. In <ref type="bibr" target="#b53">[54]</ref>, a style transfer network is presented to make the images from two domains visually similar. Recently, Yang et al. <ref type="bibr" target="#b49">[50]</ref> use fast Fourier transform to reduce the appearance difference between images from different domains.</p><p>Self-supervised learning is another effective UDA approach. In the field of UDA for semantic segmentation, self-supervised learning methods use the target prediction as pseudo-labels to train the segmentation network, which could make the model implicitly learn the domain-invariant representations <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b59">60]</ref>. In <ref type="bibr" target="#b59">[60]</ref>, a class balancing strategy and spatial prior are presented to guide the selfsupervised learning in target domain. In <ref type="bibr" target="#b26">[27]</ref>, a pyramid curriculum strategy based on multi-scale pooling is proposed to select reliable pseudo-labels to train the segmentation network. Moreover, selfsupervised learning could be combined with adversarial learning or image translation to further boost UDA performance <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>.</p><p>In this paper, unlike the previous adversarial learning methods that only focus on aligning the high-level semantic features, the proposed method simultaneously aligns semantic and edge features and utilizes adapted edge features to facilitate the transfer of semantic features. Moreover, we further present an entropy reweighting semantic adversarial learning strategy and an uncertainty-adaptive self-supervised learning approach to enhance the UDA performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>In UDA for semantic segmentation, the labeled source domain is denoted as D S = {( , )} ?S , and the unlabeled target domain is denoted as D T = { } ? T , where ? R ? ?3 is a source image, ? R ? ? is the one-hot semantic label associated with , and ? R ? ?3 is a target image. Our goal is to utilize the lowlevel edge information, which is relatively easier to be transferred on the two domains, to guide the semantic segmentation over the target domain, thereby obtaining desirable prediction performance. <ref type="figure">Figure 2</ref> illustrates our architecture that mainly contains three parts: semantic information transfer, edge information transfer, and uncertainty-adaptive self-supervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Semantic Information Transfer</head><p>Semantic stream is the basis of our architecture. Specifically, we use entropy adversarial learning method as our baseline, which has yielded promising results in UDA for semantic segmentation <ref type="bibr" target="#b40">[41]</ref> and has served as the basis of more advanced methods <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b41">42]</ref>. First, is trained by minimizing cross-entropy loss L over source data:</p><formula xml:id="formula_0">L = ? ?? ?, ?? (?, , ) log (?, , )<label>(1)</label></formula><p>where ? R ? ? is the source semantic prediction map generate by . Besides, to overcome the negative effect of class imbalance problem, lov?sz-softmax loss <ref type="bibr" target="#b2">[3]</ref> is imposed on source data. Subsequently, takes a target image as input and output the semantic prediction map . Then, the weighted self-information map ? R ? ? is calculated:</p><formula xml:id="formula_1">(?, ) = ? (?, ) log (?, )<label>(2)</label></formula><p>To reduce the domain gap, in entropy adversarial learning, a discriminator is trained to predict the domain type for the weighted self-information map, and is trained to fool . However, the entropy adversarial learning treats all the target images equally, but there exist easy-adapt images with simple scenes and hard-adapt images with difficult scenes in the target domain. To better optimize these hard-adapt samples, we argue that harder samples need to contribute more loss during the training stage. Since the entropy map can reflect the confidence levels of the target predictions <ref type="bibr" target="#b40">[41]</ref>, we utilize the pixel-wise sum of target entropy map to measure the difficulty for each target image:</p><formula xml:id="formula_2">? ? ? ? ? ? ? ? ? (?, ) = ? 1 log (?, , ) log (?, , ) E = ?, (?, )<label>(3)</label></formula><p>where E is the pixel-wise sum of entropy map . If a target image has a low overall entropy value, it can be regarded as an easyadapt sample, otherwise it is a hard-adapt sample. Based on this assumption, we propose an entropy reweighting adversarial loss:</p><formula xml:id="formula_3">L = ? ?? ?, log (1 ? ( )) ? 1 + ( E ) 2 ?? ?, log ( ( ))<label>(4)</label></formula><p>where is the source weighted self-information map, and is a weight factor. Noteworthy, we adopt the square of entropy to enlarge the loss difference between easy-adapt samples and hardadapt samples. Through optimizing L and L , the two domains are aligned at the semantic feature maps to some extent. Next, we explicitly use the low-level edge information to further facilitate the transfer of semantic features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Edge Information Transfer</head><p>In previous methods, edge information is entangled with other types of information in the segmentation network and is implicitly adapted through adversarial learning, which makes it difficult to use edge information for facilitating the transfer of semantic information.</p><p>To explicitly use low-level edge information, we use an independent edge stream to decouple edge information from . In terms of the specific network architecture, we adopt a lightweight auxiliary network introduced in <ref type="bibr">[</ref>  <ref type="figure">Figure 2</ref>: The overall architecture of our SEDA architecture, which composed of three parts: 1) In semantic information transfer, the feature-level adversarial learning approach is applied to align the semantic distributions of source and target domains. Besides, the entropy map of target output is utilized to weight each target sample at the image-level; 2) In edge information transfer, the edge information is decoupled from and independently processed by . Feature-level adversarial learning is also performed to align edge feature distributions of two domains. Then, the target semantic boundary map is used to guide the target semantic segmentation; 3) In uncertainty-adaptive self-supervised learning, the target prediction is weighted by entropy map at pixel-level and treated as pseudo-labels to train .</p><p>over the source domain. Ground truth of semantic boundaries can be directly generated from source semantic labels. Through optimizing L , is capable of generating precise semantic boundaries for source domain data. Compared to highlevel semantic features, the low-level edge features have a smaller domain gap. Moreover, due to optimizing L , the inter-domain gap in the features of shallow layers is further reduced. Accordingly, despite merely supervised by source edge information, can generate decent boundaries in the target domain. To produce higher quality semantic boundaries for target domain, similar to semantic stream, we also introduce a discriminator for predicting the domain labels for the edge feature maps, while is trained to fool :</p><formula xml:id="formula_4">L = ? ?? ?, log 1 ? (H ) + log (H )<label>(5)</label></formula><p>where H and H are the edge features of source and target domains from the last layer of . Subsequently, we add the target edge feature map back to , thereby guiding the semantic segmentation over the target domain. However, this way can only implicitly refine the semantic segmentation results, which cannot guarantee consistency between the boundary map and the predicted semantic segmentation map. To explicitly encourage the target semantic segmentation maps to align with the boundary map, we introduce an edge consistency loss L :</p><formula xml:id="formula_5">? ? ? ? ? ? ? ? ? P = 1 ? 2 ? F * arg max L = N + P ( N + ) ? B ( N + )<label>(6)</label></formula><p>where P is the semantic boundary map computed by taking a spatial derivative on the target segmentation output, F is Gaussian filter, and N + contains coordinates of all boundary pixels in both P and B . L aims at ensuring that target semantic boundary pixels are penalized if there is a mismatch with boundaries predicted by . By optimizing L , can be guided by the target boundary map, thereby generating more accurate target prediction map. Furthermore, since argmax operator is not differentiable, the Gumbel softmax trick <ref type="bibr" target="#b15">[16]</ref> is adopted to approximate the partial derivatives of L to a given parameter during the backward propagation stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Uncertainty-Adaptive Self-Supervised Learning</head><p>By means of using the low-level edge information to guide the transfer of semantic information, can generate more accurate semantic segmentation results over the target domain. Subsequently, considering the complex distribution of real-world data (target domain), we apply the self-supervised learning strategy to make our architecture further fit the distribution of the target domain.</p><p>The standard self-supervised learning method <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b59">60]</ref> sets a threshold to select high-confident target pseudo-labels. However, it is difficult to choose a suitable threshold: an over-large threshold could make the available target information very less, and an oversmall threshold could produce too many noisy labels, damaging the adaptation performance. Besides, the confidence levels of these selected pseudo-labels are also different. To address these issues, we present an uncertainty-adaptive self-supervised loss that adopts entropy to adaptively estimate uncertainty and reweight target prediction at pixel-level:</p><formula xml:id="formula_6">L = ? ?? ?, 1 ? (?, ) 2 ???( ?, , ) log (?, , )<label>(7)</label></formula><p>where?is the one-hot semantic pseudo-labels. Both L and L adopt entropy to measure uncertainty and reweight samples. However, L uses the sum of entropy to weight the target image at the image-level, but L uses entropy map to weight target prediction at the pixel-level. In L , the image with larger entropy means harder to adapt and is assigned more weight. In contrast, the pixel with a smaller entropy value represents higher confidence and is more highlighted in L . Finally, our complete loss function L is formed by all the loss functions:</p><formula xml:id="formula_7">L = L + 1 L + 2 L + 3 L + L + L<label>(8)</label></formula><p>where 1 to 3 are trade-off parameters that weight the importance of the corresponding terms. And our optimization objective is to learn a target model G according to:</p><formula xml:id="formula_8">G = arg min min max L<label>(9)</label></formula><p>The full training procedure of our method consists of three steps: 1) jointly optimizing , , , and by semantic segmentation loss, edge loss, and two adversarial learning loss over the source and target domains; 2) generating pseudo labels and correspond entropy maps by over the target domain; 3) optimizing by uncertainty-adaptive self-supervised loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, following the common protocol of previous works <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b40">41]</ref>, we conduct experiments on the two-challenging syntheticto-real unsupervised domain adaptation tasks, i.e., GTAV?Cityscapes, and SYNTHIA?Cityscapes. Specifically, we use GTAV or SYNTHIA datasets with pixel-level annotations as the source domain and Cityscapes dataset without any annotations as the target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>Cityscapes is a real-world urban scene image dataset, which provides 3975 images, each of which has a resolution of 2048?1024, collected from 50 cities in Germany <ref type="bibr" target="#b8">[9]</ref>. Following the standard protocols <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b40">41]</ref>, we use the 2975 images from Cityscapes dataset training set as the unlabeled target domain for training, and evaluate our method on the 500 images from the validation set.</p><p>GTAV is a large synthetic dataset containing 24966 high quality labeled urban scene images with a resolution of 1914?1052 from open-world computer games, Grand Theft Auto V <ref type="bibr" target="#b33">[34]</ref>. The 19 compatible semantic classes between GTAV and Cityscapes are selected in the experiment.</p><p>SYNTHIA is another synthetic urban scene dataset <ref type="bibr" target="#b34">[35]</ref>. Following previous works, we use the SUNTHIA-RAND-CITYSCAPES subset that contains 9400 annotated images with a resolution of 1280?760 and shares 16 semantic classes with Cityscapes. In the training stage, we consider the 16 common classes with the Cityscapes. In the evaluation stage, 16-and 13-class subsets are used to make quantitative assessment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>All the experiments in this paper 1 are implemented with Pytorch in a single NVIDIA GTX 1080Ti GPU. Limited by the GPU memory, during the training stage, the resolution of Cityscapes images is resized to 1024?512, and that of GTAV images is resized to 1280?720. The resolution of SYNTHIA images remains unchanged. For the sake of fair comparison, like most of the state-of-the-art methods, we do not use any data augment technique.</p><p>For the semantic stream , following most of the state-of-theart methods, we use ResNet-101 architecture <ref type="bibr" target="#b12">[13]</ref> with pretrained parameters from ImageNet <ref type="bibr" target="#b10">[11]</ref>. The implementation of edge stream follows the work <ref type="bibr" target="#b36">[37]</ref>. is mainly composed of three residual blocks, and each block is followed by a gated convolutional layer, ensuring only processes edge related information. For the discriminator , we apply the same architecture used in <ref type="bibr" target="#b40">[41]</ref>. For the discriminator , we adopt a simple structure consisting of three 4?4 convolutional layers with a stride of 2, and one 1?1 convolutional layer. Except for the last layer, each convolutional layer is followed by a Leaky-ReLU with a slope of 0.2.</p><p>To verify the robustness of our method, the hyper-parameters keep the same in both tasks. For our joint loss, the values of 1 to 3 are set as 1 ?3 , 20, and 1 ?3 , respectively. The weight factor in entropy reweighting adversarial loss is set to 10. In terms of the whole architecture training, the SGD optimizer with a learning rate of 2.5 ?4 , momentum of 0.9, and a weight decay of 5 ?4 is utilized to train and . Two Adam optimizers with a learning rate of 1 ?4 are used for training and , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance Comparison</head><p>In this subsection, we compare our proposed method with the existing state-of-the-art methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref><ref type="bibr" target="#b50">[51]</ref>. For the sake of fairness, all the reported methods use ResNet-101 as the backbone network and the data augment <ref type="table">Table 1</ref>: Evaluation results of semantic segmentation by adapting from GTAV to Cityscapes. The mechanism "T", "A", and "S" mean image translation, adversarial training, and self-supervised learning, respectively. The best results are highlighted in bold.  <ref type="table">Table 2</ref>: Evaluation results of semantic segmentation by adapting from SYNTHIA to Cityscapes. The mechanism "T", "A", and "S" mean image translation, adversarial learning, and self-supervised learning, respectively. We show the mIoU (%) of the 13 classes (mIoU*) excluding classes with "*". "-" represents the method does not report the corresponding experimental result. The best results are highlighted in bold. technique is not used. The per-class Intersection-Over-Union (IoU) and mean IoU (mIoU) are adopted as the evaluation criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GTAV?Cityscapes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SYNTHIA?Cityscapes</head><p>GTAV to Cityscapes. <ref type="table">Table 1</ref> displays the comparison results from GTAV to Cityscapes. First, all domain adaptation methods outperform the model without domain adaptation (SourceOnly) by large performance margins. Then, our method has the best mIoU 52.8%, which is significantly better than that of the compared stateof-the-art methods. Compared with some adversarial training and self-supervised learning methods, such as CLAN and PyCDA, our method improves by 9.6% and 5.4% mIoU and has significant gains in almost all classes. Moreover, some methods also combine the adversarial learning or image translation with self-supervised learning and achieve decent performance, like FDA, DAST, and UDACT. Compared to these methods, our approach still has a significant improvement. <ref type="figure">Figure 3</ref> presents some qualitative results 2 produced by our methods. SYNTHIA to Cityscapes. <ref type="table">Table 2</ref> reports the comparison results on the SYNTHIA?Cityscapes task. Like the previous work, we also report two mIoU metrics: 13 classes of mIoU* and 16 classes of mIoU. According to <ref type="table">Table 2</ref>, it is obvious that our proposed method   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Discussion</head><p>We further report the ablation study results to demonstrate the performance contribution of each element in our proposed method in <ref type="table" target="#tab_3">Table 3</ref>. It can be seen that each element contributes to the final success of the adaptation. The proposed method outperforms the "Baseline" by +7.7% and +6.9% with GTAV and SYNTHIA as the source, respectively. Specifically, our proposed image-level entropy reweighting methods can enhance the model adaptation ability in the hard samples, thereby improving performance by 1.2% and 0.6%. Besides, weight factor is an important parameter for the entropy reweighting adversarial loss, which controls the extra adaptation degree to hard samples, we evaluate the performance of the semantic stream with different on the GTAV?Cityscapes task, as shown in <ref type="table" target="#tab_4">Table 4</ref>. When =0, the loss is equal to the standard adversarial loss. As increases, the loss of high-entropy samples (i.e., hard samples) is enlarged and hard samples could get better adaptation. However, if is too large, the network could merely focus on the adaptation of  <ref type="figure">Figure 6</ref>: A-distance of semantic and edge feature representations on the two tasks.</p><p>hard samples, which may damage the adaptation performance in easy samples. Subsequently, utilizing low-level edge information can further enhance adaptation performance and lead to a large performance boost. Since the small domain gap in low-level edge features can be narrowed to some extent by semantic adversarial learning, using an independent edge stream to generate semantic boundaries and align the target prediction maps with them can improve mIoU by 2.1% and 1.9%. After explicitly performing adversarial learning for edge information, the mIoU get further improved by 0.8% and 0.7%. This obvious performance improvement (+2.9% and +2.6%) clearly demonstrates our argument. <ref type="figure">Figure 4</ref> illustrates some produced semantic boundary maps. Obviously, through adversarial learning, the small inter-domain gap in edge features get further narrowed, thereby producing more accurate semantic boundaries. Then, in <ref type="figure" target="#fig_2">Figure 5</ref>, we additionally give a contrastive analysis between semantic feature distributions without and with the guide of edge information by t-SNE <ref type="bibr" target="#b39">[40]</ref>, which reveals that our edge consistency loss can enforce the alignment of semantic features, leading to clearer and more discriminative clusters over the target domain.</p><p>To further verify our argument, we display A-distance [2] of semantic features and edge features in <ref type="figure">Figure 6</ref>, which is a commonly used metric for measuring domain discrepancy. Since it is difficult to compute the exact A-distance, a proxy distance is defined a?</p><formula xml:id="formula_9">A = 2(1 ? 2 ) [2]</formula><p>, where is the generalization error of a classifier (SVM in this paper) trained on the binary problem of distinguishing samples between the source and target domains. From <ref type="figure">Figure 6</ref>, we could see that?A on edge features is obviously smaller than?A on semantic features, which proves that low-level edge information has a smaller inter-domain gap. After performing semantic adversarial learning, the?A on semantic features is reduced. Moreover, the?A on semantic features become smaller through the guide of edge information, which verifies that edge information can be explicitly used to facilitate the transfer of semantic information.</p><p>Lastly, through UASL, the mIoU performance of the proposed method reaches 52.8% and 48.1%. In addition, we also compare UASL to the standard SL method with three commonly used thresholds:</p><p>= 0 [32], = 0.5 <ref type="bibr" target="#b26">[27]</ref>, and = 0.9 <ref type="bibr" target="#b17">[18]</ref>. The relevant results are reported in <ref type="table" target="#tab_5">Table 5</ref>. We could see that the threshold of generating pseudo-label significantly affects the performance of standard SL. And different domain adaptation tasks may have diverse optimal thresholds. It is difficult to choose a suitable threshold. In contrast, our UASL does not need to select a threshold. It can fully utilize target label information, adaptively pay large weights to high-confident pixels and suppress the effects of low-confident pixels, thereby obtaining better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we present a new domain adaptation approach by leveraging the low-level edge information that is easy to adapt to guide the transfer of high-level semantic information. Specifically, we propose a semantic-edge domain adaptation architecture. The semantic stream adopts the existing entropy adversarial learning approach. To better adapt hard target samples, an entropy reweighting method is presented to make the network pay more attention to hard samples. The edge stream can produce semantic boundaries. To make the target predicted boundaries more precise, adversarial learning is performed on the edge stream. For the purpose of explicitly guiding the transfer of semantic features, an edge consistency loss function is presented to ensure the consistency between the target semantic map and boundary map. Lastly, an uncertainty-adaptive self-supervised learning is proposed to further fit the distribution of the target domain. The experimental results in the two UDA segmentation scenarios from synthetic to real demonstrate that our method obtains better results than the existing state-of-the-art works.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Qualitative results on the GTAV?Cityscapes task. (a) Input images from Cityscapes. (b) Segmentation results without domain adaptation. (c) Segmentation results of the proposed method.(d) Ground truth. Illustrations of produced boundary maps. (a) Input images from Cityscapes. (b) Semantic boundary maps without adversarial learning. (c) Semantic boundary maps with adversarial learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>The t-SNE visualization of embedded semantic features over the target domain. (a) Features without the guide of edge information. (b) Features with the guide of edge information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Entropy map Target image Source flow Target flow Concat Discriminator Pixel-wise sum Pixel-wise product ? Target prediction Source prediction D sem Source edge map Target edge map ?</head><label></label><figDesc><ref type="bibr" target="#b36">37]</ref> for edge detection. A gated convolutional layer is introduced in to ensure that only processes edge-relevant information. Specifically, takes the output of the first convolutional layer of as input and aims to yield precise semantic boundary maps B and B . To this end, is first trained by minimizing binary cross-entropy loss L</figDesc><table><row><cell>Semantic Stream G sem</cell><cell></cell><cell>adv sem ?</cell><cell></cell></row><row><cell></cell><cell></cell><cell>seg sem ?</cell><cell></cell></row><row><cell>Source image</cell><cell></cell><cell></cell><cell>Source label</cell></row><row><cell></cell><cell></cell><cell>st ?</cell><cell></cell></row><row><cell></cell><cell></cell><cell>??</cell><cell></cell></row><row><cell></cell><cell></cell><cell>con eg ?</cell><cell></cell></row><row><cell></cell><cell></cell><cell>seg eg ?</cell><cell></cell></row><row><cell>Edge Stream G eg</cell><cell>D eg</cell><cell>adv eg ?</cell><cell>Source semantic boundary</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>27.3 76.9 19.1 21.1 27.0 32.1 18.5 81.2 14.5 72.4 55.4 21.6 62.9 29.4 8.4 2.4 24.2 35.0 36.5 Ours AS 94.0 61.8 85.8 29.2 32.5 35.4 40.6 43.3 87.2 43.9 84.4 63.8 29.1 88.7 46.0 49.9 0.0 43.7 49.9 52.8</figDesc><table><row><cell>Methods</cell><cell>Mech.</cell><cell>road</cell><cell>sidewalk</cell><cell>building</cell><cell>wall</cell><cell>fence</cell><cell>pole</cell><cell>light</cell><cell>sign</cell><cell>veg.</cell><cell>terrain</cell><cell>sky</cell><cell>person</cell><cell>rider</cell><cell>car</cell><cell>truck</cell><cell>bus</cell><cell>train</cell><cell>mbike</cell><cell>bike</cell><cell>mIoU</cell></row><row><cell cols="22">AdaSegNet [38] A 86.5 36.0 79.9 23.4 23.3 23.9 35.2 14.8 83.4 33.3 75.6 58.5 27.6 73.7 32.5 35.4 3.9 30.1 28.1 42.4</cell></row><row><cell>ADVENT [41]</cell><cell cols="21">A 89.4 33.1 81.0 26.6 26.8 27.2 33.5 24.7 83.9 36.7 78.8 58.7 30.5 84.8 38.5 44.5 1.7 31.6 32.4 45.5</cell></row><row><cell>CLAN [31]</cell><cell cols="21">A 87.0 27.1 79.6 27.3 23.3 28.3 35.5 24.2 83.6 27.4 74.2 58.6 28.0 76.2 33.1 36.7 6.7 31.9 31.4 43.2</cell></row><row><cell cols="22">AdaptPatch [39] A 92.3 51.9 82.1 29.2 25.1 24.5 33.8 33.0 82.4 32.8 82.2 58.6 27.2 84.3 33.4 46.3 2.2 29.5 32.3 46.5</cell></row><row><cell>PyCDA [27]</cell><cell cols="21">S 90.5 36.3 84.4 32.4 28.7 34.6 36.4 31.5 86.8 37.9 78.5 62.3 21.5 85.6 27.9 34.8 18.0 22.9 49.3 47.4</cell></row><row><cell>CCM [24]</cell><cell cols="21">S 93.5 57.6 84.6 39.3 24.1 25.2 35.0 17.3 85.0 40.6 86.5 58.7 28.7 85.8 49.0 56.4 5.4 31.9 43.2 49.9</cell></row><row><cell>FDA [50]</cell><cell cols="21">TS 92.5 53.3 82.4 26.5 27.6 36.4 40.6 38.9 82.3 39.8 78.0 62.6 34.4 84.9 34.1 53.1 16.9 27.7 46.4 50.4</cell></row><row><cell>IntraDA [32]</cell><cell cols="21">AS 90.6 37.1 82.6 30.1 19.1 29.5 32.4 20.6 85.7 40.5 79.7 58.7 31.1 86.3 31.5 48.3 0.0 30.2 35.8 46.3</cell></row><row><cell>FADA [43]</cell><cell cols="21">AS 91.0 50.6 86.0 43.4 29.8 36.8 43.4 25.0 86.8 38.3 87.4 64.4 38.0 85.2 31.6 46.1 6.5 25.4 37.1 50.1</cell></row><row><cell>DAST [51]</cell><cell cols="21">AS 92.2 49.0 84.3 36.5 28.9 33.9 38.8 28.4 84.9 41.6 83.2 60.0 28.7 87.2 45.0 45.3 7.4 33.8 32.8 49.6</cell></row><row><cell>BDL [26]</cell><cell cols="21">TAS 91.0 44.7 84.2 34.6 27.6 30.2 36.0 36.0 85.0 43.6 83.0 58.6 31.6 83.3 35.3 49.7 3.3 28.8 35.6 48.5</cell></row><row><cell>TIR [18]</cell><cell cols="21">TAS 92.9 55.0 85.3 34.2 31.1 34.9 40.7 34.0 85.2 40.1 87.1 61.0 31.1 82.5 32.3 42.9 0.3 36.4 46.1 50.2</cell></row><row><cell>LDR [49]</cell><cell cols="21">TAS 90.8 41.4 84.7 35.1 27.5 31.2 38.0 32.8 85.6 42.1 84.9 59.6 34.4 85.0 42.8 52.7 3.4 30.9 38.1 49.5</cell></row><row><cell>UDACT [23]</cell><cell cols="21">TAS 95.3 65.1 84.6 33.2 23.7 32.8 32.7 36.9 86.0 41.0 85.6 56.1 25.9 86.3 34.5 39.1 11.5 28.3 43.0 49.6</cell></row><row><cell>SourceOnly</cell><cell cols="2">-64.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Ablation study of the proposed method in terms of mIoU (%) on the two tasks. Here, "Baseline" represents the original adversarial learning without entropy reweighting.</figDesc><table><row><cell cols="2">Baseline L</cell><cell>L</cell><cell>L</cell><cell>L</cell><cell cols="2">GTAV SYNTHIA</cell></row><row><cell>?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>45.1</cell><cell>41.2</cell></row><row><cell>?</cell><cell>?</cell><cell></cell><cell></cell><cell></cell><cell>46.3</cell><cell>41.8</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell></cell><cell>48.4</cell><cell>43.7</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell>49.2</cell><cell>44.4</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>52.8</cell><cell>48.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Parameter analysis of the weighting factor for the entropy reweighting adversarial loss in terms of mIoU (%).</figDesc><table><row><cell></cell><cell cols="3">GTAV?Cityscapes</cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>1</cell><cell>5</cell><cell>10</cell><cell>15</cell><cell>20</cell><cell>30</cell></row><row><cell cols="7">mIoU 45.1 45.2 45.8 46.3 46.0 45.3 43.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Comparison of the proposed UASL and standard self-supervised learning method with different thresholds in terms of mIoU (%).</figDesc><table><row><cell cols="2">SL Type</cell><cell cols="2">GTAV SYNTHIA</cell></row><row><cell></cell><cell>= 0</cell><cell>51.3</cell><cell>47.1</cell></row><row><cell>SL</cell><cell>= 0.5</cell><cell>52.2</cell><cell>47.6</cell></row><row><cell></cell><cell>= 0.9</cell><cell>52.5</cell><cell>47.4</cell></row><row><cell></cell><cell>UASL</cell><cell>52.8</cell><cell>48.1</cell></row><row><cell cols="4">can outperform other state-of-the-art methods on both 13-class and</cell></row><row><cell cols="4">16-class with mIoU of 55.9% and 48.1%. In summary, these results</cell></row><row><cell cols="4">obtained on both tasks reveal the effectiveness and superiority of</cell></row><row><cell cols="4">our architecture in learning domain-invariant representations for</cell></row><row><cell cols="3">UDA in semantic segmentation.</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The source code will be made publicly available.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">For more qualitative results, please see the supplementary materials.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">137</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The lov?szsoftmax loss: A tractable surrogate for the optimization of the intersection-overunion measure in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amal</forename><forename type="middle">Rannen</forename><surname>Triki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">B</forename><surname>Blaschko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4413" to="4421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongruixuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangpei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.09225</idno>
		<title level="m">DSDANet: Deep Siamese Domain Adaptation Convolutional Neural Network for Cross-domain Change Detection</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Change Detection in Multisource VHR Images via Deep Siamese Convolutional Multiple-Layers Recurrent Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongruixuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangpei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="2848" to="2864" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic image segmentation with task-specific edge detection using cnns and a discriminatively trained domain transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4545" to="4554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="834" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Self-ensembling with gan-based data augmentation for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taekyung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changick</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6830" to="6840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Instance-aware semantic segmentation via multi-task network cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3150" to="3158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Context-aware Feature Generation for Zero-shot Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangxuan</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqing</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACMMM</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1921" to="1929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.02649</idno>
		<title level="m">Fcns in the wild: Pixel-level adversarial and constraint-based adaptation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<title level="m">Categorical reparameterization with gumbel-softmax</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Resource Efficient Domain Adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junguang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ximei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACMMM</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2220" to="2228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning texture invariant representation for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeongjin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeran</forename><surname>Byun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12975" to="12984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6129" to="6138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficient inference in fully connected crfs with gaussian edge potentials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vladlen Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gradientbased learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised Domain Adaptation for Semantic Segmentation by Content Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suhyeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhyuk</forename><surname>Hyun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongje</forename><surname>Seong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Euntai</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Contentconsistent matching for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangrui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="440" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Joint adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><forename type="middle">Harold</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binhui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACMMM</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="729" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6936" to="6945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Constructing self-motivated pyramid curriculums for cross-domain semantic segmentation: A non-adversarial approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengmao</forename><surname>Lv</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6758" to="6767" />
		</imprint>
	</monogr>
	<note>Lixin Duan, and Boqing Gong</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dynamic Extension Nets for Few-shot Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACMMM</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1441" to="1449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML. PMLR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="97" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2507" to="2516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Seokju Lee, and In So Kweon. 2020. Unsupervised Intra-domain Adaptation for Semantic Segmentation through Self-Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inkyu</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Rameau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page" from="3764" to="3773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Current methods in medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dzung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyang</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry</forename><forename type="middle">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Prince</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of biomedical engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="315" to="337" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Stephan R Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koltun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="102" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Sellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio M</forename><surname>Lopez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3234" to="3243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning from synthetic images via active pseudo-labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangchen</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lefei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="6452" to="6465" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Gatedscnn: Gated shape cnns for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Towaki</forename><surname>Takikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Acuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5229" to="5238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7472" to="7481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Domain adaptation for structured output via discriminative patch representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1456" to="1465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himalaya</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2517" to="2526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Dada: Depth-aware domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himalaya</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7364" to="7373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Classes Matter: A Fine-grained Adversarial Approach to Cross-domain Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling-Yu</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="642" to="659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Temporal segment networks: Towards good practices for deep action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="20" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Objectnessaware semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACMMM</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="307" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised Change Detection in Multitemporal VHR Images Based on Deep Kernel PCA Convolutional Mapping Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongruixuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangpei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">March on Data Imperfections: Domain Division and Domain Generalization for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongtao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Jun</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sun-Ao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACMMM</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3044" to="3053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Self-ensembling attention networks: Addressing domain shift for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lefei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoli</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangpei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AAAI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5581" to="5588" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Label-driven reconstruction for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhi</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinliang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="480" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Fda: Fourier domain adaptation for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4085" to="4095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">DAST: Unsupervised Domain Adaptation in Semantic Segmentation Based on Discriminator Attention and Self-Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hexin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">A curriculum domain adaptation approach to the semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Foroosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1823" to="1841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Fully convolutional adaptation networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaofan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6810" to="6818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Instance-level segmentation for autonomous driving with deep densely connected mrfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="669" to="677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2223" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deep unsupervised convolutional domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbao</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weigang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACMMM</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="261" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation with dual-scheme fusion network for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danbing</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qikui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pingkun</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3291" to="3298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Bvk Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="289" to="305" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
