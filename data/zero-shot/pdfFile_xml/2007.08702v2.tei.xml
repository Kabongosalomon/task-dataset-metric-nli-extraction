<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DACS: Domain Adaptation via Cross-domain Mixed Sampling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilhelm</forename><surname>Tranheden</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Chalmers University of Technology</orgName>
								<address>
									<settlement>Gothenburg</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Volvo Cars</orgName>
								<address>
									<settlement>Gothenburg</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Olsson</surname></persName>
							<email>viktor.olsson.3@volvocars.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Chalmers University of Technology</orgName>
								<address>
									<settlement>Gothenburg</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Volvo Cars</orgName>
								<address>
									<settlement>Gothenburg</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliano</forename><surname>Pinto</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Chalmers University of Technology</orgName>
								<address>
									<settlement>Gothenburg</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lennart</forename><surname>Svensson</surname></persName>
							<email>lennart.svensson@chalmers.se</email>
							<affiliation key="aff0">
								<orgName type="institution">Chalmers University of Technology</orgName>
								<address>
									<settlement>Gothenburg</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DACS: Domain Adaptation via Cross-domain Mixed Sampling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Semantic segmentation models based on convolutional neural networks have recently displayed remarkable performance for a multitude of applications. However, these models typically do not generalize well when applied on new domains, especially when going from synthetic to real data. In this paper we address the problem of unsupervised domain adaptation (UDA), which attempts to train on labelled data from one domain (source domain), and simultaneously learn from unlabelled data in the domain of interest (target domain). Existing methods have seen success by training on pseudo-labels for these unlabelled images. Multiple techniques have been proposed to mitigate low-quality pseudolabels arising from the domain shift, with varying degrees of success. We propose DACS: Domain Adaptation via Crossdomain mixed Sampling, which mixes images from the two domains along with the corresponding labels and pseudolabels. These mixed samples are then trained on, in addition to the labelled data itself. We demonstrate the effectiveness of our solution by achieving state-of-the-art results for GTA5 to Cityscapes, a common synthetic-to-real semantic segmentation benchmark for UDA. arXiv:2007.08702v2 [cs.CV] 29 Nov 2020</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">DACS</head><p>Our proposed solution builds on the idea of mixing images across domains. New, augmented samples are created</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep neural networks have significantly advanced the state of the art for the task of semantic segmentation <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b54">54]</ref>, displaying remarkable generalization abilities. Results have in large been presented for datasets where training and test domains are similar or identical in distribution. In real-world scenarios, however, a domain shift may occur, where the training data (source domain) is significantly different to the data encountered in inference (target domain) for the intended application. A common practice when dealing with domain shift is to annotate some data from the domain of interest and re-train (fine-tune) the network on this new data. Additionally, Semi-Supervised * Equal contribution.</p><p>Learning (SSL) methods for semantic segmentation have been proposed <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b29">29]</ref>, effectively training on a small amount of labelled data by relying on complementary learning from unlabelled data. These approaches are not always feasible as sometimes no annotations at all are accessible in the target domain.</p><p>Unsupervised Domain Adaptation (UDA) deals with the problem where labelled data is available for a source domain, but only unlabelled data is available for the target domain. The field has generated a lot of interest due to its potential for effectively utilizing synthetic data in training deep neural networks. Semantic segmentation in particular has been explored in recent research <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b53">53,</ref><ref type="bibr" target="#b60">60,</ref><ref type="bibr" target="#b61">61,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b55">55,</ref><ref type="bibr" target="#b56">56]</ref> due to its potential benefits in applications such as autonomous driving, where the associated annotation cost is high and we may prefer to generate cheap synthetic data.</p><p>A technique originally proposed for SSL is pseudolabelling <ref type="bibr" target="#b19">[19]</ref> (or self-training); training on artificial targets based on the class predictions of the network. Pseudolabelling was later adapted to UDA <ref type="bibr" target="#b60">[60,</ref><ref type="bibr" target="#b61">61,</ref><ref type="bibr" target="#b56">56]</ref>, where certain modifications were introduced to compensate for the domain shift. One of the earlier works on pseudo-labelling for UDA <ref type="bibr" target="#b60">[60]</ref> pointed out that pseudo-labelling naively applied to UDA tends to bias the predictions of the network to easy-to-predict classes, causing difficult classes to stop being predicted during training. To combat this collapse, they propose class-balanced sampling of the pseudo-labels. Additional difficulties of erroneous pseudo-labels, owing to the domain shift, have prompted later research to add modules for uncertainty estimation <ref type="bibr" target="#b61">[61,</ref><ref type="bibr" target="#b56">56]</ref>. We note that in existing methods for correcting erroneous pseudo-labels, certain images in the target domain are over-sampled, and low confidence pixels within images filtered out. Many pixels of low confidence are aligned with predictions at semantic boundaries <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b59">59,</ref><ref type="bibr" target="#b29">29]</ref>, thus leading to a diminished training signal there. Circumventing these issues offers an opportunity to better leverage available data in the target domain.</p><p>In this paper we propose Domain Adaptation via Crossdomain mixed Sampling, or DACS for short. The key idea here is that we form new, augmented samples by mixing pairs of images from different domains. In particular, we use the ground-truth semantic map to extract a few classes from a source domain image and paste them onto an unlabelled target domain image. To construct pseudo-labels for the new image, we mix the source domain labels with pseudo-labels created from the target domain image. Mixing across domains this way leads to parts of the pseudolabels being replaced by parts of the ground-truth semantic maps, ensuring that over the course of training all classes will border pixels from the other domain.</p><p>Our method is inspired by recently proposed methods of using mixed samples for SSL <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b29">29]</ref>, and we show that applying the naive implementation of these methods directly to UDA causes classes to become conflated, i.e., certain classes are confused with others, similarly to the previously mentioned findings in <ref type="bibr" target="#b60">[60]</ref> for naive pseudo-labelling. This problem is effectively solved by the cross-domain mixing in DACS. In contrast to existing methods for correcting erroneous pseudo-labels, we do not get rid of training data from over-sampling by class or confidence, and are able to efficiently learn from the entire unlabelled target domain dataset during the course of training. We demonstrate the effectiveness of our method by applying it on two syntheticto-real unsupervised domain adaptation benchmarks, GTA5 ? Cityscapes and SYNTHIA ? Cityscapes.</p><p>In summary, our main contributions are: (1) We introduce an algorithm that mixes images from the target domain with images from the source domain, creating new, highly perturbed samples and use these for training. <ref type="bibr" target="#b1">(2)</ref> We show that mixing of images across domains to a high degree solves the problem of conflating classes. (3) We present improvements over the state of the art in UDA for the GTA5 ? Cityscapes benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>For semantic segmentation, predominant methods for UDA include adversarial-based <ref type="bibr" target="#b36">[36]</ref>, self-training <ref type="bibr" target="#b60">[60,</ref><ref type="bibr" target="#b61">61,</ref><ref type="bibr" target="#b56">56]</ref> and consistency-based approaches <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b57">57]</ref>. This section reviews these related UDA methods in more detail, as well as some of their counterparts in SSL, as the two tasks are closely related. For a more extensive review of UDA in semantic segmentation, see <ref type="bibr" target="#b34">[34]</ref>.</p><p>Domain alignment. A lot of existing research in UDA has focused on various aspects of adversarial learning in order to bridge the gap existing between source and target domains, minimizing differences between the distributions. This can be targeted at different levels such as at the pixel level <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b44">44]</ref>, feature map level <ref type="bibr" target="#b48">[48,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b58">58,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b52">52]</ref> or semantic level <ref type="bibr" target="#b36">[36,</ref><ref type="bibr" target="#b38">38]</ref>. In particular, alignment on the semantic level has been explored with similar methods for both UDA <ref type="bibr" target="#b36">[36]</ref> and SSL <ref type="bibr" target="#b16">[16]</ref>. The key idea is viewing the segmentation network as a generator in a generative adversarial network setup, to encourage realistic semantic maps to be predicted. This approach is viable for UDA because even though the source and target domain images are quite different, it is often reasonable to assume that the corresponding semantic maps are similar in terms of spatial layout and local context. Our proposed method should also benefit from this similarity in output space, since mixing images across domains will then lead to semantic classes being placed in contexts with more similar semantics.</p><p>Other approaches to aligning the source and target domains include channel-wise alignment of feature maps <ref type="bibr" target="#b41">[41]</ref>, done differently for "stuff" classes and "things" classes in <ref type="bibr" target="#b39">[39]</ref>, transfer of texture from target to source <ref type="bibr" target="#b18">[18]</ref>, and transfer of the low-frequency part of the spectrum in Fourier space from the target domain to the source domain <ref type="bibr" target="#b47">[47]</ref>.</p><p>Pseudo-labelling. In contrast, methods based on pseudolabelling <ref type="bibr" target="#b19">[19]</ref>, or self-training, directly train on the target domain data by the use of pseudo-labels, which are artificial targets for training, created from class predictions of the network. However, UDA problems characteristically suffer from large domain gaps, i.e., considerable differences in data distributions, which give rise to faulty pseudo-labels. One of the problems is a bias in the target domain towards initially easy-to-transfer classes <ref type="bibr" target="#b60">[60,</ref><ref type="bibr" target="#b61">61]</ref>, where some classes are merged, meaning certain classes are never predicted. A similar phenomenon has been observed in UDA for classification <ref type="bibr" target="#b40">[40]</ref>, where trivial predictions for the target domain were identified to occur when applying entropy regularization. For semantic segmentation, entropy regularization methods have observed a bias towards easy-totransfer classes <ref type="bibr" target="#b37">[37]</ref> as well.</p><p>The close connection between entropy regularization and pseudo-labelling was pointed out in the original proposal of pseudo-labelling <ref type="bibr" target="#b19">[19]</ref>. As pseudo-labelling and entropy regularization strive to minimize entropy in the predictions of unlabelled data, and since predictions with conflated, i.e., merged, classes have lower entropy, entropy minimization is a reasonable explanation for why conflation of classes can occur for large enough domain shifts. To combat the problem of faulty pseudo-labels for UDA in semantic segmentation, existing works have suggested careful selection and adjustment procedures, accounting for the domain gap. Variants include specialised sampling <ref type="bibr" target="#b60">[60,</ref><ref type="bibr" target="#b27">27]</ref> and handling of uncertainty <ref type="bibr" target="#b61">[61,</ref><ref type="bibr" target="#b56">56]</ref>.</p><p>Our proposed solution also makes use of pseudolabelling, while cross-domain mixing of samples offers a simple solution to the class conflation problem by injecting reliable entropy from the source domain ground-truth labels into the pseudo-labels of the target domain. Even though we make use of pseudo-labels generated from unper-turbed images from the target domain, they are only used for training after images and labels are mixed across domains. Therefore, we categorize our approach along another line of methods, namely consistency regularization, which is consistent with related SSL methods.</p><p>Consistency Regularization. The key idea behind consistency regularization is that predictions on unlabelled samples should be invariant to perturbations. In SSL the perturbations have typically been based on image augmentations <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b17">17]</ref>. For UDA this technique has instead been used to complement minimization of distribution discrepancies on an image level, with consistency based around image-to-image translations <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b57">57]</ref>.</p><p>Mixing. The kind of augmentation technique known as mixing has successfully been used for both classification and semantic segmentation <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b33">33]</ref>. The idea is to combine pixels from two training images, thereby creating a new, highly perturbed, sample. This can be done by interpolating between the pixel values of the two images, as suggested by Zhang et al. in their mixup algorithm <ref type="bibr" target="#b50">[50]</ref>. It can also be done by having one set of pixels coming from one image and another set coming from a second image. In the latter method, the selection of pixels can be quantified by a binary mask, where the mask is one for the pixels selected from the first image and zero for pixels selected from the second image. For the case of semantic segmentation, the same mixing is also performed on the segmentation maps.</p><p>Mixing has proven to be successful in SSL for semantic segmentation, where the strong augmentations are used on unlabelled images for consistency regularization. Kim et al. <ref type="bibr" target="#b17">[17]</ref> and French et al. <ref type="bibr" target="#b10">[11]</ref> use the binary mixing method CutMix, proposed by Yun et al. <ref type="bibr" target="#b49">[49]</ref>, where a rectangular region is cut from one image and pasted on top of another. This technique was further developed in the ClassMix algorithm <ref type="bibr" target="#b29">[29]</ref>, where the mask used for mixing is instead created dynamically based on the predictions of the network. Specifically, the algorithm selects half of the classes predicted for a given image, and the corresponding pixels are pasted onto a second image, forming a strongly perturbed image, in which the semantic borders of objects are still being followed to a high degree.</p><p>Our proposed method, DACS, adapts this technique to mix images across domains. This differs from existing consistency-based approaches for UDA in that we do not attempt to combine consistency regularization with alignment of image distributions, instead, we enforce consistency between predictions of images in the target domain and images mixed across domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>This section details our proposed approach for unsupervised domain adaptation: Domain Adaptation via Crossdomain mixed Sampling, or DACS for short. We start in Section 3.1 by discussing the pitfalls of applying mixingbased consistency regularization as used for SSL directly to UDA, that is, mixing images only within the unlabelled dataset. In Section 3.2 we then describe our solution DACS and explain how it solves these problems. We then conclude with a description of the loss function and the training procedure used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Naive Mixing to UDA</head><p>As stated previously, in the original formulation of consistency regularization based on mixing for SSL <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b29">29]</ref>, samples are mixed within the unlabelled dataset to generate augmented images. In UDA, the unlabelled samples are the ones from the target dataset, so a natural adaptation to this context would be to mix target-domain images. This approach, henceforth referred to as "Naive Mixing", mixes target-domain samples to generate augmented images and corresponding pseudo-labels and then trains the network using both the augmented images and the source-domain images, as illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>However, this intuitive adaptation performs poorly in practice, as shown in the experiments in Section 4. The resulting segmentation network conflates some of the classes when predicting the semantics of target-domain images. For instance, classes with fewer occurrences like 'sidewalk' are confused with more frequent and semantically similar classes, like 'road'. Similarly, the 'rider' class is misclassified as 'person', and 'terrain' as 'vegetation', among other classes. This seems to be a consistent pattern across different seeds of training, and impacts performance considerably. The problem occurs exclusively for the target domain images, not for the images in the source domain.</p><p>This problem, which we refer to as class conflation, is similar to one identified in early works applying pseudolabelling to UDA for semantic segmentation tasks <ref type="bibr" target="#b60">[60]</ref>, where they point out a bias towards easy-to-transfer classes when applying pseudo-labelling naively to UDA. Using pseudo-labelling in a consistency regularization setting combined with mixing, as used for SSL in <ref type="bibr" target="#b29">[29]</ref>, inherits the same underlying issues. While existing works have proposed other improvements for how to correct erroneous pseudo-label generation arising due to the domain shift <ref type="bibr" target="#b60">[60,</ref><ref type="bibr" target="#b61">61,</ref><ref type="bibr" target="#b56">56]</ref>, we instead propose a change in the augmentation procedure, detailed in the next subsection. by having one set of pixels coming from a source domain image, and one set of pixels coming from a target domain image. These new samples are then used to train the network. By default we are using the mixing strategy ClassMix <ref type="bibr" target="#b29">[29]</ref>, but any mixing method based on binary masks would be valid. In our adaptation of ClassMix, half of the classes in a source domain image are selected, and the corresponding pixels are cut out and pasted onto an image from the target domain. To construct the corresponding image with pseudo-labels, the target domain image is also run through the network before the mixing in order to produce a pseudolabel for it. This pseudo-label is then mixed in the same way as the image, together with the corresponding ground-truth label from the source domain image. A diagram explaining the mixing procedure is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. An example of the input images and the resulting augmentation is illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>. Note that the resulting mixed images are not necessarily realistic. However, complete realism of the augmentations is not required for the functioning of our method, as shown by the results in Section 4.</p><p>The proposed cross-domain mixing greatly improves performance compared to Naive Mixing. Before introducing cross-domain mixing, we have two types of data: 1) source domain data with ground-truth labels, and 2) target domain data with potentially conflated pseudo-labels, where the gap between the domains may be large. Due to this potentially large gap, a network may implicitly learn to discern between the domains in order to perform better in the task, and (incorrectly) learn that the class distributions are very different in the two domains. With cross-domain mixing, we introduce new data, and considering that the labels for these new images partly come from the source domain, they will not be conflated for entire images. Furthermore, the pixels that are pseudo-labelled (target-domain labels) and the pixels that have ground-truth labels (sourcedomain labels) may now be neighbors in an image, making the implicit discerning between domains unlikely, since it would have to be done at a pixel level. Both of these as-  pects help the network to better deal with the domain gap, and effectively solve the class conflation problem, as shown in Section 4, resulting in considerably better performance. The overall UDA algorithm that trains on source-domain images and cross-domain augmentations is what we refer to as DACS.</p><p>The implementation of DACS is presented as pseudocode in Algorithm 1, where the source-domain and target-domain datasets are referred to as D S and D T , respectively. A batch of images and labels, X S and Y S , is sampled from D S , and a batch of images, X T , from D T . The images in X T are then fed to the network f ? , which outputs their predicted semantic maps? T . Then, the augmented images X M are created by mixing X S and X T , and the pseudo-labels Y M by mixing the corresponding maps in Y S and? T . From this point forward, the algorithm resembles a supervised learning approach: compute predictions, compare them with the labels (in our case using the cross-entropy loss), perform backprogragation, and perform a step of gradient descent. This process is then repeated for a predetermined amount of iterations N .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Loss Function</head><p>In DACS, the network parameters ? are trained by minimizing the following loss:</p><formula xml:id="formula_0">L(?) = E H f ? (X S ), Y S + ?H f ? (X M ), Y M .<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 DACS algorithm</head><p>Require: Source-domain and target-domain datasets D S and D T , segmentation network f ? . 1: Initialize network parameters ? randomly. <ref type="bibr">2:</ref> for i = 1 to N do 3:</p><formula xml:id="formula_1">X S , Y S ? D S 4: X T ? D T 5:? T ? f ? (X T ) 6: X M , Y M ? Augmentation and pseudo-label from mixing X S , Y S , X T and? T . 7:? S ? f ? (X S ),? M ? f ? (X M )</formula><p>Compute predictions. <ref type="bibr" target="#b7">8</ref>:</p><formula xml:id="formula_2">? L(? S , Y S ,? M , Y M )</formula><p>Compute loss for the batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>Compute ? ? by backpropagation (treating Y M as constant.) <ref type="bibr">10:</ref> Perform one step of stochastic gradient descent on ?. 11: end for 12: return f ? where the expectation is over batches of random variables; X S , Y S , X M , and Y M . Images in X S are sampled uniformly from the source domain distribution, and Y S is the corresponding labels. Further, X M and Y M are the mixed images and pseudo-labels, created by performing crossdomain mixing between the images sampled uniformly at random from the source domain and those from the target domain, as explained above. Lastly, H is the cross-entropy between the predicted semantic maps and the corresponding labels (ground-truth or pseudo) averaged over all images and pixels, and ? is a hyper-parameter that decides how much the unsupervised part of the loss affects the overall training. In line with <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b29">29]</ref>, we use an adaptive schedule for ?, where it is the proportion of pixels, for each image, where the predictions of f ? on that image have a confidence above a certain threshold. Training is performed by stochastic gradient descent on the loss using batches with the same number of source-domain images and augmented images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In order to validate the proposed DACS algorithm, we evaluate it in two popular datasets for UDA and compare to the state of the art for these tasks. We also describe additional experiments related to the source of the class conflation problem, as well as the effect of the choice of mixing strategy. This section details the experimental setup and provides the qualitative and quantitative results found.</p><p>Implementation Details. For all the experiments in this paper, we adopt the widely used <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b53">53,</ref><ref type="bibr">Cityscapes</ref> GTA5 SYNTHIA <ref type="figure">Figure 4</ref>: Images from the Cityscapes, GTA5, and SYNTHIA datasets along with their corresponding semantic maps. <ref type="bibr" target="#b60">60,</ref><ref type="bibr" target="#b61">61,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b55">55,</ref><ref type="bibr" target="#b56">56,</ref><ref type="bibr" target="#b47">47,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b52">52]</ref> DeepLab-v2 framework <ref type="bibr" target="#b4">[5]</ref> with a ResNet101 backbone <ref type="bibr" target="#b13">[13]</ref> as our model. The backbone is pretrained on ImageNet [9] and on MSCOCO <ref type="bibr" target="#b22">[22]</ref>. Most hyper-parameters are identical to those used in <ref type="bibr" target="#b35">[35]</ref>. We use Stochastic Gradient Descent with Nesterov acceleration, and an initial learning rate of 2.5?10 ?4 , which is then decreased using polynomial decay with exponent 0.9 as in <ref type="bibr" target="#b4">[5]</ref>. Weight decay is set to 5?10 ?4 and momentum to 0.9. Source images are rescaled to 760 ? 1280 and target images to 512 ? 1024, after which random crops of size 512 ? 512 are extracted. For our main results we use ClassMix unless otherwise stated and in addition we also apply Color jittering and Gaussian blurring on the mixed images. We train using batches with 2 source images and 2 mixed images for 250k iterations. The code is implemented using PyTorch, and is available at https://github.com/vikolss/DACS. Experiments were performed using a GTX 1080 Ti GPU with 12 GB memory.</p><p>Datasets. We present results for two synthetic-to-real benchmarks common for UDA for semantic segmentation. Namely GTA5 ? Cityscapes and SYNTHIA ? Cityscapes. The target dataset Cityscapes has 2,975 training images taken from a car in urban environments and is labelled with 19 classes <ref type="bibr" target="#b7">[8]</ref>. The source datasets GTA5 <ref type="bibr" target="#b30">[30]</ref> and SYN-THIA <ref type="bibr" target="#b31">[31]</ref> contain 24,966 and 9,400 synthetic training images respectively. Example images of all three datasets are shown in <ref type="figure">Figure 4</ref> together with ground-truth semantic maps. The GTA5 images are labelled with the same 19 classes as Cityscapes whereas the SYNTHIA data is labelled with 16 of the 19 classes. All results are reported with the Intersection over Union (IoU) metric per class and the mean Intersection over Union (mIoU) over all classes, the standard performance metric for semantic segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">GTA5 ? Cityscapes Results</head><p>We present our results for GTA5 ? Cityscapes in <ref type="table">Table  1</ref>, alongside the results from several existing works on the same task. All of our comparisons have results for the same DeepLab-v2 network, but for completeness we choose to include their best presented performance, regardless of back- <ref type="table">Table 1</ref>: GTA5 to Cityscapes, our results are averages from three runs, and shown as per-class IoU and mIoU. We also compare to several previous works. We present results for DACS, as well as for training only on data from the source domain. - Source" refers to a model only trained on the source data and then evaluated on the target data, and serves as our baseline, and DACS refers to the results from our proposed method, which achieves the strongest results for seven of the individual classes, as well as an overall mIoU of 52.14%, higher than all previous methods, effectively pushing the state of the art for this task. Additionally, we also provide qualitative results for GTA5 ? Cityscapes. <ref type="figure">Figure 5</ref> illustrates predictions on a few Cityscapes frames, made by DACS as well as by a source model (a model trained only supervised on the source domain). In the same figure, predictions made by a model trained using the Naive mixing described in Section 3.1 are also presented. We can see that Naive Mixing performs better than the baseline, and DACS in turn outperforms Naive Mixing. This is also evident in <ref type="table" target="#tab_3">Table 3</ref> in Section 4.5, where results from Naive Mixing are shown. There, it is clear that some classes are conflated, for instance the 'sidewalk' class which obtains an IoU of almost 0%, since it's almost always confused with 'road', which is also visible in <ref type="figure">Figure 5</ref> </p><formula xml:id="formula_3">- - - - - - - - - - - - - - - - - -</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">SYNTHIA ? Cityscapes Results</head><p>For the SYNTHIA dataset, we also compare with the best reported performance of existing methods, regardless of network. Additionally, the SYNTHIA dataset only contains 16 of the 19 classes of Cityscapes, and some authors present results for these 16 classes while other present for only 13 of them. Because of these differences in benchmarking, we present results for both 13 and 16 classes for the DACS method. The results for the SYNTHIA dataset, computed with the same metrics (per-class IoU and mIoU) as the former dataset, are shown in <ref type="table" target="#tab_2">Table 2</ref>, alongside results from several other existing works.</p><p>When evaluating on all the 16 classes, DACS obtainis an mIoU of 48.34%, while also achieving the strongest perclass results for 4 out of the 16 classes. For the 13 class formulation, DACS obtains an mIoU of 54.81%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluation Conditions</head><p>Many existing methods in Tables 1 and 2, report their results from when using early stopping based on the same validation set that is used for the final evaluation (there is no publicly available test set for Cityscapes). We believe that this is not a fair evaluation, as a high performance on the validation set does not necessarily mean high performance on all data, but could just mean that the model is performing well on those exact images. Using early stopping in our case would increase the results substantially: for GTA5 it would increase to 35.68% for the baseline just trained on the source data and to 53.84% for the DACS results. For SYNTHIA, the source baseline would increase to 32.85%, and the results for 13 classes would increase to 55.98% and for 16 classes to 49.10%. The reason for the considerable performance increase from early stopping is that performance on the validation set fluctuates a lot over the course of training, rather than that the model is overfitting the training data.</p><p>Similarly, many existing methods in UDA report final results based on the top-performing model from sensitive hyper-parameter tuning on the aforementioned validation set. Reporting performance obtained after hyper-parameter tuning would skew results in the same way as reporting the highest among multiple experiments rather than averages, as one would then exploit the variance between hyperparameters. DACS was evaluated as an average of three runs, with a top performing model of 54.09% for GTA5, 55.21% for Synthia with 13 classes, and 49.07% for Syn-Image Ground-truth Source Naive Mixing DACS <ref type="figure">Figure 5</ref>: Qualitative results of validation images from Cityscapes, when training models on the GTA5 dataset. The Naive Mixing model is consistently conflating some classes, sidewalks, for instance, are classified as road for all images. This issue is not shared with DACS. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Similarity Between Source and Target</head><p>We note that our results increase more in relation to previous works for GTA5 ? Cityscapes than it does for SYNTHIA ? Cityscapes. We hypothesise that this depends on the similarity between the source and target data, namely that GTA5 images are more similar to Cityscapes than SYNTHIA images are. This is clearly helpful in UDA and particularly so when mixing images between domains, since the mixed images will be more sensible if objects end <ref type="bibr" target="#b0">1</ref> Excluded when calculating mIoU for 13 classes. up in locations that are reasonable. This can be quantified by the spatial distribution of classes: where in the images certain classes appear. Cityscapes and GTA5 are very similar in that road is always down, sky is always up and cars are always vertically near the center of the images. This is less the case for SYNTHIA, however, as the images are taken from different perspectives, including from the ground and from above. Hence, when pasting objects from SYNTHIA to Cityscapes, it is likely that the resulting images will be nonsensical, which we believe is detrimental for training. This means that the performance of DACS might not be as high for tasks with larger domain shifts. We leave the investigation of this for future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Additional Experiments</head><p>In order to further evaluate DACS, and to better understand the source of the class conflation problem, additional experiments are performed and presented in <ref type="table" target="#tab_3">Table 3</ref>. Results are shown for the Naive Mixing explained in Section 3.1 as well as for using only pseudo-labelling without any mixing and for using different mixing strategies.</p><p>As can be seen in <ref type="table" target="#tab_3">Table 3</ref>, the performance is significantly stronger for DACS than it is for Naive Mixing. As stated in Section 3.1, the most important reason for this is that Naive Mixing conflates several of the classes, which impacts the overall performance considerably. This is clear from the per-class IoUs in the table, where seven of the classes have scores below 1% for Naive Mixing. In <ref type="figure">Figure  5</ref>, we can clearly see an illustration of the class conflation problem, where for example the 'sidewalk' class is not predicted by Naive Mixing in any of the frames, instead being classified as road. In contrast, DACS is able to correctly discern between these classes in all frames.</p><p>Since Naive Mixing is mixing images based on predictions, we investigate if the problem of class conflation could be related to, or made worse by, the mixing component. We observe that when just using pseudo-labelling (that is removing the mixing component), even more classes stop being predicted by the network, with overall performance becoming worse than the source baseline. Therefore, it is reasonable to assume that it is the pseudo-labelling component, and not the mixing, that cause class conflation, similar to the conclusion made in <ref type="bibr" target="#b60">[60]</ref>. It is possible that incorporating existing techniques for pseudo-labelling would solve this issue. Though as previously stated, our proposed method of mixing images across domains offers a simple correction purely by changing the nature of the augmentation technique.</p><p>A different way to solve the problem of conflating classes would be to impose a prior class distribution on the pseudo-labels. This has been done previously for the same task in the context of entropy regularization <ref type="bibr" target="#b37">[37]</ref>. It is therefore insightful to investigate if a similar solution can correct pseudo-labels in Naive Mixing. To this end we use Distribution Alignment, as used in <ref type="bibr" target="#b0">[1]</ref>, meaning that a distribution of classes is forced upon the predictions. This is a different way of injecting entropy into the pseudo-labels, meaning that it could also help the network avoid class conflation. We perform experiments where the ground-truth distribution p of the target dataset is used to guide the training. This is done for each sample by transforming the output prediction q for each pixel intoq = Normalize(q ? p/p), wher? p is a running average of all predictions made by the network on the target data. The setup is otherwise identical to when using Naive Mixing. The results from this are shown in <ref type="table" target="#tab_3">Table 3</ref>. In our case, this is not a legitimate method, as the ground-truth class distribution would not be known for an unlabelled dataset in a realistic setting. However, it is interesting to see that this approach also solves the issue of conflating classes, as all classes are represented in the results. This further strengthens our hypothesis that artificial injection of entropy in training can help the network avoid class conflation.</p><p>When replacing ClassMix <ref type="bibr" target="#b29">[29]</ref> with other mixing techniques such as CutMix <ref type="bibr" target="#b49">[49]</ref>, or CowMix <ref type="bibr" target="#b12">[12]</ref>, performance drops slightly but the class conflation issue remains solved independent of mixing strategy, as can be seen in <ref type="table" target="#tab_3">Table 3</ref>. This both illustrates the general applicability of cross domain mixing, and that the choice of mixing strategy is relevant for performance. Incorporating other mixing strategies with DACS has the potential for even stronger performance, and presents an interesting direction for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have proposed DACS, Domain Adaptation via Crossdomain mixed Sampling, a novel algorithm for unsupervised domain adaptation in semantic segmentation. We show how a naive adaptation of mixing-based consistency regularization as used in SSL to UDA results in systematic problems in the predictions, and detail the changes performed in order to correct these issues. Furthermore, we perform an evaluation of DACS for two popular domain adaptation benchmarks, GTA5 ? Cityscapes, where it outperforms existing methods and pushes the state of the art, and SYNTHIA ? Cityscapes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Diagram showing Naive Mixing of images. Images XT 1 and XT 2 from the target dataset DT are mixed, generating the augmented image XM and its pseudo-label YM . The segmentation network is trained on batches of augmented images and batches of images from the source dataset XS (for which ground-truth labels, YS, are available).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Diagram showing DACS. The images XS and XT are mixed together, using YS for the labels of XS, instead of a predicted semantic map to determine the binary mask. The segmentation network is then trained on both batches of augmented images and images from the source dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Example augmentation used in DACS: an image from the source domain (in this case synthetic data from GTA5) is mixed with an image from the target domain (Cityscapes), resulting in an augmented image which contains parts from both domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>39.66 87.87 30.71 39.52 38.52 46.43 52.79 87.98 43.96 88.76 67.20 35.78 84.45 45.73 50.19 0.00 27.25 33.96 52.14</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>46.6</cell></row><row><cell>CBST [60]</cell><cell>91.8</cell><cell>53.5</cell><cell>80.5</cell><cell>32.7</cell><cell>21.0</cell><cell>34.0</cell><cell>28.9</cell><cell>20.4</cell><cell>83.9</cell><cell>34.2</cell><cell>80.9</cell><cell>53.1</cell><cell>24.0</cell><cell>82.7</cell><cell>30.3</cell><cell>35.9</cell><cell>16.0</cell><cell>25.9</cell><cell>42.8</cell><cell>45.9</cell></row><row><cell>MRKLD-SP [61]</cell><cell>90.8</cell><cell>46.0</cell><cell>79.9</cell><cell>27.4</cell><cell>23.3</cell><cell>42.3</cell><cell>46.2</cell><cell>40.9</cell><cell>83.5</cell><cell>19.2</cell><cell>59.1</cell><cell>63.5</cell><cell>30.8</cell><cell>83.5</cell><cell>36.8</cell><cell>52.0</cell><cell>28.0</cell><cell>36.8</cell><cell>46.4</cell><cell>49.2</cell></row><row><cell>BDL [21]</cell><cell>91.0</cell><cell>44.7</cell><cell>84.2</cell><cell>34.6</cell><cell>27.6</cell><cell>30.2</cell><cell>36.0</cell><cell>36.0</cell><cell>85.0</cell><cell>43.6</cell><cell>83.0</cell><cell>58.6</cell><cell>31.6</cell><cell>83.3</cell><cell>35.3</cell><cell>49.7</cell><cell>3.3</cell><cell>28.8</cell><cell>35.6</cell><cell>48.5</cell></row><row><cell>CADASS [45]</cell><cell>91.3</cell><cell>46.0</cell><cell>84.5</cell><cell>34.4</cell><cell>29.7</cell><cell>32.6</cell><cell>35.8</cell><cell>36.4</cell><cell>84.5</cell><cell>43.2</cell><cell>83.0</cell><cell>60.0</cell><cell>32.2</cell><cell>83.2</cell><cell>35.0</cell><cell>46.7</cell><cell>0.0</cell><cell>33.7</cell><cell>42.2</cell><cell>49.2</cell></row><row><cell>MRNet [55]</cell><cell>89.1</cell><cell>23.9</cell><cell>82.2</cell><cell>19.5</cell><cell>20.1</cell><cell>33.5</cell><cell>42.2</cell><cell>39.1</cell><cell>85.3</cell><cell>33.7</cell><cell>76.4</cell><cell>60.2</cell><cell>33.7</cell><cell>86.0</cell><cell>36.1</cell><cell>43.3</cell><cell>5.9</cell><cell>22.8</cell><cell>30.8</cell><cell>45.5</cell></row><row><cell>R-MRNet [56]</cell><cell>90.4</cell><cell>31.2</cell><cell>85.1</cell><cell>36.9</cell><cell>25.6</cell><cell>37.5</cell><cell>48.8</cell><cell>48.5</cell><cell>85.3</cell><cell>34.8</cell><cell>81.1</cell><cell>64.4</cell><cell>36.8</cell><cell>86.3</cell><cell>34.9</cell><cell>52.2</cell><cell>1.7</cell><cell>29.0</cell><cell>44.6</cell><cell>50.3</cell></row><row><cell>PIT [26]</cell><cell>87.5</cell><cell>43.4</cell><cell>78.8</cell><cell>31.2</cell><cell>30.2</cell><cell>36.3</cell><cell>39.9</cell><cell>42.0</cell><cell>79.2</cell><cell>37.1</cell><cell>79.3</cell><cell>65.4</cell><cell>37.5</cell><cell>83.2</cell><cell>46.0</cell><cell>45.6</cell><cell>25.7</cell><cell>23.5</cell><cell>49.9</cell><cell>50.6</cell></row><row><cell>SIM [39]</cell><cell>90.6</cell><cell>44.7</cell><cell>84.8</cell><cell>34.3</cell><cell>28.7</cell><cell>31.6</cell><cell>35.0</cell><cell>37.6</cell><cell>84.7</cell><cell>43.3</cell><cell>85.3</cell><cell>57.0</cell><cell>31.5</cell><cell>83.8</cell><cell>42.6</cell><cell>48.5</cell><cell>1.9</cell><cell>30.4</cell><cell>39.0</cell><cell>49.2</cell></row><row><cell>FDA [47]</cell><cell>92.5</cell><cell>53.3</cell><cell>82.4</cell><cell>26.5</cell><cell>27.6</cell><cell>36.4</cell><cell>40.6</cell><cell>38.9</cell><cell>82.3</cell><cell>39.8</cell><cell>78.0</cell><cell>62.6</cell><cell>34.4</cell><cell>84.9</cell><cell>34.1</cell><cell>53.1</cell><cell>16.9</cell><cell>27.7</cell><cell>46.4</cell><cell>50.45</cell></row><row><cell>Yang et al. [44]</cell><cell>90.8</cell><cell>41.4</cell><cell>84.7</cell><cell>35.1</cell><cell>27.5</cell><cell>31.2</cell><cell>38.0</cell><cell>32.8</cell><cell>85.6</cell><cell>42.1</cell><cell>84.9</cell><cell>59.6</cell><cell>34.4</cell><cell>85.0</cell><cell>42.8</cell><cell>52.7</cell><cell>3.4</cell><cell>30.9</cell><cell>38.1</cell><cell>49.5</cell></row><row><cell>Kim et al. [18]</cell><cell>92.9</cell><cell>55.0</cell><cell>85.3</cell><cell>34.2</cell><cell>31.1</cell><cell>34.9</cell><cell>40.7</cell><cell>34.0</cell><cell>85.2</cell><cell>40.1</cell><cell>87.1</cell><cell>61.0</cell><cell>31.1</cell><cell>82.5</cell><cell>32.3</cell><cell>42.9</cell><cell>0.3</cell><cell>36.4</cell><cell>46.1</cell><cell>50.2</cell></row><row><cell>CAG-UDA [52]</cell><cell>90.4</cell><cell>51.6</cell><cell>83.8</cell><cell>34.2</cell><cell>27.8</cell><cell>38.4</cell><cell>25.3</cell><cell>48.4</cell><cell>85.4</cell><cell>38.2</cell><cell>78.1</cell><cell>58.6</cell><cell>34.6</cell><cell>84.7</cell><cell>21.9</cell><cell>42.7</cell><cell>41.1</cell><cell>29.3</cell><cell>37.2</cell><cell>50.2</cell></row><row><cell>IAST [27]</cell><cell>93.8</cell><cell>57.8</cell><cell>85.1</cell><cell>39.5</cell><cell>26.7</cell><cell>26.2</cell><cell>43.1</cell><cell>34.7</cell><cell>84.9</cell><cell>32.9</cell><cell>88.0</cell><cell>62.6</cell><cell>29.0</cell><cell>87.3</cell><cell>39.2</cell><cell>49.6</cell><cell>23.2</cell><cell>34.7</cell><cell>39.6</cell><cell>51.5</cell></row><row><cell>Source</cell><cell cols="4">63.31 15.65 59.39 8.56</cell><cell cols="6">15.17 18.31 26.94 15.00 80.46 15.25</cell><cell cols="2">72.97 51.04</cell><cell cols="5">17.67 59.68 28.19 33.07 3.53</cell><cell cols="3">23.21 16.73 32.85</cell></row><row><cell>DACS</cell><cell>89.90</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>bone. In the table, "</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>SYNTHIA to Cityscapes, our results are averages from three runs, and shown as per-class IoU and mIoU for 13 and 16 classes. We also compare to several previous works.</figDesc><table><row><cell>Method</cell><cell cols="2">Road SW</cell><cell cols="5">Build Wall 1 Fence 1 Pole 1 TL</cell><cell>TS</cell><cell>Veg</cell><cell>Sky</cell><cell cols="3">Person Rider Car</cell><cell>Bus</cell><cell>MC</cell><cell>Bike</cell><cell cols="2">mIoU mIoU</cell></row><row><cell cols="2">AdaptSegNet [35] 84.3</cell><cell>42.7</cell><cell>77.5</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>4.7</cell><cell>7.0</cell><cell>77.9</cell><cell>82.5</cell><cell>54.3</cell><cell>21.0</cell><cell>72.3</cell><cell>32.2</cell><cell>18.9</cell><cell>32.3</cell><cell>46.7</cell><cell>-</cell></row><row><cell>SIBAN [24]</cell><cell>82.5</cell><cell>24.0</cell><cell>79.4</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>16.5</cell><cell>12.7</cell><cell>79.2</cell><cell>82.8</cell><cell>58.3</cell><cell>18.0</cell><cell>79.3</cell><cell>25.3</cell><cell>17.6</cell><cell>25.9</cell><cell>46.3</cell><cell>-</cell></row><row><cell>CLAN [25]</cell><cell>81.3</cell><cell>37.0</cell><cell>80.1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>16.1</cell><cell>13.7</cell><cell>78.2</cell><cell>81.5</cell><cell>53.4</cell><cell>21.2</cell><cell>73.0</cell><cell>32.9</cell><cell>22.6</cell><cell>30.7</cell><cell>47.8</cell><cell>-</cell></row><row><cell>APODA [46]</cell><cell>86.4</cell><cell>41.3</cell><cell>79.3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>22.6</cell><cell>17.3</cell><cell>80.3</cell><cell>81.6</cell><cell>56.9</cell><cell>21.0</cell><cell>84.1</cell><cell>49.1</cell><cell>24.6</cell><cell>45.7</cell><cell>53.1</cell><cell>-</cell></row><row><cell>PatchAlign [36]</cell><cell>82.4</cell><cell>38.0</cell><cell>78.6</cell><cell>8.7</cell><cell>0.6</cell><cell>26.0</cell><cell>3.9</cell><cell>11.1</cell><cell>75.5</cell><cell>84.6</cell><cell>53.5</cell><cell>21.6</cell><cell>71.4</cell><cell>32.6</cell><cell>19.3</cell><cell>31.7</cell><cell>46.5</cell><cell>40.0</cell></row><row><cell>AdvEnt [37]</cell><cell>85.6</cell><cell>42.2</cell><cell>79.7</cell><cell>8.7</cell><cell>0.4</cell><cell>25.9</cell><cell>5.4</cell><cell>8.1</cell><cell>80.4</cell><cell>84.1</cell><cell>57.9</cell><cell>23.8</cell><cell>73.3</cell><cell>36.4</cell><cell>14.2</cell><cell>33.0</cell><cell>48.0</cell><cell>41.2</cell></row><row><cell>CBST [60]</cell><cell>68.0</cell><cell>29.9</cell><cell>76.3</cell><cell>10.8</cell><cell>1.4</cell><cell>33.9</cell><cell>22.8</cell><cell>29.5</cell><cell>77.6</cell><cell>78.3</cell><cell>60.6</cell><cell>28.3</cell><cell>81.6</cell><cell>23.5</cell><cell>18.8</cell><cell>39.8</cell><cell>48.9</cell><cell>42.6</cell></row><row><cell>MRKLD [61]</cell><cell>67.7</cell><cell>32.2</cell><cell>73.9</cell><cell>10.7</cell><cell>1.6</cell><cell>37.4</cell><cell>22.2</cell><cell>31.2</cell><cell>80.8</cell><cell>80.5</cell><cell>60.8</cell><cell>29.1</cell><cell>82.8</cell><cell>25.0</cell><cell>19.4</cell><cell>45.3</cell><cell>50.1</cell><cell>43.8</cell></row><row><cell>CADASS [45]</cell><cell>82.5</cell><cell>42.2</cell><cell>81.3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>18.3</cell><cell>15.9</cell><cell>80.6</cell><cell>83.5</cell><cell>61.4</cell><cell>33.2</cell><cell>72.9</cell><cell>39.3</cell><cell>26.6</cell><cell>43.9</cell><cell>52.4</cell><cell>-</cell></row><row><cell>MRNet [55]</cell><cell>82.0</cell><cell>36.5</cell><cell>80.4</cell><cell>4.2</cell><cell>0.4</cell><cell>33.7</cell><cell>18.0</cell><cell>13.4</cell><cell>81.1</cell><cell>80.8</cell><cell>61.3</cell><cell>21.7</cell><cell>84.4</cell><cell>32.4</cell><cell>14.8</cell><cell>45.7</cell><cell>50.2</cell><cell>43.2</cell></row><row><cell>R-MRNet [56]</cell><cell>87.6</cell><cell>41.9</cell><cell>83.1</cell><cell>14.7</cell><cell>1.7</cell><cell>36.2</cell><cell>31.3</cell><cell>19.9</cell><cell>81.6</cell><cell>80.6</cell><cell>63.0</cell><cell>21.8</cell><cell>86.2</cell><cell>40.7</cell><cell>23.6</cell><cell>53.1</cell><cell>54.9</cell><cell>47.9</cell></row><row><cell>PIT [26]</cell><cell>83.1</cell><cell>27.6</cell><cell>81.5</cell><cell>8.9</cell><cell>0.3</cell><cell>21.8</cell><cell>26.4</cell><cell>33.8</cell><cell>76.4</cell><cell>78.8</cell><cell>64.2</cell><cell>27.6</cell><cell>79.6</cell><cell>31.2</cell><cell>31.0</cell><cell>31.3</cell><cell>51.8</cell><cell>44.0</cell></row><row><cell>SIM [39]</cell><cell>83.0</cell><cell>44.0</cell><cell>80.3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>17.1</cell><cell>15.8</cell><cell>80.5</cell><cell>81.8</cell><cell>59.9</cell><cell>33.1</cell><cell>70.2</cell><cell>37.3</cell><cell>28.5</cell><cell>45.8</cell><cell>52.1</cell><cell>-</cell></row><row><cell>FDA [47]</cell><cell>79.3</cell><cell>35.0</cell><cell>73.2</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>19.9</cell><cell>24.0</cell><cell>61.7</cell><cell>82.6</cell><cell>61.4</cell><cell>31.1</cell><cell>83.9</cell><cell>40.8</cell><cell>38.4</cell><cell>51.1</cell><cell>52.5</cell><cell>-</cell></row><row><cell>Yang et al. [44]</cell><cell>85.1</cell><cell>44.5</cell><cell>81.0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>16.4</cell><cell>15.2</cell><cell>80.1</cell><cell>84.8</cell><cell>59.4</cell><cell>31.9</cell><cell>73.2</cell><cell>41.0</cell><cell>32.6</cell><cell>44.7</cell><cell>53.1</cell><cell>-</cell></row><row><cell>Kim et al. [18]</cell><cell>92.6</cell><cell>53.2</cell><cell>79.2</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1.6</cell><cell>7.5</cell><cell>78.6</cell><cell>84.4</cell><cell>52.6</cell><cell>20.0</cell><cell>82.1</cell><cell>34.8</cell><cell>14.6</cell><cell>39.4</cell><cell>49.3</cell><cell>-</cell></row><row><cell>CAG-UDA [52]</cell><cell>84.7</cell><cell>40.8</cell><cell>81.7</cell><cell>7.8</cell><cell>0.0</cell><cell>35.1</cell><cell>13.3</cell><cell>22.7</cell><cell>84.5</cell><cell>77.6</cell><cell>64.2</cell><cell>27.8</cell><cell>80.9</cell><cell>19.7</cell><cell>22.7</cell><cell>48.3</cell><cell>-</cell><cell>44.5</cell></row><row><cell>IAST [27]</cell><cell>81.9</cell><cell>41.5</cell><cell>83.3</cell><cell>17.7</cell><cell>4.6</cell><cell>32.3</cell><cell>30.9</cell><cell>28.8</cell><cell>83.4</cell><cell>85.0</cell><cell>65.5</cell><cell>30.8</cell><cell>86.5</cell><cell>38.2</cell><cell>33.1</cell><cell>52.7</cell><cell>57.0</cell><cell>49.8</cell></row><row><cell>Source</cell><cell cols="4">36.30 14.64 68.78 9.17</cell><cell>0.20</cell><cell cols="2">24.39 5.59</cell><cell>9.05</cell><cell cols="3">68.96 79.38 52.45</cell><cell cols="3">11.34 49.77 9.53</cell><cell cols="4">11.03 20.66 33.65 29.45</cell></row><row><cell>DACS</cell><cell cols="5">80.56 25.12 81.90 21.46 2.85</cell><cell cols="6">37.20 22.67 23.99 83.69 90.77 67.61</cell><cell cols="7">38.33 82.92 38.90 28.49 47.58 54.81 48.34</cell></row><row><cell cols="2">thia with 16 classes.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Results from experiments when using Naive Mixing, only using pseudo-labelling and when applying CutMix or CowMix instead of the default ClassMix. All experiments are performed on GTA5 ? Cityscapes. For comparison our results from Table 1 are also included. 15.65 59.39 8.56 15.17 18.31 26.94 15.00 80.46 15.25 72.97 51.04 17.67 59.68 28.19 33.07 3.53 23.21 16.73 32.85 36.92 85.47 32.63 31.95 27.86 44.17 30.19 80.34 25.28 85.79 65.03 34.99 90.08 46.69 50.40 3.48 36.90 30.62 48.69 DACS + CowMix 90.34 33.93 84.12 27.37 36.33 31.47 44.15 28.03 85.56 38.94 87.94 63.82 24.77 89.48 47.41 49.54 0.16 36.78 17.66 48.30 Distribution alignment 85.05 28.88 86.79 16.92 36.89 30.38 49.73 53.91 85.61 32.20 92.78 66.61 23.53 84.00 34.81 27.70 0.20 16.65 60.08 48.04 DACS 89.90 39.66 87.87 30.71 39.52 38.52 46.43 52.79 87.98 43.96 88.76 67.20 35.78 84.45 45.73 50.19 0.00 27.25 33.96 52.14</figDesc><table><row><cell>Method</cell><cell>Road SW</cell><cell>Build Wall</cell><cell cols="2">Fence Pole</cell><cell>TL</cell><cell>TS</cell><cell>Veg</cell><cell cols="2">Terrain Sky</cell><cell cols="3">Person Rider Car</cell><cell cols="2">Truck Bus</cell><cell cols="2">Train MC</cell><cell>Bike</cell><cell>mIoU</cell></row><row><cell cols="2">Source 63.31 Naive Mixing 84.78 0.00</cell><cell>82.81 0.34</cell><cell>0.05</cell><cell cols="5">10.56 47.96 58.86 86.87 8.08</cell><cell cols="2">90.99 56.09</cell><cell>0.00</cell><cell cols="4">86.92 40.45 11.38 0.00</cell><cell>0.45</cell><cell>0.00</cell><cell>35.08</cell></row><row><cell>Pseudo-labelling</cell><cell>85.14 0.03</cell><cell>75.84 0.35</cell><cell>0.03</cell><cell>0.23</cell><cell>3.19</cell><cell>1.30</cell><cell cols="2">78.05 36.53</cell><cell cols="2">65.78 4.89</cell><cell>0.01</cell><cell cols="2">79.17 4.24</cell><cell>1.30</cell><cell>0.00</cell><cell>0.26</cell><cell>0.02</cell><cell>22.97</cell></row><row><cell>DACS + CutMix</cell><cell>86.29</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This work was partially supported by the Wallenberg AI, Autonomous Systems and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Remixmatch: Semi-supervised learning with distribution alignment and augmentation anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<idno>abs/1911.09785</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<editor>Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d&apos;Alch?-Buc, Emily B. Fox, and Roman Garnett</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-14" />
			<biblScope unit="page" from="5050" to="5060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised pixellevel domain adaptation with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017-07-21" />
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic image segmentation with deep convolutional nets and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Semi-supervised learning in video sequences for urban scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><forename type="middle">Gontijo</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shlens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.10266</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Crdoco: Pixel-level domain transfer with crossdomain consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Computer Vision Foundation / IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1791" to="1800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Semi-supervised semantic segmentation via dynamic self-training and classbalanced curriculum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangliang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhuang</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08514</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Mackiewicz</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation needs strong, varied perturbations</title>
	</analytic>
	<monogr>
		<title level="m">29th British Machine Vision Conference, BMVC 2020</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Milking cowmask for semi-supervised image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.12022</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>Jennifer G. Dy and Andreas Krause</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsm?ssan, Stockholm</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018-07-10" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="1994" to="2003" />
		</imprint>
	</monogr>
	<note>Sweden</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Conditional generative adversarial network for structured domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixiang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1335" to="1344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adversarial learning for semisupervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan-Ting</forename><surname>Liou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<meeting><address><addrLine>Newcastle, UK</addrLine></address></meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2018-09-03" />
			<biblScope unit="page">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Structured consistency loss for semi-supervised semantic segmentation. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongmok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jooyoung</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunwoo</forename><surname>Park</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning texture invariant representation for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeongjin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeran</forename><surname>Byun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="12972" to="12981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pseudo-label : The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2013 Workshop : Challenges in Representation Learning (WREPL)</title>
		<imprint>
			<biblScope unit="volume">07</biblScope>
			<biblScope unit="page">2013</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Not all pixels are equal: Difficulty-aware semantic segmentation via deep layer cascade</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017-07-21" />
			<biblScope unit="page" from="6459" to="6468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Computer Vision Foundation / IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6936" to="6945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Microsoft COCO: common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2014 -13th European Conference</title>
		<editor>David J. Fleet, Tom?s Pajdla, Bernt Schiele, and Tinne Tuytelaars</editor>
		<meeting><address><addrLine>Zurich, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">8693</biblScope>
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
	<note>Proceedings, Part V</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Significance-aware information bottleneck for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019</title>
		<meeting><address><addrLine>Seoul, Korea (South)</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-11-02" />
			<biblScope unit="page" from="6777" to="6786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Categorylevel adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Computer Vision Foundation / IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2507" to="2516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cross-domain semantic segmentation via domain-invariant interactive relation transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengmao</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4334" to="4343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Instance adaptive self-training for unsupervised domain adaptation. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with high-and lowlevel consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudhanshu</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Tatarchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Classmix: Segmentation-based data augmentation for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilhelm</forename><surname>Tranheden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliano</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lennart</forename><surname>Svensson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.07936</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<editor>Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">9906</biblScope>
			<biblScope unit="page" from="102" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Sellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semisupervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Between-class learning for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Tokozume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5486" to="5494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Unsupervised domain adaptation in semantic segmentation: a review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Toldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Maracani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umberto</forename><surname>Michieli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Zanuttigh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.10876</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2018-06-18" />
			<biblScope unit="page" from="7472" to="7481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Domain adaptation for structured output via discriminative patch representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019</title>
		<meeting><address><addrLine>Seoul, Korea (South)</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-11-02" />
			<biblScope unit="page" from="1456" to="1465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">ADVENT: adversarial entropy minimization for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himalaya</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Computer Vision Foundation / IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2517" to="2526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Class-specific reconstruction transfer learning for visual recognition across domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Differential treatment for stuff and things: A simple unsupervised domain adaptation method for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Mei</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12635" to="12644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Entropy minimization vs. diversity maximization for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunming</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longin</forename><forename type="middle">Jan</forename><surname>Latecki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.01690</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dcan: Dual channel-wise alignment networks for unsupervised scene adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><forename type="middle">Gokhan</forename><surname>Uzunbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="518" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">ACE: adapting to changing environments for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019</title>
		<meeting><address><addrLine>Seoul, Korea (South)</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-11-02" />
			<biblScope unit="page" from="2121" to="2130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12848</idno>
		<title level="m">Unsupervised data augmentation for consistency training</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Label-driven reconstruction for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhi</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinliang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<idno>abs/2003.04614</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Context-aware domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhi</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peilin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04010</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">An adversarial perturbation oriented domain adaptation approach for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Second Innovative Applications of Artificial Intelligence Conference</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="12613" to="12620" />
		</imprint>
	</monogr>
	<note>The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Fda: Fourier domain adaptation for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4085" to="4095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sicheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><forename type="middle">L</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019</title>
		<meeting><address><addrLine>Seoul, Korea (South)</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-11-02" />
			<biblScope unit="page" from="2100" to="2110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019</title>
		<meeting><address><addrLine>Seoul, Korea (South)</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-11-02" />
			<biblScope unit="page" from="6022" to="6031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Ciss?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Manifold criterion guided transfer learning via intermediate domain generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3759" to="3773" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Category anchor-guided unsupervised domain adaptation for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<editor>Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d&apos;Alch?-Buc, Emily B. Fox, and Roman Garnett</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-14" />
			<biblScope unit="page" from="433" to="443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Fully convolutional adaptation networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaofan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2018-06-18" />
			<biblScope unit="page" from="6810" to="6818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Unsupervised scene adaptation with memory regularization in vivo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.11164</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.03773</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Uncertainty-aware consistency regularization for cross-domain semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangliang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhuang</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08878</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Penalizing top performers: Conservative loss for semantic segmentation adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinge</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ceyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="568" to="583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Improving semantic segmentation via video propagation and label relaxation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Sapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fitsum</forename><forename type="middle">A</forename><surname>Reda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">J</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shawn</forename><forename type="middle">D</forename><surname>Newsam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8856" to="8865" />
		</imprint>
		<respStmt>
			<orgName>Computer Vision Foundation / IEEE</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V K</forename><surname>Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2018 -15th European Conference</title>
		<editor>Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair Weiss</editor>
		<meeting><address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">11207</biblScope>
			<biblScope unit="page" from="297" to="313" />
		</imprint>
	</monogr>
	<note>Proceedings, Part III</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Confidence regularized self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V K</forename><surname>Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019</title>
		<meeting><address><addrLine>Seoul, Korea (South)</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-11-02" />
			<biblScope unit="page" from="5981" to="5990" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
