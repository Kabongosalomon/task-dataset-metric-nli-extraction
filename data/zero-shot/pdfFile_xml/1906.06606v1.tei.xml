<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Hop Paragraph Retrieval for Open-Domain Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Feldman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Technion -Israel Institute of Technology Haifa</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>El-Yaniv</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Technion -Israel Institute of Technology Haifa</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Hop Paragraph Retrieval for Open-Domain Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper is concerned with the task of multi-hop open-domain Question Answering (QA). This task is particularly challenging since it requires the simultaneous performance of textual reasoning and efficient searching. We present a method for retrieving multiple supporting paragraphs, nested amidst a large knowledge base, which contain the necessary evidence to answer a given question. Our method iteratively retrieves supporting paragraphs by forming a joint vector representation of both a question and a paragraph. The retrieval is performed by considering contextualized sentence-level representations of the paragraphs in the knowledge source. Our method achieves state-of-the-art performance over two well-known datasets, SQuAD-Open and HotpotQA, which serve as our single-and multi-hop open-domain QA benchmarks, respectively. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Textual Question Answering (QA) is the task of answering natural language questions given a set of contexts from which the answers to these questions can be inferred. This task, which falls under the domain of natural language understanding, has been attracting massive interest due to extremely promising results that were achieved using deep learning techniques. These results were made possible by the recent creation of a variety of large-scale QA datasets, such as TriviaQA <ref type="bibr" target="#b11">(Joshi et al., 2017)</ref> and SQuAD <ref type="bibr" target="#b20">(Rajpurkar et al., 2016)</ref>. The latest state-of-the-art methods are even capable of outperforming humans on certain tasks <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref> </p><formula xml:id="formula_0">2 .</formula><p>The basic and arguably the most popular task of QA is often referred to as Reading Comprehension (RC), in which each question is paired with a relatively small number of paragraphs (or documents) from which the answer can potentially be inferred. The objective in RC is to extract the correct answer from the given contexts or, in some cases, deem the question unanswerable <ref type="bibr" target="#b19">(Rajpurkar et al., 2018)</ref>. Most large-scale RC datasets, however, are built in such a way that the answer can be inferred using a single paragraph or document. This kind of reasoning is termed single-hop reasoning, since it requires reasoning over a single piece of evidence. A more challenging task, called multi-hop reasoning, is one that requires combining evidence from multiple sources <ref type="bibr" target="#b25">(Talmor and Berant, 2018;</ref><ref type="bibr" target="#b28">Welbl et al., 2018;</ref>. <ref type="figure">Figure 1</ref> provides an example of a question requiring multihop reasoning. To answer the question, one must first infer from the first context that Alex Ferguson is the manager in question, and only then can the answer to the question be inferred with any confidence from the second context.</p><p>Another setting for QA is open-domain QA, in which questions are given without any accompanying contexts, and one is required to locate the relevant contexts to the questions from a large knowledge source (e.g., Wikipedia), and then extract the correct answer using an RC component. This task has recently been resurged following the work of <ref type="bibr" target="#b1">Chen et al. (2017)</ref>, who used a TF-IDF based retriever to find potentially relevant documents, followed by a neural RC component that extracted the most probable answer from the retrieved documents. While this methodology performs reasonably well for questions requiring single-hop reasoning, its performance decreases significantly when used for open-domain multihop reasoning.</p><p>We propose a new approach to accomplishing this task, called iterative multi-hop retrieval, in which one iteratively retrieves the necessary evi-Question: The football manager who recruited David Beckham managed Manchester United during what timeframe? Context 1: The 1995-96 season was Manchester United's fourth season in the Premier League ... Their triumph was made all the more remarkable by the fact that Alex Ferguson ... had drafted in young players like Nicky Butt, David Beckham, Paul Scholes and the Neville brothers, Gary and Phil. Context 2: Sir Alexander Chapman Ferguson, CBE (born 31 December 1941) is a Scottish former football manager and player who managed Manchester United from 1986 to 2013. He is regarded by many players, managers and analysts to be one of the greatest and most successful managers of all time. <ref type="figure">Figure 1</ref>: An example of a question and its answer contexts from the HotpotQA dataset requiring multihop reasoning and retrieval. The first reasoning hop is highlighted in green, the second hop in purple, and the entity connecting the two is highlighted in blue bold italics. In the first reasoning hop, one has to infer that the manager in question is Alex Ferguson. Without this knowledge, the second context cannot possibly be retrieved with confidence, as the question could refer to any of the club's managers throughout its history. Therefore, an iterative retrieval is needed in order to correctly retrieve this context pair. dence to answer a question. We believe this iterative framework is essential for answering multihop questions, due to the nature of their reasoning requirements.</p><p>Our main contributions are the following:</p><p>? We propose a novel multi-hop retrieval approach, which we believe is imperative for truly solving the open-domain multi-hop QA task.</p><p>? We show the effectiveness of our approach, which achieves state-of-the-art results in both single-and multi-hop open-domain QA benchmarks.</p><p>? We also propose using sentence-level representations for retrieval, and show the possible benefits of this approach over paragraph-level representations.</p><p>While there are several works that discuss solutions for multi-hop reasoning <ref type="bibr" target="#b7">(Dhingra et al., 2018;</ref><ref type="bibr" target="#b34">Zhong et al., 2019)</ref>, to the best of our knowledge, this work is the first to propose a viable solution for open-domain multi-hop QA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definition</head><p>We define the open-domain QA task by a triplet (KS, Q, A) where KS = {P 1 , P 2 , . . . , P |KS| } is a background knowledge source and P i = (p 1 , p 2 , . . . , p l i ) is a textual paragraph consisting of l i tokens, Q = (q 1 , q 2 , . . . , q m ) is a textual question consisting of m tokens, and A = (a 1 , a 2 , . . . , a n ) is a textual answer consisting of n tokens, typically a span of tokens p j 1 , . . . , p jn in some P i ? KS, or optionally a choice from a predefined set of possible answers. The objective of this task is to find the answer A to the question Q using the background knowledge source KS. Formally speaking, our task is to learn a function ? such that A = ?(Q, KS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Single-Hop Retrieval</head><p>In the classic and most simple form of QA, questions are formulated in such a way that the evidence required to answer them may be contained in a single paragraph, or even in a single sentence. Thus, in the opendomain setting, it might be sufficient to retrieve a single relevant paragraph P i ? KS using the information present in the given question Q, and have a reading comprehension model extract the answer A from P i . We call this task variation single-hop retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Hop Retrieval</head><p>In contrast to the singlehop case, there are types of questions whose answers can only be inferred by using at least two different paragraphs. The ability to reason with information taken from more than one paragraph is known in the literature as multi-hop reasoning <ref type="bibr" target="#b28">(Welbl et al., 2018)</ref>. In multi-hop reasoning, not only might the evidence be spread across multiple paragraphs, but it is often necessary to first read a subset of these paragraphs in order to extract the useful information from the other paragraphs, which might otherwise be understood as not completely relevant to the question. This situation becomes even more difficult in the opendomain setting, where one must first find an initial evidence paragraph in order to be able to retrieve the rest. This is demonstrated in <ref type="figure">Figure 1</ref>, where one can observe that the second context alone may appear to be irrelevant to the question at hand and the information in the first context is necessary to retrieve the second part of the evidence correctly. We extend the multi-hop reasoning ability to the open-domain setting, referring to it as multi-hop retrieval, in which the evidence paragraphs are re-trieved in an iterative fashion. We focus on this task and limit ourselves to the case where two iterations of retrieval are necessary and sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>Our solution, which we call MUPPET (multi-hop paragraph retrieval), relies on the following basic scheme consisting of two main components: (a) a paragraph and question encoder, and (b) a paragraph reader. The encoder is trained to encode paragraphs into d-dimensional vectors, and to encode questions into search vectors in the same vector space. Then, a maximum inner product search (MIPS) algorithm is applied to find the most similar paragraphs to a given question. Several algorithms exist for fast (and possibly approximate) MIPS, such as the one proposed by <ref type="bibr" target="#b10">Johnson et al. (2017)</ref>. The most similar paragraphs are then passed to the paragraph reader, which, in turn, extracts the most probable answer to the question.</p><p>It is critical that the paragraph encodings do not depend on the questions. This enables storing precomputed paragraph encodings and executing efficient MIPS when given a new search vector. Without this property, any new question would require the processing of the complete knowledge source (or a significant part of it).</p><p>To support multi-hop retrieval, we propose the following extension to the basic scheme. Given a question Q, we first obtain its encoding q ? R d using the encoder. Then, we transform it into a search vector q s ? R d , which is used to retrieve the top-k relevant paragraphs {P Q 1 , P Q 2 , . . . , P Q k } ? KS using MIPS. In each subsequent retrieval iteration, we use the paragraphs retrieved in its previous iteration to reformulate the search vector. This produces k new search vectors, {q s 1 ,q s 2 , . . . ,q s k }, whereq s i ? R d , which are used in the same manner as in the first iteration to retrieve the next top-k paragraphs, again using MIPS. This method can be seen as performing a beam search of width k in the encoded paragraphs' space. A high-level view of the described solution is given in <ref type="figure">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Paragraph and Question Encoder</head><p>We define f , our encoder model, in the following way. Given a paragraph P consisting of k sentences (s 1 , s 2 , . . . , s k ) and m tokens (t 1 , t 2 , . . . , t m ), such that s i = (t i 1 , t i 2 , . . . , t i l ), where l is the length of the sentence, our encoder generates k respective d-dimensional encodings (s 1 , s 2 , . . . , s k ) = f (P ), one for each sentence. This is in contrast to previous work in paragraph retrieval in which only a single fixed-size representation is used for each paragraph <ref type="bibr" target="#b5">Das et al., 2019)</ref>. The encodings are created by passing (t 1 , t 2 , . . . , t m ) through the following layers.</p><p>Word Embedding We use the same embedding layer as the one suggested by . Each token t is embedded into a vector t using both character-level and word-level information. The word-level embedding t w is obtained via pretrained word embeddings. The characterlevel embedding of a token t with l t characters (t c 1 , t c 2 , . . . , t c lt ) is obtained in the following manner: each character t c i is embedded into a fixedsize vector t c i . We then pass each token's character embeddings through a one-dimensional convolutional neural network, followed by max-pooling over the filter dimension. This produces a fixedsize character-level representation for each token, t c = max CNN(t c 1 , t c 2 , . . . , t c lt ) . Finally, we concatenate the word-level and character-level embeddings to form the final word representation,</p><formula xml:id="formula_1">t = [t w ; t c ].</formula><p>Recurrent Layer After obtaining the word representations, we use a bidirectional GRU <ref type="bibr" target="#b2">(Cho et al., 2014)</ref> to process the paragraph and obtain the contextualized word representations, (c 1 , c 2 , . . . , c m ) = BiGRU(t 1 , t 2 , . . . , t m ).</p><p>Sentence-wise max-pooling Finally, we chunk the contextualized representations of the paragraph tokens into their corresponding sentence groups, and apply max-pooling over the time dimension of each sentence group to obtain the parargaph's d-dimensional sentence representations, s i = max(c i 1 , c i 2 , . . . , c i l ). A high-level outline of the sentence encoder is shown is <ref type="figure">Figure 3a</ref>, where we can see a series of m tokens being passed through the aforementioned layers, producing k sentence representations.</p><p>The encoding q of a question Q is computed similarly, such that q = f (Q). Note that we produce a single vector for any given question, thus the max-pooling operation is applied over all question words at once, disregarding sentence information. Reformulation Component The reformulation component receives a paragraph P and a question Q, and produces a single vectorq. First, contextualized word representations are obtained using the same embedding and recurrent layers used for the initial encoding, (c q 1 , c q 2 , . . . , c q nq ) for Q and (c p 1 , c p 2 , . . . , c p np ) for P . We then pass the contextualized representations through a bidirectional attention layer, which we adopt from . The attention between question word i and paragraph word j is computed as:  <ref type="figure">Figure 4</ref>: An example from the SQuAD dataset of a paragraph that acts as the context for two different questions. Question 1 and its evidence (highlighted in purple) have little relation to question 2 and its evidence (highlighted in green). This motivates our method of storing sentence-wise encodings instead of a single representation for an entire paragraph.</p><formula xml:id="formula_2">a ij = w a 1 ? c q i + w a 2 ? c p j + w a 3 ? (c q i c p j ),</formula><p>where w a 1 , w a 2 , w a 3 ? R d are learned vectors. For each question word, we compute the vector a i :</p><formula xml:id="formula_3">? ij = e a ij np j=1 e a ij , a i = np j=1 ? ij c p j .</formula><p>A paragraph-to-question vector a p is computed as follows:</p><formula xml:id="formula_4">m i = max 1?j?np a ij , ? i = e m i nq i=1 e m i a p = nq i=1 ? i c q i .</formula><p>We concatenate c q i , a i , c q i a i and a p a i and pass the result through a linear layer with ReLU activations to compute the final bidirectional attention vectors. We also use a residual connection where we process these representations with a bidirectional GRU and another linear layer with ReLU activations. Finally, we sum the outputs of the two linear layers. As before, we derive the ddimensional reformulated question representatio? q using a max-pooling layer on the outputs of the residual layer. A high-level outline of the reformulation layer is given in <ref type="figure">Figure 3b</ref>, where m contextualized token representations of the question and n contextualized token representations of the paragraph are passed through the component's layers to produce the reformulated question representation,q.</p><p>Relevance Scores Given the sentence representations (s 1 , s 2 , . . . , s k ) of a paragraph P , and the question encoding q for Q, the relevance score of P with respect to a question Q is calculated in the following way:</p><formula xml:id="formula_5">rel(Q, P ) = max i=1,...,k ? ? ? ? ? s i s i q s i ? q q ? ? ? ? ? ? ? ? ? w 1 w 2 w 3 w 4 ? ? ? ? + b , where w 1 , w 2 , w 4 ? R d and w 3 , b ? R are learned parameters.</formula><p>A similar max-pooling encoding approach, along with the scoring layer's structure, were proposed by <ref type="bibr" target="#b4">Conneau et al. (2017)</ref> who showed their efficacy on various sentence-level tasks. We find this sentence-wise formulation to be beneficial because it suffices for one sentence in a paragraph to be relevant to a question for the whole paragraph to be considered as relevant. This allows more fine-grained representations for paragraphs and more accurate retrieval. An example of the benefits of using this kind of sentence-level model is given in <ref type="figure">Figure 4</ref>, where we see two questions answered by two different sentences. Our model allows each question to be similar only to parts of the paragraph, and not necessarily to all of it.</p><p>Search Vector Derivation Recall that our retrieval algorithm is based on executing a MIPS in the paragraph encoding space. To derive such a search vector from the question encoding q, we observe that:</p><formula xml:id="formula_6">rel(Q, P ) ? max i=1,...,k s i (w 1 + w 2 q + w 3 ? q).</formula><p>Therefore, the final search vector of a question Q is q s = w 1 + w 2 q + w 3 ? q. The same equations apply when predicting the relevance score for the second retrieval iteration, in which case q is swapped withq.</p><p>Training and Loss Functions Each training sample consists of a question and two paragraphs, (Q, P 1 , P 2 ), where P 1 corresponds to a paragraph retrieved in the first iteration, and P 2 corresponds to a paragraph retrieved in the second iteration using the reformulated vectorq. P 1 is considered relevant if it constitutes one of the necessary evidence paragraphs to answer the question. P 2 is considered relevant only if P 1 and P 2 together constitute the complete set of evidence paragraphs needed to answer the question. Both iterations have the same form of loss functions, and the model is trained by optimizing the sum of the iterations' losses.</p><p>Our training objective for each iteration is composed of two components: a binary cross-entropy loss function and a ranking loss function. The cross-entropy loss is defined as follows:</p><formula xml:id="formula_7">L CE = ? 1 N N i=1 y i log rel(Q i , P i ) + (1 ? y i ) log 1 ? rel(Q i , P i ) ,</formula><p>where y i ? {0, 1} is a binary label indicating the true relevance of P i to Q i in the iteration in which rel(Q i , P i ) is calculated, and N is the number of samples in the current batch. The ranking loss is computed in the following manner. First, for each question Q i in a given batch, we find the mean of the scores given to positive and negative paragraphs for each question, q pos</p><formula xml:id="formula_8">i = 1 M 1 M 1 j=1 rel(Q i , P j ) and q neg i = 1 M 2 M 2 j=1 rel(Q i , P j ),</formula><p>where M 1 and M 2 are the number of positive and negative samples for Q i , respectively. We then define the margin ranking loss <ref type="bibr" target="#b22">(Socher et al., 2013)</ref> as</p><formula xml:id="formula_9">L R = 1 M M i=1 max(0, ? ? q pos i + q neg i ), (1)</formula><p>where M is the number of distinct questions in the current batch, and ? is a hyperparameter. The final objective is the sum of the two losses:</p><formula xml:id="formula_10">L = L CE + ?L R ,<label>(2)</label></formula><p>where ? is a hyperparameter.</p><p>We note that we found it slightly beneficial to incorporate pretrained ELMo <ref type="bibr" target="#b18">(Peters et al., 2018)</ref> embeddings in our model. For more detailed information of the implementation details and training process, please refer to Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Paragraph Reader</head><p>The paragraph reader receives as input a question Q and a paragraph P and extracts the most probable answer span to Q from P . We use the S-norm model proposed by . A detailed description of the model is given in Appendix A.</p><p>Training An input sample for the paragraph reader consists of a question and a single context (Q, P ). We optimize the same negative loglikelihood function used in the S-norm model for the span start boundaries:</p><formula xml:id="formula_11">L start = ? log j?P Q k?A j e s kj j?P Q n j i=1 e s ij ,</formula><p>where P Q is the set of paragraphs paired with the same question Q, A j is the set of tokens that start an answer span in the j-th paragraph, and s ij is the score given to the i-th token in the j-th paragraph. The same formulation is used for the span end boundaries, so that the final objective function is the sum of the two: L span = L start + L end .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>We test our approach on two datasets, and measure end-to-end QA performance using the standard exact match (EM) and F 1 metrics, as well as the metrics proposed by  for the HotpotQA dataset (see Appendix B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>HotpotQA  introduced a dataset of Wikipedia-based questions, which require reasoning over multiple paragraphs to find the correct answer. The dataset also includes hard supervision on sentence-level supporting facts, which encourages the model to give explainable answer predictions. Two benchmark settings are available for this dataset: (1) a distractor setting, in which the reader is given a question as well as a set of paragraphs that includes both the supporting facts and irrelevant paragraphs; (2) a full wiki setting, which is an open-domain version of the dataset. We use this dataset as our benchmark for the multi-hop retrieval setting. Several extensions must be added to the reader from Section 3.2 in order for it to be suitable for the HotpotQA dataset. A detailed description of our proposed extensions is given in Appendix B.</p><p>SQuAD-Open <ref type="bibr" target="#b1">Chen et al. (2017)</ref> decoupled the questions from their corresponding contexts in the original SQuAD dataset <ref type="bibr" target="#b20">(Rajpurkar et al., 2016)</ref>, and formed an open-domain version of the dataset by defining an entire Wikipedia dump to be the background knowledge source from which the answer to the question should be extracted. We use this dataset to test the effectiveness of our method in a classic single-hop retrieval setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Setup</head><p>Search Hyperparameters For our experiments in the multi-hop setting, we used a width of 8 in the first retrieval iteration. In all our experiments, unless stated otherwise, the reader is fed the top 45 paragraphs through which it reasons independently and finds the most probable answers. In addition, we found it beneficial to limit the search space of our MIPS retriever to a subset of the knowledge source, which is determined by a TF-IDF heuristic retriever. We define n i to be the size of the search space for retrieval iteration i. As we will see, there is a trade-off for choosing various values of n i . A large value of n i offers the possibility of higher recall, whereas a small value of n i introduces less noise in the form of irrelevant paragraphs.</p><p>Knowledege Sources For HotpotQA, our knowledge source is the same Wikipedia version used by  3 . This version is a set of all of the first paragraphs in the entire Wikipedia. For SQuAD-Open, we use the same Wikipedia dump used by <ref type="bibr" target="#b1">Chen et al. (2017)</ref>. For both knowledge sources, the TF-IDF based retriever we use for search space reduction is the one proposed by <ref type="bibr" target="#b1">Chen et al. (2017)</ref>, which uses bigram hashing and TF-IDF matching. We note that in the HotpotQA Wikipedia version each document is a single paragraph, while in SQuAD-Open, the full Wikipedia documents are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setting</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Answer . At the bottom, we compare the end-to-end performance on the full wiki setting. TF-IDF + Reader refers to using the TF-IDF based retriever without our MIPS retriever. MUPPET (sentence-level) refers to our approach with sentence-level representations, and MUPPET (paragraph-level) refers to our approach with paragraph-level representations. For both sentence-and paragraph-level results, we set n 1 = 32 and n 2 = 512.</p><note type="other">Sup Fact Joint EM</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method EM F1</head><p>DrQA <ref type="bibr" target="#b1">(Chen et al., 2017)</ref> 28.4 -DrQA <ref type="bibr">(Chen et al., 2017) (multitask)</ref> 29.8 -R 3 <ref type="bibr" target="#b26">(Wang et al., 2018a)</ref> 29.1 37.5 DS-QA <ref type="bibr" target="#b13">(Lin et al., 2018)</ref> 28.7 36.6 Par. Ranker + Full Agg.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Primary <ref type="table" target="#tab_1">Results Tables 1 and 2</ref> show our main results on the HotpotQA and SQuAD-Open datasets, respectively. In the HotpotQA distractor setting, our paragraph reader greatly improves the results of the baseline reader, increasing the joint EM and F 1 scores by 17.12 (148%) and 13.22 (32%) points, respectively. In the full wiki setting, we compare three methods of retrieval: (1) TF-IDF, in which only the TF-IDF heuristic is used. The reader is fed all possible paragraph pairs from the top-10 paragraphs.</p><p>(2) Sentencelevel, in which we use MUPPET with sentencelevel encodings. (3) Paragraph-level, in which we use MUPPET with paragraph-level encodings (no sentence information). We can see that both methods significantly outperform the na?ve TF-IDF retriever, indicating the efficacy of our approach. As of writing this paper, we are placed second in the HotpotQA full wiki setting (test set) leaderboard 4 . For SQuAD-Open, our sentencelevel method established state-of-the-art results, improving the current non-BERT <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref> state-of-the-art by 4.6 (13%) and 3.6 (8%) EM and F 1 points, respectively. This shows that our encoder can be useful not only for multi-hop questions, but also for single-hop questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval Recall Analysis</head><p>We analyze the performance of the TF-IDF retriever for HotpotQA in <ref type="figure" target="#fig_1">Figure 5a</ref>. We can see that the retriever succeeds in retrieving at least one of the gold paragraphs for each question (above 90% with the top-32 paragraphs), but fails at retrieving both gold paragraphs. This demonstrates the necessity of an efficient multi-hop retrieval approach to aid or replace classic information retrieval methods.</p><p>Effect of Narrowing the Search Space In <ref type="figure" target="#fig_1">Figures 5b</ref> and 5c, we show the performance of our method as a function of the size of the search space of the last retrieval iteration. For SQuAD-Open, the TF-IDF retriever initially retrieves a set of documents, which are then split into paragraphs to form the search space. Each search space of top-k paragraphs limits the potential recall of the model to that of the top-k paragraphs retrieved by the TF-IDF retriever. This proves to be suboptimal for very small values of k, as the performance of the TF-IDF retriever is not good enough. Our models, however, fail to benefit from increasing the search space indefinitely, hinting that they are not as robust to noise as we would want them to be. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effectiveness of Sentence-Level Encodings</head><p>Our method proposes using sentence-level encodings for paragraph retrieval. We test the significance of this approach in Figures 5b and 5c. While sentence-level encodings seem to be vital for improving state-of-the-art results on SQuAD-Open, the same cannot be said about HotpotQA. We hypothesize that this is a consequence of the way the datasets were created. In SQuAD, each paragraph serves as the context of several questions, as shown in <ref type="figure">Figure 4</ref>. This leads to questions being asked about facts less essential to the gist of the paragraph, and thus they would not be encapsulated in a single paragraph representation. In HotpotQA, however, most of the paragraphs in the training set serve as the context of at most one question. <ref type="bibr" target="#b1">Chen et al. (2017)</ref> first introduced the use of neural methods to the task of open-domain QA using a textual knowledge source. They proposed DrQA, a pipeline approach with two components: a TF-IDF based retriever, and a multi-layer neural network that was trained to find an answer span given a question and a paragraph. In an attempt to improve the retrieval of the TF-IDF based component, many existing works have used Distant Supervision (DS) to further re-rank the retrieved paragraphs <ref type="bibr" target="#b9">(Htut et al., 2018;</ref><ref type="bibr" target="#b30">Yan et al., 2018)</ref>. <ref type="bibr" target="#b26">Wang et al. (2018a)</ref> used reinforcement learning to train a re-ranker and an RC component in an end-to-end manner, and showed its advan-tage over the use of DS alone. <ref type="bibr" target="#b16">Min et al. (2018)</ref> trained a sentence selector and demonstrated the effectiveness of reading minimal contexts instead of complete documents. As DS can often lead to wrong labeling, <ref type="bibr" target="#b13">Lin et al. (2018)</ref> suggested a denoising method for alleviating this problem. While these methods have proved to increase performance in various open-domain QA datasets, their re-ranking approach is limited in the number of paragraphs it can process, as it requires the joint reading of a question with all possible paragraphs. This is in contrast to our approach, in which all paragraph representations are precomputed to allow efficient large-scale retrieval. There are some works that adopted a similar precomputation scheme.  learned an encoding function for questions and paragraphs and ranked paragraphs by their dot-product similarity with the question. Many of their improvements, however, can be attributed to the incorporation of answer aggregation methods as suggested by <ref type="bibr" target="#b27">Wang et al. (2018b)</ref> in their model, which enhanced their results significantly. <ref type="bibr" target="#b21">Seo et al. (2018)</ref> proposed phrase-indexed QA (PI-QA), a new formulation of the QA task that requires the independent encoding of answers and questions. The question encodings are then used to retrieve the correct answers by performing MIPS. This is more of a challenge task rather than a solution for opendomain QA. A recent work by <ref type="bibr" target="#b5">Das et al. (2019)</ref> proposed a new framework for open-domain QA that employs a multi-step interaction between a retriever and a reader. This interactive framework is used to refine a question representation in order for the retrieval to be more accurate. Their method is complimentary to ours -the interactive framework is used to enhance retrieval performance for single-hop questions, and does not handle the multi-hop domain. Another line of work reminiscent of our method is the one of Memory Networks . Memory Networks consist of an array of cells, each capable of storing a vector, and four modules (input, update, output and response) that allow the manipulation of the memory for the task at hand. Many variations of Memory Networks have been proposed, such as end-to-end Memory Networks <ref type="bibr" target="#b24">(Sukhbaatar et al., 2015)</ref>, Key-Value Memory Networks <ref type="bibr" target="#b15">(Miller et al., 2016)</ref>, and Hierarchical Memory Networks <ref type="bibr" target="#b0">(Chandar et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Concluding Remarks</head><p>We present MUPPET, a novel method for multihop paragraph retrieval, and show its efficacy in both single-and multi-hop QA datasets. One difficulty in the open-domain multi-hop setting is the lack of supervision, a difficulty that in the singlehop setting is alleviated to some extent by using distant supervision. We hope to tackle this problem in future work to allow learning more than two retrieval iterations. An interesting improvement to our approach would be to allow the retriever to automatically determine whether or not more retrieval iterations are needed. A promising direction could be a multi-task approach, in which both single-and multi-hop datasets are learned jointly. We leave this for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Paragraph Reader</head><p>In this section we describe in detail the reader mentioned in Section 3.2. The paragraph reader receives as input a question Q and a paragraph P and extracts the most probable answer span to Q from P . We use the shared-norm model presented by , which we refer to as S-norm. The model's architecture is quite similar to the one we used for the encoder. First, we process Q and P seperately to obtain their contexualized token representations, in the same manner as used in the encoder. We then pass the contextualized representations through a bidirectional attention layer similar to the one defined in the reformulation layer of the encoder, with the only difference being that the roles of the question and the paragraph are switched. As before, we further pass the bidirectional attention representations through a residual connection, this time using a self-attention layer between the bidirectional GRU and the linear layer. The self-attention mechanism is similar to the bidirectional attention layer, only now it is between the paragraph and itself. Therefore, question-to-parargaph attention is not used, and we set a ij = ?? if i = j. The summed outputs of the residual connection are passed to the prediction layer. The inputs to the prediction layer are passed through a bidirectional GRU followed by a linear layer that predicts the answer span start scores. The hidden layers of that GRU are concatenated with the input and passed through another bidirectional GRU and linear layer to predict the answer span end scores.</p><p>Training An input sample for the paragraph reader consists of a question and a single context (Q, P ). We optimize the same negative loglikelihood function used in the S-norm model for the span start boundaries:</p><formula xml:id="formula_12">L start = ? log j?P Q k?A j e s kj j?P Q n j i=1 e s ij ,</formula><p>where P Q is the set of paragraphs paired with the same question Q, A j is the set of tokens that start an answer span in the j-th paragraph, and s ij is the score given to the i-th token in the j-th paragraph. The same formulation is used for the span end boundaries, so that the final objective function is the sum of the two: L span = L start + L end .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Paragraph Reader Extension for HotpotQA</head><p>HotpotQA presents the challenge of not only predicting an answer span, but also yes/no answers. This is a combination of span-based questions and multiple-choice questions. In addition, one is also required to provide explainability to the answer predictions by predicting the supporting facts leading to the answer. We extend the paragraph reader from Section 3.2 to support these predictions in the following manner.</p><p>Yes/No Prediction We argue that one can decide whether the answer to a given question should be span-based or yes/no-based without looking at any context at all. Therefore, we first create a fixed-size vector representing the question using max-pooling over the first bidirectional GRU's states of the question. We pass this representation through a linear layer that predicts whether this is a yes/no-based question or a span-based question. If span-based, we predict the answer span from the context using the original span prediction layer. If yes/no-based, we encode the questionaware context representations to a fixed-size vector by performing max-pooling over the outputs of the residual self-attention layer. As before, we then pass this vector through a linear layer to predict a yes/no answer.</p><p>Supporting Fact Prediction As a context's supporting facts for a question are at the sentencelevel, we encode the question-aware context representations to fixed-size sentence representations by passing the outputs of the residual self-attention layer through another bidirectional GRU, followed by performing max-pooling over the sentence groups of the GRU's outputs. Each sentence representation is then passed through a multilayer perceptron with a single hidden layer equipped with ReLU activations to predict whether it is indeed a supporting fact or not.</p><p>Training An input sample for the paragraph reader consists of a question and a single context, (Q, P ). Nevertheless, as HotpotQA requires multiple paragraphs to answer a question, we define P to be the concatenation of these paragraphs.</p><p>Our objective function comprises four loss functions, corresponding to the four possible predictions of our model. For the span-based prediction we use L span , as before. We use a similar neg-ative log likelihood loss for the answer type prediction (whether the answer should be span-based or yes/no-based) and for a yes/no answer prediction: are the likelihood scores of the j-th questionparagraph pair being a binary yes/no-based type, a span-based type, and its true type, respectively. e s yes j , e s no j and e s yes/no j are the likelihood scores of the j-th question-paragraph pair having the answer 'yes', the answer 'no', and its true answer, respectively. For span-based questions, L yes/no is defined to be zero, and vice-versa.</p><formula xml:id="formula_13">L type = ? log j?P Q e s</formula><p>For the supporting fact prediction, we use a binary cross-entropy loss on each sentence, L sp . The final loss function is the sum of these four objectives, L hotpot = L span + L type + L yes/no + L sp During inference, the supporting facts prediction is taken only from the paragraph from which the answer is predicted.</p><p>Metrics Three sets of metrics were proposed by  to evaluate performance on the HotpotQA dataset. The first set of metrics focuses on evaluating the answer span. For this purpose the exact match (EM) and F 1 metrics are used, as suggested by <ref type="bibr" target="#b20">Rajpurkar et al. (2016)</ref>. The second set of metrics focuses on the explainability of the models, by evaluating the supporting facts directly using the EM and F 1 metrics on the set of supporting fact sentences. The final set of metrics combines the evaluation of answer spans and supporting facts as follows. For each example, given its precision and recall on the answer span (P (ans) , R (ans) ) and the supporting facts (P (sup) , R (sup) ), respectively, the joint F 1 is calculated as P (joint) = P (ans) P (sup) , R (joint) = R (ans) R (sup) ,</p><formula xml:id="formula_14">Joint F 1 = 2P (joint) R (joint) P (joint) + R (joint) .</formula><p>The joint EM is 1 only if both tasks achieve an exact match and otherwise 0. Intuitively, these metrics penalize systems that perform poorly on either task. All metrics are evaluated example-byexample, and then averaged over examples in the evaluation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Implementation Details</head><p>We use the Stanford CoreNLP toolkit  for tokenization. We implement all our models using TensorFlow.</p><p>Architecture Details For the word-level embeddings, we use the GloVe 300-dimensional embeddings pretrained on the 840B Common Crawl corpus <ref type="bibr" target="#b17">(Pennington et al., 2014)</ref>. For the characterlevel embeddings, we use 20-dimensional character embeddings, and use a 1-dimensional CNN with 100 filters of size 5, with a dropout (Srivastava et al., 2014) rate of 0.2. For the encoder, we also concatenate ELMo <ref type="bibr" target="#b18">(Peters et al., 2018)</ref> embeddings with a dropout rate of 0.5 and the token representations from the output of embedding layer to form the final token representations, before processing them through the first bidirectional GRU. We use the ELMo weights pretrained on the 5.5B dataset. 5 To speed up computations, we cache the context independent token representations of all tokens that appear at least once in the titles of the HotpotQA Wikipedia version, or appear at least five times in the entire Wikipedia version. Words not in this vocabulary are given a fixed OOV vector. We use a learned weighted average of all three ELMo layers. Variational dropout <ref type="bibr" target="#b8">(Gal and Ghahramani, 2016)</ref>, where the same dropout mask is applied at each time step, is applied on the inputs of all recurrent layers with a dropout rate of 0.2. We set the encoding size to be d = 1024.</p><p>For the paragraph reader used for HotpotQA, we use a state size of 150 for the bidirectional GRUs. The size of the hidden layer in the MLP used for supporting fact prediction is set to 150 as well. Here again variational dropout with a dropout rate of 0.2 is applied on the inputs of all recurrent layers and attention mechanisms. The reader used for SQuAD is the shared-norm model trained on the SQuAD dataset by <ref type="bibr">Clark and Gardner (2018). 6</ref> Training Details We train all our models using the Adadelta optimizer (Zeiler, 2012) with a learning rate of 1.0 and ? = 0.95.</p><p>SQuAD-Open: The training data is gathered as follows. For each question in the original SQuAD dataset, the original paragraph given as the question's context is considered as the single relevant (positive) paragraph. We gather ?12 irrelevant (negative) paragraphs for each question in the following manner:</p><p>? The three paragraphs with the highest TF-IDF similarity to the question in the same SQuAD document as the relevant paragraph (excluding the relevant paragraph). The same method is applied to retrieve the three paragraphs most similar to the relevant paragraph.</p><p>? The two paragraphs with the highest TF-IDF similarity to the question from the set of all first paragraphs in the entire Wikipedia (excluding the relevant paragraph's article). The same method is applied to retrieve the two paragraphs most similar to the relevant paragraph.</p><p>? Two randomly sampled paragraphs from the entire Wikipedia.</p><p>Questions that contain only stop-words are dropped, as they are most likely too dependent on the original context and not suitable for opendomain. In each epoch, a question appears as a training sample four times; once with the relevant paragraph, and three times with randomly sampled irrelevant paragraphs. We train with a batch size of 45, and do not use the ranking loss by setting ? = 0 in Equation (2). We limit the length of the paragraphs to 600 tokens.</p><p>HotpotQA: The paragraphs used for training the encoder are the gold and distractor paragraphs supplied in the original HotpotQA training set. As mentioned in Section 3.1, each training sample consists of a question and two paragraphs, (Q, P 1 , P 2 ), where P 1 corresponds to a paragraph retrieved in the first iteration, and P 2 corresponds to a paragraph retrieved in the second iteration. For each question, we create the following sample types:</p><p>1. Gold: The two paragraphs are the two gold paragraphs of the question. Both P 1 and P 2 are considered positive.</p><p>2. First gold, second distractor: P 1 is one of the gold paragraphs and considered positive, while P 2 can be a random paragraph from the training set, the same as P 1 , or one of the distractors, with probabilities 0.05, 0.1 and 0.85, respectively. P 2 is considered negative.</p><p>3. First distractor, second gold: P 1 is either one of the distractors or a random paragraph from the training set, with probabilities 0.9 and 0.1, respectively. P 2 is one of the gold paragraphs. Both P 1 and P 2 are considered negative.</p><p>4. All distractors: Both P 1 and P 2 are sampled from the question's distractors, and are considered negative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Gold from another question:</head><p>A gold paragraph pair taken from another question; both paragraphs are considered negative.</p><p>The use of the sample types from the above list motivation is motivated as follows. Sample type 1 is the only one that contains purely positive examples and hence is mandatory. Sample type 2 is necessary to allow the model to learn a valuable reformulation, which does not give a relevant score based solely on the first paragraph. Sample type 3 is complementary to type 2; it allows the model to learn that a paragraph pair is irrelevant if the first paragraph is irrelevant, regardless of the second. Sample type 3 is used for random negative sampling, which is the most common case of all. Sample type 4 is used to guarantee the model does not determine relevancy solely based on the paragraph pair, but also based on the question. In each training batch, we include three samples for each question in the batch: a single gold sample (type 1), and two samples from the other four types, with sample probabilities of 0.35, 0.35, 0.25 and 0.05, respectively.</p><p>We use a batch size of 75 (25 unique questions). We set the margin to be ? = 1 in Equation (1) and ? = 1 in Equation (2), for both prediction iterations. We limit the length of the paragraphs to 600 tokens.</p><p>HotpotQA Reader: The reader receives a question and a concatenation of a paragraph pair as input. Each training batch consists of three samples with three different paragraph pairs for each question: a single gold pair, which is the two gold paragraphs of the question, and two randomly sampled paragraph pairs from the set of the distractors and one of the gold paragraphs of the question. We label the correct answer spans to be every text span that has an exact match with the ground truth answer, even in the distractor paragraphs. We use a batch size of 75 (25 unique questions), and limit the length of the paragraphs (before concatenation) to 600 tokens.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>A high-level overview of our solution, MUPPET. Architecture of the main components of our paragraph and question encoder. (a) Our sentence encoder architecture. The model receives a series of tokens as input and produces a sequence of sentence representations. (b) Our reformulation component architecture. This layer receives contextualized representations of a question and a paragraph, and produces a reformulated representation of the question.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Various results based on the TF-IDF retriever. (a) Retrieval results of the TF-IDF hueristic retriever on HotpotQA. At Least One @ k is the number of questions for which at least one of the paragraphs containing the supporting facts is retrieved in the top-k paragraphs. Potentially Perfect @ k is the number of questions for which both of the paragraphs containing the supporting facts are retrieved in the top-k paragraphs. (b) and (c) Performance analysis on the SQuAD-Open and HotpotQA datasets, respectively, as more documents/paragraphs are retrieved by the TF-IDF heuristic retriever. Note that for SQuAD-Open each document contains several paragraphs, and the reader is fed the top-k TF-IDF ranked paragraphs from within the documents in the search space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>L</head><label></label><figDesc>yes/no = ? log j?P Q e s yes/no j j?P Q (e s yes j + e s no j ) , where P Q is the set of paragraphs paired with the same question Q, and e s binary j , e s span j and e s type j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Yang et al., 2018) 44.44 58.28 21.95 66.66 11.56 40.86    Primary results for HotpotQA (dev set). At the top of the table, we compare our Paragraph Reader to the baseline model of (as of writing this paper, no other published results are available other than the baseline results)</figDesc><table><row><cell>F1</cell><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Primary results for SQuAD-Open.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Code is available at https://github.com/yairf11/MUPPET 2 https://rajpurkar.github.io/SQuAD-explorer/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">It has recently come to our attention that during our work, some details of the Wikipedia version have changed. Due to time limitations, we use the initial version description.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">March 5, 2019. Leaderboard available at https://hotpotqa.github.io/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Available at https://allennlp.org/elmo 6 Available at https://github.com/allenai/document-qa</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was partially supported by the Israel Science Foundation (grant No. 710/18).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07427</idno>
		<title level="m">Hierarchical memory networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1171</idno>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Aglar G?l?ehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bahdanau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Fethi Bougares, Holger Schwenk, and Yoshua Bengio</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo?c</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-step retrieverreader interaction for scalable open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shehzaad</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural models for reasoning over multiple mentions using coreference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiao</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2007</idno>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A theoretically grounded application of dropout in recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In NIPS</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Training a ranking function for opendomain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phu Mon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Htut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Billion-scale similarity search with gpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno>abs/1702.08734</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1147</idno>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ranking paragraphs for improving answer recall in open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seongjun</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miyoung</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Denoising distantly supervised open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhe</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mc-Closky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1147</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Amir-Hossein Karimi, Antoine Bordes, and Jason Weston</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient and robust question answering from minimal context over documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: Unanswerable questions for squad</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Squad: 100, 000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Phraseindexed question answering: A new challenge for scalable document comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The web as a knowledge-base for answering complex questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">R 3 : Reinforced ranker-reader for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerry</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evidence aggregation for answer re-ranking in open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Constructing datasets for multi-hop reading comprehension across documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<title level="m">Memory networks. In ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A deep cascade model for multi-document reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangnan</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongzhou</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiqing</forename><surname>Chen</surname></persName>
		</author>
		<idno>abs/1811.11374</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aileen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01718</idno>
		<title level="m">End-to-end open-domain question answering with bertserini</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">ADADELTA: an adaptive learning rate method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeiler</surname></persName>
		</author>
		<idno>abs/1212.5701</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Coarse-grain fine-grain coattention network for multi-evidence question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
