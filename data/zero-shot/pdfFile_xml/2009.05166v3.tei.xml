<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FILTER: An Enhanced Fusion Method for Cross-lingual Language Understanding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Dynamics 365 AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
							<email>shuohang.wang@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Dynamics 365 AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
							<email>zhe.gan@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Dynamics 365 AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqi</forename><surname>Sun</surname></persName>
							<email>siqi.sun@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Dynamics 365 AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Dynamics 365 AI Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">FILTER: An Enhanced Fusion Method for Cross-lingual Language Understanding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large-scale cross-lingual language models (LM), such as mBERT, Unicoder and XLM, have achieved great success in cross-lingual representation learning. However, when applied to zero-shot cross-lingual transfer tasks, most existing methods use only single-language input for LM finetuning, without leveraging the intrinsic cross-lingual alignment between different languages that proves essential for multilingual tasks. In this paper, we propose FILTER, an enhanced fusion method that takes cross-lingual data as input for XLM finetuning. Specifically, FILTER first encodes text input in the source language and its translation in the target language independently in the shallow layers, then performs crosslanguage fusion to extract multilingual knowledge in the intermediate layers, and finally performs further languagespecific encoding. During inference, the model makes predictions based on the text input in the target language and its translation in the source language. For simple tasks such as classification, translated text in the target language shares the same label as the source language. However, this shared label becomes less accurate or even unavailable for more complex tasks such as question answering, NER and POS tagging. To tackle this issue, we further propose an additional KL-divergence self-teaching loss for model training, based on auto-generated soft pseudo-labels for translated text in the target language. Extensive experiments demonstrate that FIL-TER achieves new state of the art on two challenging multilingual multi-task benchmarks, XTREME and XGLUE. 1 2 Fusion in the Intermediate Layers of TransformER</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Cross-lingual low-resource adaptation has been a critical and exigent problem in the NLP field, despite recent success in large-scale language models (mostly trained on English with abundant training corpora). How to adapt models trained in high-resource languages (e.g., English) to lowresource ones (most of the 6,900 languages in the world) still remains challenging. To address the proverbial domain gap between languages, three schools of approach have been widely studied. (i) Unsupervised pre-training: to learn a universal encoder (cross-lingual language model) for different * Equal Contribution Copyright ? 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. <ref type="bibr">1</ref> Our code is released at https://github.com/yuwfan/FILTER. languages. For example, mBERT <ref type="bibr" target="#b9">(Devlin et al. 2019)</ref>, Unicoder ) and XLM <ref type="bibr" target="#b16">(Lample and Conneau 2019)</ref> have achieved strong performance on many crosslingual tasks by successfully transferring knowledge from source language to a target one. (ii) Supervised training: to enforce models insensitive to labeled data across different languages, through teacher forcing <ref type="bibr" target="#b18">(Wu et al. 2020)</ref> or adversarial learning <ref type="bibr" target="#b2">(Cao, Liu, and Wan 2020)</ref>. (iii) Translation: to translate either source language to the target one, or vice versa <ref type="bibr" target="#b8">(Cui et al. 2019;</ref><ref type="bibr" target="#b12">Hu et al. 2020;</ref><ref type="bibr" target="#b18">Liang et al. 2020)</ref>, so that training and inference can be performed in the same language.</p><p>The translation approach has proven highly effective on recent multilingual benchmarks. For example, the translatetrain method has achieved state of the art on XTREME <ref type="bibr" target="#b12">(Hu et al. 2020</ref>) and XGLUE <ref type="bibr" target="#b18">(Liang et al. 2020</ref>). However, translate-train is simple data augmentation, which doubles training data by translating source text into target languages. Thus, only single-language input is considered for finetuning with augmented data, leaving out cross-lingual alignment between languages unexplored. Dual BERT <ref type="bibr" target="#b8">(Cui et al. 2019)</ref> is recently proposed to make use of the representations learned from source language to help target language understanding. However, it only injects information from the source language into the decoder of target language, without scoping into the intrinsic relations between languages.</p><p>Motivated by this, we propose FILTER, 2 a generic and flexible framework that leverages translated data to enforce fusion between languages for better cross-lingual language understanding. As illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>(c), FILTER first (i) encodes a translated language pair separately in shallow layers; then (ii) performs cross-lingual fusion between languages in the intermediate layers; and finally (iii) encodes language-specific representations in deeper layers. Compared to the translate-train baseline <ref type="figure" target="#fig_0">(Figure 2(a)</ref>), FILTER learns additional cross-lingual alignment that is instrumental to cross-lingual representations. Furthermore, compared to simply concatenating the language pair as the input of XLM <ref type="figure" target="#fig_0">(Figure 2(b)</ref>), FILTER strikes a well-measured balance between cross-lingual fusion and individual language representation learning.</p><p>For classification tasks such as natural language infer- <ref type="figure">Figure 1</ref>: Examples from XTREME for cross-lingual natural language inference, part-of-speech tagging, and question answering tasks. The source language is English; the target language can be any other languages.</p><p>ence, translated text in the target language shares the same label as the source language. However, for question answering (QA) tasks, the answer span in the translated text of target language generally differs from that in the source language. For sequential labeling tasks such as NER (Named Entity Recognition) and POS (Part-of-Speech) tagging, the sequence of labels in the target language becomes unavailable, as the linguistic structure of sentences greatly varies across different languages. To bridge the gap, we propose to generate soft pseudo-labels for translated text, and use an additional KL-divergence self-teaching loss for model training. Specifically, we first train a teacher FILTER model, to collect the inference probabilities for the translated text of all training samples, which will be used as pseudo soft-labels to train a student FILTER as the final prediction model. For QA, POS and NER tasks, this self-training process generates more reliable and accurate labels than hard label assignment on translated text, leading to better model performance. For classification tasks where the target label is identical to the source, self-teaching loss proves to also improve performance, by serving as an effective regularizer.</p><p>The main contributions are summarized as follows. (i) We propose FILTER, a new approach to cross-lingual language understanding by leveraging intrinsic linguistic alignment between languages for XLM finetuning. (ii) We propose a self-teaching loss to address the unreliable/unavailable label issue in target language, boosting model performance across diverse NLP tasks. (iii) We achieve Top-1 performance on both XTREME and XGLUE benchmarks, outperforming previous state of the art by absolute 8.8 and 2.2 points (published and unpublished) in XTREME, and 4.0 points in XGLUE, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Cross-lingual Datasets Cross-lingual language understanding has been investigated for many NLP tasks, where the knowledge learned from a pivot language (e.g., English) is transferred to other languages indirectly, as labeled data in low-resource languages are often scarce. There exist many multilingual corpora for diverse NLP tasks. <ref type="bibr" target="#b20">Nivre et al. (2016)</ref> released a collection of multilingual treebanks on universal dependencies for 33 languages. <ref type="bibr">Pan et al. (2017)</ref> introduced cross-lingual name tagging and linking for 282 languages. Other multilingual datasets range over tasks such as document classification, natural language inference, information retrieval, paraphrase identification, and summa-rization <ref type="bibr" target="#b15">(Klementiev, Titov, and Bhattarai 2012;</ref><ref type="bibr" target="#b3">Cer et al. 2017;</ref><ref type="bibr" target="#b7">Conneau et al. 2018;</ref><ref type="bibr" target="#b21">Sasaki et al. 2018;</ref><ref type="bibr">Yang et al. 2019;</ref><ref type="bibr">Zhu et al. 2019)</ref>.</p><p>More recent studies on open-domain question answering and machine reading comprehension also introduced cross-lingual datasets, such as MLQA <ref type="bibr" target="#b17">(Lewis et al. 2020)</ref>, XQuAD <ref type="bibr" target="#b0">(Artetxe, Ruder, and Yogatama 2020)</ref>, and Ty-DiQA <ref type="bibr" target="#b5">(Clark et al. 2020)</ref>. Most recently, XTREME <ref type="bibr" target="#b12">(Hu et al. 2020</ref>) and XGLUE <ref type="bibr" target="#b18">(Liang et al. 2020)</ref> released several datasets across multiple tasks, and set up public leaderboards for evaluating cross-lingual models. In this paper, we work on both XTREME (see <ref type="figure">Figure 1</ref> for examples) and XGLUE to demonstrate the effectiveness of our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-lingual Models</head><p>Most previous work tackles crosslingual problems in two fashions: (i) cross-lingual zeroshot transfer; and (ii) translate-train/test. For cross-lingual zero-shot transfer, models are trained on labeled data in the source language only, and directly evaluated on target languages. Early work focused on training multilingual word embeddings <ref type="bibr" target="#b19">(Mikolov, Le, and Sutskever 2013;</ref><ref type="bibr" target="#b10">Faruqui and Dyer 2014;</ref><ref type="bibr">Xu et al. 2018)</ref>, while more recent work proposed to pre-train cross-lingual language models, such as mBERT <ref type="bibr" target="#b9">(Devlin et al. 2019)</ref>, XLM <ref type="bibr" target="#b16">(Lample and Conneau 2019)</ref> and XLM-Roberta <ref type="bibr" target="#b6">(Conneau et al. 2020)</ref>, to learn contextualized representations.</p><p>For translate-train/test, external machine translation tools are leveraged. A common approach is to augment training data by first translating all data in the source language to target languages, then train the model on translated data <ref type="bibr" target="#b12">(Hu et al. 2020;</ref><ref type="bibr" target="#b18">Liang et al. 2020)</ref>. Another approach is translatetest <ref type="bibr" target="#b12">(Hu et al. 2020)</ref> or round-trip translation <ref type="bibr">(Zhu et al. 2019)</ref>, which translates the text in the test set of target languages into source language, so that all the models trained in the source language can be directly applied for inference, and the prediction can be translated back to the target language if needed. To enhance these translation-based pipelines, <ref type="bibr" target="#b8">Cui et al. (2019)</ref> proposed to simultaneously model text in both languages to enrich the learned language representations. <ref type="bibr" target="#b14">Huang, Ji, and May (2019)</ref> proposed to use adversarial transfer to enhance low-resource name tagging. <ref type="bibr" target="#b2">And Cao, Liu, and Wan (2020)</ref> proposed to jointly learn the alignment and perform summarization across languages. FILTER follows the translate-train line of thought, but provides a better way to encode text in both source and target languages simultaneously. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposed Approach</head><p>In this section, we first introduce the proposed FILTER model architecture, then describe the self-teaching loss for model enhancement. An overview of the framework is illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FILTER Architecture</head><p>Although the domain gap between languages has been largely reduced by translate-train method, translated text may not succeed in keeping the semantic meaning and label of the original text unchanged, due to quality constraint of translation tools. Furthermore, the source language and translated target language are usually encoded separately, without tapping into the cross-lingual relations among different languages. Therefore, we propose to use language pairs as input, and fuse the learned representations between languages through intermediate network layers, so that the model can learn cross-lingual information that is instrumental to inference in different languages. The proposed FILTER model consists of three components: (i) "local" Transformer layers for encoding the input language pair independently; (ii) cross-lingual fusion layers for leveraging the context in different languages; and (iii) deeper domain-specific Transformer layers to shift the focus back on individual languages, after injecting information from the other language. For notation, S ? R d?ls and T ? R d?lt are denoted as the word embedding matrix for text input S and T in the source and target language, respectively. If tasks involve pairwise data, S is the concatenation of a sequence pair, such as the context and question in QA tasks. T is translated from S via translation tools. d is the word embedding dimension. l s and l t are the lengths of the text input S and T , respectively. Formally,</p><formula xml:id="formula_0">H s l = Transformer-XLM local (S) , H t l = Transformer-XLM local (T) ,</formula><p>where the position embeddings are counted from 0 for both sequences, H s l ? R d?ls and H t l ? R d?lt are "local" representations of the sequence pair. We set the number of layers in Transformer-XLM local as m, which can be tuned for solving different cross-lingual tasks. The concatenation of the local representations from both languages, [H s l ; H t l ] ? R d?(ls+lt) , is the input for the next layer to learn the fusion between different languages, as follows:</p><formula xml:id="formula_1">H s f ; H t f = Transformer-XLM f use ( H s l ; H t l ) ,</formula><p>(1) where [?; ?] denotes the concatenation of two matrices, H s f ? R d?ls and H t f ? R d?lt are the representations in corresponding languages. We set the number of layers in Transformer-XLM f use as k, which is another hyperparameter to control the cross-lingual fusion degree. As the final goal is to predict the label in one language, we limit the top layers specifically designed to encode the text in one language, so that not too much noise is introduced from translated text in other languages. Specifically,</p><formula xml:id="formula_2">H s d = Transformer-XLM domain (H s f ),<label>(2)</label></formula><formula xml:id="formula_3">H t d = Transformer-XLM domain (H t f ),<label>(3)</label></formula><p>where H s d ? R d?ls and H t d ? R d?lt are the final representations for prediction.</p><p>As demonstrated in <ref type="figure" target="#fig_0">Figure 2</ref>, FILTER is realized by stacking the three types of transformer layer on top of each other. FILTER is a generic framework for solving multilingual tasks, where k and m can be flexibly set to different values depending on the task. For example, for classification tasks, a smaller k is desired; while for question answering, Algorithm 1 FILTER Training Procedure.</p><p>1: # Teacher model training 2: # S, l s : text and label in the source language 3: # T, l t : text and label in the target language 4: for all S, l s do 5:</p><p>T = Translation (S); 6:</p><p>l t = Transfer from l s if available; 7:</p><p>Train FILTER tea with (S, l s ) and (T, l t ); 8: end for 9:</p><p>10: # Self-teaching, i.e., student model training 11: for all S, l s , T, l t do 12:</p><formula xml:id="formula_4">p s tea , p t tea = FILTER tea (S, T ) 13:</formula><p>Train FILTER stu with (S, l s ), (T, l t ) and (T, p t tea ) 14: end for a larger k is needed for absorbing richer cross-lingual information (see Experiments for empirical evidence). Since we use XLM-R as the backbone in our framework, the number of layers in Transformer-XLM domain is 24 ? k ? m. When m = 24, k = 0, FILTER degenerates to the translate-train baseline <ref type="figure" target="#fig_0">(Figure 2(a)</ref>). When m = 0, k = 24, FILTER reduces to another baseline that simply concatenates the text in different languages for XLM finetuning <ref type="figure" target="#fig_0">(Figure 2(b)</ref>). FILTER also stacks a task-specific linear layer on top of H s d and H t d to compute the candidate probabilities and we simplify the whole framework as follows:</p><formula xml:id="formula_5">p s , p t = FILTER (S, T), L s = Loss task (p s , l s ), L t = Loss task (p t , l t ),<label>(4)</label></formula><p>where p s and p t are task-specific probability vectors over candidates, used to compute the final loss based on the labels l s and l t from source and target languages, respectively. As shown in <ref type="figure">Figure 1</ref>, for natural language inference, the label can be entailment/contradiction/neutral; for question answering, the label is an answer span positions; for NER and POS tagging, the supervision becomes a sequence of labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Self-Teaching Loss</head><p>The teacher-student framework, or distillation loss <ref type="bibr" target="#b11">(Hinton, Vinyals, and Dean 2015)</ref>, has been widely adopted in many areas. In this paper, we propose to add self-teaching loss for training FILTER, and it can be readily adapted to all the cross-lingual tasks. As transferring the labels in source language to the corresponding translated text may introduce noise due to the word order or even semantic meaning changes after translation, the additional self-teaching loss is to bridge this gap. The proposed training procedure is summarized in Algorithm 1. We first train a "teacher" FILTER based on clean labels in the source language and the transferred "noisy" labels in the target language (if available) with loss from Eqn. (4). This FILTER will then be used as a teacher to generate pseduo soft-labels to regularize a second FILTER (student) trained from scratch. As the noise mainly comes from translated text, we only add soft labels in the target language dur- </p><formula xml:id="formula_6">p s tea , p t tea = FILTER tea (S, T), p s stu , p t stu = FILTER stu (S, T), L kl = Loss KL (p t tea , p t stu ),<label>(5)</label></formula><p>where Loss KL denotes KL divergence. The soft label p t tea is fixed when training the student FILTER, which is used for final prediction. When no labels can be transferred to the target language, this method helps the model receive more gradients on the target language, instead of purely on the source side, thus reducing the domain gap between languages. When labels can be transferred, it serves as a smoothing or regularization term appended to the supervised losses. By merging the self-teaching loss, our final training objective for the student FILTER is summarized as:</p><formula xml:id="formula_7">L f inal = L s + ?L t + (1 ? ?)L kl ,<label>(6)</label></formula><p>where ? is a hyper-parameter to tune, and ? is set to zero when no labels in the target languages can be transferred from the source language (e.g., for NER and POS tagging).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inference</head><p>During inference, we pair the text input in the target language with the translated text in the source language, so that FILTER can fuse the information from both languages. For classification tasks, we use the probabilities from either source or target language for prediction. However, for structured prediction and question answering tasks, only the probabilities from the target language can be used for prediction, as the tagging order is different between languages, and the answers are also difficult to evaluate if in different languages. Therefore, for simplicity, we consistently use the probabilities p t stu from the target language for final prediction.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In this section, we present experimental results on the XTREME and XGLUE benchmarks and provide detailed analysis on the effectiveness of FILTER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>There are nine datasets in both XTREME <ref type="bibr" target="#b12">(Hu et al. 2020)</ref> and XGLUE <ref type="bibr" target="#b18">(Liang et al. 2020)</ref>  Tatoeba <ref type="bibr" target="#b1">(Artetxe and Schwenk 2019)</ref>. For leaderboard submission, we apply models trained on XNLI directly on these two datasets for inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>Our implementation is based on HuggingFace's Transformers <ref type="bibr">(Wolf et al. 2019)</ref>. We leverage the pre-trained XLM-R model <ref type="bibr" target="#b6">(Conneau et al. 2020)</ref> to initialize our FILTER, which contains 24 layers, each layer with 1,024 hidden states. For fair comparison to XLM-R, each transformer layer in FIL-TER is shared for encoding both source and target languages, so that the total number of parameters are exactly the same as XLM-R.</p><p>We conduct experiments on 8 Nvidia V100-32GB GPU cards for model finetuning, and set batch size to 64 for all tasks. For self-teaching loss, we set the weight of the KL loss to 1.0 for structured prediction tasks where no labels are available in the target language. We set the weight of KL loss for classification and QA tasks to 0.5 and 0.1 respectively, by searching over [0.1, 0.3, 0.5]. As the official XTREME repo 3 does not provide translated target language data for POS and NER, we use Microsoft Machine Translator 4 for translation. More details on translation data and model hyper-parameters are provided in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines</head><p>We compare FILTER with previous state-of-the-art multilingual models:</p><p>? Pre-trained models: mBERT <ref type="formula">(</ref>   <ref type="table">Table 5</ref>: XNLI accuracy scores for each language. Results of mBERT, MMTE, XLM and XLM-R are from XTREME <ref type="bibr" target="#b12">(Hu et al. 2020)</ref>. mtl denotes translate-train in multi-task version.</p><p>Transformer models on large-scale multi-lingual dataset including machine translation data. ? Data augmentation: X-STILTs <ref type="bibr" target="#b21">(Phang et al. 2020)</ref> first finetunes XLM-R on an additional intermediate auxiliary task, then further finetunes on the target task. ? Translate-train <ref type="bibr" target="#b12">(Hu et al. 2020</ref>) finetunes cross-lingual pre-trained language model XLM-R on English training data and all translated data by using Google's in-house Machine Translation system.  <ref type="table" target="#tab_6">Table 4</ref> provides more detailed results on different tasks in XTREME. First, we build a strong translate-train baseline using XLM-R as the backbone, which already outperforms previous state-of-the-art models by a significant margin on every dataset. Second, compared to the translate-train XLM-R baseline, FILTER further provides 0.9 and 2.28 points improvement on average on classification and question answering tasks. Lastly, the self-teaching loss further boosts the performance of FILTER on every dataset, especially on POS and NER tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Results</head><p>To provide a deeper look into the model performance across languages, <ref type="table">Table 5</ref> provides results on each language, taking the XNLI dataset as an example. Results show that FILTER outperforms all baselines on each language. Complete results on other datasets are provided in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Analysis</head><p>Below, we provide a detailed analysis to better understand the effectiveness of FILTER and the self-teaching loss on different tasks. In general, we observe that different tasks need different numbers of "local" transformer layers (m) and intermediate fusion layers (k) Furthermore, the self-teaching loss is helpful on all tasks, especially on tasks lacking labels   <ref type="table">Table 6</ref>: Analysis on cross-lingual transfer gap of different models on XTREME benchmark (except for retrieval task). A lower gap indicates a better cross-lingual transfer model. The average score (Avg) is calculated on all classification and QA tasks.</p><p>in the target languages. Effect of Fusing Languages As shown in <ref type="table" target="#tab_6">Table 4</ref> and discussed above, FILTER outperforms the translate-train baseline by a significant margin on classification and QA datasets, demonstrating the effectiveness of fusing languages. For POS and NER, there is no translate-train baseline as labels are unavailable in translated target language. Nonetheless, FILTER improves XLM-R by 2.9 and 1.3 points, thanks to the use of intermediate cross-attention between language pair. For the simple concatenation baseline, its performance can be analyzed by setting m = 0, k = 24 in <ref type="figure" target="#fig_1">Figure 3</ref>. Compared to FILTER, the performance drops 2.5/15.2 points on PAWS-X and POS datasets. For MLQA, there is only a minor drop. We hypothesize that for simple classification tasks, single-language input already provides rich information, while concatenating the paired language input directly at the very beginning introduces more noise, therefore making the model more difficult to train. Overall, performing cross-attention between the language pair in intermediate layers performs the best. <ref type="figure" target="#fig_1">Figure 3</ref> shows the results on the dev sets with different k and m combinations (see <ref type="figure" target="#fig_0">Figure 2</ref> for its definition). We perform experiments on PAWS-X, POS and MLQA, and consider them as representative datasets for classification, structured prediction and question answering tasks. For MLQA, performance is consistently improved with the number of intermediate fusion layers increasing, resulting in 2.6 points improvement from k = 1 to k = 20 when m is set to 1. By contrast, the performance on PAWS-X and POS drops significantly when the number of intermediate fusion layers increases. For example, when m is set to 1, accuracy decreases by 2.5/16.5 points from k = 1 to k = 24 on PAWS-X and POS datasets. Effect of Local Transformer Layers As shown in <ref type="figure" target="#fig_1">Figure 3</ref>, for POS and MLQA, FILTER performs better when using more local transformer layers. For example, when k is set to 10, we observe performance improvement by setting m to 0, 1, 10 sequentially. On the contrary, for PAWS-X, when k = 10, the performance of setting m = 0, 1 is better than setting m = 10. This suggests that we should use more local layers for complex tasks such as QA and structured prediction, and fewer local layers for classification tasks. Effect of Self-teaching Loss As can be seen from Table 4, for POS and NER, the use of self-teaching loss improves FILTER by 0.7 and 1.0 points. This confirms that self-teaching loss is very helpful in addressing the no-label issue for target languages. For classification and question answering tasks, we observe minor improvement, which is expected, as ground-truth labels are available for target languages, and adding the self-teaching loss only provides some label smoothing effect. <ref type="table">Table 6</ref> shows analysis results of cross-lingual gap of different models, by calculating the difference between the performance on English test set and the average performance of other target languages. We observe that FILTER reduces the cross-lingual gap significantly among all tasks compared to mBERT, XLM-R and translate-train baselines. The transfer learning gap of FIL-TER is reduced by additional 2.5 and 10.6 points on average for classification and QA tasks, respectively, compared to the translate-train baseline respectively. For structured prediction tasks, the gap reduces even further, but a large gap still exists, indicating that this task demands stronger crosslingual transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Intermediate Fusion Layers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-lingual Transfer Gap</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We present FILTER, a new approach for cross-lingual language understanding that first encodes paired language input independently, then fuses them in the intermediate layers of XLM, and finally performs further language-specific encoding. An additional self-teaching loss is proposed for enhanced model training. By combining FILTER and selfteaching loss, we achieve new state of the art on the challenging XTREME and XGLUE benchmarks. Future work points to more effective ways of automatically discovering the best configuration of FILTER for different cross-lingual tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-parameters</head><p>For XNLI, PAWS-X and TyDiQA-Gold, we finetune 4 epochs. For MLQA and XQuAD, we finetune 2 epochs. To select the best k and m for each dataset, we choose PAWS-X, POS and MLQA as the representative datasets for each category. Then, we perform grid search over k and m from <ref type="bibr">[1, 10, 20, 24] and [0, 1, 10, 20]</ref> on the dev set, respectively, and apply the best hyper-parameters for all tasks in each category. Note that we keep k + m ? 24. After choosing the best k and m, learning rate is the only hyper-parameter tuned for FILTER. We select the model with the best average result over all the languages on the dev sets, by searching the learning rate over <ref type="bibr">[3e-6, 5e-6, 1e-5]</ref>. We use the hyperparameters learned from MLQA for XQuAD test set, which does not have a dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Translation Data</head><p>During training, we use the provided English training data as the source language. The translated target-language training data of XNLI and PAWS-X are provided in the original datasets. For POS and NER, we use Microsoft Machine Translator 5 to translate English training data to target languages. As the translator does not cover all target languages, we exclude paired training data in the following languages: Basque, Javanese, Georgian, Burmese, Tagalog and Yoruba. For XQuAD, MLQA and TyDiQA-GoldP, we use the translation data provided by the official XTREME repo 6 . For leaderboard submission, we use additional SQuAD v1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results for Each Dataset and Language</head><p>Below, we provide detailed results for each dataset and language. Results of mBERT, XLM, MMTE and XLM-R are from XTREME <ref type="bibr" target="#b12">(Hu et al. 2020</ref>       </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Comparison between different methods for finetuning XLM-R model for the XTREME benchmark. (a) Translate-train baseline. (b) Another baseline via simple concatenation of translated text. (c) Proposed FILTER approach. (a) and (b) can be considered as special instantiations of FILTER by setting m = 24, k = 0 and m = 0, k = 24, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Results on the dev set of PAWS-X, POS and MLQA with different m and k values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the datasets in XTREME and XGLUE. #train, #dev and #test are the numbers of examples in the training, dev and test sets, respectively. For dev and test set, the number is for each target language. #languages is the number of target languages in the test set. Note that language generation tasks in XGLUE are not included.</figDesc><table><row><cell>Benchmark</cell><cell>Task</cell><cell>Dataset</cell><cell cols="2">#train #dev</cell><cell>#test</cell><cell>#languages</cell></row><row><cell></cell><cell>Classification</cell><cell>XNLI PAWS-X</cell><cell cols="2">392K 2.5K 49.4K 2K</cell><cell>5K 2K</cell><cell>15 7</cell></row><row><cell>XTREME</cell><cell>Struct. pred.</cell><cell>POS NER</cell><cell>21K 20K</cell><cell>4K 10K</cell><cell>47-20K 1K-10K</cell><cell>33 40</cell></row><row><cell></cell><cell>QA</cell><cell>XQuAD MLQA</cell><cell>87K</cell><cell>34K</cell><cell>1190 4.5K-11K</cell><cell>11 7</cell></row><row><cell></cell><cell></cell><cell cols="4">TyDiQA-GoldP 3.7K 0.6K 0.3K-2.7K</cell><cell>9</cell></row><row><cell></cell><cell>Retrieval</cell><cell>BUCC Tatoeba</cell><cell>--</cell><cell>--</cell><cell>1.9K-14K 1K</cell><cell>5 33</cell></row><row><cell></cell><cell></cell><cell>XNLI</cell><cell cols="2">392K 2.5K</cell><cell>5K</cell><cell>15</cell></row><row><cell></cell><cell></cell><cell>PAWS-X</cell><cell>49.4K</cell><cell>2K</cell><cell>2K</cell><cell>4</cell></row><row><cell></cell><cell>Classification</cell><cell>NC QADSM</cell><cell cols="2">100K 10K 100K 10K</cell><cell>10K 10K</cell><cell>5 3</cell></row><row><cell>XGLUE</cell><cell></cell><cell>WPR</cell><cell cols="2">100K 10K</cell><cell>10K</cell><cell>7</cell></row><row><cell></cell><cell></cell><cell>QAM</cell><cell cols="2">100K 10K</cell><cell>10K</cell><cell>3</cell></row><row><cell></cell><cell>Struct. pred.</cell><cell>POS NER</cell><cell cols="2">25.4K 1.0K 15.0K 2.8K</cell><cell>0.9K 3.4K</cell><cell>18 4</cell></row><row><cell></cell><cell>QA</cell><cell>MLQA</cell><cell cols="2">87.6K 0.6K</cell><cell>5.7K</cell><cell>7</cell></row></table><note>ing the training of the second FILTER. Specifically,</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results on the test set of XTREME. FILTER achieves new state of the art at the time of submission(Sep. 8, 2020). For TydiQA-GoldP dataset, we use additional SQuAD v1.1 English training data. The score on question answering is calculated by the average of EM and F1 scores on three datasets. ( ?) indicates unpublished work.</figDesc><table><row><cell>Model</cell><cell cols="7">Avg NER POS NC MLQA XNLI PAWS-X QADSM WPR QAM</cell></row><row><cell cols="2">Unicoder 76.1 79.7 79.6 83.5</cell><cell>66.0</cell><cell>75.3</cell><cell>90.1</cell><cell>68.4</cell><cell>73.9</cell><cell>68.9</cell></row><row><cell>FILTER</cell><cell>80.1 82.6 81.6 83.5</cell><cell>76.2</cell><cell>83.9</cell><cell>93.8</cell><cell>71.4</cell><cell>74.7</cell><cell>73.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Results on the test set of XGLUE. FILTER achieves new state of the art at the time of submission (Sep. 14, 2020). Note that cross-lingual language generation tasks are not included. Leaderboard: https://microsoft.github.io/XGLUE.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Teaching 89.5 83.6 86.4 85.6 85.4 86.6 85.7 81.1 83.7 78.7 81.7 83.2 79.1 83.9 83.8 83.9</figDesc><table><row><cell>Model</cell><cell>en</cell><cell>ar</cell><cell>bg</cell><cell>de</cell><cell>el</cell><cell>es</cell><cell>fr</cell><cell>hi</cell><cell>ru</cell><cell>sw</cell><cell>th</cell><cell>tr</cell><cell>ur</cell><cell>vi</cell><cell>zh</cell><cell>avg</cell></row><row><cell>mBERT</cell><cell cols="16">80.8 64.3 68.0 70.0 65.3 73.5 73.4 58.9 67.8 49.7 54.1 60.9 57.2 69.3 67.8 65.4</cell></row><row><cell>MMTE</cell><cell cols="16">79.6 64.9 70.4 68.2 67.3 71.6 69.5 63.5 66.2 61.9 66.2 63.6 60.0 69.7 69.2 67.5</cell></row><row><cell>XLM</cell><cell cols="16">82.8 66.0 71.9 72.7 70.4 75.5 74.3 62.5 69.9 58.1 65.5 66.4 59.8 70.7 70.2 69.1</cell></row><row><cell>XLM-R</cell><cell cols="16">88.7 77.2 83.0 82.5 80.8 83.7 82.2 75.6 79.1 71.2 77.4 78.0 71.7 79.3 78.2 79.2</cell></row><row><cell cols="17">XLM-R (translate-train) 88.6 82.2 85.2 84.5 84.5 85.7 84.2 80.8 81.8 77.0 80.2 82.1 77.7 82.6 82.7 82.6</cell></row><row><cell>FILTER</cell><cell cols="16">89.7 83.2 86.2 85.5 85.1 86.6 85.6 80.9 83.4 78.2 82.2 83.1 77.4 83.7 83.7 83.6</cell></row><row><cell>FILTER + Self-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>Overall test results on three different categories of cross-lingual language understanding tasks. Results of mBERT (De- vlin et al. 2019), XLM (Lample and Conneau 2019) and XLM-R (Conneau et al. 2020) are from XTREME (Hu et al. 2020). InfoXLM (Chi et al. 2020) only provides results on XNLI and MLQA. We also experimented on translate-train with XLM-R as an additional baseline for fair comparison with FILTER.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>and 3 summarizes our results on XTREME and</cell></row><row><cell>XGLUE, outperforming all the leaderboard submissions.</cell></row><row><cell>On XTREME, compared to the unpublished state-of-the-</cell></row><row><cell>art VECO approach, FILTER outperforms by 2.8/1.5/1.3/4.0</cell></row><row><cell>points on the four categories respectively, achieving an aver-</cell></row><row><cell>age score of 77.0, an absolute 2.2-point improvement. Com-</cell></row><row><cell>pared to the XLM-R baseline, we achieve an absolute 8.8-</cell></row><row><cell>point improvement (77.0 vs. 68.2), which is a significant</cell></row><row><cell>margin. On XGLUE, compared to the Unicoder baseline,</cell></row><row><cell>FILTER achieves an absolute 4.0-point improvement.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>J.; Xu, C.; Scao, T. L.; Gugger, S.; Drame, M.; Lhoest, Q.; and Rush, A. M. 2019. HuggingFace's Transformers: Stateof-the-art Natural Language Processing. arXiv preprint arXiv:1910.03771 . Wu, Q.; Lin, Z.; Karlsson, B. F.; Lou, J.-G.; and Huang, B. 2020. Single-/Multi-Source Cross-Lingual NER via Teacher-Student Learning on Unlabeled Data in Target Language. In Association for Computational Linguistics.</figDesc><table><row><cell>Xu, R.; Yang, Y.; Otani, N.; and Wu, Y. 2018. Unsupervised</cell></row><row><cell>cross-lingual transfer of word embedding spaces. In Empir-</cell></row><row><cell>ical Methods in Natural Language Processing.</cell></row><row><cell>Yang, Y.; Zhang, Y.; Tar, C.; and Baldridge, J. 2019. PAWS-</cell></row><row><cell>X: A cross-lingual adversarial dataset for paraphrase iden-</cell></row><row><cell>tification. In Empirical Methods in Natural Language Pro-</cell></row><row><cell>cessing.</cell></row><row><cell>Zhu, J.; Wang, Q.; Wang, Y.; Zhou, Y.; Zhang, J.; Wang, S.;</cell></row><row><cell>and Zong, C. 2019. NCLS: Neural cross-lingual summariza-</cell></row><row><cell>tion. In Empirical Methods in Natural Language Process-</cell></row><row><cell>ing.</cell></row><row><cell>Zweigenbaum, P.; Sharoff, S.; and Rapp, R. 2018. Overview</cell></row><row><cell>of the third BUCC shared task: Spotting parallel sentences</cell></row><row><cell>in comparable corpora. In Proceedings of 11th Workshop on</cell></row><row><cell>Building and Using Comparable Corpora.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>1 training data during finetuning on TyDiQA-Gold, as the original training set only contains 3K training samples. During inference, we automatically translate the target-language test data to English using the aforementioned translator. For POS and NER, we use the original target-language text itself if the target languages are not covered by the translator.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>PAWS-X accuracy scores for each language./ 72.2 61.5 / 45.1 70.6 / 54.0 62.6 / 44.9 75.5 / 56.9 59.2 / 46.0 71.3 / 53.3 42.7 / 33.5 55.4 / 40.1 69.5 / 49.6  58.0 / 48.3 64.5 / 49.4 XLM 74.2 / 62.1 61.4 / 44.7 66.0 / 49.7 57.5 / 39.1 68.2 / 49.8 56.6 / 40.3 65.3 / 48.2 35.4 / 24.5 57.9 / 41.2 65.8 / 47.6 49.7 / 39.7 59.8 / 44.3 MMTE 80.1 / 68.1 63.2 / 46.2 68.8 / 50.3 61.3 / 35.9 72.4 / 52.5 61.3 / 47.2 68.4 / 45.2 48.4 / 35.9 58.1 / 40.9 70.9 / 50.1 55.8 / 36.4 64.4 / 46.2 XLM-R 86.5 / 75.7 68.6 / 49.0 80.4 / 63.4 79.8 / 61.7 82.0 / 63.9 76.7 / 59.7 80.1 / 64.3 74.2 / 62.8 75.9 / 59.3 79.1 / 59.0 59.3 / 50.0 76.6 / 60.8 FILTER 85.6 / 73.0 79.8 / 61.3 82.5 / 66.2 82.6 / 64.6 84.8 / 67.4 83.1 / 66.5 82.5 / 66.8 80.7 / 73.9 81.2 / 65.7 83.3 / 64.1 78.9 / 75.7 82.3 / 67.8 FILTER + Self-Teaching 86.4 / 74.6 79.5 / 60.7 83.2 / 67.0 83.0 / 64.6 85.0 / 67.9 83.1 / 66.6 82.8 / 67.4 79.6 / 73.2 80.4 / 64.4 83.8 / 64.7 79.9 / 77.0 82.4 / 68.0</figDesc><table><row><cell>Model</cell><cell>en</cell><cell>ar</cell><cell>de</cell><cell>el</cell><cell>es</cell><cell>hi</cell><cell>ru</cell><cell>th</cell><cell>tr</cell><cell>vi</cell><cell>zh</cell><cell>avg</cell></row><row><cell>mBERT</cell><cell>83.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc>XQuAD results (F1 / EM) for each language.</figDesc><table><row><cell>Model</cell><cell>en</cell><cell>ar</cell><cell>de</cell><cell>es</cell><cell>hi</cell><cell>vi</cell><cell>zh</cell><cell>avg</cell></row><row><cell>mBERT</cell><cell cols="8">80.2 / 67.0 52.3 / 34.6 59.0 / 43.8 67.4 / 49.2 50.2 / 35.3 61.2 / 40.7 59.6 / 38.6 61.4 / 44.2</cell></row><row><cell>XLM</cell><cell cols="8">68.6 / 55.2 42.5 / 25.2 50.8 / 37.2 54.7 / 37.9 34.4 / 21.1 48.3 / 30.2 40.5 / 21.9 48.5 / 32.6</cell></row><row><cell>MMTE</cell><cell>78.5 / -</cell><cell>56.1 / -</cell><cell>58.4 / -</cell><cell>64.9 / -</cell><cell>46.2 / -</cell><cell>59.4 / -</cell><cell>58.3 / -</cell><cell>60.3 / 41.4</cell></row><row><cell>XLM-R</cell><cell cols="8">83.5 / 70.6 66.6 / 47.1 70.1 / 54.9 74.1 / 56.6 70.6 / 53.1 74.0 / 52.9 62.1 / 37.0 71.6 / 53.2</cell></row><row><cell>FILTER</cell><cell cols="8">83.5 / 70.3 71.8 / 51.0 74.6 / 59.8 77.9 / 60.2 76.1 / 57.7 77.7 / 57.2 69.0 / 44.2 75.8 / 57.2</cell></row><row><cell cols="9">FILTER + Self-Teaching 84.0 / 70.8 72.1 / 51.1 74.8 /60.0 78.1 / 60.1 76.0 / 57.6 78.1 /57.5 70.5 / 47.0 76.2 / 57.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 9 :</head><label>9</label><figDesc>MLQA results (F1 / EM) for each language. Teaching 72.4 / 59.1 72.8 / 50.8 70.5 / 56.6 73.3 / 57.2 76.8 / 59.8 33.1 / 12.3 68.9 / 46.6 77.4 / 65.7 69.9 / 50.4 68.3 / 50.9</figDesc><table><row><cell>Model</cell><cell>en</cell><cell>ar</cell><cell>bn</cell><cell>fi</cell><cell>id</cell><cell>ko</cell><cell>ru</cell><cell>sw</cell><cell>te</cell><cell>avg</cell></row><row><cell>mBERT</cell><cell cols="10">75.3 / 63.6 62.2 / 42.8 49.3 / 32.7 59.7 / 45.3 64.8 / 45.8 58.8 / 50.0 60.0 / 38.8 57.5 / 37.9 49.6 / 38.4 59.7 / 43.9</cell></row><row><cell>XLM</cell><cell cols="10">66.9 / 53.9 59.4 / 41.2 27.2 / 15.0 58.2 / 41.4 62.5 / 45.8 14.2 / 5.1 49.2 / 30.7 39.4 / 21.6 15.5 / 6.9 43.6 / 29.1</cell></row><row><cell>MMTE</cell><cell cols="10">62.9 / 49.8 63.1 / 39.2 55.8 / 41.9 53.9 / 42.1 60.9 / 47.6 49.9 / 42.6 58.9 / 37.9 63.1 / 47.2 54.2 / 45.8 58.1 / 43.8</cell></row><row><cell>XLM-R</cell><cell cols="10">71.5 / 56.8 67.6 / 40.4 64.0 / 47.8 70.5 / 53.2 77.4 / 61.9 31.9 / 10.9 67.0 / 42.1 66.1 / 48.1 70.1 / 43.6 65.1 / 45.0</cell></row><row><cell>FILTER</cell><cell cols="10">71.9 / 58.9 73.7 / 47.9 68.7 / 53.1 71.2 / 54.9 77.9 / 59.8 33.0 / 12.3 68.7 / 45.9 78.7 / 66.1 69.4 / 48.6 68.1 / 49.7</cell></row><row><cell>FILTER + Self-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 10 :</head><label>10</label><figDesc>TyDiQA-GolP results (F1 / EM) for each language. 56.2 85.0 85.2 81.1 95.5 86.9 79.1 60.7 66.7 78.9 84.2 56.2 67.2 78.3 71.0 88.4 XLM 88.5 63.1 85.0 85.8 84.3 95.4 85.8 78.3 62.8 64.7 78.4 82.8 65.9 66.2 77.3 70.2 87.4 MMTE 86.2 65.9 87.2 85.8 77.7 96.6 85.8 81.6 61.9 67.3 81.1 84.3 57.3 76.4 78.1 73.5 89.2 XLM-R 89.8 67.5 88.1 88.5 86.3 96.1 88.3 86.5 72.5 70.6 85.8 87.2 68.3 76.4 82.6 72.4 89.4 FILTER 88.5 66.0 87.6 89.0 88.1 96.0 89.0 85.9 76.8 70.7 85.9 87.8 64.9 75.4 82.5 72.6 88.6 FILTER + Self-Teaching 88.7 66.1 88.5 89.2 88.3 96.0 89.1 86.3 78.0 70.8 86.1 88.9 64.9 76.7 82.6 72.6 89.8 Teaching 40.4 80.4 53.3 86.4 89.4 88.3 90.5 65.3 87.3 57.2 94.1 77.0 70.9 58.0 43.1 53.1 76.9</figDesc><table><row><cell>Model</cell><cell>af</cell><cell>ar</cell><cell>bg</cell><cell>de</cell><cell>el</cell><cell>en</cell><cell>es</cell><cell>et</cell><cell>eu</cell><cell>fa</cell><cell>fi</cell><cell>fr</cell><cell>he</cell><cell>hi</cell><cell>hu</cell><cell>id</cell><cell>it</cell></row><row><cell>mBERT</cell><cell>86.6 ja</cell><cell>kk</cell><cell>ko</cell><cell>mr</cell><cell>nl</cell><cell>pt</cell><cell>ru</cell><cell>ta</cell><cell>te</cell><cell>th</cell><cell>tl</cell><cell>tr</cell><cell>ur</cell><cell>vi</cell><cell>yo</cell><cell>zh</cell><cell>avg</cell></row><row><cell>mBERT</cell><cell cols="17">49.2 70.5 49.6 69.4 88.6 86.2 85.5 59.0 75.9 41.7 81.4 68.5 57.0 53.2 55.7 61.6 71.5</cell></row><row><cell>XLM</cell><cell cols="17">49.0 70.2 50.1 68.7 88.1 84.9 86.5 59.8 76.8 55.2 76.3 66.4 61.2 52.4 20.5 65.4 71.3</cell></row><row><cell>MMTE</cell><cell cols="17">48.6 70.5 59.3 74.4 83.2 86.1 88.1 63.7 81.9 43.1 80.3 71.8 61.1 56.2 51.9 68.1 73.5</cell></row><row><cell>XLM-R</cell><cell cols="17">15.9 78.1 53.9 80.8 89.5 87.6 89.5 65.2 86.6 47.2 92.2 76.3 70.3 56.8 24.6 25.7 73.8</cell></row><row><cell>FILTER</cell><cell cols="17">38.4 79.5 53.0 84.7 89.3 88.1 90.4 64.8 87.6 54.5 93.1 76.3 68.6 57.6 39.2 52.6 76.2</cell></row><row><cell>FILTER + Self-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 11 :</head><label>11</label><figDesc>POS results (Accuracy) for each language. 77.4 41.1 77.0 70.0 78.0 72.5 77.4 75.4 66.3 46.2 77.2 79.6 56.6 65.0 76.4 53.5 81.5 29.0 66.4 XLM 82.6 74.9 44.8 76.7 70.0 78.1 73.5 74.8 74.8 62.3 49.2 79.6 78.5 57.7 66.1 76.5 53.1 80.7 23.6 63.0 MMTE 77.9 74.9 41.8 75.1 64.9 71.9 68.3 71.8 74.9 62.6 45.6 75.2 73.9 54.2 66.2 73.8 47.9 74.1 31.2 63.9 XLM-R 84.7 78.9 53.0 81.4 78.8 78.8 79.5 79.6 79.1 60.9 61.9 79.2 80.5 56.8 73.0 79.8 53.0 81.3 23.2 62.5 FILTER 83.3 78.7 56.2 83.3 75.4 79.0 79.7 75.6 80.0 67.0 70.3 80.1 79.6 55.0 72.3 80.2 52.7 81.6 25.2 61.8 FILTER + self-teaching 83.5 80.4 60.7 83.5 78.4 80.4 80.7 74.0 81.0 66.9 71.3 80.2 79.9 57.4 74.3 82.2 54.0 81.9 24.3 63.5 45.8 59.6 52.3 58.2 72.7 45.2 81.8 80.8 64.0 67.5 50.7 48.5 3.6 71.7 71.8 36.9 71.8 44.9 42.7 XLM 67.7 57.2 26.3 59.4 62.4 69.6 47.6 81.2 77.9 63.5 68.4 53.6 49.6 0.3 78.6 71.0 43.0 70.1 26.5 32.4 MMTE 60.9 43.9 58.2 44.8 58.5 68.3 42.9 74.8 72.9 58.2 66.3 48.1 46.9 3.9 64.1 61.9 37.2 68.1 32.1 28.9 XLMR 71.6 56.2 60.0 67.8 68.1 57.1 54.3 84.0 81.9 69.1 70.5 59.5 55.8 1.3 73.2 76.1 56.4 79.4 33.6 33.1 FILTER 70.0 50.6 63.8 67.3 66.4 68.1 60.7 83.7 81.8 71.5 68.0 62.8 56.2 1.5 74.5 80.9 71.2 76.2 40.4 35.9 FILTER + Self-Teaching 71.0 51.1 63.8 70.2 69.8 69.3 59.0 84.6 82.1 71.1 70.6 64.3 58.7 2.4 74.4 83.0 73.4 75.8 42.9 35.4</figDesc><table><row><cell>Model</cell><cell>en</cell><cell>af</cell><cell>ar</cell><cell>bg</cell><cell>bn</cell><cell>de</cell><cell>el</cell><cell>es</cell><cell>et</cell><cell>eu</cell><cell>fa</cell><cell>fi</cell><cell>fr</cell><cell>he</cell><cell>hi</cell><cell>hu</cell><cell>id</cell><cell>it</cell><cell>ja</cell><cell>jv</cell></row><row><cell>mBERT</cell><cell>85.2 ka</cell><cell>kk</cell><cell>ko</cell><cell>ml</cell><cell>mr</cell><cell>ms</cell><cell>my</cell><cell>nl</cell><cell>pt</cell><cell>ru</cell><cell>sw</cell><cell>ta</cell><cell>te</cell><cell>th</cell><cell>tl</cell><cell>tr</cell><cell>ur</cell><cell>vi</cell><cell>yo</cell><cell>zh</cell></row><row><cell>mBERT</cell><cell>64.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 12 :</head><label>12</label><figDesc>NER results (F1) for each language.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/google-research/xtreme 4 https://azure.microsoft.com/en-us/services/cognitiveservices/translator/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://azure.microsoft.com/en-us/services/cognitiveservices/translator/ 6 https://github.com/google-research/xtreme</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the cross-lingual transferability of monolingual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Massively multilingual sentence embeddings for zero-shot cross-lingual transfer and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Jointly Learning to Align and Summarize for Neural Cross-Lingual Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lopez-Gazpio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.00055</idno>
		<title level="m">Semeval-2017 task 1: Semantic textual similaritymultilingual and cross-lingual focused evaluation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-L</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.07834</idno>
		<title level="m">-foXLM: An Information-Theoretic Framework for Cross-Lingual Language Model Pre-Training</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">TyDi QA: A benchmark for information-seeking question answering in typologically diverse languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nikolaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Palomaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Guzm?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">XNLI: Evaluating cross-lingual sentence representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cross-lingual machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving vector space word representations using multilingual correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Xtreme: A massively multilingual multitask benchmark for evaluating cross-lingual generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unicoder: A universal language encoder by pre-training with multiple cross-lingual tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cross-lingual multilevel adversarial transfer to enhance low-resource name tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>May</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Inducing crosslingual distributed representations of words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klementiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bhattarai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cross-lingual language model pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">MLQA: Evaluating cross-lingual extractive question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.01401</idno>
		<title level="m">Xglue: A new benchmark dataset for cross-lingual pre-training, understanding and generation</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Universal dependencies v1: A multilingual treebank collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-C</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hajic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Language Resources and Evaluation</title>
		<meeting><address><addrLine>Pan, X</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Cross-lingual learning-to-rank with shared representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Htut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Calixto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schamoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Inui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.13013</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">English Intermediate-Task Training Improves Zero-Shot Cross-Lingual Transfer Too. arXiv preprint</note>
	<note>In North American Chapter of the Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluating the Cross-Lingual Effectiveness of Massively Multilingual Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Riesa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Raman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8854" to="8861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2002 Shared Task: Language-Independent Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tjong</forename><surname>Kim Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING-02: The 6th Conference on Natural Language Learning</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tjong</forename><surname>Kim Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>De Meulder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL</title>
		<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<imprint>
			<publisher>Plu</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
