<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Spatial-Temporal Fusion Graph Neural Networks for Traffic Flow Forecasting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengzhang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
							<email>zhanxing.zhu@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Spatial-Temporal Fusion Graph Neural Networks for Traffic Flow Forecasting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Spatial-temporal data forecasting of traffic flow is a challenging task because of complicated spatial dependencies and dynamical trends of temporal pattern between different roads. Existing frameworks typically utilize given spatial adjacency graph and sophisticated mechanisms for modeling spatial and temporal correlations. However, limited representations of given spatial graph structure with incomplete adjacent connections may restrict effective spatial-temporal dependencies learning of those models. Furthermore, existing methods are out at elbows when solving complicated spatial-temporal data: they usually utilize separate modules for spatial and temporal correlations, or they only use independent components capturing localized or global heterogeneous dependencies. To overcome those limitations, our paper proposes a novel Spatial-Temporal Fusion Graph Neural Networks (STFGNN) for traffic flow forecasting. First, a data-driven method of generating "temporal graph" is proposed to compensate several existing correlations that spatial graph may not reflect. SFTGNN could effectively learn hidden spatial-temporal dependencies by a novel fusion operation of various spatial and temporal graphs, treated for different time periods in parallel. Meanwhile, by integrating this fusion graph module and a novel gated convolution module into a unified layer, SFTGNN could handle long sequences by learning more spatial-temporal dependencies with layers stacked. Experimental results on several public traffic datasets demonstrate that our method achieves state-of-theart performance consistently than other baselines 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Forecasting task of spatial-temporal data especially traffic data has been widely studied recently because (1) traffic forecasting is one of the most important part of Intelligent Transportation System (ITS) which has great effect on daily life; (2) its data structures is also representative in reality: other location-based data such as wind energy stations, air monitoring stations and cell towers can all be formulated as this spatial-temporal data structure.</p><p>Recently, graph modeling on spatial-temporal data has been in the spotlight with the development of graph neural networks. Many works have achieved impressive per-Copyright ? 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.</p><p>1 Code available at: https://github.com/MengzhangLI/STFGNN <ref type="figure">Figure 1</ref>: Example of spatial-temporal dependencies in a network. Yellow lines indicate the spatial adjacency in reality. Districts play the same role in traffic network are likely to have similar temporal pattern, which are represented by green dash lines.</p><p>formance on prediction accuracy. Although significant improvements have been made in incorporating graph structure into spatial-temporal data forecasting model, these models still face several shortcomings. The first limitation is being lack of an informative graph construction. Taking <ref type="figure">Figure 1</ref> for example, those distant nodes may have certain correlations, i.e., they would share similar "temporal pattern". For instance, during rush hours, most roads near the office buildings (from business districts) will encounter traffic jams in the same period. However, most existing models only utilize given spatial adjacency matrix for graph modeling, and ignore the temporal similarity between nodes when modeling the adjacency matrix. Some works already made several attempts to improve representation of graph. Mask matrix <ref type="bibr" target="#b11">(Song et al. 2020</ref>) and self-adaptive matrix <ref type="bibr" target="#b15">(Wu et al. 2019</ref>) are introduced to adjust existed spatial adjacency matrix, but these learnable matrices are both lack of correlations representation ability for complicated spatial-temporal dependencies in graph. Temporal self-attention module <ref type="bibr" target="#b16">(Xu et al. 2020;</ref><ref type="bibr" target="#b14">Wang et al. 2020</ref>) of transformers can also extract dynamic spatial-temporal correlations, and predetermined spatial graph may not reflect it. However, it may face overfitting of spatial-temporal dependencies learning due to dynamical change and noisy information in reality data especially in long-range prediction tasks, where autoregressive models can hardly avoid error accumulation.</p><p>Besides, current studies of spatial-temporal data forecasting are ineffective to capture dependencies between local and global correlations. RNN/LSTM-based models <ref type="bibr" target="#b7">(Li et al. 2017;</ref><ref type="bibr" target="#b18">Zhang et al. 2018</ref>) are time-consuming and may suffer gradient vanishing or explosion when capturing long-range sequences. Sequential procedure of transformers <ref type="bibr" target="#b9">(Park et al. 2019;</ref><ref type="bibr" target="#b14">Wang et al. 2020;</ref><ref type="bibr" target="#b16">Xu et al. 2020</ref>) may still be time-consuming in inference. CNN-based methods need to stack layers for capturing global correlations of long sequences. STGCN <ref type="bibr" target="#b17">(Yu, Yin, and Zhu 2017)</ref> and GraphWaveNet <ref type="bibr" target="#b15">(Wu et al. 2019</ref>) may lose local information if dilation rate increases. STSGCN <ref type="bibr" target="#b11">(Song et al. 2020)</ref> proposes a novel localized spatial-temporal subgraph that synchronously capture local correlations, which is only designed locally and ignoring global information. When missing data happens, situation is more severe where it would only learn local noise.</p><p>To capture both local and global complicated spatialtemporal dependencies, we present a novel CNN-based framework called Spatial-Temporal Fusion Graph Neural Network (STFGNN). Motivated by dynamic time warping <ref type="bibr" target="#b0">(Berndt and Clifford 1994)</ref>, we propose a novel datadriven method for graph construction: the temporal graph learned based on similarities between time series. Then several graphs could be integrated as a spatial-temporal fusion graph to obtain hidden spatial-temporal dependencies. Moreover, to break the local and global correlation tradeoff, gated dilated convolution module is introduced, whose larger dilation rate could capture long-range dependencies. The main contributions of this work are as follows.</p><p>? We construct a novel graph by a data-driven method, which preserve hidden spatial-temporal dependencies. This data-driven adjacency matrix is able to extract correlations that given spatial graph may not present. Then, we propose a novel spatial-temporal fusion graph module to capture spatial-temporal dependencies synchronously.</p><p>? We propose an effective framework to capture local and global correlations simultaneously, by assembling a Gated dilated CNN module with spatial-temporal fusion graph module in parallel. Long-range spatial-temporal dependencies could also be extracted with layers stacked.</p><p>? To make thorough comparisons and test performance in complicated cases, extensive experiments are conducted on four real-world datasets used in previous works, respectively. The results show our model consistently outperforms baselines, which strongly proves our proposed model could handle complicated traffic situations in reality with different traffic characteristics, road numbers and missing value ratios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Works Graph Convolution Network</head><p>Graph convolution networks are widely applied in many graph-based tasks such as classification <ref type="bibr" target="#b6">(Kipf and Welling 2016)</ref> and clustering <ref type="bibr" target="#b2">(Chiang et al. 2019</ref>), which has two types. One is extending convolutions to graphs in spectral domain by finding the corresponding Fourier basis <ref type="bibr" target="#b1">(Bruna et al. 2013)</ref>. GCN <ref type="bibr" target="#b6">(Kipf and Welling 2016)</ref> is representative work and constructs typical baselines in many tasks. The other is generalizing spatial neighbours by typical convolution. GAT <ref type="bibr" target="#b13">(Veli?kovi? et al. 2017</ref>) which introduces attention mechanism into graph filed, and GraphSAGE (Hamilton, Ying, and Leskovec 2017) which generates node embeddings by sampling and aggregating features locally are all typical works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial-Temporal Forecasting</head><p>Spatial-temporal prediction plays an important role in many application areas. To incorporate spatial dependencies more effectively, recent works introduce graph convolutional network (GCN) to learn the traffic networks. DCRNN <ref type="bibr" target="#b7">(Li et al. 2017</ref>) utilizes the bi-directional random walks on the traffic graph to model spatial information and captures temporal dynamics by gated recurrent units (GRU). Transformer models such as <ref type="bibr" target="#b14">(Wang et al. 2020;</ref><ref type="bibr" target="#b9">Park et al. 2019</ref>) utilize spatial and temporal attention modules in transformer for spatial-temporal modeling. They would be more effective when training than LSTM but still make predictions step by step due to their autoregressvie structures. STGCN <ref type="bibr" target="#b17">(Yu, Yin, and Zhu 2017)</ref> and GraphWaveNet <ref type="bibr" target="#b15">(Wu et al. 2019</ref>) employed graph convolution on spatial domain and 1-D convolution along time axis. They process graph information and time series separately. STSGCN <ref type="bibr" target="#b11">(Song et al. 2020</ref>) make attempts to incorporate spatial and temporal blocks altogether by localized spatial-temporal synchronous graph convolution module regardless of global mutual effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Temporal Graph Generation</head><p>Input: N time series from V(|V| = N ) 1 W Initialization, reset to zero matrix TDL: Temporal Distance Calculation defined in Alg 2 2 for i = 1, 2, ? ? ? , N do</p><formula xml:id="formula_0">3 for j = 1, 2, ? ? ? , N do 4 disti,j = TDL(Vi, Vj) (Alg. 2) 5 end 6 Sort smallest k(k ? N ) element and their index j = {j1, j2, ? ? ? , j k } s.t. disti,j 1 ? disti,j 2 ? disti,j k ifj ? j then W i,j = Wj ,i = 1; 7 end 8 return Weighted Matrix W of Temporal Graph G.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Similarity of Temporal Sequences</head><p>The methods for measuring the similarity between time series can be divided into three categories: (1) timestep- based, such as Euclidean distance reflecting point-wise temporal similarity; (2) shape-based, such as Dynamic Time Warping <ref type="bibr" target="#b0">(Berndt and Clifford 1994)</ref> according to the trend appearance;</p><p>(3) change-based, such as Gaussian Mixture Model(GMM) <ref type="bibr" target="#b10">(Povinelli et al. 2004</ref>) which reflects similarity of data generation process. Dynamic Time Warping is a typical algorithm to measure similarity of time series. Given two time series X = (x 1 , x 2 , ? ? ? , x n ) and Y = (y 1 , y 2 , ? ? ? , y m ), series distance matrix M n?m could be introduced whose entry is M i,j = |x i ? y j |. Then cost matrix M c could be defined:</p><formula xml:id="formula_1">Mc(i, j) = Mi,j +min(Mc(i, j?1), Mc(i?1, j), Mc(i, j)) (1)</formula><p>After several iterations of i and j, dist(X, Y ) = M c (n, m) 1 2 is the final distance between X and Y with the best alignment which can represent the similarity between two time series.</p><p>From Eq.</p><p>(1) we can tell that Dynamic Time Warping is an algorithm based on dynamic programming and its core is solving the warping curve, i.e., matchup of series points x i and y j . In other words the "warping path" ? ? = (? 1 , ? 2 , ? ? ? , ? ? ), max(n, m) ? ? ? n + m is generated through iterations of Eq. (1). Its element ? ? = (i, j) means matchup of x i and y j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preliminaries</head><p>We can represent the road network as a graph G = (V, E, A SG ), where V is a finite set of nodes |V | = N 2 , corresponding to the observation of N sensors or roads; E is a set of edges and A SG ? R N ?N is a spatial adjacency matrix representing the nodes proximity or distance. Denote the observed graph signal X (t) G ? R N ?d means it represent the observation of spatial graph information G at time step t, whose element is observed d traffic features(e.g., the speed, volume) of each sensor. The aim of traffic forecasting is learning a function f from previous T speed observations to predict next T traffic speed from N correlated sensors on the road network.</p><formula xml:id="formula_2">[X (t?T +1) G , ? ? ? , X t G ] f ? ? [X t+1 G , ? ? ? , X t+T G ]</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial-Temporal Fusion Graph Neural Networks</head><p>We present the framework of Spatial-Temporal Fusion Graph Neural Network in <ref type="figure" target="#fig_1">Figure 3</ref>. It consists of (1) an input layer, (2) stacked Spatial-Temporal Fusion Graph Neural</p><p>Algorithm 2: Temporal Distance Calculation (TDL)</p><formula xml:id="formula_3">Input: X = (x1, ? ? ? , xn) ? R n?d , Y = (y1, ? ? ? , ym) ? R m?d , Searching Length T 1 for i = 1, 2, ? ? ? , n do 2 for j = max(0, i ? T ), ? ? ? , min(m, i + T + 1) do 3 Mi,j = |Xi ? Yj|; 4 if i = 0, j = 0 then MC (i, j) = M 2 i,j ; 5 else if i = 0 then MC (i, j) = M 2 i,j + Mi,j?1; 6 else if j = 0 then MC (i, j) = M 2 i,j + Mi?1,j; 7 else if j = i ? T then MC (i, j) = M 2 i,j + min(Mi?1,j?1, Mi?1,j); 8 else if j = i + T then MC (i, j) = M 2 i,j + min(Mi?1,j?1, Mi,j?1); 9 else MC (i, j) = M 2 i,j + min(Mi?1,j?1, Mi,j?1, Mi?1,j); 10 end 11 end 12 return dist(X, Y ) = MC (n, m) 1 2</formula><p>Layers and (3) an output layer. The input and output layer are one and two Fully-Connected Layer followed by activation layer such as "ReLU" (Nair and Hinton 2010) respectively. Every Spatial-Temporal Fusion Graph Layer is constructed by several Spatial-Temporal Fusion Graph Neural Modules (STFGN Modules) in parallel and a Gated CNN Module which includes two parallel 1D dilated convolution blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial-Temporal Fusion Graph Construction</head><p>The aim of generating temporal graph is to achieve certain graph structure with more accurate dependency and genuine relation than spatial graph. Then, incorporating temporal graph into a novel spatial-temporal fusion graph, which could make deep learning model lightweight because this fusion graph already has correlation information of each node with its (1) spatial neighbours, (2) nodes with similar temporal pattern, and (3) own previous or later situation along time axis.</p><p>However, generating temporal graph based on similarity of time series by DTW is not easy, it is a typical dynamic programming algorithm with computational complexity O(n 2 ). Thus it might be unacceptable for many applications because time series of real world is usually very long. To reduce complexity of DTW, we restrict its "Search Length" T . The searching space of warping path is circumscribed by:</p><formula xml:id="formula_4">? k = (i, j), |i ? j| ? T<label>(3)</label></formula><p>Consequently, the computational complexity of DTW is reduced from O(n 2 ) to O(T n) which made its application on large scale spatial-tempral data possible. We name it "fast-DTW". As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, given two roads' time series whose length is |X| and |Y |, repectively. The distance of those two time series M c (|X|, |Y |) could be calculated by Eq. (1). The warping path of fast-DTW is restrcited near the diagonal (red zone in <ref type="figure" target="#fig_0">Figure 2</ref>), consequently the cost of calculating match i and j of the element ? ? = (i, j) of warping path ? is not as expensive as DTW algorithm.</p><p>The set of ? which determines how many smallest numbers are treated in Alg. 1 is tricky and we would analysis it in the section of experiments. Empirically, we keep the sparisity of Temporal Graph A T G almost the same as Spatial Graph A SG . <ref type="figure" target="#fig_1">Figure 3(b)</ref> is the example of Spatial-Temporal Fusion Graph. It consists of three kinds N ? N matrix: Spatial Graph A SG which is given by dataset, Temporal Graph A T G generated by Alg. 1, and Temporal Connectivity graph A T C whose element is nonzero iif previous and next time steps is the same node. Given Spatial-Temporal Fusion Graph A ST F G ? R 3N ?3N , and taken A T G within a red circle in <ref type="figure" target="#fig_1">Figure 3</ref>(b) for instance. It denotes the connection between same node from time step: 2 to 3 (current time step t = 2). For each node l ? {1, 2, ? ? ? , N }, i = (t+1) * N +l = 3N +l and j = t * N + l = 2N + l, then A ST F G(i,j) = 1. To sum up, Temporal Connectivity graph denotes connection of the same node at proximate time steps.</p><p>Finally, Spatial-Temporal Fusion Graph A ST F G ? R KN ?KN is generated. Altogether with the sliced input data of each STFGN Module:</p><formula xml:id="formula_5">h 0 = [X (t) G , ? ? ? , X (t+K) G ] ? R K?N ?d?C<label>(4)</label></formula><p>It is sliced iteratively from total input data:</p><formula xml:id="formula_6">X = [X (t) G , ? ? ? , X (t+T ) G ] ? R T ?N ?d?C (5) X (t) G is high-dimension feature of original data X (t)</formula><p>G . C is the number of input feature channel from STFGN module, which is also the number of output feature channel from input layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial-Temporal Fusion Graph Neural Module</head><p>In Spatial-Temporal Fusion Graph Neural Module (STFGN Module), the lightweight deep learning model could extract hidden spatial-temporal dependencies by several simple operations such as matrix multiplication with Spatial-Temporal Fusion Graph A ST F G , residual connections and max pooling.</p><p>In this paper, regular spectral filter such as Laplacian in graph convolution is replaced with a more simplified and time-saving operation: matrix multiplication. Each node in network could aggregate spatial dependency from A SG , temporal pattern correlation from A T G and its own proximate correlation long time axis from A T C by several times matrix multiplication with A ST F G .</p><p>Gating mechanism in LSTM/RNN is also utilized in graph multiplication block. In STFGN Module, gated linear units is used for generalization in graph multiplication by its nonlinar activation. Graph multiplication module is formulated as below:</p><formula xml:id="formula_7">h l+1 = (A * h l W 1 + b 1 ) ?(A * h l W 2 + b 2 )<label>(6)</label></formula><p>where h l denotes l-th hidden states of certain STFGN module. A * is shorthand of spatial-temporal fusion graph is the example of Spatial-Temporal Fusion Graph, whose size K is 4 and 3, respectively. It consists of three kinds of adjacency matrix ? N ? N : spatial graph A SG , temporal graph A T G and temporal connectivity graph A T C . The A T C within a red circle would be taken for instance in the body. (c) is overall structure of STFGNN, its Gated CNN module and STFGNN modules are in parallel. (d) is detailed architecture of the Spatial-Temporal Fusion Graph Modules, each module will be independently trained for input iteratively generated from (a) in parallel as well.</p><formula xml:id="formula_8">A ST F G ? R KN ?KN , W 1 , W 2 ? R C?C , b 1 , b 2 ? R C are</formula><p>all model parameters of GLU. means Hadamard product and ? means sigmoid function. By stacking L graph multiplication blocks, more complicated and non-local spatial-dependencies could be aggregated. Intuitively, the residual connections <ref type="bibr" target="#b5">(He et al. 2016)</ref> would also be introduced for each block. Max Pooling would be operated on the concatenation of each hidden state h M = M axP ool([h 1 , ? ? ? , h L ]) ? R K?N ?d?C . Finally this concatenation corresponding to the middle time step would be cropped, saving h o = h M K 2 : K 2 + 1, :, :, : ? R 1?N ?d?C <ref type="figure" target="#fig_1">Figure 3</ref>(b) shows this cropped feature has contained complicated heterogeneity. In each matrix multiplication, A SG in the middle of diagonal (corresponding to cropped location of concatenation) transmit information from spatial neighbour. A T C in its horizontal and vertical direction gives each node its own information along time axis. A T G in corner enhance information from nodes with similar temporal pattern.</p><p>Input data would be treated by multiple STFGN Modules independently in parallel, which is time-saving and could capture more complicated correlations. Then concatenation of each STFGN module output would be added with Gated CNN output and becomes input of next STFGN layer. Noted that the size of each STFGN module output is R (T ?K+1)?N ?d?C , i.e., each STFGN layer would cut input from T to T ? K + 1 in time dimensions. It means STFGN layers could stack up to T K?1 ? 1 layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gated Convolution Module</head><p>Although A ST F G could extract global spatial-temporal dependencies by integration of A T G , the correlation it contains is more from nodes in a distant (like the example from <ref type="figure">Figure 1</ref>). Long-range spatial-temporal dependencies of the node itself is also important, which is very challenging for many CNN-based works <ref type="bibr" target="#b17">(Yu, Yin, and Zhu 2017;</ref><ref type="bibr" target="#b15">Wu et al. 2019;</ref><ref type="bibr" target="#b11">Song et al. 2020</ref>) because inborn structure of CNN can hardly outperform auto-regressive models like transformer <ref type="bibr" target="#b9">(Park et al. 2019;</ref><ref type="bibr" target="#b14">Wang et al. 2020)</ref>. Different from previous work like GraphWaveNet and STGCN, dilated convolution with large dilation rate is introduced in this paper. Given the total input data X ? R T ?N ?d?C , it takes the form:</p><formula xml:id="formula_9">Y = ?(? 1 * X + a) ?(? 2 * X + b)<label>(7)</label></formula><p>Similar with Eq. (6), ?(?) and ?(?) are tanh and sigmoid function, respectively. ? 1 and ? 2 are two independent 1D convolution operation with dilation rate = K -1. It could enlarge receptive filed along time axis thus strengthen model performance for extracting sequential dependencies.</p><p>Huber loss is chosen as loss function, objective function  </p><formula xml:id="formula_10">L(X (t+1):(t+T ) G , ?) = T i=1 N j=1 d k=1 h X (t+i) G , X (t+i) G T ? N ? d (8) h ? , Y = ? ? ? ? ? 1 2 (? ? Y ) 2 , |? ? Y | ? ? ?|? ? Y | ? 1 2 ? 2 , |? ? Y | &gt; ?</formula><p>? is hyperparameter to control sensitivity of squared error loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Datasets</head><p>We verify the performance of STFGNN on four public traffic network datasets. PEMS03, PEMS04, PEMS07, PEMS08 released by <ref type="bibr" target="#b11">(Song et al. 2020)</ref>. Those four datasets are constructed from four districts, respectively in California. All these data is collected from the Caltrans Performance Measurement System (PeMS) and aggregated into 5-minutes windows, which means there are 288 points in the traffic flow for one day. The spatial adjacency networks for each dataset is constructed by actual road network based on distance. Z-score normalization is adopted to standardize the data inputs. The detailed information is shown in <ref type="table" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline Methods</head><p>We compare STFGNN with those following models:</p><p>? FC-LSTM: Long Short-Term Memory Network, which is a recurrent neural network with fully connected LSTM hidden units <ref type="bibr" target="#b12">(Sutskever, Vinyals, and Le 2014)</ref>.</p><p>? DCRNN: Diffusion Convolution Recurrent Neural Network, which integrates graph convolution into a encoderdecoder gated recurrent unit <ref type="bibr" target="#b7">(Li et al. 2017</ref>).</p><p>? STGCN: spatio-temporal Graph Convolutional Networks, , which integrates graph convolution into a 1D convolution unit <ref type="bibr" target="#b17">(Yu, Yin, and Zhu 2017)</ref>.</p><p>? ASTGCN(r): Attention Based Spatial Temporal Graph Convolutional Networks, which introduces spatial and temporal attention mechanisms into model. Only recent components of modeling periodicity is taken to keep fair comparison <ref type="bibr" target="#b3">(Guo et al. 2019</ref>).</p><p>? GraphWaveNet: Graph WaveNet is a framework combines adaptive adjacency matrix into graph convolution with 1D dilated convolution <ref type="bibr" target="#b15">(Wu et al. 2019</ref>).</p><p>? STSGCN: Spatial-Temporal Synchronous Graph Convolutional Networks, which utilizes localized spatialtemporal subgraph module to model localized correlations independently <ref type="bibr" target="#b11">(Song et al. 2020</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment Settings</head><p>To make fair comparison with previous baselines, we split the data with ratio 6 : 2 : 2 at PEMS03, PEMS04, PEMS07, PEMS08 into training sets, validation sets and test sets. One hour 12 continuous time steps historical data is used to predict next hour's 12 continuous time steps data. STFGNN is evaluated more than 10 times in each public dataset. Experiments are conducted under the environment with one Intel(R) Xeon(R) Gold 6240 CPU @ 2.60GHz and NVIDIA TESLA V100 GPU 16GB card. The temporal graph A T G generated by fast-DTW in Alg. 1 costs less than 30 minutes in most public datasets. The Searching Length "T" in "fast-DTW" algorithm is 12, which is the largest prediction time steps in our traffic forecasting task. The sparsity of A T G is 0.01. The model contains 3 STFGNLs, where each contains 8 independent STFGNMs and 1 gated convolution module with dilation rate 3 because the size K of spatial-temporal fusion graph we use is 4. Elements of all three kinds graph are booled to 0 or 1 for the sake of simplification. Filters in each convolution are all 64. We train our model using Adam optimizer with learning rate 0.001. The threshold parameter of loss function ? is 1, the batch size is 32 and the training epoch is 200. <ref type="table" target="#tab_3">Table 2</ref> shows the through comparison between different models. Results show our STFGNN outperforms baseline models consistently and overwhelmingly on every dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment Results and Analysis</head><p>Followed by metrics previous baseline <ref type="bibr" target="#b11">(Song et al. 2020</ref>) takes, <ref type="table" target="#tab_3">Table 2</ref> compares the performance of STFGNN and other models for 60 minutes ahead prediction on PEMS03, PEMS04, PEMS07 and PEMS08 datasets.</p><p>All these four datasets are not particularly smooth, the relatively poor performance of GraphWaveNet reveals its struggle because it can not stack its spatial-temporal layers and enlarge receptive fields of 1D CNN concurrently.</p><p>Modules of STSGCN only extract local spatial-temporal dependencies, and their modules only use multiplication operation (Fully-connected network and adjacency matrix multiplication operation). Thus frequent missing values would disturb its local learning module and smooth time series would magnify its limited representation ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Experiments</head><p>To verify effectiveness of different parts in STFGNN, we conduct ablation experiments on PEMS04 and PEMS08. Table 3 shows metric of MAE, MAPE and RMSE. The "Model Element" represents each configuration. Some conclusions could be drawn:</p><p>? For ingredient of A ST F G , larger A ST F G means more complicated heterogeneity in spatial-temporal dependencies could be extracted regradless of less stacking layers.   <ref type="table">Table 3</ref>: Ablation experiments on different configurations of modules. ST 4 means A ST F G with size k = 4. T 4 means A SG is all replaced to A T G in A ST F G . T sp5 , T sp1 means nonzero ratio of A T G is about 5% and 1%, respectively. ? represents whether gated convolution module is added into each STFGN layer. The default STFGNN configuration we use in this paper is [ST 4 , T sp1 , ?].</p><p>? For sparsity of A T G , it is an important hyperparameter, which determines performance of STFGNN. Empirically, it was set based on sparsity of prior spatial graph. We also demonstrate, with proper sparsity of A T G , spatial information free traffic forecasting model is possible, which has promising application value if A SG is unavailable. ? For Gated Convolution Module, it could remedy longrange learning ability of STFGN Modules which could improve performance of STSGNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we present a novel framework for spatialtemporal traffic data forecasting. Our model could capture hidden spatial-dependencies effectively by a novel data-driven graph and its further fusion with given spatial graph. By integration with STFGN module and a novel Gated CNN module which enlarges receptive filed on temporal sequences and stacking it, STFGNN could learn localized spatial-temporal heterogeneity and global spatial-temporal homogeneity simultaneously. Detailed experiments and analysis reveal advantages and defects of previous models, which in turn demonstrate STFGNN consistent great performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Two time series and their warping path calculated by DTW and fast-DTW algorithm. The red zone is searching zone of fast-DTW defined by "Searching Length" T .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Detailed framework of STFGNN. (a) is the example of input of Spatial-Temporal Fusion Graph, which would be generated iteratively along the time axis. (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Dataset description and statistics.</figDesc><table><row><cell>is shown below:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>? 0.24 18.18 ? 0.15 17.49 ? 0.46 17.69 ? 1.43 19.85 ? 0.03 17.48 ? 0.15 16.77 ? 0.09 MAPE(%) 23.33 ? 4.23 18.91 ? 0.82 17.15 ? 0.45 19.40 ? 2.24 19.31 ? 0.49 16.78 ? 0.20 16.30? 0.09 RMSE 35.11 ? 0.50 30.31 ? 0.25 30.12 ? 0.70 29.66 ? 1.68 32.94 ? 0.18 29.21 ? 0.56 28.34? 0.46 PEMS04 MAE 27.14 ? 0.20 24.70 ? 0.22 22.70 ? 0.64 22.93 ? 1.29 25.45 ? 0.03 21.19 ? 0.10 19.83? 0.06 MAPE(%) 18.20 ? 0.40 17.12 ? 0.37 14.59 ? 0.21 16.56 ? 1.36 17.29 ? 0.24 13.90 ? 0.05 13.02? 0.05 RMSE 41.59 ? 0.21 38.12 ? 0.26 35.55 ? 0.75 35.22 ? 1.90 39.70 ? 0.04 33.65 ? 0.20 31.88? 0.14 PEMS07 MAE 29.98 ? 0.42 25.30 ? 0.52 25.38 ? 0.49 28.05 ? 2.34 26.85 ? 0.05 24.26 ? 0.14 22.07? 0.11 MAPE(%) 13.20 ? 0.53 11.66 ? 0.33 11.08 ? 0.18 13.92 ? 1.65 12.12 ? 0.41 10.21 ? 1.65 9.21? 0.07 RMSE 45.94 ? 0.57 38.58 ? 0.70 38.78 ? 0.58 42.57 ? 3.31 42.78 ? 0.07 39.03 ? 0.27 35.80? 0.18 PEMS08 MAE 22.20 ? 0.18 17.86 ? 0.03 18.02 ? 0.14 18.61 ? 0.40 19.13 ? 0.08 17.13 ? 0.09 16.64? 0.09 MAPE(%) 14.20 ? 0.59 11.45 ? 0.03 11.40 ? 0.10 13.08 ? 1.00 12.68 ? 0.57 10.96 ? 0.07 10.60? 0.06 RMSE 34.06 ? 0.32 27.83 ? 0.05 27.83 ? 0.20 28.16 ? 0.48 31.05 ? 0.07 26.80 ? 0.18 26.22? 0.15</figDesc><table><row><cell>Datasets</cell><cell>Metric</cell><cell>FC-LSTM</cell><cell>DCRNN</cell><cell>STGCN</cell><cell>ASTGCN(r) Graph WaveNet</cell><cell>STSGCN</cell><cell>STFGNN</cell></row><row><cell></cell><cell>MAE</cell><cell>21.33</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>PEMS03</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison of STFGNN and baseline models on PEMS03, PEMS04, PEMS07 and PEMS08 datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="4">Model Elements MAE MAPE% RMSE</cell></row><row><cell></cell><cell>STSGCN</cell><cell>21.19</cell><cell>13.90</cell><cell>33.65</cell></row><row><cell></cell><cell>[ST 3 , T sp5 ]</cell><cell>20.74</cell><cell>13.77</cell><cell>33.44</cell></row><row><cell>PEMS04</cell><cell>[ST 3 , T sp1 ] [ST 4 , T sp1 ]</cell><cell>20.09 19.92</cell><cell>13.24 13.03</cell><cell>32.44 31.93</cell></row><row><cell></cell><cell>[T 4 , T sp1 , ?]</cell><cell>20.02</cell><cell>13.17</cell><cell>31.98</cell></row><row><cell></cell><cell>[T 4 , T sp5 , ?]</cell><cell>19.91</cell><cell>13.11</cell><cell>32.19</cell></row><row><cell></cell><cell>[ST 4 , T sp1 , ?]</cell><cell>19.83</cell><cell>13.02</cell><cell>31.88</cell></row><row><cell></cell><cell>STSGCN</cell><cell>17.13</cell><cell>10.96</cell><cell>26.80</cell></row><row><cell></cell><cell>[ST 3 , T sp5 ]</cell><cell>19.47</cell><cell>12.27</cell><cell>29.59</cell></row><row><cell>PEMS08</cell><cell>[ST 3 , T sp1 ] [ST 4 , T sp1 ]</cell><cell>16.84 16.70</cell><cell>10.80 10.63</cell><cell>26.58 26.24</cell></row><row><cell></cell><cell>[T 4 , T sp1 , ?]</cell><cell>18.23</cell><cell>11.52</cell><cell>29.05</cell></row><row><cell></cell><cell>[T 4 , T sp5 , ?]</cell><cell>16.02</cell><cell>10.07</cell><cell>25.39</cell></row><row><cell></cell><cell>[ST 4 , T sp1 , ?]</cell><cell>16.64</cell><cell>10.60</cell><cell>26.22</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In this paper, N represents number of traffic roads/nodes, n represents given length of certain time series. They are totally different.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Using dynamic time warping to find patterns in time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Berndt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD workshop</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="359" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6203</idno>
		<title level="m">Spectral networks and locally connected networks on graphs</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cluster-GCN: An efficient algorithm for training deep and large graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-L</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="257" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Attention based spatial-temporal graph convolutional networks for traffic flow forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="922" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Diffusion convolutional recurrent neural network: Data-driven traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.01926</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Stgrat: A spatio-temporal graph attention network for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bahng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.13181</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Time series classification using Gaussian mixture models of reconstructed phase spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Povinelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Lindgren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="779" to="783" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="914" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<title level="m">Graph attention networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Traffic Flow Prediction via Spatial Temporal Graph Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference</title>
		<meeting>The Web Conference</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="1082" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.00121</idno>
		<title level="m">Graph wavenet for deep spatial-temporal graph modeling</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.02908</idno>
		<title level="m">Spatial-Temporal Transformer Networks for Traffic Flow Forecasting</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04875</idno>
		<title level="m">Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07294</idno>
		<title level="m">Gaan: Gated attention networks for learning on large and spatiotemporal graphs</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
