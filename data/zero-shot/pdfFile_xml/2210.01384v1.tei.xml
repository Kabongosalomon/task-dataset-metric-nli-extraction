<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Toward Edge-Efficient Dense Predictions with Synergistic Multi-Task Neural Architecture Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Vu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UNC at Chapel Hill</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
							<email>yanqiz@google.com</email>
							<affiliation key="aff1">
								<orgName type="department">The Moonshot Factory</orgName>
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>3 X</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Wen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueqi</forename><surname>Li</surname></persName>
							<email>yueqili@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Michael</forename><surname>Frahm</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UNC at Chapel Hill</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Toward Edge-Efficient Dense Predictions with Synergistic Multi-Task Neural Architecture Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Multi-Task Learning</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hardware -Aware NAS Dense Predictions on Edge accuracy speed speed accuracy scalability negative transfer reduction proxyless target task GFLOPs Relative Accuracy Gain (%) -5 0 5 10 15 0 25 50 75 100</p><p>Figure 1: An overview of our proposed methods. First, EDNAS framework leverages the synergy and joint learning of multi-task dense prediction (MT-DP) and hardware-aware NAS to both complement each component and boost on-device performance. On the left is an illustration of the synergistic relationship of these components. Second, JAReD loss reduces depth estimation noise and further improves accuracy. On the right is the performance of our proposed techniques on CityScapes compared to state-of-the-art MT-DP approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In this work, we propose a novel and scalable solution to address the challenges of developing efficient dense predictions on edge platforms. Our first key insight is that Multi-Task Learning (MTL) and hardware-aware Neural Architecture Search (NAS) can work in synergy to greatly benefit on-device Dense Predictions (DP). Empirical results reveal that the joint learning of the two paradigms is surprisingly effective at improving DP accuracy, achieving superior performance over both the transfer learning of single-task NAS and prior state-of-the-art approaches in MTL, all with just 1/10th of the computation. To the best of our knowledge, our framework, named EDNAS, is the first to successfully leverage the synergistic relationship of NAS and MTL for DP. Our second key insight is that the standard depth training for multi-task DP can cause significant instability and noise to MTL evaluation. Instead, we propose JAReD, an improved, easy-to-adopt Joint Absolute-Relative Depth loss, * Work done during an internship at X. ? Work done while at X.</p><p>that reduces up to 88% of the undesired noise while simultaneously boosting accuracy. We conduct extensive evaluations on standard datasets, benchmark against strong baselines and state-of-the-art approaches, as well as provide an analysis of the discovered optimal architectures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>First, EDNAS framework leverages the synergy and joint learning of multi-task dense prediction (MT-DP) and hardware-aware NAS to both complement each component and boost on-device performance. On the left is an illustration of the synergistic relationship of these components. Second, JAReD loss reduces depth estimation noise and further improves accuracy. On the right is the performance of our proposed techniques on CityScapes compared to state-of-the-art MT-DP approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In this work, we propose a novel and scalable solution to address the challenges of developing efficient dense predictions on edge platforms. Our first key insight is that Multi-Task Learning (MTL) and hardware-aware Neural Architecture Search (NAS) can work in synergy to greatly benefit on-device Dense Predictions (DP). Empirical results reveal that the joint learning of the two paradigms is surprisingly effective at improving DP accuracy, achieving superior performance over both the transfer learning of single-task NAS and prior state-of-the-art approaches in MTL, all with just 1/10th of the computation. To the best of our knowledge, our framework, named EDNAS, is the first to successfully leverage the synergistic relationship of NAS and MTL for DP. Our second key insight is that the standard depth training for multi-task DP can cause significant instability and noise to MTL evaluation. Instead, we propose JAReD, an improved, easy-to-adopt Joint Absolute-Relative Depth loss,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recent years have witnessed a strong integration of computer vision in many downstream edge applications such as autonomous driving <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b67">68]</ref>, mobile vision <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b62">63]</ref>, robotics <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b41">42]</ref>, and even computational agriculture <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b36">37]</ref>, fueled by rapid innovations of deep neural networks. In many of these applications, pixel-level dense prediction tasks such as semantic segmentation or depth estimation can play a critical role. For example, self-driving agents are using semantic and depth information to detect lanes, avoid obstacles, and locate their own positions. In precision agriculture, the output of these tasks can be used for crop analysis, yield predic-tion, in-field robot navigation, etc. As more and more neural models are being deployed into the real world, there has been a continuously growing interest in developing edgeefficient architectures for dense predictions over the years.</p><p>However, designing fast and efficient dense prediction models for edge devices is challenging. First of all, pixellevel predictions such as semantic segmentation and depth estimation are fundamentally slower than some other popular vision tasks, including image classification or object detection. This is because after encoding the input images into low-spatial resolution features, these networks need to upsample them back to produce high-resolution output masks. In fact, dense estimation can be several times or even an order of magnitude slower than their counterparts, depending on the specific model, hardware, and target resolution. Thus, real-time dense prediction models are not only nontrivial to design, they can easily become a latency bottleneck in systems that utilize their outputs. Such problems are intensified for edge applications on platforms like the Coral TPU <ref type="bibr" target="#b12">[13]</ref> due to the limited computational resources, despite the need for low latency, e.g., to inform the users or process subsequent tasks in real time.</p><p>Second, developing models for these edge environments is costly and hard to scale in practice. On one hand, the architectural design process requires a significant amount of time, human labor, and expertise, with the development process ranging from a few months to a couple of years. On the other hand, edge applications may require deployment on various platforms, including cell phones, robots, drones, and more. Unfortunately, optimal designs discovered for one hardware may not generalize to another. All of these together pose challenges to the development of fast and efficient models for on-edge dense predictions.</p><p>To tackle these problems, our first key insight is that Multi-Task Learning of Dense Predictions (MTL-DP or MT-DP) and hardware-aware Neural Architecture Search (h-NAS) can work in synergy to not only mutually benefit but also significantly improve accuracy and computation. To the best of our knowledge, our framework, named EDNAS 1 , is the first to successfully exploit such a synergistic relationship of NAS and MTL for dense predictions. Indeed, on one hand, state-of-the-art methods for multi-task dense predictions <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b65">66]</ref>, in which related tasks are learned jointly together, mostly focus on learning how to share a fixed set of model components effectively among tasks but do not consider if such a set itself is optimal for MTL to begin with. Moreover, these works typically study large models targeting powerful graphic accelerators such as V100 GPU for inference and are not readily suitable for edge applications. On the other hand, NAS methods aim to automatically learn an optimal set of neural components and their connections. However, the current 1 short for "Edge-Efficient Dense Predictions via Multi-Task NAS" literature often focuses on either simpler tasks such as classification <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b61">62]</ref> or single-task training setup <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b33">34]</ref>. In contrast, we jointly learn MTL-DP and NAS and leverage their strengths to tackle the aforementioned issues simultaneously, resulting in a novel and improved approach to efficient dense predictions for edge.</p><p>Our second key insight is that the standard depth estimation training used in MTL-DP can produce significant fluctuation in the evaluation accuracy. Indeed, our analysis reveals a potential for undesirably large variance in both absolute and relative depth. We hypothesize that this is caused by the standard depth training practice that relies solely on L 1 loss function. This can significantly and negatively affect the accuracy of MT-DP evaluation as arbitrary "improvement" (or "degradation") can manifest purely because of random fluctuation in the relative error. It is important that we raise awareness of and appropriately address this issue as segmentation and depth information are arguably two of the most commonly jointly learned and used tasks in edge applications. To this end, we propose JAReD, an easy-toadopt augmented loss that jointly and directly optimizes for both relative and absolute depth errors. The proposed loss is highly effective at simultaneously reducing noisy fluctuations and boosting overall prediction accuracy.</p><p>We conduct extensive evaluations on CityScapes <ref type="bibr" target="#b13">[14]</ref> and NYUv2 <ref type="bibr" target="#b49">[50]</ref> to demonstrate the effectiveness and robustness of EDNAS and JAReD loss. Experimental results indicate that our methods can yield significant gains, up to +8.5% and +10.9% DP accuracy respectively, considerably higher than the previous state of the art, with only 1/10th of the parameter and FLOP counts ( <ref type="figure" target="#fig_0">Fig. 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background and Related Works</head><p>In general, dense prediction models are often designed manually, in isolation, or not necessarily constrained by limited edge computation <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref>. Specifically, works on multi-task learning for dense predictions (MTL-DP) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b57">58]</ref> often take a fixed base architecture such as DeepLab <ref type="bibr" target="#b8">[9]</ref> and focus on learning to effectively shared components, e.g. by cross-task communication modules <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b19">20]</ref>, adaptive tree-like branching <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b57">58]</ref>, layer skipping <ref type="bibr" target="#b52">[53]</ref>, etc. <ref type="figure">(Fig. 2</ref>). On the other hand, neural architecture search (NAS) studies up until recently have focused mostly on either image classification problems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b61">62]</ref> or learning tasks in isolation <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b66">67]</ref>. Few have explored architecture search for joint training of dense prediction tasks. However, as mentioned earlier, edge efficiency can potentially benefit both MTL-DP and NAS. To the best of our knowledge, our study is the first to report successful joint optimization of these two learning paradigms for dense predictions. Next, we give an overview of the most relevant efforts in the two domains of MTL and NAS. For more details, please refer to (a) Hard parameter sharing <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b65">66]</ref> (b) Learning to branch <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b57">58]</ref> (c) Learning to skip layers <ref type="bibr" target="#b52">[53]</ref> (d) Searching for layers (ours) <ref type="figure">Figure 2</ref>: Conceptual comparison with existing approaches. While current MT-DP methods focus on how to better share a fixed set of layers, we instead learn better sets of layers to share. Components in red are learnable while others are fixed these comprehensive surveys: MTL <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">15]</ref>, MTL for dense predictions <ref type="bibr" target="#b58">[59]</ref>, NAS <ref type="bibr" target="#b45">[46]</ref>, and hardware-aware NAS <ref type="bibr" target="#b2">[3]</ref>, .</p><p>Neural Architecture Search (NAS). In the past few years, neural architecture search (NAS) has emerged as a solution to automate parts of the network design process. NAS methods have shown remarkable progress and outperformed many handcrafted models <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56]</ref>. In our case, we are interested in hardware-aware NAS <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b66">67]</ref> which can discover efficient architectures suitable for one or multiple targeted edge platforms. This is typically done by casting hardware-aware NAS as a multi-objective optimization problem <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b62">63]</ref> and adding hardware cost, e.g. latency, memory, and energy, alongside prediction accuracy, to guide the search. However, current studies often focus on image classification <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b61">62]</ref> or learning tasks in isolation <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b66">67]</ref>. However, performing multiple dense prediction tasks simultaneously can have significant benefits for both inference speed and accuracy since tasks can leverage each other's training signals as inductive biases to improve their own learning and the model's generalization <ref type="bibr" target="#b7">[8]</ref>.</p><p>Thus, we are interested in combining hardware-aware NAS with multi-task learning of dense prediction tasks to achieve both better accuracy and better inference speed on edge devices. To this end, there have been only a limited number of studies <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b57">58]</ref> that started to explore similar problems, which we will discuss next.</p><p>MTL for Dense Predictions. The goal of Multi-Task Learning (MTL) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">15]</ref> is to jointly learn multiple tasks together to leverage cross-task information to improve pertask prediction quality. In the context of edge applications, we are also interested in the property of MTL that lets tasks share computation and output multiple task predictions in one pass, thereby improving the overall inference speed. This is particularly useful for dense predictions because they tend to be more computationally expensive than their counterparts such as classification <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56]</ref> or detection <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b63">64]</ref>. A popular formulation of MTL that accomplishes this goal is called hard parameter sharing (HPS) <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b65">66]</ref>. Compared to soft parameter sharing (SPS) <ref type="bibr" target="#b19">[20]</ref>, whose multi-task model size scales linearly with the number of tasks due to separate per-task sub-networks, HPS models are more edge-friendly due to their compact architectural structure. Specifically, HPS architectures are typically composed of a shared trunk that extracts joint features for all tasks and multiple per-task heads or branches that take the extracted features as input and produce specific task prediction. The most standard setup is to have all task heads branch off at the same point <ref type="bibr" target="#b35">[36]</ref>. This is also our setup of choice for the scope of this work. In addition, recent studies have begun to explore strategies to learn adaptive sharing architectures from data <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b57">58]</ref>. Attention <ref type="bibr" target="#b39">[40]</ref> and Layer-skipping <ref type="bibr" target="#b52">[53]</ref> have been used to efficiently learn a single shared model while modifying their behaviors to output the desired task-specific prediction, given a task. Other studies <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b57">58]</ref> opt to augment the HPS architectures by learning the branching of tasks. In other words, the learned models may have multiple splitting points, where some tasks can branch off earlier while some others share more layers. A common theme of these approaches is that given a fixed starting architecture, the focus is on learning which components of such network should be shared. Our work shifts the focus to the base network and instead asks what components should be included in such architecture to best benefit multi-task dense predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">EDNAS: Joint MTL-DP and h-NAS</head><p>Synergistic Joint Learning. Our key idea is that we can leverage multi-task inference to significantly reduce computation across several dense prediction tasks, while utilizing hardware-aware NAS to simultaneously improve edge latency, design scalability, and multi-task learning. Combining these two paradigms, MT-DP and NAS, is beneficial not only to edge inference but also to each other. <ref type="figure" target="#fig_0">Fig. 1</ref> illustrates these relationships. First, regarding edge applications, multi-task models <ref type="bibr" target="#b58">[59]</ref> that output several predictions at once are attractive since they share computation across tasks to avoid multiple inference runs and improve the overall latency linearly by design. However, this multitask setup also leads to performance degradation, known as negative transfer. While most current works attribute this problem to improper sharing of neural components, we hy-pothesize that components of popular base networks such as DeepLab <ref type="bibr" target="#b8">[9]</ref> -ResNet <ref type="bibr" target="#b22">[23]</ref> may be well-tuned for their original individual task, but not necessarily optimal for multitask setting. It is possible that certain layers, for example, may need more channels to capture nuanced features required when the number of tasks increases. Moreover, these models may need to be deployed on different edge platforms and thus, their components need to be optimized accordingly. This motivates us to explore NAS as a systematic and scalable method to discover components that could be more suitable for multi-task learning and edge inference. Second, from the perspective of NAS, directly searching for multi-task architectures can potentially yield better results than transferring single-task searched architectures to multi-task settings post NAS. In a way, we are removing a proxy target and its assumption that architectures, which are good for an individual task such as segmentation, are also optimal for multi-task learning.</p><p>Hardware-Aware Multi-Task Objective. Given a fixed set of N tasks T = {T 1 , T 2 , ...T N }, we formulate the problem of multi-task NAS as a multi-objective search. Our goal is to discover optimal models with both high accuracy for all tasks in T and low inference latency on specific edge devices. Let a be an architecture with weights w a sampled from the search space A and h be a target edge hardware. Our optimization can then be expressed as follows:</p><formula xml:id="formula_0">max a?A Rwd(a, T, h, w * a )<label>(1)</label></formula><formula xml:id="formula_1">s.t. w * a = arg min wa Loss(a, T, w a )<label>(2)</label></formula><p>and Lat(a, h) ? l h</p><p>with Rwd() being the objective or reward function and l h being the target edge latency dependent on the hardware and application domain. Inspired by <ref type="bibr" target="#b53">[54]</ref>, we use a weighted product for the reward function Rwd() to jointly optimize for models' accuracy and latency constrained by hardwaredependent requirements such as inference latency, chip area, energy usage, etc. This allows for flexible customization and encourages Pareto optimal solutions of multiobjective learning <ref type="bibr" target="#b16">[17]</ref>. In this work, we focus on inference latency Lat(a, h) as the main hardware constraint.</p><formula xml:id="formula_3">Rwd(a, T, h, w a ) = Acc(a, T, w a ) Lat(a, h) l h ? (4) s.t. ? = p if Lat(a, h) ? l h q otherwise<label>(5)</label></formula><p>We use an in-house cycle-accurate performance simulator to estimate the on-device latency of sampled architectures during NAS. This offers a middle ground between the accurate-but-expensive benchmarking methods that use real, physical devices and the cheap-but-inaccurate one that use proxy metrics like FLOPs, MACs, or number of parameters. Moreover, by configuring such a simulator differently, we can inject hardware-specific information and bias the search to adapt to different targeted edge platforms. Unlike prior works <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b66">67]</ref>, we extend the notion of Acc() to multi-task setting using a simple-yet-effective nested weighted product of metrics and tasks. Let M i = {m i,1 , m i,2 , ..., m i,K } be the set of metrics of interest for tasks T i , e.g. {mIoU, PixelAcc} for semantic segmentation. Our multi-task Acc() can be expressed as:</p><formula xml:id="formula_4">Acc(a, T, w a ) = i m i 1/N (6) s.t. m i = ? ? j m wi,j i,j ? ? 1/ j wi,j<label>(7)</label></formula><p>This extended formulation is straightforward and scalable even when the number of tasks or metrics increases. Since our goal is to discover multi-task networks that can perform well across all tasks without bias to individual tasks, we treat all task rewards equally in our formulation.</p><p>Edge-Friendly Base Architecture. Previously works <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b57">58]</ref> typically use bigger networks such as ResNet <ref type="bibr" target="#b22">[23]</ref> or VGG <ref type="bibr" target="#b50">[51]</ref> backbone with ASPP <ref type="bibr" target="#b8">[9]</ref> decoder. Such models, however, are not suitable for edge platforms like the Coral TPU <ref type="bibr" target="#b12">[13]</ref> due to their limited computational resources. To this end, we propose the use of Efficient-Net <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b55">56]</ref> backbone and BiFPN fusion modules <ref type="bibr" target="#b56">[57]</ref>, which have been shown to have significantly better FLOPs and parameter efficiency (e.g. an order of magnitude lower) compared to their counterparts <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b66">67]</ref>. These advantages make them promising candidate modules to build edge-friendly models. To generate multi-task outputs while saving computation, we share the majority of the network, including both the EfficientNet backbone and BiFPN modules, across all tasks and use only small per-task heads. This keeps our model compact and avoids a significant increase in size as the number of tasks goes up . We also replace Swish activation and attention-based fusion with ReLU6 and Sum operations in <ref type="bibr" target="#b54">[55]</ref> to further improve efficiency on edge. We balance the compact EfficientNet backbone with 4 BiFPN fusion modules instead of 3 like <ref type="bibr" target="#b56">[57]</ref> to boost accuracy. The multi-scale fusion modules take features {P 3 , P 4 , P 5 , P 6 , P 7 } from levels 3-7 of the backbone. These components together make up our edge-friendly base architecture, which we will use as both the seed for our NAS and the baseline model for evaluating MTL performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Depth Estimation Noise and JAReD Loss</head><p>Instability in Depth Estimation. During our study, we discover that depth prediction accuracy can vary greatly across different training runs of the same setting. This is illustrated in Tab. 1 by the results of standard depth training with L 1 loss. Note that the standard deviation of depth errors across identical runs are fairly large at 4.4% and 4.1%, ?2 higher than that of segmentation mIoU. Such large variation is problematic for the multi-task evaluation as one model could potentially arbitrarily and falsely "improve" or "degrade" purely by chance. Moreover, this may even interfere with the joint learning MT-DP and NAS through noisy task accuracy in the objective function in Eq 4. In other words, it would be challenging for NAS to identify good architectures if training accuracy itself is unstable and unreliable.</p><p>Joint Absolute-Relative Depth. We hypothesize that the noisy depth result is due to the fact that popular MT-DP training <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b58">59]</ref> relies only L 1 loss, which focuses on optimizing for absolute depth and only implicitly learn relative depth. For monocular setting, learning absolute depth directly is ill-posed and challenging due to the scale ambiguity <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b30">31]</ref>. Instead, we propose to augment the standard loss using a weighted relative-error component, resulting in a Joint Absolute-Relative Depth loss, or JAReD:</p><formula xml:id="formula_5">L JAReD = 1 N ?|y ??| + ? 1 N ? y ?? y<label>(8)</label></formula><p>Tab. 1 shows that JAReD can help significantly reduce depth estimation noise-the STDs of all tasks decrease, especially for relative error with 87.8% lower fluctuation. Moreover, JAReD can simultaneously improve accuracy, with both absolute and relative errors dropping by 4.7% and 8.6%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup</head><p>Datasets and Tasks. We evaluate our proposed method using two popular datasets for multi-task dense predictions: CityScapes <ref type="bibr" target="#b13">[14]</ref> and NYU-v2 <ref type="bibr" target="#b49">[50]</ref>. CityScapes contains 2975 training images and 500 validation images of driving scenes while NYU-v2 is composed of 1449 densely labeled RGBD indoor images, with a stand training-to-validation split of 795 to 654. We use the preprocessed versions provided by AdaShare <ref type="bibr" target="#b52">[53]</ref>. We jointly learn semantic segmentation (19 classes) and depth prediction for CityScapes. For NYU-v2, we study 3-task learning of segmentation, depth prediction, and surface normal estimation.</p><p>Baselines. We adopt the standard practice of evaluating our proposed techniques against the Single-Task (ST) and vanilla Multi-Task (MT) versions, which are EfficientNetbased in our case. We refer to these as edge baselines. For fair comparisons, we consult the training hyperparameters used by AdaShare <ref type="bibr" target="#b52">[53]</ref> to match their baseline performance and only compare the relative improvements.</p><p>Implementation Details. For all experiments, we use EfficientNet-B0 <ref type="bibr" target="#b54">[55]</ref> as our backbone. We use Regularized Evolution <ref type="bibr" target="#b44">[45]</ref> as our search controller as it can produce compact and accurate models with less search time,  MT stands for multi-task. We multiply the FLOPs by the number of tasks for methods that need multiple runs to get different per-task predictions. FLOP counts are in gigas(G) and parameter counts are in millions(M). Both of these, along with our model's edge latency, are measured for 256x256 resolution. We consult <ref type="table">Table 8</ref> and <ref type="table" target="#tab_0">Table 11</ref> in <ref type="bibr" target="#b52">[53]</ref> as well as its first author to acquire the full measurements of prior works   <ref type="bibr" target="#b52">[53]</ref> while edge denotes our edge-friendly baselines thus shortening the experimentation cycle. Nonetheless, we expect other controllers, e.g. PPO <ref type="bibr" target="#b48">[49]</ref> as used by prior works <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b66">67]</ref>, to also work. We use Adam <ref type="bibr" target="#b29">[30]</ref> optimizer and cosine learning rate scheduler for all our training, including both the proxy task during NAS and the final training of the best candidates, to reduce hyperparameter tuning effort. For full training, we train each model 3 times and take the average results similar to <ref type="table" target="#tab_0">Table 1</ref> to reduce noise. All models are trained from scratch without any pretrained weights. We acquire wall-clock latency measurements by benchmarking models on a Coral EdgeTPU <ref type="bibr" target="#b12">[13]</ref>. Further details are included in the supplementary.</p><p>Evaluation Metrics. We use mean Intersection over Union (mIoU) and pixel accuracy (PAcc) for semantic segmentation, and mean absolute error (AbsE) and mean relative error (RelE) for depth prediction. For surface normal estimation on NYU-v2, we use mean angle distance error (MeanE) across all pixels, as well as the percentage of pixels with angle distances less a threshold ? ? {11.25?, 22.5?, 30?}, denoted as {?11, ?22, ?30} respectively. Following other works <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b58">59]</ref>, we calculate a single evaluation score ?T averaging over all relative gains ?T i of all tasks T i relative to the Single-Task baseline. A formal definition of these metrics are provided in our supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>EDNAS for 2-task CityScapes. Tab. 2 shows our experiments for the 2-task learning of 19-class semantic segmentation and depth estimation on CityScapes dataset. In this experiment, the same ?T of -4.1 is shared by the MT edge baseline and its large-scale counterpart, indicating that they both experience a similar level of negative transfer and MTL difficulty. Following <ref type="bibr" target="#b52">[53]</ref>, we present MTL gains relative to the ST baseline model. The proposed EDNAS exhibits a strong multi-task performance with ?T =+8.5, outperforming all prior methods. Since the full training of MT edge baseline and EDNAS-found architecture are identical, it shows that joint MTL-DP and NAS can produce a superior relative improvement of +8.5 -(-4.1) = +12.6 compared to the vanilla multi-task model.</p><p>JAReD Loss. From Tab. 2, we see that the proposed JAReD loss is able to greatly improve depth estimation with a relative gain of ?T D =13.3%. This in turn further strengthens the overall multi-task performance by a significant margin of +2.4 on top of the already-strong result (?T =+8.  <ref type="table">Table 4</ref>: Three-task NYUv2 results . Our tasks of interest include 40-class semantic segmentation, depth estimation, and surface normal estimation. Best numbers are in bold, the second best are underlined. ST stands for single-task and MT stands for multi-task. We multiply the FLOPs by the number of tasks for methods that need multiple runs to get different per-task predictions. The measurements of prior works are from <ref type="table">Table 9</ref> and <ref type="table" target="#tab_0">Table 11</ref>   ther demonstrates the benefits of our proposed joint learning for discovering and training better multi-task architectures for dense predictions on edge platforms.</p><p>Generalization to 3-Task NYUv2. Unlike with Cityscapes where the MT baselines have similar accuracy drop, for NYUv2, we notice a large difference between the amount of negative transfer in MT edge baseline (?T =-11.3) and in the large-scale MT model (?T =+2.0), as shown in Tab. 3. This indicates that multi-task training on NYUv2 data may be more challenging for edge models with limited computation. Because of such discrepancy in the level of MTL difficulty, we directly use the MT models (instead of ST models) as the baselines to benchmark the improvement gained.</p><p>Note that despite such a large gap compared to the ST edge setting, our MT edge model is still comparable to the computationally heavy ST baselines of prior studies, with a negligible ?T =-0.1. The NYUv2 results from Tab. 4 show that EDNAS and JAReD continue to achieve consistent and significant improvements (?T of +9.6 and +12.7) over the baseline, similar to what we observed for Cityscapes.</p><p>Robustness to Stronger Baselines. To further demonstrate the robustness of EDNAS as a solution for discovering better multi-task architectures for dense predictions, we are interested in examining its performance with stronger baselines (Tab. 5). Although prior work <ref type="bibr" target="#b52">[53]</ref> only uses learning rates in the order of 1e-4 to 1e-3, we also experiment with other rates and observe a huge jump of ?T =+20.3 in performance when simply increasing the learning rate while holding other settings the same. We utilize this simple adjustment to obtain our stronger edge baseline with the largest learning rate of maxLR=1e-2. Taking a step further, we add JAReD loss to our ST edge baseline both to demonstrate the effectiveness of JAReD loss even for single-task depth estimation and to acquire our strongest baseline for evaluation. Our result of training the EDNAS-found architecture with similar setup (+maxLR and +JAReD) illustrates the strength of our proposed method with a relative multi-task gain of ?T =+3.3. We emphasize that +3.3, despite being smaller than the improvements we have seen so far, is still comparable to the majority of state-of-the-art methods shown in Tab. 2, and that is on top of a +30% stronger ST baseline! Index Layer <ref type="table" target="#tab_0">0  Conv2D  2  3  32  -1  FusedIBN  1  3  16  1  2  IBN  2  5  36  6  3  FusedIBN  1  5  24  6  4  FusedIBN  2  3  60  6  5  FusedIBN  1  3  40  3  6  FusedIBN  2  5  120  3  7  IBN  1  3  120  3  8  FusedIBN  1  5  80  6  9</ref> FusedIBN <ref type="formula" target="#formula_0">1</ref>   Joint Learning vs Transfer Learning. Tab. 5 also shows the performance of EDNAS when compared to the transferring of NAS-found single-task models to the multi-task setting. Although transferred architectures can bring a considerable amount of improvement compared to our baseline ST and MT models, EDNAS' joint learning of multi-task dense predictions and hardware-aware NAS evidently offers the optimal performance among these models, achieving either the best or second best scores in all categories. Moreover, it is also important to note that there is a significant difference in the performance gains of the transferred depth estimation network compared to that of the transferred segmentation model. Therefore, we may not know in advance which specific tasks transfer better than the other, further illustrating the power and benefits of our EDNAS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stride Kernel Filters Expansion</head><p>Analysis of EDNAS-Found Architectures. Tab. 6 gives a summary of the backbone architecture found by ED-NAS for multi-task segmentation and depth estimation on CityScapes. This is the same model as presented in CityScapes experiment section. Except for the first Conv2D layer, which is a fixed stem, the following 16 layers (  <ref type="table" target="#tab_0">0  Conv2D  2  3  32  -1  FusedIBN  1  3  24  1  2  IBN  2  3  36  6  3  IBN  1  3  36  6  4  FusedIBN  2  5  40  6  5  FusedIBN  1  5  40  3  6  IBN  2  3  80  6  7  FusedIBN  1  3  120  3  8  FusedIBN  1  3  80  6  9  FusedIBN  1  3  168  3  10  FusedIBN  1  3  56  6  11  FusedIBN  1  3  112  3  12  FusedIBN  2  5  192  6  13  FusedIBN  1  3  192  6  14  IBN  1  5  192  3  15  IBN  1  5  192  3  16</ref> FusedIBN 1 5 240 3 <ref type="table">Table 7</ref>: Backbone Architecture found by Single-task NAS -An example of the backbone architecture found the single-task NAS targeting depth estimation on CityScapes . We suspect that multi-task learning can benefit from more expressive layers such as FusedIBN; thus, fewer of such layers compared Tab. 6 may correlate to the lower accuracy as seen in the previous experiments.</p><p>ture also has IBN for layer 7 but not for layer 2. Hence, we believe that even though sparsely used, IBN layers can still be beneficial if placed strategically, e.g. via EDNAS. Tab. 7 provides an example of architectures found by our single-task NAS for depth estimation. We observe that there are consistently and considerably lower numbers of Fused-IBN modules, namely 11 compared to 14 in <ref type="table">Table Tab</ref>. 6, which is produced by EDNAS, a multi-task NAS algorithm. Similar observation also applies to the single-task NAS for segmentation, which has 12 FusedIBN layers. We conjecture that multi-task learning might require more powerful and expressive layers to capture cross-task nuances. As a result, single-task NAS, which performs an indirect search using individual tasks, may fail to recognize and meet these needs, leading to fewer FusedIBN blocks and poorer accuracy as seen in the transferring experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, our two main contributions include EDNAS and JAReD loss. The former is a novel and scalable solution that exploits the synergy of MTL and h-NAS to improve both accuracy and speed for dense prediction task on edge platforms. The latter is an easy-to-adopt augmented depth loss that simultaneously mitigates noise and further boosts accuracy. Through extensive experimentation, we show that the proposed techniques can outperform stateof-the-art methods, minimize on-device computational cost, generalize to different data and training settings, as well as discover meaningful and effective architectures.  <ref type="figure">Figure 3</ref>: A system-level overview of our proposed methods. We leverage multi-objective, hardware-aware neural architecture search to discover optimal neural components suitable for multi-task dense predictions, while simultaneously ensuring efficient edge inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental details</head><p>Hyperparameters of NAS. We use a Regularized Evolution controller with a population size of 50, random initialization, uniform mutator, and a tournament sample size of 10. We let the search run for about 2000 generations. These parameters were simply chosen to fit our computational budget and were not tuned. During the search, we train models for 5000 iterations as a proxy task to save computation. The final models are trained for 20000 iterations following AdaShare. For the ? in the objective function in Eq. 5, we use (p=0.0) to set up a hard constraint function and (q=-0.07) to promote Pareto optimality, following MnasNet. We use w i,j =1.0 to equally weight all evaluation metrics M i,j of any task T i in Eq. 6 and Eq. 7. These can be adjusted to suit downstream applications. With 512 TPUv2 cores, our multi-trial search takes about 1.5 days for Cityscapes and 3.5 days for NYUv2. Since EDNAS is not constrained by the specific NAS algorithm, one can also use a one-shot search with weight sharing <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b62">63]</ref> instead for better computational efficiency. Finally, <ref type="figure" target="#fig_1">Fig. 4</ref>   <ref type="table">Table 8</ref>: Final loss weights. This table specifies the per-task loss weights for models trained on 2-task Cityscapes and 3-task NYUv2. "SN" stands for surface normal estimation.</p><p>Task Loss and Weighting. Following AdaShare <ref type="bibr" target="#b52">[53]</ref>, we use Cross-Entropy loss L CE to train semantic segmentation, L 1 loss for the base training of monocular depth estimation, and the inverse of cosine similarity loss L ICS for surface normal prediction. Our JAReD loss also includes a weighted mean relative error component L RE as specified in Eq. <ref type="bibr" target="#b7">8</ref> We manually tune the loss weights to avoid ineffective weighting interfering with the evaluation of NAS-found architectures, using two guidelines: (1) We set task weights so that our MT edge baseline best matches Loss weight</p><formula xml:id="formula_6">Seg Depth Avg Method L CE L 1 L RE mIoU PAcc AbsE RelE ?T S ?T D ?T</formula><p>Single-task seg 1.000 0.000 0.000 40.04 88.68 -----Single-task depth 0.000 1.000 0.000 --0.0157 0.340 ---Multi-task seg-depth 0.500 1.000 0.000 38.64 88.49 0.0171 0.354 -1.9 -6.3 -4.1 Multi-task seg-depth 0.500 0.999 0.001 46.78 90.62 0.0149 0.323 +9.5 +5.1 +7.3 Multi-task seg-depth 0.500 0.990 0.010 46.83 90.56 0.0144 0.304 +9.5 +9.5 +9.5 Multi-task seg-depth 0.500 0.950 0.050 46.11 90.47 0.0143 0.281 +8.6 +13.3 +10.9 Multi-task seg-depth 0.500 0.900 0.010 46.41 90.56 0.0146 0.300 +9.0 +9.5 +9.3 <ref type="table">Table 9</ref>: Impact of loss weighting</p><p>AdaShare's (Sec. 4.1), then use similar weights for ED-NAS.</p><p>(2) For EDNAS+JAReD, we keep the ? in Eq. 8 small to avoid overwhelming the L 1 and other tasks such as segmentation. Tab. 8 details the final weights of our main models, as presented in Tab. 2 and Tab. 3. In addition, Tab. 9 illustrates the impact of different loss weighting strategies on the multi-task performance of segmentation and depth prediction.</p><p>? Metrics for MTL Evaluation. Following the standard metrics for evaluating multi-task learning <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b58">59]</ref>, we calculate the scores of multi-task learning relative to the single-task performance. Specifically, given a multi-task model a for evaluation, let T i ? T be a task of interest (e.g. semantic segmentation) and m ij ? M i be an evaluation metric for task T i (e.g. mIoU). Letm ij be the baseline score of a corresponding singe-task model (e.g. singletask segmentation mIoU). We define the per-metric relative score ?m ij (e.g. ?mIoU) of the multi-task model a with regard to its baselinem ij as followed:</p><formula xml:id="formula_7">?m ij = (?1) lj m ij ?m i? m ij * 100%<label>(9)</label></formula><p>with l j = 1 if lower is better for metric M j 0 otherwise</p><p>We then define the per-task relative score ?T i (e.g. ?Seg) of any task T i and the overall multi-task score ?T of model a respectively as:</p><formula xml:id="formula_9">?T i = 1 |M i | |Mi| j=1 ?m ij<label>(11)</label></formula><formula xml:id="formula_10">?T = 1 |T | |T | i=1 ?T i<label>(12)</label></formula><p>with |M i | and |T | being the cardinality of the corresponding metric set and task set respectively.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Qualitative Results</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An overview of our proposed methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>A visual comparison of the Inverted Bottleneck (IBN)<ref type="bibr" target="#b47">[48]</ref> and Fused-IBN<ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b55">56]</ref> blocks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 Figure 5 :</head><label>55</label><figDesc>presents some qualitative results of semantic segmentation and depth estimation on CityScapes dataset Input Image Ground Truth Single-Task Multi-Task EDNAS Qualitative results for semantic segmentation (top) and depth estimation (bottom) on CityScapes dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Depth estimation noise and JAReD loss. We train a model for segmentation and depth prediction on CityScapes with the standard L1 and proposed JAReD loss. The mean and standard deviation are taken across 3 runs. Except for mIoU, lower is better.</figDesc><table><row><cell cols="2">Depth Loss mIoU</cell><cell>?%</cell><cell>AbsE</cell><cell>?%</cell><cell>RelE</cell><cell>?%</cell></row><row><cell>L 1</cell><cell>38.6</cell><cell>2.5</cell><cell>0.01763</cell><cell>4.4</cell><cell>0.3541</cell><cell>4.1</cell></row><row><cell>JAReD</cell><cell>38.9</cell><cell>1.6</cell><cell>0.01680</cell><cell>1.9</cell><cell>0.3237</cell><cell>0.5</cell></row><row><cell>% improved</cell><cell cols="2">?0.8 ?36.0</cell><cell>?4.7</cell><cell>?56.8</cell><cell>?8.6</cell><cell>?87.8</cell></row></table><note>Edge-Friendly Search Space. Modern NAS usually re- tains some aspect of the base architecture in order to keep the search space tractable and to reduce the compu- tational cost. Thus, it is important to have a good ini- tialization architecture to seed the search. For this, we leverage the base architecture designed above and Pyglove [43], a Python AutoML library that supports flexible layer- level mutation for NAS components via symbolic program- ming. This allows us to transform the static Efficient- Net backbone into a tunable search space by replacing any standard computational node with a PyGlove's mu- table object, e.g. converting Conv2d(kernel=3) into Conv2d(kernel=oneof([3,5,7])). Furthermore, we expand the search space to include Fused-IBN [56, 64, 67] modules alongside the standard Inverted Bottleneck (IBN) [48]. Despite inciting more trainable parameters, Fused-IBN can potentially offer better efficiency on edge devices if strategically placed, e.g. via NAS. This is be- cause industry accelerators are better tuned for regular con- volution than their depthwise counterparts, e.g. resulting in 3? speedup for certain tensor shapes and kernel dimen- sions [64]. Our final search space is defined by the follow- ing per-layer decisions: ? Layer type: {IBN, Fused-IBN} ? Kernel size: {3, 5} ? Output channel multiplier: {0.5, 0.75, 1.0, 1.5} ? Expansion ratio: {3, 6} The search is performed for all 16 IBN blocks of our base EfficientNet backbone, together with the other search parameters, producing an expressive search space of size (2 * 2 * 4 * 2) 16 = 2 80 ? 1.2e24.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>PAcc AbsE RelE ?mIoU ?PAcc ?AbsE ?RelE ?T S ?T D ?T</figDesc><table><row><cell></cell><cell></cell><cell>Model</cell><cell></cell><cell>Seg</cell><cell>Depth</cell><cell>?Seg</cell><cell></cell><cell cols="2">?Depth</cell><cell></cell><cell>Avg</cell></row><row><cell cols="6">Method GFLOP Speed mIoU ST baseline [53] #P 42.6 87.1 -40.20 74.70 .0170 .330</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">MT baseline [53] 21.3</cell><cell>43.6</cell><cell>-</cell><cell cols="2">37.70 73.80 .0180 .340</cell><cell>-6.2</cell><cell>-1.2</cell><cell>-5.9</cell><cell>-3.0</cell><cell>-3.7</cell><cell>-4.5</cell><cell>-4.1</cell></row><row><cell>Cross-Stitch [41]</cell><cell>42.6</cell><cell>48.4</cell><cell>-</cell><cell cols="2">40.30 74.30 .0150 .300</cell><cell>+0.2</cell><cell>-0.5</cell><cell>+11.8</cell><cell>+9.1</cell><cell cols="3">-0.1 +10.4 +5.1</cell></row><row><cell>Sluice [47]</cell><cell>42.6</cell><cell>48.4</cell><cell>-</cell><cell cols="2">39.80 74.20 .0160 .310</cell><cell>-1.0</cell><cell>-0.7</cell><cell>5.9</cell><cell>6.1</cell><cell>-0.8</cell><cell>+6.0</cell><cell>+2.6</cell></row><row><cell cols="2">NDDR-CNN [21] 44.1</cell><cell>50.1</cell><cell>-</cell><cell cols="2">41.50 74.20 .0170 .310</cell><cell>3.2</cell><cell>-0.7</cell><cell>0.0</cell><cell>6.1</cell><cell>+1.3</cell><cell>+3.0</cell><cell>+2.2</cell></row><row><cell>MTAN [36]</cell><cell>51.3</cell><cell>57.9</cell><cell>-</cell><cell cols="2">40.80 74.30 .0150 .320</cell><cell>+1.5</cell><cell>-0.5</cell><cell>+11.8</cell><cell>+3.0</cell><cell>+0.5</cell><cell>+7.4</cell><cell>+3.9</cell></row><row><cell>DEN [1]</cell><cell>23.9</cell><cell>51.2</cell><cell>-</cell><cell cols="2">38.00 74.20 .0170 .370</cell><cell>-5.5</cell><cell>-0.7</cell><cell>0.0</cell><cell>-12.1</cell><cell>-3.1</cell><cell>-6.1</cell><cell>-4.6</cell></row><row><cell>AdaShare [53]</cell><cell>21.3</cell><cell>87.1</cell><cell>-</cell><cell cols="2">41.50 74.90 .0160 .330</cell><cell>3.2</cell><cell>0.3</cell><cell>5.9</cell><cell>0.0</cell><cell>+1.8</cell><cell>+2.9</cell><cell>+2.3</cell></row><row><cell>ST edge baseline</cell><cell>3.4</cell><cell>2.3</cell><cell cols="3">?1.0 40.04 88.68 .0157 .340</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">MT edge baseline 3.4</cell><cell>1.2</cell><cell cols="3">?1.2 38.64 88.49 .0171 .354</cell><cell>-3.5</cell><cell>-0.2</cell><cell>-8.5</cell><cell>-4.1</cell><cell>-1.9</cell><cell>-6.3</cell><cell>-4.1</cell></row><row><cell>EDNAS</cell><cell>4.3</cell><cell>4.1</cell><cell cols="3">?1.3 46.52 90.61 .0143 .316</cell><cell>+16.2</cell><cell>+2.2</cell><cell>+8.9</cell><cell>+6.9</cell><cell>+9.2</cell><cell>+7.9</cell><cell>+8.5</cell></row><row><cell>EDNAS+JAReD</cell><cell>4.3</cell><cell>4.1</cell><cell cols="3">?1.3 46.11 90.47 .0143 .281</cell><cell>+15.1</cell><cell>+2.0</cell><cell>+9.1</cell><cell>+17.4</cell><cell cols="3">+8.6 +13.3 +10.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Two-task CityScapes results. Best numbers are in bold, the second best are underlined. ST stands for single-tasks.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>NYUv2 baselines. ST and MT are prior large-scale mod- els from</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>5) of EDNAS. Together, our two proposed techniques outperform all previous approaches on 3 out of 4 individual metrics, namely ?mIoU, ?PAcc, and ?RelE, as well as on all the average metrics, which are ?T S , ?T D , and ?T . PAcc AbsE RelE MeanE ?11 ?22 ?30 ?T S ?T D ?T SN ?T</figDesc><table><row><cell></cell><cell>Seg</cell><cell></cell><cell cols="2">Depth</cell><cell></cell><cell>Surface Normal</cell><cell></cell><cell cols="2">Avg</cell><cell></cell></row><row><cell cols="2">Method mIoU MT baseline [53] 24.1</cell><cell>57.2</cell><cell>0.58</cell><cell>0.23</cell><cell>16.6</cell><cell>42.5 73.2 84.6</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Cross-Stitch [41]</cell><cell>25.4</cell><cell>57.6</cell><cell>0.58</cell><cell>0.23</cell><cell>17.2</cell><cell cols="2">41.4 70.5 82.9 +3.0</cell><cell>+0.0</cell><cell>-3.0</cell><cell>+0.0</cell></row><row><cell>Sluice [47]</cell><cell>23.8</cell><cell>56.9</cell><cell>0.58</cell><cell>0.24</cell><cell>17.2</cell><cell>38.9 71.8 83.9</cell><cell>-0.9</cell><cell>-2.2</cell><cell>-3.7</cell><cell>-2.3</cell></row><row><cell cols="2">NDDR-CNN [21] 21.6</cell><cell>53.9</cell><cell>0.66</cell><cell>0.26</cell><cell>17.1</cell><cell>37.4 73.7 85.6</cell><cell>-8.1</cell><cell>-13.4</cell><cell>-3.3</cell><cell>-8.3</cell></row><row><cell>MTAN [36]</cell><cell>26.0</cell><cell>57.2</cell><cell>0.57</cell><cell>0.25</cell><cell>16.6</cell><cell cols="2">43.7 73.3 84.4 +3.9</cell><cell>-3.5</cell><cell>+0.7</cell><cell>+0.4</cell></row><row><cell>DEN [1]</cell><cell>23.9</cell><cell>54.9</cell><cell>0.97</cell><cell>0.31</cell><cell>17.1</cell><cell>36.0 73.4 85.9</cell><cell>-2.4</cell><cell>-51.0</cell><cell>-4.1</cell><cell>-19.2</cell></row><row><cell>AdaShare [53]</cell><cell>30.2</cell><cell>62.4</cell><cell>0.55</cell><cell>0.20</cell><cell>16.6</cell><cell cols="3">45.0 71.7 83.0 +17.2 +9.1</cell><cell>+0.5</cell><cell>+8.9</cell></row><row><cell>MT edge baseline</cell><cell>19.5</cell><cell>54.8</cell><cell>0.55</cell><cell>0.22</cell><cell>16.5</cell><cell>41.9 73.0 85.1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>EDNAS</cell><cell>22.1</cell><cell>57.7</cell><cell>0.51</cell><cell>0.20</cell><cell>14.3</cell><cell cols="2">49.5 79.2 89.4 +9.3</cell><cell>+8.2</cell><cell>+11.3</cell><cell>+9.6</cell></row><row><cell>EDNAS+JAReD</cell><cell>22.1</cell><cell>58.1</cell><cell>0.51</cell><cell>0.20</cell><cell>12.6</cell><cell cols="2">56.1 83.9 92.4 +9.7</cell><cell>+8.2</cell><cell cols="2">+20.3 +12.7</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Edge-Efficient Inference. Regarding edge efficiency, ED-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">NAS and EDNAS+JAReD use only 1/5th of the parameters</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">and 1/10th of the FLOPs compared to prior ResNet-based</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">methods. More importantly, the EDNAS-found model is</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">able to practically maintain the same on-device speed as the</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">vanilla MT baseline, if not slightly faster, despite the +12.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">improvement. This equates to a 30% improvement in la-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">tency compared to separate single-task inferences, and fur-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Stronger baselines on CityScapes. ST edge baseline and ST edge+maxLR have identical training setting with the only exception of their learning rate being 3e-4 and 1e-2 respectively</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Backbone Architecture found by EDNAS -Backbone architecture found EDNAS for multi-task segmentation and depth estimation on CityScapes, same model as presented in Tab. 2.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>Toward Edge-Efficient Dense Predictions with Synergistic Multi-Task NeuralArchitecture Search</figDesc><table><row><cell></cell><cell cols="3">Supplementary Material</cell><cell></cell></row><row><cell>EDNAS</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Edge-Friendly</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Search Space</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Proxy</cell><cell>accuracy</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Multi-Task</cell><cell></cell></row><row><cell>Search Algorithm</cell><cell>sample</cell><cell>Edge-Efficient Candidate</cell><cell>Training</cell><cell>Hardware-Aware Multi-Task Objective</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Edge</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Latency Estimator</cell><cell>latency</cell></row><row><cell>nas</cell><cell></cell><cell>reward</cell><cell></cell><cell></cell></row><row><cell>model</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>training hardware</cell><cell></cell><cell>Optimal Edge Architecture</cell><cell>Final Multi-Task Training</cell><cell>Joint Absolute-Relative Depth Loss</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>provides a visual comparison of IBN and Fused-IBN blocks.</figDesc><table><row><cell></cell><cell></cell><cell>Seg</cell><cell cols="2">Depth</cell><cell>SN</cell></row><row><cell cols="2">Reference Model</cell><cell>L CE</cell><cell>L 1</cell><cell cols="2">L RE L ICS</cell></row><row><cell>Tab. 2:</cell><cell>MT edge baseline</cell><cell>0.4</cell><cell>1.000</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">Cityscapes EDNAS</cell><cell>0.4</cell><cell>1.000</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>EDNAS+JAReD</cell><cell>0.5</cell><cell cols="2">0.950 0.050</cell><cell>-</cell></row><row><cell>Tab. 3:</cell><cell>MT edge baseline</cell><cell>1.0</cell><cell>1.000</cell><cell>-</cell><cell>40.0</cell></row><row><cell>NYUv2</cell><cell>EDNAS</cell><cell>1.0</cell><cell>1.000</cell><cell>-</cell><cell>50.0</cell></row><row><cell></cell><cell>EDNAS+JAReD</cell><cell>1.0</cell><cell cols="3">0.999 0.001 60.0</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep Elastic Networks with Model Selection for Multi-Task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chanho</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunwoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songhwai</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The price of schedulability in multi-object tracking: The history-vs.-accuracy trade-off</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanya</forename><surname>Amert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saujas</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F. Donelson</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Symposium on Real-Time Distributed Computing (ISORC)</title>
		<meeting>the IEEE International Symposium on Real-Time Distributed Computing (ISORC)</meeting>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hardware-Aware Neural Architecture Search: Survey and Taxonomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadjer</forename><surname>Benmeziane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaoutar</forename><forename type="middle">El</forename><surname>Maghraoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamza</forename><surname>Ouarnoughi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smail</forename><surname>Niar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Wistuba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naigang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automated Search for Resource-Efficient Branched Multi-Task Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bruggemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menelaos</forename><surname>Kanakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exploring Relational Context for Multi-Task Dense Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bruggemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menelaos</forename><surname>Kanakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Obukhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multi-Task Learning for Multi-Objective Evolutionary Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronghong</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CEC</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rich Caruana. Multitask Learning</title>
	</analytic>
	<monogr>
		<title level="m">Machine learning</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets and atrous convolution and and fully connected CRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TPAMI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Semantic image segmentation with deep convolutional nets and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">Loddon</forename><surname>Yuille</surname></persName>
		</author>
		<idno>abs/1412.7062</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Simpledet: A simple and versatile distributed framework for object detection and instance recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxia</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Agriculture-vision: A large aerial image database for agricultural pattern analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingqian</forename><surname>Mang Tik Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrant</forename><surname>Brunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hovnatan</forename><surname>Khachatrian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Karapetyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dozier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<editor>Thomas S. Huang, and Honghui Shi</editor>
		<meeting><address><addrLine>Greg Rose, David Wilson, Adrian Tudor, Naira Hovakimyan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Coral</forename><surname>Edge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tpu</forename></persName>
		</author>
		<ptr target="https://coral.ai/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2016. License: Cityscapes is freely available to academic and non-academic entities for non-commercial purposes</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Crawshaw</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.09796</idno>
		<title level="m">Multi-Task Learning with Deep Neural Networks: A Survey</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Chamnet: Towards efficient network design through platform-aware model adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxu</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marat</forename><surname>Dukhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Uyttendaele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niraj</forename><forename type="middle">K</forename><surname>Jha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-objective optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Search methodologies</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="403" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Depth map prediction from a single image using a multi-scale deep network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Densely connected search space for more flexible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiemin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">MTL-NAS: Task-Agnostic Neural Architecture Search towards General-Purpose Multi-Task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoping</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Nddr-cnn: Layerwise feature fusing in multi-task cnns by neural discriminative dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to Branch for Multi-Task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengsheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Yu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ulbricht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Searching for mobilenetv3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Real-time semantic segmentation with fast attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Heilbron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep learning in agriculture: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kamilaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesc</forename><surname>Xavier Prenafeta-Bold?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Electron. Agric</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="70" to="90" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Auto-VirtualNet: Cost-adaptive dynamic architecture search for multi-task learnin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunwoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chanho</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songhwai</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neurocomputing</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Monocular depth estimation using relative depth maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae-Han</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Su</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning dynamic routing for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evolutionary Architecture Search For Deep Multitask Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risto</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GECCO</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Auto-deeplab: Hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Yolactedge: Real-time instance segmentation on the edge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><forename type="middle">A Rivera</forename><surname>Soto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanyi</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Jae</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">End-to-End Multi-Task Learning with Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Johns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Using depth information and colour space variations for improving outdoor robustness for instance segmentation of cabbage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>L?ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Reiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Stana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><forename type="middle">W</forename><surname>Griepentrog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Selfsupervised pillar motion learning for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<title level="m">SNR: Sub-Network Routing for Flexible Parameter Sharing in Multi-task Learning. In AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Attentive Single-Tasking of Multiple Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevis-Kokitsi</forename><surname>Maninis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ilija Radosavovic, and Iasonas Kokkinos</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Crossstitch networks for multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Multi-task template matching for object detection, segmentation and pose estimation using depth images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiru</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Patten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann</forename><surname>Prankl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Vincze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7207" to="7213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Symbolic Programming for Automated Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiyi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kraft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pyglove</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multimodal fusion transformer for end-to-end autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashyap</forename><surname>Chitta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Regularized Evolution for Image Classifier Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A Comprehensive Survey of Neural Architecture Search: Challenges and Solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengzhen</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Yao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Computing Surveys</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Latent multi-task architecture learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>S?gaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.04381</idno>
		<title level="m">verted Residuals and Linear Bottlenecks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Indoor segmentation and support inference from rgbd images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Pushmeet Kohli Nathan Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1409.1556</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Kretzschmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xerxes</forename><surname>Dotiwalla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Chouard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijaysai</forename><surname>Patnaik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tsui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Caine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiquan</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksei</forename><surname>Timofeev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krivokon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Scalability in perception for autonomous driving: Waymo open dataset</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ximeng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rameswar</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">MnasNet: Platform-Aware Neural Architecture Search for Mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">EfficientNetV2: Smaller Models and Faster Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">EfficientDet: Scalable and Efficient Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Bert De Brabandere, and Luc Van Gool. Branched Multi-Task Networks: Deciding What Layers To Share</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Georgoulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Multi-Task Learning for Dense Prediction Tasks: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wouter</forename><surname>Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TPAMI</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Any-width networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Eder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">True</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Michael</forename><surname>Frahm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPRW</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">How your phone recognizes your home: An investigation of mobile object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Piros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadovnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">National Conference on Undergraduate Research (NCUR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Multi-path Neural Networks for On-device Multi-domain Visual Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Greaves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Sbaiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyman</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">MobileDets: Searching for Object Detection Architectures for Mobile Accelerators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyang</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suyog</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berkin</forename><surname>Akin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Re-thinking cnn frameworks for time-sensitive autonomousdriving applications: Addressing an industrial challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shige</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Bakita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">Donelson</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Michael</forename><surname>Frahm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS)</title>
		<meeting>the IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Gradient Surgery for Multi-Task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhe</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Rethinking codesign of neural architectures and hardware accelerators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berkin</forename><surname>Akin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiyi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianjian</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Yazdanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Narayanaswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Laudon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.08619</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Crossmodality 3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
