<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Mao</surname></persName>
							<email>xmao@stu.ecnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Technology</orgName>
								<orgName type="department" key="dep2">Alibaba Group</orgName>
								<orgName type="institution">East China Normal University Lazada</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenting</forename><surname>Wang</surname></persName>
							<email>wenting.wang@lazada.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Technology</orgName>
								<orgName type="department" key="dep2">Alibaba Group</orgName>
								<orgName type="institution">East China Normal University Lazada</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
							<email>ybwu@cs.ecnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Technology</orgName>
								<orgName type="department" key="dep2">Alibaba Group</orgName>
								<orgName type="institution">East China Normal University Lazada</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Man</forename><surname>Lan</surname></persName>
							<email>mlan@cs.ecnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Technology</orgName>
								<orgName type="department" key="dep2">Alibaba Group</orgName>
								<orgName type="institution">East China Normal University Lazada</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cross-lingual entity alignment (EA) aims to find the equivalent entities between crosslingual KGs (Knowledge Graphs), which is a crucial step for integrating KGs. Recently, many GNN-based EA methods are proposed and show decent performance improvements on several public datasets. However, existing GNN-based EA methods inevitably inherit poor interpretability and low efficiency from neural networks. Motivated by the isomorphic assumption of GNN-based methods, we successfully transform the cross-lingual EA problem into an assignment problem. Based on this re-definition, we propose a frustratingly Simple but Effective Unsupervised entity alignment method (SEU) without neural networks. Extensive experiments have been conducted to show that our proposed unsupervised approach even beats advanced supervised methods across all public datasets while having high efficiency, interpretability, and stability.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The knowledge graph (KG) represents a collection of interlinked descriptions of real-world objects and events, or abstract concepts (e.g., documents), which has facilitated many downstream applications, such as recommendation systems <ref type="bibr" target="#b3">(Cao et al., 2019b;</ref> and question-answering <ref type="bibr" target="#b17">Qiu et al., 2020)</ref>. Over recent years, a large number of KGs are constructed from different domains and languages by different organizations. These cross-lingual KGs usually hold unique information individually but also share some overlappings. Integrating these cross-lingual KGs could provide a broader view for users, especially for the minority language users who usually suffer from lacking language resources. Therefore, how to fuse the knowledge from cross-lingual KGs has attracted increasing attentions.</p><p>As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, cross-lingual entity alignment (EA) aims to find the equivalent entities  across multi-lingual KGs, which is a crucial step for integrating KGs. Conventional methods <ref type="bibr" target="#b21">(Suchanek et al., 2011;</ref><ref type="bibr" target="#b9">Jim?nez-Ruiz and Grau, 2011)</ref> usually solely rely on lexical matching and probability reasoning, which requires machine translation systems to solve cross-lingual tasks. However, existing machine translation systems are not able to achieve high accuracy with limited contextual information, especially for language pairs that are not alike, such as Chinese-English and Japanese-English.</p><p>Recently, Graph Convolutional Network (GCN) <ref type="bibr" target="#b12">(Kipf and Welling, 2017)</ref> and subsequent Graph Neural Network (GNN) variants have achieved state-of-the-art results in various graph application. Intuitively, GNN is better in capturing structural information of KGs to compensate for the shortcoming of conventional methods. Specifically, several GNN-based EA methods <ref type="bibr" target="#b27">Wu et al., 2019a;</ref> indeed demonstrate decent performance improvements on public datasets. All these GNN-based EA methods are built upon a core premise, i.e., entities and their counterparts have similar neighborhood structures. However, better performance is not the only outcome of using GNN. Existing GNN-based methods inevitably inherit the following inborn defects from neural networks:</p><p>(1) Poor Interpretability: Recently, many researchers view GNN <ref type="bibr" target="#b27">Wu et al., 2019a)</ref> as a black box, focusing on improving performance metrics. The tight coupling between non-linear operations and massive parameters makes GNN hard to be interpreted thoroughly. As a result, it is hard to judge whether the new designs are universal or just over-fitting on a specific dataset. A recent summary  notes that several "advanced" EA methods are even beaten by the conventional methods on several public datasets.</p><p>(2) Low Efficiency: To further increase the performance, newly proposed EA methods try to stack novel techniques, e.g., Graph Attention Networks <ref type="bibr" target="#b27">(Wu et al., 2019a)</ref>, Graph Matching Networks , and Joint Learning <ref type="bibr" target="#b2">(Cao et al., 2019a)</ref>. Consequently, the overall architectures become more and more unnecessarily complex, resulting in their time-space complexities also dramatically increase.  present that the running time of complex methods (e.g., RDGCN <ref type="bibr" target="#b27">(Wu et al., 2019a)</ref>) is 10? more than that of vanilla GCN <ref type="bibr" target="#b25">(Wang et al., 2018)</ref>.</p><p>In this paper, we notice that existing GNN-based EA methods inherit considerable complexity from their neural network lineage. Naturally, we consider eliminating the redundant designs from existing EA methods to enhance interpretability and efficiency without losing accuracy. Leveraging the core premise of GNN-based EA methods, we restate the assumption that both structures and textual features of source and target KGs are isomorphic. With this assumption, we are able to successfully transform the cross-lingual EA problem into an assignment problem, which is a fundamental and well-studied combinatorial optimization problem. Afterward, the assignment problem could be easily solved by the Hungarian algorithm <ref type="bibr" target="#b13">(Kuhn, 1955)</ref> or Sinkhorn operation <ref type="bibr" target="#b5">(Cuturi, 2013)</ref>.</p><p>Based on the above findings, we propose a frustratingly Simple but Effective Unsupervised EA method (SEU) without neural networks. Compared to existing GNN-based EA methods, SEU only retains the basic graph convolution operation for feature propagation while abandoning the complex neural networks, significantly improving efficiency and interpretability. Experimental results on the public datasets show that SEU could be completed in several seconds with the GPU or tens of seconds with the CPU. More startlingly, our unsupervised method even outperforms the state-of-the-art supervised approaches across all public datasets. Furthermore, we discuss the possible reasons behind the unsatisfactory performance of existing complex EA methods and the necessity of neural networks in cross-lingual EA. The main contributions are summarized as follows:</p><p>? By assuming that both structures and textual features of source and target KGs are isomorphic, we successfully transform the crosslingual EA problem into an assignment problem. Based on this finding, we propose a frustratingly Simple but Effective Unsupervised entity alignment method (SEU).</p><p>? Extensive experiments on public datasets indicate that our unsupervised method outperforms all advanced supervised competitors while preserving high efficiency, interpretability, and stability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definition</head><p>KG stores the real-world knowledge in the form of triples (h, r, t). A KG could be defined as G = (E, R, T ), where E, R, and T represent the entity set, relation set, and triple set, respectively. Given a source graph G s = (E s , R s , T s ) and a target graph G t = (E t , R t , T t ), EA aims to find the entity correspondences P between KGs.</p><p>3 Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Cross-lingual Entity Alignment</head><p>Existing cross-lingual EA methods are based on the premise that equivalent entities in different KGs have similar neighboring structures. Following this idea, most of them can be summarized into two steps (as shown in <ref type="figure" target="#fig_1">Figure 2</ref>): (1) Using KG embedding methods (e.g., TransE <ref type="bibr" target="#b1">(Bordes et al., 2013)</ref> and <ref type="bibr">GCN (Kipf and Welling, 2016)</ref>) to generate low-dimensional embeddings for entities and relations in each KGs.</p><p>(2) Mapping these embeddings into a unified vector space through contrastive losses <ref type="bibr" target="#b8">(Hadsell et al., 2006;</ref><ref type="bibr" target="#b19">Schroff et al., 2015)</ref> and pre-aligned entity pairs. Based on the vanilla GCN, many EA methods design task-specific modules for improving the performance of EA. <ref type="bibr" target="#b2">Cao et al. (2019a)</ref> propose a multichannel GCN to learn multi-aspect information from KGs. <ref type="bibr" target="#b27">Wu et al. (2019a)</ref> use a relation-aware dual-graph network to incorporate relation information with structural information. Moreover, due to the lack of labeled data, some methods <ref type="bibr" target="#b23">(Sun et al., 2018;</ref><ref type="bibr" target="#b15">Mao et al., 2020)</ref> apply iterative strategies to generate semi-supervised data. In order to provide a multi-aspect view from both structure and semantic, some methods <ref type="bibr" target="#b28">(Wu et al., 2019b;</ref><ref type="bibr" target="#b30">Yang et al., 2019)</ref> use word vectors of translated entity names as the input features of GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Assignment Problem</head><p>The assignment problem is a fundamental and wellstudied combinatorial optimization problem. An intuitive instance is to assign N jobs for N workers. Assuming that each worker can do each job at a term, though with varying degrees of efficiency, let x ij be the profit if the i-th worker is assigned to the j-th job. Then the problem is to find the best assignment plan (which job should be assigned to which person in one-to-one basis) so that the total profit of performing all jobs is maximum. Formally, it is equivalent to maximizing the following equation:</p><formula xml:id="formula_0">arg max P ?P N P , X F (1) X ? R N ?N is the profit matrix.</formula><p>P is a permutation matrix denoting the assignment plan. There are exactly one entry of 1 in each row and each column in P while 0s elsewhere. P N represents the set of all N-dimensional permutation matrices.</p><p>Here, ? F represents the Frobenius inner product.</p><p>In this paper, we adopt the Hungarian algorithm <ref type="bibr" target="#b13">(Kuhn, 1955)</ref> and the Sinkhorn operation <ref type="bibr" target="#b5">(Cuturi, 2013)</ref> to solve the assignment problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Proposed Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">From Alignment to Assignment</head><p>The inputs of our proposed SEU are four matrices: A s ? R |Es|?|Es| and A t ? R |Et|?|Et| represent the adjacent matrices of the source graph G s and the target graph G t . H s ? R |Es|?d and H t ? R |Et|?d represent the textual features of entities that have been pre-mapped into a unified semantic space through machine translation systems or crosslingual word embeddings. Similar to the assignment plan, aligned entity pairs in EA also needs to satisfy the one-to-one constraint. Let a permutation matrix P ? P |E| represent the entity correspondences between G s and G t . P ij = 1 indicates that e i ? G s and e j ? G t are an equivalent entity pair. The goal of SEU is to solve P according to {A s , A t , H s , H t }. Consider the following ideal situation:</p><p>(1) A s and A t are isomorphic, i.e., A s could be transformed into A t by reordering the entity node indices according to P (as shown in <ref type="figure" target="#fig_2">Figure 3)</ref>:</p><formula xml:id="formula_1">P A s P ?1 = A t<label>(2)</label></formula><p>(2) The textual features of equivalent entity pairs are mapped perfectly by the translation system. Therefore, H s and H t could also be aligned according to the entity correspondences P :</p><formula xml:id="formula_2">P H s = H t<label>(3)</label></formula><p>By combining Equation <ref type="formula" target="#formula_1">(2)</ref> and <ref type="formula" target="#formula_2">(3)</ref>, the connection between the 5-tuple {A s , A t , H s , H s , P } could be described as follows:</p><formula xml:id="formula_3">(P A s P ?1 ) l P H s = A l t H t ?l ? N ? P A l s H s = A l t H t ?l ? N<label>(4)</label></formula><p>Based on Equation <ref type="formula" target="#formula_3">(4)</ref>, P could be solved by minimizing the Frobenius norm</p><formula xml:id="formula_4">P A l s H s ? A l t H t 2 F</formula><p>under the one-to-one constraint P ? P |E| . Theoretically, for arbitrarily depth l ? N, the solution of P should be the same. However, the above inference is based on the ideal isomorphic situation. In practice, G s and G t are not strictly isomorphic and the translation system cannot perfectly map the textual features into a unified semantic space either. In order to reduce the impact of noise existing in practice, P should be fit for various depths l. Therefore, we propose the following equation to solve the cross-lingual EA problem:</p><formula xml:id="formula_5">arg min P ?P |E| L l=0 P A l s H s ? A l t H t 2 F<label>(5)</label></formula><p>Theorem 1 Equation <ref type="formula" target="#formula_5">(5)</ref> is equivalent to solving the following assignment problem:</p><formula xml:id="formula_6">arg max P ?P |E| P , L l=0 A l t Ht A l s Hs T F (6)</formula><p>Proof: According to the property of Frobenius</p><formula xml:id="formula_7">norm A ? B 2 F = A 2 F + B 2 F ? 2 A, B F , Equation (5) could be derived into following: arg min P ?P |E| L l=0 P A l s Hs ? A l t Ht 2 F = arg min P ?P |E| L l=0 P A l s Hs 2 F + A l t Ht 2 F ? 2 P A l s Hs, A l t Ht F<label>(7)</label></formula><p>Here, the permutation matrix P must be orthogonal, so both P A l s H s 2 F and A l t H t 2 F are constants. Then, Equation <ref type="formula" target="#formula_7">(7)</ref> is equivalent to maximizing as below:</p><formula xml:id="formula_8">arg max P ?P |E| L l=0 P A l s Hs, A l t Ht F<label>(8)</label></formula><p>For arbitrarily real matrices A and B, these two equations always hold:</p><formula xml:id="formula_9">A, B F = Tr(AB T ) and A, B + C F = A, B F + A, C F , where</formula><p>Tr(X) represents the trace of matrix X. Therefore, Theorem 1 is proved:</p><formula xml:id="formula_10">arg max P ?P |E| L l=0 P A l s Hs, A l t Ht F = arg max P ?P |E| L l=0 Tr P A l s Hs(A l t Ht) T = arg max P ?P |E| L l=0 P , A l t Ht(A l s Hs) T F = arg max P ?P |E| P , L l=0 A l t Ht A l s Hs T F<label>(9)</label></formula><p>By Theorem 1, we successfully transform the EA problem into the assignment problem. Compared to GNN-based EA methods, our proposed method retains the basic graph convolution operation for feature propagation but replaces the complex neural networks with the well-studied assignment problem. Note that the entity scales |E s | and |E t | are usually inconsistent in practice, resulting in the profit matrix not being a square matrix. This kind of unbalanced assignment problem could be reduced to the balanced assignment problem easily. Assuming that |E s |&gt;|E t |, a naive reduction is to pad the profit matrix with zeros such that its shape becomes R |Es|?|Es| . This naive reduction is suitable for the dataset with a small gap between |E s | and |E t |. For the dataset with a large entity scale gap, there is a more efficient reduction algorithm available <ref type="bibr" target="#b18">(Ramshaw and Tarjan, 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Two Algorithms for Solving the Assignment Problem</head><p>The first polynomial time-complexity algorithm for the assignment problem is the Hungarian algorithm <ref type="bibr" target="#b13">(Kuhn, 1955)</ref>, which is based on improving a matching along the augmenting paths. The time complexity of the original Hungarian algorithm is O(n 4 ). Later, <ref type="bibr" target="#b10">Jonker and Volgenant (1987)</ref> improve the algorithm to achieve O(n 3 ) running time, which is one of the most popular variants.</p><p>Besides the Hungarian algorithm, the assignment problem could also be regarded as a special case of the optimal transport problem. In the optimal transport problem, the assignment plan P could be any doubly stochastic matrix instead of a permutation matrix. Based on the Sinkhorn operation <ref type="bibr" target="#b20">(Sinkhorn, 1964;</ref><ref type="bibr" target="#b0">Adams and</ref><ref type="bibr">Zemel, 2011), Cuturi (2013)</ref> proposes a fast and completely parallelizable algorithm for the optimal transport problem:</p><p>S 0 (X) = exp(X), S k (X) = N c (N r (S k?1 (X))),</p><formula xml:id="formula_11">Sinkhorn(X) = lim k?? S k (X).<label>(10)</label></formula><p>where N r (X)=X (X1 N 1 T N ) and N c =X (1 N 1 T N X) are the row and column-wise normalization operators of a matrix, represents the elementwise division, and 1 N is a column vector of ones. Then, <ref type="bibr" target="#b16">Mena et al. (2018)</ref> further prove that the assignment problem could also be solved by the Sinkhorn operation as a special case of the optimal transport problem:</p><formula xml:id="formula_12">arg max P ?P N P , X F = lim ? ?0 + Sinkhorn(X/? )<label>(11)</label></formula><p>In general, the time complexity of the Sinkhorn operation is O(kn 2 ). Because the number of iteration k is limited, the Sinkhorn operation can only obtain an approximate solution in practice. But according to our experimental results, a very small k is enough to achieve decent performance in entity alignment. Therefore, compared to the Hungarian algorithm, the Sinkhorn operation is n times more efficient, i.e., O(n 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation Details</head><p>The above two sections introduce how to transform the cross-lingual EA problem into the assignment problem and how to solve the assignment problem. This section will clarify two important implementation details of our proposed method SEU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Textual Features H</head><p>The input features of SEU include two aspects:</p><p>Word-Level. In previous cross-lingual EA methods <ref type="bibr" target="#b27">Wu et al., 2019a)</ref>, the most commonly used textual features are wordlevel entity name vectors. Specifically, these methods first use machine translation systems or crosslingual word embeddings to map entity names into a unified semantic space and then average the pretrained entity name vectors to construct the initial features. To make fair comparisons, we adopt the same entity name translations and word vectors provided by .</p><p>Char-Level. Because of the contradiction between the extensive existence of proper nouns (e.g., person and city name) and the limited size of word vocabulary, the word-level EA methods suffer from a serious out of vocabulary (OOV) issue. Therefore, many EA methods explore the char-level features, using char-CNN  or name-BERT  to extract the char/sub-word features of entities. In order to keep the simplicity and consistency of our proposed method, we adopt the character bigrams of translated entity names as the char-level input textual features instead of complex neural networks.</p><p>In addition to these text-based methods, we notice that some structure-based EA methods <ref type="bibr" target="#b25">(Wang et al., 2018;</ref> do not require any textual information at all, where the entity features are randomly initialized. Section 5.6 will discuss the connection between text-based and structure-based methods and challenge the necessity of neural networks in cross-lingual EA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Adjacent Matrix A</head><p>In Section 4.1, all deductions are built upon the assertion that the adjacency matrices A s and A t are isomorphic. Obviously, let D be the degree matrix of adjacency matrix A s/t , the equal probability random walk matrix A r = D ?1 A s/t and the symmetric normalized Laplacian matrix A L = I ? D ?1/2 A s/t D ?1/2 of A s and A t are also isomorphic too. Therefore, if A s/t is replaced by A r or A L , our method still holds.  However, the above matrices ignore the relation types in the KGs and treat all types of relations equally important. We believe the relations with less frequency should have higher weight because they represent more unique information. Following this intuition, we apply a simple strategy to generate the relational adjacency matrix A rel , for a ij ? A rel :</p><formula xml:id="formula_13">aij = r j ?R i,j ln(|T |/|Tr j |) k?N i r k ?R i,k ln(|T |/|Tr k |)<label>(12)</label></formula><p>where N i represents the neighboring set of entity e i , R i,j is the relation set between e i and e j , |T | and |T r | represent the total number of all triples and the triples containing relation r, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Our experiments are conducted on a workstation with a GeForce GTX Titan X GPU and a Ryzen ThreadRipper 3970X CPU. The code and datasets are available in github.com/MaoXinn/SEU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>To make fair comparisons with previous EA methods, we experiment with two widely used public datasets: <ref type="formula">(1)</ref>  The statistics of these datasets are summarized in <ref type="table" target="#tab_2">Table 1</ref>. Most of the previous studies <ref type="bibr" target="#b25">(Wang et al., 2018;</ref><ref type="bibr" target="#b2">Cao et al., 2019a)</ref> randomly split 30% of the entity pairs for training and development, while using the remaining 70% for testing. Because our proposed method is unsupervised, all of the entity pairs could be used for testing.   Baselines are separated in accord with the three groups described in Section 5.2. Most results are from the original papers. Some recent papers are failed to run on missing datasets or do not release the source code yet. We will fill in these blanks after contacting their authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baselines</head><p>We compare our method against the following three groups of advanced EA methods: (1) Structure: These methods only use the structure information (i.e., triples): GCN-Align <ref type="bibr" target="#b25">(Wang et al., 2018)</ref>, MuGNN <ref type="bibr" target="#b2">(Cao et al., 2019a)</ref>, BootEA <ref type="bibr" target="#b23">(Sun et al., 2018)</ref>, MRAEA <ref type="bibr" target="#b15">(Mao et al., 2020)</ref>, JEANS <ref type="bibr" target="#b4">(Chen et al., 2021)</ref>. (2) Word-level: These methods average the pre-trained entity name vectors to construct the initial features: GM-Align , RDGCN <ref type="bibr" target="#b27">(Wu et al., 2019a)</ref>, HGCN <ref type="bibr" target="#b28">(Wu et al., 2019b)</ref>, DAT <ref type="bibr" target="#b32">(Zeng et al., 2020b)</ref>, DGMC <ref type="bibr" target="#b6">(Fey et al., 2020)</ref>. (3) Char-level: These EA methods further adopt the char-level textual features: At-trGNN , CEA <ref type="bibr" target="#b31">(Zeng et al., 2020a)</ref>, EPEA . For our proposed method, SEU(word) and SEU(char) represent the model only using the word and char features as the inputs, respectively. SEU(w+c) represents concatenating the word and char features together as the inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Settings</head><p>Metrics. Following convention, we use Hits@k and Mean Reciprocal Rank (MRR) as our evaluation metrics. The Hits@k score is calculated by measuring the proportion of correct pairs in the top-k. In particular, Hits@1 equals accuracy.</p><p>Hyper-parameter. In the main experiments, we use the Sinkhorn operation to solve the assignment problem. For all dataset, we use a same default setting: the depth L = 2; the iterations k = 10; the temperature ? = 0.02. <ref type="table" target="#tab_4">Table 2</ref> shows the main experimental results of all EA methods. Numbers in bold denote the best results among all methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Main Experiments</head><p>SEU vs. Baselines. According to the results, our method consistently achieves the best performance across all datasets. Compared with the previous SOTA methods, SEU (w+c) improves the performance on Hits@1 and M RR by 1.5% and 1.3% at least. More importantly, SEU outperforms the supervised competitors as an unsupervised method, which is critical in practical applications.</p><p>In addition to the better performances, SEU also has better interpretability and stability: (1) When solving with the Hungarian algorithm, we can trace the reasons for each decision by the augmenting path, which brings better interpretability.</p><p>(2) As we all know, neural networks optimized by SGD usually have some performance fluctuations. Since both the Hungarian algorithm and Sinkhorn operation are deterministic, multiple runs of these algorithms remain unchanged under the same hyperparameters, which means better stability.   Word vs. Char. From <ref type="table" target="#tab_4">Table 2</ref>, we observe that the char-level SEU greatly outperforms the word-level SEU. Especially in SRPRS FR?EN , the performance gap on Hits@1 is more than 16%. As mentioned in Section 4.3.1, the main reason is that these datasets contain extensive OOV proper nouns. For example, in DBP15K, 4-6% of the words are OOV; while in SRPRS DE?EN and SRPRS FR?EN , more than 12% and 16% of the entity names are OOV, respectively.</p><p>Note that the performance difference between SEU(word) and SEU (char) is vast, but these two features still complement to each other, so the combination of them still improves the performances (especially on DBP ZH?EN dataset). We believe the hidden reason is synonyms. For example, soccer and football refer to the same Chinese phrase, but there is almost no overlap in the char-level between these two English words. However, the word-level features could bridge such semantic gap via pretrained cross lingual word vectors. SEU vs. PARIS. As mentioned in Section 1, a recent summary  notes that several "advanced" EA methods are even beaten by the conventional methods. To make this study more comprehensive, we also compare 1 Since the Hungarian algorithm only outputs the assigned entity pairs, instead of a probability matrix P , we can only report the Hits@1 performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>DBP15K SRPRS GCN-Align <ref type="bibr" target="#b25">(Wang et al., 2018)</ref> 103 87 MuGNN <ref type="bibr" target="#b2">(Cao et al., 2019a)</ref> 3,156 2,215 BootEA <ref type="bibr" target="#b23">(Sun et al., 2018)</ref> 4,661 2,659 MRAEA <ref type="bibr" target="#b15">(Mao et al., 2020)</ref> 3,894 1,248 GM-Align  26,328 13,032 RDGCN <ref type="bibr" target="#b27">(Wu et al., 2019a)</ref> 6,711 886 HGCN <ref type="bibr" target="#b28">(Wu et al., 2019b)</ref> 11,275 2,504 SEU(CPU) 22.1 13.8 SEU(GPU) 16.2 9.6  <ref type="bibr" target="#b21">(Suchanek et al., 2011)</ref> in <ref type="figure" target="#fig_5">Figure 4</ref>, which is a holistic unsupervised solution to align KGs based on probability estimates. Since PARIS may not always output a target entity for every source entity, we use the F1-score as the evaluation metric to deal with entities that do not have a match. In our method, the F1-score is equivalent to Hits@1. Consistent with Zhang's summary, PARIS is better than most GNN-based EA methods. On the other hand, SEU outperforms PARIS significantly on these public datasets except for DBP ZH?EN . Hungarian vs. Sinkhorn <ref type="table" target="#tab_5">Table 3</ref> reports the performances of SEU(w+c) with the Hungarian algorithm and Sinkhorn operation, respectively. Theoretically, the Hungarian algorithm could generate the optimal solution precisely, while the Sinkhorn operation can only generate an approximate solution. Therefore, the Hungarian algorithm is always slightly better, but the performance gap is relatively small. Furthermore, we list the time costs of these two algorithms in <ref type="table" target="#tab_6">Table 4</ref>. We observe that the time costs of the Hungarian algorithm are unstable, which depend on the dataset. Meanwhile, the time costs of the Sinkhorn operation are much more stable. Because the Sinkhorn operation is completely parallelizable, its time costs could be further reduced by the GPU. In general, the Sinkhorn operation is more suitable for large-scale EA because of its higher efficiency.</p><p>Overall Time Efficiency We specifically evaluate the overall time costs of some EA methods and report the results in <ref type="table" target="#tab_7">Table 5</ref>. It is obvious that the efficiency of SEU far exceeds all advanced competitors. Typically, existing GNN-based methods require forward propagations on every batch, and the convergence of models usually requires hundreds of batches. Since SEU does not have any trainable parameters, it only requires forward propagation once, enabling SEU to achieve such acceleration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Auxiliary Experiments</head><p>To explore the behavior of SEU in different situations, we design the following experiments: Temperature ? . Similar to the temperature ? in the softmax operation, ? in the Sinkhorn operation is also used to make the distribution closer to onehot. With the remaining config unchanged, we set ? with different values and report the corresponding performances of SEU(w+c) on DBP ZH?EN in <ref type="figure">Figure 5</ref>. If we choose an appropriate ? , the Sinkhorn algorithm will converge quickly to the optimal solution. But if ? is set too large, the algorithm will fail to converge.</p><p>Depth L. For depth L, we list the experimental results in <ref type="figure">Figure 6</ref>. In particular, L = 0 is equivalent to aligning entities only according to their own features without the neighborhood information. SEU(w+c) with L = 2 achieves the best performance on all subsets of DBP15K, which indicates the necessity of introducing neighborhood information. Similar to GNN-based EA methods, SEU is also affected by the over-smoothing problem. When stacking more layers, the performances begin to decrease slightly.</p><p>Adjacency matrix A. To distinguish different relation types in KGs, we adopt a simple strategy to generate the relational adjacency matrix A rel . <ref type="table" target="#tab_9">Table 6</ref> reports the performances of SEU(w+c) with different types of adjacency matrices. A is the standard adjacency matrix, A r = D ?1 A is the  equal probability random walk matrix and A L = I ? D ?1/2 AD ?1/2 is the symmetric normalized Laplacian matrix. The experimental results show that A rel achieves the best performance across all these three subsets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Discussion</head><p>From the experimental results, we observe that the supervised EA methods are even beaten by the unsupervised methods. In this section, we propose a hypothesis that the reason behind this counterintuitive phenomenon is potential over-fitting. As mentioned in Section 5.2, existing EA methods could be divided into structure-based and textbased according to the input features. The only difference between them is that the structure-based methods use randomly initialized vectors as the entity features, while the text-based methods use pre-mapped textual features as the inputs. Let us consider the vanilla GCN as a sample:</p><formula xml:id="formula_14">H l+1 = ?(A L H l W l )<label>(13)</label></formula><p>where ? represents the activation function. For the structure-based methods, since the input features H and the transformation matrix W are both randomly initialized, they could be simplified into one matrix, i.e., H l+1 = ?(A L H l ). This idea has been proved by many structure-based EA methods <ref type="bibr" target="#b2">(Cao et al., 2019a;</ref><ref type="bibr" target="#b15">Mao et al., 2020)</ref>, which propose to diagonalize or remove the transformation matrix W . In this situation, GCN is reduced to a simple fully connected neural network with adjacency matrices as its input features. The essence of structure-based EA methods is to map the features of adjacency matrices into a unified vector space. Therefore, these structure-based EA methods require supervised data to learn the parameters. As for the text-based EA methods, the textual features of entities have already been pre-mapped into a unified semantic space by machine translation or cross-lingual word vectors. Therefore, these text-based EA methods are equivalent to further fitting these pre-mapped features on a few aligned entity pair seeds, which could cause potential overfitting. Considering that we could directly align entities as an assignment problem, it is unnecessary to further fit entity features via neural networks.</p><p>As a simple unsupervised method, our proposed SEU achieves excellent performances on several EA datasets, which confirms the above analysis from the empirical side. It is noted that this section only proposes a possible explanation, not rigorous proof. We will continue to explore in this direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we successfully transform the crosslingual EA problem into the assignment problem. Based on this finding, we propose a frustratingly Simple but Effective Unsupervised EA method (SEU) without neural networks. Experiments on widely used public datasets indicate that SEU outperforms all advanced competitors and has high efficiency, interpretability, and stability.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An example of cross-lingual knowledge graph entity alignment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The architecture of existing EA methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>=Figure 3 :</head><label>3</label><figDesc>An example of isomorphic graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>DBP15K<ref type="bibr" target="#b22">(Sun et al., 2017)</ref>: This dataset consists of three cross-lingual subsets from multi-lingual DBpedia: DBP FR?EN , DBP ZH?EN , DBP JA?EN . Each subset contains 15, 000 entity pairs. (2) SRPRS: propose this sparse dataset, including two cross-lingual subsets: SRPRS FR?EN and SRPRS DE?EN . Each subset also contains 15, 000 entity pairs but with much fewer triples compared to DBP15K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>F1-score of SEU(w+c) and PARIS. algorithm DBP ZH?EN DBP JA?EN DBP FR?EN Hungarian 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Hits@1 on DBP ZH?EN with different ? . Hits@1 with different depths L.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Marvel USA Robert Downey Jr. Iron Man</head><label></label><figDesc></figDesc><table><row><cell>KG EN</cell><cell></cell><cell></cell><cell></cell><cell>KG CN</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>??</cell><cell></cell><cell>??</cell></row><row><cell>[own by]</cell><cell>[born in]</cell><cell>SAME?</cell><cell>[own by]</cell><cell>???</cell><cell>[born in]</cell></row><row><cell>[friend]</cell><cell>[act]</cell><cell></cell><cell>[friend]</cell><cell></cell><cell></cell></row><row><cell>Spider Man</cell><cell></cell><cell></cell><cell></cell><cell>????</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistical data of DBP15K and SRPRS.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Main experimental results on DBP15K and SRPRS.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Hits@1 of Hungarian and Sinkhorn. 1 algorithm DBP ZH?EN DBP JA?EN DBP FR?EN</figDesc><table><row><cell>Hungarian</cell><cell>43.4s</cell><cell>19.8s</cell><cell>7.6s</cell></row><row><cell>Sinkhorn(CPU)</cell><cell>6.1s</cell><cell>6.1s</cell><cell>6.2s</cell></row><row><cell>Sinkhorn(GPU)</cell><cell>1.8s</cell><cell>1.7s</cell><cell>1.8s</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Time costs of Hungarian and Sinkhorn.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>: Time costs of EA methods (seconds). 2</cell></row><row><cell>SEU against a representative conventional method</cell></row><row><cell>PARIS</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Performances with different types of adjacency matrices A.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Ranking via sinkhorn propagation. CoRR, abs/1106</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prescott</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garc?a-Dur?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Lake Tahoe, Nevada, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-12-05" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
	<note>Proceedings of a meeting held</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-channel graph neural network for entity alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1140</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy; Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07-28" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1452" to="1461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unifying knowledge graph learning and recommendation: Towards a better understanding of user preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zikun</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<idno type="DOI">10.1145/3308558.3313705</idno>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2019-05-13" />
			<biblScope unit="page" from="151" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cross-lingual entity alignment with incidental supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijia</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-04-19" />
			<biblScope unit="page" from="645" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sinkhorn distances: Lightspeed computation of optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held December 5-8</title>
		<meeting><address><addrLine>Lake Tahoe, Nevada, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2292" to="2300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep graph matching consensus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Eric</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><forename type="middle">M</forename><surname>Kriege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to exploit long-term relational dependencies in knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingbing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="page" from="2505" to="2514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2006.100</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="page" from="1735" to="1742" />
			<date type="published" when="2006-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Logmap: Logic-based and scalable ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernesto</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo Cuenca</forename><surname>Grau</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-25073-6_18</idno>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web -ISWC 2011 -10th International Semantic Web Conference</title>
		<meeting><address><addrLine>Bonn, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-10-23" />
			<biblScope unit="page" from="273" to="288" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A shortest augmenting path algorithm for dense and sparse linear assignment problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Jonker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Volgenant</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02278710</idno>
	</analytic>
	<monogr>
		<title level="j">Computing</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="325" to="340" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno>abs/1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harold W Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Naval research logistics quarterly</title>
		<imprint>
			<date type="published" when="1955" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="83" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploring and evaluating attributes, values, and structures for entity alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangming</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.515</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="6355" to="6364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MRAEA: an efficient and robust entity alignment approach for cross-lingual knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huimin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Man</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3336191.3371804</idno>
	</analytic>
	<monogr>
		<title level="m">WSDM &apos;20: The Thirteenth ACM International Conference on Web Search and Data Mining</title>
		<meeting><address><addrLine>Houston, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-02-03" />
			<biblScope unit="page" from="420" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning latent permutations with gumbel-sinkhorn networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gonzalo</forename><forename type="middle">E</forename><surname>Mena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">W</forename><surname>Linderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. Open-Review.net</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Stepwise reasoning for multi-relation question answering over knowledge graph with weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3336191.3371812</idno>
	</analytic>
	<monogr>
		<title level="m">WSDM &apos;20: The Thirteenth ACM International Conference on Web Search and Data Mining</title>
		<meeting><address><addrLine>Houston, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-02-03" />
			<biblScope unit="page" from="474" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">On minimum-cost assignments in unbalanced bipartite graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert E Tarjan</surname></persName>
		</author>
		<idno>HPL-2012-40R1</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>HP Labs</publisher>
			<pubPlace>Palo Alto, CA, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2015.7298682</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015-06-07" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A relationship between arbitrary positive matrices and doubly stochastic matrices. The annals of mathematical statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Sinkhorn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1964" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="876" to="879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">PARIS: probabilistic alignment of relations, instances, and schema</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Senellart</surname></persName>
		</author>
		<idno type="DOI">10.14778/2078331.2078332</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="157" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cross-lingual entity alignment via joint attributepreserving embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-68288-4_37</idno>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web -ISWC 2017 -16th International Semantic Web Conference</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017-10-21" />
			<biblScope unit="volume">10587</biblScope>
			<biblScope unit="page" from="628" to="644" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bootstrapping entity alignment with knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2018/611</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018</title>
		<meeting>the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-13" />
			<biblScope unit="page" from="4396" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-task feature learning for knowledge graph enhanced recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minyi</forename><surname>Guo</surname></persName>
		</author>
		<idno type="DOI">10.1145/3308558.3313411</idno>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2019-05-13" />
			<biblScope unit="page" from="2000" to="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cross-lingual knowledge graph alignment via graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingsong</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-1032</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10-31" />
			<biblScope unit="page" from="349" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Knowledge graph alignment with entity-pair embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoju</forename><surname>Ye</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.130</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-11-16" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="1672" to="1680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Relation-aware entity alignment for heterogeneous knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuting</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/733</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-10" />
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page" from="5278" to="5284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Jointly learning entity and relation representations for entity alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuting</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1023</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-03" />
			<biblScope unit="page" from="240" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Crosslingual knowledge graph alignment via graph matching neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1304</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2019-07-28" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3156" to="3161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Aligning cross-lingual entities with multi-aspect information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiu-Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1451</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-03" />
			<biblScope unit="page" from="4430" to="4440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Collective entity alignment via adaptive features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiuyang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuemin</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDE48307.2020.00191</idno>
	</analytic>
	<monogr>
		<title level="m">36th IEEE International Conference on Data Engineering</title>
		<meeting><address><addrLine>Dallas, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-20" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="1870" to="1873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Degree-aware alignment for entities in tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiuyang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3397271.3401161</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event</title>
		<meeting>the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020-07-25" />
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Yuejia Xiang, and Yefeng Zheng. 2020. An industry evaluation of embedding-based entity alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hualuo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaoyan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-industry.17</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020 -Industry Track</title>
		<meeting>the 28th International Conference on Computational Linguistics, COLING 2020 -Industry Track</meeting>
		<imprint>
			<date type="published" when="2020-12-12" />
			<biblScope unit="page" from="179" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Complex factoid question answering with a free-text knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><forename type="middle">L</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<idno type="DOI">10.1145/3366423.3380197</idno>
	</analytic>
	<monogr>
		<title level="m">WWW &apos;20: The Web Conference 2020</title>
		<meeting><address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-20" />
			<biblScope unit="page" from="1205" to="1216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An experimental study of state-of-the-art entity alignment approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
