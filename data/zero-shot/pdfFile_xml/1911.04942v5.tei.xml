<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
							<email>bailin.wang@ed.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Shin</surname></persName>
							<email>ricshin@cs.berkeley.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
							<email>polozov@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>When translating natural language questions into SQL queries to answer questions from a database, contemporary semantic parsing models struggle to generalize to unseen database schemas. The generalization challenge lies in (a) encoding the database relations in an accessible way for the semantic parser, and (b) modeling alignment between database columns and their mentions in a given query. We present a unified framework, based on the relation-aware self-attention mechanism, to address schema encoding, schema linking, and feature representation within a text-to-SQL encoder. On the challenging Spider dataset this framework boosts the exact match accuracy to 57.2%, surpassing its best counterparts by 8.7% absolute improvement.</p><p>Further augmented with BERT, it achieves the new state-of-the-art performance of 65.6% on the Spider leaderboard. In addition, we observe qualitative improvements in the model's understanding of schema linking and alignment. Our implementation will be open-sourced at https://github.com/Microsoft/rat-sql.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ability to effectively query databases with natural language (NL) unlocks the power of large datasets to the vast majority of users who are not proficient in query languages. As such, a large body of research has focused on the task of translating NL questions into SQL queries that existing database software can execute.</p><p>The development of large annotated datasets of questions and the corresponding SQL queries has catalyzed progress in the field. In contrast to prior semantic parsing datasets (Finegan-Dollak et al., * Equal contribution. Order decided by a coin toss. ? Work done during an internship at Microsoft Research. ? Work done partly affiliated with Microsoft Research. Now at Microsoft: richard.shin@microsoft.com.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2018)</head><p>, new tasks such as WikiSQL <ref type="bibr" target="#b37">(Zhong et al., 2017)</ref> and Spider <ref type="bibr" target="#b34">(Yu et al., 2018b)</ref> pose the reallife challenge of generalization to unseen database schemas. Every query is conditioned on a multitable database schema, and the databases do not overlap between the train and test sets.</p><p>Schema generalization is challenging for three interconnected reasons. First, any text-to-SQL parsing model must encode the schema into representations suitable for decoding a SQL query that might involve the given columns or tables. Second, these representations should encode all the information about the schema such as its column types, foreign key relations, and primary keys used for database joins. Finally, the model must recognize NL used to refer to columns and tables, which might differ from the referential language seen in training. The latter challenge is known as schema linking -aligning entity references in the question to the intended schema columns or tables.</p><p>While the question of schema encoding has been studied in recent literature <ref type="bibr" target="#b1">(Bogin et al., 2019a)</ref>, schema linking has been relatively less explored. Consider the example in <ref type="figure">Figure 1</ref>. It illustrates the challenge of ambiguity in linking: while "model" in the question refers to car_names.model rather than model_list.model, "cars" actually refers to both cars_data and car_names (but not car_makers) for the purpose of table joining. To resolve the column/table references properly, the semantic parser must take into account both the known schema relations (e.g. foreign keys) and the question context.</p><p>Prior work <ref type="bibr" target="#b1">(Bogin et al., 2019a)</ref> addressed the schema representation problem by encoding the directed graph of foreign key relations in the schema with a graph neural network (GNN). While effective, this approach has two important shortcomings. First, it does not contextualize schema encoding with the question, thus making reasoning about For the cars with 4 cylinders, which model has the largest horsepower?  <ref type="figure">Figure 1</ref>: A challenging text-to-SQL task from the Spider dataset. schema linking difficult after both the column representations and question word representations are built. Second, it limits information propagation during schema encoding to the predefined graph of foreign key relations. The advent of self-attentional mechanisms in NLP <ref type="bibr" target="#b28">(Vaswani et al., 2017)</ref> shows that global reasoning is crucial to effective representations of relational structures. However, we would like any global reasoning to still take into account the aforementioned schema relations.</p><p>In this work, we present a unified framework, called RAT-SQL, 1 for encoding relational structure in the database schema and a given question. It uses relation-aware self-attention to combine global reasoning over the schema entities and question words with structured reasoning over predefined schema relations. We then apply RAT-SQL to the problems of schema encoding and schema linking. As a result, we obtain 57.2% exact match accuracy on the Spider test set. At the time of writing, this result is the state of the art among models unaugmented with pretrained BERT embeddings -and further reaches to the overall state of the art (65.6%) when RAT-SQL is augmented with BERT. In addition, we experimentally demonstrate that RAT-SQL enables the model to build more accurate internal representations of the question's true alignment with schema columns and tables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Semantic parsing of NL to SQL recently surged in popularity thanks to the creation of two new multi-table datasets with the challenge of schema generalization -WikiSQL <ref type="bibr" target="#b37">(Zhong et al., 2017)</ref> and Spider <ref type="bibr" target="#b34">(Yu et al., 2018b)</ref>. Schema encoding is not as challenging in WikiSQL as in Spider because it lacks multi-table relations. Schema linking is relevant for both tasks but also more challenging in Spider due to the richer NL expressiveness and less restricted SQL grammar observed in it. The state of the art semantic parser on WikiSQL <ref type="bibr">(He et al.,</ref><ref type="bibr">1</ref> Relation-Aware Transformer. 2019) achieves a test set accuracy of 91.8%, significantly higher than the state of the art on Spider.</p><p>The recent state-of-the-art models evaluated on Spider use various attentional architectures for question/schema encoding and AST-based structural architectures for query decoding. IRNet <ref type="bibr" target="#b9">(Guo et al., 2019)</ref> encodes the question and schema separately with LSTM and self-attention respectively, augmenting them with custom type vectors for schema linking. They further use the AST-based decoder of <ref type="bibr" target="#b32">Yin and Neubig (2017)</ref> to decode a query in an intermediate representation (IR) that exhibits higher-level abstractions than SQL. <ref type="bibr" target="#b1">Bogin et al. (2019a)</ref> encode the schema with a GNN and a similar grammar-based decoder. Both works emphasize schema encoding and schema linking, but design separate featurization techniques to augment word vectors (as opposed to relations between words and columns) to resolve it. In contrast, the RAT-SQL framework provides a unified way to encode arbitrary relational information among inputs.</p><p>Concurrently with this work, <ref type="bibr" target="#b2">Bogin et al. (2019b)</ref> published Global-GNN, a different approach to schema linking for Spider, which applies global reasoning between question words and schema columns/tables. Global reasoning is implemented by gating the GNN that encodes the schema using the question token representations. This differs from RAT-SQL in two important ways: (a) question word representations influence the schema representations but not vice versa, and (b) like in other GNN-based encoders, message propagation is limited to the schema-induced edges such as foreign key relations. In contrast, our relation-aware transformer mechanism allows encoding arbitrary relations between question words and schema elements explicitly, and these representations are computed jointly over all inputs using self-attention.</p><p>We use the same formulation of relation-aware self-attention as <ref type="bibr" target="#b24">Shaw et al. (2018)</ref>. However, they only apply it to sequences of words in the context of machine translation, and as such, their relation types only encode the relative distance between two words. We extend their work and show that relationaware self-attention can effectively encode more complex relationships within an unordered set of elements (in our case, columns and tables within a database schema as well as relations between the schema and the question). To the best of our knowledge, this is the first application of relation-aware self-attention to joint representation learning with both predefined and softly induced relations in the input structure. Hellendoorn et al. (2020) develop a similar model concurrently with this work, where they use relation-aware self-attention to encode data flow structure in source code embeddings. <ref type="bibr" target="#b26">Sun et al. (2018)</ref> use a heterogeneous graph of KB facts and relevant documents for open-domain question answering. The nodes of their graph are analogous to the database schema nodes in RAT-SQL, but RAT-SQL also incorporates the question in the same formalism to enable joint representation learning between the question and the schema.</p><p>3 Relation-Aware Self-Attention First, we introduce relation-aware self-attention, a model for embedding semi-structured input sequences in a way that jointly encodes pre-existing relational structure in the input as well as induced "soft" relations between sequence elements in the same embedding. Our solutions to schema embedding and linking naturally arise as features implemented in this framework.</p><p>Consider a set of inputs X = {x i } n i=1 where x i ? R dx . In general, we consider it an unordered set, although x i may be imbued with positional embeddings to add an explicit ordering relation. A self-attention encoder, or Transformer, introduced by <ref type="bibr" target="#b28">Vaswani et al. (2017)</ref>, is a stack of self-attention layers where each layer (consisting of H heads) transforms each x i into y i ? R dx as follows:</p><formula xml:id="formula_0">e (h) ij = xiW (h) Q (xjW (h) K ) dz/H ; ? (h) ij = softmax j e (h) ij z (h) i = n j=1 ? (h) ij (xjW (h) V ); zi = Concat z (1) i , ? ? ? , z (H) i ?i = LayerNorm(xi + zi) yi = LayerNorm(?i + FC(ReLU(FC(?i)))<label>(1)</label></formula><p>where FC is a fully-connected layer, LayerNorm is layer normalization <ref type="bibr">(Ba et al., 2016)</ref>,</p><formula xml:id="formula_1">1 ? h ? H, and W (h) Q , W (h) K , W<label>(h)</label></formula><p>V ? R dx?(dx/H) . One interpretation of the embeddings computed by a Transformer is that each head of each layer computes a learned relation between all the input elements x i , and the strength of this relation is encoded in the attention weights ? (h) ij . However, in many applications (including text-to-SQL parsing) we are aware of some preexisting relational features between the inputs, and would like to bias our encoder model toward them. This is straightforward for non-relational features (represented directly in each x i ). We could limit the attention computation only to the "hard" edges where the preexisting relations are known to hold. This would make the model similar to a graph attention network <ref type="bibr" target="#b29">(Veli?kovi? et al., 2018)</ref>, and would also impede the Transformer's ability to learn new relations. Instead, RAT provides a way to communicate known relations to the encoder by adding their representations to the attention mechanism. <ref type="bibr" target="#b24">Shaw et al. (2018)</ref> describe a way to represent relative position information in a self-attention layer by changing Equation (1) as follows:</p><formula xml:id="formula_2">e (h) ij = x i W (h) Q (x j W (h) K + r K ij ) d z /H z (h) i = n j=1 ? (h) ij (x j W (h) V + r V ij ).</formula><p>(2)</p><p>Here the r ij terms encode the known relationship between the two elements x i and x j in the input. While Shaw et al. used it exclusively for relative position representation, we show how to use the same framework to effectively bias the Transformer toward arbitrary relational information. Consider R relational features, each a binary relation R (s) ? X ? X (1 ? s ? R). The RAT framework represents all the pre-existing features for each edge (i, j) as</p><formula xml:id="formula_3">r K ij = r V ij = Concat ? (1) ij , . . . , ? (R) ij where each ? (s)</formula><p>ij is either a learned embedding for the relation R (s) if the relation holds for the corresponding edge (i.e. if (i, j) ? R (s) ), or a zero vector of appropriate size. In the following section, we will describe the set of relations our RAT-SQL model uses to encode a given database schema.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RAT-SQL</head><p>We now describe the RAT-SQL framework and its application to the problems of schema encoding and linking. First, we formally define the text-to-SQL semantic parsing problem and its components. In the rest of the section, we present our implementation of schema linking in the RAT framework.</p><p>Type of x Type of y Edge label Description Column Column SAME-TABLE x and y belong to the same table. FOREIGN-KEY-COL-F x is a foreign key for y. FOREIGN-KEY-COL-R y is a foreign key for x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Column</head><p>Table PRIMARY-KEY-F x is the primary key of y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BELONGS-TO-F</head><p>x is a column of y (but not the primary key). <ref type="table">Table  Column</ref> PRIMARY-KEY-R y is the primary key of x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BELONGS-TO-R</head><p>y is a column of x (but not the primary key). <ref type="table">Table  Table   FOREIGN</ref>-KEY-TAB-F <ref type="table">Table x</ref> has a foreign key column in y.</p><p>FOREIGN-KEY-TAB-R Same as above, but x and y are reversed. FOREIGN-KEY-TAB-B x and y have foreign keys in both directions.  <ref type="figure">Figure 2</ref>: An illustration of an example schema as a graph G. We do not depict all the edges and label types of <ref type="table" target="#tab_1">Table 1</ref> to reduce clutter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Problem Definition</head><p>Given a natural language question Q and a schema S = C, T for a relational database, our goal is to generate the corresponding SQL P . Here the question Q = q 1 . . . q |Q| is a sequence of words, and the schema consists of columns C = {c 1 , . . . , c |C| } and tables T = t 1 , . . . , t |T | . Each column name c i contains words c i,1 , . . . , c i,|c i | and each table name t i contains words t i,1 , . . . , t i,|t i | . The desired program P is represented as an abstract syntax tree T in the context-free grammar of SQL. Some columns in the schema are primary keys, used for uniquely indexing the corresponding table, and some are foreign keys, used to reference a primary key column in a different table. In addition, each column has a type ? ? {number, text}.</p><p>Formally, we represent the database schema as a directed graph G = V, E . Its nodes V = C ? T are the columns and tables of the schema, each labeled with the words in its name (for columns, we prepend their type ? to the label). Its edges E are defined by the pre-existing database relations, described in <ref type="table" target="#tab_1">Table 1</ref>. <ref type="figure">Figure 2</ref> illustrates an example graph (with a subset of actual edges and labels).  While G holds all the known information about the schema, it is insufficient for appropriately encoding a previously unseen schema in the context of the question Q. We would like our representations of the schema S and the question Q to be joint, in particular for modeling the alignment between them. Thus, we also define the questioncontextualized schema graph</p><formula xml:id="formula_4">G Q = V Q , E Q where V Q = V ? Q = C ? T ? Q includes nodes</formula><p>for the question words (each labeled with a corresponding word), and E Q = E ? E Q?S are the schema edges E extended with additional special relations between the question words and schema members, detailed in the rest of this section.</p><p>For modeling text-to-SQL generation, we adopt the encoder-decoder framework. Given the input as a graph G Q , the encoder f enc embeds it into joint representations c i , t i , q i for each column c i ? C, table t i ? T , and question word q ? Q respectively. The decoder f dec then uses them to compute a distribution Pr(P | G Q ) over the SQL programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Relation-Aware Input Encoding</head><p>Following the state-of-the-art NLP literature, our encoder first obtains the initial representations c init i , t init i for every node of G by (a) retrieving a pre-trained Glove embedding <ref type="bibr" target="#b22">(Pennington et al., 2014)</ref> for each word, and (b) processing the embeddings in each multi-word label with a bidirectional LSTM (BiLSTM) <ref type="bibr" target="#b12">(Hochreiter and Schmidhuber, 1997)</ref>. It also runs a separate BiLSTM over the question Q to obtain initial word representations q init i . The initial representations c init i , t init i , and q init i are independent of each other and devoid of any relational information known to hold in E Q . To produce joint representations for the entire input graph G Q , we use the relation-aware self-attention mechanism (Section 3). Its input X is the set of all the node representations in G Q :</p><formula xml:id="formula_5">X = (c init 1 , ? ? ? , c init |C| , t init 1 , ? ? ? , t init |T | , q init 1 , ? ? ? , q init |Q| )</formula><p>.</p><p>The encoder f enc applies a stack of N relationaware self-attention layers to X, with separate weight matrices in each layer. The final representations c i , t i , q i produced by the N th layer constitute the output of the whole encoder. Alternatively, we also consider pre-trained BERT <ref type="bibr" target="#b5">(Devlin et al., 2019)</ref> embeddings to obtain the initial representations. Following <ref type="bibr" target="#b13">(Huang et al., 2019;</ref>, we feed X to the BERT and use the last hidden states as the initial representations before proceeding with the RAT layers. <ref type="bibr">2</ref> Importantly, as detailed in Section 3, every RAT layer uses self-attention between all elements of the input graph G Q to compute new contextual representations of question words and schema members. However, this self-attention is biased toward some pre-defined relations using the edge vectors r K ij , r V ij in each layer. We define the set of used relation types in a way that directly addresses the challenges of schema embedding and linking. Occurrences of these relations between the question and the schema constitute the edges E Q?S . Most of these relation types address schema linking (Section 4.3); we also add some auxiliary edges to aid schema encoding (see Appendix A).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Schema Linking</head><p>Schema linking relations in E Q?S aid the model with aligning column/table references in the question to the corresponding schema columns/tables. This alignment is implicitly defined by two kinds of information in the input: matching names and matching values, which we detail in order below. <ref type="bibr">2</ref> In this case, the initial representations c init i , t init i , q init i are not strictly independent although still yet uninfluenced by E. Name-Based Linking Name-based linking refers to exact or partial occurrences of the column/table names in the question, such as the occurrences of "cylinders" and "cars" in the question in <ref type="figure">Figure 1</ref>. Textual matches are the most explicit evidence of question-schema alignment and as such, one might expect them to be directly beneficial to the encoder. However, in all our experiments the representations produced by vanilla self-attention were insensitive to textual matches even though their initial representations were identical. <ref type="bibr" target="#b3">Brunner et al. (2020)</ref> suggest that representations produced by Transformers mix the information from different positions and cease to be directly interpretable after 2+ layers, which might explain our observations. Thus, to remedy this phenomenon, we explicitly encode name-based linking using RAT relations.</p><p>Specifically, for all n-grams of length 1 to 5 in the question, we determine (1) whether it exactly matches the name of a column/table (exact match); or (2) whether the n-gram is a subsequence of the name of a column/table (partial match). 3 Then, for Value-Based Linking Question-schema alignment also occurs when the question mentions any values that occur in the database and consequently participate in the desired SQL, such as "4" in Figure 1. While this example makes the alignment explicit by mentioning the column name "cylinders", many real-world questions do not. Thus, linking a value to the corresponding column requires background knowledge.</p><formula xml:id="formula_6">every (i, j) where x i ? Q, x j ? S (or vice versa), we set r ij ? E Q?S to QUESTION-COLUMN-M, QUESTION-</formula><p>The database itself is the most comprehensive and readily available source of knowledge about possible values, but also the most challenging to process in an end-to-end model because of the privacy and speed impact. However, the RAT framework allows us to outsource this processing to the database engine to augment G Q with potential value-based linking without exposing the model itself to the data. Specifically, we add a new COLUMN-VALUE relation between any word q i and column name c j s.t. q i occurs as a value (or a full word within a value) of c j . This simple approach drastically improves the performance of RAT-SQL (see Section 5). It also directly addresses the aforementioned DB challenges: (a) the model is never exposed to database content that does not occur in the question, (b) word matches are retrieved quickly via DB indices &amp; textual search.</p><p>Memory-Schema Alignment Matrix Our intuition suggests that the columns and tables which occur in the SQL P will generally have a corresponding reference in the natural language question. To capture this intuition in the model, we apply relation-aware attention as a pointer mechanism between every memory element in y and all the columns/tables to compute explicit alignment matrices L col ? R |y|?|C| and L tab ? R |y|?|T | :</p><formula xml:id="formula_7">L col i,j = y i W col Q (c final j W col K + r K ij ) ? d x (3) L tab i,j = y i W tab Q (t final j W tab K + r K ij ) ? d x L col i,j = softmax j L col i,j L tab i,j = softmax j L tab i,j</formula><p>Intuitively, the alignment matrices in Eq.</p><p>(3) should resemble the real discrete alignments, therefore should respect certain constraints like sparsity. When the encoder is sufficiently parameterized, sparsity tends to arise with learning, but we can also encourage it with an explicit objective. Appendix B presents this objective and discusses our experiments with sparse alignment in RAT-SQL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Decoder</head><p>The decoder f dec of RAT-SQL follows the treestructured architecture of <ref type="bibr" target="#b32">Yin and Neubig (2017)</ref>. It generates the SQL P as an abstract syntax tree in depth-first traversal order, by using an LSTM to output a sequence of decoder actions that either (i) expand the last generated node into a grammar rule, called APPLYRULE; or when completing a leaf node, (ii) choose a column/table from the schema, called SELECTCOLUMN and SELECTTABLE.</p><p>Formally,</p><formula xml:id="formula_8">Pr(P | Y) = t Pr(a t | a &lt;t , Y) where Y = f enc (G Q )</formula><p>is the final encoding of the question and schema, and a &lt;t are all the previous actions. In a tree-structured decoder, the LSTM state is updated as m t , h t = f LSTM ([a t?1 z t h pt a pt n ft ], m t?1 , h t?1 ) where m t is the LSTM cell state, h t is the LSTM output at step t, a t?1 is the embedding of the previous action, p t is the step corresponding to </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Column?</head><p>Tree-structured decoder Self-attention layers <ref type="figure">Figure 4</ref>: Choosing a column in a tree decoder.</p><p>expanding the parent AST node of the current node, and n ft is the embedding of the current node type. Finally, z t is the context representation, computed using multi-head attention (with 8 heads) on h t?1 over Y.</p><formula xml:id="formula_9">For APPLYRULE[R], we compute Pr(a t = APPLYRULE[R] | a &lt;t , y) = softmax R (g(h t ))</formula><p>where g(?) is a 2-layer MLP with a tanh nonlinearity. For SELECTCOLUMN, we comput?</p><formula xml:id="formula_10">? i = h t W sc Q (y i W sc K ) T ? d x ? i = softmax i ? i Pr(a t = SELECTCOLUMN[i] | a &lt;t , y) = |y| j=1 ? j L col j,i</formula><p>and similarly for SELECTTABLE. We refer the reader to <ref type="bibr" target="#b32">Yin and Neubig (2017)</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We implemented RAT-SQL in PyTorch <ref type="bibr" target="#b21">(Paszke et al., 2017)</ref>. During preprocessing, the input of questions, column names and table names are tokenized and lemmatized with the StandfordNLP toolkit . Within the encoder, we use GloVe <ref type="bibr" target="#b22">(Pennington et al., 2014)</ref> word embeddings, held fixed in training except for the 50 most common words in the training set. For RAT-SQL BERT, we use the WordPiece tokenization. All word embeddings have dimension 300. The bidirectional LSTMs have hidden size 128 per direction, and use the recurrent dropout method of <ref type="bibr" target="#b8">Gal and Ghahramani (2016)</ref> with rate 0.2. We stack 8 relation-aware self-attention layers on top of the bidirectional LSTMs. Within them, we set d x = d z = 256, H = 8, and use dropout with rate 0.1. The position-wise feed-forward network has inner layer dimension 1024. Inside the decoder, we use rule embeddings of size 128, node type embeddings of size 64, and a hidden size of 512 inside the LSTM with dropout of 0.21.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dev Test</head><p>IRNet <ref type="bibr" target="#b9">(Guo et al., 2019)</ref> 53.2 46.7 Global-GNN <ref type="bibr" target="#b2">(Bogin et al., 2019b)</ref> 52.7 47.4 IRNet V2 <ref type="bibr" target="#b9">(Guo et al., 2019)</ref> 55.4 48.5 RAT-SQL (ours) 62.7 57.2</p><p>With BERT: EditSQL + BERT  57.6 53.4 GNN + Bertrand-DR <ref type="bibr" target="#b16">(Kelkar et al., 2020)</ref> 57.9 54.6 IRNet V2 + BERT <ref type="bibr" target="#b9">(Guo et al., 2019)</ref> 63.9 55.0 RYANSQL V2 + BERT <ref type="bibr" target="#b4">(Choi et al., 2020)</ref>   We used the Adam optimizer (Kingma and <ref type="bibr" target="#b17">Ba, 2015)</ref> with the default hyperparameters. During the first warmup_steps = max_steps/20 steps of training, the learning rate linearly increases from 0 to 7.4?10 ?4 . Afterwards, it is annealed to 0 with formula 10 ?3 (1 ? step?warmup_steps max_steps?warmup_steps ) ?0.5 . We use a batch size of 20 and train for up to 40,000 steps. For RAT-SQL + BERT, we use a separate learning rate of 3?10 ?6 to fine-tune BERT, a batch size of 24 and train for up to 90,000 steps.</p><p>Hyperparameter Search We tuned the batch size <ref type="bibr">(20,</ref><ref type="bibr">50,</ref><ref type="bibr">80)</ref>, number of RAT layers (4, 6, 8), dropout (uniformly sampled from [0.1, 0.3]), hidden size of decoder <ref type="bibr">RNN (256,</ref><ref type="bibr">512)</ref>, max learning rate (log-uniformly sampled from [5 ? 10 ?4 , 2 ? 10 ?3 ]). We randomly sampled 100 configurations and optimized on the dev set. RAT-SQL + BERT reuses most hyperparameters of RAT-SQL, only tuning the BERT learning rate (1 ? 10 ?4 , 3 ? 10 ?4 , 5?10 ?4 ), number of RAT layers (6, 8, 10), number of training steps (4 ? 10 4 , 6 ? 10 4 , 9 ? 10 4 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and Metrics</head><p>We use the Spider dataset <ref type="bibr" target="#b34">(Yu et al., 2018b)</ref> for most of our experiments, and also conduct preliminary experiments on WikiSQL <ref type="bibr" target="#b37">(Zhong et al., 2017)</ref> to confirm generalization to other datasets. As described by <ref type="bibr">Yu et al.,</ref><ref type="bibr">Spider contains 8,</ref><ref type="bibr">659</ref> examples (questions and SQL queries, with the accompanying schemas), including 1,659 examples lifted from the Restaurants <ref type="bibr" target="#b23">(Popescu et al., 2003;</ref><ref type="bibr" target="#b27">Tang and Mooney, 2000)</ref>, GeoQuery (Zelle and Mooney, 1996), Scholar <ref type="bibr" target="#b15">(Iyer et al., 2017)</ref>, Academic <ref type="bibr" target="#b18">(Li and Jagadish, 2014)</ref>, Yelp and IMDB <ref type="bibr" target="#b31">(Yaghmazadeh et al., 2017)</ref> datasets.</p><p>As <ref type="bibr" target="#b34">Yu et al. (2018b)</ref> make the test set accessible only through an evaluation server, we perform   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Spider Results</head><p>In <ref type="table" target="#tab_5">Table 2</ref> we show accuracy on the (hidden) Spider test set for RAT-SQL and compare to all other approaches at or near state-of-the-art (according to the official leaderboard). RAT-SQL outperforms all other methods that are not augmented with BERT embeddings by a large margin of 8.7%. Surprisingly, it even beats other BERT-augmented models. When RAT-SQL is further augmented with BERT, it achieves the new state-of-the-art performance. Compared with other BERT-argumented models, our RAT-SQL + BERT has smaller generalization gap between development and test set. We also provide a breakdown of the accuracy by difficulty in <ref type="table" target="#tab_7">Table 3</ref>. As expected, performance drops with increasing difficulty. The overall generalization gap between development and test of RAT-SQL was strongly affected by the significant drop in accuracy (9%) on the extra hard questions. When RAT-SQL is augmented with BERT, the generalization gaps of most difficulties are reduced. <ref type="table" target="#tab_8">Table 4</ref> shows an ablation study over different RAT-based relations. The ablations are run on RAT-SQL without value-based linking to avoid interference with information from the database. Schema linking and graph relations make statistically significant improvements (p&lt;0.001). The full model accuracy here slightly differs from <ref type="table" target="#tab_5">Table 2</ref> because the latter shows the best model from a hyper-parameter sweep (used for test evaluation) and the former gives the mean over five runs where we only change the random seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">WikiSQL Results</head><p>We also conducted preliminary experiments on WikiSQL <ref type="bibr" target="#b37">(Zhong et al., 2017)</ref> to test generalization of RAT-SQL to new datasets. Although WikiSQL lacks multi-table schemas (and thus, its challenge of schema encoding is not as prominent), it still presents the challenges of schema linking and generalization to new schemas. For simplicity of experiments, we did not implement either BERT augmentation or execution-guided decoding (EG) , both of which are common in state-ofthe-art WikiSQL models. We thus only compare to the models that also lack these two enhancements.</p><p>While not reaching state of the art, RAT-SQL still achieves competitive performance on WikiSQL as shown in <ref type="table" target="#tab_10">Table 5</ref>. Most of the gap between its accuracy and state of the art is due to the simplified implementation of value decoding, which is required for WikiSQL evaluation but not in Spider. Our value decoding for these experiments is a simple token-based pointer mechanism, which often fails to retrieve multi-token value constants accurately. A robust value decoding mechanism in RAT-SQL is an important extension that we plan to address outside the scope of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Discussions</head><p>Alignment Recall from Section 4 that we explicitly model the alignment matrix between question words and table columns, used during decoding for column and table selection. The existence of the alignment matrix provides a mechanism for the model to align words to columns. An accurate alignment representation has other benefits such as identifying question words to copy to emit a constant value in SQL.</p><p>In <ref type="figure" target="#fig_3">Figure 5</ref> we show the alignment generated by our model on the example from <ref type="figure">Figure 1</ref>. 4 For the three words that reference columns ("cylinders", "model", "horsepower"), the alignment matrix correctly identifies their corresponding columns. The alignments of other words are strongly affected by these three keywords, resulting in a sparse span-tocolumn like alignment, e.g. "largest horsepower" to horsepower. The tables cars_data and cars_names are implicitly mentioned by the word "cars". The alignment matrix successfully infers to use these two tables instead of car_makers using the evidence that they contain the three mentioned columns.</p><p>The Need for Schema Linking One natural question is how often does the decoder fail to select the correct column, even with the schema encoding and linking improvements we have made. To  <ref type="bibr" target="#b6">(Dong and Lapata, 2018)</ref> 72.5 79.0 71.7 78.5 PT-MAML  63.1 68.3 62.8 68.0  <ref type="table">Table 6</ref>: Accuracy (exact match %) on the development set given an oracle providing correct columns and tables ("Oracle columns") and/or the AST sketch structure ("Oracle sketch"). answer this, we conducted an oracle experiment (see <ref type="table">Table 6</ref>). For "oracle sketch", at every grammar nonterminal the decoder is forced to choose the correct production so the final SQL sketch exactly matches that of the ground truth. The rest of the decoding proceeds conditioned on that choice. Likewise, "oracle columns" forces the decoder to emit the correct column/table at terminal nodes.</p><p>With both oracles, we see an accuracy of 99.4% which just verifies that our grammar is sufficient to answer nearly every question in the data set. With just "oracle sketch", the accuracy is only 73.0%, which means 72.4% of the questions that RAT-SQL gets wrong and could get right have incorrect column or table selection. Similarly, with just "oracle columns", the accuracy is 69.8%, which means that 81.0% of the questions that RAT-SQL gets wrong have incorrect structure. In other words, most questions have both column and structure wrong, so both problems require important future work.</p><p>Error Analysis An analysis of mispredicted SQL queries in the Spider dev set showed three main causes of evaluation errors. (I) 18% of the mispredicted queries are in fact equivalent implementations of the NL intent with a different SQL syntax (e.g. ORDER BY C LIMIT 1 vs. SELECT MIN(C)). Measuring execution accuracy rather than exact match would detect them as valid. (II) 39% of errors involve a wrong, missing, or extraneous column in the SELECT clause. This is a limitation of our schema linking mechanism, which, while substantially improving column resolution, still struggles with some ambiguous references. Some of them are unavoidable as Spider questions do not always specify which columns should be returned by the desired SQL. Finally, (III) 29% of errors are missing a WHERE clause, which is a common error class in text-to-SQL models as reported by prior works. One common example is domain-specific phrasing such as "older than 21", which requires background knowledge to map it to age &gt; 21 rather than age &lt; 21. Such errors disappear after in-domain fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Despite active research in text-to-SQL parsing, many contemporary models struggle to learn good representations for a given database schema as well as to properly link column/table references in the question. These problems are related: to encode &amp; use columns/tables from the schema, the model must reason about their role in the context of the question. In this work, we present a unified framework for addressing the schema encoding and linking challenges. Thanks to relation-aware self-attention, it jointly learns schema and question representations based on their alignment with each other and schema relations.</p><p>Empirically, the RAT framework allows us to gain significant state of the art improvement on text-to-SQL parsing. Qualitatively, it provides a way to combine predefined hard schema relations and inferred soft self-attended relations in the same encoder architecture. This representation learning will be beneficial in tasks beyond text-to-SQL, as long as the input has some predefined structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Auxiliary Relations for Schema Encoding</head><p>In addition to the schema graph edges E (Section 4.2) and schema linking edges (Section 4.3), the edges in E Q also include some auxiliary relation types to aid the relation-aware self-attention. Specifically, for each x i , x j ? V Q :</p><p>? If i = j, then COLUMN-IDENTITY or TABLE-IDENTITY.</p><p>?</p><formula xml:id="formula_11">x i ? Q, x j ? Q: QUESTION-DIST-d, where d = clip(j ? i, D),</formula><p>clip(a, D) = max(?D, min(D, a)).</p><p>We use D = 2.</p><p>? Otherwise, one of COLUMN-COLUMN, COLUMN <ref type="table" target="#tab_3">-TABLE, TABLE-COLUMN, or  TABLE-TABLE.</ref> B Alignment Loss</p><p>The memory-schema alignment matrix is expected to resemble the real discrete alignments, therefore should respect certain constraints like sparsity. For example, the question word "model" in <ref type="figure">Figure 1</ref> should be aligned with car_names.model rather than model_list.model or model_list.model_id.</p><p>To further bias the soft alignment towards the real discrete structures, we add an auxiliary loss to encourage sparsity of the alignment matrix. Specifically, for a column/table that is mentioned in the SQL query, we treat the model's current belief of the best alignment as the ground truth. Then we use a cross-entropy loss, referred as alignment loss, to strengthen the model's belief:</p><formula xml:id="formula_12">align_loss = ? 1 |Rel(C)| j?Rel(C) log max i L col i,j ? 1 |Rel(T )| j?Rel(T ) log max i L tab i,j</formula><p>where Rel(C) and Rel(T ) denote the set of relevant columns and tables that appear in the SQL.</p><p>In earlier experiments, we found that the alignment loss did improve the model (statistically significantly, from 53.0% to 55.4%). However, it does not make a statistically significant difference in our final model in terms of overall exact match. We hypothesize that hyperparameter tuning that caused us  to increase encoding depth eliminated the need for explicit supervision of alignment. With few layers in the Transformer, the alignment matrix provided additional degrees of freedom, which became unnecessary once the Transformer was sufficiently deep to build a rich joint representation of the question and the schema.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Consistency of RAT-SQL</head><p>In Spider dataset, most SQL queries correspond to more than one question, making it possible to evaluate the consistency of RAT-SQL given paraphrases. We use two metrics to evaluate the consistency: 1) Exact Match -whether RAT-SQL produces the exact same predictions given paraphrases, 2) Correctness -whether RAT-SQL achieves the same correctness given paraphrases. The analysis is conducted on the development set.</p><p>The results are shown in <ref type="table" target="#tab_12">Table 7</ref>. We found that when augmented with BERT, RAT-SQL becomes more consistent in terms of both metrics, indicating the pre-trained representations of BERT are beneficial for handling paraphrases.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Alignment between the question "For the cars with 4 cylinders, which model has the largest horsepower" and the database car_1 schema (columns and tables) depicted inFigure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>SELECT T1.model FROM car_names AS T1 JOIN cars_data AS T2 ON T1.make_id = T2.id WHERE T2.cylinders = 4 ORDER BY T2.horsepower DESC LIMIT 1 Question ? Column linking (unknown) Question ? Table linking (unknown) Column ? Column foreign keys (known)</figDesc><table><row><cell>Desired SQL:</cell></row><row><cell>Schema:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Description of edge types present in the directed graph G created to represent the schema. An edge exists from source node x ? S to target node y ? S if the pair fulfills one of the descriptions listed in the table, with the corresponding label. Otherwise, no edge exists from x to y.</figDesc><table><row><cell></cell><cell>airports</cell><cell>country abbrev</cell><cell cols="2">airline id airline name</cell></row><row><cell>city</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">primary key</cell><cell></cell><cell>primary key</cell></row><row><cell>airport code</cell><cell>airport name</cell><cell>country</cell><cell></cell></row><row><cell cols="2">foreign key</cell><cell></cell><cell></cell><cell>airlines</cell></row><row><cell>foreign key</cell><cell>flights</cell><cell></cell><cell></cell></row><row><cell>source airport</cell><cell></cell><cell>dest airport</cell><cell></cell></row><row><cell cols="2">primary key primary key</cell><cell></cell><cell></cell></row><row><cell>airline</cell><cell></cell><cell>flight number</cell><cell>abbreviation</cell><cell>country</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE - M</head><label>-</label><figDesc>, COLUMN-QUESTION-M or TABLE-QUESTION-M depending on the type of x i and x j . Here M is one of EXACTMATCH, PAR-TIALMATCH, or NOMATCH.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Accuracy on the Spider development and test sets, compared to the other approaches at the top of the dataset leaderboard as of May 1st, 2020. The test set results were scored using the Spider evaluation server.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Accuracy on the Spider development and test sets, by difficulty as defined by<ref type="bibr" target="#b34">Yu et al. (2018b)</ref>.</figDesc><table><row><cell>Model</cell><cell>Accuracy (%)</cell></row><row><cell>RAT-SQL + value-based linking</cell><cell>60.54 ? 0.80</cell></row><row><cell>RAT-SQL</cell><cell>55.13 ? 0.84</cell></row><row><cell>w/o schema linking relations</cell><cell>40.37 ? 2.32</cell></row><row><cell>w/o schema graph relations</cell><cell>35.59 ? 0.85</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: Accuracy (and ?95% confidence interval) of</cell></row><row><cell>RAT-SQL ablations on the dev set.</cell></row><row><cell>most evaluations (other than the final accuracy mea-</cell></row><row><cell>surement) using the development set. It contains</cell></row><row><cell>1,034 examples, with databases and schemas dis-</cell></row><row><cell>tinct from those in the training set. We report re-</cell></row><row><cell>sults using the same metrics as Yu et al. (2018a):</cell></row><row><cell>exact match accuracy on all examples, as well as</cell></row><row><cell>divided by difficulty levels. As in previous work on</cell></row><row><cell>Spider, these metrics do not measure the model's</cell></row><row><cell>performance on generating values in the SQL.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5 :</head><label>5</label><figDesc>RAT-SQL accuracy on WikiSQL, trained without BERT augmentation or execution-guided decoding (EG). Compared to other approaches without EG. "LF Acc" = Logical Form Accuracy; "Ex. Acc" = Execution Accuracy.</figDesc><table><row><cell>Model</cell><cell>Acc.</cell></row><row><cell>RAT-SQL</cell><cell>62.7</cell></row><row><cell>RAT-SQL + Oracle columns</cell><cell>69.8</cell></row><row><cell>RAT-SQL + Oracle sketch</cell><cell>73.0</cell></row><row><cell cols="2">RAT-SQL + Oracle sketch + Oracle columns 99.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>Consistency of the two RAT-SQL models.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">This procedure matches that of<ref type="bibr" target="#b9">Guo et al. (2019)</ref>, but we use the matching information differently in RAT.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The full alignment also maps from column and table names, but those end up simply aligning to themselves or the table they belong to, so we omit them for brevity.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Jianfeng Gao, Vladlen Koltun, Chris Meek, and Vignesh Shiv for the discussions that helped shape this work. We thank Bo Pang, Tao Yu for their help with the evaluation. We also thank anonymous reviewers for their invaluable feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint/>
	</monogr>
	<note type="report_type">Hinton. 2016. Layer Normalization.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Representing schema structure with graph neural networks for text-to-SQL parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1448</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4560" to="4565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Global reasoning over database structures for textto-SQL parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1378</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3657" to="3662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On identifiability in Transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gino</forename><surname>Brunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damian</forename><surname>Pascual</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Wattenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">RYANSQL: Recursively applying sketch-based slot fillings for complex text-to-SQL in cross-domain databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeong Cheol</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunggyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong Ryeol</forename><surname>Shin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.03125</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Coarse-to-fine decoding for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1068</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="731" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving Text-to-SQL Evaluation Methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Finegan-Dollak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sesh</forename><surname>Sadasivam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="351" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1019" to="1027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Towards complex text-to-SQL in crossdomain database with intermediate representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zecheng</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1444</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4524" to="4535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaushik</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.08113</idno>
		<title level="m">SQL: reinforce schema representation with context</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Global relational models of source code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Hellendoorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petros</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Maniatis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Music Transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Zhi Anna</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Curtis</forename><surname>Hawthorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><surname>Dinculescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Eck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Natural language to structured query generation via meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="732" to="738" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning a neural semantic parser from user feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="963" to="973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amol</forename><surname>Kelkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Relan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishali</forename><surname>Bhardwaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Vaichal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Relan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.00557</idno>
		<title level="m">Bertrand-DR: Improving text-to-SQL using a discriminative re-ranker</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Constructing an interactive natural language interface for relational databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<idno type="DOI">10.14778/2735461.2735468</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="73" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mc-Closky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL) System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The natural language decathlon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.08730</idno>
	</analytic>
	<monogr>
		<title level="m">Multitask learning as question answering</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards a theory of natural language interfaces to databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana-Maria</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Kautz</surname></persName>
		</author>
		<idno type="DOI">http:/doi.acm.org/10.1145/604045.604070</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Intelligent User Interfaces</title>
		<meeting>the 8th International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="149" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Self-Attention with Relative Position Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2074</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="464" to="468" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kedar</forename><surname>Tatwawadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaushik</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05054</idno>
		<title level="m">IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic Oracles</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Open domain question answering using early fusion of knowledge bases and text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathryn</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4231" to="4242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automated construction of database interfaces: Intergrating statistical and relational learning for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lappoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2000 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="133" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Graph Attention Networks. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kedar</forename><surname>Tatwawadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03100</idno>
		<title level="m">Robust Text-to-SQL Generation with Execution-Guided Decoding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sqlizer: Query synthesis from natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navid</forename><surname>Yaghmazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuepeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isil</forename><surname>Dillig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dillig</surname></persName>
		</author>
		<idno type="DOI">10.1145/3133887</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Object-Oriented Programming, Systems, Languages, and Applications</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A Syntactic Neural Model for General-Purpose Code Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1041</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="440" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">SyntaxSQLNet: Syntax Tree Networks for Complex and Cross-Domain Text-to-SQL Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1653" to="1663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingning</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanelle</forename><surname>Roman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3911" to="3921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth National Conference on Artificial Intelligence</title>
		<meeting>the Thirteenth National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Editing-based SQL query generation for cross-domain context-dependent questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungrok</forename><surname>Er</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.00103</idno>
		<title level="m">Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
