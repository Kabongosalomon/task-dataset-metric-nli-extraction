<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-directional Feature Fusion Network for Building Damage Assessment from Satellite Imagery</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Shen</surname></persName>
							<email>shenyu@njust.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of North Carolina at Charlotte</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Nanjing University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijie</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of North Carolina at Charlotte</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taojiannan</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of North Carolina at Charlotte</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
							<email>chen.chen@uncc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of North Carolina at Charlotte</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-directional Feature Fusion Network for Building Damage Assessment from Satellite Imagery</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fast and effective responses are required when a natural disaster (e.g., earthquake, hurricane, etc.) strikes. Building damage assessment from satellite imagery is critical before an effective response is conducted. High-resolution satellite images provide rich information with pre-and post-disaster scenes for analysis. However, most existing works simply use pre-and post-disaster images as input without considering their correlations. In this paper, we propose a novel cross-directional fusion strategy to better explore the correlations between pre-and post-disaster images. Moreover, the data augmentation method CutMix is exploited to tackle the challenge of hard classes. The proposed method achieves state-of-the-art performance on a large-scale building damage assessment dataset -xBD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural disasters, such as earthquakes, floods and tsunami, cause serious social and economic devastation. When a natural disaster strikes, accurate and immediate responses are required in Humanitarian Assistance and Disaster Response (HADR) for saving thousands of lives <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Before these responses, rescue planning and preparations are conducted based on the damage analysis <ref type="bibr" target="#b2">[3]</ref>. With the rapid development of remote sensing technology, high resolution satellite images are now available for damage analysis. Traditionally, these images of disaster areas are analyzed by experts, which might be time-consuming if the areas are large. Therefore, automatic information extraction from satellite images, such as building segmentation and damage assessment, is imperative under time-critical situations.</p><p>Building damage assessment plays a pivotal role in HADR, which aims at predicting the building damage level for each pixel based on building segmentation. With a pair of pre-and post-disaster images, the extent of the damage to buildings can be learned by machine learning algorithms. Recently, deep learning-based methods have shown their effectiveness in building damage assessment. Xu et al. [4]  investigated the capability of convolutional neural networks (CNN) for building damage detection by identifying damaged and undamaged buildings. To evaluate the damage levels more precisely, Weber et al.</p><p>[5] considered building damage assessment as a semantic segmentation task.</p><p>With a pair of pre-and post-disaster images for building damage assessment, a key question would be how to effectively model the correlations between these images? Unfortunately, there are only a few works have explored this direction. Hao et al. [6]  simply concatenated the features from preand post-disaster images and fed them into non-local attention modules. Gupta et al. [7]  developed a framework that uses the difference of pre-and post-disaster features as input of a network.</p><p>Another challenge of building damage assessment from satellite imagery lies in the visual similarity between certain classes (e.g., no damage and minor damage). These classes are considered as hard classes. To better explain this problem, we use the xBD [8] dataset, which is the largest dataset for building damage assessment to date, as an example. <ref type="figure">Fig. 1</ref> shows a pair of images from this dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Based on the visual observation, it is difficult to distinguish between classes such as no damage and minor damage due to high visual similarities. To further verify this observation, <ref type="table" target="#tab_0">Table 1</ref> reports the classification results of baseline method (ResNet-50) on xBD. From the classification confusion matrix, about 24.2% of minor damage are mis-classified as no damage. One effective strategy to cope with hard classes and improve the model performance is data augmentation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. Data augmentation has been widely used as a pre-processing technique to artificially increase the size of dataset in segmentation tasks <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>. Recently, CutMix <ref type="bibr" target="#b13">[14]</ref> is proposed as a new data augmentation technique, which generates a new image by combining two image samples, to enhance the generalization ability of neural networks. CutMix directly cuts and pastes image patches from one image to another, which can be easily used in segmentation tasks. Motivated by the above observations, we introduce a twostage U-Net <ref type="bibr" target="#b14">[15]</ref> based framework that integrates preand post-disaster features for building damage assessment. First, a single U-Net is used for building segmentation. Then a two-branch U-Net is applied for damage assessment using the weights from building segmentation for fine tuning. In the network, a cross-directional fusion model is proposed to explore the correlations between features from pre-and post-disaster images. By leveraging channel-wise and spatial-wise correlations, the fused features can be further enhanced. Moreover, to tackle the hard classes problem, CutMix is employed for data augmentation. Specifically, we only apply CutMix to hard classes to make the network pay more attention to those classes, thereby learning more robust representations for hard classes. In the experiments, we show that this strategy yields superior classification performance over simply adopting CutMix for all classes.</p><p>In summary, this work makes two key contributions. (1) We present a new framework that integrates pre-and post-disaster images for building damage assessment. The proposed cross-directional fusion model effectively aggregates the feature representations from two images. <ref type="bibr" target="#b1">(2)</ref> We unveil the challenge of hard classes in building damage assessment and explore a data augmentation strategy CutMix to address this problem. The proposed framework achieves state-of-the-art performance on a large-scale building damage assessment benchmark -xBD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Method</head><p>Overview. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>(a), the whole framework consists of two stages: building segmentation (stage 1) and damage assessment (stage 2). In stage 1, a single U-Net branch (i.e., the upper one) is used for building segmentation. This U-Net branch uses only pre-disaster images as input and produces segmentation masks of building objects. In stage 2, the pre-and post-disaster images are fed into the two network branches separately. The weights are shared in the two-branch U-Net to reduce the computational cost. The network weights from stage 1 are used as initialization for network fine tuning in stage 2. To further enhance the feature representations, a cross-directional fusion model and CutMix data augmentation are utilized in the proposed framework.</p><p>Cross-directional fusion model. To further explore the correlations between pre-and post-disaster features, the proposed cross-directional fusion (CDF) model is added in the framework. Inspired by the squeeze and excitation (SE) block <ref type="bibr" target="#b15">[16]</ref>, the proposed CDF model focuses on recalibrating features from channel and spatial dimensions. Moreover, the channel and spatial information from pre-and post-disaster features is aggregated together in a cross manner and then embedded in the network respectively. The model details are depicted in <ref type="figure" target="#fig_1">Fig. 2(b)</ref>. Let U pre ? R C?H?W and U post ? R C?H?W be the feature maps obtained from the two branches of U-Net respectively, the channel information can be extracted by where [U pre , U post ] denotes the concatenation of feature maps, P (?) represents the global average pooling, ?(?) is the sigmoid function and I cha is a feature vector of C channels after dimension reduction from 2C. Then the new features from two branches can be formulated as</p><formula xml:id="formula_0">I cha = ?(P ([U pre , U post ])),<label>(1)</label></formula><formula xml:id="formula_1">U cha pre = I cha * U post + U pre and U cha post = I cha * U pre + U post ,<label>(2)</label></formula><p>where * denote the channel-wise multiplication between the input feature maps and vector I cha . The output of channel feature fusion are then used in the spatial feature fusion. We concatenate U cha pre and U cha post and feed them into a 1 ? 1 convolution P conv as follows</p><formula xml:id="formula_2">I spa = ?(P conv ([U cha pre , U cha post ])),<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">P conv ([U cha pre , U cha post ]) ? R 1?H?W .</formula><p>Then the output features are</p><formula xml:id="formula_4">U spa pre = I spa ? U cha post + U pre and U spa post = I spa ? U cha pre + U post ,<label>(4)</label></formula><p>where I spa ? U cha post and I spa ? U cha pre denote the spatial-wise multiplication. As a result, channel and spatial information from pre-and post-disaster branches are effectively aggregated in the crossdirectional fusion model. The proposed fusion model consists of only simple convolution and matrix operations, which is easy to implement and integrate with existing CNN architectures.</p><p>Data augmentation with CutMix. As discussed in Sec. 1, there are several damage levels that are difficult to distinguish from each other due to object visual similarities in satellite images. To address this challenge, we leverage the CutMix data augmentation scheme to increase the sample sizes of hard classes, hoping to build better feature representations for these classes. Specifically, image patches are cut from samples that contain hard classes (i.e., minor and major damage classes for the xBD dataset based on the results in <ref type="table" target="#tab_0">Table 1</ref>), and then pasted into any random sample images. The CutMix procedure is illustrated in <ref type="figure" target="#fig_2">Fig. 3</ref>. Let {X pre A , X post A } ? R c?H?W and Y A ? R H?W be a randomly selected training sample (an image pair) and label, (X pre B , X post B , Y B ) be a randomly selected sample from hard classes, where c is the channel number of images. Then the CutMix operation in this task can be defined asX</p><formula xml:id="formula_5">pre = M X pre A + (1 ? M ) X pre B , X post = M X post A + (1 ? M ) X post B , Y = M Y A + (1 ? M ) Y B ,<label>(5)</label></formula><p>where M ? {0, 1} W ?H denotes a binary mask indicating where to cut out and fill in from two image samples, is an element-wise multiplication, and (X pre ,X post ,? ) represents the generated new sample. With the increased sample sizes of hard classes using CutMix, the network is forced to pay more attention to these classes and learn more robust representations for them. Dataset description. The xBD dataset is a large-scale public dataset of satellite images for building segmentation and damage assessment <ref type="bibr" target="#b7">[8]</ref>. It covers a variety of disasters (such as hurricanes, floods, wildfire and earthquakes) and locations with more than 800,000 building annotations across the world. The dataset consists of image pairs (pre-and post-disaster) with a size of 1024 ? 1024 pixels. The damage assessment contains 4 levels, including no damage, minor damage, major damage and destroyed. The training and testing sets are listed in <ref type="table" target="#tab_1">Table 2</ref>. It is worth mentioning that the data is imbalanced and the damage level is highly skewed toward "no damage". The number of each damage level's polygons is reported in <ref type="table" target="#tab_2">Table 3</ref>. All experiments are evaluated on xBD dataset with metric F 1 b for building segmentation, which is defined as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><formula xml:id="formula_6">F 1 b = 2T P 2T P + F P + F N ,<label>(6)</label></formula><p>where T P , F P and F N are the number of true-positive, false-positive and false-negative pixels of segmentation results. The F 1 d metric for damage assessment is in a similar manner with F 1 b . The overall score F 1 s of building segmentation and damage assessment is defined as:</p><formula xml:id="formula_7">F 1 s = 0.3 ? F 1 b + 0.7 ? F 1 d .<label>(7)</label></formula><p>Implementation details. We use Pytorch framework to build the networks. All experiments are conducted on a machine with an Intel i9-9920X CPU and two NVIDIA TITAN-V GPUs. All images are cropped to a size of 512 ? 512 pixels for training. Apart from CutMix, basic data augmentation is used, such as flip and rotation. The cross-entropy loss is used for both building segmentation and damage assessment. The optimization method is Adam. In the building segmentation stage, the learning rate is 0.00015 and the number of epoch is 120. In the building damage assessment stage, the learning rate is 0.0002 and the number of epoch is 20. Results analysis. To validate the effectiveness of the proposed framework, we employ state-of-the-art methods for comparison on xBD. All the models adopt Res50 as backbone. A Res50 baseline without cross-directional fusion and CutMix is also used for comparison. As shown in <ref type="table" target="#tab_3">Table 4</ref>, the proposed framework using the vanilla U-Net structure alone (i.e., Res50 (baseline)) is able to outperform the existing methods in terms of all three metrics. With the proposed cross-directional fusion model and CutMix data augmentation, it further improves the accuracy for damage assessment (0.778 vs. 0.757 in F 1 d ), and the improvement is consistent for all the damage levels. Several visual examples of building segmentation and damage assessment results of our method are presented in the Appendix. We also compare the parameter size and computational cost (FLOP) between the proposed method and the baseline. As shown in <ref type="table" target="#tab_4">Table 5</ref>, although the cross-directional fusion model is added in the network, it brings less than 1M additional parameters. And this results in only slight increase in computational cost (107.6 vs. 92.9 GFLOPs). Ablation study. To investigate the contribution of cross-directional fusion model and CutMix data augmentation, we perform ablation studies on these two components. From <ref type="table" target="#tab_5">Table 6</ref>, we can observe that the cross-directional fusion model brings 0.6% (0.789 vs. 0.795 in F 1 s ) improvement compared with the baseline. Moreover, the CutMix strategy on hard classes boosts the overall performance (F 1 s ) by 1.3%, which is a considerable gain. In particular, the accuracy of minor damage class is improved by 2.7% (0.578 vs. 0.605) with CutMix. For the xBD dataset, minor damage and major damage are the most difficult classes based on the results in <ref type="table" target="#tab_5">Table 6</ref>. Therefore, in our proposed method, CutMix data augmentation is mainly focused on these two damage levels to generate more training samples for them. We further conduct experiments to investigate the influence of CutMix on different damage levels. <ref type="table" target="#tab_6">Table 7</ref> reports the overall scores when CutMix is applied on different damage levels. We can clearly observe that there is barely any improvement when CutMix is used on the entire dataset (i.e., considering all classes). In contrast, a significant improvement is achieved when only minor and major damage levels are considered in the data augmentation. This hard-class biased data augmentation strategy facilitates the network to learn better representations for those classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we propose a two-stage U-Net framework that integrates cross-directional fusion model for building damage assessment. In the fusion model, channel and spatial information from preand post-disaster image features is aggregated and embedded in the network, which enables the network to learn feature representations more effectively. Moreover, a data augmentation strategy CutMix is used to mitigate the challenge of hard classes. Experimental results show that significant improvements can be achieved when CutMix is applied on hard damage levels. The proposed method also yields state-of-the-art building damage assessment performance on the xBD dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Visual Examples</head><p>Figures 4-7 provide visual comparisons of the building damage assessment results of our proposed method and the baseline for different disasters. We can observe that our proposed framework achieves better performance in damage level assessment. For example, in <ref type="figure">Figure 4</ref>, some regions of major damage (orange color) and no damage (green color) are mis-classified as destroyed (red color) and minor damage (yellow color) respectively by the baseline, while our proposed method yields much less mis-classification and produces a segmentation map that is very close to the ground-truth.</p><p>(e) pre and post-disaster (f) ground-truth (g) baseline (h) ours </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A pair of images and their annotations from the xBD dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>(a) Overall framework of the proposed method. In the building segmentation stage, only pre-disaster images and the upper U-Net branch are used. In the damage assessment stage, pre-and post disaster images are fed into the two network branches separately. (b) Architecture of the cross-directional fusion model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Data augmentation with CutMix for hard classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :Figure 5 :Figure 6 :Figure 7 :</head><label>4567</label><figDesc>A visual comparison of results of the baseline and the proposed method over a hurricane disaster image. A visual comparison of results of the baseline and the proposed method over a hurricane disaster image. (e) pre and post-disaster (f) ground-truth (g) baseline (h) ours A visual comparison of results of the baseline and the proposed method over a tsunami disaster image. (e) pre and post-disaster (f) ground-truth (g) baseline (h) ours A visual comparison of results of the baseline and the proposed method over a wildfire disaster image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Classification confusion matrix (%) of ResNet-50 baseline on xBD test set.</figDesc><table><row><cell>Damage Level C0 C1 C2 C3 C4</cell></row><row><cell>Background (C0) 98.6 0.9 0.2 0.2 0.1 No damage (C1) 7.1 88.7 3.2 0.8 0.1 Minor Damage (C2) 6.3 24.2 60.0 9.2 0.4 Major Damage (C3) 3.0 6.6 14.9 73.1 2.4 Destroyed (C4) 5.5 2.4 1.2 8.9 82.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>xBD dataset splits and annotation numbers.</figDesc><table><row><cell cols="3">Split Image No. Polygons No.</cell></row><row><cell cols="2">Train 18336</cell><cell>632228</cell></row><row><cell>Test</cell><cell>1866</cell><cell>109724</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Damage level annotations.</figDesc><table><row><cell>No damage Minor Major Destroyed</cell></row><row><cell>No. 313003 36860 29904 31560</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Building segmentation and damage assessment performance comparison on xBD dataset.</figDesc><table><row><cell></cell><cell>F 1s (overall)</cell><cell>F 1 b</cell><cell>F 1 d</cell><cell cols="4">No damage Minor Major Destroyed</cell></row><row><cell>Gupta et al. [7]</cell><cell>0.741</cell><cell cols="2">0.835 0.697</cell><cell>0.906</cell><cell>0.493</cell><cell>0.722</cell><cell>0.837</cell></row><row><cell>Weber et al. [5]</cell><cell>0.770</cell><cell cols="2">0.840 0.740</cell><cell>0.885</cell><cell>0.563</cell><cell>0.771</cell><cell>0.808</cell></row><row><cell>Res50 (baseline)</cell><cell>0.789</cell><cell cols="2">0.864 0.757</cell><cell>0.923</cell><cell>0.578</cell><cell>0.760</cell><cell>0.869</cell></row><row><cell>Res50 (ours)</cell><cell>0.804</cell><cell cols="2">0.864 0.778</cell><cell>0.927</cell><cell>0.610</cell><cell>0.781</cell><cell>0.873</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table><row><cell cols="2">Parameters (M) and FLOPs (G)</cell></row><row><cell cols="2">of our method and baseline.</cell></row><row><cell>Method</cell><cell>Params FLOPs</cell></row><row><cell cols="2">Res50 (baseline) 32.5 Ours 33.1 107.6 92.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Ablation study on cross-directional fusion and CutMix.</figDesc><table><row><cell>Method</cell><cell cols="3">F 1s F 1 b F 1 d No damage Minor Major Destroyed</cell></row><row><cell cols="2">Res50 (baseline) 0.789 0.864 0.757</cell><cell>0.923</cell><cell>0.578 0.760 0.869</cell></row><row><cell cols="2">Ours w/o CutMix 0.795 0.864 0.765</cell><cell>0.923</cell><cell>0.592 0.769 0.871</cell></row><row><cell cols="2">Ours w/o Fusion 0.802 0.864 0.775</cell><cell>0.926</cell><cell>0.605 0.779 0.872</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Ablation study of CutMix on different classes.</figDesc><table><row><cell cols="2">Backbone No damage Minor Major Destroyed F 1s</cell></row><row><cell>Res50</cell><cell>0.789</cell></row><row><cell>Res50</cell><cell>0.790</cell></row><row><cell>Res50</cell><cell>0.797</cell></row><row><cell>Res50</cell><cell>0.802</cell></row><row><cell>Res50</cell><cell>0.795</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Sidrane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Fitzpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Annex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Diane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Donoghue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bili?ski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.06521</idno>
		<title level="m">Machine learning for generalizable prediction of flood susceptibility</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Firenet: Real-time segmentation of fire perimeter from aerial video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jigar</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominic</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Massey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Llueca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Borensztein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Baird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devaki</forename><surname>Raj</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.06407</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Detecting natural disasters, damage, and incidents in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuria</forename><surname>Marzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aritro</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferda</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ofli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Imran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torralba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.09188</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Building damage detection in satellite imagery using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zebo</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valeriya</forename><surname>Khaitan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaytseva</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.06444</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Building disaster damage assessment in satellite imagery with multi-temporal fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Kan?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05525</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiang</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriram</forename><surname>Baireddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">R</forename><surname>Bartusiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Latisha</forename><surname>Konz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Latourette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gribbons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moses</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">L</forename><surname>Comer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">J</forename><surname>Delp</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.06643</idno>
		<title level="m">An attention-based system for damage assessment using satellite imagery</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.07312</idno>
		<title level="m">Rescuenet: Joint building segmentation and damage assessment from satellite imagery</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritwik</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Hosfelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Sajeev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nirav</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryce</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jigar</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Heim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Howie</forename><surname>Choset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Gaston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09296</idno>
		<title level="m">A dataset for assessing building damage from satellite imagery</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A survey on image data augmentation for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Connor</forename><surname>Shorten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">60</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Hern?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Garc?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>K?nig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.03852</idno>
		<title level="m">Data augmentation instead of explicit regularization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">3d mri brain tumor segmentation using autoencoder regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Myronenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International MICCAI Brainlesion Workshop</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="311" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recalibrating fully convolutional networks with spatial and channel squeeze and excitation blocks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Abhijit Guha Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wachinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="540" to="549" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
