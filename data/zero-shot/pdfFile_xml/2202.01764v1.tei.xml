<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">JaQuAD: Japanese Question Answering Dataset for Machine Reading Comprehension</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-02-03">3 Feb 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byunghoon</forename><surname>So</surname></persName>
							<email>byunghoon@skelterlabs.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyuhong</forename><surname>Byun</surname></persName>
							<email>khbyun@skelterlabs.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyungwon</forename><surname>Kang</surname></persName>
							<email>kangnak@skelterlabs.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seongjin</forename><surname>Cho</surname></persName>
							<email>sjcho@skelterlabs.com</email>
						</author>
						<title level="a" type="main">JaQuAD: Japanese Question Answering Dataset for Machine Reading Comprehension</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-02-03">3 Feb 2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Question Answering (QA) is a task in which a machine understands a given document and a question to find an answer. Despite impressive progress in the NLP area, QA is still a challenging problem, especially for non-English languages due to the lack of annotated datasets. In this paper, we present the Japanese Question Answering Dataset, JaQuAD, which is annotated by humans. JaQuAD consists of 39,696 extractive question-answer pairs on Japanese Wikipedia articles. We finetuned a baseline model which achieves 78.92% for F1 score and 63.38% for EM on test set. The dataset and our experiments are available at https://github.com/SkelterLabsInc/JaQuAD.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question Answering (QA), a.k.a. Reading Comprehension (RC), is a natural language processing task in which a machine understands a given document and a question to find an answer. This task has become popular with the emergence of a large-scale and high-quality QA dataset named SQuAD <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b15">16]</ref>, leading to the release of other datasets such as Natural Questions <ref type="bibr" target="#b9">[10]</ref>, CoQA <ref type="bibr" target="#b17">[18]</ref>, and HotpotQA <ref type="bibr" target="#b23">[24]</ref>. These datasets contributed impressive progress for English question answering models over the past few years.</p><p>Naturally, a variety of studies have emerged for non-English QA. Some researchers made substantial efforts to construct non-English QA datasets. Similar to SQuAD, large-scale and high-quality datasets have been proposed, such as KorQuAD in Korean <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b25">26]</ref>, FQuAD in French <ref type="bibr" target="#b5">[6]</ref>, and GermanQuAD in German <ref type="bibr" target="#b12">[13]</ref>. As a more general solution for non-English QA, other studies proposed multilingual models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b4">5]</ref> or techniques transferring a monolingual model to the target language <ref type="bibr" target="#b1">[2]</ref>. Although these approaches solved QA without training data of the target language, the reported performance failed to achieve comparable results compared to the performance training with the target language data <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>To fill the gap for the Japanese language, we propose a Japanese Question Answering Dataset (JaQuAD) to address the need for a large-scale and high-quality Japanese QA dataset. JaQuAD contains 39,696 questionanswer pairs annotated by humans and 12,348 contexts which span over one or more paragraphs from 901 Japanese Wikipedia articles. More specifically, the training, development, and test sets of JaQuAD contain 31,748, 3,939, and 4,009 question-answer pairs, respectively.</p><p>To evaluate the JaQuAD, we finetuned BERT-Japanese <ref type="bibr" target="#b7">[8]</ref>, a transformer-based pretrained language model, on JaQuAD. This baseline achieves 78.92% for F1 score and 63.38% for EM on test set. It suggests there is plenty of room for improvement in modeling and learning on the JaQuAD dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work 2.1 Reading comprehension in English</head><p>The Reading Comprehension <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b16">17]</ref> attempts to solve the Question Answering problem by finding the span in one or several paragraphs which answer a given question. In recent years, English Question Answering models made impressive progress. This progress was affected by the release of large and realistic English QA datasets such as SQuAD 1.1 <ref type="bibr" target="#b16">[17]</ref>, SQuAD 2.0 <ref type="bibr" target="#b15">[16]</ref>, MS Marco <ref type="bibr" target="#b13">[14]</ref>, Natural Questions <ref type="bibr" target="#b9">[10]</ref>, QuAC <ref type="bibr" target="#b2">[3]</ref>, CoQA <ref type="bibr" target="#b17">[18]</ref>, and HotpotQA <ref type="bibr" target="#b23">[24]</ref>. Among them, SQuAD 1.1 has been one of the most famous reference datasets which consists </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Reading comprehension in other languages</head><p>There were a few SQuAD format datasets released in non-English languages. Some examples are KorQuAD 1.0 <ref type="bibr" target="#b26">[27]</ref>, KorQuAD 2.0 <ref type="bibr" target="#b25">[26]</ref>, KLUE-MRC <ref type="bibr" target="#b14">[15]</ref>, FQuAD 1.1 <ref type="bibr" target="#b5">[6]</ref>, GermanQuAD <ref type="bibr" target="#b12">[13]</ref>, and SberQuAD <ref type="bibr" target="#b6">[7]</ref>. Ko-rQuAD 1.0 is a Korean QA dataset that contains over 70k samples. KorQuAD 2.0 is another Korean QA dataset that contains over 100k samples whose contexts are HTML contents from Korean Wikipedia, not plain text contents. KLUE-MRC is a Korean QA dataset that contains over 29k samples which includes unanswerable questions and plausible fake answers. FQuAD 1.1 is a French QA dataset that contains over 60k samples. Ger-manQuAD is a German QA dataset that contains over 13k samples. SberQuAD is a Russian QA dataset that contains over 50k samples. <ref type="table">Table 1</ref> lists some of the available datasets along with the number of question-answer pairs they contain <ref type="bibr" target="#b19">[20]</ref>. For comparison, <ref type="table">Table 1</ref> also includes some English QA datasets and JaQuAD.</p><p>In the case of Japanese, a few Japanese QA datasets were released such as a driving-domain RC-QA dataset <ref type="bibr" target="#b24">[25]</ref> and an answerability annotated RC dataset <ref type="bibr" target="#b0">[1]</ref>. The driving-domain RC-QA dataset contains over 20k samples. However, the documents of the dataset come from driving-blogs which limits its domain and patterns. The answerability annotated RC dataset contains 12k question-answer pairs over 56k contexts. The question-answer pairs come from buzzer quizzes of the abc/EQIDEN competition and the contexts are paragraphs automatically collected from Wikipedia articles. Later, the answerability score of a context is annotated by crowdsourcing. Thus, this dataset has a shortcoming that the majority of contexts and corresponding questions are contrived, and that they could be biased by the original competition in some ways.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset Collection</head><p>Referencing the data collection of SQuAD 1.1, we collect our dataset in three stages: (1) collecting contexts, <ref type="bibr" target="#b1">(2)</ref> generating question-answer pairs on those contexts, and (3) validating collected questions and answers. For stages <ref type="bibr" target="#b1">(2)</ref> and (3), human annotators were selected through a qualification test. We asked annotators to generate question-answer pairs from a Wikipedia document and news articles as the qualification test. Then, only the annotators who generated fluent questions and produced answers in a consistent format participated in dataset collection.  <ref type="table">Table 2</ref>: Distribution of answer types. For JaQuAD, the distribution was extracted from the entire dataset. For KorQuAD 1.0 and SQuAD 1.1, the distributions are extracted from the random 280 and 192 samples from the development set, respectively. "SQuAD 1.1 except Others type" represents the proportions of the remaining types calculated by taking the remaining 81.9% as the total, excluding the Others type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Contexts collection</head><p>We chose Japanese Wikipedia pages as contexts to cover a wide range of domains. We collected 799 articles from the Japanese Wikipedia pages referencing quality articles <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>. Also, we collected 102 articles in other categories to broaden the domains of our dataset. 901 articles are randomly split to training, development, and test sets which are made up of 691, 101, and 109 articles, respectively. From each article, we extracted a context consisting of an individual paragraph or consecutive paragraphs without an image, a figure, and a table. As a result, training, development, and test sets are made up of 9,713, 1,431, and 1,479 contexts, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Question and answer pairs generation</head><p>Human annotators generated multiple question-answer pairs while reading a context. A question had to be answerable using the content of the corresponding context. And an answer must be a span in the context. For the consistency of the answers, all annotators generated answers according to the criteria provided. For example, the answer should be the minimum span corresponding to the question and the basic unit should be included when asked about the number. The details are in Appendix A. Also, we asked annotators to tag the answer types and question types used in KorQuAD 1.0 and gave feedback on balancing the question and answer type to control the distribution of each type. As a result, 39,696 question-answer pairs are generated. Training, development, and test sets have 31,748, 3,939, and 4,009 question-answer pairs, respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Quality management</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dataset Analysis</head><p>This chapter compares JaQuAD with two datasets in the same format, SQuAD 1.1 and KorQuAD 1.0. Referencing the analyses on SQuAD 1.1 <ref type="bibr" target="#b11">[12]</ref> and KorQuAD 1.0 <ref type="bibr" target="#b26">[27]</ref>, we analyzed questions and answers of JaQuAD. First, we categorized answers by predefined types and measured the distribution of each answer type. Second, we categorized questions according to the required reasoning ability and measured the distribution of each question type. Finally, we measured the distribution of the lengths of contexts and answers. </p><formula xml:id="formula_0">???????????? ? ???????????????? ? . . . ????????????? ??????? ? ???????????????????? ? . . .</formula><p>(Direct extrusion or forward extrusion is the most common extrusion process. . . . it generally requires more force than indirect extrusion because it creates friction with the surrounding walls during the entire process. . . ) Logical reasoning Question: ?1????????????????????????? ? ?????????? (What kind of people had the least influence on one vote in the first parliamentary elections?) . . . ??????1?????2? ? ?15? ? ???45????????????????????? ??? ? . . . (. . . It was an extremely unequal election system in which 1 vote for landowners was equivalent to 2 votes for citizens, 15 votes for farmers, and 45 votes for workers. . . . ) <ref type="table">Table 3</ref>: An example for each question type. The answers are underlined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Answer type analysis</head><p>The first analysis aims to understand the answer types of the dataset. For the answer type analysis, annotators manually labeled the answer types during data collection and validation. We used six answer types used in the analysis of KorQuAD 1.0: Object, Person, Date/Time, Location, Manner, and Cause. Further, we compared JaQuAD with SQuAD 1.1 by matching answer types to corresponding question types of SQuAD 1.1 which are categorized based on interrogative <ref type="bibr" target="#b11">[12]</ref>. Among them, the "Others" question type is removed, and "What" and "Which" question types are merged into the "Object" answer type because they are hard to distinguish clearly by answers. <ref type="table">Table 2</ref> shows the distribution of answer types on SQuAD 1.1, KorQuAD 1.0, and JaQuAD. In the Answer Types column, corresponding question types used in SQuAD 1.1 are described in parentheses. Because KorQuAD 1.0 and JaQuAD do not have Others type, we added the column "SQuAD 1.1 except Others type" for direct comparison. This column represents the proportions of the remaining types calculated by taking the remaining 81.9% as the total, excluding the Others type. In SQuAD 1.1 and KorQuAD 1.0, Object type occupies more than half of the dataset. Similarly, Object type occupies the largest proportion in JaQuAD, but it decreases to 49.4%. Compared to the other datasets, the proportion of Date/Time and Location types significantly increased to 19.7% and 14.0%, respectively. The proportion of Person type is 15.4%, similar to that of the SQuAD 1.1. As a result, the proportions of the Person, Date/Time, and Location types are similar. In contrast, the proportion of Manner and Cause types significantly decreases to 0.5% and 1.0%, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Question type analysis</head><p>The second analysis aims to understand the question types of the dataset. Referencing KorQuAD 1.0, we categorized questions into five question types according to the reasoning ability required to answer the question.  <ref type="table">Table 4</ref>: Distribution of question types. For JaQuAD, the distribution was extracted from the entire dataset. For KorQuAD 1.0 and SQuAD 1.1, we use the values in their paper which are the results of the random 280 and 192 samples from the development set, respectively. <ref type="table">Table 3</ref> shows an example for each question type. Syntactic variation implies that a question is made by changing the word order or reorganizing the sentence. Lexical variation (synonymy) implies that the keywords in a question are transformed to a synonym compared to the context. Lexical variation (world knowledge) implies that world knowledge is required to match keywords in a question and the corresponding words in the context. Multiple sentence reasoning implies that reasoning over multiple sentences is required to answer the question. Logical reasoning implies that the question requires multi-hop reasoning to find the answer among the multiple options in the context: the answer could be found by matching the condition of the question or actively using the information in parentheses. This type of question often requires comparing features of listed items or using implicit information in the context. <ref type="table">Table 4</ref> shows the proportion of question types of SQuAD 1.1, KorQuAD 1.0, and JaQuAD. The Ambiguous type includes the cases that authors of the paper disagree with annotators' answers, a question does not have a unique answer, and external knowledge out of the corresponding context is needed to answer a question.</p><p>The proportion of Syntactic variation type is almost half compared to SQuAD 1.1 and KorQuAD 1.0. In contrast, the proportions of Lexical variation (world knowledge) and Logical reasoning types are more than double. The proportion of Lexical variation (synonymy) and Multiple sentence reasoning types remains similar to KorQuAD 1.0. These represent JaQuAD requires a higher level of reasoning ability than SQuAD 1.1 and KorQuAD 1.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Context and answer length</head><p>The third analysis aims to understand the distribution of context and answer lengths. The length represents the number of tokens. We use the tokenizer of BERT-Japanese in the transformers library <ref type="bibr" target="#b22">[23]</ref>. The tokenizer first segments a text into morphemes using MeCab tokenzier <ref type="bibr" target="#b3">[4]</ref> and the Unidic 2.1.2 dictionary <ref type="bibr" target="#b8">[9]</ref>. Then, the tokenizer generates subword tokens from each morpheme. The vocabulary size of BERT-Japanese is 32,000. <ref type="figure" target="#fig_1">Figure 1</ref> shows the distribution of context lengths, question lengths, and answer lengths. In <ref type="figure" target="#fig_1">Figure 1a</ref>, the context length ranges from 22 to 1,130, and the average is 266. 5.0% of contexts are longer than 500 tokens. As the max sequence length of pre-trained models is 512 in general, truncation of these contexts could affect the performance of a model. In <ref type="figure" target="#fig_1">Figure 1b</ref>, the question length ranges from 5 to 126, and the average is 21.1. As all of the questions are shorter than 128 tokens, we did not truncate a question during training. In <ref type="figure" target="#fig_1">Figure 1c</ref>, the answer length ranges from 1 to 70, and the average is 3.3. Most of the answers are short, and only 4.1% are longer than 8 tokens. Therefore, JaQuAD has lower coverage for long answers compared to other datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Dataset Evaluation</head><p>We use two evaluation metrics, Exact Match (EM) and F1 score, which are common metrics for evaluating performances of QA models. Exact Match (EM). This metric measures the percentage of predictions that match exactly to the ground truth answer. F1 score. This metric measures the overlap between the prediction and the ground truth answer. We treat the prediction and the ground truth as bags of characters, compute F1 score, and average over all of the questions. Note that although SQuAD used word-level F1 score, we computed character-level F1 score.</p><p>Computing F1 in words is not trivial in Japanese because Japanese sentences do not have spaces. We chose a character-level F1 score as an evaluation metric by referring to the use of character-based evaluation metrics in Korean QA datasets <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b14">15]</ref>. Because Japanese uses thousands of kanji (Chinese characters) and each kanji has a meaning, the probability of two phrases coincidentally overlapping by character is low when the two phrases have different meanings. <ref type="table" target="#tab_4">Table 5</ref> shows an example of calculating the character-level F1 score in Japanese and the word-level F1 scores in English. When we translate the ground truth and prediction in English, "treatment problem of German residents" (?????????) and "self-determination for treatment problem" (?????????????) overlap two words in English ('treatment' and 'problem'). No words overlap coincidentally. The comparison in Japanese is similar; ?????????? (treatment problem of German residents) and ????????????? (self-determination for treatment problem) overlap five characters (?, ?, ?, ?, and ?). Only one Japanese character (?), which means people or nation, overlap coincidentally.</p><p>Although the evaluation process in SQuAD ignores punctuation and articles (a, an, the), we did not need them because Japanese has no articles, and there is no punctuation in the ground truth answers of JaQuAD. Thus, we could remain consistent with the former approach without any additional filtering.</p><p>Context: ????? ? ???????????????????????????? ? ????? ???????????????? ? . . . (Hitler insisted on self-determination for the treatment problem of German residents in neighboring countries and demanded the merger of German settlements with Germany. . . . ) Question: ????? ? ????????????????????????? ? ???????? ?????????????? ? (For what problems did Hitler insist on self-determination and demand the annexation of German settlements into Germany?) Ground Truth: ?????????? English translation: treatment problem of German residents Prediction: ????????????? English translation: self-determination for treatment problem Character-level F1 in Japanese: 43.5% Word-level F1 in English: 44.4%  <ref type="table">Table 6</ref>: Performance of the baseline on JaQuAD 6 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental setup</head><p>The baseline model is a Japanese pre-trained language model, BERT-Japanese <ref type="bibr" target="#b7">[8]</ref>, published in HugginFace's transformers library <ref type="bibr" target="#b22">[23]</ref>. We trained the baseline model on JaQuAD for four epochs with a learning rate of 2 ? 10 ?5 using AdamW with default settings. The learning rate is linearly increased for the first 10% of steps and linearly decreased to zero afterward. The batch size is set to 32 and a maximum sequence length of 384 tokens. We did not truncate a question, because the longest question has 126 tokens. However, contexts could be truncated to meet the maximum sequence length. All the experiments were carried out with the HuggingFace transformers library <ref type="bibr" target="#b22">[23]</ref> and trained with cloud TPUs provided by TPU Research Cloud program 1 . <ref type="table">Table 6</ref> shows the performance of the baseline model on the development and the test sets of JaQuAD. The baseline achieves 78.92% for F1 score and 63.38% for EM on test set. Further, we analyzed the performance of the baseline by the question types, answer types, and answer lengths described in Chapter 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Model performance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Performance by answer types</head><p>In order to understand the effect of answer types on model performance, we analyzed the model performance according to the answer type. We have explored the answer types and the distribution of them in Chapter 4.1. <ref type="figure" target="#fig_3">Figure 2a</ref> shows the F1 and EM scores of the baseline for each answer type. The model shows much better performance on Date/Time than the average, followed by Person, Object, and Location types. The model seems to perform better on types with few plausible candidates, such as Date/Time and Person types. Note that the proportions of Manner and Cause types are up to 1%. These types seem to suffer from the lack of training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Performance by question types</head><p>In order to understand the effect of required reasoning ability on model performance, we analyzed the model performance according to the question type. We have explored the question types and the distribution of them in Chapter 4.2. <ref type="figure" target="#fig_3">Figure 2b</ref> shows the F1 and EM scores of the baseline for each question type. Syn., Lex.   The performances on Lexical variation (world knowledge) and Multiple sentence reasoning are similar to the average. As expected, the performance on Logical reasoning type is the lowest of all types, which is more than 20%p lower than the average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Performance by answer lengths</head><p>We analyzed the model performance according to the answer lengths. <ref type="figure" target="#fig_4">Figure 3</ref> shows the F1 and EM scores of the baseline according to the answer lengths. The model performed best on the answers with length 3-4 tokens, but the f1 score are similar when the answer lengths are 3-8 tokens. The model shows the lower performance when the answer length is 1-2 tokens or 9+ tokens. This result shows that a question with a short answer is not always an easy one.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we proposed the Japanese Question Answering Dataset, JaQuAD. We collected the contexts from Japanese Wikipedia articles and 39k+ questions were manually annotated by fluent Japanese speakers. JaQuAD has the same format as SQuAD, and the characteristics of the data are generally similar to KorQuAD 1.0. In the experiments, we fine-tuned a Japanese pre-trained language model with JaQuAD as a baseline and achieved 78.92% for F1 score and 63.38% for EM on test set. The baseline reaches promising results, but there is plenty of room for improvement. Extension of the dataset, such as covering longer answers, is left for future work. The dataset and our experiments are available at https://github.com/SkelterLabsInc/JaQuAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices A Criteria for choosing answer spans</head><p>? Select the minimum answer span corresponding to the question.</p><p>? When the answer is proper nouns (e.g. event, book, work name), include parentheses.</p><p>? When the answer is a year, use basic calendar year and include '?'.</p><p>? When the answer is numeric, include the basic unit of measurement (e.g. ?, ?, ?, km).</p><p>? When the answer is an approximate value, include the expressions that indicate approximation (e.g. ?, ??, ?).</p><p>? When the answer is 'correct answer (explanation)' form, exclude parentheses except the above cases.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>For</head><label></label><figDesc>credible evaluation, collected data went through a cross-validation process. During this process, annotators validated not only questions and answers, but answer types and question types. While validating the answer and question types, validators double-checked the logical process of inferring answers. Thus, they naturally validate the answerability of the question in-depth. Ambiguous question-answer pairs were corrected through discussion in the annotator group. During validation, we fixed either question or answer in 4693 question-answer pairs and the question type or answer type of 1807 question-answer pairs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Distribution of context, question, and answer lengths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Performance for answer type and question type. (syn), Lex. (world), Mul. sent., and Logical represent Syntactic variation, Lexical variation (synonymy), Lexical variation (world knowledge), Multiple sentence reasoning, and Logical reasoning types, respectively. The model performed best on Syntactic variation type and performed the second-best on Lexical variation (synonymy) type.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Performance by answer length.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Syntactic variation Question: ???????????????????? (What is the cause of heart disease?) ??????LDL??????????????????????? ? . . . (Oxidized LDL cholesterol in the blood is thought to cause heart disease, . . . ) Lexical variation (synonymy) Question: ?????????????????????? (How long has Anne's Diary been written?) ???????2????? ? ??? ? ???????????????????? ? (Life here lasted for two years, in the meantime, Anne kept writing about her hideout in her diary.) Lexical variation (world knowledge) Question: ????????????? ? (What are the mediators of dengue fever?) ??????????????? ? ???????????? ? ??????????????? ????????? ? . . . (Dengue fever is a transient febrile disease known to transfer the virus from person to person and reach high fever through the bloodsucking activity of mosquitoes, . . . ) Multiple sentence reasoning Question: ??????????? ? ???????????????????????????? (Among direct extrusion or indirect extrusion, which technique generally requires more force?)</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>An example of calculating F1 scores in English and Japanese.</figDesc><table><row><cell>Model</cell><cell>Model size</cell><cell>Development F1 EM</cell><cell>Test F1</cell><cell>EM</cell></row><row><cell cols="5">BERT-Japanese BERT BAS E 77.35 61.01 78.92 63.38</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://sites.research.google/trc/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgements</head><p>This work was supported by TPU Research Cloud (TRC) program. For training models, we used cloud TPUs provided by TRC. We also thanks to anotators who geernated and labeled JaQuAD.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">/</forename><surname>Eqiden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>???????????????</surname></persName>
		</author>
		<ptr target="http://www.cl.ecei.tohoku.ac.jp/rcqa/" />
		<imprint>
			<date type="published" when="2022-01" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the cross-lingual transferability of monolingual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="4623" to="4637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">QuAC: Question answering in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11" />
			<biblScope unit="page" from="2174" to="2184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">??????????????????????????</forename><surname>??????????</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mecab</surname></persName>
		</author>
		<ptr target="https://taku910.github.io/mecab/" />
		<title level="m">Yet Another Part-of-Speech and Morphological Analyzer</title>
		<imprint>
			<date type="published" when="2022-01" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Guzm?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">FQuAD: French question answering dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hoffschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Belblidia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brendl?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<meeting><address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="1193" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">SberQuAD -Russian Reading Comprehension Dataset: Description and Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Efimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chertok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Boytsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Braslavski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Pretrained Japanese BERT models</title>
		<ptr target="https://github.com/cl-tohoku/bert-japanese/tree/v1.0" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
		<respStmt>
			<orgName>Inui Laboratory, Tohoku University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kawase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ogiso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Unidic</surname></persName>
		</author>
		<ptr target="https://osdn.net/projects/unidic/" />
		<imprint>
			<date type="published" when="2022-01" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Natural Questions: A Benchmark for Question Answering Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="452" to="466" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">MLQA: Evaluating cross-lingual extractive question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="7315" to="7330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Stochastic answer networks for machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1694" to="1704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">GermanQuAD and GermanDPR: Improving Non-English Question Answering and Passage Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Risch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pietsch</surname></persName>
		</author>
		<idno>abs/2104.12741</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">MS MARCO: A human generated machine reading comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)</title>
		<meeting>the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12" />
			<biblScope unit="volume">1773</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">I</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Oh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.09680</idno>
		<title level="m">Korean language understanding evaluation</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Know What You Don&apos;t Know: Unanswerable Questions for SQuAD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="784" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-11" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">CoQA: A Conversational Question Answering Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="249" to="266" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">MCTest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="193" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">NLP-progress</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<ptr target="https://nlpprogress.com/english/question_answering.html" />
		<imprint>
			<date type="published" when="2022-01" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<title level="m">Wikipedia Contributors. Wikipedia: ????? (Good articles</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<ptr target="https://ja.wikipedia.org/wiki/Wikipedia:?????" />
		<title level="m">Wikipedia Contributors. Wikipedia: ????? (Featured articles</title>
		<imprint>
			<date type="published" when="2022-01" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brew</surname></persName>
		</author>
		<idno>abs/1910.03771</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11" />
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">????</forename><surname>????</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">????</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">????</forename><surname>?????????????????????? ?????</surname></persName>
		</author>
		<title level="m">Proceedings of the Twenty-fifth Annual Meeting of the Association for Natural Language Processing. The Association for Natural Language Processing</title>
		<meeting>the Twenty-fifth Annual Meeting of the Association for Natural Language Processing. The Association for Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">???</forename><surname>???</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">???</forename><surname>???</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">???</forename><surname>Korquad</surname></persName>
		</author>
		<idno>2.0: ??? ????? ?? ??? ???? ????. ????????</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="577" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">???</forename><surname>???</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">???</forename><surname>Korquad</surname></persName>
		</author>
		<title level="m">????? ?? ??? ???? ????. ??????? ???????</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="539" to="541" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
