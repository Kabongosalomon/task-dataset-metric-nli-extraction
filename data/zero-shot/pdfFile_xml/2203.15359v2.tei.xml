<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Nested Collaborative Learning for Long-Tailed Visual Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">CBSR&amp;NLPR</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichang</forename><surname>Tan</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Institute of Deep Learning</orgName>
								<orgName type="institution">Baidu Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">National Engineering Laboratory for Deep Learning Technology and Application</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wan</surname></persName>
							<email>jun.wan@ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">CBSR&amp;NLPR</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
							<email>zlei@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">CBSR&amp;NLPR</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Centre for Artificial Intelligence and Robotics</orgName>
								<orgName type="institution" key="instit1">Hong Kong Institute of Science&amp;Innovation</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Guo</surname></persName>
							<email>guoguodong01@baidu.com</email>
							<affiliation key="aff2">
								<orgName type="department">Institute of Deep Learning</orgName>
								<orgName type="institution">Baidu Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">National Engineering Laboratory for Deep Learning Technology and Application</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Nested Collaborative Learning for Long-Tailed Visual Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The networks trained on the long-tailed dataset vary remarkably, despite the same training settings, which shows the great uncertainty in long-tailed learning. To alleviate the uncertainty, we propose a Nested Collaborative Learning (NCL), which tackles the problem by collaboratively learning multiple experts together. NCL consists of two core components, namely Nested Individual Learning (NIL) and Nested Balanced Online Distillation (NBOD), which focus on the individual supervised learning for each single expert and the knowledge transferring among multiple experts, respectively. To learn representations more thoroughly, both NIL and NBOD are formulated in a nested way, in which the learning is conducted on not just all categories from a full perspective but some hard categories from a partial perspective. Regarding the learning in the partial perspective, we specifically select the negative categories with high predicted scores as the hard categories by using a proposed Hard Category Mining (HCM). In the NCL, the learning from two perspectives is nested, highly related and complementary, and helps the network to capture not only global and robust features but also meticulous distinguishing ability. Moreover, self-supervision is further utilized for feature enhancement. Extensive experiments manifest the superiority of our method with outperforming the state-of-the-art whether by using a single model or an ensemble. Code is available at https://github.com/Bazinga699/NCL</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, deep neural networks have achieved resounding success in various visual tasks, i.e., face analy-* The first two authors contributed equally to this work ? Corresponding author  <ref type="figure">Figure 1</ref>. The comparisons of model outputs (logits) and Kullback-Leibler (KL) distance between two networks that are trained from scratch. Analysis is conducted on CIFAR100-LT dataset with Imbalanced Factor (IF) of 100. The logits are visualized on the basis of a random selected example, and the KL distance is computed based on the whole test set and then the average results of each category are counted and reported. Although the employed two networks have the same network structure and training settings, their predictions differ largely from each other especially in tail classes. Bested viewed in color. sis <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b60">61]</ref>, action and gesture recognition <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b64">65]</ref>. Despite the advances in deep technologies and computing capability, the huge success also highly depends on large welldesigned datasets of having a roughly balanced distribution, such as ImageNet <ref type="bibr" target="#b11">[12]</ref>, MS COCO <ref type="bibr" target="#b34">[35]</ref> and Places <ref type="bibr" target="#b63">[64]</ref>. This differs notably from real-world datasets, which usually exhibit long-tailed data distributions <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b50">51]</ref> where few head classes occupy most of the data while many tail classes have only few samples. In such scenarios, the model is easily dominated by those few head classes, whereas low accuracy rates are usually achieved for many other tail classes. Undoubtedly, the long-tailed characteristics challenges deep visual recognition, and also immensely hinders the practical use of deep models.</p><p>In long-tailed visual recognition, several works focus on designing the class re-balancing strategies <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b50">51]</ref> and decoupled learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b26">27]</ref>. More recent efforts aim to improve the long-tailed learning by using multiple experts <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b57">58]</ref>. The multi-expert algorithms follow a straightforward idea of complementary learning, which means that different experts focus on different aspects and each of them benefits from the specialization in the dominating part. For example, LFME <ref type="bibr" target="#b52">[53]</ref> formulates a network with three experts and it forces each expert learn samples from one of head, middle and tail classes. Previous multiexpert methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b52">53]</ref>, however, only force each expert to learn the knowledge in a specific area, and there is a lack of cooperation among them.</p><p>Our motivation is inspired by a simple experiment as shown in <ref type="figure">Fig. 1</ref>, where the different networks vary considerably, particularly in tail classes, even if they have the same network structure and the same training settings. This signifies the great uncertainty in the learning process. One reliable solution to alleviate the uncertainty is the collaborative learning through multiple experts, namely, that each expert can be a teacher to others and also can be a student to learn additional knowledge of others. Grounded in this, we propose a Nested Collaborative Learning (NCL) for long-tailed visual recognition. NCL contains two main important components, namely Nested Individual Learning (NIL) and Nested Balanced Online Distillation (NBOD), the former of which aims to enhance the discriminative capability of each network, and the later collaboratively transfers the knowledge among any two experts. Both NCL and NBOD are performed in a nested way, where the NCL or NBOD conducts the supervised learning or distillation from a full perspective on all categories, and also implements that from a partial perspective of focusing on some important categories. Moreover, we propose a Hard Category Mining (HCM) to select the hard categories as the important categories, in which the hard category is defined as the category that is not the ground-truth category but with a high predicted score and easily resulting to misclassification. The learning manners from different perspectives are nested, related and complementary, which facilitates to the thorough representations learning. Furthermore, inspired by self-supervised learning <ref type="bibr" target="#b17">[18]</ref>, we further employ an additional moving average model for each expert to conduct self-supervision, which enhances the feature learning in an unsupervised manner.</p><p>In the proposed NCL, each expert is collaboratively learned with others, where the knowledge transferring between any two experts is allowed. NCL promotes each expert model to achieve better and even comparable performance to an ensemble's. Thus, even if a single expert is used, it can be competent for prediction. Our contributions can be summarized as follows:</p><p>? We propose a Nested Collaborative Learning <ref type="bibr">(NCL)</ref> to collaboratively learn multiple experts concurrently, which allows each expert model to learn extra knowledge from others.</p><p>? We propose a Nested Individual Learning (NIL) and Nested Balanced Online Distillation (NBOD) to conduct the learning from both a full perspective on all categories and a partial perspective of focusing on hard categories.</p><p>? We propose a Hard Category Mining (HCM) to greatly reduce the confusion with hard negative categories.</p><p>? The proposed method gains significant performance over the state-of-the-art on five popular datasets including CIFAR-10/100-LT, Places-LT, ImageNet-LT and iNaturalist 2018.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Long-tailed visual recognition. To alleviate the longtailed class imbalance, lots of studies <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b62">63]</ref> are conducted in recent years. The existing methods for long-tailed visual recognition can be roughly divided into three categories: class re-balancing <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b50">51]</ref>, multi-stage training <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b26">27]</ref> and multi-expert methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b57">58]</ref>. Class re-balancing, which aims to re-balance the contribution of each class during training, is a classic and widely used method for long-tailed learning. More specifically, class re-balancing consists of data re-sampling <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b26">27]</ref>, loss re-weighting <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b47">48]</ref>. Class re-balancing improves the overall performance but usually at the sacrifice of the accuracy on head classes. Multi-stage training methods divide the training process into several stages. For example, Kang et al. <ref type="bibr" target="#b26">[27]</ref> decouple the training procedure into representation learning and classifier learning. Li et al. <ref type="bibr" target="#b30">[31]</ref> propose a multi-stage training strategy constructed on basis of knowledge distillation. Besides, some other works <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b56">57]</ref> tend to improve performance via a post-process of shifting model logits. However, multi-stage training methods may rely on heuristic design. More recently, multi-expert frameworks receive increasing concern, e.g., LFME <ref type="bibr" target="#b52">[53]</ref>, BBN <ref type="bibr" target="#b62">[63]</ref>, RIDE <ref type="bibr" target="#b49">[50]</ref>, TADE <ref type="bibr" target="#b57">[58]</ref> and ACE <ref type="bibr" target="#b1">[2]</ref>. Multiexpert methods indeed improve the recognition accuracy for long-tailed learning, but those methods still need to be further exploited. For example, most current multi-expert methods employ different models to learn knowledge from different aspects, while the mutual supervision among them is deficient. Moreover, they often employ an ensemble of experts to produce predictions, which leads to a complexity increase of the inference phase.</p><p>Knowledge distillation. Knowledge distillation is a prevalent technology in knowledge transferring. Early methods <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b39">40]</ref> often adopt an offline learning strategy, where the distillation follows a teacher-student learning scheme <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b21">22]</ref>, which transfers knowledge from a large teacher model to a small student model. However, the teacher normally should be a complex high-capacity model and the training process may be cumbersome and timeconsuming. In recent years, knowledge distillation has been extended to an online way <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b59">60]</ref>, where the whole knowledge distillation is conducted in a one-phase and end-to-end training scheme. For example, in Deep Mutual Learning <ref type="bibr" target="#b59">[60]</ref>, any one model can be a student and can distil knowledge from all other models. Guo et al. <ref type="bibr" target="#b15">[16]</ref> propose to use an ensemble of soft logits to guide the learning. Zhu et al. <ref type="bibr" target="#b29">[30]</ref> propose a multi-branch architecture with treating each branch as a student to further reduce computational cost. Online distillation is an efficient way to collaboratively learn multiple models, and facilitates the knowledge transferred among them.</p><p>Contrastive learning. Many contrastive methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18]</ref> are built based on the task of instance discrimination. For example, Wu et al. <ref type="bibr" target="#b51">[52]</ref> propose a noise contrastive estimation to compare instances based on a memory bank of storing representations. Representation learning for longtailed distribution also been exploit <ref type="bibr" target="#b25">[26]</ref>. More recently, Momentum Contrast (MoCo) <ref type="bibr" target="#b17">[18]</ref> is proposed to produce the compared representations by a moving-averaged encoder. To enhance the discriminative ability, contrastive learning often compares each sample with many negative samples. SimCLR <ref type="bibr" target="#b6">[7]</ref> achieves this by using a large batch size. Later, Chen et al. <ref type="bibr" target="#b7">[8]</ref> propose an improved method named MOCOv2, which achieving promising performance without using a large batch size for training. Considering the advantages of MoCOv2, our self-supervision is also constructed based on this structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>The proposed NCL aims to collaboratively and concurrently learn multiple experts together as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. In the following, firstly, we introduce the preliminaries, and then present Hard Category Mining (HCM), Nested Individual Learning (NIL), Nested Balanced Online Distillation (NBOD) and self-supervision part. Finally, we show the overall loss of how to aggregate them together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminaries</head><p>We denote the training set with n samples as D = {x i , y i }, where x i indicates the i-th image sample and y i denotes the corresponding label. Assume a total of K experts are employed and the k-th expert model is parameterized with ? k . Given image x i , the predicted probability of class-j in the k-th expert is computed as:</p><formula xml:id="formula_0">p j (x i ; ? k ) = exp(z k ij ) C l=1 exp(z k il )<label>(1)</label></formula><p>where z k ij is the k-th expert model's class-j output and C is the number of classes. This is a widely used way to compute the predicted probability, and some losses like Cross Entropy (CE) loss is computed based on it. However, it does not consider the data distribution, and is not suitable for long-tailed visual recognition, where a naive learned model based onp(x i ; ? k ) would be largely dominated by head classes. Therefore, some researchers <ref type="bibr" target="#b40">[41]</ref> proposed to compute predicted probability of class-j in a balanced way:</p><formula xml:id="formula_1">p j (x i ; ? k ) = n j exp(z k ij ) C l=1 n l exp(z k il )<label>(2)</label></formula><p>where n j is the total number of samples of class j. In this way, contributions of tail classes are strengthened while contributions of head classes are suppressed. Based on such balanced probabilities, Ren et al. <ref type="bibr" target="#b40">[41]</ref> further proposed a Balanced Softmax Cross Entropy (BSCE) loss to alleviate long-tailed class imbalance in model training. However, BSCE loss is still not enough, where the uncertainty in training still cannot be eliminated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Hard Category Mining</head><p>In representation learning, one well-known and effective strategy to boost performance is Hard Example Mining (HEM) <ref type="bibr" target="#b20">[21]</ref>. HEM selects hard samples for training while discarding easy samples. However, directly applying HEM to long-tailed visual recognition may distort the data distribution and make it more skewed in long-tailed learning. Differing from HEM, we propose a more amicable method named Hard Category Mining (HCM) to exclusively select hard categories for training, which explicitly improves the ability of distinguishing the sample from hard categories. In HCM, the hard category means the category that is not the ground-truth category but with a high predicted score. Therefore, the hard categories can be selected by comparing values of model's outputs. Specifically, we have C categories in total and suppose C hard categories are selected to focus on. For the sample x i and expert k, the corresponding set ? k i containing the output of selected categories is denoted as:</p><formula xml:id="formula_2">? k i = T opHard{z k ij |j ? = y i } ? {z k iyi }<label>(3)</label></formula><p>where T opHard means selecting C hard examples with largest values. In order to adapt to long-tailed learning better, we computed the probabilities of the selected categories in a balanced way, which is shown as:</p><formula xml:id="formula_3">p * (x i ; ? k ) = { n j exp(z k ij ) z k il ?? k i n l exp(z k il ) |z k ij ? ? k i }<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Nested Individual Learning</head><p>The individual supervised learning on each expert is also an important component in our NCL, which ensures that each network can achieve the strong discrimination ability. To learn thoroughly, we proposed a Nested Individual Learning (NIL) to perform the supervision in a nested way. Besides the supervision on all categories for a global and robust learning, we also force the network to focus on some important categories selected by HCM, which enhance model's meticulous distinguishing ability. The supervision on all categories is trivial and constructed on BSCE loss. Since our framework is constructed on multiple experts, the supervision is applied to each expert and the loss on all categories over all experts is the sum of the loss of each expert:</p><formula xml:id="formula_4">L all nil = ? k log(p yi (x i ; ? k ))<label>(5)</label></formula><p>For the supervision on hard categories, it also can be obtained in a similar way. Mathematically, it can be represented as:</p><formula xml:id="formula_5">L hard nil = ? k log(p * yi (x i ; ? k ))<label>(6)</label></formula><p>In the proposed NIL, the two nested supervisions are employed together to achieve a comprehensive learning, and the summed loss is written as:</p><formula xml:id="formula_6">L nil = L all nil + L hard nil (7)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Nested Balanced Online Distillation</head><p>To collaboratively learn multiple experts from each other, online distillation is employed to allow each model to learn extra knowledge from others. Previous methods <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b59">60]</ref> consider the distillation from a full perspective of all categories, which aims to capture global and robust knowledge. Different from previous methods, we propose a Nested Balanced Online Distillation (NBOD), where the distillation is conducted not only on all categories, but also on some hard categories that are mined by HCM, which facilitates the network to capture meticulous distinguishing ability. According to previous works <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b59">60]</ref>, the Kullback Leibler (KL) divergence is employed to perform the knowledge distillation. The distillation on all categories can be formulated as:</p><formula xml:id="formula_7">L all dis = 1 K(K ? 1) K k K q? =k KL(p(x i ; ? k )||p(x i ; ? q )) (8)</formula><p>As we can see, the distillation is conducted among any two experts. Note here that we use balanced distributions instead of original distributions to compute KL distance, which aims to eliminate the distribution bias under the longtailed setting. And this is also one aspect of how we distinguish from other distillation methods. Moreover, all experts employ the same hard categories for distillation, and we randomly select an expert as an anchor to generate hard categories for all experts. Similarly, the distillation on hard categories also can be formulated as:</p><formula xml:id="formula_8">L hard dis = 1 K(K ? 1) K k K q? =k KL(p * (x i ; ? k )||p * (x i ; ? q )) (9)</formula><p>The nested distillation on both all categories and hard categories are learned together, which is formulated as:</p><formula xml:id="formula_9">L dis = L all dis + L hard dis<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Feature Enhancement via Self-Supervision</head><p>Self-supervised learning aims to improve feature representations via an unsupervised manner. Following previous works <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18]</ref>, we adopt the instance discrimination as the self-supervised proxy task, in which each image is regarded as a distinct class. We leverage an additional temporary average model so as to conduct self-supervised learning, and its parameters are updated following a momentum-based moving average scheme <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18]</ref> as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. The employed self-supervision is also a part of our NCL, which cooperatively learns an expert model and its moving average model to capture better features.</p><p>Take the self-supervision for expert k as an example. Let v k i denote the normalized embedding of the i th image in the original expert model, and? k i denote the normalized embedding of its copy image with different augmentations in the temporally average model. Besides, a dynamic queue Q k is employed to collect historical features. The samples in the queue are progressively replaced with the samples in current batch enqueued and the samples in oldest batch dequeued. Assume that the queue Q k has a size of N and N can be set to be much larger than the typical batch size, which provides a rich set of negative samples and thus obtains better feature representations. The goal of instance discrimination task is to increase the similarity of features of the same image while reduce the similarity of the features of two different images. We achieve this by using a contrastive learning loss, which is computed as:</p><formula xml:id="formula_10">L k con = ?log( exp(v k i T? k i /? ) exp(v k i T? k i /? ) + ? k j ?Q k exp(v k i T? k j /? ) )<label>(11)</label></formula><p>where ? is a temperature hyper-parameter. Similar to Eq. 5 and Eq. 6, the self-supervised loss over all experts can be represented as L con = k L k con .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Model Training</head><p>The overall loss in our proposed NCL consists of three parts: the loss L nil of our NIL for learning each expert individually, the loss L dis of our NBOD for cooperation among multiple experts, and the loss L con of self-supervision. The overall loss L is formulated as:</p><formula xml:id="formula_11">L = L nil + L con + ?L dis<label>(12)</label></formula><p>where ? denotes the loss weight to balance the contribution of cooperation among multiple experts. For L nil and L con , they play their part inside the single expert, and we equally set their weighs as 1 in consideration of generality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and Protocols</head><p>We conduct experiments on five widely used datasets, including CIFAR10-LT <ref type="bibr" target="#b10">[11]</ref>, CIFAR100-LT <ref type="bibr" target="#b10">[11]</ref>, ImageNet-LT <ref type="bibr" target="#b36">[37]</ref>, Places-LT <ref type="bibr" target="#b63">[64]</ref>, and iNaturalist 2018 <ref type="bibr" target="#b45">[46]</ref>. <ref type="bibr" target="#b10">[11]</ref> are created from the original balanced CIFAR datasets <ref type="bibr" target="#b28">[29]</ref>. Specifically, the degree of data imbalance in datasets is controlled by an Imbalance Factor (IF), which is defined by dividing the number of the most frequent category by that of the least frequent category. The imbalance factors of 100 and 50 are employed in these two datasets. ImageNet-LT <ref type="bibr" target="#b36">[37]</ref> is sampled from the popular ImageNet dataset <ref type="bibr" target="#b11">[12]</ref> under longtailed setting following the Pareto distribution with power value ?=6. ImageNet-LT contains 115.8K images from 1,000 categories. Places-LT is created from the large-scale dataset Places <ref type="bibr" target="#b63">[64]</ref>. This dataset contains 184.5K images from 365 categories. iNaturalist 2018 <ref type="bibr" target="#b45">[46]</ref> is the largest dataset for long-tailed visual recognition. iNaturalist 2018 contains 437.5K images from 8,142 categories, and it is extremely imbalanced with an imbalance factor of 512.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR10-LT and CIFAR100-LT</head><p>According to previous works <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b26">27]</ref> the top-1 accuracy is employed for evaluation. Moreover, for iNaturalist 2018 dataset, we follow the works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b26">27]</ref> to divide classes into many (with more than 100 images), medium (with 20 ? 100 images) and few (with less than 20 images) splits, and further report the results on each split.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>For CIFAR10/100-LT, following <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b58">59]</ref>, we adopt ResNet-32 <ref type="bibr" target="#b18">[19]</ref> as our backbone network and liner classifier for all the experiments. We utilize ResNet-50 <ref type="bibr" target="#b18">[19]</ref>, ResNeXt-50 <ref type="bibr" target="#b53">[54]</ref> as our backbone network for ImageNet-LT, ResNet-50 for iNaturalist 2018 and pretrained ResNet-152 for Places-LT respectively, based on <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b36">37]</ref>. Following <ref type="bibr" target="#b56">[57]</ref>, cosine classifier is utilized for these models. Due to the use of the self-supervision component, we use the same training strategies as PaCo <ref type="bibr" target="#b9">[10]</ref>, i.e., training all the models for 400 epochs except models on Places-LT, which is 30 epochs. In addition, for fair comparison, following <ref type="bibr" target="#b9">[10]</ref>, RandAugument <ref type="bibr" target="#b8">[9]</ref> is also used for all the experiments except Places-LT. The influence of RandAugument will be discussed in detail in Sec. 4.4. These models are trained on 8 NVIDIA Tesla V100 GPUs.</p><p>The ? = C hard /C in HCM is set to 0.3. And the ratio of Nested Balanced Online Distillation loss ?, which plays its part among networks, is set to 0.6. The influence of ? and ? will be discussed in detail in Sec. 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparisons to Prior Arts</head><p>We compare the proposed method NCL with previous state-of-the-art methods, like LWS <ref type="bibr" target="#b26">[27]</ref>, ACE <ref type="bibr" target="#b1">[2]</ref> and so on. Our NCL is constructed based on three experts and both the performance of a single expert and an ensemble of multiple experts are reported. Besides NCL, we also report the baseline results of a network with using BSCE loss for comparisons. Comparisons on CIFAR10/100-LT are shown in <ref type="table">Table 1</ref> Places-LT are shown in <ref type="table" target="#tab_0">Table 2</ref>, and comparisons on iNat-uralist2018 are shown in of 100), 54.2% (IF of 100), 59.5% (with ResNet-50), 41.8% and 74.9%, respectively. More results on many, medium and few splits are listed in Supplementary Material. Some previous multi-expert methods were constructed based on a multi-branch network with higher complexity. For example, RIDE <ref type="bibr" target="#b49">[50]</ref> with 4 experts brings 0.4 times more computation than the original single network. However, our method of only using a single expert for evaluation won't bring any extra computation but still outperforms them. Besides, despite that some previous methods employ a multi-stage training <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b31">32]</ref> or a post-processing <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b56">57]</ref> to further improve the performance, our method still outperforms them. The significant performance over the state-of-the-art shows the effectiveness of our proposed NCL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Component Analysis</head><p>Influence of the ratio of hard categories. The ratio of selected hard categories is defined as ? = C hard /C. Experiments on our NIL model are conducted within the range of ? from 0 to 1 as shown in <ref type="figure" target="#fig_2">Fig. 3 (a)</ref>. The highest performance is achieved when setting ? to 0.3. Setting ? with a small and large values brings limited gains due to the under and over explorations on hard categories.</p><p>Effect of loss weight. To search an appropriate value for ?, experiments on the proposed NCL with a series of ? are conducted as shown in <ref type="figure" target="#fig_2">Fig. 3 (b)</ref>. ? controls the contribution of knowledge distillation among multiple experts in total loss. The best performance is achieved when ? = 0.6, which shows that a balance is achieved between single network training and knowledge transferring among experts.</p><p>Impact of different number of experts. As shown in <ref type="figure" target="#fig_3">Fig. 4</ref>, experiments using different number of experts are conducted. The ensemble performance is improved steadily as the number of experts increases, while for only using a  single expert for evaluation, its performance can be greatly improved when only using a small number of expert networks, e.g., three experts. Therefore, three experts are mostly employed in our multi-expert framework for a balance between complexity and performance. Single expert vs. multi-expert. Our method is essentially a multi-expert framework, and the comparison among using a single expert or an ensemble of multi-expert is a matter of great concern. As shown in <ref type="figure" target="#fig_3">Fig. 4</ref>, As the number of experts increases, the accuracy of the ensemble over a single expert also tends to rise. This demonstrates the power of ensemble learning. But for the main goal of our proposed NCL, the performance improvement over a single expert is impressive enough at the number of three.</p><p>Influence of data augmentations. Data augmentation is a common tool to improve performance. For example, previous works use Mixup <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b61">62]</ref> and RandAugment <ref type="bibr" target="#b8">[9]</ref> to obtain richer feature representations. Our method follows PaCo <ref type="bibr" target="#b9">[10]</ref> to employ RandAugment <ref type="bibr" target="#b8">[9]</ref> for experiments. As shown in <ref type="table">Table 4</ref> Ablation studies on all components. In this subsection, we perform detailed ablation studies for our NCL on CIFAR100-LT dataset, which is shown in <ref type="table" target="#tab_2">Table 5</ref>. To conduct a comprehensive analysis, we evaluate the proposed components including Self-Supervision ('SS' for short), NIL, NBOD and ensemble on two baseline settings of using CE and BSCE losses. Furthermore, for more detailed analysis, we split NBOD into two parts namely BOD all and BOD hard . Take the BSCE setting as an example, SS and NIL improve the performance by 0.82% and 0.64%, respectively. And employing NBOD further improves the performance from 51.24% to 53.19%. When employing an ensemble for evaluation, the accuracy is further improved and reaches the highest. For the CE baseline setting, similar improvements can be achieved for SS, NIL, DBOD and ensemble. Generally, benefiting from the label distribution shift, BSCE loss can achieve better performance than CE loss. The steadily performance improvements are achieved for all components on both baseline settings, which shows the effectiveness of the proposed NCL. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Discussion and Further Analysis</head><p>Score distribution of hardest negative category. Deep models normally confuse the target sample with the hardest negative category. Here we visualize the score distribution for the baseline method ('BSCE') and our method ('BSCE+NCL') as shown in <ref type="figure" target="#fig_4">Fig 5 (a)</ref>. The higher the score of the hardest negative category is, the more likely it is to produce false recognition. The scores in our proposed method are mainly concentrated in the range of 0-0.2, while the scores in the baseline model are distributed in the whole interval (including the interval with large values). This shows that our NCL can considerably reduce the confusion with the hardest negative category.</p><p>KL distance of pre/post collaborative learning. As shown in <ref type="figure" target="#fig_4">Fig. 5 (b)</ref>, when networks are trained with our NCL, the KL distance between them is greatly reduced, which shows that the uncertainty in predictions is effectively alleviated. Besides, the KL distance is more balanced than that of BSCE and CE, which indicates that collaborative learning is of help to the long-tailed bias reduction.</p><p>NBOD without balancing probability. As shown in <ref type="figure" target="#fig_5">Fig. 6 (a)</ref>, when removing the balanced probability in NBOD (denoted as 'NOD') both the performance of the single expert and the ensemble decline about 1%, which manifests the importance of employing the balanced probability for the distillation in long-tailed learning.</p><p>Offline distillation vs. NBOD. To further verify the effectiveness of our NBOD, we employ an offline distillation for comparisons. The offline distillation (denoted as 'NIL+OffDis') first employs three teacher networks of NIL to train individually, and then produces the teacher labels by using the averaging outputs over three teacher models. The comparisons are shown in <ref type="figure" target="#fig_5">Fig. 6 (b)</ref>. Although NIL+OffDis gains some improvements via an offline distillation, but its performance still 1.5% worse than that of NIL+NBOD. It shows that our NBOD of the collaborative learning can learn more knowledge than offline distillation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this work, we have proposed a Nested Collaborative Learning (NCL) to collaboratively learn multiple experts. Two core components, i.e., NIL and NBOD, are proposed for individual learning of a single expert and knowledge transferring among multiple experts. Both NIL and NBOD consider the features learning from both a full perspective and a partial perspective, which exhibits in a nested way. Moreover, we have proposed a HCM to capture hard categories for learning thoroughly. Extensive experiments have verified the superiorities of our method.</p><p>Limitations and Broader impacts. One limitation is that more GPU memory and computing power are needed when training our NCL with multiple experts. But fortunately, one expert is also enough to achieve promising performance in inference. Moreover, the proposed method improves the accuracy and fairness of the classifier, which promotes the visual model to be further put into practical use. To some extent, it helps to collect large datasets without forcing class balancing preprocessing, which improves efficiency and effectiveness of work. The negative impacts can yet occur in some misuse scenarios, e.g., identifying minorities for malicious purposes. Therefore, the appropriateness of the purpose of using long-tailed classification technology is supposed to be ensured with attention.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>An illustration of our proposed NCL of containing three experts. The NIL enhances discriminative ability of a single expert, and NBOD allows knowledge transferring among multiple experts. NIL conducts the supervised learning from both a full and a partial view, which focus on all categories and some hard categories, respectively. Similarly, NBOD conducts the knowledge distillation also from both a full and a partial view. The contrastive loss is calculated by using an extra momentum encoder and MLP layers, which can be removed in evaluation. Probabilities employed in NIL and NBOD are balanced according to the data distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Parameter analysis of (a) the ratio ? and (b) the loss weight ? on CIFAR100-LT dataset with IF of 100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Comparisons of using different expert numbers on CIFAR100-LT with an IF of 100. We report the performance on both a single network and an ensemble. Specifically, the performance on a single network is reported as the average accuracy on all experts, and the ensemble performance is computed based on the averaging logits over all experts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>(a) The distribution of the largest softmax probability of hardest negative category. (b) The average KL distance between two models' output probabilities on the test set. Analysis is conducted on CIFAR100-LT with an IF of 100. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>(a) Comparisons of using NOD or NBOD for distillation. (b) Comparisons of using offline distillation or our NBOD. Analysis is conducted on CIFAR100-LT with an IF of 100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>, comparisons on ImageNet-LT and Comparisons on ImageNet-LT and Places-LT datasets.</figDesc><table><row><cell>Method</cell><cell>Ref.</cell><cell cols="3">CIFAR100-LT CIFAR10-LT 100 50 100 50</cell></row><row><cell cols="3">CB Focal loss [11] CVPR'19 38.7 LDAM+DRW [4] NeurIPS'19 42.0 LDAM+DAP [25] CVPR'20 44.1 BBN [63] CVPR'20 39.4 LFME [53] ECCV'20 42.3 CAM [59] AAAI'21 47.8 Logit Adj. [38] ICLR'21 43.9 RIDE [50] ICLR'21 49.1 LDAM+M2m [28] CVPR'21 43.5 MiSLAS [62] CVPR'21 47.0 LADE [23] CVPR'21 45.4 Hybrid-SC [49] CVPR'21 46.7 DiVE [20] ICCV'21 45.4 SSD [32] ICCV'21 46.0 ACE [2] ICCV'21 49.6 PaCo [10] ICCV'21 52.0</cell><cell>46.2 45.1 49.2 47.0 -51.7 ---52.3 50.5 51.9 51.3 50.5 51.9 56.0</cell><cell>74.6 79.3 77.0 79.3 80.0 82.2 79.8 82.2 --80.0 83.6 77.7 ---79.1 -82.1 85.7 --81.4 85.4 ----81.4 84.9 --</cell></row><row><cell>BSCE (baseline) Ours (single) Ours (ensemble)</cell><cell>---</cell><cell>50.6 53.3 54.2</cell><cell>55.0 56.8 58.2</cell><cell>84.0 85.8 84.7 86.8 85.5 87.3</cell></row><row><cell cols="5">Table 1. Comparisons on CIFAR100-LT and CIFAR10-LT</cell></row><row><cell cols="2">datasets with the IF of 100 and 50.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>Ref.</cell><cell cols="2">ImageNet-LT Res50 ResX50</cell><cell>Places-LT Res152</cell></row><row><cell>OLTR [37] BBN [63] NCM [27] cRT [27] ? -norm [27] LWS [27] BSCE [41] RIDE [50] DisAlign [57] DiVE [20] SSD [32] ACE [2] PaCo [10]</cell><cell>CVPR'19 CVPR'20 ICLR'20 ICLR'20 ICLR'20 ICLR'20 NeurIPS'20 ICLR'21 CVPR'21 ICCV'21 ICCV'21 ICCV'21 ICCV'21</cell><cell>-48.3 44.3 47.3 46.7 47.7 -55.4 52.9 53.1 -54.7 57.0</cell><cell>-49.3 47.3 49.6 49.4 49.9 -56.8 --56.0 56.6 58.2</cell><cell>35.9 -36.4 36.7 37.9 37.6 38.7 -----41.2</cell></row><row><cell>BSCE (baseline) Ours (single) Ours (ensemble)</cell><cell>---</cell><cell>53.9 57.4 59.5</cell><cell>53.6 58.4 60.5</cell><cell>40.2 41.5 41.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .Table 3</head><label>33</label><figDesc>Our proposed method achieves the state-of-the-art performance on all datasets whether using a single expert or an ensemble of all experts.</figDesc><table><row><cell>For only using a single expert for evaluation, our NCL out-performs previous methods on CIFAR10-LT, CIFAR100-LT, ImageNet-LT, Places-LT and iNaturalist2018 with ac-curacies of 84.7% (IF of 100), 53.3% (IF of 100), 57.4% (with ResNet-50), 41.5% and 74.2%, respectively. When further using an ensemble for evaluation, the performance on CIFAR10-LT, CIFAR100-LT, ImageNet-LT, Places-LT and iNaturalist2018 can be further improved to 85.5% (IF</cell></row></table><note>. Comparisons on iNaturalist 2018 dataset with ResNet-50.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5 .</head><label>5</label><figDesc>Ablation studies on CIFAR100-LT dataset with an IF of 100. 'SS' indicates self-supervision. 'BOD all ' and 'BOD hard ' represent the balanced online distillation on all categories and only hard categories, respectively. NBOD means the setting when both 'BOD all ' and 'BOD hard ' are employed. Experiments are conducted on the framework of containing three experts.</figDesc><table><row><cell></cell><cell>Method</cell><cell cols="2">w/o RandAug</cell><cell cols="2">w/ RandAug</cell></row><row><cell cols="2">CE BSCE BSCE+NCL</cell><cell cols="2">41.88 45.88 47.93</cell><cell>44.79 50.60 53.31</cell><cell></cell></row><row><cell cols="2">BSCE+NCL  ?</cell><cell cols="2">49.22</cell><cell>54.42</cell><cell></cell></row><row><cell cols="6">Table 4. Comparisons of training the network with ('w/') and with-</cell></row><row><cell cols="6">out ('w/o') employing RandAugment. Experiments are conducted</cell></row><row><cell cols="6">on CIFAR100-LT dataset with an IF of 100.  ? Indicates the en-</cell></row><row><cell cols="3">semble performance is reported.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">NIL SS BOD all BOD hard Ensemble Acc.@CE Acc.@BSCE</cell></row><row><cell>? ? ? ? ? ? ? ?</cell><cell>? ? ? ?</cell><cell>? ? ?</cell><cell>?</cell><cell>44.79 48.18 46.05 48.81 49.34 49.89 51.04</cell><cell>50.60 51.24 51.42 52.64 53.19 53.31 54.42</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A systematic study of the class imbalance problem in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuto</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej A</forename><surname>Mazurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ace: Ally complementary experts for solving long-tailed recognition in one-shot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenq-Neng</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain balancing: Face recognition on longtailed domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning imbalanced datasets with labeldistribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Smote: synthetic minority oversampling technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">W</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">O</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W Philip</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Online knowledge distillation with diverse peers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Defang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Ping</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<title level="m">Improved baselines with momentum contrastive learning</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPRW</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Parametric contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV, 2021. 5</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Diversity with cooperation: Ensemble methods for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Dvornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Born again neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Furlanello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICML</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Bootstrap your own latent: A new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pierre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><forename type="middle">Daniel</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Azar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07733</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Online knowledge distillation via collaborative learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiushan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinjiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning from imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibo</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Edwardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distilling virtual examples for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Yin-Yin He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07737</idno>
		<title level="m">defense of the triplet loss for person re-identification</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Disentangling label distribution for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngkyu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungju</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwanghee</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seokjun</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beomsu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buru</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning deep representation for imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rethinking classbalanced methods for long-tailed visual recognition from a domain adaptation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Exploring balanced feature spaces for representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sa</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.09217</idno>
		<title level="m">Jiashi Feng, and Yannis Kalantidis. Decoupling representation and classifier for long-tailed recognition</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">M2m: Imbalanced classification via major-to-minor translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehyung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongheon</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Knowledge distillation by on-the-fly native ensemble</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.04606</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Self supervision to distillation for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gangshan</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Self supervision to distillation for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gangshan</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Overcoming classifier imbalance for long-tail object detection with balanced group softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jintao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Memory-based jitter: Improving visual recognition on long-tailed data with diversity in memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Long-tail learning via logit adjustment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Singh Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.07314</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Gesture recognition: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sushmita</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinku</forename><surname>Acharya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning deep representations with probabilistic knowledge transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Passalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasios</forename><surname>Tefas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Balanced metasoftmax for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunjun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunan</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.10740</idno>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Bin Yang, and Raquel Urtasun. Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Equalization loss for long-tailed object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingru</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changbao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient group-n encoding and decoding for facial age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichang</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruicong</forename><surname>Zhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2610" to="2623" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Attention-based pedestrian attribute analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichang</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanyuan</forename><surname>Hang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6126" to="6140" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The inaturalist species classification and detection dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><forename type="middle">Mac</forename><surname>Grant Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Multi-modal face presentation attack detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Escalera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><forename type="middle">Jair</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">SLCV</biblScope>
			<biblScope unit="page" from="1" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Seesaw loss for longtailed instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Contrastive learning based hybrid networks for longtailed image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Long-tailed recognition by routing diverse distribution-aware experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2021</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning from multiple experts: Self-paced knowledge distillation for long-tailed classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuyu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiguang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Identifying and compensating for feature deviation in imbalanced deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han-Jia</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-You</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>De-Chuan Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.01385</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Distribution alignment: A unified framework for long-tail visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shipeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2021</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Test-agnostic long-tailed recognition by test-time aggregating diverse experts with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanqing</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.09249</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Bag of tricks for long-tailed visual recognition with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongshun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI, 2021. 5</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Deep mutual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huchuan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Face recognition: A literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azriel</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CSUR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="399" to="458" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Improving calibration for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Min</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Regional attention with architecture-rebuilt 3d network for rgb-d gesture recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjia</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
