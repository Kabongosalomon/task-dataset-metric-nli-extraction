<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-shot Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-03-18">March 18, 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangji</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Nebula AI Group</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Shanghai Key Lab of Intelligent Information Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihan</forename><surname>Liang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Nebula AI Group</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Shanghai Key Lab of Intelligent Information Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyang</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Nebula AI Group</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Shanghai Key Lab of Intelligent Information Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Yu</forename><surname>Zhou</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
							<email>wfge@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Nebula AI Group</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Shanghai Key Lab of Intelligent Information Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Yu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqiang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Shanghai Key Lab of Intelligent Information Processing</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-shot Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-03-18">March 18, 2022</date>
						</imprint>
					</monogr>
					<note>* Corresponding author:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents new hierarchically cascaded transformers that can improve data efficiency through attribute surrogates learning and spectral tokens pooling. Vision transformers have recently been thought of as a promising alternative to convolutional neural networks for visual recognition. But when there is no sufficient data, it gets stuck in overfitting and shows inferior performance. To improve data efficiency, we propose hierarchically cascaded transformers that exploit intrinsic image structures through spectral tokens pooling and optimize the learnable parameters through latent attribute surrogates. The intrinsic image structure is utilized to reduce the ambiguity between foreground content and background noise by spectral tokens pooling. And the attribute surrogate learning scheme is designed to benefit from the rich visual information in image-label pairs instead of simple visual concepts assigned by their labels. Our Hierarchically Cascaded Transformers, called HCTransformers, is built upon a self-supervised learning framework DINO and is tested on several popular few-shot learning benchmarks.</p><p>In the inductive setting, HCTransformers surpass the DINO baseline by a large margin of 9.7% 5-way 1shot accuracy and 9.17% 5-way 5-shot accuracy on miniImageNet, which demonstrates HCTransformers are efficient to extract discriminative features. Also, HCTransformers show clear advantages over SOTA few-shot classification methods in both 5-way 1-shot and 5-way 5-shot settings on four popular benchmark datasets, including miniImageNet, tieredImageNet, FC100, and CIFAR-FS. The trained weights and codes are available at https: //github.com/StomachCold/HCTransformers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Vision transformers have recently become a prominent alternative to convolutional neural networks (CNNs) in many computer vision tasks, including image classification <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b56">57]</ref>, object detection <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b84">85]</ref>, semantic segmentation <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b82">83]</ref> and etc. However, according to <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b36">37]</ref>, transformers will work in low efficiency on a learning task with only few annotated samples. In this paper, we investigate whether vision transformers can still work well when the amount of labeled training data is extremely limited.</p><p>Few-shot learning <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b61">62]</ref> refers to the problem of learning from a very small amount of labeled data, which is expected to reduce the labeling cost, achieve a low-cost and quick model deployment, and shrink the gap between human intelligence and machine models. The key problem of few-shot learning is how to efficiently learn from the rich information hidden in annotated data. Inspired by the part-whole hierarchical concepts used in GraphFPN <ref type="bibr" target="#b80">[81]</ref> and GLOM <ref type="bibr" target="#b24">[25]</ref>, part layout information of objects/scenes contains various visual information. If it can be embedded in vision transformers to guide the feature learning, we will get discriminative feature representations. Meanwhile, to avoid the concentration of visual information on single concepts, we need to expand the hidden information of image labels into a much more general semantic representation. Then how to mine such latent information and generate a complete description of visual concepts becomes important.</p><p>In this paper, we aim to improve the data efficiency in ViT <ref type="bibr" target="#b15">[16]</ref> for few-shot image classification. To be specific, we design a meta feature extractor composed of three consecutively cascaded transformers, each of which models the dependency of image regions at different semantic levels. The output tokens of a previous transformer are passed to a spectral tokens pooling layer to produce the input tokens for the subsequent. The spectral tokens pooling is partly based on spectral clustering <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b73">74]</ref>, where features of tokens within same clusters are averaged to generate new token descriptors for the subsequent transformer. The motivation behind the spectral tokens pooling is to bring the image segmentation hierarchy into transformers. That means when the transformer performs self-attention, it needs to consider the image layout not simply through the positional embedding, but from the semantic relationship of different image regions. In our implementation, each token can be thought to represent some specific region within an image. We treat every token as a vertex in a graph and the token similarity matrix describes the edge connectivity. Thus, the spectral tokens pooling becomes an image segmentation problem and can be solved efficiently as that in normalized cut <ref type="bibr" target="#b54">[55]</ref>.</p><p>In practice, we insert two spectral tokens pooling layers between three transformers. Since they capture the semantic dependencies of tokens in different hierarchies, we call them Hierarchically Cascaded Transformers (written as HCTransformers). Besides, we don't utilize the supervision information directly as that in other state-of-the-art few-shot learning methods <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b83">84]</ref>. Instead, we introduce a latent attribute surrogates learning scheme to learn robust representations of visual concepts. We hallucinate some latent semantic surrogates for each class to guide the learning of deep models. The latent semantic surrogates also have learnable parameters that can be jointly learnt with the parameters of transformers end-to-end. In fact, it's a kind of weakly supervised learning by generalizing image-level annotation into attribute-level supervision. Based on such a latent attribute surrogate learning scheme, we avoid directly mapping an image into a single visual concept from a predefined set of object categories.</p><p>The contributions of this paper are as follows:</p><p>? We employ ViT as the meta feature extractor for fewshot learning and propose Hierarchically Cascaded Transformers (HCTransformers), which greatly improve the data efficiency through attribute surrogates learning and spectral tokens pooling.</p><p>? We propose a latent supervision propagation scheme for transformers in a weakly supervised manner. It converts the image label prediction task into a latent attribute surrogates learning problem. In this way, both the class and patch tokens can be supervised efficiently.</p><p>? We introduce a novel spectral tokens pooling scheme to transformers. It models the dependency relationship of image regions in both the spatial layout and the semantic relationship. Due to such a mechanism, ViT can learn much more discriminative features at different semantic hierarchies.</p><p>? Experiments demonstrate that our HCTransformers surpass its DINO baseline on miniImageNet <ref type="bibr" target="#b61">[62]</ref>, and outperform other state-of-the-art algorithms significantly on multiple few-shot learning benchmarks, including miniImageNet <ref type="bibr" target="#b61">[62]</ref>, tieredImageNet <ref type="bibr" target="#b51">[52]</ref>, and CIFAR-FS <ref type="bibr" target="#b3">[4]</ref> and FC-100 <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Meta-/Few-shot Learning. Meta-learning or "learning to learn" <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b46">47]</ref> refers to improving a learning task by learning over multiple learning episodes. Meta-learning has become the dominant paradigm for few-shot learning <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b59">60]</ref>. Various meta-learning based methods have been proposed for few-shot image classification, such as MAML <ref type="bibr" target="#b17">[18]</ref>, REGRAB <ref type="bibr" target="#b48">[49]</ref>, TAML <ref type="bibr" target="#b26">[27]</ref>, MetaOptNet <ref type="bibr" target="#b32">[33]</ref>, and etc. However, according to <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b47">48]</ref>, training CNNs from scratch with meta-learning shows inferior performance in comparison to fine-tuning a CNN feature extractor pretrained in a standard manner. There are also other methods focusing on better feature extraction <ref type="bibr" target="#b67">[68]</ref>, additional knowledge <ref type="bibr" target="#b64">[65]</ref>, knowledge transfer <ref type="bibr" target="#b33">[34]</ref>, and graph neural networks <ref type="bibr" target="#b30">[31]</ref>. Different from previous meta-learning methods, we introduce the inherent semantic hierarchies of images into transformers, and supervise the parameter learning with latent attribute surrogates. By this way, we alleviate the overfitting problem and get impressive results.</p><p>Tokens Pooling in Transformers. ViT <ref type="bibr" target="#b15">[16]</ref> directly applies transformer architecture into vision tasks by splitting input image into 16 ? 16 tokens via patch embedding. Despite impressive results on several vision benchmarks, vanilla transformer architectures focus on attending global information while neglecting local connections, which hinders the use of fine-grained image features thus leading to their data-hungry nature. Many subsequent works address this issue by establishing a progressive shrinking pyramid that allows models to explicitly process low-level patterns. There is a group of approaches that merge tokens within each fixed window into one to reduce the number of tokens <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b75">76]</ref>. In contrast, the second group of methods drops this constraint and introduces more flexible selection scheme <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b76">77]</ref>. While our HCTransformers allow tokens to be adaptively merged with their neighboring tokens according to their spatial layout and semantic similarities.</p><p>Supervise Patch Tokens in Transformers. ViT <ref type="bibr" target="#b15">[16]</ref> adds a [cls] token to globally summarize the integral information of patch tokens and only this token directly receives supervision signals. However, other tokens maintain the ability to express distinctive patterns and may delicately assist final prediction. Some works proposed to remove the [cls] token and construct a global token by integrating patch tokens via certain average pooling operation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b50">51]</ref>. LV-ViT <ref type="bibr" target="#b28">[29]</ref> explored the possibility to jointly utilize [cls] token and patch tokens. It reformulates the classification task with the token labeling problem. Likewise, So-ViT <ref type="bibr" target="#b69">[70]</ref> applied a second-order and cross-covariance pooling to visual tokens, which is combined with the [cls] token for final classification. Our method shares similar intuition with these two methods, but the difference is apparent. We integrate patch tokens as a weighted sum where scores are calculated based on their connections with the global [cls] token, which aims to mostly utilize significant patch tokens. Besides, we suppose the integrated patch tokens do not share the feature space with the [cls] token and supervise them within their own feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Hierarchically Cascaded Transformers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overview</head><p>The core of HCTransformers is to make the full usage of the annotated data to train transformers as a strong meta feature extractor for few-shot learning. To benefit from existing self-supervised learning techniques <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b21">22]</ref>, we use DINO <ref type="bibr" target="#b6">[7]</ref> as our base learning framework and multi-crop strategy <ref type="bibr" target="#b5">[6]</ref> to conduct knowledge distillation <ref type="bibr" target="#b25">[26]</ref>. In the pretraining stage of few-shot learning, we can access image labels. We design a latent attribute surrogates learning scheme for both patch tokens and the [cls] tokens to avoid directly learning from labels. To incorporate the semantic hierarchy into transformers, we insert a spectral tokens pooling layer between two ViTs <ref type="bibr" target="#b15">[16]</ref>. The output similarity matrix of patches can be used to conduct spectral clustering to segment patches into disjoint regions. Then the feature average of patches in the same region is treated as a new token feature, which captures higher-level semantic information. In <ref type="figure" target="#fig_1">Fig. 1</ref>, we illustrate the complete pipeline of our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Preliminary</head><p>Similar to BYOL <ref type="bibr" target="#b21">[22]</ref>, DINO <ref type="bibr" target="#b6">[7]</ref> employs a knowledge distillation framework for self-supervised learning with two homogeneous networks: teacher and student, where the teacher's parameter (? t ) is an exponential moving average results of the updated student's parameter (? s ) on the foundation of ViT <ref type="bibr" target="#b15">[16]</ref> architecture. Each network consists of a transformer encoder and a classification head (i.e., a multilayer perceptron and one fully connected layer).</p><p>Given an input image x ? R H?W ?C , DINO first re-shapes x into a sequence of flattened 2D patch tokens t p ? R N ?D . t p is then concatenated with a learnable class token t c ? R 1?D for an augmented sequence T ? R (N +1)?D . Here, {H, W } denote the spatial resolution of the input image, C stands for the image channel number. N = HW/P 2 is the resulting number of patches, where P denotes the patch size. D represents the encoded feature dimension. After passing through the transformer encoder, the sequence enhances its representation through self-attention. We denote the enhanced patch tokens as f p (x) ? R N ?D . Likewise, the enhanced [cls] token is denoted as f c (x) ? R 1?D . Moreover, the token similarity matrix A ? R (N +1)?(N +1) can be acquired from the self-attention process. Afterwards, only the encoded [cls] token is used for final prediction. We pass this [cls] token to the projection head to map it into a higher D -dimension, which is denoted as P (x).</p><p>Besides, DINO employs a multi-crop training augmentation scheme. For any given image x, it constructs a set V of the subregions, including two global views, x g 1 and x g 2 and m local views. DINO minimizes the following loss to encourage the "local-to-global" prediction consistency:</p><formula xml:id="formula_0">L DINO = 1 M xg?{x g 1 ,x g 2 } x ?V, x =xg ?P t (x g ) logP s (x ), (1) where M is the pair number 2?(m+1). P t (x g ), P s (x )</formula><p>are the outputs of teacher and student networks, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Jointly Attribute Surrogates and Parameters Learning</head><p>We design a latent supervision propagation scheme for transformers to avoid supervising the parameter learning only through a quite limited amount of one-hot labels. For each visual concept y in the label space, we aim to learn a semantic attribute surrogate z(y) ? R 1?D for it,</p><formula xml:id="formula_1">y ? z(y),<label>(2)</label></formula><p>where D is the surrogate descriptor dimension. When there are C classes, the surrogate descriptors Z ? R C?D would contain C entries. During the learning process, the supervision is passed through surrogates to supervise the student's parameter learning. At the same time, these surrogates need to be learnt at the same time. Supposing the supervised learning objective of the student is L surr , then the parameters ? s of the student and its associated surrogates can be updated with the following equations  <ref type="figure" target="#fig_1">Figure 1</ref>. Illustration of the overall structure. HCTransformers contain three sets of cascaded transformer networks, each corresponding to a teacher-student knowledge distillation framework. During training, every student transformer builds and updates a surrogate descriptor for each category. The patch tokens integrated through the attention map are also used to generate patch surrogate descriptors in the first stage. In between every two transformer sets, a spectral tokens pooling layer is used to down-sample the patch token number by 1 2 for information aggregation.</p><formula xml:id="formula_2">? t+1 s = ? t s ? ? 1 ?L surr ?? t s ,<label>(3)</label></formula><formula xml:id="formula_3">z(y) t+1 = z(y) t ? ? 2 ?L surr ?z(y) t ,<label>(4)</label></formula><p>where ? 1 and ? 2 are the learning rates. During the initialization, both ? s and Z are initialized with Gaussian noises. Following the settings in DINO <ref type="bibr" target="#b6">[7]</ref>, we use the AdamW optimizer <ref type="bibr" target="#b37">[38]</ref> with momentum to update both ? s and Z with linear scaling rule <ref type="bibr" target="#b20">[21]</ref>, which is a slightly different with that in the center loss <ref type="bibr" target="#b63">[64]</ref>.</p><p>To make the fully advantage of transformers, we learn semantic attribute surrogates for both patch and class tokens respectively.</p><p>Supervise the Class Token. In DINO <ref type="bibr" target="#b6">[7]</ref> and other knowledge distillation methods, the student network produces probability over D dimensions. Different from traditional supervised learning paradigms, D is set to a quite large number without considering the dataset's real class number. In this paper, we set D = 8192. To be consistent with the teacher-student knowledge distillation in DINO, we use the surrogate loss to supervise the probability distribution learning for every class. Then the surrogate descriptor z c (y) ? R 8192 of the class y is a vector on 8192 dimensions. We normalize z c (y) with the Softmax operation to get an attribute distribution z c (y). Following the annotations in Eq. 1, the class token loss becomes:</p><formula xml:id="formula_4">L cls surr = 1 2 xg?{x g 1 ,x g 2 } D KL (P s (x g )||z c (y)),<label>(5)</label></formula><p>where y is the label of the input image x, and D KL is the Kullback-Leibler divergence. Note that only global views are involved here considering that local views may introduce negative effects when updating class centers due to the loss of information.</p><p>Supervise Patch Tokens. In transformers, patch tokens are hard to be supervised due to the lack of patch-level annotations. To supervise patch tokens, we firstly aggregate the patch token features f p (x) to generate a global descriptor of an image x by applying the attention map A c (x) ? R 1?N :</p><formula xml:id="formula_5">F p (x) = A c (x)f p (x)<label>(6)</label></formula><p>where A c (x) denotes the similarity matrix that can be acquired by calculating the similarity between the [cls] token and each patch token. F p (x) ? R 1?D is the patch token feature. We treat each entry in F p (x) as a description about some semantic attributes, and normalize it with a Softmax operation to convert it into an attribute distribution F p (x) = Softmax F p (x). Similarly with that in the class token, we have an attribute surrogate z p (y) for each class. The patch token loss becomes:</p><formula xml:id="formula_6">L pth surr = 1 2 xg?{x g 1 ,x g 2 } D KL (F p (x)||z p (y)),<label>(7)</label></formula><p>where z p (y) = Softmax z p (y). Only the global views are applied for same consideration as aforementioned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Spectral Tokens Pooling</head><p>Multi-scale hierarchical structures have been proven effective in both convolutional neural networks <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b35">36]</ref> and transformers <ref type="bibr" target="#b36">[37]</ref>. We aim to improve the feature discriminative ability through embedding hierarchical structures into transformers. Different from the grid pooling scheme in Swin Transformer <ref type="bibr" target="#b36">[37]</ref>, here we exploit the irregular pooling method to match the image structures with more flexibility. Since transformers will generate self-attention matrices among tokens, it provides a strong prior for spectral clustering algorithms to segment tokens according to both their semantic similarities and the spatial layout. So we propose a spectral clustering-based pooling method, called spectral tokens pooling. For the N patch tokens in a ViT, we retrieve attention matrix between patches A p ? R N ?N from A. To bring in spatial consistency, we maintain an adjacency matrix H ? R N ?N to reflect the neighborhood relationship. In our design, only 8-connected neighboring tokens are connected with the center token. We use the following formula to retrieve a symmetric S matrix.</p><formula xml:id="formula_7">S = A p H + A T p H T .<label>(8)</label></formula><p>Through the spatial constraint, the S matrix can be viewed as a sparse matrix for computation acceleration. We then perform the Softmax operation on each row of S to get the final adjacency weight matrix S . The spectral clustering algorithms <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b71">72]</ref> are exploited to partition patch tokens into N clusters T = {T 1 , T 2 , ..., T N } and generate new tokens with Algorithm 1. During the backward stage, gradients of token clusters are copied to each of the averaged tokens. We implement the spectral tokens pooling with Py-Torch. <ref type="figure" target="#fig_0">Fig. 2</ref> visualizes results of two consecutive spectral tokens pooling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Training Strategy of HCTransformers</head><p>In our design, two spectral tokens pooling layers are inserted into three different transformers. That means the outputs of previous transformers are sent to the subsequent transformers after performing pooling operations. In this way, tokens are organized with different semantic hierarchies. For different transformers, we set the output token numbers to 784, 392, 196, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Spectral Tokens Pooling Algorithm</head><p>Input: Tokens T ? R N?D , adjacency weight matrix S ? R N?N , number N clusters to construct. Output: Tokens T ? R N ?D . <ref type="bibr" target="#b0">1</ref> Compute the normalized Laplacian L from S ; 2 Compute the first N eigenvectors ? 1 , ? 2 , ..., ? N of L; 3 Construct a matrix U ? R N?N to contain the vectors ? 1 , ? 2 , ..., ? N as columns; <ref type="bibr" target="#b3">4</ref> For i = 1, ..., n, let v i ? R N be the vector corresponding to the i-th row of U ; 5 Cluster the points (v i ) i=1,...,N ? R N with K-means algorithm into clusters T = {T 1 , T 2 , ..., T N }; <ref type="bibr" target="#b5">6</ref> Features of tokens in the same clusters are averaged to generate new tokens T ? R N ?D .</p><p>Since computing eigenvectors in spectral tokens pooling is time consuming ( 21.3 im/sec and 75.2 im/sec in two pooling layers respectively), we don't jointly all the three transformers end-to-end. The training is divided into two stages. In the first stage, we train the first two transformer as the same setting as DINO <ref type="bibr" target="#b6">[7]</ref> with the loss function bellow,</p><formula xml:id="formula_8">L stage1 = L DINO + ?L cls surr + ?L pth surr .<label>(9)</label></formula><p>Then we frozen parameters of the first two transformer and train the subsequent two sets of transformers jointly with the same loss function in Eq. 10. We only supervise on the [cls] token for higher efficiency in the second stage. Since features produced by the first transformer already have strong discriminative ability, the training of subsequent transformers converges quickly in several epochs.</p><formula xml:id="formula_9">L stage2 = L DINO + ?L cls surr<label>(10)</label></formula><p>The weights ? and ? are set to 1 and 0.1 in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>We perform experiments on four popular benckmark datasets for few-shot classification, including miniImageNet <ref type="bibr" target="#b61">[62]</ref>, tieredImageNet <ref type="bibr" target="#b51">[52]</ref>, CIFAR-FS <ref type="bibr" target="#b3">[4]</ref>, and FC100 <ref type="bibr" target="#b44">[45]</ref>. miniImageNet <ref type="bibr" target="#b61">[62]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>All experiments are run on ViT-S/8 (8 is the size of each patch). We adopt the multi-crop strategy of DINO, we randomly crop and resize an image to 2 global images at resolution 224 2 and 8 local images at resolution 96 2 . The teacher networks take in the 2 global views and the student networks take in all 10 image corps. In the first stage, to train a reliable meta feature extractor, we set ? and ? to 1 and 0.1, respectively, then the gradients produced by L DINO , L cls surr and L pth surr are in the same order of magnitude. Other specific parameters are inherited from DINO. In the second stage for spectral tokens pooling, we employ K-mean++ to conduct clustering. The [cls] token input for the latter pooling transformer is initialized by the former's transformed [cls] token for efficient training. Evaluation. We evaluate experiments on 5-way 1-shot and 5-way 5-shot classification. For each task, we randomly select 5 categories. In each category, we use 1 or 5 labeled images as support data and another 599 or 595 unlabeled images of the same category as novel data. The reported results are the averaged classification accuracy over 10,000 tasks. During the meta test, we don't fuse the features of three student transformers. We actually use the validation set to select the class token features of the second student transformer to generate the final feature representation. For module ablations, we use the class token feature of individual transformer as the output. We use the simple Cosine classifier and the linear classifier in S2M2 <ref type="bibr" target="#b41">[42]</ref> to predict query labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparisons with State-of-the-art Results</head><p>Tab. 3 shows the 1-shot and 5-shot comparison results with the latest state-of-the-art (SOTA) methods on miniImagenet <ref type="bibr" target="#b61">[62]</ref> and tieredImagenet <ref type="bibr" target="#b51">[52]</ref>. We outperform previous SOTA results by great margins with simple classifiers. For instance, on miniImagnet, HCTransformers surpasses SOTAs by 5.37% (1-shot) and 4.03% (5-shot), respectively. When we turn to tieredImagenet, our method outperforms the most recent DC [75] by 1.48% and 1.81% on 1-shot and 5-shot, respectively. Compared with DC which borrows class statistics from the base training set, we don't need to do this and our classifier is lightweight. Another evidence is that the margin between our method and the third-best approach is 5.09% on 1-shot, which helps validate our contribution. We give credit to our network structure for such impressive results, which can learn a lot of inherent information in data and maintain good generalization ability.</p><p>Tab. 2 and Tab. 3 display the results on small-resolution datasets, i.e., CIFAR-FS and FC100. HCTransformers show comparable or better results in these low-resolution settings: 1-shot (1.02%) and 5-shot (0.76%) on CIFAR-FS; 1-shot (0.51%) and 5-shot (1.12%) on FC100. We observe that on the small resolution datasets, we don't surpass previous SOTA methods too much. We attribute this to the patching mechanism of ViT. When the image resolution is small, such as 32 2 , it is difficult to retrieve useful representation from cropped patches with limited numbers of real pixels. Similarly, DeepEMD <ref type="bibr" target="#b77">[78]</ref> also mentioned that patch cropping would have negative impacts on the small resolution images. However, our method still achieves the new SOTA results on both of these two benchmarks.  <ref type="table">Table 3</ref>. Comparison with the state-of-the-art 5-way 1-shot and 5way 5-shot performance with 95% confidence intervals on FC100.</p><p>Top three results are shown in red, blue and green.</p><p>Learnable Parameters Comparision. In <ref type="table" target="#tab_4">Table 4</ref>, we can find that more learnable parameters don't lead to better performance directly. The backbone of METAQDA ICCV21 has much more parameters than IE CVPR21 and HCTransformers, but get inferior performances. Compared with the ViT-S backbone and DINO ICCV21 , HCTransformers get impressive improvements. It indicates that the proposed attribute surrogates learning and spectral tokens pooling are very important to utlize the strong learning abilities of transformers. Although we have more parameters than IE CVPR21 with the ResNet-12 backbone, we argue that our contribution is improving the data efficiency for transformers, and thus make them suitable for few-shot learning.  Computational Cost of Spectral Tokens Pooling. In Table 5, we list the training time cost of different modules in HCTransformers. It can be find that the spectral tokens pooling are relatively slow in our whole pipeline. But when compared with the first training stage, the time spent is still affordable because it needs only several epochs to train the second and third sets of transformers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Studies</head><p>To investigate the contributions of different components, we conduct thorough experiments in this section. In the following, we use the cosine classifier for query labels prediction.   <ref type="table">Table 6</ref>. The results of the first student transformer trained with different supervision on miniImagenet. All models are based on the DINO baseline. "CE" stands for the combination of a crossentropy loss (as that in ViT <ref type="bibr" target="#b15">[16]</ref>) and the DINO loss. "PTH" stands for the combination of the patch surrogate loss and the DINO loss. "CLS" stands for the combination of the class surrogate loss and the DINO loss. "CLS+PTH" stands for the full combination of the class surrogate loss, the patch surrogate loss and the DINO loss.    <ref type="table">Table 7</ref>. Test of the choice of different ? about the patch surrogate loss in the first student transformer on miniImagenet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Whether the latent supervision propagation is helpful?</head><p>To demonstrate the effectiveness of our proposed latent supervision propagation scheme, we conduct a series of experiments with different settings on miniImagenet in the first training stage. Results in Tab. 6 show that our proposed scheme greatly improves over DINO baseline by 9.70% for 1-shot setting and 9.17% for 5-shot setting. To explore if the patch and class surrogate losses bring in benefits, we replace them with the commonly used cross entropy loss as in ViT to supervise the parameter learning together with the DINO loss. The 5-way 1-shot and 5-way 5-shot performances drop by 4.46% and 4.41% respectively. It validates our assumption that when there is few labeled data, supervising transformers with one-hot vectors will show inferior generalization ability.</p><p>We also test the effects of the class and patch surrogate losses individually. When we remove the patch token loss for Eq. 9, the 5-way 1-shot and 5-way 5-shot accuracy drop by 2.3% and 1.85%. If we remove the class token loss from Eq. 9, the performances drop to 63.17% and 78.59% which indicates that the class surrogate loss is key to get good performance. All these experiments show that the two surrogate losses are effective in training transformers.</p><p>We try different weights ? for the patch surrogate loss by setting it to 1, 0.1, 0.01, respectively. Tab. 7 shows that setting ? to 0.1 is most suitable for the current setting.</p><p>How is the input resolution affects the results? In our implementation, images are resized into 224 ? 224, which   <ref type="table">Table 9</ref>. The influence of image resolutions on two state-of-the-art methods on miniImagenet for 5-way 1-shot classification.</p><p>is higher than traditional CNN-based methods, such as IE <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b52">53]</ref>. Multiple experiments are conducted to prove such a resolution yields is suitable for ViT <ref type="bibr" target="#b15">[16]</ref>, while other state-of-the-art methods including IE <ref type="bibr" target="#b52">[53]</ref> and Deep-EMD <ref type="bibr" target="#b77">[78]</ref>, fail to utilize high-resolution inputs. To test the performance of our HCTransformers when taking in images with different resolutions, we conduct experiments on CIFAR-FS <ref type="bibr" target="#b3">[4]</ref>. We resize images into 32 ? 32 to 54 ? 54, 112?112, and 224?224. The patch sizes are then 2?2,4?4 and 8?8 respectively. Results of different settings are listed in Tab. 8, showing that higher resolutions lead to better performance. We think that a higher resolution will make transformers get more information in the input patches and produce stable patch representations.</p><p>We also run other state-of-the-art methods on miniImagenet in 5-way 1-shot setting by upgrading the resolution to 224 ? 224, and list experimental results in Tab. 9. Their performances with high resolution are worse than their original ones. Results suggest that higher resolution will always lead to performance improvement  <ref type="table">Table 10</ref>. Ablations of training the last two sets of transformers in a one-by-one or end-to-end manner.</p><p>in few-shot learning tasks. Similar to ours, BML <ref type="bibr" target="#b83">[84]</ref> also made experiments on DeepEMD with high-resolution inputs but failed to obtain satisfactory results.</p><p>Is the end-to-end training necessary in the second training stage? To test whether it will be better to train the last two sets of transformers one-by-one, we train the second set of transformers and then freeze their parameters to train the third set of transformers. As shown in Tab. 10, training the last two sets of transformers one-by-one leads to comparable but slightly lower performance than the end-to-end one. The reason may be that jointly training the latter two sets of transformers end-to-end may help the second set of transformers to learn better features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Limitations</head><p>HCTransformers achieve good results in few-shot classification, but the current setting requires images to have a rather large resolution to pacify possible chaos within the patch to construct a stable patch-level representation. This may lead to unsatisfactory performance when the input images are in low resolutions. Besides, spectral tokens pooling is time-consuming. It will limit the usage of HCTransformers in many real applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We propose hierarchically cascaded transformers that can improve the data efficiency to tackle the task of fewshot image classification. Despite vision transformer's datahungry nature, we achieved good performance in few-shot learning tasks. Our proposed method introduces a latent supervision propagation technique that implicitly supervises the parameter learning with attribute surrogates that can be learnt. We propose a scheme to integrate patch tokens that can work in complementary with [cls] token. Also, spectral tokens pooling is proposed to embed the object/scene layout and semantic relationship among tokens for transformers. Our proposed HCTransformers not only outperform the DINO baseline significantly, but also surpass previous state-of-the-art methods by clear margins on miniImagenet, tieredImagenet datasets, CIFAR-FS and FC100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgement</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material for Attribute Surrogates Learning and Spectral Tokens Pooling in</head><p>Transformers for Few-shot Learning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. More Ablation Results</head><p>Extended experiments are conducted to further validate our design's effectiveness.</p><p>Do class and patch surrogates need different semantic spaces? In our proposed methods, we expect class surrogates and patch surrogates to reside in different semantic spaces to complete each other by solely feeding class output into a MLP layer.</p><p>Experimental results show that without this re-projecting procedure, performance drops significantly by 29.5%. It suggests that when constrained within the same feature space, supervision on class surrogate and patch surrogate might lead to severe confusion that hinders efficient learning.</p><p>Are local views harmful for surrogate learning? For every input image, our training framework produces several local and global views for self-supervision. When imposing additional surrogate-level supervision, we only attend to these global views for their better information perseverance. Experimental results show that with both global and local views supervised, performance drops by 1.9% , corresponding to the second line with views global+local in <ref type="table">Table 1</ref>. It suggests that local views tend to introduce noise for surrogate learning, which is natural considering the non-neglected object truncation issues in local views.</p><p>Why not use patch loss in latter stages? In our design, we choose to let latter transformers inherit [class] token from previous stage for initialization and impose no surrogate supervision on patch levels. We conduct experiments where patchlevel supervision is preserved in latter transformer sets. As shown in Tab. 2, with patch-level supervision, results barely improve over the basis of stage 1 and are inferior to our design with class-level supervision only. We suggest that the reason lies in that at latter stages, complementary characteristics of [cls] surrogates is key to further performance improvement. With patch loss added, network will lose its focus in [cls] surrogate learning and the intertwined training will lose previous [cls] surrogates' good properties.</p><p>Do higher resolutions always lead to better performance? Our proposed method use image with resolution 224 ? 224 as input, which is different from existing SOTA methods. To prove that our performance elevation is not a resolution gain, we conduct experiments with two SOTA methods in 224 ? 224 settings in <ref type="table">Table 7</ref> of our paper. Results show that higher resolutions lead to performance drop because of the increased tendency to overfitting for these methods. For supplementary, results with Meta-baseline <ref type="bibr" target="#b10">[11]</ref> are listed in 3. These results show that our method's improvement is not introduced by higher resolution and possess stronger generalization ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Qualitative Results</head><p>To further validate that our method can retrieve meaningful semantic representations with small datasets, we visualize selfattention maps associated with [cls] token and show results from our retrained DINO baseline and DINO +CE(with classlevel cross entropy supervision) in <ref type="figure" target="#fig_1">Fig. 1</ref> for fair comparison. Results show that our method focuses more on foreground information than the other two methods. In addition, we listed more visual results of two consecutive spectral tokens pooling procedure in <ref type="figure" target="#fig_0">Fig. 2</ref>  <ref type="table">Table 3</ref>. Comparison with the state-of-the-art 5-way 1-shot and 5-way 5-shot performance with 95% confidence intervals on different resolutions on miniImagenet and tieredImagenet. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DINO</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Visualized tokens pooling results. After spectral tokens pooling operations, adjacent tokens with similar semantics are clustered into one. (c) and (d) shows that our clustering results are well consistent with the image's basic structure. The pixel colors in the same cluster are averaged.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Stage 1 (</head><label>1</label><figDesc>400 epoch) Stage 2(2 epoch) Stage 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Visualizing features of DINO and HTransformers by t-SNE [61] on both train and validation sets on miniImagenet. Points with the same color correspond to the same category. (a) and (b) show that when equipped with semantic surrogates, more distinctive features can be learned compared with DINO baseline. Feature distribution patterns on validation set(i.e., (c) and (d)) illustrate that our method can generalize well on unseen data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>? 0.16 78.59 ? 0.12 0.1 71.27 ? 0.17 84.68 ? 0.10 0.01 70.40 ? 0.16 84.07 ? 0.10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 1 .Figure 2 .</head><label>12</label><figDesc>Visualization of Self-attention maps with the [cls] token in final layers by DINO baseline, DINO + CE(with class-level supervision) and our proposed method. More visualization of tokens pooling process. After spectral tokens pooling operations, adjacent tokens with similar semantics are clustered into one. (c) and (d) shows that our clustering results are well consistent with the image's basic structure. The pixel colors in the same cluster are averaged.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Class Surrogate Update 2 nd Teacher Transformer 2 nd Student Transformer Encoder ( ) Encoder Spectral Token Pooling CLS loss ( ) CE loss Class Surrogate Update 3 rd Teacher Transformer 3 rd Student Transformer Encoder ( ) Encoder CLS loss patch tokens class token attention class token class token class token</head><label></label><figDesc></figDesc><table><row><cell></cell><cell cols="2">1 st Teacher Transformer</cell><cell></cell></row><row><cell></cell><cell>Encoder</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Spectral Token</cell><cell>Spectral Token</cell></row><row><cell>View 1</cell><cell></cell><cell></cell><cell>Pooling</cell><cell>Pooling</cell></row><row><cell></cell><cell>( )</cell><cell></cell><cell>Update</cell><cell>( )</cell></row><row><cell></cell><cell>CE loss</cell><cell></cell><cell></cell><cell>CE loss</cell></row><row><cell>Input Image</cell><cell>Encoder ( )</cell><cell>CLS loss</cell><cell>Class Surrogate</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Spectral Token</cell></row><row><cell>View 2</cell><cell></cell><cell></cell><cell>Pooling</cell></row><row><cell></cell><cell></cell><cell>PTH loss</cell><cell>Patch</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Surrogate</cell></row><row><cell></cell><cell cols="2">Attention Vector</cell><cell>Update</cell></row><row><cell></cell><cell cols="2">1 st Student Transformer</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>contains 100 classes from the ImageNet [54] [4], randomly split into 64 bases, 16 validation, and 20 novel classes, and each class contains 600 images. tieredImageNet [52] contains 608 classes from 34 super-classes of the ImageNet, randomly split into 351 bases, 97 validation, and 160 novel classes. There are 779,165 images in total. CIFAR-FS [4] contains 100 classes from the CIFAR100 [32], randomly split into 64 bases, 16 validation, adn 20 novel calsses, and each class ResNet-12 65.91 ? 0.82 82.41 ? 0.56 71.16 ? 0.87 86.03 ? 0.58 IE [53] ResNet-12 67.28 ? 0.80 84.78 ? 0.52 72.21 ? 0.90 87.08 ? 0.58 DMF [71] ResNet-12 67.76 ? 0.46 82.71 ? 0.31 71.89 ? 0.52 85.96 ? 0.35 BML [84] ResNet-12 67.04 ? 0.63 83.63 ? 0.29 68.99 ? 0.50 85.49 ? 0.34 PAL [41] ResNet-12 69.37 ? 0.64 84.40 ? 0.44 72.25 ? 0.72 86.95 ? 0.47 METAQDA [80] WRN 67.38 ? 0.55 84.27 ? 0.75 74.29 ? 0.66 89.41 ? 0.77 TPMN [67] ResNet-12 67.64 ? 0.63 83.44 ? 0.43 72.24 ? 0.70 86.55 ? 0.63 MN + MC [79] ResNet-12 67.14 ? 0.80 83.82 ? 0.51 74.58 ? 0.88 86.73 ? 0.61 DC [75] WRN-28-10 68.57 ? 0.55 82.88 ? 0.42 78.19 ? 0.25 89.90 ? 0.</figDesc><table><row><cell>Method</cell><cell>backbone</cell><cell>miniImagenet 1-shot 5-shot</cell><cell>tieredImagenet 1-shot 5-shot</cell></row><row><cell>DeepEMD [78]</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>41</cell></row><row><cell>MELR [17]</cell><cell>ResNet-12</cell><cell cols="2">67.40 ? 0.43 83.40 ? 0.28 72.14 ? 0.51 87.01 ? 0.35</cell></row><row><cell>COSOC [40]</cell><cell>ResNet-12</cell><cell>69.28 ? 0.49 85.16 ? 0.42</cell><cell>73.57 ? 0.43 87.57 ? 0.10</cell></row><row><cell>CSEI [35]</cell><cell>ResNet-12</cell><cell cols="2">68.94 ? 0.28 85.07 ? 0.50 73.76 ? 0.32 87.83 ? 0.59</cell></row><row><cell>CNL [82]</cell><cell>ResNet-12</cell><cell cols="2">67.96 ? 0.98 83.36 ? 0.51 73.42 ? 0.95 87.72 ? 0.75</cell></row><row><cell>Baseline-Cosine</cell><cell>ViT-S</cell><cell cols="2">52.92 ? 0.17 65.04 ? 0.14 66.04 ? 0.20 78.05 ? 0.16</cell></row><row><cell>Ours-Cosine</cell><cell>ViT-S</cell><cell cols="2">74.74 ? 0.17 85.66 ? 0.10 79.67 ? 0.20 89.27 ? 0.13</cell></row><row><cell>Ours-Classifier</cell><cell>ViT-S</cell><cell></cell><cell></cell></row></table><note>74.62 ? 0.20 89.19 ? 0.13 79.57 ? 0.20 91.72 ? 0.11 Table 1. Comparison with the state-of-the-art 5-way 1-shot and 5-way 5-shot performance with 95% confidence intervals on miniImagenet and tieredImagenet. ViT-S is our baseline. Top three results are shown in red, blue and green based on their relative rankings.contains 600 images. FC100 [45] contains 100 classes from 36 super-classes of the CIFAR100, where 36 super-classes were split into 12 base (including 60 classes), 4 validation (including 20 classes) and 4 novel (including 20 classes) super-classes, and each class contains 600 images.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Top three results are shown in red, blue and green . ResNet-12 46.40 ? 0.81 61.33 ? 0.71 ConstellationNet [73] ResNet-12 43.80 ? 0.20 59.70 ? 0.20</figDesc><table><row><cell>Method</cell><cell>backbone</cell><cell cols="3">CIFAR-FS 1-shot 5-shot</cell></row><row><cell>DSN-MR [56]</cell><cell>ResNet-12</cell><cell cols="3">75.60 ? 0.90 86.20 ? 0.60</cell></row><row><cell>TPMN [67]</cell><cell>ResNet-12</cell><cell cols="3">75.50 ? 0.90 87.20 ? 0.60</cell></row><row><cell>IE [53]</cell><cell>ResNet-12</cell><cell cols="3">77.87 ? 0.85 89.74 ? 0.57</cell></row><row><cell>PSST [12]</cell><cell cols="4">WRN-28-10 77.02 ? 0.38 88.45 ? 0.35</cell></row><row><cell>BML [84]</cell><cell>ResNet-12</cell><cell cols="3">73.45 ? 0.47 88.04 ? 0.33</cell></row><row><cell>PAL [41]</cell><cell>ResNet-12</cell><cell cols="3">77.10 ? 0.70 88.00 ? 0.50</cell></row><row><cell>MN + MC [79]</cell><cell>ResNet-12</cell><cell cols="3">74.63 ? 0.91 86.45 ? 0.59</cell></row><row><cell>RENet [30]</cell><cell>ResNet-12</cell><cell cols="3">74.51 ? 0.46 86.60 ? 0.32</cell></row><row><cell>METAQDA [80]</cell><cell>WRN</cell><cell cols="3">75.95 ? 0.59 88.72 ? 0.79</cell></row><row><cell>ConstellationNet [73]</cell><cell>ResNet-12</cell><cell cols="3">75.40 ? 0.20 86.80 ? 0.20</cell></row><row><cell>Baseline-Cosine</cell><cell>ViT-S</cell><cell cols="3">57.75 ? 0.16 72.15 ? 0.12</cell></row><row><cell>Ours-Cosine</cell><cell>ViT-S</cell><cell cols="3">78.89 ? 0.18 87.73 ? 0.11</cell></row><row><cell>Ours-Classifier</cell><cell>ViT-S</cell><cell cols="3">78.88 ? 0.18 90.50 ? 0.09</cell></row><row><cell cols="5">Table 2. Comparison with the state-of-the-art 5-way 1-shot</cell></row><row><cell cols="5">and 5-way 5-shot performance with 95% confidence intervals on</cell></row><row><cell>CIFAR-FS. Method</cell><cell>backbone</cell><cell>1-shot</cell><cell>FC100</cell><cell>5-shot</cell></row><row><cell>DeepEMD [78]</cell><cell cols="4">ResNet-12 46.47 ? 0.78 63.22 ? 0.71</cell></row><row><cell>IE [53]</cell><cell cols="4">ResNet-12 47.76 ? 0.77 65.30 ? 0.76</cell></row><row><cell>BML [84]</cell><cell cols="4">ResNet-12 45.00 ? 0.41 63.03 ? 0.41</cell></row><row><cell>ALFA+MeTAL [3]</cell><cell cols="4">ResNet-12 44.54 ? 0.50 58.44 ? 0.42</cell></row><row><cell>MixtFSL [1]</cell><cell cols="4">ResNet-12 41.50 ? 0.67 58.39 ? 0.62</cell></row><row><cell>PAL [41]</cell><cell cols="4">ResNet-12 47.20 ? 0.60 64.00 ? 0.60</cell></row><row><cell>TPMN [67]</cell><cell cols="4">ResNet-12 46.93 ? 0.71 63.26 ? 0.74</cell></row><row><cell>MN + MC [79]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Baseline-Cosine</cell><cell>ViT-S</cell><cell cols="3">40.83 ? 0.15 50.93 ? 0.15</cell></row><row><cell>Ours-Cosine</cell><cell>ViT-S</cell><cell cols="3">48.27 ? 0.15 61.49 ? 0.15</cell></row><row><cell>Ours-Classifier</cell><cell>ViT-S</cell><cell cols="3">48.15 ? 0.16 66.42 ? 0.16</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>?0.17 85.66 ?0.10</figDesc><table><row><cell>Method</cell><cell>Backbone</cell><cell>Params</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>IE CVPR21</cell><cell>ResNet-12</cell><cell>12.4M</cell><cell cols="2">69.28 ?0.80 85.16 ?0.52</cell></row><row><cell>METAQDA ICCV21</cell><cell>WRN-28-10</cell><cell>36.5M</cell><cell cols="2">67.38 ?0.55 84.27 ?0.75</cell></row><row><cell>Cosine Distance</cell><cell>ResNet-50</cell><cell>23M</cell><cell cols="2">59.28 ?0.20 72.68 ?0.16</cell></row><row><cell>Cosine Distance</cell><cell>ViT-S</cell><cell>21M</cell><cell cols="2">52.92 ?0.17 65.04 ?0.14</cell></row><row><cell>DINO ICCV21 (baseline)</cell><cell>ViT-S</cell><cell>21M</cell><cell cols="2">61.57 ?0.16 75.51 ?0.12</cell></row><row><cell>HCTransformers 1</cell><cell>ViT-S</cell><cell>21M</cell><cell cols="2">71.27 ?0.17 85.66 ?0.10</cell></row><row><cell>HCTransformers 2</cell><cell>ViT-S</cell><cell>21M</cell><cell cols="2">74.74 ?0.17 89.19 ?0.13</cell></row><row><cell>HCTransformers 3</cell><cell>ViT-S</cell><cell>21M</cell><cell>72.66</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Comparison of state-of-the-art algorithms with different backbones on miniImagenet.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>The amount of training time spent at each stage on 8 Nvidia RTX 3090 GPUs on miniImageNet. ? 0.17 82.83 ? 0.11 Ours CLS+PTH 71.27 ? 0.17 84.68 ? 0.10 CE: cross-entropy loss, PTH: pth loss, CLS: cls loss.</figDesc><table><row><cell>Method</cell><cell>Loss</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>DINO</cell><cell>-</cell><cell cols="2">61.57 ? 0.16 75.51 ? 0.12</cell></row><row><cell>DINO</cell><cell>CE</cell><cell cols="2">66.81 ? 0.17 80.27 ? 0.12</cell></row><row><cell>DINO</cell><cell>PTH</cell><cell cols="2">63.17 ? 0.16 78.59 ? 0.12</cell></row><row><cell>DINO</cell><cell>CLS</cell><cell>68.95</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 .</head><label>8</label><figDesc>The performances of the first student transformer which takes in images with different resolutions/patch sizes on CIFAR-FS.</figDesc><table><row><cell>model</cell><cell>84 2</cell><cell>224 2</cell></row><row><cell>IE [53]</cell><cell cols="2">66.82 ? 0.80 60.88 ? 0.81</cell></row><row><cell cols="3">DeepEMD [78] 65.91 ? 0.82 63.07 ? 0.81</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>? 0.17 74.40 ? 0.17 73.01 ? 0.18 end-to-end 71.27 ? 0.17 74.74 ? 0.17 72.66 ? 0.18</figDesc><table><row><cell>training mode</cell><cell>stage1</cell><cell>stage2</cell><cell>stage3</cell></row><row><cell>one-by-one</cell><cell>71.27</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 2 .</head><label>2</label><figDesc>. ? 0.17 56.27 ? 0.15 DINO -global+local 69.37 ? 0.16 82.99 ? 0.11 Ours global 71.27 ? 0.17 84.68 ? 0.10 fc(x): the encoded [cls] token, P (x): the [cls] token after projection head Table 1. Results of the first student transformer trained with different surrogate space and image view settings on miniImagenet. All models are based on the DINO baseline. Two choices for class surrogate are tested : fc(x), the [cls] token extracted from ViT encoder, and P (x), projection of [cls] token via classification head. To explore impacts of local views for surrogate-level supervision, experiment with all views supervised is conducted for fair comparison. DINO+CLS+PTH 71.27 ? 0.17 71.25 ? 0.17 71.19 ? 0.17 DINO+CLS -74.74 ? 0.17 72.66 ? 0.18 DINO+CLS: combination of the class surrogate loss and the DINO loss. DINO+CLS+PTH: full combination of the class surrogate loss, the patch surrogate loss and the DINO loss. Results of supervising learning process for the latter two transformer sets with or without patch surrogates. 63.17 ? 0.23 79.26 ? 0.17 68.62 ? 0.27 83.74 ? 0.18 Meta-baseline [11] 224 2 67.20 ? 0.23 81.19 ? 0.16 70.28 ? 0.27 82.24 ? 0.20 Ours-Cosine 224 2 74.74 ? 0.17 85.66 ? 0.10 79.67 ? 0.20 89.27 ? 0.13</figDesc><table><row><cell cols="2">Method f c (x) P(x)</cell><cell>views</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>DINO</cell><cell>-</cell><cell>global</cell><cell>41.79</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was partly supported by the National Natural Science Foundation of China under Grant Nos. 62106051 and the Shanghai Pujiang Program Nos. 21PJ1400600.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mixture-based feature space learning for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Afrasiyabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Fran?ois</forename><surname>Lalonde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Gagn?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="9041" to="9051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Misha</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando De</forename><surname>Shillingford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3981" to="3989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Meta-learning with taskadaptive loss function for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungyong</forename><surname>Baik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janghoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dohee</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesik</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9465" to="9474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable closedform solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">End-toend object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="213" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.09882,2020.3</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Emerging properties in self-supervised vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.14294</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Psvit: Better vision transformer via token pooling and attention sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peixia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baopu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.03428</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Chasing sparsity in vision transformers:an end-to-end exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Meta-baseline: Exploring simple metalearning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinbo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huijuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Pareto self-supervised training for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixie</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heshen</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siteng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donglin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13663" to="13672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynamic detr: End-toend object detection with dynamic attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengchuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2988" to="2997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">UP-DETR: unsupervised pre-training for object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yugeng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junying</forename><surname>Chen</surname></persName>
		</author>
		<idno>2021. 1</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1601" to="1610" />
		</imprint>
	</monogr>
	<note>Computer Vision Foundation / IEEE</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangao</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiancai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solq</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.02351</idno>
		<title level="m">Segmenting objects by learning queries</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>ICLR 2021, Virtual Event. OpenReview.net, 2021. 1, 2, 3, 7, 8</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">MELR: meta-learning via modeling episode-level relationships for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyi</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Boosting few-shot visual learning with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4367" to="4375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent -A new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo?vila</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Valko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sotr: Segmenting objects with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruohao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dantong</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liao</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenbo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7157" to="7166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rethinking spatial dimensions of vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byeongho</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seong Joon</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="11936" to="11945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">How to represent part-whole hierarchies in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.12627</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Task agnostic meta-learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamal</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11719" to="11727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Doubleu-net: A deep convolutional neural network for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dag</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P?l</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H?vard D</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 33rd International Symposium on Computer-Based Medical Systems (CBMS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="558" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">All tokens matter: Token labeling for training better vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Daquan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Relational embedding for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahyun</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeseung</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhong</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8822" to="8833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Edge-labeling graph neural network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongmin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwoong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10657" to="10665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Large-scale few-shot learning: Knowledge transfer with class hierarchy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoxue</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiange</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7212" to="7220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning intact features by erasing-inpainting for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page" from="8401" to="8409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ternational Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Fixing weight decay regularization in adam</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Learning from very few samples: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinghua</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieping</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.02653</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Rectifying the shortcut learning of background: Shared object concentration for few-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longhui</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangjian</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinrong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zenglin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<idno>abs/2107.07746</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Partner-assisted learning for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanchen</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangxing</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Fu</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note>Aram Galstyan, and Wael Abd-Almageed</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Charting the right manifold: Manifold mixup for fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puneet</forename><surname>Mangla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nupur</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vineeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Winter Conference on Applications of Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2218" to="2227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitrii</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jen-Hao Rick</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Ranjan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.03860</idno>
		<title level="m">Anish Prabhu, Mohammad Rastegari, and Oncel Tuzel. Token pooling in vision transformers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">TADAM: task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Pau Rodr?guez L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems</title>
		<editor>Nicol? Cesa-Bianchi, and Roman Garnett</editor>
		<meeting><address><addrLine>NeurIPS; Montr?al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12-03" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note>Samy Bengio,</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Scalable vision transformers with hierarchical pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizheng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021-10" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Meta-learning by landmarking various learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hilan</forename><surname>Bensusan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><forename type="middle">G</forename><surname>Giraud-Carrier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Machine Learning</title>
		<editor>Pat Langley</editor>
		<meeting>the Seventeenth International Conference on Machine Learning<address><addrLine>Stanford, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2000-06-29" />
			<biblScope unit="page" from="743" to="750" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Fewshot image recognition by predicting parameters from activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7229" to="7238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Few-shot relation extraction via bayesian metalearning on relation graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Pascal</forename><surname>Xhonneux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<idno>PMLR, 2020. 2</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="7867" to="7876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Dynamicvit: Efficient vision transformers with dynamic token sparsification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongming</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benlin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Global filter networks for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongming</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Meta-learning for semi-supervised fewshot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 6th International Conference on Learning Representations ICLR</title>
		<meeting>6th International Conference on Learning Representations ICLR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Exploring complementary strengths of invariant and equivariant representations for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Mamshad Nayeem Rizve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="10836" to="10846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Adaptive subspaces for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrtash</forename><surname>Harandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4135" to="4144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Bottleneck transformers for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="16519" to="16529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Segmenter: Transformer for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Strudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="7262" to="7272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Rethinking transformer-based set prediction for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengcao</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3611" to="3620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Pyramid vision transformer: A versatile backbone for dense prediction without convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng-Ping</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaitao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaipeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="499" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Few-shot learning with localization in realistic settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davis</forename><surname>Wertheimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6558" to="6567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Cvt: Introducing convolutions to vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiping</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="22" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Task-aware part mining network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiamin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianzhu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Parn: Position-aware relation networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihua</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6659" to="6667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Segformer: Simple and efficient design for semantic segmentation with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.15203</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">So-vit: Mind visual tokens for vision transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangtao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiren</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qilong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihua</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.10935</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Learning dynamic alignment via meta-filter for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jilin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Fast normalized cut with linear constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linli</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2866" to="2873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Attentional constellation nets for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Fast approximate spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="907" to="916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Free lunch for few-shot learning: Distribution calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<biblScope unit="page" from="2021" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Tokens-to-token vit: Training vision transformers from scratch on imagenet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi-Hang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><forename type="middle">E H</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="558" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Vision transformer with progressive sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanghui</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="387" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Deepemd: Few-shot image classification with differentiable earth mover&apos;s distance and structured classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Meta navigator: Search for a good adaptation policy for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henghui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruibo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Shallow bayesian meta learning for real-world few-shot recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Gouk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.02833</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Graphfpn: Graph feature pyramid network for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gangming</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2763" to="2772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Looking wider for better adaptive representation in few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10981" to="10989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sixiao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zekun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yabiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<idno>2021. 1</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual</title>
		<imprint>
			<publisher>Computer Vision Foundation / IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6881" to="6890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Binocular mutual learning for improving few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangtao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Deformable {detr}: Deformable transformers for end-to-end object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xizhou</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
