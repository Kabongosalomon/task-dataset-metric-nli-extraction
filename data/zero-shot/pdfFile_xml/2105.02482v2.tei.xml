<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Unified Pre-training Framework for Conversational AI</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqi</forename><surname>Bao</surname></persName>
							<email>baosiqi@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingjin</forename><surname>Chen</surname></persName>
							<email>chenbingjin@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huang</forename><surname>He</surname></persName>
							<email>hehuang@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tian</surname></persName>
							<email>tianxin06@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhou</surname></persName>
							<email>zhouhan05@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Wang</surname></persName>
							<email>wang.fan@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
							<email>wuhua@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
							<email>wanghaifeng@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenquan</forename><surname>Wu</surname></persName>
							<email>wuwenquan01@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingzhan</forename><surname>Lin</surname></persName>
							<email>linyingzhan01@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Unified Pre-training Framework for Conversational AI</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we explore the application of PLATO-2 on various dialogue systems, including open-domain conversation, knowledge grounded dialogue, and task-oriented conversation. PLATO-2 is initially designed as an open-domain chatbot, trained via two-stage curriculum learning. In the first stage, a coarse-grained response generation model is learned to fit the simplified one-to-one mapping relationship. This model is applied to the task-oriented conversation, given that the semantic mappings tend to be deterministic in task completion. In the second stage, another fine-grained generation model and an evaluation model are further learned for diverse response generation and coherence estimation, respectively. With superior capability on capturing one-to-many mapping, such models are suitable for the open-domain conversation and knowledge grounded dialogue. For the comprehensive evaluation of PLATO-2, we have participated in multiple tasks of DSTC9, including interactive evaluation of open-domain conversation (Track3-task2), static evaluation of knowledge grounded dialogue (Track3-task1), and end-toend task-oriented conversation (Track2-task1). PLATO-2 has obtained the 1st place in all three tasks, verifying its effectiveness as a unified framework for various dialogue systems. * Equal contribution, listed in alphabetical order.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The neural models in the conversational AI can be roughly divided into three categories: open-domain chatbot, knowledge grounded dialogue agent, and task-oriented dialogue system <ref type="bibr" target="#b9">(Gao, Galley, and Li 2018)</ref>. Due to the significant differences among these tasks, it is usually necessary to customize the modeling and training for each task. Recently, pre-trained language models have gained tremendous success in natural language processing <ref type="bibr" target="#b4">(Devlin et al. 2019;</ref><ref type="bibr" target="#b3">Brown et al. 2020</ref>) and pioneering efforts have been made to pre-train dialogue generation models <ref type="bibr" target="#b1">(Bao et al. 2020a;</ref><ref type="bibr" target="#b26">Zhang et al. 2020)</ref>. However, there still lacks a unified pretraining framework which may effectively handle all these three conversational tasks.</p><p>In this work, we will explore the application of PLATO-2 <ref type="bibr" target="#b2">(Bao et al. 2020b</ref>) on the aforementioned tasks, including open-domain conversation, knowledge grounded dialogue, and task-oriented conversation. PLATO-2 is initially It is snowing outside.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How about making a snowman?</head><p>It's so cold. I really miss summer.</p><p>. . .  designed as an open-domain chat-bot 1 , trained via twostage curriculum learning. In the first stage, a coarse-grained model is trained for general response generation under the simplified relationship of one-to-one mapping. In fact, one dialogue context might have multiple appropriate responses in open-domain conversations, as shown in the toy example of <ref type="figure" target="#fig_1">Figure 1</ref>. The one-to-one mapping network can only capture the common response patterns, resulting in general and dull responses during inference. As such, the curriculum learning continues to the next stage for high-quality response generation, as illustrated in <ref type="figure" target="#fig_2">Figure 2</ref>. In the second stage, the discrete latent variable is encoded into the network for the one-to-many relationship modeling. Another finegrained generation model and an evaluation model are further learned for diverse response generation and coherence estimation, respectively. The combination of fine-grained generation and evaluation helps PLATO-2 obtain new stateof-the-art results in open-domain conversations.</p><p>Similar to the open-domain conversation, the oneto-many mapping relationship also exists in knowledge grounded dialogue: given a dialogue context, multiple pieces of knowledge might be applicable for the response generation. Therefore, the one-to-many mapping models of the second stage can also be adapted for knowledge grounded dialogue. By expanding the network input with the knowledge segment, the background knowledge is encoded and grounded for response generation. Distinct from the opendomain conversation and knowledge grounded dialogue, there is a specific goal to be accomplished in task-oriented ? ( | , ) ( | , ) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) Curriculum Learning Process</head><p>Pre-normalization</p><formula xml:id="formula_0">? [*]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLS [M]</head><p>[M] CLS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 1 Coarse-grained Generation</head><p>One-to-One Mapping General Response Generation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 2.1 Fine-grained Generation</head><p>One-to-Many Mapping Diverse Response Generation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 2.2 Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Response Coherence Estimation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 1 Coarse-grained Generation</head><p>One-to-One Mapping General Response Generation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 2.1 Fine-grained Generation</head><p>One-to-Many Mapping Diverse Response Generation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 2.2 Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Response Coherence Estimation</head><p>?  conversation. Accordingly, the conversation flow would become less diverse and concentrated on task completion. Therefore, the one-to-one mapping generation model of PLATO-2 is employed for the end-to-end task-oriented conversation. Given the dialogue context, this model will learn to generate the dialogue state, system action, and system response all together. To evaluate PLATO-2's performance on various dialogue systems, we have participated in multiple tasks of DSTC9 <ref type="bibr" target="#b11">(Gunasekara et al. 2020)</ref>, including interactive evaluation of open-domain conversation (Track3-task2), static evaluation of knowledge grounded dialogue (Track3-task1), and endto-end task-oriented conversation (Track2-task1). PLATO-2 obtains 1st place in all the three tasks, whose effectiveness and generalization are verified through these comprehensive evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PLATO-2</head><p>The network overview and curriculum learning process of PLATO-2 are illustrated in <ref type="figure" target="#fig_2">Figure 2</ref>. The network backbone is consisted of transformer blocks with pre-normalization <ref type="bibr" target="#b20">(Vaswani et al. 2017;</ref><ref type="bibr" target="#b17">Radford et al. 2019)</ref>. And the network's input representation is the sum of token, segment and position embeddings. Distinct with conventional Seq2Seq approaches, PLATO-2 adopts the unified network <ref type="bibr" target="#b6">(Dong et al. 2019;</ref><ref type="bibr" target="#b1">Bao et al. 2020a)</ref>, where transformer block parameters are shared across encoder and decoder.</p><p>As shown in <ref type="figure" target="#fig_2">Figure 2</ref>, there are two stages involved in the curriculum learning process. In the first stage, a coarsegrained generation model is learned under the simplified relationship of one-to-one mapping. Given one training sample of dialogue context and response (c, r), the training objective is to minimize the negative log-likelihood (NLL) loss:</p><formula xml:id="formula_1">L Baseline N LL = ?E log p(r|c) = ?E T t=1 log p(r t |c, r &lt;t ) ,</formula><p>where T is the length of the response and r &lt;t denotes previous tokens. In order to obtain better language understanding, bi-directional self-attention is enabled within the context part, shown as blue lines. And for the auto-regressive generation, uni-directional self-attention is employed within the response part, shown as orange dashed lines. As discussed in the introduction, there exists the one-to-many relationship in open-domain conversations, i.e., one dialogue context may correspond to multiple appropriate responses. The one-to-one mapping network can only capture the typical patterns of diversified responses, resulting in general and dull responses during inference. Despite the problem of safe responses, the network is still highly effective in capturing the coarse-grained mapping relationship between dialogue context and response.</p><p>To obtain high-quality responses for open-domain conversations, a fine-grained generation model and an evaluation model are further learned in stage 2. The discrete latent variable is encoded for the one-to-many relationship modeling, acting as a latent speech act. For the sake of accurate optimization, latent act recognition is first carried out to estimate the distribution of the latent variable w.r.t. the training sample p(z|c, r). The response is then generated with the sample latent variable p(r|c, z), where z ? p(z|c, r). The calculation of NLL loss becomes:</p><p>L Generation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N LL</head><p>= ?E z?p(z|c,r) log p(r|c, z)</p><formula xml:id="formula_2">= ?E z?p(z|c,r) T t=1 log p(r t |c, z, r &lt;t )<label>(1)</label></formula><p>where z is one K-way categorical variable z ? {1, ? ? ? , K}. Given that the sampling operation is not differentiable, we approximate it with Gumbel-Softmax <ref type="bibr" target="#b13">(Jang, Gu, and Poole 2017)</ref>. Besides the classical NLL loss, the bag-of-words (BOW) loss <ref type="bibr" target="#b28">(Zhao, Zhao, and Eskenazi 2017)</ref> is also employed to facilitate the training process of latent variable:</p><formula xml:id="formula_3">L Generation BOW = ?E z?p(z|c,r) T t=1 log p(r t |c, z) = ?E z?p(z|c,r) T t=1 log e fr t v?V e fv ,<label>(2)</label></formula><p>where V refers to the vocabulary, the function f tries to predict all the words in the target response using the output embedding h z . As compared with the NLL loss, BOW loss ignores the word order and forces the final latent embedding to capture the global information of the response. To sum up, the training objective of the fine-grained generation model is to minimize the integrated loss:</p><formula xml:id="formula_4">L Generation = L Generation N LL + L Generation BOW<label>(3)</label></formula><p>By assigning distinct values to the latent variable, the finegrained generation model is able to produce multiple diverse responses. For selecting the most appropriate one from these candidate responses, the evaluation model is trained to estimate the coherence between each response and the given dialogue context. During training, the evaluation model needs to distinguish the golden response r from the randomly selected negative response r ? .</p><formula xml:id="formula_5">L Evaluation RCE = ? log p(l r = 1|c, r) ? log p(l r ? = 0|c, r ? )</formula><p>Besides the response coherence estimation (RCE) loss, the conventional masked language model (MLM) loss <ref type="bibr" target="#b4">(Devlin et al. 2019</ref>) is also included to retain the representation ability of the network. To sum up, the training objective of the evaluation model is to minimize the integrated loss:</p><formula xml:id="formula_6">L Evaluation = L Evaluation RCE + L Evaluation M LM (4)</formula><p>During inference, conditioned on each latent value z ? {1, ? ? ? , K}, its corresponding candidate response is produced by the fine-grained generation model p(r|c, z). The most coherent response can be selected in the following way:</p><formula xml:id="formula_7">r * = max z?{1,??? ,K} p(l r = 1|c, r)<label>(5)</label></formula><p>In addition to the above coherence estimation, two other approaches are commonly adopted for response selection: length-averaged log-likelihood and maximum mutual information. The length-averaged log-likelihood considers the forward probability p(r|c), which tends to select those common and general responses. The maximum mutual information considers the backward probability p(c|r), which favors those responses of high-overlap with the dialogue context. In comparison, the evaluation model p(l r = 1|c, r) considers the bi-directional information flow between the dialogue context and response, achieving better performance at selecting coherent responses. . . . PLATO-2 learns gradually from coarse-grained general response generation to fine-grained diverse response generation via this curriculum learning process. Besides, the evaluation model further selects the most coherent response from multiple candidate responses. This combination of fine-grained generation and evaluation helps PLATO-2 obtain high-quality responses in open-domain conversations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Knowledge Grounded Dialogue</head><p>Another common conversational task is knowledge grounded dialogue, where the response is generated based on the dialogue context and background knowledge. The background knowledge can come in a variety of forms, such as persona profiles <ref type="bibr" target="#b25">(Zhang et al. 2018)</ref>, Wikipedia , news articles <ref type="bibr" target="#b10">(Gopalakrishnan et al. 2019)</ref>, and so on. One example from Persona-Chat is given in <ref type="figure" target="#fig_3">Figure 3</ref>. It can be observed that the response generation relies on not only the dialogue context but also the persona profiles. Similar to the open-domain conversation, there also exists the one-to-many mapping relationship in knowledge grounded dialogue <ref type="bibr" target="#b14">(Kim, Ahn, and Kim 2019)</ref>: given a dialogue context, multiple pieces of knowledge might be applicable for the response generation.</p><p>Within the PLATO-2 framework, the background knowledge can be encoded into the fine-grained generation and evaluation network straightforwardly by adding a segment of knowledge before the dialogue context. The learning of response generation becomes p(r|k, c, z), where k refers to the background knowledge. And the evaluation model p(l r = 1|k, c, r) will consider the coherence with the dialogue context and the consistency with the background knowledge simultaneously. The fine-grained generation model produces diverse knowledge grounded responses and the evaluation model further selects out the most appropriate one from these candidates.   been introduced for end-to-end task-oriented dialogue generation with pre-trained language models. In this section, we will discuss how to apply PLATO-2 on end-to-end taskoriented conversations. Distinct from open-domain conversation and knowledge grounded dialogue, the task-oriented conversation is supposed to accomplish a particular goal. Therefore, the semantic mapping between dialogue context and response would be less diverse. To this end, the one-to-one mapping generation model in stage 1 is employed for task-oriented conversation. Even with this powerful pre-trained generation model, it is still challenging to carry out end-to-end task-completion conversations. Firstly, the generation model needs to find out an effective way to interact with the external database. It is necessary to retrieve relevant information from the database for response generation, such as retrieving the candidates meeting the current user's criteria. Secondly, it is crucial for task completion to extract the entity precisely from the conversation. However, the entity name is non-categorical, and the user might mention it in various forms. Thirdly, the user's requests might be ambiguous, and the model has difficulties in capturing the user's real needs. Taking the utterance "I want to find a hotel to stay" as an example, it is hard to tell whether the user wants to find a place to stay or the user wants to find a hotel instead of a guesthouse to stay.</p><p>To tackle the above problems, several techniques are employed in our work. Firstly, the interaction with the external database is enabled through dialogue state estimation <ref type="bibr" target="#b11">(Ham et al. 2020</ref>) and a flexible two-phase generation process is adopted to produce the final response. In the first phase, the model generates the dialogue state, system action, and system response simultaneously. The dialogue state will be used as a constraint for database query, and the system action can be refreshed according to the queried results. If there is any update about the system action or no candidate found from the queried results, the second phase generation will be carried out to produce the final response. Secondly, to boost the extraction of entity names, we employ fuzzy matching between the dialogue context and database, where special tokens &lt;name/&gt; and &lt;/name&gt; will be added around the candidate entity names. Through this enhanced presentation, our model achieves better accuracy and generalization in entity detection. Thirdly, to deal with the ambiguous requests, active clarification is introduced by raising one clarifying question towards the user, such as "would you like a guesthouse or a hotel". With active clarification, the model can capture the user's real needs under ambiguous scenarios. The above three techniques -effective interaction with an external database, improved entity representation, and active clarification, help PLATO-2 achieve a better success rate and user experience in task-oriented conversations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>For the comprehensive evaluation of PLATO-2, we have enrolled in multiple tasks of DSTC9 <ref type="bibr" target="#b11">(Gunasekara et al. 2020</ref>):</p><p>? Track3-task2 interactive evaluation of open-domain conversation;</p><p>? Track3-task1 static evaluation of knowledge grounded dialogue;</p><p>? Track2-task1 end-to-end task-oriented conversation.   <ref type="table">Table 4</ref>: Human evaluation results on Track2-task1 end-to-end task-oriented conversations, with the best value written in bold.</p><p>beam search, where the beam size is set to 5. Experimental details on each task will be discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Open-domain Conversation</head><p>Interactive open-domain conversation is the most challenging direction in dialogue systems. The users are free to talk about any topic and the system's replies are expected to meet a high standard on many aspects, including coherence, consistency, informativeness, engagingness, etc. Since PLATO-2 is initially designed as an open-domain chatbot, it can be applied directly in open-domain conversations. In DSTC9 Track3-task2, real internet users are attracted through Facebook advertising and communicate with the backend dialogue systems through DialPort <ref type="bibr" target="#b27">(Zhao, Lee, and Eskenazi 2016)</ref>. The collected logs are then distributed to AMT workers for assessments. For each system, 200 interactive dialogues are collected for human evaluation. And for each dialogue, three crowd-sourcing workers are asked to annotate it from multiple aspects and provide an overall score. The human evaluation results are summarized in <ref type="table" target="#tab_4">Table 1</ref>. PLATO-2 achieves the highest score of overall human rating and performs well on many evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Knowledge Grounded Dialogue</head><p>In DSTC9 Track3-task1, experiments are carried out on Topical-Chat <ref type="bibr" target="#b10">(Gopalakrishnan et al. 2019)</ref>, which is a largescale dataset on knowledge grounded dialogue. For background knowledge, there are 300 entities in Topical-Chat, and each entity is associated with several short facts or articles. For each conversational turn, several relevant facts are provided, and the system can leverage these facts for response generation. As large-scale pre-trained models are capable of packing knowledge into the parameters <ref type="bibr" target="#b18">(Roberts, Raffel, and Shazeer 2020)</ref>, we test two experimental settings: PLATO-2 with and without explicit knowledge. In the first setting, the given relevant facts are appended before the dialogue context, and the model learns the response generation based on explicit knowledge p(r|k, c, z). In the second setting, the model tries to encode the knowledge into the network implicitly and learn the knowledge grounded response generation directly p(r|c, z). In this task, systems need to produce the response given the dialogue context and relevant facts. During the evaluation, 100 randomly selected samples are distributed to AMT workers for assessments. For each conversational turn, three crowd-sourcing workers are asked to annotate it from multiple aspects and provide an overall score. The human evaluation results are summarized in <ref type="table" target="#tab_5">Table 2</ref>. Three approaches are tied for the first place, where the top two are our submitted PLATO-2 without and with explicit knowledge. Given the name of the third approach, PLATO-2 might dominate the leaderboard in knowledge grounded dialogue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">End-to-end Task-oriented Conversation</head><p>In DSTC9 Track2-task1, the end-to-end task-oriented conversation is carried out on MultiWOZ 2.1 , which is a multi-domain dialogue dataset on travel planning. In the experiments, we employ the one-to-one mapping model of PLATO-2 and fine-tune it with the aforementioned three techniques. In this task, the ConvLab-2 platform ) provides the user simulator for automatic evaluation. The evaluation results are summarized in <ref type="table" target="#tab_7">Table 3</ref> and That would be awful.</p><p>Well i disagree, robots are more efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context</head><p>[P1] do you have a twitter account ? [P2] i do n't , do you ? [P1] nope do n't have one either . i here they covered the florida shooting . did you hear about that ?</p><p>[P2] i did ! i read a few of the student 's tweets , but i did n't realize teachers were involved in tweeting about it as well . its interesting to see how younger generations are making their voices heard though [P1] yes it is , technology is in know way slowing down and today 's youth know how to use it well .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge</head><p>Taylor Swift : Taylor Swift once accidentally released 8 seconds of white noise and topped the Canadian iTunes charts.</p><p>Golden Response i had a random factual section about taylor swift-apparently at one point she accidentally released a few seconds of white noise and it topped itunes charts in canada . did you hear about that ?</p><p>Baseline i think that is a great way to put it . i think it 's funny that she released 8 seconds of white noise on itunes and it topped the canadian itunes charts .</p><p>PLATO-2 w/o explicit knowledge I agree. I think the younger generation has the potential to make a real difference in the world though. Do you ever listen to music on your phone?</p><p>PLATO-2 w/ explicit knowledge i wonder if it is slowing down though , as technology has advanced and people are more connected to each other . have you ever heard the white noise taylor swift releases on social media ? Maybe one day we can all be robots, it would be a great advancement</p><p>That would be awful.</p><p>Well i disagree, robots are more efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context</head><p>[P1] do you have a twitter account ?</p><p>[P2] i do n't , do you ?</p><p>[P1] nope do n't have one either . i here they covered the florida shooting . did you hear about that ?</p><p>[P2] i did ! i read a few of the student 's tweets , but i did n't realize teachers were involved in tweeting about it as well . its interesting to see how younger generations are making their voices heard though [P1] yes it is , technology is in know way slowing down and today 's youth know how to use it well .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge</head><p>Taylor Swift : Taylor Swift once accidentally released 8 seconds of white noise and topped the Canadian iTunes charts.</p><p>Golden Response i had a random factual section about taylor swift-apparently at one point she accidentally released a few seconds of white noise and it topped itunes charts in canada . did you hear about that ?</p><p>Baseline i think that is a great way to put it . i think it 's funny that she released 8 seconds of white noise on itunes and it topped the canadian itunes charts .</p><p>PLATO-2 w/o explicit knowledge I agree. I think the younger generation has the potential to make a real difference in the world though. Do you ever listen to music on your phone?</p><p>PLATO-2 w/ explicit knowledge i wonder if it is slowing down though , as technology has advanced and people are more connected to each other . have you ever heard the white noise taylor swift releases on social media ? our approach ranks the 1st with the highest success rate.</p><p>Aside from the automatic evaluation, AMT workers are asked to communicate with the systems for task completion. When the conversation is finished, AMT workers need to give evaluation scores on several aspects. The human evaluation results are summarized in <ref type="table">Table 4</ref>. The average success rate is calculated as the average value of the following two metrics: the success rate without database grounding and the success rate with database grounding. The success rate without database grounding is based on the AMT worker's annotation during communication (success or fail). In fact, AMT workers do not know whether the provided values from the system are consistent with the database or not. In comparison, the success rate with database grounding is a more strict and practical metric. The dialogue is considered as a success if and only if: 1) AMT worker marks the dialogue as success; 2) the provided request slot values plus inform slot values from the system can be found in the database. Our approach achieves the highest score on success rate with database grounding. The first two approaches are placed as co-champion based on the average success rate in the final ranking.</p><p>That's interesting, maybe we are both robots and are talking to each other I'm not a robot. Sometime I wish I were.</p><p>Maybe one day we can all be robots, it would be a great advancement That would be awful.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Discussions</head><p>To further dissect the performance of PLATO-2, several cases from various conversations are provided for analysis. As shown in <ref type="figure" target="#fig_4">Figure 4</ref>, one dialogue snippet is selected from the interaction between a real user and our system. In the Di-alPort platform, users are informed in advance that they will communicate with AI bots. This dialogue snippet demonstrates that PLATO-2 is able to produce coherent and engaging responses in open-domain conversation. For knowledge grounded dialogue, one example is selected to display in <ref type="table" target="#tab_8">Table 5</ref>. As compared with the golden and baseline responses, the responses generated by PLATO-2 are more coherent with the dialogue context. Instead of changing the topic suddenly or copying the given facts directly, PLATO-2 absorbs the knowledge and conveys the information in a natural way. For task-oriented conversation, one dialogue snippet with the corresponding goal is selected and shown in <ref type="figure" target="#fig_5">Figure 5</ref>. The user is asked to interact with the system to accomplish a specific goal. The system needs to find out the entity that satisfies the user's requirements. As exhibited in the case, the system actively communicates with the user to narrow down the scope of candidates and successfully returns the required information.</p><p>Despite the effectiveness on multiple conversational tasks, PLATO-2 still suffers from several limitations of general dialogue models, including factual error, logic inconsistency, toxic and biased language, and so on. Recently, some pioneering works have been proposed to alleviate these problems. For example, the knowledge provenance from Wikipedia is provided in the retrieval-augmented generation <ref type="bibr" target="#b15">(Lewis et al. 2020)</ref>. Some recipes are explored and discussed to increase the safety in open-domain chatbots . Future work will be carried out along these directions to boost the model's capacity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Related works will be discussed on pre-trained dialogue generation models and task-oriented dialogue systems.</p><p>Pre-trained language models have brought significant breakthroughs in natural language processing <ref type="bibr" target="#b4">(Devlin et al. 2019;</ref><ref type="bibr" target="#b17">Radford et al. 2019;</ref><ref type="bibr" target="#b3">Brown et al. 2020)</ref>. To boost the performance of dialogue generation, DialoGPT ) is trained on the basis of GPT-2 <ref type="bibr" target="#b17">(Radford et al. 2019)</ref> using Reddit comments. To obtain a human-like chatbot, Meena <ref type="bibr" target="#b0">(Adiwardana et al. 2020</ref>) utilizes more social media conversations and scales up the network to 2.6B parameters. To strengthen the desirable conversational skills, Blender <ref type="bibr" target="#b19">(Roller et al. 2020</ref>) further fine-tunes the pre-trained model with human-annotated conversations. To tackle the one-tomany mapping problem, PLATO-2 <ref type="bibr" target="#b2">(Bao et al. 2020b</ref>) encodes discrete latent variable into the network and achieves new state-of-the-art results in open-domain conversations. In this work, we demonstrate that the one-to-many mapping models of PLATO-2 can be applied effectively on both opendomain conversation and knowledge grounded dialogue.</p><p>For task-oriented dialogue systems, conventional approaches <ref type="bibr" target="#b24">(Young et al. 2013;</ref><ref type="bibr" target="#b12">Henderson, Thomson, and Williams 2014;</ref><ref type="bibr" target="#b21">Wen et al. 2015)</ref> usually adopt pipeline modules, including natural language understanding (NLU), dialogue state tracking (DST), dialogue policy, and natural language generation (NLG). Recently, some end-to-end neural models <ref type="bibr" target="#b22">(Wen et al. 2017;</ref><ref type="bibr" target="#b11">Ham et al. 2020;</ref><ref type="bibr" target="#b16">Peng et al. 2020</ref>) have been introduced for task-oriented dialogue systems. The end-to-end system (Ham et al. 2020) remains the core concepts of pipeline and generates the dialogue state, system action, and system response simultaneously. In this work, we demonstrate that the one-to-one mapping model of PLATO-2 can be adopted as a powerful basis. With enhanced entity representation and active clarification, PLATO-2 achieves new state-of-the-art results in task-oriented conversation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we explore the application of PLATO-2 on various dialogue systems, including open-domain chit-chat, knowledge grounded dialogue, and task-oriented conversation. The training of PLATO-2 is carried out via two-stage curriculum learning. In the first stage, the network tries to fit the simplified one-to-one mapping between the dialogue context and response. In the second stage, the discrete latent variable is encoded into the network for the one-to-many mapping modeling. One fine-grained generation and one evaluation model are further learned for diverse response generation and coherence estimation. The model in the first stage is applicable to task-oriented conversation, while those models in the second stage are suitable for open-domain conversation and knowledge grounded dialogue. Comprehensive evaluations in DSTC9 demonstrate that PLATO-2 is an effective unified pre-training framework for conversational AI.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Toy example to show the one-to-one mapping (gray line) and one-to-many mapping (blue dashed lines) in open-domain conversations. Left: dialogue context; Right: candidate responses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>PLATO-2 illustration. (a) Network overview with the details of transformer blocks. (b) Curriculum learning process with self-attention visualization and training objectives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>One example of knowledge grounded dialogue from Persona-Chat.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Case analysis on open-domain conversation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Case analysis on task-oriented conversation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Transformer Block ? 1Transformer Block</figDesc><table><row><cell>? +</cell><cell>? ,</cell><cell>? -</cell><cell>? .</cell><cell>? /</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BOW</cell><cell>NLL</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>?$</cell><cell>??</cell><cell>??</cell></row><row><cell></cell><cell cols="4">Transformer Block L</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Feed Forward</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Transformer Blocks</cell></row><row><cell></cell><cell></cell><cell>?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Transformer Block 2</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Layer Norm</cell><cell></cell><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell></cell><cell cols="4">Transformer Block 1</cell><cell></cell><cell></cell><cell></cell><cell cols="2">?</cell><cell>Latent</cell><cell cols="2">Context</cell><cell cols="2">Response</cell><cell>Latent</cell><cell>Context</cell><cell>Response</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Multi-Head Attention</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">? ( | , )</cell></row><row><cell></cell><cell cols="3">Token Embedding</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Segment Embedding</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Layer Norm</cell><cell></cell><cell cols="3">Transformer Block</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Position Embedding</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Transformer Blocks</cell></row><row><cell>+</cell><cell>,</cell><cell>-</cell><cell>.</cell><cell>/</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Transformer Block ? 1</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[M ]</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>[M]</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">(a) Network Overview</cell><cell></cell><cell></cell><cell>Latent</cell><cell cols="2">Context</cell><cell cols="2">Response</cell><cell>Latent</cell><cell>Context</cell><cell>Response</cell></row><row><cell>( | )</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NLL</cell><cell></cell><cell cols="2">( &amp; | , )</cell><cell></cell><cell></cell><cell></cell><cell>RCE</cell><cell>MLM</cell></row><row><cell cols="4">Transformer Block</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>??</cell><cell>??</cell><cell></cell><cell cols="3">Transformer Block</cell><cell></cell><cell>?'()</cell><cell>?[*] ?[*]</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Transformer Blocks</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Transformer Blocks</cell></row><row><cell cols="4">Transformer Block ? 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Transformer Block ? 1</cell><cell></cell><cell></cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell></cell><cell></cell><cell>?</cell><cell></cell><cell>?</cell><cell>[M]</cell><cell>[M]</cell><cell>?</cell></row><row><cell cols="2">Context</cell><cell></cell><cell cols="2">Response</cell><cell></cell><cell>Context</cell><cell></cell><cell cols="2">Response</cell><cell></cell><cell cols="2">Context</cell><cell cols="2">Response</cell><cell></cell><cell>Context</cell><cell>Response</cell></row><row><cell cols="5">Self-attention Visualization</cell><cell></cell><cell cols="3">Training Objectives</cell><cell></cell><cell cols="5">Self-attention Visualization</cell><cell cols="2">Training Objectives</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Human evaluation results on Track3-task2 interactive open-domain conversations, with the best value written in bold.</figDesc><table><row><cell>Rank</cell><cell>Team ID</cell><cell>Best Spec #</cell><cell>Average Success Rate</cell><cell>Success Rate w/ DB Grounding</cell><cell>Success Rate w/o DB Grounding</cell><cell>Language Understanding Score</cell><cell>Response Appropriateness Score</cell><cell>Turns</cell></row><row><cell>1</cell><cell>1 (Ours)</cell><cell>Submission5</cell><cell>74.8</cell><cell>70.2</cell><cell>79.4</cell><cell>4.54</cell><cell>4.47</cell><cell>18.5</cell></row><row><cell>1</cell><cell>2</cell><cell>Submission1</cell><cell>74.8</cell><cell>68.8</cell><cell>80.8</cell><cell>4.51</cell><cell>4.45</cell><cell>19.4</cell></row><row><cell>3</cell><cell>7</cell><cell>Submission4</cell><cell>72.3</cell><cell>62.0</cell><cell>82.6</cell><cell>4.53</cell><cell>4.41</cell><cell>17.1</cell></row><row><cell>4</cell><cell>6</cell><cell>Submission1</cell><cell>70.6</cell><cell>60.8</cell><cell>80.4</cell><cell>4.41</cell><cell>4.41</cell><cell>20.1</cell></row><row><cell>5</cell><cell>3</cell><cell>Submission3</cell><cell>67.8</cell><cell>60.0</cell><cell>75.6</cell><cell>4.56</cell><cell>4.42</cell><cell>21.0</cell></row><row><cell>N/A</cell><cell>Baseline</cell><cell>Baseline</cell><cell>69.6</cell><cell>56.8</cell><cell>82.4</cell><cell>4.34</cell><cell>4.18</cell><cell>18.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Human evaluation results on Track3-task1 static knowledge grounded dialogues, with the best value written in bold.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Automatic evaluation results on Track2-task1 end-to-end task-oriented conversations, with the best value written in bold.</figDesc><table><row><cell cols="3">PLATO-2 w/o explicit knowledge</cell><cell>1</cell><cell>4.2814</cell><cell>2.8746</cell><cell>2.8542</cell><cell>2.5627</cell><cell cols="2">2.8814</cell><cell>2.6678</cell><cell>2.8780</cell><cell>0.9932</cell><cell>2.9119</cell></row><row><cell cols="3">PLATO-2 w/ explicit knowledge</cell><cell>1</cell><cell>4.2804</cell><cell>2.8142</cell><cell>2.8480</cell><cell>2.5439</cell><cell cols="2">2.8682</cell><cell>2.6520</cell><cell>2.8682</cell><cell>0.9966</cell><cell>2.8885</cell></row><row><cell cols="3">final-results-test-plato-best-1004</cell><cell>1</cell><cell>4.2799</cell><cell>2.8396</cell><cell>2.8703</cell><cell>2.5631</cell><cell cols="2">2.8976</cell><cell>2.6860</cell><cell>2.9147</cell><cell>0.9966</cell><cell>2.9147</cell></row><row><cell cols="2">nofact-data-finetune</cell><cell></cell><cell>4</cell><cell>4.2603</cell><cell>2.8185</cell><cell>2.8082</cell><cell>2.6062</cell><cell cols="2">2.8493</cell><cell>2.6849</cell><cell>2.8048</cell><cell>1.0000</cell><cell>2.9075</cell></row><row><cell cols="3">dialogpt-fact-dialogrpt-v0</cell><cell>5</cell><cell>4.2526</cell><cell>2.8601</cell><cell>2.8771</cell><cell>2.5768</cell><cell cols="2">2.8703</cell><cell>2.7167</cell><cell>2.9044</cell><cell>0.9966</cell><cell>2.9078</cell></row><row><cell>Rank</cell><cell cols="2">Team ID</cell><cell></cell><cell>Best Spec #</cell><cell>Success Rate</cell><cell></cell><cell>Complete Rate</cell><cell></cell><cell>Book Rate</cell><cell cols="2">Inform P/R/F1</cell><cell>Turn (succ/all)</cell></row><row><cell>1</cell><cell cols="2">1 (Ours)</cell><cell></cell><cell>Submission3</cell><cell>93.0</cell><cell></cell><cell>95.2</cell><cell></cell><cell>94.6</cell><cell cols="2">84.1 / 96.2 / 88.1</cell><cell>12.5 / 12.7</cell></row><row><cell>2</cell><cell></cell><cell>2</cell><cell></cell><cell>Submission5</cell><cell>91.4</cell><cell></cell><cell>96.9</cell><cell></cell><cell>96.2</cell><cell cols="2">80.2 / 97.3 / 86.0</cell><cell>15.3 / 15.7</cell></row><row><cell>3</cell><cell></cell><cell>3</cell><cell></cell><cell>Submission1</cell><cell>90.8</cell><cell></cell><cell>94.4</cell><cell></cell><cell>96.7</cell><cell cols="2">81.0 / 95.4 / 85.9</cell><cell>13.4 / 13.6</cell></row><row><cell>4</cell><cell></cell><cell>4</cell><cell></cell><cell>Submission2</cell><cell>89.8</cell><cell></cell><cell>94.6</cell><cell></cell><cell>96.3</cell><cell cols="2">72.4 / 96.0 / 80.1</cell><cell>15.1 / 15.8</cell></row><row><cell>5</cell><cell></cell><cell>5</cell><cell></cell><cell>Submission2</cell><cell>83.3</cell><cell></cell><cell>88.5</cell><cell></cell><cell>89.1</cell><cell cols="2">81.1 / 90.3 / 83.5</cell><cell>13.5 / 13.8</cell></row><row><cell>N/A</cell><cell cols="2">Baseline</cell><cell></cell><cell>Baseline</cell><cell>85.0</cell><cell></cell><cell>92.4</cell><cell></cell><cell>91.4</cell><cell cols="2">79.3 / 94.9 / 84.5</cell><cell>13.8 / 14.9</cell></row><row><cell>Rank</cell><cell>Team ID</cell><cell>Best Spec #</cell><cell></cell><cell>Average Success Rate</cell><cell cols="2">Success Rate w/ DB Grounding</cell><cell cols="2">Success Rate w/o DB Grounding</cell><cell cols="2">Language Understanding Score</cell><cell>Response Appropriateness Score</cell><cell>Turns</cell></row><row><cell>1</cell><cell>1 (Ours)</cell><cell>Submission5</cell><cell></cell><cell>74.8</cell><cell>70.2</cell><cell></cell><cell>79.4</cell><cell></cell><cell></cell><cell>4.54</cell><cell>4.47</cell><cell>18.5</cell></row><row><cell>1</cell><cell>2</cell><cell>Submission1</cell><cell></cell><cell>74.8</cell><cell>68.8</cell><cell></cell><cell>80.8</cell><cell></cell><cell></cell><cell>4.51</cell><cell>4.45</cell><cell>19.4</cell></row><row><cell>3</cell><cell>7</cell><cell>Submission4</cell><cell></cell><cell>72.3</cell><cell>62.0</cell><cell></cell><cell>82.6</cell><cell></cell><cell></cell><cell>4.53</cell><cell>4.41</cell><cell>17.1</cell></row><row><cell>4</cell><cell>6</cell><cell>Submission1</cell><cell></cell><cell>70.6</cell><cell>60.8</cell><cell></cell><cell>80.4</cell><cell></cell><cell></cell><cell>4.41</cell><cell>4.41</cell><cell>20.1</cell></row><row><cell>5</cell><cell>3</cell><cell>Submission3</cell><cell></cell><cell>67.8</cell><cell>60.0</cell><cell></cell><cell>75.6</cell><cell></cell><cell></cell><cell>4.56</cell><cell>4.42</cell><cell>21.0</cell></row><row><cell>N/A</cell><cell>Baseline</cell><cell>Baseline</cell><cell></cell><cell>69.6</cell><cell>56.8</cell><cell></cell><cell>82.4</cell><cell></cell><cell></cell><cell>4.34</cell><cell>4.18</cell><cell>18.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Case analysis on knowledge grounded dialogue.</figDesc><table><row><cell>Yes, on the job site it does. In the office, I just have to use my brain.</cell></row><row><cell>That's always good, the office is often times a stressful environment</cell></row><row><cell>It can be! It can also be very boring. That is why I'm chatting with a</cell></row><row><cell>bot right now</cell></row><row><cell>That makes sense, is it a robot that is chatting with you?</cell></row><row><cell>I'm not sure. What are you?</cell></row><row><cell>That's interesting, maybe we are both robots and are talking to each other</cell></row><row><cell>I'm not a robot. Sometime I wish I were.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Any one is ok I would recommend the acorn guest house . It is in the moderate price range and has 4 stars . It also has free parking and wifi . Would you like more information ? yes , please tell me the postcode The postcode is cb41da . Is there anything else I can help you with ?that's all . thank you You 're welcome , have a great day . You are looking for a place to stay. The hotel should be in the north. The hotel should include free parking.? The hotel should include free wifi.? Once you find a hotel, make sure you get postcode, stars.</figDesc><table><row><cell>Well i disagree, robots are more efficient.</cell></row><row><cell>Task Goal:</cell></row><row><cell>?</cell></row><row><cell>I need a hotel to stay in the north , it should have free parking</cell></row><row><cell>What price range would you like ?</cell></row><row><cell>I don't care the pricerange . it must have free wifi</cell></row><row><cell>Would you like a guesthouse or a hotel ?</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Source code and pre-trained models are released at https:// github.com/PaddlePaddle/Knover/tree/develop/projects/PLATO-2. arXiv:2105.02482v2 [cs.CL] 27 May 2021</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">End-to-end Task-oriented ConversationConventional task-oriented dialogue systems usually adopt the pipeline architecture, including natural language understanding (NLU), dialogue state tracking (DST), dialogue policy, and natural language generation (NLG) modules. Recently, some works<ref type="bibr" target="#b11">(Ham et al. 2020;</ref><ref type="bibr" target="#b16">Peng et al. 2020</ref>) have</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the reviewers for their constructive suggestions; Jingzhou He, and Tingting Li for the help on resource coordination; Gaopeng Yong, Liankai Huang, and Hua Lu for their generous help. This work was supported by the Natural Key Research and Development Project of China (No. 2018AAA0101900).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Adiwardana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nemade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.09977</idno>
		<title level="m">Towards a Human-like Open-Domain Chatbot</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="85" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16779</idno>
		<title level="m">Towards Building an Open-Domain Chatbot via Curriculum Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<title level="m">Language Models are Few-Shot Learners</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Wizard of Wikipedia: Knowledge-Powered Conversational Agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unified Language Model Pre-training for Natural Language Understanding and Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Hon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="13063" to="13075" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">MultiWOZ 2.1: A Consolidated Multi-Domain Dialogue Dataset with State Corrections and State Tracking Baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 12th Language Resources and Evaluation Conference</title>
		<meeting>The 12th Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="422" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hierarchical Neural Story Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="889" to="898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural Approaches to Conversational AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1371" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hedayatnia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gottardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-T?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual Conference of the International Speech Communication Association</title>
		<meeting>the 20th Annual Conference of the International Speech Communication Association</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1891" to="1895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Endto-End Neural Pipeline for Goal-Oriented Dialogue Systems using GPT-2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gunasekara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Haro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hedayatnia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-T?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shayandeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Traum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beirami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Eunjoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Cho; Crook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geramifard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poddar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Subba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-E</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.06486</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="583" to="592" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Overview of the Ninth Dialog System Technology Challenge: DSTC9</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Second Dialog State Tracking Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Categorical Reparameterization with Gumbel-Softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Retrieval-augmented generation for knowledge-intensive nlp tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>K?ttler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rockt?schel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shayandeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.05298</idno>
		<title level="m">SOLOIST: Few-shot Task-Oriented Dialog with A Single Pre-trained Auto-regressive Model</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Language Models are Unsupervised Multitask Learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>OpenAI</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">How Much Knowledge Can You Pack Into the Parameters of a Language Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5418" to="5426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13637</idno>
		<title level="m">Recipes for building an open-domain chatbot</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semantically Conditioned LSTMbased Natural Language Generation for Spoken Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrk?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1711" to="1721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Network-based End-to-End Trainable Task-oriented Dialogue System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrk?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M R</forename><surname>Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="438" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.07079</idno>
		<title level="m">Recipes for Safety in Open-domain Chatbots</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">POMDP-Based Statistical Spoken Dialog Systems: A Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ga?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="1160" to="1179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Personalizing Dialogue Agents: I have a dog, do you have pets too?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2204" to="2213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="270" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">DialPort: Connecting the Spoken Dialog Research Community to Real User Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Spoken Language Technology Workshop</title>
		<imprint>
			<biblScope unit="page" from="83" to="90" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="654" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and Diagnosing Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Takanobu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="142" to="149" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
