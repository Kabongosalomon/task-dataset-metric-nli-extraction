<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">OCD: LEARNING TO OVERFIT WITH CONDITIONAL DIFFUSION MODELS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahar</forename><surname>Lutati</surname></persName>
							<email>shahar761@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
							<email>wolf@cs.tau.ac.il</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering The Faculty of Engineering</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Mentee Robotics LTD</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">the Blavatnik School of Computer Science</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">OCD: LEARNING TO OVERFIT WITH CONDITIONAL DIFFUSION MODELS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a dynamic model in which the weights are conditioned on an input sample x and are learned to match those that would be obtained by finetuning a base model on x and its label y. This mapping between an input sample and network weights is shown to be approximated by a linear transformation of the sample distribution, which suggests that a denoising diffusion model can be suitable for this task. The diffusion model we therefore employ focuses on modifying a single layer of the base model and is conditioned on the input, activations, and output of this layer. Our experiments demonstrate the wide applicability of the method for image classification, 3D reconstruction, tabular data, and speech separation. Our code is available at https://github.com/ ShaharLutatiPersonal/OCD.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>"Here is a simple local algorithm: For each testing pattern, (1) select the few training examples located in the vicinity of the testing pattern, (2) train a neural network with only these few examples, and (3) apply the resulting network to the testing pattern." <ref type="bibr">Bottou &amp; Vapnik (1992)</ref> Thirty years after the local learning method in the epigraph was introduced, it can be modernized in a few ways. First, instead of training a neural network from scratch on a handful of samples, the method can finetune, with the same samples, a base model that is pretrained on the entire training set. The empirical success of transfer learning methods <ref type="bibr" target="#b7">(Han et al., 2021)</ref> suggests that this would lead to an improvement. Second, instead of retraining a neural network each time, we can learn to predict the weights of the locally-trained neural network for each input sample. This idea utilizes a dynamic, input-dependent architecture, also known as a hypernetwork <ref type="bibr" target="#b6">(Ha et al., 2016)</ref>.</p><p>Third, we can take the approach to an extreme and consider local regions that contain a single sample. During training, we finetune the base model for each training sample separately. In this process, which we call "overfitting", we train on each specific sample s = (x, y) from the training set, starting with the weights of the base model and obtaining a model f ?s . We then learn a model g that maps between x (without the label) and the shift in the weights of f ?s from those of the base model. Given a test sample x, we apply the learned mapping g to it, obtain model weights, and apply the resulting model to x.</p><p>The overfitted models are expected to be similar to the base model, since the samples we overfit are part of the training set of the base model. We provide theoretical arguments that support that the mapping from the x part of s to f ?s can be approximated by a locally convex transformation. As a result, it is likely that a diffusion process that is able to generate samples in the domain of x would also work for generating the weights of the fine-tuned networks. Recently, diffusion models, such as DDPM <ref type="bibr" target="#b41">(Song et al., 2020b)</ref> and DDIM <ref type="bibr" target="#b40">(Song et al., 2020a)</ref> were shown to be highly successful in generating perceptual samples <ref type="bibr" target="#b3">(Dhariwal &amp; Nichol, 2021b;</ref><ref type="bibr" target="#b15">Kong et al., 2021)</ref>. We, therefore, employ a conditional diffusion model to model g.</p><p>In order to make the diffusion models suitable for predicting network weights, we make three adjustments. First, we select a specific layer of the neural model and modify only this layer. This considerably reduces the size of the generated data and, in our experience, is sufficient for supporting the overfitting effect. Second, we condition the diffusion process on the input of the selected layer, its activations, and its output. Third, since the diffusion process assumes unit variance scale <ref type="bibr" target="#b41">(Song et al., 2020b)</ref>, we separately learn the scale of the weight modification.</p><p>Our method is widely applicable, and we evaluate it across four very different domains: image classification, image synthesis, regression in tabular data, and speech separation. In all cases, the results obtained by our method improve upon the non-local use of the same underlying architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Local learning <ref type="bibr">Bottou &amp; Vapnik (1992)</ref> have presented a simple algorithm for adjusting the capacity of the learned model locally, and discuss the advantages of such models for learning with uneven data distributions. <ref type="bibr" target="#b0">Alpaydin &amp; Jordan (1996)</ref> combine multiple local perceptrons in either a cooperative or a discriminative manner, and <ref type="bibr" target="#b49">Zhang et al. (2006)</ref> combine multiple local support vector machines. These and other similar contributions rely on local neighborhoods containing multiple samples. The one-shot similarity kernel of <ref type="bibr" target="#b47">Wolf et al. (2009)</ref> contrasts a single test sample with many training samples. We are unaware of any previous contribution that finetunes a model based on a single sample or any local learning approach that involves hypernetworks.</p><p>Hypernetworks <ref type="bibr" target="#b6">(Ha et al., 2016)</ref> are neural models that generate the weights of a second primary network, which performs the actual prediction task. Since the inferred weights are multiplied by the activations of the primary network, hypernetworks are a form of multiplicative interactions <ref type="bibr" target="#b10">(Jayakumar et al., 2020)</ref>, and extend layer-specific dynamic networks, which have been used to adapt neural models to the properties of the input sample <ref type="bibr" target="#b13">(Klein et al., 2015;</ref><ref type="bibr" target="#b31">Riegler et al., 2015)</ref>.</p><p>Hypernetworks benefit from the knowledge-sharing ability of the weight-generating network and are therefore suited for meta-learning tasks, including few-shot learning (Bertinetto et al., 2016), continual learning <ref type="bibr" target="#b45">(von Oswald et al., 2020)</ref>, and model personalization <ref type="bibr" target="#b36">Shamsian et al. (2021)</ref>. When there is a need to repeatedly train similar networks, predicting the weights can be more efficient than backpropagation. Hypernetworks have, therefore, been used for neural architecture search <ref type="bibr">(Brock et al., 2018;</ref><ref type="bibr" target="#b48">Zhang et al., 2019)</ref>, and hyperparameter selection <ref type="bibr" target="#b21">(Lorraine &amp; Duvenaud, 2018)</ref>. <ref type="bibr" target="#b26">Mitchell et al. (2021)</ref> explores the problem of model editing for large language models, in which the model's parameters are updated after training to incorporate new data. In our work, the goal is to predict the label of the new sample and not to update the model. Unlike MEND, our method does not employ the label of the new sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MEND by</head><p>Diffusion models Many of the recent generative models for images <ref type="bibr">Chen et al., 2020;</ref><ref type="bibr" target="#b2">Dhariwal &amp; Nichol, 2021a)</ref> and speech <ref type="bibr" target="#b15">(Kong et al., 2021;</ref><ref type="bibr">Chen et al., 2020)</ref> are based on a degenerate form of the Focker-Planck equation. <ref type="bibr" target="#b39">Sohl-Dickstein et al. (2015)</ref> showed that complicated distributions could be learnt using a simple diffusion process. The Denoising Diffusion Probablistic Models (DDPM) of <ref type="bibr" target="#b8">Ho et al. (2020)</ref> extend the framework and present high quality image synthesis. <ref type="bibr" target="#b42">Song et al. (2020c)</ref> sped up the inference time by an order of magnitude using implicit sampling with their DDIM method. <ref type="bibr" target="#b46">Watson et al. (2021)</ref> propose a dynamic programming algorithm to find an efficient denoising schedule and San-Roman et al. (2021) apply a learned scaling adjustments to the noise scheduling. <ref type="bibr" target="#b22">Luhman &amp; Luhman (2021)</ref> combined knowledge distillation with DDPMs.</p><p>The iterative nature of the denoising generation scheme creates an opportunity to steer the process, by considering the gradients of additional loss terms. The Iterative Latent Variable Refinement (ILVR) method <ref type="bibr" target="#b1">Choi et al. (2021)</ref> does so for images by directing the generated image toward a low-resolution template. A similar technique was subsequently employed for voice modification <ref type="bibr">Levkovitch et al. (2022)</ref>. Direct conditioning is also possible:  generate photo-realistic text-to-image scenes by conditioning a diffusion model on text embedding; <ref type="bibr">Amit et al. (2021)</ref> repeatedly condition on the input image to obtain image segmentation. In voice generation, the mel-spectrogram can be used as additional input to the denoising network Chen et al.</p><p>(2020); <ref type="bibr" target="#b15">Kong et al. (2021)</ref>; , as can the input text for a text-to-speech diffusion model <ref type="bibr" target="#b29">Popov et al. (2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM SETTING AND ANALYSIS</head><p>We are given a dataset S of samples x i ? X , for i = 1..n, and the associated labels y i ? Y sampled i.i.d from some distribution P X?Y over the composite domain X ? Y. We consider prediction models f : X ? ? ? Y that are parameterized by weight vectors in the domain ?. Specifically, we first learn a base model f ? (x) = f (x, ?), which is trained over the entire training set S.</p><p>For every sample s ? P X?Y , we further consider a finetuned version of f ? that is optimized to overfit on the sample s = (x, y) , i.e., we minimize the loss of the single sample s, initializing the optimization process with ?. We denote the obtained parameters as ? s ? ? and the obtained network as f ?s . Naturally, the prediction error of f ?s on the sample s is expected to be small, improving upon that f ? for that specific sample.</p><p>The meta-learning problem we consider is the one of learning a model g, that maps x (the input domain of sample s) and potentially multiple latent representations of x in the context of f ? , collectively denoted as I(x), to a vector of weight differences, such that the following loss is minimized</p><formula xml:id="formula_0">L(s) = M SE(? s , ? + g(x, I(x))) ,<label>(1)</label></formula><p>where M SE is the mean squared error. If g generalizes well to unseen samples s * = (x * , y * ), we would expect f (x * , ? + g(x * , I(x * ))) to be a better prediction of y * than f (x * , ?).</p><p>We rewrite the mapping function g(x, I(x)) as a unit-norm component g u (x, I(x)), and a scale factor ?(x, I(x)), i.e.,</p><formula xml:id="formula_1">g(x, I(x)) = ?(x, I(x)) ? g u (x, I(x)) , where (2) ||g u (x, I(x))|| 2 = 1<label>(3)</label></formula><p>Denote the mapping between a sample s = (x, y) and ?s?? ||?s??|| as H : Next, we provide two theoretical arguments without concrete quantization. First, following <ref type="bibr" target="#b14">Kleinberg et al. (2018)</ref>, if ? is near a local minima or an inflection point of the finetuning loss, then ? s would converge to this point and H(s + ?s) is expected to be convex.</p><formula xml:id="formula_2">X ? Y ? ?. Let H 1 : X ? Y ? X ? Y ? ? be</formula><p>Second, since ? is obtained via an SGD optimization process over a sample from the distribution P X?Y , and since s ? P X?Y , it is near either a local minima or an inflection point for the training loss of finetuning with sample s. See, for example, <ref type="bibr" target="#b14">Kleinberg et al. (2018)</ref>.</p><p>Combining the two claims, we can expect H to be locally convex. Lemma 1. Since H is locally convex, it follows that the distribution P H1(s) in the domain ? obtained when applying H 1 to samples s ? P X?Y takes the following form:</p><formula xml:id="formula_3">P H1(s) = P X?Y (H 1 ?1 (s) ? s)|det(H ?1 1 )| ,<label>(4)</label></formula><p>where</p><formula xml:id="formula_4">H ?1 1 (s) : (X ? Y ? ?) ? (X ? Y)</formula><p>is the pseudoinverse of the tensor H 1 (s) (first we compute H 1 at given s, and then compute the tensor pseudoinverse).</p><p>Proof. For any random variable r, and a mapping function M that is monotonic and with a countable number of zeros, the following holds <ref type="bibr" target="#b33">(Rosenblatt (1974)</ref>):</p><formula xml:id="formula_5">P M (r) = P r (M ?1 (r))| dM ?1 (r) dr |<label>(5)</label></formula><p>Where M ? 1 is the pseudoinverse of M . From the local convexity of H, we have that its' Hessian is nonnegative.</p><formula xml:id="formula_6">H is locally convex ? ? 2 H(s + ?s) ? 0; ??s ? 0<label>(6)</label></formula><p>Recall that the Hessian of H is the gradient of H 1 , thus its gradient is non-negative, leading to monotonicity.</p><formula xml:id="formula_7">H 1 (s) = ?H(s) ? ?H 1 (s) = ? 2 H(s) (7) ?H 1 (s) ? 0 (8) In addition, since H 1 is a linear operator with finite size, it must have a finite dimension of null space. Ker(H 1 ) ? dim(H 1 ) ,<label>(9)</label></formula><p>where Ker is the tensor null space, dim is the tensor dimensions. This fulfils the second condition of the mapping function having countable number of zeros.</p><p>Therefore, the distribution of H 1 is a linear transformation of the distribution of s. <ref type="bibr" target="#b41">Song et al. (2020b)</ref> showed that a diffusion process is suitable for estimating samples from complicated sample distributions. Assume that there exists a diffusion process, with weights ?, over the sample distribution, such that the variational bound is maximized</p><formula xml:id="formula_8">max ? E q (log(p ? (x 0:T )) ? log(q(x 1:T |x 0 ))) ,<label>(10)</label></formula><p>where p ? is the model distribution, q(x 0 ) is the data distribution, and x 0:T forms a Markov chain. From Lemma. 1 we have that the image of the distribution of H 1 is contained in the image of q, with the same input set. Thus, if a diffusion model has the capacity to capture q, it will also capture H 1 , which is a subset of q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHOD</head><p>Our method is based on a modified diffusion process. Recall that we denote the training dataset as</p><formula xml:id="formula_9">S = {(x i , y i )} n i=1</formula><p>, and the overfitted parameters (function) for a specific sample s as ? s (f ?s ). In our method, ? s = ? + g(x, I(x)), where ? are the base model's parameters which are trained over S, and g(x, I(x)) is a mapping function that maps the input, i.e., the x part of s, and multiple latent representations of it, I(x), to the desired shift in the model parameters.</p><p>Layer selection Current deep neural networks can have millions or even billions of parameters. Thus, learning to modify all network parameters can be a prohibitive task. Therefore, we opt to modify, via function g, on a single layer of f ? .</p><p>To select this layer, we follow <ref type="bibr" target="#b23">Lutati &amp; Wolf (2021)</ref> and choose the layer that presents the maximal entropy of the loss, when fixing the samples s, and perturbing the layer's parameters. Denote the perturbed weights, in which only layer L is perturbed, as ? L . The score used for selection is</p><formula xml:id="formula_10">(x,y)?S Entropy ? L (L(f (x, ? L ), y)) ,<label>(11)</label></formula><p>where L is the loss objective on which the function of f ? is trained on, and the entropy is computed over multiple draws of ? L . The entropy is computed by fitting a Gaussian Kernel Density Estimation (GKDE) <ref type="bibr" target="#b37">(Silverman, 1986)</ref> to the obtained empirical distribution of the loss function. Since sampling does not involve a backpropagation computation, the process is not costly, so 10, 000 samples are used.</p><p>The conditioning signal The latent representations, I(x), has three components. Given a selected layer, L, we denote the input to this layer (when passing a sample x to f (x, ?)), as i L (x) and the activation of this layer as a L (x). We also use the output of the base function f ? (x). I(x) is, therefore, the tuple</p><formula xml:id="formula_11">I(x) = [i L (x), a L (x), f ? (x)]<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">DIFFUSION PROCESS</head><p>The diffusion goal is to reconstruct the mapping function g u (x, I(x)). The process iteratively starts a random ? T , iterates with ? t , where t is decreasing and is the diffusion step, and returns ? 0 .</p><p>The diffusion error estimation network, ? is a function of the current estimation, ? t , the latent representation tuple, I(x), and the diffusion timestep, t. The latter is encoded through a positional  = N (0, 1) 10:</p><formula xml:id="formula_12">? t = 10 ?4 (T ?t)+10 ?2 (t?1) T ?1 ,? t = 1 ? ? t ,? t = ? k=t k=0 ? k 11</formula><p>:</p><formula xml:id="formula_13">? t = ?? t ? norm s + 1 ?? t 2 12:</formula><p>Take a gradient step on ?|| ? ? (? t , (I(x), t))||, updating ? , P E and the components of I 13: until || ? ? (? t , (I(x), t))|| converges encoding network <ref type="bibr" target="#b44">(Vaswani et al., 2017)</ref>, P E. All inputs, except for ? t are combined into one vector: e = P E(t)</p><formula xml:id="formula_14">+ E i (i L ) + E a (a L ) + E o (f ? (x)), where E i , E a , E<label>o</label></formula><p>are the encodings of the layer input, layer activations and network output. Note that most of the components of e do not change during the diffusion process, and can be computed only once. This way, the conditioning overhead is reduced to minimum. The conditional diffusion process is depicted in <ref type="figure">Fig 1.</ref> Training Phase The complete training procedure of ? is depicted in Alg. 1. The first phase is overfitting, using simple gradient decent over a single input-output pair, see line 5. The overfitting phase is not demanding, since the backpropagation is conducted only over the selected layer and a single sample.</p><p>As stated in Sec. 4.2, while regular diffusion assumes that the input has unit variance, when estimating network weights, scaling has a crucial impact. This normalization ensures that the diffusion is trained over unit-variance input. We denote by ? norm s the normalized difference between ? s and the parameters ? of the base model (line 7).</p><p>Following <ref type="bibr" target="#b40">Song et al. (2020a)</ref>, linear scheduling is used for the diffusion process, and ? t , ? t ,? t ,? t are set in line 10. A training example is then sampled:</p><formula xml:id="formula_15">? t = ?? t ? norm s + 1 ?? t 2 ,<label>(13)</label></formula><p>where ? N (0, 1) is normal noise. Since our goal is to recover the noiseless ? norm s , the objective is || ? ? (? t , (I(x), t))|| (14) A gradient step is taken in order to optimize this objective, see line. 12.</p><p>Inference Phase Given an unseen input x, I(x) is computed using the base network f (x, ?) and is used for all calls to the diffusion network ? . The exact diffusion steps are depicted in Alg. 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SCALE ESTIMATION</head><p>The Evidence Lower Bound (ELBO) used in <ref type="bibr" target="#b41">Song et al. (2020b)</ref> assumes that the generated data has unit variance. In our case, in which the generated data reflects a difference in the layer's weights, the scale of the data presents considerable variation. Naturally, shifting the weights of a network by some vector d or by some scale times d can create a significant difference.</p><p>We, therefore, as indicated in Eq. 2, use an MLP network ?(x, I(x)) to estimate the appropriate scale factor, based on the same conditioning signal that is used for the network ? that implements g u as a diffusion process.</p><p>When learning network ?, the following objective function is used <ref type="figure">Figure 1</ref>: The diffusion process. x is the input of the base network, f ? (x). I(x) is a tuple of latent representations of x. E i ,E a , and E o are the input, activation, and output encoders, respectively, of the selected layer that is being modified. t is the diffusion step, and ? t is the current diffusion estimation.</p><formula xml:id="formula_16">L scale = s=(x,y)?S 10 ? log 10 ( |?(x, I(x)) ? ? s | 2 ? s ) ,<label>(15)</label></formula><p>Algorithm 2 Inference Algorithm.</p><p>Input: x input sample, ? the parameters of the base network, ? diffusion network, T diffusion steps. Output: g u (x, I(x)) estimated normalized (? s ??) for s associates with x.</p><formula xml:id="formula_17">1: t = T 2: = N (0, 1) 3: while t ? 0 do 4: ? t = 10 ?4 (T ?t)+10 ?2 (t?1) T ?1 , ? t = 1 ? ? t , ? t = ? k=t k=0 ? k ,? t = 1??t?1 1??t ? t 5</formula><p>:</p><formula xml:id="formula_18">? t?1 = ?t? 1?? t ? 1?? t ? (?t,I(x),t) ? ?t + 1 t&gt;1 ? t 6: t = t ? 1 7: end while 8: return ? 0 where ? s = ||? s ? ?||.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">ARCHITECTURE</head><p>The network ? is a U-Net <ref type="bibr" target="#b32">(Ronneberger et al., 2015)</ref>, following <ref type="bibr" target="#b41">Song et al. (2020b)</ref>. Each resolution level has residual blocks, and an attention layer. The bottleneck contains two attention layers.</p><p>The positional encoder is composed of stacked sine and cosine encodings, following <ref type="bibr" target="#b44">Vaswani et al. (2017)</ref>. The encoders of i L , a L are both single fully-connected layers, with dimensions to match the positional embedding. The encoder of the base network's output f ? (x) depends on the output type. In the case of a classification network, where the output is a vector in R C , where C is the number of classes, the encoder E O is a single fully-connected layer. In the case of image generation, the output image is first encoded using a VGG11 encoder <ref type="bibr" target="#b38">(Simonyan &amp; Zisserman, 2014)</ref>, and then the latent representation is passed through a single fully-connected layer, again matching the dimension of the positional encoder. For speech separation, the estimated speech is first transformed to a spectogram with 1024 bins of FFT, then encoded using the same VGG11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In all experiments the UNet ? has 128 channels and five downsampling layers. The Adam optimizer <ref type="bibr" target="#b12">(Kingma &amp; Ba, 2014)</ref>, with a learning rate of 10 ?4 , is used. A linear noise schedule is used based on <ref type="bibr" target="#b40">Song et al. (2020a)</ref>, and the number of diffusion steps is 10. All experiments are repeated three times to report the standard deviation (SD) of the success metrics.</p><p>In addition to the full method, we also show results for the network that overfits on the test data, which serves as an upper bound that cannot be applied without violating the train/test protocol. On some datasets we check to what extent selecting a single layer limits our results, by performing the overfitting process on all of the model weights. On all datasets, we ablate the scale component of our "Overfit with Conditional Diffusion models" (OCD) method, by estimating a fixed global scale factor? = E s?S (? s ) as the mean value of the scale factor ? s over the train-set. An additional ablation selects the model f ?s of the training sample s with the closest x to the test sample. This "nearest neighbor" ablation can be seen as the simplest way to implement the concept of OCD. Finally, we present an ablation that selects the layer with the second highest layer selection score, to evaluate the significance of the selection criterion.</p><p>Image Classification Results for the MNIST dataset <ref type="bibr">(LeCun &amp; Cortes, 2010)</ref> are obtained with the LeNet5 architecture <ref type="bibr" target="#b17">(Lecun et al., 1998)</ref>. The selected layer is the one next to the last fully connected layer, which, as can be seen in <ref type="figure" target="#fig_2">Fig. 2(a)</ref> has the maximal entropy among LeNet5's layers. CIFAR10 images <ref type="bibr" target="#b16">(Krizhevsky et al., 2009</ref>) are classified using GoogleNet <ref type="bibr" target="#b43">(Szegedy et al., 2014)</ref>. The selected layer was the last fully-connected layer, see <ref type="figure" target="#fig_2">Fig. 2(b)</ref>. For both architectures, the three encoders E Li , E Lo , E O are simple fully-connected layers, with dimensions to match the number of channels in the UNet (128).</p><p>For classification experiments we measure both the cross entropy (evaluted on the test set) and the test accuracy. As can seen in Tab. 1, our method reduces the CE loss by a factor of 8 in comparison to the base network and there is a improvement of 0.5% in accuracy. Ablating the scale prediction, the results considerably degrade in comparison to the full method. The Nearest-Neighbor ablation yields slightly better results than the base network. The ablation that selects an alternative layer results in performance that is similar or slightly better than the base network. This is congruent with the small difference between fitting the selected layer and fitting all layers, which may suggest that much of the benefit of overfitting occurs in the selected layer.</p><p>On CIFAR10, our method improves classification accuracy from 92.9% to 93.7%. As in MNIST, much of the improvement is lost when running the three ablations.</p><p>In both MNIST and CIFAR, when using the ground truth to overfit a specific example, the accuracy becomes, as expected, 100%. Considering the CE loss, overfitting the entire model instead of the selected layers yields only mild improvement (for MNIST below the standard deviation). This indicates that the added improvement gained by applying our method to all layers (and not just to the selected one) may not justify the additional resources required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image Synthesis</head><p>We further tested our method on the image generation task of novel view synthesis, using a NeRF architecture <ref type="bibr" target="#b25">(Mildenhall et al., 2020)</ref> and the "Synthetic-Blender" dataset. The Tiny-NeRF architecture employs an MLP network consisting of three fully-connected layers. The input is a 3D ray as a 5D coordinate (spatial location and viewing direction). The output is the corresponding emitted radiance. For each view, a batch of 4096 rays is computed, from which the interpolated image is synthesized.  0.052 ? 0.006 0.047 ? 0.004 0.057 ? 0.006</p><p>We experimented with three objects from the dataset: Lego, Hotdog, and Drums. For each object a different TinyNeRF base model is trained over the corresponding training set. A single overfitting example is produced by considering a batch of 4096 rays from the same viewpoint.</p><p>Based on the data in <ref type="figure" target="#fig_2">Fig. 2(c)</ref>, the first layer is selected. We, therefore, changed the layer-input encoder, E i , such that the input image is first encoded by the VGG-11 encoder of <ref type="bibr">Simonyan &amp; Zisserman (2014) (pretrained over ImageNet-1k)</ref>, followed by a fully-connected layer, to match the dimensions of UNet channels. The encoders E a , E o are simple fully-connected layers, with dimensions to match the number of channels in the UNet (128).</p><p>As can seen in Tab. 2, our method improves the MSE by 31% on the Lego model, by 25% for Hotdog, and 16% for Drums. Without input-dependent scaling, the performance is much closer to the base network than to that of our complete method. Sample test views are shown in <ref type="figure" target="#fig_3">Fig. 3</ref> for the Lego Model, <ref type="figure">Fig. 4</ref> for the Hotdog model, and <ref type="figure">Fig. 5</ref> for the Drums model. Evidently, our method improves both image sharpness and color palette, bringing the synthesized image closer to the one obtained by overfitting the test image.</p><p>Tabular Data <ref type="bibr" target="#b5">Gorishniy et al. (2021)</ref> have extensively benchmarked various architectures and tabular datasets. We use their simple MLP architecture as a base network (3 Layers). We were unable to reproduce the reported transformer, since the hyperparameters are not provided, and our resources did not allow us to run a neural architecture search, as <ref type="bibr" target="#b5">Gorishniy et al. (2021)</ref> did. We run on two of the benchmarks listed: California Housing Kelley Pace &amp; Barry (1997) (CA), which is the first listed and has the least number of samples, and Microsoft LETOR4.0(MI) <ref type="bibr" target="#b30">(Qin &amp; Liu, 2013)</ref>, which is the last listed and has the largest number of samples. <ref type="figure" target="#fig_2">Fig. 2(d)</ref> presents the layer selection criterion, with the first layer chosen for both datasets. As can seen in Tab. 3, for CA the base MLP model falls behind ResNet. Applying our method, the simple architecture achieves better results. For MI when applying our method, the simple baseline achieves a record MSE of 0.743, surpassing the current best record on this dataset, which is 0.745 <ref type="bibr" target="#b28">(Popov et al., 2020)</ref>. The ablation that removes input-dependent scaling degrades the performance of the base network, emphasizing the importance of accurate scaling per sample.</p><p>Speech Separation To tackle the task of single microphone speech separation of multiple speakers, <ref type="bibr" target="#b27">Nachmani et al. (2020)</ref> introduce the Gated-LSTM architecture with MulCat block and <ref type="bibr" target="#b4">Dovrat et al. (2021)</ref> introduced a permutation-invariant loss based on the Hungarian matching algorithm, using the same architecture. <ref type="bibr" target="#b24">Lutati et al. (2022)</ref> further improved results for this architecture, by employing an iterative method based on a theoretical upper bound, achieving state-of-the-art results.  13.4 ? 0.1</p><p>The same backbone and Hungarian-method loss are used in our experiments, which run on the Libri5Mix dataset without augmentations, measuring the SI-SDRi score. The selected layer was the projection layer of the last MulCat block <ref type="figure" target="#fig_2">(Fig. 2(e)</ref>). The output of the Gated-LSTM is the separated sounds, and to encode it, we apply the audio encoding described in Sec. 4.3 to each output channel separately and concatenate before applying the linear projection to R 128 .</p><p>As can seen in Tab. 4, applying our diffusion model over the Gated-LSTM model, achieves 13.4dB and surpasses current state-of-the-art results, and approaches the results obtained by overfitting on the test data. The ablation that removes input-dependent scaling is much closer in performance to the base network than to our complete method.</p><p>Limitations We show that the diffusion process outperforms a nearest neighbor selection of one of the finetuned networks from the training set. Future experiments could compare diffusion processes with other alternative hypernetwork generators. Similarly, for lack of resources and to prioritize domain diversity, we do not run our experiments on large scale datasets or very deep architectures. Given the wide applicability of OCD, our effort would benefit from large-scale runs. We also note that the method is not limited to supervised learning and can be readily applied to RL and various forms of unsupervised learning. This, too, is beyond the scope of the current effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We present what is, as far as we can ascertain, the first diffusion-based hypernetwork and show that learning the scale independently is required for best performance. The hypernetwork is studied in the specific context of local learning, in which a dynamic model is conditioned on a single input sample. This, too, seems to be a novel contribution. Using the diffusion architecture for the local learning task is justified by a first-order analysis of the change to a network's weights when performing limited finetuning.</p><p>The training samples for the hypernetwork are collected by finetuning a model on each specific sample from the training set used by the base model. By construction, this is only slightly more demanding than fitting the base model on the training set. More limiting is the size of the output of the hypernetwork, which for modern networks can be larger than the output dimensions of other diffusion processes. We, therefore, focus on a single layer, which is selected as the one that is most affected by weight perturbations. We extensively tested our method, tackling a very diverse set of tasks, using the same set of hyperparameters.</p><p>We are yet to find a single dataset or architecture on which our OCD method does not significantly improve the results of the baseline architecture.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>the linear approximation of the operator H, i.e., H(s + ?s) = H(s) + H 1 (s) ? ?s + O(?s ? ?s), where ? denotes the tensor product along the sample dimensions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>step on ?L(y, f ?s (x)), updating ? s</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Layer Selection Criterion for different experiments. (a) For LeNet5 on MNIST, the next to last Fully-Connected layer is selected since it has the maximal entropy. (b) For GoogleNet on CIFAR10, the last Fully-Connected layer is selected. (c) For TinyNeRF (three datasets), the first Fully-Connected layer is selected. (d) For Tabular MLP the first layer is selected. (e) For MulCat the last projection layer is selected.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Sample TinyNeRF results on the Lego model. (a) Base model on a test view. (b) Same test view, overfitted using the ground truth (c) OCD (ours).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Sample TinyNeRF results on the Hotdog model. (a) Base model on a test view. (b) Same test view, overfitted using the ground truth (c) OCD (ours). Sample TinyNeRF results on the Drums model. (a) Base model on a test view. (b) Same test view, overfitted using the ground truth (c) OCD (ours).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Algorithm 1 Training Algorithm. Input: S training set, ? base network parameters, L the loss of the primary task, T diffusion steps Output: ? diffusion network (including E i ,E a , and E o ).</figDesc><table><row><cell cols="2">1: repeat</cell></row><row><cell>2:</cell><cell>sample (x, y) ? S</cell></row><row><cell>3:</cell><cell>? s = ?</cell></row><row><cell>4:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Performance on classification tasks.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">CE=Cross Entropy</cell><cell></cell></row><row><cell></cell><cell cols="2">MNIST (LeNet5)</cell><cell cols="2">CIFAR10 (GoogleNet)</cell></row><row><cell>Method</cell><cell cols="4">Test-CE (?) Accuracy %(?) Test-CE (?) Accuracy %(?)</cell></row><row><cell>Base network</cell><cell>0.080 ? 0.009</cell><cell>99.2 ? 0.1</cell><cell cols="2">0.085 ? 0.01 92.85 ? 0.40</cell></row><row><cell>Overfitting on test</cell><cell>0.002 ? 0.0001</cell><cell>100</cell><cell>0.075 ? 0.005</cell><cell>100</cell></row><row><cell cols="2">Overfitting on test (All Layers) 0.002 ? 0.0001</cell><cell>100</cell><cell>0.073 ? 0.003</cell><cell>100</cell></row><row><cell cols="2">OCD nearest neighbor ablation 0.073 ? 0.010</cell><cell>99.3 ? 0.1</cell><cell cols="2">0.082 ? 0.02 93.03 ? 0.40</cell></row><row><cell>OCD no scaling ablation</cell><cell>0.069 ? 0.010</cell><cell>99.3 ? 0.1</cell><cell cols="2">0.084 ? 0.02 93.01 ? 0.35</cell></row><row><cell cols="2">OCD alternative layer ablation 0.078 ? 0.010</cell><cell>99.2 ? 0.1</cell><cell cols="2">0.084 ? 0.01 92.96 ? 0.27</cell></row><row><cell>OCD (ours)</cell><cell cols="4">0.010 ? 0.006 99.7 ? 0.1 0.080 ? 0.01 93.68 ? 0.38</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Performance (MSE?SD, lower is better) for the TinyNeRF network.</figDesc><table><row><cell>Method</cell><cell>Lego</cell><cell>Hotdog</cell><cell>Drums</cell></row><row><cell>Base model</cell><cell>0.076 ? 0.004</cell><cell>0.063 ? 0.007</cell><cell>0.068 ? 0.006</cell></row><row><cell>Overfitting on test</cell><cell>0.043 ? 0.005</cell><cell>0.032 ? 0.005</cell><cell>0.049 ? 0.003</cell></row><row><cell cols="2">OCD no scaling ablation 0.070 ? 0.008</cell><cell>0.060 ? 0.005</cell><cell>0.064 ? 0.008</cell></row><row><cell>OCD (ours)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Tabular benchmarks by<ref type="bibr" target="#b5">Gorishniy et al. (2021)</ref>. M SE ? SD, lower is better. Overfit MLP on test 0.4750 ? .0020 0.7410 ? .0003 OCD + MLP no scale 0.5000 ? .0030 0.7490 ? .0006 OCD + MLP (ours) 0.4800 ? .0020 0.7430 ? .0004</figDesc><table><row><cell>Method</cell><cell>CA</cell><cell>MI</cell></row><row><cell>MLP</cell><cell cols="2">0.4990 ? 0.0030 0.7470 ? .0004</cell></row><row><cell>ResNet</cell><cell cols="2">0.4860 ? 0.0030 0.7480 ? .0003</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Performance of Gated-LSTM with the Hungarian loss on Libri5Mix.</figDesc><table><row><cell>Method</cell><cell>SI-SDRi[dB] (?)</cell></row><row><cell cols="2">Dovrat et al. (2021) 12.7 ? 0.1</cell></row><row><cell>Lutati et al. (2022)</cell><cell>13.2 ? 0.2</cell></row><row><cell>Overfit on test</cell><cell>13.5 ? 0.1</cell></row><row><cell>OCD no scale</cell><cell>12.8 ? 0.3</cell></row><row><cell>OCD (ours)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Tomer Amit, Eliya Nachmani, Tal Shaharbany, and Lior Wolf. Segdiff: Image segmentation with diffusion probabilistic models. arXiv preprint arXiv:2112.00390, 2021. Luca Bertinetto, Jo?o F Henriques, Jack Valmadre, Philip Torr, and Andrea Vedaldi. Learning feedforward one-shot learners. In Advances in Neural Information Processing Systems, pp. 523-531, 2016. L?on Bottou and Vladimir Vapnik. Local learning algorithms. Neural Computation, 4(6):888-900, 1992. doi: 10.1162/neco.1992.4.6.888. Andrew Brock, Theo Lim, J.M. Ritchie, and Nick Weston. SMASH: One-shot model architecture search through hypernetworks. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=rydeCEhs-.</figDesc><table /><note>Nanxin Chen, Yu Zhang, Heiga Zen, Ron J Weiss, Mohammad Norouzi, and William Chan. Wave- grad: Estimating gradients for waveform generation. arXiv preprint arXiv:2009.00713, 2020.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant ERC CoG 725974).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Local linear perceptrons for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethem</forename><surname>Alpaydin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="788" to="794" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ilvr: Conditioning method for denoising diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jooyoung</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghyun</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjune</forename><surname>Gwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="14347" to="14356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.05233</idno>
		<title level="m">Diffusion models beat gans on image synthesis</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Diffusion models beat gans on image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2105.05233" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Many-speakers single channel speech separation with optimal permutation training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaked</forename><surname>Dovrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliya</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2104.08955" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Revisiting deep learning models for tabular data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yury</forename><surname>Gorishniy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Rubachev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Khrulkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Babenko</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2106.11959" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hypernetworks</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.09106</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Pre-trained models: Past, present and future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxian</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqi</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihua</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2106.07139" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">and Tim Salimans. Cascaded diffusion models for high fidelity image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitwan</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Norouzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">47</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multiplicative interactions and where to find them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jayakumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sparse spatial autoregressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelley</forename><surname>Pace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Barry</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0167-7152(96)00140-X.URLhttps:/www.sciencedirect.com/science/article/pii/S016771529600140X</idno>
		<idno>0167-7152. doi</idno>
		<ptr target="https://doi.org/10.1016/S0167-7152(96)00140-X.URLhttps://www.sciencedirect.com/science/article/pii/S016771529600140X" />
	</analytic>
	<monogr>
		<title level="j">Statistics Probability Letters</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="291" to="297" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A dynamic convolutional layer for short range weather prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Afek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4840" to="4848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">An alternative view: When does sgd escape local minima?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yuan</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1802.06175" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Diffwave: A versatile diffusion model for audio synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaji</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kexin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<idno type="DOI">10.1109/5.726791</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note type="report_type">MNIST handwritten digit database</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Zero-shot voice conditioning for denoising diffusion tts models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Levkovitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliya</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Diffsinger: Singing voice synthesis via shallow diffusion mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinglin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.02446</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Lorraine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.09419</idno>
		<title level="m">Stochastic hyperparameter optimization through hypernetworks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Knowledge distillation in iterative generative models for improved sampling speed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Luhman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Troy</forename><surname>Luhman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.02388</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hyperhypernetwork for the design of antenna arrays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahar</forename><surname>Lutati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7214" to="7223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Sepit: Approaching a single channel speech separation bound</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahar</forename><surname>Lutati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliya</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2205.11801" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Nerf: Representing scenes as neural radiance fields for view synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Mildenhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pratul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Tancik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2003.08934" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.11309</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Fast model editing at scale</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Voice separation with an unknown number of multiple speakers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliya</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yossi</forename><surname>Adi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2003.01531" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Neural oblivious decision ensembles for deep learning on tabular data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergei</forename><surname>Popov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislav</forename><surname>Morozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Babenko</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=r1eiu2VtwH" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Gradtts: A diffusion probabilistic model for text-to-speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vadim</forename><surname>Popov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vovk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Gogoryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tasnima</forename><surname>Sadekova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Kudinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8599" to="8608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1306.2597" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Introducing letor 4.0 datasets</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Conditioned regression models for non-blind single image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Ruther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="522" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1505.04597" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosenblatt</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4612-9852-6</idno>
		<ptr target="https://doi.org/10.1007/978-1-4612-9852-6" />
		<title level="m">Random Processes</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Photorealistic text-to-image diffusion models with deep language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitwan</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lala</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seyed</forename><surname>Kamyar Seyed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ghasemipour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Sara</forename><surname>Burcu Karagol Ayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rapha Gontijo</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Norouzi</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2205.11487" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Noise estimation for generative diffusion models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>San-Roman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliya</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2104.02600" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Personalized federated learning using hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aviv</forename><surname>Shamsian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aviv</forename><surname>Navon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Fetaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Chechik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9489" to="9502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Density Estimation for Statistics and Data Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Silverman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1409.1556" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niru</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2256" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Denoising diffusion implicit models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenlin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2010.02502" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Denoising diffusion implicit models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenlin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2010.02502" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenlin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02502</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">Denoising diffusion implicit models. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1409.4842" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1706.03762" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Continual learning with hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oswald</forename><surname>Johannes Von</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Henning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><surname>Sacramento</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">F</forename><surname>Grewe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Learning to efficiently sample from diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03802</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The one-shot similarity kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taigman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="897" to="902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Graph hypernetworks for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rkgW0oA9FX" />
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Svm-knn: Discriminative nearest neighbor classification for visual category recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2126" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
