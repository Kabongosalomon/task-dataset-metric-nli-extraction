<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SPCL: A New Framework for Domain Adaptive Semantic Segmentation via Semantic Prototype-based Contrastive Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binhui</forename><surname>Xie</surname></persName>
							<email>binhuixie@bit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingjia</forename><surname>Li</surname></persName>
							<email>mingjiali@bit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Li</surname></persName>
							<email>shuangli@bit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SPCL: A New Framework for Domain Adaptive Semantic Segmentation via Semantic Prototype-based Contrastive Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Unsupervised domain adaptation</term>
					<term>semantic segmentation</term>
					<term>prototype-based contrastive learning</term>
					<term>self-supervision</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Although there is significant progress in supervised semantic segmentation, it remains challenging to deploy the segmentation models to unseen domains due to domain biases. Domain adaptation can help in this regard by transferring knowledge from a labeled source domain to an unlabeled target domain. Previous methods typically attempt to perform the adaptation on global features, however, the local semantic affiliations accounting for each pixel in the feature space are often ignored, resulting in less discriminability. To solve this issue, we propose a novel semantic prototype-based contrastive learning framework for finegrained class alignment. Specifically, the semantic prototypes provide supervisory signals for per-pixel discriminative representation learning and each pixel of source and target domains in the feature space is required to reflect the content of the corresponding semantic prototype. In this way, our framework is able to explicitly make intra-class pixel representations closer and inter-class pixel representations further apart to improve the robustness of the segmentation model as well as alleviate the domain shift problem. Our method is easy to implement and attains superior results compared to state-of-the-art approaches, as is demonstrated with a number of experiments. The code is publicly available at https://github.com/BinhuiXie/SPCL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic segmentation aims to assign a semantic label to each pixel of an image. This task can be of paramount importance in various real-world scenarios (e.g., robot control <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b56">57]</ref>, autonomous driving <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b79">80]</ref>, medical diagnosis <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b50">51]</ref>, etc.). Recent achievements in this field have been driven by deep neural networks with massive annotations <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b77">78]</ref>. However, assembling such largescale datasets with pixel-level annotations is onerous and even infeasible <ref type="bibr" target="#b7">[8]</ref>. <ref type="figure">Fig. 1</ref>: Main idea. The mechanism and segmentation result of global alignment are shown in the second column, where many pixels are adapted into wrong area due to lack of local consistency. In the third column, the coarse-grained class alignment alleviates pain to some extent but fails in some tail classes and boundaries of objects. In the last column, we propose a discriminative per-pixel representation learning scheme for fine-grained class alignment to achieve better performance. It encourages the representation of each pixel in feature space to be close to the corresponding semantic prototype for both source and target domains, while being away from other prototypes.</p><p>An appealing alternative is to use images with dense ground-truth annotations from a simulator <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b51">52]</ref>. Unfortunately, models purely trained from synthetic data usually undergo a noticeable performance drop when directly applied to real images due to the domain shift <ref type="bibr" target="#b47">[48]</ref>. Therefore, domain adaptation (DA) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b28">29]</ref> has become a promising direction, whose purpose is to facilitate the knowledge learned from a well-labeled source domain better transferring to another unlabeled target domain.</p><p>The key to the domain adaptive semantic segmentation is that the divergence across domains should be reduced to lower the upper bound of error on the target domain. In the literature, most previous works exploit adversarial training <ref type="bibr" target="#b15">[16]</ref> for distribution alignment in the input <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b80">81]</ref>, intermediate feature <ref type="bibr" target="#b20">[21]</ref>, or output <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b31">32]</ref> space. However, existing techniques mostly strive to align marginal distribution in the domain level. In consequence, it is possible that decision boundaries traverse high-density regions of the target domain, rendering the learned classifier are less discriminative. To improve upon such alignment, latest works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b74">75]</ref> have shown that class conditional distributions should also be aligned, which plays a vital role in reducing the domain discrepancy. Nonetheless, since the conditional distributions are unknown on the target domain, the extracted semantic features could be noisy.</p><p>As a matter of fact, the local semantic affiliations of each pixel in the feature space are crucial during adaptation. As depicted in <ref type="figure">Fig. 1</ref>, we note that 1) Global alignment methods, e.g., AdaptSegNet <ref type="bibr" target="#b53">[54]</ref>, are inclined to consider the domain divergence globally and ignore the underlying structures among classes, leading to domain-invariant but class-indistinguishable segmentation results. 2) Although some class alignment methods, e.g., CAG-UDA <ref type="bibr" target="#b74">[75]</ref>, achieve potential gains, they might remain inconsistent concerning the boundaries of objects or some tail classes (e.g., light, sign, bike). Such alignment does not incorporate abundant pixel-wise context and structural information, which usually obtain coarse-grained results. 3) Instead, our method explicitly investigates per-pixel discriminative representation learning and performs fine-grained class alignment guided by semantic prototypes, achieving more discriminative features and consistent performance.</p><p>In this paper, we provide a new perspective for tackling domain adaptation in semantic segmentation. The primary aim is to enhance the intra-class compactness and inter-class separability of the source domain (with annotations) in the pixel wise and transfer such discriminative information into the target domain (without annotations) via semantic prototype-based contrastive learning. Specifically, we first construct the representative semantic prototype for each individual class via source ground-truth labels, which can provide supervisory signals for learning discriminative pixel representations across the two domains. To ensure the reliability of the generated semantic prototypes, we dynamically update and distinguish different prototypes. Simultaneously, separation of pixel representations from different classes in source-domain data can be naturally guaranteed. Furthermore, for the target-domain data, representation of each pixel can be correspondingly divided into subsets according to its reliable pseudo label. In this way, for each pixel representation from both domains, we can properly construct one positive pixel-prototype pair and C ? 1 (C is the number of semantic labels) negative pixel-prototype pairs. Finally, a novel contrastive loss is introduced to improve the discrimination of pixel representations, enforcing the positive-concentrated and negative-separated properties. In summary, we make the following contributions:</p><p>-We propose a simple DA method for semantic segmentation that explicitly enhances pixel-wise intra-class compactness and pixel-wise inter-class separability. -Directly applying contrastive learning techniques validated in image classification renders particular challenges in segmentation. We investigate a novel semantic prototype-based contrastive learning to effectively align pixel-wise representations with contextual semantic prototypes across domains. -We conduct extensive experimental studies on four popular datasets including GTA5, Synscapes, SYNTHIA, and Cityscapes. Comprehensive analyses are conducted to validate the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Contrastive learning</head><p>Contrastive learning has become a dominant part in unsupervised learning <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b48">49]</ref>. The intuition is that different augmented versions of an image should have similar representations and these representations should also differ from those of a distinct image. In contrast, we aim to learn pixel-wise representations to distinguish different areas in an image for segmentation task instead of facilitating learning of meaningful image-wise representations for classification task. In essence, the optimization objective is different. Recent works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b60">61]</ref> also generalize contrastive learning to pixel-level dense prediction tasks. However, these methods engage in the unsupervised pretraining <ref type="bibr" target="#b67">[68]</ref>, the fully supervised setting <ref type="bibr" target="#b60">[61]</ref> or semi-supervised setting <ref type="bibr" target="#b0">[1]</ref>. And the recipes for semantic segmentation under the context of domain shift are yet to be built. To this end, we tailor multiple similar/dissimilar pixel-prototype pairs according to semantic prototypes for aligning source and target features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Domain adaptive semantic segmentation</head><p>Generally, domain adaptation (DA) has been extensively explored to narrow the distribution mismatch between training and testing dataset for the image classification task <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28]</ref>. Not until recently has limited effort been made for semantic segmentation. Hoffman et al. <ref type="bibr" target="#b20">[21]</ref> are the first to introduce DA to segmentation, where they consider feature alignment with additional category constraints. Enormous adversarial learning variants are proposed to learn domain-invariant features and they can be categorized into input <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b29">30]</ref>, feature <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b63">64]</ref>, output <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b68">69]</ref> or patch <ref type="bibr" target="#b54">[55]</ref> space adaptations. To name a few, Tsai et al. <ref type="bibr" target="#b53">[54]</ref> consider segmentation as structured outputs, where images from different domains share strong similarities in semantic layout. Similarly, Luo et al. <ref type="bibr" target="#b34">[35]</ref> suggest applying different adversarial weights to different pixels. Wang et al.. <ref type="bibr" target="#b58">[59]</ref> incorporate class information into the discriminator to align features at a fine-grained level. Most recently, Kang et al. <ref type="bibr" target="#b22">[23]</ref> and Melas-Kyriazi et al. <ref type="bibr" target="#b37">[38]</ref> provide a non-adversarial perspective to diminish domain gap via exploiting the correlations of pixels. However, implicit class alignment may be affected by class imbalance. On the contrary, we delve into considering per-pixel discriminative representation learning with the aid of semantic prototypes.</p><p>Another direction resorts to self-supervision <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b59">60]</ref> to boost the segmentation performance, where the confident predictions of the unlabeled target data are used to fine-tune the model trained on the source domain. Zou et al. <ref type="bibr" target="#b81">[82]</ref> first propose an iterative learning strategy with class balance and spatial prior in the target domain. In addition, a soft-assignment version of the pseudo label is proposed in <ref type="bibr" target="#b57">[58]</ref> to focus on "most-confused" pixels, which obtains better performance. Very recently, Pan et al. <ref type="bibr" target="#b40">[41]</ref> propose a two-step self-supervised domain adaptation technique, which considers adapting from the easy image to the hard image within the target domain. However, they all rely on a good initialization and a difficult fine-tuning process.</p><p>Of particular relevance to our work is the method CAG-UDA <ref type="bibr" target="#b74">[75]</ref>, which enforces category-aware feature alignment by minimizing distance between pixel feature and the corresponding category centroid. However, except for the semantic information, per-pixel feature also involves abundant structural information. Naively minimizing the distance loss only independently adapt semantic features across domains and thus is less discriminative. In contrast, we set forth a simple semantic prototype-based contrastive loss to learn discriminative pixel rep-resentations, which allows us to model pixel-wise intra-class compactness and pixel-wise inter-class separability across domains. In addition, the prototypes provided by our method are gradually updated and refined, while CAG-UDA only supports fixed targets during training. Note that our updating strategy (will be discuss in Section 3.2) dynamically accommodates the parameters of the network. Such alignment strengthens the connections between pixel representations of both domains and the corresponding prototypes, which enables the adaptation in a more accurate and stable manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of the framework</head><p>In domain adaptation, given a collection of images and ground-truth labels from the source domain denoted as D s = {X si , Y si } ns i=1 , as well as unlabeled images from the target domain D t = {X tj } nt j=1 , the problem is to adapt a segmentation model from source domain D s to target domain D t . Here n s and n t are the numbers of samples from two domains. Note that X s , X t ? R H?W ?3 , and Y s ? B H?W ?C with pixel-level one-hot vectors, where H and W represent the spatial dimensions of the image and C is the number of semantic class labels.</p><p>The overall framework is depicted in <ref type="figure" target="#fig_0">Figure 2</ref>. Specifically, the segmentation network consists of an encoder E and a decoder (multi-class classifier) D. We first pass both source and target images through the encoder E and obtain their feature maps F s , F t ? R H ? ?W ? ?N , then pass the features to the decoder D and get the predictions O s , O t ? R H ? ?W ? ?C . Finally, we acquire the pixel-wise output predictions P s , P t ? R H?W ?C after the upsample and softmax operations.</p><p>The key in our work is to ensure representation of each pixel in feature maps F s and F t to be close to their corresponding source semantic prototype, while being pushed away from other semantic prototypes. In this way, features from the same class in the two domains tend to be clustered compactly, effectively boosting the model generalization capability. To achieve this, source class centroids can be calculated as representative semantic prototypes. Then each pixel representation in feature space derived from encoder E will be considered and processed separately given their predicted masks M s and M t . Based on this, an effective semantic prototype-based contrastive loss is proposed to align conditional distributions across domains via learning discriminative representations of pixels. Note that the proposed contrastive loss can be used in both source and target domains simultaneously. For one thing, when the loss is applied in F s , the encoder is able to yield more discriminative features for decoder, which could increase the robustness of semantic segmentation model. For another, the designed pixel-wise contrastive loss for target feature map F t facilitates transferring knowledge from source to target explicitly, achieving more precise alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Semantic prototype-based contrastive learning</head><p>Contrastive learning revisit Contrastive learning and its variants <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b39">40]</ref>  pairs, in which meaningful and discriminative representations are learned through a contrastive loss function ?. If we denote the query and key vectors as u, v ? R N , where N is the dimension of embedding space, the loss ? is designed to reflect the incompatibility of data pair (u, v). Here, v + and {v ? } represent the positive key and negative key sets with respect to query u, respectively. In a word, a desirable ? returns low value given the positive pair (u, v + ), but achieves high loss for the negative pairs (u, {v ? }), which could effectively force positive query and key vectors to be similar while distinct from negative ones. Inspired by <ref type="bibr" target="#b39">[40]</ref>, a standard contrastive learning problem can be treated as a "two-class" classification problem, and the loss for query u is formulated as:</p><formula xml:id="formula_0">?(u, v + , {v ? }) = ? log exp u?v + /? exp (u?v + /? ) + v ? exp u?v ? /? .<label>(1)</label></formula><p>As shown above, the contrastive loss is essentially based on the softmax formulation with a temperature ? <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b39">40]</ref> to cluster the positive pair (u, v + ) as well as push away the negative pairs (u, {v ? }). Hence, the meaningful representations can be learned via multiple unlabeled data. In essence, expect for the formulation design of contrastive loss, how to construct the positive and negative key-query pairs remains challenging for the successful application of contrastive learning. In this paper, we novelly set semantic prototypes for all classes as key vectors, and pixel representations in the intermediate layers of both domains as query vectors. Meanwhile, combined with the proposed contrastive learning loss, the cross-domain discriminative clustering structures will be learned for better adaptation.</p><p>Semantic prototype learning In order to encode all pixel representations from both domains for discriminative feature learning and knowledge transfer, for each class, we intend to cluster the representations around their corresponding class centroid (semantic prototype). In the meantime, a dynamic semantic prototypes updating strategy is proposed during the training.</p><p>Prototype initialization. The initial semantic prototypes can be calculated as the mean feature representation of each class from source domain since the groundtruth semantic labels are available and can naturally provide valuable supervisions. To assign each source pixel feature with a reliable semantic label, we can directly leverage the downsampled ground-truth label map? s (a downsampled version of Y s ) to obtain a mask M s for an input image by M</p><formula xml:id="formula_1">(h ? ,w ? ) s = arg max c? (h ? ,w ? ,c) s</formula><p>. Based on the mask M s , the semantic prototype of c-th class on the entire source domain can be calculated as:</p><formula xml:id="formula_2">? c = 1 ns i 1 |? c i | h ? ,w ? I [M (h ? ,w ? ) s i =c] F (h ? ,w ? ) s i ,<label>(2)</label></formula><p>where I is an indicator function which returns 1 if the condition holds or 0 otherwise. ? c i denotes the pixel set that contains all the pixel features belonging to the c-th semantic class within F si and |?| is the number of pixels in the set. Note that the semantic prototypes are only initialized once at the beginning of the learning algorithm by performing the forward computation, and the prototypes can be continuously updated as the learning proceeds.</p><p>Prototype updating. At each iteration, the encoded pixel features of each image are different, and should be involved in the prototype updating process to represent the latest semantic knowledge. Technically, the c-th centroid ? c is updated with the mean of the encoded pixel features belonging to class c within a new feature map F s as follows:</p><formula xml:id="formula_3">? c ? ?? c + 1 ? ? |? c | h ? ,w ? I [M (h ? ,w ? ) s =c] F (h ? ,w ? ) s .<label>(3)</label></formula><p>Here ? ? [0, 1] is a coefficient for updating semantic prototypes, and ? is empirically set as 0.1 in this paper. Note that ? = 1.0 denotes that the prototypes are fixed during the training process. With the updated prototypes, our method can dynamically guide the cross-domain pixel representations to cluster around the corresponding prototype, and enforce the category alignment across domains.</p><p>Fine-grained class alignment Recently, several prior methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b37">38]</ref> have leveraged class alignment to remedy the domain gap. However, most of them are coarse-grained adaptation and often neglect the discriminative knowledge of pixel representations, which severely limits their potential capability in pixel-level prediction tasks. By contrast, in our work, we explicitly model the intra-class compactness and inter-class separability across domains in the pixel wise by proposing a semantic prototype-based contrastive learning framework. Specifically, to design an effective contrastive loss for domain adaptive semantic segmentation, the key is to construct the appropriate query-key pairs. Different from the conventional contrastive learning methods, which rely on the data itself for supervision, we believe that the source semantic prototypes can provide valuable guidance for the pixel samples in both domains. In essence, the proposed contrastive loss is to force the features from the same class to concentrate together while pushing away different clusters for both domains, enhancing the model robustness and improving cross-domain knowledge transfer.</p><p>Therefore, if we define each pixel obtained from the encoder E as a query vector, the corresponding semantic prototype from the same class is reasonably set as the unique positive key vector, and semantic prototypes in other C ? 1 classes should be negative keys. In practice, we normalize these features onto a unit sphere to prevent the space from collapsing or expanding. Then in source domain, by integrating the source mask M s and feature map F s , the proposed contrastive loss on source domain is</p><formula xml:id="formula_4">L s cl = i h ? ,w ? c I [M (h ? ,w ? ) s i =c] ?(F (h ? ,w ? ) s i , ? c , {? c? }) ,<label>(4)</label></formula><p>where ? c and {? c? } represent the corresponding positive and C ? 1 negative semantic prototypes, respectively. Optimizing L s cl can leverage label information effectively in the feature space. In addition to this, we conduct the proposed contrastive learning for all target pixel features as well to transfer the supervised knowledge from source to target.</p><p>However, for target domain data, training error could be amplified by noisy predictions when generating the target mask. To remedy this, we employ a confident strategy with a confidence threshold ? c o for each class c individually. In detail, firstly, a confidence map is generated according to the segmentation prediction map O t , where the confidence value is the maximum item of the softmax output in each pixel. This enables the pseudo label at each pixel to be associated with a confidence value, i.e., the prediction probability. Secondly, if the median confidence value for a certain class is above 0.9, then the confidence threshold for that class is set to 0.9; otherwise it is set to the median confidence value. With the ? c o being set, we can define target mask in the feature space as follows:</p><formula xml:id="formula_5">M (h ? ,w ? ) t = arg max c I [O (h ? ,w ? ,c) t &gt;? c o ] O (h ? ,w ? ,c) t .<label>(5)</label></formula><p>Similarly, we can obtain target contrastive loss for all the target pixel representations as:</p><formula xml:id="formula_6">L t cl = j h ? ,w ? c I [M (h ? ,w ? ) t j =c] ?(F (h ? ,w ? ) t j , ? c , {? c? }) .<label>(6)</label></formula><p>By observing Eq. (6), optimizing L t cl can not only pull each target pixel sample to its corresponding semantic prototype and achieve class-level knowledge transfer, but also preserve the target intrinsic discriminative structure, which will boost the final model generalization capability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Objective</head><p>In this work, we follow a popular two-step training procedure <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b74">75]</ref> to reduce the domain shift and improve the performance of the segmentation model on the target domain. First, given source images with ground-truth labels, we employ the broadly used cross-entropy loss to guarantee a small source error,</p><formula xml:id="formula_7">Lseg = ? i h,w c Y (h,w,c) s i log P (h,w,c) s i .<label>(7)</label></formula><p>Combining L seg , L s cl , L t cl with a balancing weight ?, we are able to close the domain gap between the source and target data and perform the segmentation task, and the overall objective is formulated as follows:</p><formula xml:id="formula_8">min E ,D Lseg + ?(L s cl + L t cl ).<label>(8)</label></formula><p>By optimizing Eq. (8), clusters of pixels belonging to the same class are pulled together in the feature space while synchronously pushing apart from other classes. In this way, our method can simultaneously minimize the domain gap across domains as well as enhance the intra-class compactness and inter-class separability in a unified framework. Second, once the alignment is finished, we can generate the reliable pseudo labels for target data by choosing the confidence threshold ? c p for each class respectively according to the output predictions P t (similar to setting ? c o ). The target pseudo labels in the output space are obtained as follows:?  </p><formula xml:id="formula_9">I [? (h,w) t j =c] log P (h,w,c) t j .<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setups</head><p>Datasets. We evaluate our method under the "Sim-to-Real" scenario with four popular benchmark datasets, i.e., transferring from the synthetic images (GTA5 <ref type="bibr" target="#b49">[50]</ref>, Synscapes <ref type="bibr" target="#b64">[65]</ref>, and SYNTHIA <ref type="bibr" target="#b51">[52]</ref>) to the real images (Cityscapes <ref type="bibr" target="#b7">[8]</ref>). Cityscapes includes 5,000 urban scene images of resolution 2048?1024. They are splitted into training, validation, and testing set with 2,975, 500, and 1,525 images respectively. Similar to <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b82">83]</ref>, we evaluate our adapted model on the validation set. GTA5 contains 24,966 images with the resolution of 1914?1052. Synscapes contains 25,000 images with a resolution of 1,440?720. SYNTHIA offers 9,400 images of resolution 1280?760. Network architectures. For fair comparison, we utilize the DeepLab-v2 framework <ref type="bibr" target="#b3">[4]</ref> with ResNet-101 <ref type="bibr" target="#b18">[19]</ref> or VGG-16 <ref type="bibr" target="#b52">[53]</ref> as the base encoder E. Note that some state-of-the-art methods <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b74">75]</ref> use different backbone networks <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b76">77]</ref>, and we present them as references to analyze how much our method can improve. All models are pre-trained on ImageNet <ref type="bibr" target="#b8">[9]</ref>. To better capture the scene context, Atrous Spatial Pyramid Pooling (ASPP) <ref type="bibr" target="#b3">[4]</ref> is used as decoder D and applied on the encoder's outputs. Following <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b82">83]</ref>, sampling rates are fixed as {6, 12, 18, 24} and we modify the stride and dilation rate of the last layers to produce denser feature maps with larger field-of-views.</p><p>Training details. Our training is carried out on 4 Tesla V100 GPUs. And we implement all methods with PyTorch <ref type="bibr" target="#b44">[45]</ref>. To train the segmentation network, we adopt the SGD optimizer where the momentum is 0.9 and the weight decay is 10 ?4 . The learning rate is initially set to 2.5 ? 10 ?4 and is decreased following a 'poly' learning rate policy with power of 0.9. ? is constantly set to 0.1 and ? is set to 1.0 for all experiments. Regarding the training procedure, we first use the source data to train the network as well as to align the output distributions following <ref type="bibr" target="#b53">[54]</ref> as the baseline. Then the network is fine-tuned using our method for 40k iterations with batch size of 8 (four are source images and the other four are target images). Some data augmentations (e.g., color jittering and random horizontal flip etc.) are used to prevent overfitting. Finally, similar to <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b63">64]</ref>, we apply the self supervision loss to further improve the performance on the target domain.</p><p>Evaluation metrics. We employ the PSACAL VOC Intersection-over-Union (IoU) as the evaluation metric <ref type="bibr" target="#b10">[11]</ref>, i.e, IoU = T P T P +F P +F N , where T P , F P , and F N stand for the amount of true positive, false positive and false negative pixels, respectively, determined over the whole test set. For GTA5 ? Cityscapes and Synscapes ? Cityscapes tasks, we report the results on the common 19 classes and the tail classes. For SYNTHIA ? Cityscapes task, we report the results over 16 and 13 classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison with state-of-the-art methods</head><p>We compare our method with previous state-of-the-arts in <ref type="table" target="#tab_0">Table 1</ref>, <ref type="table" target="#tab_1">Table 2, and  Table 3</ref>. All the models utilize DeepLab-v2 <ref type="bibr" target="#b3">[4]</ref> framework, except that PyCDA is based on PSPNet <ref type="bibr" target="#b76">[77]</ref> and CAG-UDA is based on DeepLab-v3+ 1 <ref type="bibr" target="#b4">[5]</ref>. It can be seen that our method outperforms all the existing competing methods and achieves new state-of-the-art performance in terms of mIoU.</p><p>Specifically, for GTA5 ? Cityscapes task, our method exceeds the global alignment based method, AdaptSegNet, by +9.8% and +9.7% for VGG-16 and  ResNet-101 respectively. Our method also obtains +4.4% improvements for Synscapes ? Cityscapes task based on ResNet-101. Next, for SYNTHIA ? Cityscapes task, our method compares favorably with the others. Compared with other class alignment approaches (CLAN, SSF-DAN, CAG-UDA, SIM, FADA etc.), a general gain of over 1.0% is witnessed. Moreover, our method also performs comparable to or even better than the strong baselines, i.e., self-supervision <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b82">83]</ref> and pixel association <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b37">38]</ref> approaches. These results reflect that the way of considering the per-pixel discriminative representation learning benefits the adaptation capability. Qualitative results for GTA5 ? Cityscapes task are presented at <ref type="figure">Figure 3</ref>, verifying that our method also brings a significant visual improvement. More qualitative results are provided in Appendix C.</p><p>Results on tail classes. We show the class distribution of Cityscapes validation set in Appendix B and the tail classes are highlighted with blue in <ref type="table" target="#tab_0">Table 1</ref> and <ref type="table" target="#tab_1">Table 2</ref>. In essence, our method can achieve better performance at the majority of tail classes, demonstrating its superiority in mitigating the conditional domain shift. As mentioned earlier, the prior work CAG-UDA <ref type="bibr" target="#b74">[75]</ref> naively maximizes connections between pixels and the fixed category centroids whereas our</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target Image</head><p>AdaptSegNet CAG-UDA Ground Truth Ours <ref type="figure">Fig. 3</ref>: Qualitative results for GTA5 ? Cityscapes task. For each target image, we show results with global alignment (AdaptSegNet), coarse-grained class alignment (CLAN) and our method, and the ground-truth label map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CAG-UDA</head><p>Ours T arget Image <ref type="figure">Fig. 4</ref>: Comparisons of segmentation result and t-SNE visualization <ref type="bibr" target="#b36">[37]</ref> between CAG-UDA <ref type="bibr" target="#b74">[75]</ref> and our method.     method contrastively encourages the representation of each pixel in feature space to be close to the corresponding semantic prototype while being away from other prototypes. In <ref type="table" target="#tab_0">Table 1</ref>, we can see that our method consistently performs better in terms of both mIoU and mIoU tail . To further answer why our method are effective, we study from the t-SNE visualization <ref type="bibr" target="#b36">[37]</ref> perspective. And we measure the high-dimensional pixel representations of prior work <ref type="bibr" target="#b74">[75]</ref> and ours to a 2D space with t-SNE shown in <ref type="figure">Figure 4</ref>. The comparison results further prove that our method is more discriminative and consistent at a fine-grained level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation studies</head><p>We present comprehensive studies to evaluate the contribution of each component of our approach in <ref type="table" target="#tab_3">Table 4</ref>. First of all, we follow the work of <ref type="bibr" target="#b53">[54]</ref> and employ global alignment in the output space, which serves as the baseline of our work. The results are shown in the first rows.</p><p>Effect of contrastive loss. Applying the proposed contrastive loss on the source domain (L s cl ) can outperform global alignment, which demonstrates enhancing intra-/inter-class affinities in the source domain is helpful for discriminative representation learning and also promotes the adaptability of segmentation model. To reduce the domain gap between domains, we further exploit the proposed contrastive loss on the target domain (L s cl + L t cl ) and it contributes +7.8% of mIoU and +6.3% of mIoU for GTA5 ? Cityscapes and SYNTHIA ? Cityscapes respectively, which makes it comparable with other approaches.</p><p>Effect of self supervised loss. When only applying self supervision loss (L ssl ) to the baseline, it leads to a slight gain. Naturally, we also employ L ssl to explore the great veiled potentials of our method. This yields significant improvements, which benefits from explicitly enforcing intra-class pixel representations closer and inter-class pixel representations further apart.</p><p>Effect of hyperparameters. We conduct a study to tune the proper values of the hyperparameters ? and ? in our experiments. The selected hyperparame- ters for GTA5 ? Cityscapes task are listed in <ref type="table" target="#tab_4">Table 5</ref> and <ref type="table" target="#tab_5">Table 6</ref>. Our method is able to achieve consistent performance within a wide range of ? and ?. It worth noting that updated semantic prototypes gives better performance than fixed ones (? = 1.0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Feature discriminability</head><p>To verify our method is capable of driving the intra-class pixel representations closer and the inter-class pixel representations further apart, we follow the Class Center Distance (CCD) metric in <ref type="bibr" target="#b58">[59]</ref> to better compare the superiority of our method with other state-of-the-arts. Specifically, we randomly select 1,000 source images and 1,000 target images to calculate the CCD and report the comparison results in <ref type="figure" target="#fig_4">Figure 5</ref>. The results of our method are significantly lower than those trained using AdaptSegNet <ref type="bibr" target="#b53">[54]</ref>, FADA <ref type="bibr" target="#b58">[59]</ref>, and CAG-UDA <ref type="bibr" target="#b74">[75]</ref>, especially in the tail classes. It implies that our method is effective in driving pixel representations towards the corresponding semantic prototype to reduce the domain divergence and enhance feature discriminability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we present a novel semantic prototype-based contrastive learning to improve the adaptability in semantic segmentation. In particular, we design a fine-grained class alignment with an elegant contrastive loss to enforce the network to approximate the positive-concentrated and negative-separated properties of cross-domain pixel representations. The proposed method performs favorably against previous state-of-the-arts on multiple cross-domain segmentation scenarios. We believe that our exploration can inspire more efforts in this area. Percentage of Pixels (%) <ref type="bibr" target="#b36">37</ref>   <ref type="figure" target="#fig_6">Figure 6</ref> shows the class distribution of Cityscapes validation set. In this paper, those classes whose percentage of pixels is less than 1% are defined as the tail classes. We can see that 11 out of 19 classes are the tail classes, and they are wall, fence, light, sign, terr., rider, truck, bus, train, mbike, bike.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Class Distribution on Cityscapes Validation Set</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C More Qualitative Comparisons</head><p>We present additional results for qualitative comparisons under various settings, including GTA5 ? Cityscapes <ref type="figure">(Figure 7)</ref>, SYNTHIA ? Cityscapes <ref type="figure">(Figure 8</ref>), and Synscapes ? Cityscapes <ref type="figure">(Figure 9</ref>). For GTA5 ? Cityscapes and SYNTHIA ? Cityscapes tasks, we visualize the segmentation results of the Source Only model, global alignment model (AdaptSegNet <ref type="bibr" target="#b53">[54]</ref>), coarse-grained class alignment model (CAG-UDA <ref type="bibr" target="#b74">[75]</ref>) and our model. And for Synscapes ? Cityscapes task, we show results of the Source Only model, global alignment model (Adapt-SegNet <ref type="bibr" target="#b53">[54]</ref>), and our model. The results predicted by our method are smoother and contain less spurious predictions than those predicted by other state-of-theart approaches, demonstrating that with our fine-grained class alignment, it can bring a great visual improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Class Center Distance</head><p>To further answer why our contrastive loss is effective, we study from the feature distribution perspective. We measure the Class Center Distance (CCD) metric <ref type="bibr" target="#b58">[59]</ref> by taking intra-class and inter-class distances into account. The CCD for class c is defined as follows:</p><formula xml:id="formula_10">CDD(c) = 1 C ? 1 C k=1,k? =c 1 |? c | x?? c ?x ? ? c ? 2 ?? c ? ? k ? 2 ,<label>(10)</label></formula><p>where ? c is the semantic prototype of class c, ? c denotes the pixel set that contains all the pixel representations belonging to the c-th semantic class and | ? | is the number of pixels in the set.</p><p>T arget Image Source Only AdaptSegNet CAG-UDA Ours Ground Truth <ref type="figure">Fig. 7</ref>: Example results of adapted segmentation for GTA5 ? Cityscapes task. For each target image, we show segmentation results with Source Only, global alignment (AdaptSegNet <ref type="bibr" target="#b53">[54]</ref>), coarse-grained class alignment (CAG-UDA <ref type="bibr" target="#b74">[75]</ref>), and our fine-grained class alignment and ground-truth label map.</p><p>T arget Image Source Only AdaptSegNet CAG-UDA Ours Ground Truth <ref type="figure">Fig. 8</ref>: Example results of adapted segmentation for SYNTHIA ? Cityscapes task. For each target image, we show results with Source Only, global alignment (AdaptSegNet <ref type="bibr" target="#b53">[54]</ref>), coarse-grained class alignment (CAG-UDA <ref type="bibr" target="#b74">[75]</ref>), and our fine-grained class alignment and ground truth-label map.</p><p>Target Image Source Only AdaptSegNet Ours Ground Truth <ref type="figure">Fig. 9</ref>: Example results of adapted segmentation for Synscapes ? Cityscapes task. For each target image, we show results with Source Only, global alignment (AdaptSegNet <ref type="bibr" target="#b53">[54]</ref>), and our fine-grained class alignment and ground-truth label map.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>aim to learn representations from unlabeled data organized in similar/dissimilar Overview of the proposed method. Images in the source (brown arrows) and target (green arrows) domains are randomly selected and passed through the segmentation network (E and D) to get final predictions. For the source data, a segmentation loss L seg is computed based on the ground truth Y s . We separate each pixel representation obtained from E in both domains according to their masks M s and M t and pass them to semantic prototypebased contrastive learning module. As a result, clusters of pixel representations belonging to the same prototype are pulled together in the feature space while simultaneously pushing apart from other prototypes, which improves pixel-wise compactness and separability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>.</head><label></label><figDesc>Then, we fine-tune the model via optimizing a self supervision loss L ssl in Eq. (9) on the entire target training data to make the model more adaptive to the target domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>? 0 .</head><label>0</label><figDesc>01 0.1 0.5 1.0 2.0 10.0 mIoU 50.3 51.4 51.9 52.1 51.8 50.1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>c e p o le li g h t s ig n v e g e . t e r r . s k y p e r s . r id e r c a r t r u c k b u s t r a in m o t o r b ik e m e Quantitative analysis of the feature discrimination. For each class, we show the Class Center Distance (CDD) as defined in [59], where a low CCD means the representations of the same class are densely clustered while distances between different classes are relatively large. Our method shows a better aligned structure in class-level compared with other methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>b u s t r a i n m b i k e b i k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 :</head><label>6</label><figDesc>Class distribution on Cityscapes validation set. The tail classes are highlighted in blue.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Experimental results for GTA5 ? Cityscapes. mIoU tail denotes the mean IoU of the tail classes in blue. 84.0 31.9 27.3 35.4 36.3 15.7 83.6 34.7 82.1 58.2 28.9 85.7 29.0 38.2 0.0 24.7 19.5 44.8 26.0 UDA [75] 90.4 51.6 83.8 34.2 27.8 38.4 25.3 48.4 85.4 38.2 78.1 58.6 34.6 84.7 21.9 42.7 41.1 29.3 37.2 50.2 34.6 PixelMatch [38] 91.6 51.2 84.7 37.3 29.1 24.6 31.3 37.2 86.5 44.3 85.3 62.8 22.6 87.6 38.9 52.3 0.7 37.2 50.0 50.3 34.6 FDA [72] 92.5 53.3 82.4 26.5 27.6 36.4 40.6 38.9 82.3 39.8 78.0 62.6 34.4 84.9 34.1 53.1 16.9 27.7 46.4 50.5 35.1 Ours 90.3 50.3 85.7 45.3 28.4 36.8 42.2 22.3 85.1 43.6 87.2 62.8 39.0 87.8 41.3 53.9 17.7 35.9 33.8 52.1 36.7</figDesc><table><row><cell cols="2">Backbone Method</cell><cell>r o a d</cell><cell>s id e .</cell><cell>b u il .</cell><cell>w a ll</cell><cell>fe n c e p o le</cell><cell>li g h t s ig n</cell><cell>v e g</cell><cell>t e r r .</cell><cell>s k y</cell><cell>p e r s .</cell><cell>r id e r c a r</cell><cell>t r u c k b u s t r a in m b ik e b ik e</cell><cell>mIoU mIoUtail</cell></row><row><cell></cell><cell cols="14">AdaptSegNet [54] 87.3 29.8 78.6 21.1 18.2 22.5 21.5 11.0 79.7 29.6 71.3 46.8 6.5 80.1 23.0 26.9 0.0 10.6 0.3 35.0</cell><cell>15.3</cell></row><row><cell></cell><cell>CBST [82]</cell><cell cols="13">90.4 50.8 72.0 18.3 9.5 27.2 28.6 14.1 82.4 25.1 70.8 42.6 14.5 76.9 5.9 12.5 1.2 14.0 28.6 36.1</cell><cell>15.7</cell></row><row><cell></cell><cell>AdvEnt [58]</cell><cell cols="13">86.9 28.7 78.7 28.5 25.2 17.1 20.3 10.9 80.0 26.4 70.2 47.1 8.4 81.5 26.0 17.2 18.9 11.7 1.6 36.1</cell><cell>17.7</cell></row><row><cell>VGG-16</cell><cell>CLAN [35] APODA [70]</cell><cell cols="13">88.0 30.6 79.2 23.4 20.5 26.1 23.0 14.8 81.6 34.5 72.0 45.8 7.9 80.5 26.6 29.9 0.0 10.7 0.0 36.6 88.4 34.2 77.6 23.7 18.3 24.8 24.9 12.4 80.7 30.4 68.6 48.9 17.9 80.8 27.0 27.2 6.2 19.1 10.2 38.0</cell><cell>17.4 16.7</cell></row><row><cell></cell><cell>CrCDA [22]</cell><cell cols="13">86.8 37.5 80.4 30.7 18.1 26.8 25.3 15.1 81.5 30.9 72.1 52.8 19.0 82.1 25.4 29.2 10.1 15.8 3.7 39.1</cell><cell>20.3</cell></row><row><cell></cell><cell>FADA [59]</cell><cell cols="13">92.3 51.1 83.7 33.1 29.1 28.5 28.0 21.0 82.6 32.6 85.3 55.2 28.8 83.5 24.4 37.4 0.0 21.1 15.2 43.8</cell><cell>24.6</cell></row><row><cell cols="15">Ours Source Only AdaptSegNet [54] 86.5 36.0 79.9 23.4 23.3 23.9 35.2 14.8 83.4 33.3 75.6 58.5 27.6 73.7 32.5 35.4 3.9 30.1 28.1 42.4 65.0 16.1 68.7 18.6 16.8 21.3 31.4 11.2 83.0 22.0 78.0 54.4 33.8 73.9 12.7 30.7 13.7 28.1 19.7 36.8 CLAN [35] 87.0 27.1 79.6 27.3 23.3 28.3 35.5 24.2 83.6 27.4 74.2 58.6 28.0 76.2 33.1 36.7 6.7 31.9 31.4 43.2 AdvEnt [58] 89.9 36.5 81.6 29.2 25.2 28.5 32.3 22.4 83.9 34.0 77.1 57.4 27.9 83.7 29.4 39.1 1.5 28.4 23.3 43.8 SSF-DAN [10] 90.3 38.9 81.7 24.8 22.9 30.5 37.0 21.2 84.8 38.8 76.9 58.8 30.7 85.7 30.6 38.1 5.9 28.3 36.9 45.4 CBST [82] 91.8 53.5 80.5 32.7 21.0 34.0 28.9 20.4 83.9 34.2 80.9 53.1 24.0 82.7 30.3 35.9 16.0 25.9 42.8 45.9 APODA [70] 85.6 32.8 79.0 29.5 25.5 26.8 34.6 19.9 83.7 40.6 77.9 59.2 28.3 84.6 34.6 49.2 8.0 32.6 39.6 45.9 IntraDA [41] 90.6 37.1 82.6 30.1 19.1 29.5 32.4 20.6 85.7 40.5 79.7 58.7 31.1 86.3 31.5 48.3 0.0 30.2 35.8 46.3 CRST [83] 91.0 55.4 80.0 33.7 21.4 37.3 32.9 24.5 85.0 34.1 80.8 57.7 24.6 84.1 27.8 30.1 26.9 26.0 42.3 47.1 PyCDA [31] 90.5 36.3 84.4 32.4 28.7 34.6 36.4 31.5 86.8 37.9 78.5 62.3 21.5 85.6 27.9 34.8 18.0 22.9 49.3 47.4 PLCA [23] 84.0 30.4 82.4 35.3 24.8 32.2 36.8 24.5 85.5 37.2 78.6 66.9 32.8 85.5 40.4 48.0 8.8 29.8 41.8 47.7 91.3 44.9 ResNet-101 WeakSegDA [46] 91.6 47.4 84.0 30.4 28.3 31.4 37.4 35.4 83.9 38.3 83.9 61.2 28.2 83.7 28.8 41.3 8.8 24.7 46.4 48.2</cell><cell>21.7 26.1 27.8 26.6 28.7 28.4 31.1 29.1 29.5 31.0 32.7 31.6</cell></row><row><cell></cell><cell>BDL [30]</cell><cell cols="13">91.0 44.7 84.2 34.6 27.6 30.2 36.0 36.0 85.0 43.6 83.0 58.6 31.6 83.3 35.3 49.7 3.3 28.8 35.6 48.5</cell><cell>32.9</cell></row><row><cell></cell><cell>CrCDA [22]</cell><cell cols="13">92.4 55.3 82.3 31.2 29.1 32.5 33.2 35.6 83.5 34.8 84.2 58.9 32.2 84.7 40.6 46.1 2.1 31.1 32.7 48.6</cell><cell>31.7</cell></row><row><cell></cell><cell>SIM [64]</cell><cell cols="13">90.6 44.7 84.8 34.3 28.7 31.6 35.0 37.6 84.7 43.3 85.3 57.0 31.5 83.8 42.6 48.5 1.9 30.4 39.0 49.2</cell><cell>33.9</cell></row><row><cell></cell><cell>FADA [59]</cell><cell cols="13">92.5 47.5 85.1 37.6 32.8 33.4 33.8 18.4 85.3 37.7 83.5 63.2 39.7 87.5 32.9 47.8 1.6 34.9 39.5 49.2</cell><cell>32.4</cell></row><row><cell></cell><cell>LDR [71]</cell><cell cols="13">90.8 41.4 84.7 35.1 27.5 31.2 38.0 32.8 85.6 42.1 84.9 59.6 34.4 85.0 42.8 52.7 3.4 30.9 38.1 49.5</cell><cell>34.3</cell></row><row><cell></cell><cell>CCM [25]</cell><cell cols="13">93.5 57.6 84.6 39.3 24.1 25.2 35.0 17.3 85.0 40.6 86.5 58.7 28.7 85.8 49.0 56.4 5.4 31.9 43.2 49.9</cell><cell>33.7</cell></row><row><cell></cell><cell>CAG-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Experimental results for Synscapes ? Cityscapes. 94.2 60.9 85.1 29.1 25.2 38.6 43.9 40.8 85.2 29.7 88.2 64.4 40.6 85.8 31.5 43.0 28.3 30.5 56.</figDesc><table><row><cell cols="2">Backbone Method</cell><cell>r o a d</cell><cell>s id e .</cell><cell>b u il .</cell><cell>w a ll</cell><cell>fe n c e</cell><cell>p o le</cell><cell>li g h t</cell><cell>s ig n</cell><cell>v e g</cell><cell>t e r r .</cell><cell>s k y</cell><cell>p e r s .</cell><cell>r id e r</cell><cell>c a r</cell><cell>t r u c k</cell><cell>b u s</cell><cell>t r a in m b ik e b ik e</cell><cell>mIoU mIoUtail</cell></row><row><cell></cell><cell>Source Only</cell><cell cols="18">81.8 40.6 76.1 23.3 16.8 36.9 36.8 40.1 83.0 34.8 84.9 59.9 37.7 78.4 20.4 20.5 7.8 27.3 52.5 45.3</cell><cell>28.9</cell></row><row><cell>ResNet-101</cell><cell cols="19">AdaptSegNet [54] 7 52.7 IntraDA [41] 94.0 60.0 84.9 29.5 26.2 38.5 41.6 43.7 85.3 31.7 88.2 66.3 44.7 85.7 30.7 53.0 29.5 36.5 60.2 54.2</cell><cell>36.3 38.8</cell></row><row><cell></cell><cell>Ours</cell><cell cols="18">92.7 49.4 86.7 37.2 38.9 40.0 48.5 45.8 87.4 41.8 88.2 69.0 45.3 86.6 33.7 51.2 38.1 43.6 61.0 57.1 44.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Experimental results for SYNTHIA ? Cityscapes. mIoU * denotes the mean IoU of 13 classes, excluding the classes with * . 79.8 4.8 0.1 24.1 22.8 17.8 79.4 76.5 60.8 24.7 85.7 33.5 26.4 54.4 46.1 54.5 Ours 86.9 43.2 81.6 16.2 0.2 31.4 12.7 12.1 83.1 78.8 63.2 23.7 86.9 56.1 33.8 45.7 47.2 54.4</figDesc><table><row><cell cols="2">Backbone Method</cell><cell>r o a d</cell><cell>s id e .</cell><cell>b u il .</cell><cell>w a ll  *</cell><cell>fe n c e  *</cell><cell>p o le  *</cell><cell>li g h t</cell><cell>s ig n</cell><cell>v e g</cell><cell>s k y</cell><cell>p e r s .</cell><cell>r id e r</cell><cell>c a r</cell><cell>b u s</cell><cell>m b ik e</cell><cell>b ik e</cell><cell>mIoU mIoU  *</cell></row><row><cell></cell><cell>AdvEnt [58]</cell><cell cols="17">67.9 29.4 71.9 6.3 0.3 19.9 0.6 2.6 74.9 74.9 35.4 9.6 67.8 21.4 4.1 15.5 31.4 36.6</cell></row><row><cell></cell><cell>CrCDA [22]</cell><cell cols="17">74.5 30.5 78.6 6.6 0.7 21.2 2.3 8.4 77.4 79.1 45.9 16.5 73.1 24.1 9.6 14.2 35.2 41.1</cell></row><row><cell></cell><cell>CBST [82]</cell><cell cols="17">69.6 28.7 69.5 12.1 0.1 25.4 11.9 13.6 82.0 81.9 49.1 14.5 66.0 6.6 3.7 32.4 35.4 36.1</cell></row><row><cell>VGG-16</cell><cell cols="5">AdaptSegNet [54] 78.9 29.2 75.5 -CLAN [35] 80.4 30.7 74.7 -</cell><cell>--</cell><cell>--</cell><cell cols="10">0.1 4.8 72.6 76.7 43.4 8.8 71.1 16.0 3.6 8.4 1.4 8.0 77.1 79.0 46.5 8.9 73.8 18.2 2.2 9.9</cell><cell>--</cell><cell>37.6 39.3</cell></row><row><cell></cell><cell>APODA [70]</cell><cell cols="4">82.9 31.4 72.1 -</cell><cell>-</cell><cell cols="11">-10.4 9.7 75.0 76.3 48.5 15.5 70.3 11.3 1.2 29.4</cell><cell>-</cell><cell>41.1</cell></row><row><cell></cell><cell>FADA [59]</cell><cell cols="17">80.4 35.9 80.9 2.5 0.3 30.4 7.9 22.3 81.8 83.6 48.9 16.8 77.7 31.1 13.5 17.9 39.5 46.0</cell></row><row><cell></cell><cell>Ours</cell><cell cols="17">86.6 41.0 79.5 1.7 0.2 28.5 0.0 6.8 80.5 82.7 54.8 14.5 83.3 36.3 19.7 32.3 40.5 48.3</cell></row><row><cell></cell><cell>Source Only</cell><cell cols="17">56.8 21.5 75.5 5.3 0.1 26.2 10.3 13.8 77.2 73.2 53.6 15.6 77.1 30.3 10.9 17.5 35.3 41.0</cell></row><row><cell></cell><cell cols="18">AdaptSegNet [54] 79.2 37.2 78.8 10.5 0.3 25.1 9.9 10.5 78.2 80.5 53.5 19.6 67.0 29.5 21.6 31.3 39.5 45.9</cell></row><row><cell></cell><cell>AdvEnt [58]</cell><cell cols="17">87.0 44.1 79.7 9.6 0.6 24.3 4.8 7.2 80.1 83.6 56.4 23.7 72.7 32.6 12.8 33.7 40.8 47.6</cell></row><row><cell></cell><cell>CLAN [35]</cell><cell cols="4">81.3 37.0 80.1 -</cell><cell>-</cell><cell cols="11">-16.1 13.7 78.2 81.5 53.4 21.2 73.0 32.9 22.6 30.7</cell><cell>-</cell><cell>47.8</cell></row><row><cell></cell><cell>IntraDA [41]</cell><cell cols="17">84.3 37.7 79.5 5.3 0.4 24.9 9.2 8.4 80.0 84.1 57.2 23.0 78.0 38.1 20.3 36.5 41.7 48.9</cell></row><row><cell></cell><cell>CBST [82]</cell><cell cols="17">68.0 29.9 76.3 10.8 1.4 33.9 22.8 29.5 77.6 78.3 60.6 28.3 81.6 23.5 18.8 39.8 42.6 48.9</cell></row><row><cell></cell><cell>SSF-DAN [10]</cell><cell cols="4">84.6 41.7 80.8 -</cell><cell>-</cell><cell cols="11">-11.5 14.7 80.8 85.3 57.5 21.6 82.0 36.0 19.3 34.5</cell><cell>-</cell><cell>50.0</cell></row><row><cell></cell><cell>CrCDA [22]</cell><cell cols="17">86.2 44.9 79.5 8.3 0.7 27.8 9.4 11.8 78.6 86.5 57.2 26.1 76.8 39.9 21.5 32.1 42.9 50.0</cell></row><row><cell></cell><cell>CRST [83]</cell><cell cols="17">67.7 32.2 73.9 10.7 1.6 37.4 22.2 31.2 80.8 80.5 60.8 29.1 82.8 25.0 19.4 45.3 43.8 50.1</cell></row><row><cell></cell><cell>BDL [30]</cell><cell cols="4">86.0 46.7 80.3 -</cell><cell>-</cell><cell cols="11">-14.1 11.6 79.2 81.3 54.1 27.9 73.7 42.2 25.7 45.3</cell><cell>-</cell><cell>51.4</cell></row><row><cell>ResNet-101</cell><cell cols="18">WeakSegDA [46] 92.0 53.5 80.9 11.4 0.4 21.8 3.8 6.0 81.6 84.4 60.8 24.4 80.5 39.0 26.0 41.7 44.3 51.9 SIM [64] 83.0 44.0 80.3 ---17.1 15.8 80.5 81.8 59.9 33.1 70.2 37.3 28.5 45.8 -52.1</cell></row><row><cell></cell><cell>FDA [72]</cell><cell cols="4">79.3 35.0 73.2 -</cell><cell>-</cell><cell cols="11">-19.9 24.0 61.7 82.6 61.4 31.1 83.9 40.8 38.4 51.1</cell><cell>-</cell><cell>52.5</cell></row><row><cell></cell><cell>FADA [59]</cell><cell cols="17">84.5 40.1 83.1 4.8 0.0 34.3 20.1 27.2 84.8 84.0 53.5 22.6 85.4 43.7 26.8 27.8 45.2 52.5</cell></row><row><cell></cell><cell cols="5">CAG-UDA [75] 84.8 41.7 85.5 -</cell><cell>-</cell><cell cols="11">-13.7 23.0 86.5 78.1 66.3 28.1 81.8 21.8 22.9 49.0</cell><cell>-</cell><cell>52.6</cell></row><row><cell></cell><cell>CCM [25]</cell><cell cols="17">79.6 36.4 80.6 13.3 0.3 25.5 22.4 14.9 81.8 77.4 56.8 25.9 80.7 45.3 29.9 52.0 45.2 52.9</cell></row><row><cell></cell><cell>APODA [70]</cell><cell cols="4">86.4 41.3 79.3 -</cell><cell>-</cell><cell cols="11">-22.6 17.3 80.3 81.6 56.9 21.0 84.1 49.1 24.6 45.7</cell><cell>-</cell><cell>53.1</cell></row><row><cell></cell><cell>LDR [71]</cell><cell cols="4">85.1 44.5 81.0 -</cell><cell>-</cell><cell cols="11">-16.4 15.2 80.1 84.8 59.4 31.9 73.2 41.0 32.6 44.7</cell><cell>-</cell><cell>53.1</cell></row><row><cell></cell><cell>PLCA [23]</cell><cell cols="17">82.6 29.0 81.0 11.2 0.2 33.6 24.9 18.3 82.8 82.3 62.1 26.5 85.6 48.9 26.8 52.2 46.8 54.0</cell></row><row><cell></cell><cell>PixMatch [38]</cell><cell cols="2">92.5 54.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Ablation of the proposed loss functions.</figDesc><table><row><cell>Method</cell><cell>L s cl L t cl L ssl</cell><cell cols="3">GTA5 ? Cityscapes SYNTHIA ? Cityscapes mIoU mIoU mIoU*</cell></row><row><cell>Baseline [54]</cell><cell>?</cell><cell>41.4 44.5</cell><cell>39.5 42.3</cell><cell>45.9 49.1</cell></row><row><cell></cell><cell>?</cell><cell>43.9</cell><cell>40.8</cell><cell>47.5</cell></row><row><cell>Ours</cell><cell>? ?</cell><cell>49.2</cell><cell>45.8</cell><cell>52.6</cell></row><row><cell></cell><cell>? ? ?</cell><cell>52.1</cell><cell>47.2</cell><cell>54.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Hyperparameter study on ?.</figDesc><table><row><cell>? 0.0 0.1 0.2 0.5 0.8 1.0</cell></row><row><cell>mIoU 51.1 52.1 52.1 52.0 51.7 48.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Hyperparameter study ?.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/RogerZhangzz/CAG_UDA/issues/6</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Semi-supervised semantic segmentation with pixel-level contrastive learning from a class-wise memory bank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sabater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ferstl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Montesano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Murillo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="8219" to="8228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Contrastive learning of global and local features for medical image segmentation with limited annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chaitanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Erdil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="833" to="851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ICML</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="1597" to="1607" />
			<date type="published" when="2020" />
			<publisher>PMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">No more discrimination: Cross city adaptation of road scene segmenters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="1992" to="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Ssfdan: Separated semantic feature based domain adaptation network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="982" to="991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="136" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Lempitsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>PMLR</publisher>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1180" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Self-paced contrastive learning with hybrid memory for domain adaptive object re-id</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Are we ready for autonomous driving? the KITTI vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3354" to="3361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Geodesic flow kernel for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="2066" to="2073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="2672" to="2680" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9726" to="9735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">CyCADA: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>PMLR</publisher>
			<biblScope unit="page" from="1989" to="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Fcns in the wild: Pixel-level adversarial and constraint-based adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno>abs/1612.02649</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Contextual-relation consistent domain adaptation for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ECCV</title>
		<imprint>
			<biblScope unit="volume">12360</biblScope>
			<biblScope unit="page" from="705" to="722" />
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Pixel-level cycle association: A new perspective for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Learning cross-modal contrastive features for video domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="13618" to="13627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Content-consistent matching for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ECCV</title>
		<imprint>
			<biblScope unit="volume">12359</biblScope>
			<biblScope unit="page" from="440" to="456" />
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Joint adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="729" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Domain invariant and class discriminative feature learning for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4260" to="4273" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generalized domain conditioned adaptation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell. pp</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Transferable semantic augmentation for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="11516" to="11525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="6936" to="6945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Constructing self-motivated pyramid curriculums for cross-domain semantic segmentation: A non-adversarial approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="6757" to="6766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Bapa-net: Boundary adaptation and prototype alignment for cross-domain semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="8801" to="8811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Transferable representation learning with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3071" to="3085" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Conditional adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="1647" to="1657" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2507" to="2516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Pareto domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">86</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Pixmatch: Unsupervised domain adaptation via pixelwise consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Melas-Kyriazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Manrai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="12435" to="12445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Visual attention control by sensor space segmentation for a small quadruped robot based on information criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mitsunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Asada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RoboCup</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">2377</biblScope>
			<biblScope unit="page" from="154" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno>abs/1807.03748</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unsupervised intra-domain adaptation for semantic segmentation through self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rameau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3764" to="3773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Transferrable prototypical networks for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2239" to="2247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Contrastive learning for unpaired imageto-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ECCV</title>
		<imprint>
			<biblScope unit="volume">12354</biblScope>
			<biblScope unit="page" from="319" to="345" />
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>K?pf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="8024" to="8035" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Domain adaptive semantic segmentation using weak labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Roy-Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ECCV</title>
		<imprint>
			<biblScope unit="volume">12354</biblScope>
			<biblScope unit="page" from="571" to="587" />
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Moment matching for multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="1406" to="1415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Dataset Shift in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quionero-Candela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schwaighofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>PMLR</publisher>
			<biblScope unit="page" from="8748" to="8763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="102" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<editor>MICCAI.</editor>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Lopez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="3234" to="3243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7472" to="7481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Domain adaptation for structured output via discriminative patch representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="1456" to="1465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="4068" to="4076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Formation control of nonholonomic mobile robots with omnidirectional visual servoing and motion segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Shakernia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<editor>ICRA</editor>
		<imprint>
			<date type="published" when="2003" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="584" to="589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2517" to="2526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Classes matter: A finegrained adversarial approach to cross-domain semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ECCV</title>
		<imprint>
			<biblScope unit="volume">12359</biblScope>
			<biblScope unit="page" from="642" to="659" />
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Domain adaptive semantic segmentation with self-supervised depth estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Fink</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="8515" to="8525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Exploring crossimage pixel contrast for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="7303" to="7313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Dense contrastive learning for self-supervised visual pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3024" to="3033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Uncertainty-aware pseudo label refinery for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="9092" to="9101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Differential treatment for stuff and things: A simple unsupervised domain adaptation method for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="12635" to="12644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Synscapes: A photorealistic synthetic dataset for street scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wrenninge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Unger</surname></persName>
		</author>
		<idno>abs/1810.08705</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Active learning for domain adaptation: An energy-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/2112.01406</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Learning semantic representations for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<editor>ICML.</editor>
		<imprint>
			<date type="published" when="2018" />
			<publisher>PMLR</publisher>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="5419" to="5428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Propagate yourself: Exploring pixel-level consistency for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="16684" to="16693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">An adversarial perturbation oriented domain adaptation approach for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="12613" to="12620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">An adversarial perturbation oriented domain adaptation approach for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="12613" to="12620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Label-driven reconstruction for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ECCV</title>
		<imprint>
			<biblScope unit="volume">12372</biblScope>
			<biblScope unit="page" from="480" to="498" />
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">FDA: fourier domain adaptation for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="4084" to="4094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Prototypical cross-domain self-supervised learning for few-shot unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13834" to="13844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Prototypical pseudo label denoising and target structure learning for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="12414" to="12424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Category anchor-guided unsupervised domain adaptation for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="433" to="443" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Curriculum domain adaptation for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="2039" to="2049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6230" to="6239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Learning discriminative feature with CRF for unsupervised video object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Quan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV. Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">12372</biblScope>
			<biblScope unit="page" from="445" to="462" />
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Joint semantic segmentation and boundary detection using iterative pyramid contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Quan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13663" to="13672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Joint 3d instance segmentation and object detection for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="1836" to="1846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="2242" to="2251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V K V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ECCV</title>
		<imprint>
			<biblScope unit="volume">11207</biblScope>
			<biblScope unit="page" from="297" to="313" />
			<date type="published" when="2018" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Confidence regularized selftraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V K V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="5981" to="5990" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
