<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PolyNet: Polynomial Neural Network for 3D Shape Recognition with PolyShape Representation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Yavartanoo</surname></persName>
							<email>myavartanoo@snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">SNU ECE &amp; ASRI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Hsuan</forename><surname>Hung</surname></persName>
							<email>hungsh@oregonstate.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Oregon State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reyhaneh</forename><surname>Neshatavar</surname></persName>
							<email>reyhanehneshat@snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">SNU ECE &amp; ASRI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
							<email>zhangyue@oregonstate.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Oregon State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung</forename><forename type="middle">Mu</forename><surname>Lee</surname></persName>
							<email>kyoungmu@snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">SNU ECE &amp; ASRI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PolyNet: Polynomial Neural Network for 3D Shape Recognition with PolyShape Representation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T19:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>3D shape representation and its processing have substantial effects on 3D shape recognition. The polygon mesh as a 3D shape representation has many advantages in computer graphics and geometry processing. However, there are still some challenges for the existing deep neural network (DNN)-based methods on polygon mesh representation, such as handling the variations in the degree and permutations of the vertices and their pairwise distances. To overcome these challenges, we propose a DNNbased method (PolyNet) and a specific polygon mesh representation (PolyShape) with a multi-resolution structure. PolyNet contains two operations; (1) a polynomial convolution (PolyConv) operation with learnable coefficients, which learns continuous distributions as the convolutional filters to share the weights across different vertices, and (2) a polygonal pooling (PolyPool) procedure by utilizing the multi-resolution structure of PolyShape to aggregate the features in a much lower dimension. Our experiments demonstrate the strength and the advantages of PolyNet on both 3D shape classification and retrieval tasks compared to existing polygon mesh-based methods and its superiority in classifying graph representations of images. The code is publicly available from this link. arXiv:2110.07882v1 [cs.CV]  </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, increasing applications of 3D shapes representation have made it a fundamental problem in computer vision, computer graphics, and augmented reality. The structure and the high-quality appearance of the representation significantly impact many tasks, such as 3D shape classification and retrieval. With the advent of deep neural network (DNN) architectures, several methods have been proposed to learn 3D shapes. Generally, these methods can be categorized into four groups based on the input shape representation; point clouds <ref type="bibr" target="#b47">[47,</ref><ref type="bibr" target="#b48">48]</ref>, voxel grids <ref type="bibr" target="#b64">[64,</ref><ref type="bibr" target="#b41">41]</ref>, 2D projections <ref type="bibr" target="#b56">[56,</ref><ref type="bibr" target="#b52">52,</ref><ref type="bibr" target="#b50">50,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b63">63]</ref>, and polygon meshes <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b40">40]</ref>. The point clouds suffer from harsh noises and wasted substantial structural information of the 3D shapes. The voxel grids require large memory, and also rendering voxel grids generates unnecessarily voluminous data and quantization artifacts. Furthermore, 2D projection representations encounter severe self-occlusions.</p><p>By contrast, a polygon mesh is a collection of vertices and faces that defines a 3D shape smoothly and entirely. Therefore, this representation contains structural information without any harsh noises, severe artifacts, and selfocclusions. Additionally, it is a memory-efficient representation that can store the full geometry details by reducing unnecessary voluminous data. However, in polygon meshbased methods, weight sharing is still a challenging problem due to variations in the degree of vertices, the permutation of adjacent vertices, and their pairwise distances.</p><p>To overcome the limitations of the polygon mesh-based methods, in this work, we propose PolyNet, a novel network that can effectively learn and extract features of a polygon mesh representation of 3D shapes by a continuous polynomial convolution (PolyConv). PolyConv is a polynomial function with learnable coefficients which learns continuous distributions as the convolutional filters to share the corresponding weights among the features of the vertices in the local patches made from each vertex and its adjacent vertices on the surface. This operation is invariant to the number of adjacent vertices, their permutations, and their pairwise distances nearby the central vertex in the local patch. Moreover, we design PolyShape representation, a specific polygon mesh representation with a multi-resolution structure. We utilize this multi-resolution attribute to design our PolyPool operation and apply it after each PolyConv layer. This PolyPool operation reduces the mesh resolution by a fixed factor at each layer. We achieve the best classification accuracy and mean Average Precision (mAP) compared to the previous methods based on voxel grid and polygon mesh and comparable performance to point cloud-based methods. We also show the superiority of our designed PolyConv on the challenging 75 Superpixel MNIST dataset. We summarize the main contributions of our method as follows:</p><p>? We propose PolyNet, a novel neural network method with a continuous convolution operation invariant to the number of adjacent vertices, their permutations, and their pairwise distances in 3D shapes.</p><p>? We employ PolyNet on PolyShape, a polygon mesh representation with a multi-resolution structure that enables us to use a pooling operation named PolyPool.</p><p>? We achieve an improvement in classification and retrieval tasks compared to the previous mesh-based methods on the ModelNet dataset and the best classification performance on the 75 Superpixel MNIST.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>In this section, we review the related works based on the representation of the input 3D shapes: point cloud, voxel grid, 2D projection, and polygon mesh. Point cloud. PointNet <ref type="bibr" target="#b47">[47]</ref>, as a simple and effective DNNbased method on point clouds, learns the features directly from each point and aggregate them as one global representation. However, extracting local structures is important for the success of convolutional architectures. To overcome the lack of local structure of this method, PointNet++ <ref type="bibr" target="#b48">[48]</ref> proposes a hierarchical neural network that employs Point-Net <ref type="bibr" target="#b47">[47]</ref> on the group of points divided into overlapping local patches. Te et al. <ref type="bibr" target="#b57">[57]</ref> and Wang et al. <ref type="bibr" target="#b60">[60]</ref> utilized the GraphCNNs to learn the features from a local graph formed by the connection of the adjacent points. These graph-based methods produce little shape information since they do not explicitly represent the local neighboring points in an ordered alignment. Voxel grid. 3D ShapeNets <ref type="bibr" target="#b64">[64]</ref> and VoxNet <ref type="bibr" target="#b41">[41]</ref> transfer a 3D shape to a structured binary 3D grid called voxel gird. Then they learn the global features from the voxels by extending the CNN architectures from 2D to 3D convolutions. To reduce the computational complexity on the sparse voxels, Riegler et al. <ref type="bibr" target="#b49">[49]</ref> and Wang et al. <ref type="bibr" target="#b61">[61]</ref> applied the octree data structure. However, these methods require heavy computations and unnecessarily voluminous data. 2D projection. MVCNN <ref type="bibr" target="#b56">[56]</ref> and RotationNet <ref type="bibr" target="#b24">[24]</ref> learn the features of a 3D shape over a multi-view rendered 2D images based on conventional 2D CNNs. Moreover, pooling operations aggregate these feature values to reduce the rotation effects of the 3D shape <ref type="bibr" target="#b52">[52,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b56">56]</ref>. However, these pooling operations lose a lot of geometric details among the views, such as two surfaces occluded to each other. Se-qViews2SeqLabels <ref type="bibr" target="#b19">[19]</ref> and SPNet VE <ref type="bibr" target="#b63">[63]</ref> aggregate the information among the sequential views by considering the view specific importance to prevent the lost information. On the other hand, DeepPano <ref type="bibr" target="#b52">[52]</ref> and PANORAMA-NN <ref type="bibr" target="#b50">[50]</ref> consider a panoramic view of the 3D shape. They project the shape into a cylinder surrounding it to accumulate the contents of multiple views altogether. To extend the number of viewpoints, utilizing a sphere instead of the cylinder leads CNNs to cover all views and learn more robust features consistent with rotations <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b63">63]</ref>. However, these image-based methods suffer from self-occlusions. Polygon mesh. A polygon mesh is a discrete representation of the surface of a 3D shape with faces and vertices. This representation can be expressed as a graph; accordingly, any graph-based methods can be applied to it. The existing graph-based methods are classified into two main categories: spectral methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b32">32]</ref> and spatial methods <ref type="bibr" target="#b42">[42,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b23">23]</ref>. The convolution operation in the spectral domain is defined by the eigendecomposition of the graph Laplacian, where the eigenvectors are the same as the Fourier basis <ref type="bibr" target="#b7">[8]</ref>. This process is basisdependent, which indicates applying the learned parameters producing different features on a new domain <ref type="bibr" target="#b37">[37]</ref>. Moreover, this operation is non-localized filtering in the spectral domain <ref type="bibr" target="#b9">[10]</ref>. An efficient method to solve the nonlocalization problem is approximating the local spectral filters via the Chebyshev polynomial expansion <ref type="bibr" target="#b9">[10]</ref>. On the other hand, there is no easy way to induce the weight sharing across different locations of the graph due to the difficulty of matching local neighborhoods in the spatial domain <ref type="bibr" target="#b7">[8]</ref>. Nevertheless, Atwood and Towsley <ref type="bibr" target="#b1">[2]</ref> proposed a spatial filtering method that assumes information is transferred from a vertex to its adjacent vertex with a specific transition probability. The power of the transition probability matrix implies that farther adjacent vertices provide little information for the central vertex. Furthermore, Geodesic CNN <ref type="bibr" target="#b40">[40]</ref>, MoNet <ref type="bibr" target="#b43">[43]</ref>, and SplineCNN <ref type="bibr" target="#b13">[14]</ref> deal with the weight sharing problem by designing local coordinate systems for the central vertex in a local patch. They apply a set of weighting functions to aggregate features on adjacent vertices. Then they compute a learnable weighted average of these aggregated features as the spatial convolution. However, these methods are computationally expensive and require predefined local systems of coordinates. Moreover, Neural3DMM <ref type="bibr" target="#b4">[5]</ref> introduces the spiral convolution operation by enforcing a local ordering of vertices through the spiral operator. An initial point for each spiral is a vertex with the shortest geodesic path to a fixed reference point on a template shape. The remaining vertices of the spiral are ordered in the clockwise or counterclockwise directions inductively. However, finding a reference point for an arbitrary shape is challenging. Moreover, the initial point is not unique once two or more adjacent vertices have the same shortest path to the reference point. <ref type="figure">Figure 1</ref>: The overview of PolyNet architecture. PolyNet takes a PolyShape as an input and applies four PolyConv followed by instance normalization and pooling layers and three fully connected (FC) followed by batch normalization layers to learn the local and the global features of the shape. Then, we employ the hyperbolic tangent and ReLU activation functions to empower PolyConv and FC layers, respectively. Moreover, PolyPool layers reduce the spatial dimensions and minimize the overfitting by utilizing the multi-resolution structure of the PolyShape. The global average pooling layer avoids the permutation ambiguities of the vertices. Note that V and F refer to the number of vertices and faces for each shape, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PolyNet</head><p>In this section, we explain the details of our PolyNet architecture and its consistency to the number of adjacent vertices, their permutations, and their pairwise distances in 3D shapes. PolyNet learns the features locally by PolyConv operation, and performs PolyPool procedure by utilizing the multi-resolution structure of our designed PolyShape representation. <ref type="figure">Figure 1</ref> shows the overview of our PolyNet architecture. A 3D shape with PolyShape representation passes through a straightforward network with three Poly-Conv layers followed by PolyPool layers and another Poly-Conv layer with a global average pooling to learn and extract the features. Then three fully connected layers classify the shape with these extracted features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Polynomial convolution operation</head><p>To overcome the challenges of the weight sharing across different vertices in the conventional CNNs and GraphC-NNs, we propose PolyConv operation, which learns a probability density function (PDF) as a convolutional filter. Let us assume that the surface of a 3D shape is a differential manifold M. For a point v and its neighbor u in a local patch N (v) on the manifold M, we define signals x : M ? [?1, 1] and y : M ? [?1, 1] as the features at those points, respectively. Without loss of generality, we consider the convolutional weights of the standard CNN as the probability distributions. We then argue that a patch operation D(v) in the standard CNN can be expressed as an expected value over the features on sample points N s (v) ? N (v) surrounding v as Eq. 1:</p><formula xml:id="formula_0">D(v) = E[y|x] = u?Ns(v) w(u)y(u),<label>(1)</label></formula><p>where w(u) is the corresponding probability (weight) to the point u. However, in a general graph or polygon mesh, the locations of the adjacent points are in a continuous domain and can vary; hence, it is not possible to assign a discrete distribution as the weights. Therefore, we assume that there is an unknown conditional PDF that can express the convolution filter weights, and then we can formulate the expected value over each patch as Eq. 2:</p><formula xml:id="formula_1">D(v) = E[y|x] = N (v) yf (y|x)dy,<label>(2)</label></formula><p>where f (y|x) is the conditional probability of the feature y on point u in the neighborhood of the central point v with the given feature x. The conditional probability f (y|x) can be written as Eq. 3:</p><formula xml:id="formula_2">f (y|x) = f (x, y) f x (x) = f (x, y) 1 ?1 f (x, y)dy ,<label>(3)</label></formula><p>where f x (x) is the marginal distribution that can be obtained by integrating the joint probability distribution, f (x, y), over y. Note that, since the value of feature y is defined in</p><formula xml:id="formula_3">[?1, 1] ? R, 1 ?1 f (x, y)dy is a definite integral on the interval [?1, 1] ? R.</formula><p>We reformulate f (y|x) by approximating f (x, y) with a polynomial function of x and y by considering a certain degree d as Eq. 4:</p><formula xml:id="formula_4">f (y|x) = 0?i,j,i+j?d a i,j x i y j 0?i?d b i x i ,<label>(4)</label></formula><p>where the coefficients b i can be directly obtained by computing the marginal distribution f x (x) from f (x, y). To ensure that the polynomial function as a PDF is always positive, the coefficient matrix A in the compact form of the  polynomial function as Eq. 5 must be positive definite.</p><formula xml:id="formula_5">f (x, y) = 0?i,j,i+j?d a i,j x i y j = X T AX &gt; 0,<label>(5)</label></formula><p>where X is the vector of variables x and y with degrees of less or equal d/2. Therefore, instead of learning the coefficient matrix A, we parameterize it as A = BB T 0. Indeed, we approximate the conditional PDF f (x|y) as the continuous convolutional filters with the polynomial functions, which are parameterized by the learnable symmetric matrix B. For more details, refer to the supplementary material. The large degree of freedom in polynomial functions allows approximating any complex distributions.</p><p>It is important to note that since we only have few samples N s (e.g., points, vertices, etc.) in each local patch N on the manifold M, computing the exact expected value over each local patch is not possible with Eq. 2. Therefore, we approximate the integral by taking the weighted average over these sample points as Eq. 6:</p><formula xml:id="formula_6">N (v) yf (y|x)dy 1 |N s (v)| u?Ns(v) yf (y|x). (6)</formula><p>Finally, we design unsqueezed and squeezed operations based on the proposed patch operator as the convolutions to learn from the input features, as shown in <ref type="figure" target="#fig_0">Figure 2</ref>. In the first approach, similar to the conventional CNNs, we consider multiple conditional PDFs corresponding to the input and the output channels as the convolution filters. However, this operation requires heavy computations and large memory usage. Therefore, we squeeze it by allocating different conditional PDFs to only the input channels and aggregate the results by a fully connected layer. The second approach is beneficial when the number of input vertices is large. Therefore, with this continuous convolution operation, we can locally learn the features from the surface of 3D shapes, which is invariant to the number of vertices in a local patch, their permutation, and their pairwise distances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Polygonal shape representation and pooling</head><p>To apply pooling after each convolution operation, we present PolyShape representation with a multi-resolution structure made of a sequence of the subdivisions and shape fittings, as shown in <ref type="figure">Figure 3</ref>. This multi-resolution structure enables the pooling operations without any learnable parameter, which is similar to the multi-level pooling on images. Moreover, PolyShape maintains the structural details and the topology of the shape after each pooling and provides a semi-regular structure that benefits the analysis of the local structure of the shape (i.e., each vertex and its corresponding neighborhood) <ref type="bibr" target="#b46">[46]</ref>.</p><p>For PolyShape processing, we first employ the mesh fusion <ref type="bibr" target="#b55">[55]</ref> to a given 3D CAD model for the abstraction of the shapes with a simpler topology. Next, we fix the geometric errors of the meshes, such as the non-manifold edges and double vertices, and then reduce the number of the vertices to obtain a coarse mesh with nearly 400 vertices. Lastly,</p><formula xml:id="formula_7">PolyShape 3D CAD Model X Y Z Coarse</formula><p>Subdivision Level  <ref type="figure">Figure 3</ref>: The overview of PolyShape processing. A given 3D CAD model passes through a preprocessing pipeline to produce a coarse polygon mesh with a simpler topology and single connected component. Next, the subdivisions and shape fitting procedures sequentially create PolyShape with the multi-resolution structure for the shape.</p><p>we subdivide the coarse mesh and fit the resulting mesh to the given model to restore the details of the original shape.</p><p>We apply this sub-division routine iteratively, as frequent as the number of the pooling layers in the PolyNet (i.e., 3 times). For the subdivision, there are two common methods: the primal triangle quadrisection (PTQ) <ref type="bibr" target="#b39">[39]</ref> and the ? 3-subdivision <ref type="bibr" target="#b28">[28]</ref>. PTQ is a straightforward approach that splits a triangle into four sub-triangles. It creates new vertices on each edge in the original mesh and connects them to each of the other new vertices from the same face. The other strategy, ? 3-subdivision, adds the new vertices inside each triangle in the original mesh and connects the new vertices to each of its three old surrounding vertices and adjacent new vertices. Every two iterations of the ? 3subdivision separate each original triangle into nine subtriangles. Thus, PolyShapes have fewer triangles by the ? 3subdivision than the PTQ. We evaluate the effectiveness of the PolyShapes made by both subdivisions in Section 4.</p><p>With the multi-resolution structure of PolyShape, we can downsample the output of PolyConv layers by collapsing the neighboring vertices to each interior vertex (i.e., the vertices of the coarser meshes), shown in <ref type="figure" target="#fig_1">Figure 4</ref>. The PTQ and ? 3-subdivision upsample the mesh vertices by adding another vertex at the center of each edge and each triangle, respectively. The downsampling procedures are accomplished as the inverse process of the upsampling methods, which allow us to generate relatively larger polygons, as shown in <ref type="figure" target="#fig_1">Figure 4</ref>. Therefore, we can reduce the number of polygons by the factors of four and three by employing the PTQ and ? 3-subdivision methods, respectively. We use these downsampling procedures as the pooling, which facilitates aggregating the features, where each vertex V on the downsampled mesh takes the maximum (max-pool) over </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we present the details of the datasets and several experiments of PolyNet on the 3D shapes with and without PolyShape representation and graph representation of images. We compare our proposed method with the stateof-the-art methods on both classification and retrieval tasks. We use Adam optimizer in all of our experiments with the initial learning rate as 1.e-3 and 1.e-2 for unsqueezed and squeezed cases, respectively. We set a mini-batch size as 100 and 10 for experiments on 3D shapes and graph representation of images, respectively. We choose hyperbolic tangent for the activation functions on PolyConv layers to guarantee that the input features to the next layers are in the interval [?1, 1] ? R, and we use cross-entropy loss between the model predicted scores and ground truth labels. We also implement our model in Python3.6 using PyTorch via CUDA instruction. PolyShape processing, including both subdivision methods, takes 92 ms for one CAD model on average, and we ensure all the conversions are successful for the ModelNet dataset. The average testing times for the baseline of PolyNet per shape for the ? 3-subdivision and PTQ are 13 ms and 18 ms, respectively. We will publish the code for both PolyShape processing and PolyNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>In our experiments, we use both the ModelNet-10 and the ModelNet-40 datasets [64] containing 4,899 CAD models (3991 for training and 908 for testing) in 10 categories and 12,311 CAD models (9843 for training and 2468 for testing) in 40 categories, respectively. We apply our PolyShape processing to the CAD models with Houdini <ref type="bibr" target="#b53">[53]</ref>, a popular 3D modeling software. For more details about the PolyShape pipeline, refer to supplemental material. Additionally, we translate and scale the resulting PolyShapes into the bounding box [?1, 1] 3 ? R 3 . We extract the coordinates (x, y, z) ? R 3 and the normal vectors (nx, ny, nz) ? R 3 , for all vertices as the first input into PolyNet. We also use the MNIST dataset <ref type="bibr" target="#b31">[31]</ref>, which includes 28?28 images. These images are represented as different graphs so that each vertex and each edge corresponds to a superpixel and the spatial relation between two superpixels, respectively <ref type="bibr" target="#b43">[43]</ref>. Therefore, we consider the construction of superpixel-based graphs with 75 vertices. We use the standard splitting of the MNIST dataset, including 60k and 10K images for training and testing, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Convolution operation</head><p>We evaluate our convolution operation PolyConv with different configurations and compare it with various famous convolutional operations as shown in <ref type="table">Table 1</ref>  <ref type="table">Table 1</ref>: Classification accuracy (Acc%), testing time, and number of parameters in only convolution layers on the ModelNet-10 with both subdivision strategies for the various convolution operations in PolyNet.</p><p>memory usage compared to the unsqueezed version due to the less number of learnable parameters, we use it for the experiments of 3D shape classification where the inputs are extremely large (roughly 10k vertices). We consider two different degrees d = 2 and d = 4 for each polynomial function defined in Eq. 5 which each requires six and 21 learnable coefficients for a patch operation, respectively. The results on MoldelNet-10 with both subdivision strategies show that PolyConv with degree d = 2 achieves relatively higher performance than degree d = 4, which can be due to its straightforward and easier to learn structure for approximating the distributions. Furthermore, we evaluate PolyNet on ModelNet-10 by replacing PolyConv with well-known convolutions such as ChebConv <ref type="bibr" target="#b10">[11]</ref>, GCN-Conv <ref type="bibr" target="#b27">[27]</ref>, GMMConv <ref type="bibr" target="#b43">[43]</ref>, SplineConv <ref type="bibr" target="#b13">[14]</ref>, XConv <ref type="bibr" target="#b36">[36]</ref>, and FiLMConv <ref type="bibr" target="#b6">[7]</ref>. We show that PolyConv with degree d = 2 achieves superior performances compared to all mentioned convolutions for both subdivision strategies. Towards a better understanding of the PDFs, we visualize the learned joint PDFs f (x, y) and the marginal PDFs f x (x) of squeezed PolyConv for polynomial functions of degree d = 2 which are learned on the ModelNet-10 dataset with the ? 3-subdivision in <ref type="figure" target="#fig_2">Figure 5</ref>. The results illustrate the diversity of learned PDFs among different input channels and different layers of PolyNet.</p><p>On the other hand, we evaluate our unsqueezed Poly-Conv and compare it with the squeezed PolyConv for the polynomial functions of degree d = 2 on a classical task of handwritten digit classification in the graph representation of the MNIST dataset <ref type="bibr" target="#b43">[43]</ref> with 75 vertices. Despite the simplicity of underlying images, this is a challenging task due to the lack of a regular grid structure among the nodes, as shown in <ref type="figure" target="#fig_3">Figure 6</ref>. We use three convolutional layers (256,256,256) and three fully connected layers (1024,1024,10) in the network architecture. We employ both unsqueezed and squeezed PolyConvs as the convolution operations and the graclus clustering for the pooling procedure. We use the position information of the vertices as the extra features. We show in <ref type="table" target="#tab_3">Table 2</ref> that PolyConv outperforms the existing methods, which demonstrates the strengths of PolyConv to learn features from irregular data as well as semi-regular data. Moreover, we show that while the squeezed version of PolyConv achieves only slightly lower performance, it requires 135k learnable parameters in PolyConv layers, which is much more efficient than unsqueezed PolyConv with 792k parameters. Note that the average testing time for squeezed PolyConv on the samples of the 75 Superpixel MNIST is 1.4 ms, while it is 12.4 ms for the unsquzeed PolyConv.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Pooling layers</head><p>To show the benefits of our PolyPool operation, we apply PolyNet with various configurations of the pooling operation and input data type and compare the results in <ref type="table" target="#tab_4">Table 3</ref>. We consider two different data representations, including data with and without PolyShape processing for the ModelNet-10 dataset. Our experiments demonstrate that PolyPool with PolyShape representation can effectively im-prove the performance, especially by the pooling based on ? 3-subdivision. Moreover, we employ a three-level graclus <ref type="bibr" target="#b11">[12]</ref> as an efficient clustering algorithm on the data without PolyShape representation. However, the results show lower accuracy when we use pooling based on the graclus clustering compared to both ? 3-subdivision and PTQ. We interpret the accuracy gap as the effect of losing structural information of 3D shapes by applying the graclus clustering. Note that we compute the maximum value (maxpool) of each local patch for all pooling strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">3D shape classification</head><p>To improve the 3D shape classification performance, we combine the output of the last PolyConv layer for both subdivisions by taking an average over their features. We compare the classification results of our PolyNet, with the recent state-of-the-art methods in <ref type="table" target="#tab_5">Table 4</ref> on the ModelNet-10 and ModelNet-40 datasets. We note that our PolyNet outperforms all the mesh-based and voxel-based approaches on the classification task and achieves comparable performance to the methods based on point clouds. The performance gaps between the 2D projection-based methods and other methods are due to utilizing pre-trained networks on a large number of images. Moreover, images include texture information produced by lights and shadows, while the other representations suffer from a lack of such information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Acc. (max) MoNet <ref type="bibr" target="#b43">[43]</ref> 91.11 SplineCNN <ref type="bibr" target="#b13">[14]</ref> 95.22 GCGP <ref type="bibr" target="#b59">[59]</ref> 95.80 GAT <ref type="bibr" target="#b3">[4]</ref> 96.19 PNCNN <ref type="bibr" target="#b14">[15]</ref> 98.76 PolyConv (squeezed) 98.39 PolyConv (unsqueezed) 98.95   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">3D shape retrieval</head><p>We also evaluate and compare PolyNet in the retrieval task with previous methods. We extract the output after the softmax, measure similarities between the query and the retrieved shapes by the L1 norm, and rank the relevant shapes. We use mAP to quantitatively compare our retrieval approach to the related methods on both the ModelNet-10 and the ModelNet-40 datasets, as shown in <ref type="table" target="#tab_5">Table 4</ref>. We outperform all previously evaluated methods on the retrieval task based on polygon mesh and voxel grid representations. Lastly, we show some retrieved shapes in a ranked order for the given queries on the ModelNet-10 trained by squeezed PolyConvs, including polynomial functions of degree d = 2 in <ref type="figure">Figure 7</ref>. We illustrate that our method can retrieve visually similar shapes even when the query and retrieved shapes are in different categories (e.g., retrieved table for <ref type="figure">Figure 7</ref>: Retrieval results. This figure demonstrates the retrieved shapes for the given queries using PolyNet. The blue models in the first column are the queries. The retrieved results in green are from the same category as the query, while the results in red are from different categories. From left to right, the results are ordered with a descending rank.</p><p>the query desk and nightstand for the dresser).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose PolyNet, a DNN-based method consists of PolyConv and PolyPool operations to locally learn and aggregate the information on the surface of 3D shapes. In PolyConv, we utilize polynomial functions to learn a continuous distribution as the convolutional filters, which is invariant to the variation in the degree of vertices, their permutations, and their pairwise distances. Moreover, we design PolyShape with a multi-resolution structure that enables applying PolyPool operation without missing geometrical structures after each layer. Our comprehensive evaluations of PolyNet across classification and retrieval tasks and the theoretical analysis indicating the invariant properties of PolyConv demonstrate its strength and superiority over most of the previous methods. In future works, we will explore the applications of PolyNet in 3D shape segmentation and PolyConv in image-based computer vision tasks where there are no regular neighboring connectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S. PolyNet analysis</head><p>In this section, we provide more mathematical and qualitative analysis of our proposed PolyNet with additional explanations of PolyConv operation and the preprocessing procedure of PolyShape and its results. First, we analyze some equations of PolyConv mentioned in the main paper for better understanding. Then we discuss PolyShape preprocessing in detail and show its step-by-step results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.1. Expansion of PolyConv</head><p>We derive the compact form of the polynomial function f (x, y) defined in Eq. 5 in the main paper for d = 2 and d = 4 as in the following Eq. S1 and Eq. S2, respectively. (S1) = a 0,0 + a 1,0 x + a 0,1 y + a 2,0 x 2 + a 1,1 xy + a 0,2 y 2 + a 3,0 x 3 + a 2,1 x 2 y + a 1,2 xy 2 + a 0,3 y 3 + a 4,0 x 4 + a 3,1 x 3 y + a 2,2 x 2 y 2 + a 1,3 xy 3 + a 0,4 y 4 = 0?i,j,i+j?4 a i,j x i y j = f (x, y).</p><formula xml:id="formula_8">X T AX = 1 x y ? ? A 11 A 12 A 13 A 21 A 22 A 23 A 31 A 32 A 33</formula><formula xml:id="formula_9">X T AX = 1 x y x 2 xy y 2 ? ? A 11 A 12 A 13 A 14 A 15 A 16 A 21 A 22 A 23 A 24 A 25 A 26 A 31 A 32 A 33 A 34 A 35 A 36 ? ? ? ? ? ? ? ? ? ? 1 x y x 2 xy y 2 ? ? ? ? ? ? ? ? = A</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(S2)</head><p>Note that we parameterize the matrix A by the matrix B and learn the matrix B instead of the matrix A. The parametrized matrix A for the polynomial functions of de-  </p><p>where B is a learnable symmetric matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.2. Details of PolyShape Processing</head><p>We provide the flowchart of the PolyShape processing in Houdini software in <ref type="figure" target="#fig_5">Figure S1</ref>. Given a 3D CAD model and its cleaned model by mesh fusion, we first resize the models and remove the unused points with the matchsize and clean nodes. Next, we generate the coarse mesh by reducing the number of vertices to 400 with polyreduce and fitting the shape to the 3D CAD model with ray. We create the multiresolution of the PolyShape by subdividing the coarse mesh three times with primal triangle quadrisection (PTQ, subdivide) or ? 3-subdivision (tridivide), respectively. At each iteration of these subdivisions, we fit the generated mesh to the given 3D CAD model to maintain the details of the original shape. <ref type="figure" target="#fig_0">Figure S2</ref> and <ref type="figure">Figure S3</ref> show the resulting PolyShapes of ? 3-subdivision and PTQ with the same input models, respectively. The PolyShapes generated by ? 3-subdivision have fewer faces than the shapes created by PTQ at the same level of details. For the highest resolution of the PolyShapes, ? 3-subdivision creates 0.43 fewer faces than PTQ on average. Therefore, the ? 3-subdivision provides a more efficient representation for storage and the computation of the classification.  <ref type="figure">Figure S3</ref>: PolyShape representation. PolyShape processing results on some samples of ModelNet-10 dataset based on PTQ. PTQ1 to PTQ3 refer to the output of the PolyShape procedure after each level of subdivision. Note that V and F refer to the number of vertices and faces for each shape.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>PolyConv operations over a local patch. A set of conditional PDFs approximated with polynomial functions with learnable coefficients is applied as the convolutional filters to learn the input features on a local patch of vertices N s (v) ? N (v). (a) The unsqueezed operation includes C ? C conditional PDFs as the convolutional filterers which map the input features to the higher dimensional output features. (b) The squeezed operation contains only C conditional PDFs which is combined with a fully connected layer to map the input features to the higher dimensional output features. Note that C and C refer to the size of input channels and output channels, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>PolyPool operations. The black dots and red dots show the vertices before and after PolyPool, respectively. Dash lines indicate the omitted edges after the subdivisions.features values of the vertices v ? {u i } m i=1 in a local patch on the output of PolyConv layers. Therefore, PolyPool enables describing a 3D shape with a large number of vertices by aggregating the features. These aggregated features are much lower in dimension compared to using all of the extracted features and also can improve the performance like the conventional pooling operation of the 2D CNNs<ref type="bibr" target="#b44">[44]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Joint and marginal distributions. Visualization of (a) the learned joint distributions f (x, y) and (b) the marginal distributions f x (x) approximated by polynomial functions of degree d = 2 on the ModelNet-10 with the ? 3-subdivision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>The graphs of the MNIST dataset. Visualization of handwritten digits in the MNIST dataset individually represented as the graph of superpixel with 75 vertices.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>11 +</head><label>11</label><figDesc>(A 12 + A 21 )x + (A 13 + A 31 )y + A 22 x 2 + (A 23 + A 32 )xy + A 33 y 2 = a 0,0 + a 1,0 x + a 0,1 y + a 2,0 x 2 + a 1,1 xy + a 0,2 y 2 = 0?i,j,i+j?2 a i,j x i y j = f (x, y).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure S1 :</head><label>S1</label><figDesc>PolyShape processing in Houdini. Each box refers to a node with the same name in the software.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure S2 :</head><label>S2</label><figDesc>PolyShape representation. PolyShape processing results on some samples of ModelNet-10 dataset based on ? 3subdivision. Sqrt1 to Sqrt3 refer to the output of the PolyShape procedure after each level of subdivision. Note that V and F refer to the number of vertices and faces for each shape.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>93.85 93.38 9ms 93.85 93.30 13ms 179k GMMConv [43] 93.32 92.68 17ms 93.20 92.36 28ms 4.6m FiLMConv [7] 94.43 93.89 9ms 94.30 93.76 13ms 1.1m PolyConv(d = 4) 93.96 93.13 25ms 94.00 92.38 38ms 189k PolyConv(d = 2) 94.52 93.95 13ms 94.40 94.08 18ms 182k</figDesc><table><row><cell>Conv.</cell><cell>? max avg Time max avg Time 3-subdivision PTQ</cell><cell>Params.</cell></row><row><cell>XConv [36]</cell><cell cols="2">84.58 83.31 173ms 85.54 83.85 835ms 473k</cell></row><row><cell cols="3">SplineConv [14] 93.46 92.72 12ms 93.16 92.66 18ms 111m</cell></row><row><cell cols="3">ChebConv [11] 93.95 93.42 12ms 93.70 93.11 14ms 712k</cell></row><row><cell>GCNConv [27]</cell><cell></cell><cell></cell></row><row><cell>. Since</cell><cell></cell><cell></cell></row><row><cell>squeezed PolyConv requires fewer computations and less</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Classification accuracy (Acc%) of various methods and our PolyConv operations on a superpixel representation of the MNIST dataset with 75 vertices.</figDesc><table><row><cell>Pooling</cell><cell>Poly Accuracy Time Num. Shape max avg</cell></row><row><cell>No pooling</cell><cell>94.11 92.69 22ms 2.8k</cell></row><row><cell>Graclus [12]</cell><cell>94.14 92.73 16ms 2.8k</cell></row><row><cell cols="2">PolyPool(PTQ) PolyPool( ? 3-sub) 94.52 93.95 13ms 10.8k 94.40 94.08 18ms 25.7k</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Classification accuracy (Acc%), average testing time, and average number of vertices for various types of poolings and data with and without PolyShape processing. ENN [50] 96.85 93.28 95.56 86.34 SPNet VE [63] 97.25 94.20 92.63 85.21</figDesc><table><row><cell cols="2">Rep. Method</cell><cell cols="4">ModelNet-10 ModelNet-40 Acc mAP Acc mAP</cell></row><row><cell></cell><cell>DeepPano [52]</cell><cell cols="4">85.45 84.18 77.63 76.81</cell></row><row><cell></cell><cell>MVCNN [56]</cell><cell>-</cell><cell>-</cell><cell cols="2">90.10 79.50</cell></row><row><cell>2D Projection</cell><cell>PANORAMA-RotationNet [24]</cell><cell>98.46</cell><cell>-</cell><cell>97.37</cell><cell>-</cell></row><row><cell></cell><cell>3D ShapeNets [64]</cell><cell cols="4">83.54 68.26 77.32 49.23</cell></row><row><cell></cell><cell>VoxNet [41]</cell><cell>92.00</cell><cell>-</cell><cell>83.00</cell><cell>-</cell></row><row><cell>voxel</cell><cell>VRN [6]</cell><cell>93.61</cell><cell>-</cell><cell>91.33</cell><cell>-</cell></row><row><cell>grid</cell><cell>FusionNet [21]</cell><cell>93.11</cell><cell>-</cell><cell>90.80</cell><cell>-</cell></row><row><cell></cell><cell>LP-3DCNN [29]</cell><cell>94.40</cell><cell>-</cell><cell>92.10</cell><cell>-</cell></row><row><cell></cell><cell>PointNet [47]</cell><cell>-</cell><cell>-</cell><cell>89.20</cell><cell>-</cell></row><row><cell></cell><cell>PointNet++ [48]</cell><cell>-</cell><cell>-</cell><cell>91.90</cell><cell>-</cell></row><row><cell></cell><cell>SO-Net [33]</cell><cell>95.50</cell><cell>-</cell><cell>90.80</cell><cell>-</cell></row><row><cell></cell><cell>KCNet [51]</cell><cell>94.40</cell><cell>-</cell><cell>91.00</cell><cell>-</cell></row><row><cell>Point cloud</cell><cell>PCNN [3] SpiderCNN [62] PointCNN [35]</cell><cell>94.90 --</cell><cell>---</cell><cell>92.30 92.40 92.50</cell><cell>---</cell></row><row><cell></cell><cell>DGCNN [1]</cell><cell>-</cell><cell>-</cell><cell>92.90</cell><cell>-</cell></row><row><cell></cell><cell>KPConv [58]</cell><cell>-</cell><cell>-</cell><cell>92.90</cell><cell>-</cell></row><row><cell></cell><cell>RS-CNN [38]</cell><cell>-</cell><cell>-</cell><cell>93.60</cell><cell>-</cell></row><row><cell></cell><cell>SPH [25]</cell><cell cols="4">79.79 44.05 68.23 33.26</cell></row><row><cell></cell><cell>Geometry Image [54]</cell><cell cols="4">88.40 74.90 83.90 51.30</cell></row><row><cell></cell><cell>MeshNet [13]</cell><cell>-</cell><cell>-</cell><cell cols="2">91.90 81.90</cell></row><row><cell></cell><cell>Cross-atlas [34]</cell><cell>91.20</cell><cell>-</cell><cell>87.50</cell><cell>-</cell></row><row><cell>Polygon</cell><cell>SNGC [18]</cell><cell>-</cell><cell>-</cell><cell>91.60</cell><cell>-</cell></row><row><cell>Mesh</cell><cell>MeshWalker [30] PolyNet ( ? 3),(d=2)</cell><cell cols="4">-94.52 83.91 92.14 82.36 -92.30 -</cell></row><row><cell></cell><cell cols="5">PolyNet (PTQ),(d=2) PolyNet (PTQ, ? 3),(d=2) 94.93 84.62 92.42 82.86 94.40 83.84 92.06 81.91</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell>Classification accuracy (Acc%) and mean Aver-</cell></row><row><cell>age Precision (mAP%) of PolyNet compared to the state-</cell></row><row><cell>of-the-art methods based on different representations on the</cell></row><row><cell>ModelNet-10 and the ModelNet-40 datasets.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>11 + (A 12 + A 21 )x + (A 13 + A 31 )y + (A 22 + A 15 + A 51 )x 2 + (A 23 + A 32 + A 14 + A 41 )xy + (A 33 + A 16 + A 61 )y 2 + (A 25 + A 52 )x 3 + (A 35 + A 53 + A 24 + A 42 )x 2 y + (A 26 + A 62 + A 34 + A 43 )xy 2 + (A 36 + A 63 )y 3 + A 55 x 4 + (A 45 + A 54 )x 3 y + (A 44 + A 56 + A 65 )x 2 y 2 + (A 46 + A 64 )xy 3 + A 66 y 4</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>A 11 A 12 A 13 A 21 A 22 A 23 A 31 A 32 A 33 B 11 B 12 B 13 B 12 B 22 B 23 B 13 B 23 B 33 B 11 B 12 B 13 B 12 B 22 B 23 B 13 B 23 B 33 =? A 12 = B 11 B 12 + B 12 B 22 + B 13 B 23 =? A 13 = B 11 B 13 + B 12 B 23 + B 13 B 33 =? A 21 = B 12 B 11 + B 22 B 12 + B 23 B 13 =? A 22 = B 2 12 + B 2 22 + B 2 23 =? A 23 = B 12 B 13 + B 22 B 23 + B 23 B 33 =? A 31 = B 13 B 11 + B 23 B 12 + B 33 B 13 =? A 32 = B 13 B 12 + B 23 B 22 + B 33 B 23</figDesc><table><row><cell cols="2">gree d = 2 is as Eq. S3;</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">A = BB T</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>?</cell><cell>?</cell><cell></cell><cell></cell></row><row><cell>=</cell><cell>?</cell><cell>?</cell><cell></cell><cell></cell></row><row><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>=</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell cols="4">=? A 11 = B 2 11 + B 2 12 + B 2 13</cell><cell></cell></row><row><cell cols="4">=? A 33 = B 2 13 + B 2 23 + B 2 33 ,</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dgcnn: A convolutional neural network over large-scale labeled graphs</title>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diffusionconvolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Atwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">F</forename><surname>Towsley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Point convolutional neural networks by extension operators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matan</forename><surname>Atzmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haggai</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Superpixel image classification with graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H C</forename><surname>Avelar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Tavares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L T</forename><surname>Da Silveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Lamb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural 3d morphable models: Spiral convolutional networks for 3d shape representation learning and generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Bouritsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sergiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stylianos</forename><surname>Bokhnyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Ploumpis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Generative and discriminative voxel modeling with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andr?</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodore</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Weston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graph neural networks with feature-wise linear modulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gnn-Film</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Le-Cun</surname></persName>
		</author>
		<title level="m">Spectral networks and locally connected networks on graphs. CoRR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Taco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>K?hler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spherical cnns. CoRR</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?l</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?l</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Neural Information Processing Systems</title>
		<meeting>the 30th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Weighted graph cuts without eigenvectors a multilevel approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Meshnet: Mesh neural network for 3d shape representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xibin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Splinecnn: Fast geometric deep learning with continuous b-spline kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Weichert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Marc Finzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bondesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<title level="m">Probabilistic numeric convolutional neural networks. ArXiv, abs</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep semantic hashing of 3d geometric features for efficient 3d model retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takahiko</forename><surname>Furuya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryutarou</forename><surname>Ohbuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CGIC</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Surface networks via general covers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Haim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nimrod</forename><surname>Segol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heli</forename><surname>Ben-Hamu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haggai</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lipman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Seqviews2seqlabels: Learning 3d global features via aggregating sequential views by rnn with attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zwicker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L P</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rana</forename><surname>Hanocka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noa</forename><surname>Fish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raja</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shachar</forename><surname>Fleishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fusionnet: 3d object classification using multiple data representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishakh</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><forename type="middle">Bosagh</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep convolutional networks on graph-structured data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Texturenet: Consistent local parametrizations for learning from highresolution signals on meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nie?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rotationnet: Joint object categorization and pose estimation using multiviews from unsupervised viewpoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanezaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nishida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Rotation invariant spherical harmonic representation of 3d shape descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Szymon</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rusinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Geometry Processing</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">3-subdivisionn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leif</forename><surname>Kobbelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques</title>
		<meeting>the 27th Annual Conference on Computer Graphics and Interactive Techniques</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">LP-3DCNN: unveiling local phase in 3d convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudhakar</forename><surname>Kumawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanmuganathan</forename><surname>Raman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Meshwalker: Deep mesh understanding by random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lahav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cayleynets: Graph convolutional neural networks with complex rational spectral filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Levie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">So-net: Selforganizing network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><forename type="middle">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cross-atlas convolution for parameterization invariant learning on textured mesh surface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Quan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingchao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhan</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pointcnn: Convolution on x-transformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingchao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhan</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning spectral descriptors for deformable shape correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Shiming Xiang, and Chunhong Pan. Relation-shape convolutional neural network for point cloud analysis (cvpr 2019 oral &amp; best paper finalist)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Fan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Smooth subdivision surfaces based on triangles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Loop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>University of Utah</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis. Department of Mathematics</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Geodesic convolutional neural networks on riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCVW</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Voxnet: A 3d convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Neural network for graphs: A contextual constructive approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodol?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Max-pooling convolutional neural networks for vision-based hand gesture recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ducatelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Caro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cire?an</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Giusti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSIPA</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning convolutional neural networks for graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Kutzkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Semiregular triangle remeshing: A comprehensive study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Payan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C?line</forename><surname>Roudet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basile</forename><surname>Sauvage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><forename type="middle">O</forename><surname>Ulusoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Octnet</surname></persName>
		</author>
		<title level="m">Learning deep 3d representations at high resolutions. CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Exploiting the PANORAMA Representation for Convolutional Neural Network Classification and Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Sfikas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Workshop on 3D Object Retrieval</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Theoharis Theoharis, and Ioannis Pratikakis</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Mining point cloud local structures by kernel correlation and graph pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiru</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoqing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deeppano: Deep panoramic representation for 3-d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sidefx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Houdini</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep learning 3d shape surfaces using geometry images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayan</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Ramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Learning 3d shape completion under weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Stutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learned-Miller. Multi-view convolutional neural networks for 3d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Rgcnn: Regularized graph cnn for point cloud segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gusi</forename><surname>Te</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongming</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Kpconv: Flexible and deformable convolution for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Emmanuel</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatriz</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Graph convolutional Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Local spectral graph convolution for point set feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Babak</forename><surname>Samari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaleem</forename><surname>Siddiqi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">O-cnn: Octree-based convolutional neural networks for 3d shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Shuai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Spidercnn: Deep learning on point sets with parameterized convolutional filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Spnet: Deep 3d object classification and retrieval using stereographic projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Yavartanoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Euyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
