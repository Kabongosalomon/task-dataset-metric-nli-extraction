<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BBAM: Bounding Box Attribution Map for Weakly Supervised Semantic and Instance Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihun</forename><surname>Yi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaehun</forename><surname>Shin</surname></persName>
							<email>chaehuny@snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
							<email>sryoon@snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">ASRI</orgName>
								<orgName type="institution" key="instit2">INMC</orgName>
								<orgName type="institution" key="instit3">ISRC, and Institute of Engineering Research</orgName>
								<orgName type="institution" key="instit4">Seoul National University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">BBAM: Bounding Box Attribution Map for Weakly Supervised Semantic and Instance Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Weakly supervised segmentation methods using bounding box annotations focus on obtaining a pixel-level mask from each box containing an object. Existing methods typically depend on a class-agnostic mask generator, which operates on the low-level information intrinsic to an image. In this work, we utilize higher-level information from the behavior of a trained object detector, by seeking the smallest areas of the image from which the object detector produces almost the same result as it does from the whole image. These areas constitute a bounding-box attribution map (BBAM), which identifies the target object in its bounding box and thus serves as pseudo ground-truth for weakly supervised semantic and instance segmentation. This approach significantly outperforms recent comparable techniques on both the PASCAL VOC and MS COCO benchmarks in weakly supervised semantic and instance segmentation. In addition, we provide a detailed analysis of our method, offering deeper insight into the behavior of the BBAM. The code is available at:</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Object segmentation is one of the most important steps in image recognition. Advances in deep learning have greatly improved the performance of semantic and instance segmentation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23]</ref> through the use of huge amounts of pixel-level annotated training data. However, annotating with pixel-level masks requires a lot of effort. According to Bearman et al. <ref type="bibr" target="#b3">[4]</ref>, constructing a pixel-level mask for an image containing an average of 2.8 objects takes about 4 minutes. This is why weakly supervised methods have been proposed, in which segmentation networks are trained using annotations that are less detailed than pixel-level masks, such as bounding boxes <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b59">60]</ref>, or image-level tags <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>The most easily obtainable annotation is the class label. * Correspondence to: Sungroh Yoon &lt;sryoon@snu.ac.kr&gt;.</p><p>Labeling an image with class labels takes around 20 seconds <ref type="bibr" target="#b3">[4]</ref>, but it only indicates that objects of certain classes are depicted and gives no information about their locations in the image. Moreover, class labels provide no help in separating different objects of the same class, which is the goal of instance segmentation.</p><p>Bounding boxes provide information about individual objects and their locations. Bounding box annotation takes about 38.1 seconds per image <ref type="bibr" target="#b4">[5]</ref>, which is much more attractive than constructing pixel-level masks. Many researchers have tackled semantic segmentation <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b59">60]</ref> and instance segmentation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b61">62]</ref> using bounding box annotations as a search space in which a class-agnostic object mask can be found by an off-the-shelf object mask generator. These are mostly based on GrabCut <ref type="bibr" target="#b52">[53]</ref> or multiscale combinatorial grouping (MCG) <ref type="bibr" target="#b48">[49]</ref>. Those mask generators operate on the low-level information of images, such as the color or brightness of pixels, and this limits the quality of the resulting mask. Thus, applying these mask generators to bounding box annotations requires additional steps such as estimating what proportion of the pixels in a bounding-box belong to the corresponding object <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b59">60]</ref>, iterative refinement of an estimated mask <ref type="bibr" target="#b10">[11]</ref>, and auxiliary attention modules <ref type="bibr" target="#b33">[34]</ref>.</p><p>We propose a pixel-level method of localizing a target object inside its bounding box using a trained object detector. We make use of attribution maps obtained from the trained object detector, which highlight the image regions that the detector focuses on in conducting object detection. Inspired by the perturbation methods used to explain the output of image classifiers <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref>, we introduce a bounding box attribution map (BBAM) which provides an indication of the smallest areas of an image that are sufficient to make an object detector produce almost the same result as that from the original image. The BBAM identifies the area occupied by the object in each bounding box predicted by the trained object detector. Since this localization takes place at the pixel level, it can be used as a pseudo ground truth for weakly supervised learning of semantic and instance segmentation.</p><p>The main contributions of this paper can be summarized as follows.</p><p>? We propose a bounding box attribution map (BBAM), which can draw on the rich semantics learned by an object detector to produce pseudo ground-truth for training semantic and instance segmentation networks. ? Our technique significantly outperforms previous stateof-the-art methods of weakly supervised semantic and instance segmentation, assessed on the PASCAL VOC 2012 and MS COCO 2017 benchmarks. ? We analyze our method from various viewpoints, providing deeper insights into the properties of the BBAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Fully supervised semantic and instance segmentation based on pixel-level annotations is highly reliable, but the manual annotation process is laborious. This requirement is overcome by weakly supervised methods based on inexact, but easily obtainable, annotations such as scribbles <ref type="bibr" target="#b62">[63]</ref>, bounding boxes <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b59">60]</ref>, or class labels <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b60">61]</ref>. In this section, we briefly review some recently introduced weakly supervised approaches that use class labels (Section 2.1) or bounding boxes (Section 2.2). In addition, we describe some visual saliency methods related to our method (Section 2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Learning with Class Labels</head><p>A class activation map (CAM) <ref type="bibr" target="#b68">[69]</ref> is a widely adopted technique to obtain a localization map from class labels. However, a CAM only identifies the most discriminative regions of objects <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>, and hence the majority of existing methods that use class labels <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b57">58]</ref> are primarily concerned with expanding the area of the target object activated by a CAM. For instance, erasure methods <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b63">64]</ref> iteratively find new regions of the target object by removing discriminative regions in an image. Other methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b60">61]</ref> consider the information shared between several images by capturing cross-image semantic similarities and differences. Seed growing and refinement techniques <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b27">28]</ref> are typically used to expand the regions representing the target object imperfectly that are in the initial CAM, on the basis of relationships between pixels. Other methods construct CAMs that embody the multi-scale semantic context in an image <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b64">65]</ref>. Despite these efforts, the information available from class labels remains limited, so auxiliary information acquired from web images <ref type="bibr" target="#b55">[56]</ref> or videos <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b36">37]</ref> can be used together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Learning with Bounding Boxes</head><p>Class labels have led to significant achievements in semantic segmentation, but they are inherently unhelpful in instance segmentation, which requires the separation of different objects of the same class. In contrast, bounding boxes do provide information about the location of individual objects in an image, and they are still much cheaper than constructing pixel-level masks <ref type="bibr" target="#b4">[5]</ref>. Most existing methods utilized a bounding box as a search space to conduct low-level searches for object masks. They create a pseudo mask within a box using off-the-shelf methods of mask proposal such as MCG <ref type="bibr" target="#b48">[49]</ref> or GrabCut <ref type="bibr" target="#b52">[53]</ref>. These processes can be guided by specifying the proportion of the pixels in a bounding box that are likely to belong to the object <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b59">60]</ref>. Iterative mask refinement techniques <ref type="bibr" target="#b10">[11]</ref> can also be applied. However, these methods are largely based on low-level information in the image, and they ignore the semantics associated with the bounding boxes. A rare exception is the multipleinstance learning formulation with a bounding box tightness prior <ref type="bibr" target="#b26">[27]</ref>: a crossing line within a box must contain at least one pixel of the target object. The drawback with this approach is that only a small number of pixels are contributing to the localization of the object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Visual Saliency Methods</head><p>Various methods have been proposed to visually explain the predictions of deep neural networks (DNNs) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b68">69]</ref> in a form of a saliency map. However, most studies have been concerned with classifiers, and only a few have looked at DNNs performing other tasks <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b50">51]</ref>. In particular, there have been no attempts to explain the predictions of object detectors, except Wu et al. <ref type="bibr" target="#b65">[66]</ref>, who embedded interpretability inside the DNN, in this case Faster R-CNN <ref type="bibr" target="#b51">[52]</ref>. However, the explanation produced by their modified DNN is not immediately understandable because it is given as a form of tree, and thus it is not appropriate to generate pseudo ground truth for weakly supervised segmentation. Gradientbased methods, such as SimpleGrad <ref type="bibr" target="#b67">[68]</ref>, SmoothGrad <ref type="bibr" target="#b58">[59]</ref>, and Grad-CAM <ref type="bibr" target="#b54">[55]</ref>, can provide visual saliency maps of the results from classifiers, but these methods are not easily extended to object detectors, because of the structural difference between classifiers and object detectors. Nevertheless, gradient-based methods have a significant bearing on our approach, and we look at them in more detail in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>We first provide a brief description of the operation of object detectors in Section 3.1. In Section 3.2, we introduce the BBAM for localizing objects in the bounding box. We then utilize the BBAM for weakly supervised semantic and instance segmentation in Sections 3.3 and 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Revisiting Object Detectors</head><p>Modern object detectors can be divided into two categories: one-stage <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b49">50]</ref> and two-stage <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b51">52]</ref> approaches. We focus on two-stage object detectors such as Faster R-CNN <ref type="bibr" target="#b51">[52]</ref>, in which the two stages are region proposal and box refinement. A region proposal network (RPN) generates candidate object proposals in the form of bounding boxes; but these proposals are class-agnostic and noisy, and most of them are redundant, thereby necessitating a subsequent refinement step, in which classification and bounding box regression are performed on each proposal. Since the proposal boxes proposed by the RPN are of different sizes, RoI pooling (e.g., RoIAlign <ref type="bibr" target="#b22">[23]</ref>) is used to convert the feature map corresponding to each proposal to a predefined fixed size, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>(a). The pooled feature map is then passed to the classification head and also to the bounding box regression head. Classification head. It computes the class probability p c of class c for each proposal and assigns the most likely class c * = argmax c p c to the proposal.</p><p>Bounding box regression head. It adjusts the noisy proposal to fit the object by computing the offsets t c = (t c x , t c y , t c w , t c h ) for each class c ? {1, 2, ? ? ? , C}. The final localization is obtained by shifting each coordinate of the proposal using the offset t c * . We refer to Ren et al. <ref type="bibr" target="#b51">[52]</ref> for the details of the parameterization of each coordinate.</p><p>For simplicity, we will abbreviate classification head and bounding box regression head as cls head and box head, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Bounding Box Attribution Map</head><p>Suppose we are given an image I and the corresponding bounding box annotations. We also have a set of object proposals O = {o k } K k=1 , either given or obtained by RPN, where K is the number of proposals. For each proposal o k , the box head f box and the cls head f cls produce box offsets t k = f box (I, o k ) and the class probability p k = f cls (I, o k ), respectively. We omit the proposal indices k for brevity.</p><p>The bounding box attribution map (BBAM) identifies the important region in the image that the detector needs to perform object detection. We find the smallest mask</p><formula xml:id="formula_0">M : ? ? [0, 1]</formula><p>where ? is a set of pixels, which captures a subset of the image that produces almost the same prediction as the original image. A small M reduces the amount of unnecessary information reaching the detector. The mask specifies a subset of the image in terms of the perturbation</p><formula xml:id="formula_1">function ?(I, M) = I ? M+? ? (1?M)</formula><p>, where ? denotes pixel-wise multiplication, and ? is the per-channel mean of the training data with the same size as M. For each proposal o, the best mask M * is obtained by optimizing the following function using gradient descent with respect to M:</p><formula xml:id="formula_2">M * = argmin M?[0,1] ? ? M 1 + L perturb ,<label>(1)</label></formula><formula xml:id="formula_3">L perturb = 1 box t c ? f box (?(I, M), o) 1 + 1 cls p c ? f cls (?(I, M), o) 1 ,<label>(2)</label></formula><p>where 1 box and 1 cls are logical variables that have a value of 0 or 1, to control which head is used to produce localizations, and t c = f box (I, o) and p c = f cls (I, o) are the predictions for the original image. Previous studies show that using a mask of the same spatial size as the input image incurs undesirable artifacts due to the adversarial effect <ref type="bibr" target="#b20">[21]</ref>: even a perturbation in a tiny magnitude can significantly change the prediction of a DNN. This problem can be addressed by introducing a coarse mask downsampled by a stride s <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b25">26]</ref>, so multiple image pixels are perturbed by a single element of M. We can then optimize M ? R w/s ? h/s for the image I ? R w?h , using the perturbation function ?(I,</p><formula xml:id="formula_4">M) = I ?M + ? ? (1 ?M), whereM ? R w?h is upsampled M</formula><p>to a width of w pixels and a height of h pixels.</p><p>Existing methods of explaining the output of classifiers <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref> or semantic segmentation networks <ref type="bibr" target="#b25">[26]</ref> use a fixed value of s for all images, i.e., they fix the size of a perturbation unit 1 . However, in the case of object detectors, a perturbation unit of fixed size can result in perturbations of different sizes to the RoI-pooled features, depending on the size of the proposals, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>(a). <ref type="figure" target="#fig_0">Figure 1</ref>(b) shows how the size of a perturbation unit, after RoI pooling, can fail to match the sizes of target objects: the perturbations are too coarse for small objects and too fine for large objects. Therefore, we use an adaptive stride s(a) where a is the ratio of the area of the bounding box predicted by the object detector to that of the image, so that we use a small stride for a small object and a large stride for a large object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Generating Pseudo Ground Truth</head><p>Since the BBAM is a pixel-level localization of the target object in a bounding box predicted by the object detector, it can be used as pseudo ground-truth for weakly supervised semantic and instance segmentation, using the following procedure: We first train an object detector, then create pseudo ground-truth semantic and instance masks for training images, using the BBAM of the trained object detector. These pseudo ground-truth masks can then be used to train semantic and instance segmentation networks. We will now explain this procedure in more detail.</p><p>Creating masks. Multiple proposals on a single object yield multiple predictions from the object detector. In order to benefit from the diversity of these predictions, we build the pseudo ground-truth from the BBAMs of multiple proposals. For each ground-truth box, we generate a set of object proposals O by randomly jittering each coordinate of the box by up to ?30%. These proposals are sent to the f cls and the f box . If the f cls correctly predicts the ground-truth class, and the intersection over union (IoU) value associated with the predicted box by f box is greater than 0.8, then the proposal is added to a set of positive proposals O + ? O. We then use a modified version of L perturb in Eq. 1 to amalgamate all the positive proposals into a single localization map, as follows:</p><formula xml:id="formula_5">L perturb = E o?O + [1 box t c ? f box (?(I, M), o) 1 + 1 cls p c ? f cls (?(I, M), o) 1 ].<label>(3)</label></formula><p>In this equation both 1 box and 1 cls are set to 1, since the BBAMs of f box and f cls provide complementary localization results (see Section 5 for details). A BBAM obtained in this way may partially cover the target object because not all pixels of the object are considered by f box and f cls . Therefore we refine the BBAM using CRFs <ref type="bibr" target="#b32">[33]</ref>, following previous work <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b59">60]</ref>. Finally, we create pseudo instance-level ground-truth masks by considering the pixels in each BBAM with values greater than a threshold ? to be foreground. We denote such a mask as T . The threshold ? controls the size of T . However, the proportion of pixels in each BBAM which correspond to the foreground will vary, so it may not be appropriate to use a fixed ?. Therefore we introduce two thresholds ? fg and ? bg : pixels whose attribution values are higher than ? fg are considered to be part of the foreground, and pixels whose values are lower than ? bg are considered to be part of the background. The remaining pixels are ignored in the loss computations during training segmentation networks.</p><p>Refine with MCG proposals. MCG <ref type="bibr" target="#b48">[49]</ref> is an unsupervised mask proposal generator, which is commonly used in weakly supervised instance segmentation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b70">71]</ref>. We can use mask proposals generated by MCG to refine a mask T . We first select the mask proposal that has the highest IoU with T . However, that proposal may partially cover the target object. We therefore consider other proposals that are completely contained within T . More formally, given a set of MCG proposals {m i } K i=1 , the refined mask T r is derived as follows:</p><formula xml:id="formula_6">T r = i?S m i , where S = {i |m i ? T } ? {argmax i IoU(m i , T )}.<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Training the Segmentation Network</head><p>We now explain the procedure that we use for training the semantic and instance segmentation network.</p><p>Instance segmentation. We use Mask R-CNN <ref type="bibr" target="#b22">[23]</ref>, pretrained on ImageNet <ref type="bibr" target="#b12">[13]</ref>. We use a seed growing technique <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref> for pseudo-labeling the pixels ignored during training: Starting with the pixels identified by the initial pseudo ground-truth mask, more of the ignored pixels progressively participate in the loss computation as training proceeds. We refer to Huang et al. <ref type="bibr" target="#b27">[28]</ref> for more details.</p><p>Semantic segmentation. We use DeepLab-v2 <ref type="bibr" target="#b7">[8]</ref>, pretrained on the ImageNet <ref type="bibr" target="#b12">[13]</ref> dataset. The pseudo labels produced in Section 3.3 can easily be made suitable for semantic segmentation by converting them from instancelevel to class-level. Pixels assigned to two or more object classes are ignored during the loss computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>Dataset and evaluation metrics. We conducted experiments on the PASCAL VOC <ref type="bibr" target="#b13">[14]</ref> and the MS COCO datasets <ref type="bibr" target="#b41">[42]</ref>. The PASCAL VOC dataset contains 20 object classes and one background class. Following the same protocol as other recent work on weakly supervised semantic and instance segmentation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b59">60]</ref>, we used an augmented set of 10,582 training images produced by Hariharan et al. <ref type="bibr" target="#b21">[22]</ref>. The MS COCO dataset has 118K training images containing 80 object classes. We report mean intersectionover-union (mIoU) values for semantic segmentation. For instance segmentation, we report average precision (AP ? ) at IoU thresholds ? ; averaged AP over IoU thresholds from 0.5 to 0.95; and the average best overlap (ABO).</p><p>Reproducibility. We used the PyTorch <ref type="bibr" target="#b47">[48]</ref> implementation <ref type="bibr" target="#b44">[45]</ref> of Faster R-CNN <ref type="bibr" target="#b51">[52]</ref> and Mask R-CNN <ref type="bibr" target="#b22">[23]</ref>. For semantic segmentation, we used the PyTorch implementation of DeepLab-v2-ResNet101 <ref type="bibr" target="#b45">[46]</ref>. We set s(a) to 16 + 48 ? a and ? to 0.007. We set ? fg and ? bg to 0.8 and 0.2 respectively. To find M * in Eq. 1, we used Adam optimizer <ref type="bibr" target="#b31">[32]</ref> with a learning rate of 0.02 for 300 iterations. The experiments </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Weakly Supervised Instance Segmentation</head><p>Results on PASCAL VOC. <ref type="table" target="#tab_0">Table 1</ref> compares the performance of our method with that of other recent methods of weakly supervised instance segmentation which use imagelevel tags or bounding boxes. Our method significantly outperforms those methods. Specifically, the AP 50 and AP 70 values of our method are both 6.0% higher than those of the previous best performing method which also uses bounding box annotation <ref type="bibr" target="#b2">[3]</ref>. We include results from two fully supervised methods: MNC <ref type="bibr" target="#b11">[12]</ref> and Mask R-CNN <ref type="bibr" target="#b22">[23]</ref>. The performance of Mask R-CNN <ref type="bibr" target="#b22">[23]</ref>, which is fully supervised, can be viewed as an upper bound on the achievable performance of our method. We achieve 92.2% and 95.7% of the performance of fully supervised Mask R-CNN, in terms of AP 50 and ABO respectively. <ref type="figure" target="#fig_1">Figure 2</ref> presents examples of instance masks produced by our method.</p><p>Results on MS COCO 2017. This is a challenging dataset containing more objects in an image on average than PASCAL VOC. The sizes of instances of objects are also more diverse. <ref type="table" target="#tab_1">Table 2</ref> compares the performance of our method with that of other weakly supervised instance segmentation methods with various levels of supervision on MS COCO. Our method achieves a 6.7% higher value of AP 75 than the previous best performing method which uses bound-   <ref type="table" target="#tab_2">Table 3</ref> compares published mIoU values achieved by recent methods performing semantic segmentation on validation and test images from the PASCAL VOC 2012 dataset. Since the labels for test images are not publicly available, the results for the test images were obtained from the official PASCAL VOC evaluation server. Our method, using the BBAM, yields an mIoU value of 73.7 for both the validation and the test images in the PASCAL VOC 2012 semantic segmentation benchmark. Our method outperforms all the methods that use image-level tags or bounding boxes for supervision. This new state-of-the-art performance was achieved with vanilla DeepLab-v2 <ref type="bibr" target="#b7">[8]</ref> without any modifica-  <ref type="figure">Figure 3</ref>: Examples of predicted semantic masks for PASCAL VOC val images of DSRG <ref type="bibr" target="#b27">[28]</ref>, Shen et al. <ref type="bibr" target="#b55">[56]</ref>, FickleNet <ref type="bibr" target="#b35">[36]</ref>, Lee et al. <ref type="bibr" target="#b36">[37]</ref>, and our method. tions to networks or additional training techniques, such as label refinement during training <ref type="bibr" target="#b10">[11]</ref>, recursive training <ref type="bibr" target="#b30">[31]</ref>, or fine-tuning with additional losses <ref type="bibr" target="#b59">[60]</ref>. <ref type="figure">Figure 3</ref> presents examples of semantic masks produced by our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Weakly Supervised Semantic Segmentation</head><p>The concurrent method, Box2Seg <ref type="bibr" target="#b33">[34]</ref>, achieved an mIoU of 76.4% on the PASCAL VOC validation images, but it is based on UperNet <ref type="bibr" target="#b66">[67]</ref>, which is a more powerful segmentation network than DeepLab-v2 <ref type="bibr" target="#b45">[46]</ref>. For a fair comparison between Box2Seg <ref type="bibr" target="#b33">[34]</ref> and our BBAM, we attempt to relieve the benefit of UperNet <ref type="bibr" target="#b66">[67]</ref> over DeepLab-v2 <ref type="bibr" target="#b7">[8]</ref> by comparing the relative performance of the weakly supervised model to the fully supervised model. Box2Seg achieves 88.4% of the performance of its fully supervised equivalent (76.4 vs. 86.4); but the corresponding figure for BBAM and its fully supervised equivalent is 96.7% (73.7 vs. 76.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>MCG proposals. <ref type="table" target="#tab_3">Table 4</ref> shows how mask refinement with MCG proposals improves the instance segmentation performance of our method on the PASCAL VOC and MS COCO datasets. Mask refinement with MCG proposals is particularly effective on masks for medium and large objects. The results obtained without MCG proposals offer the possibility of a fairer comparison with Hsu et al. <ref type="bibr" target="#b26">[27]</ref>, which do not use MCG proposals. Our method produces better results than that of Hsu et al. <ref type="bibr" target="#b26">[27]</ref> for both the PASCAL VOC and MS COCO datasets, which are shown in Tables 1 and 2 respectively. Hereinafter, to observe the contribution of each component of our system, we report results without using MCG proposals.</p><p>Box and cls heads. BBAM can provide a separate attribution map for each head of the object detector by controlling the logical variables 1 box and 1 cls in Eq. 3. <ref type="figure" target="#fig_2">Figure 4</ref> shows the effect of the BBAM obtained from each head on the    performance of weakly supervised semantic and instance segmentation. Using the BBAM obtained from either the box head (1 box = 1 and 1 cls = 0) or the cls head (1 box = 0 and 1 cls = 1) shows competent performance, but the best performance is achieved when the two heads are used together. We attribute this to the complementary property of the two heads, which is examined in more detail in Section 5. Parameter sensitivity analysis. <ref type="table" target="#tab_4">Table 5</ref> shows the effect of the thresholds ? fg and ? bg , and the seed growing technique G. When ? fg equals to ? bg , all pixels are assigned to either the foreground or the background. We see that ignoring some pixels can improve the AP values, and the seed growing technique further improves performance. We then studied the effect of ?, which controls the sparsity of the BBAM, on the performance of weakly supervised semantic and instance segmentation, with the results shown in <ref type="table" target="#tab_5">Table 6</ref>. Our method shows similar performance on semantic and instance segmentation over a broad range of values of ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Detailed Analysis of the BBAM</head><p>Examples of BBAMs. <ref type="figure" target="#fig_4">Figure 5</ref> shows BBAMs for validation images from PASCAL VOC <ref type="bibr" target="#b13">[14]</ref> and MS COCO <ref type="bibr" target="#b41">[42]</ref>. The BBAMs have high values on the boundary and discriminative parts of each object, which are informative in conducting object detection.</p><p>Complementary operation of the box and cls heads. To determine which regions of an object are important to each head, we investigated the distribution of high-value pixels in the BBAM produced by each head. In <ref type="figure" target="#fig_5">Figure 6(a)</ref>, C is the set of points on the contour of the object mask, and x c is its centroid. For each pixel x, we determine r 1 = x ? x c 2 and r 2 = min c?C x ? c 2 . Letting the angle between x? x c and the x-axis be ?, the position of the pixel x relative to x c is R = ( r1 r1+r2 cos ?, r1 r1+r2 sin ?). In <ref type="figure" target="#fig_5">Figure 6</ref>(b), we plot the relative positions of all the pixels with attribution values above 0.9 obtained from validation images of the PASCAL VOC dataset. Pixels for which R 2 ? 1 are near the boundary of the object. We observed that high values attributed by the box head mainly occur near the boundary of the object, and those by the cls head mainly occur in the interior.</p><p>Furthermore, we observed how much the prediction of each head changes when either of 1 box and 1 cls is set to 1 during the optimization of Eq. 1. The extent of the change in prediction of each head can be inferred from the corresponding loss in Eq. 2. <ref type="figure" target="#fig_5">Figure 6</ref>(c) shows that applying the optimization of Eq. 1 to one of the heads increases the loss of the other head, implying that the discriminative area of the image necessary for each head is not sufficient for the other head to maintain the prediction. These two observations suggest that the BBAM of each head provides complementary attributions. Examples of BBAMs obtained from each head are presented in the Appendix. Label noise in object detection. We also looked at the robustness of our system against noisy box coordinate labels in instance segmentation. Hsu et al. <ref type="bibr" target="#b26">[27]</ref> considered the effect of up to ?15% of label noise: we extend this to ?20%. The validity of the bounding box tightness priors used by Hsu et al. <ref type="bibr" target="#b26">[27]</ref> is seriously compromised by inaccurate box coordinates, with a considerable effect on performance, as shown in <ref type="figure" target="#fig_6">Figure 7</ref>(a). Our method shows better robustness than that of Hsu et al. <ref type="bibr" target="#b26">[27]</ref>, whether the noise consists of expanded or contracted bounding box annotations.  Effectiveness of an adaptive stride s(a). As mentioned in Section 3.2, we use an adaptive stride 16 ? s(a) ? 64 to cope with feature transformation due to RoI pooling. <ref type="figure" target="#fig_6">Figure 7</ref>(b) shows the IoU between the BBAM and ground truth mask on PASCAL VOC validation images, along with the results using fixed strides of <ref type="bibr">24 and 48. Figure 7(b)</ref> shows that a small fixed stride (s=24) is ineffective with large objects, as is a large fixed stride (s=48) with small objects. By contrast, an adaptive stride s(a) can deal with objects of various sizes.</p><p>Comparison with gradient-based methods. Gradientbased attribution methods, such as SimpleGrad <ref type="bibr" target="#b67">[68]</ref>, Smooth-Grad <ref type="bibr" target="#b58">[59]</ref>, and Grad-CAM <ref type="bibr" target="#b54">[55]</ref> can also provide attributions for the output of an object detector. However, since only the subset of features associated with the imperfect proposal is delivered to the cls and box heads, the gradients with respect to pixels, which exist outside the proposal yet essential for prediction, can vanish (but not completely, due to the receptive field). We provide empirical results supporting this analysis on the PASCAL VOC validation images: (1) <ref type="figure" target="#fig_7">Figure 8</ref> shows examples in which SimpleGrad <ref type="bibr" target="#b67">[68]</ref> is applied to three similar predictions from different proposals. Pixels outside the proposal do indeed influence the predictions, but SimpleGrad's attributions mainly appear inside the proposal.</p><p>(2) We observed that the majority (87%) of pixels with attribution values above 0.9 appear inside the imperfect proposal; shows that attribution maps from gradient-based attribution methods correlate poorly with ground truth masks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We have introduced a bounding box attribution map (BBAM), which provides pixel-level localization of each target object in its bounding box by finding the smallest region that preserves the predictions of the object detector. Our formulation is built on two-stage object detectors, but applying our method to one-stage object detectors is straightforward as long as they have box and cls heads. Our experiments demonstrate that the BBAM achieves state-of-the-art performance on the PASCAL VOC and MS COCO benchmarks in weakly supervised semantic and instance segmentation. We have also analyzed BBAMs from various viewpoints, and compared our technique with other attribution methods, to provide a deeper understanding of our approach. We expect BBAMs to be a staple of future work on weakly supervised semantic and instance segmentation with bounding boxes, on a par with the CAM for class labels. A. Appendix A.1. Implementation details TV norm. To suppress the artifacts in the mask M, we regularized M with total variation (TV) norm in Eq. 1 in the main paper, as done in Fong et al. <ref type="bibr" target="#b17">[18]</ref>. The resulting loss function to find the best M * becomes:</p><formula xml:id="formula_7">L M =? M 1 + ? TV ?M ? ? + 1 box t c ? f box (?(I, M), o) 1 + 1 cls p c ? f cls (?(I, M), o) 1 ,<label>(5)</label></formula><p>where ? TV is a balancing factor for TV norm. We set ? TV to 10 ?4 and ? to 3. We observed that the resulting mask M * has a little dependency on the value of ? TV .</p><p>We can find the best M * by using gradient descent with respect to M. Letting the mask at iteration t be M t , the mask at iteration t + 1 can be expressed as</p><formula xml:id="formula_8">M t+1 = M t ? ?? M t L M t ,<label>(6)</label></formula><p>where ? is a learning rate. Indeed, the update in Eq 6 was implemented through Adam optimizer.</p><p>Optimization details for semantic segmentation. We used the default setting provided by <ref type="bibr" target="#b45">[46]</ref>, except for the batch size, the number of training iterations, and the learning rate. We set the batch size to 8, the number of training iterations to 2.4 ? 10 4 , and the learning rate to 2 ? 10 ?4 .</p><p>Optimization details for instance segmentation on the PASCAL VOC dataset. Regarding the characteristics of the PASCAL VOC dataset <ref type="bibr" target="#b13">[14]</ref>, we adjusted the input image size and the anchor size accordingly. We set the max and min size of training images to 800 and 512, respectively, and anchor sizes for each FPN level to <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr">84,</ref><ref type="bibr">168,</ref><ref type="bibr">332]</ref>. We trained Mask R-CNN <ref type="bibr" target="#b22">[23]</ref> with a learning rate 8 ? 10 ?3 for 2 ? 10 4 iterations.</p><p>Optimization details for instance segmentation on the MS COCO 2017 dataset. We followed the default settings provided by maskrcnn-benchmark repository <ref type="bibr" target="#b44">[45]</ref>.</p><p>Post-processing of semantic and instance segmentation. CRF <ref type="bibr" target="#b32">[33]</ref> is a popular post-processing technique for semantic and instance segmentation <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b57">58]</ref>. We also used CRFs as a post-processing method for semantic and instance segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Additional Results</head><p>Comparison of per-class mIoU scores. <ref type="table" target="#tab_0">Table A1</ref> shows the per-class mIoU of our method and recently produced methods.</p><p>More examples of BBAMs. We present more examples of BBAMs for PASCAL VOC <ref type="bibr" target="#b13">[14]</ref> validation images with Faster R-CNN <ref type="bibr" target="#b51">[52]</ref> ( <ref type="figure" target="#fig_0">Figure A1</ref>) and for MS COCO 2017 <ref type="bibr" target="#b41">[42]</ref> validation images with Faster R-CNN <ref type="bibr" target="#b51">[52]</ref> ( <ref type="figure" target="#fig_1">Figure A2</ref>).</p><p>Additional mask examples on semantic segmentation. <ref type="figure">Figure A3</ref> shows more examples of the semantic masks produced by DSRG <ref type="bibr" target="#b27">[28]</ref>, Shen et al. <ref type="bibr" target="#b55">[56]</ref>, FickleNet <ref type="bibr" target="#b35">[36]</ref>, Lee et al. <ref type="bibr" target="#b36">[37]</ref>, and our method.</p><p>More mask examples on instance segmentation. <ref type="figure" target="#fig_2">Figure A4</ref> shows more examples of the instance masks on PAS-CAL VOC 2012 validation images obtained from IRNet <ref type="bibr" target="#b0">[1]</ref>, Hsu et al. <ref type="bibr" target="#b26">[27]</ref>, and our method. <ref type="figure" target="#fig_4">Figure A5</ref> shows examples of instance masks on MS COCO 2017 validation images obtained by our method.  <ref type="figure">Figure A3</ref>: Examples of predicted semantic masks for PASCAL VOC validation images of DSRG <ref type="bibr" target="#b27">[28]</ref>, Shen et al. <ref type="bibr" target="#b55">[56]</ref>, FickleNet <ref type="bibr" target="#b35">[36]</ref>, Lee et al. <ref type="bibr" target="#b36">[37]</ref>, and our method. <ref type="figure" target="#fig_2">Figure A4</ref>: Examples of predicted instance masks for PASCAL VOC validation images of our method. <ref type="figure" target="#fig_4">Figure A5</ref>: Examples of predicted instance masks for MS COCO 2017 validation images of our method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The size of the perturbation unit needs to be adjusted to the object size. (a) RoIAlign [23] produces perturbation units of different sizes. (b) Examples of resulting BBAMs with small fixed values of s, large fixed values of s, and values of s determined adaptively. Fixed values of s, whether large or small, tend to generate unwanted artifacts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Examples of predicted instance masks for PASCAL VOC val images of IRNet<ref type="bibr" target="#b0">[1]</ref>, Hsu et al.<ref type="bibr" target="#b26">[27]</ref>, and ours.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Effect of each head on instance and semantic segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>?</head><label></label><figDesc>fg ? bg G AP AP 50 AP 75</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Examples of the predicted boxes and corresponding BBAMs. (a) BBAMs for MS COCO validation images. (b) BBAMs for PACSAL VOC validation images. Each BBAM corresponds to the predicted box of the same color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Complementary operation of the box head and the cls head. (a) The definition of relative position. (b) Relative positions of the highly activated pixels from each head. (c) Box and class loss curves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>(a) Robustness against noisy box coordinate labels. (b) Localization accuracy by different strides. (c) Localization accuracy by different attribution methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Examples of SimpleGrad [68] for three similar predictions obtained from different proposals. the mean IoU between the set of positive proposals and the corresponding predictions is low (i.e., 0.56). (3) Figure 7(c)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure A1 :Figure A2 :</head><label>A1A2</label><figDesc>Examples of PASCAL VOC<ref type="bibr" target="#b13">[14]</ref> validation images with the results of object detection and corresponding BBAMs, obtained from Faster R-CNN<ref type="bibr" target="#b51">[52]</ref>. Examples of MS COCO 2017<ref type="bibr" target="#b41">[42]</ref> validation images with the results of object detection and corresponding BBAMs, obtained from Faster R-CNN<ref type="bibr" target="#b51">[52]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Weakly supervised instance segmentation performance on PASCAL VOC 2012 val images. Method AP 25 AP 50 AP 70 AP 75 ABO</figDesc><table><row><cell cols="2">Full supervision: Instance masks</cell><cell></cell></row><row><cell>MNC CVPR '16 [12]</cell><cell cols="2">-63.5 41.5 -</cell><cell>-</cell></row><row><cell cols="4">Mask R-CNN ICCV '17 [23] 77.3 69.1 49.9 41.9 65.8</cell></row><row><cell cols="2">Weak supervision: Image-level tags</cell><cell></cell></row><row><cell>PRM CVPR '18 [70]</cell><cell>44.3 26.8 -</cell><cell cols="2">9.0 37.6</cell></row><row><cell>IAM CVPR '19 [71]</cell><cell cols="3">45.9 28.8 -11.9 41.9</cell></row><row><cell cols="4">Label-PEnet ICCV '19 [19] 49.1 30.2 -12.9 41.4</cell></row><row><cell>CountSeg CVPR '19 [9]</cell><cell cols="3">48.5 30.2 -14.4 44.3</cell></row><row><cell>IRNet CVPR '19 [1]</cell><cell cols="2">-46.7 23.5 -</cell><cell>-</cell></row><row><cell>Kim et al. WACV '21 [29]</cell><cell cols="3">56.6 38.1 -12.3 48.2</cell></row><row><cell>LIID TPAMI '20 [44]</cell><cell cols="3">-48.4 -24.9 50.8</cell></row><row><cell>Arun et al. ECCV '20 [3]</cell><cell cols="3">59.1 49.7 29.2 27.1 -</cell></row><row><cell cols="2">Weak supervision: Bounding boxes</cell><cell></cell></row><row><cell>SDI CVPR '17 [31]</cell><cell cols="3">-44.8 -16.3 49.1</cell></row><row><cell>Liao et al. ICASSP '19 [40]</cell><cell cols="3">-51.3 -22.4 51.9</cell></row><row><cell>Sun et al. Access '20 [62]</cell><cell cols="3">-56.9 -21.4 56.9</cell></row><row><cell cols="4">Hsu et al. NeurIPS '19 [27] 75.0 58.9 30.4 21.6 -</cell></row><row><cell>Arun et al. ECCV '20 [3]</cell><cell cols="3">73.1 57.7 33.5 31.2 -</cell></row><row><cell>BBAM (Ours)</cell><cell cols="3">76.8 63.7 39.5 31.8 63.0</cell></row></table><note>were performed on NVIDIA Tesla V100 GPUs. For MCG mask proposals, we used the pre-computed proposals for PASCAL VOC and MS COCO images provided by Pont- Tuset et al. [49].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison of instance segmentation methods with various types of supervision on MS COCO. The results of Hsu et al.<ref type="bibr" target="#b26">[27]</ref> were obtained from here.Methodsup. AP AP 50 AP 75</figDesc><table><row><cell>MS COCO val images</cell><cell></cell><cell></cell></row><row><cell cols="2">Mask R-CNN ICCV '17 [23] F</cell><cell>35.4 57.3 37.5</cell></row><row><cell>Shen et al. CVPR '19 [57]</cell><cell>I</cell><cell>6.1 11.7 5.5</cell></row><row><cell cols="3">Laradji et al. arXiv '19 [35] I, P 7.8 18.2 8.8</cell></row><row><cell>Hsu et al. NeurIPS '19 [27]</cell><cell>B</cell><cell>21.1 45.5 17.2</cell></row><row><cell>BBAM (Ours)</cell><cell>B</cell><cell>26.0 50.0 23.9</cell></row><row><cell>MS COCO test-dev images</cell><cell></cell><cell></cell></row><row><cell cols="2">Mask R-CNN ICCV '17 [23] F</cell><cell>35.7 58.0 37.8</cell></row><row><cell>Fan et al. ECCV '18 [16]</cell><cell cols="2">I, S I 13.7 25.5 13.5</cell></row><row><cell>LIID TPAMI '20 [44]</cell><cell>I</cell><cell>16.0 27.1 16.5</cell></row><row><cell>BBAM (Ours)</cell><cell>B</cell><cell>25.7 50.0 23.3</cell></row></table><note>F ?Full, I?Image label, P?Point, B?Box, S I ?Instance saliency</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Weakly supervised semantic segmentation on PAS-CAL VOC 2012 val and test images.</figDesc><table><row><cell>Method</cell><cell>val</cell><cell>test</cell></row><row><cell>Full supervision: Semantic masks</cell><cell></cell><cell></cell></row><row><cell>DeepLab TPAMI '17 [8]</cell><cell cols="2">76.8 76.2</cell></row><row><cell>Weak supervision: Image-level tags</cell><cell></cell><cell></cell></row><row><cell>FickleNet CVPR '19 [36]</cell><cell cols="2">64.9 65.3</cell></row><row><cell>CIAN AAAI '20 [15]</cell><cell cols="2">64.3 65.3</cell></row><row><cell>Chang et al. CVPR '20 [7]</cell><cell cols="2">66.1 65.9</cell></row><row><cell>Sun et al. ECCV '20 [61]</cell><cell cols="2">66.2 66.9</cell></row><row><cell>Weak Supervision: Bounding boxes</cell><cell></cell><cell></cell></row><row><cell>WSSL ICCV '15 [47]</cell><cell cols="2">60.6 62.2</cell></row><row><cell>BoxSup ICCV '15 [11]</cell><cell cols="2">62.0 64.6</cell></row><row><cell>SDI CVPR '17 [31]</cell><cell>69.4</cell><cell>-</cell></row><row><cell>Song et al. CVPR '19 [60]</cell><cell>70.2</cell><cell>-</cell></row><row><cell>BBAM (Ours)</cell><cell cols="2">73.7 73.7</cell></row></table><note>ing box annotations. Since the labels for test-dev images are not publicly available, the results for the test-dev images were obtained from the MS COCO challenge website.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Effectiveness of using MCG proposals for instance segmentation. AP S , AP M , and AP L respectively denote the AP values for small, medium, and large objects.MCG AP AP 50 AP 75 AP S AP M AP L</figDesc><table><row><cell cols="2">PASCAL VOC val images:</cell><cell></cell><cell></cell></row><row><cell>29.6 61.9</cell><cell>25.8</cell><cell>5.6</cell><cell>21.6 40.1</cell></row><row><cell>33.4 63.7</cell><cell>31.8</cell><cell>6.5</cell><cell>26.4 44.1</cell></row><row><cell>MS COCO val images:</cell><cell></cell><cell></cell><cell></cell></row><row><cell>23.5 47.9</cell><cell cols="3">20.3 10.4 24.9 36.5</cell></row><row><cell>26.0 50.0</cell><cell cols="3">23.9 10.8 28.5 40.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Analysis of thresholds ? fg and ? bg , and effect of the growing technique G. AP AP 50 AP 75 mIoU 0.001 26.6 58.7 21.1 67.9 0.003 28.1 59.9 22.8 69.7 0.005 28.7 60.2 24.3 70.8 0.007 29.6 61.9 25.8 71.4 0.010 28.7 60.4 24.4 70.7 0.020 28.3 59.6 23.7 70.3</figDesc><table><row><cell>Ins.</cell><cell>Sem.</cell></row><row><cell>?</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Effect of ? on instance (Ins.) and semantic (Sem.) segmentation.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table A1 :</head><label>A1</label><figDesc>Comparison of per-class mIoU scores. bkg aero bike bird boat bottle bus car cat chair cow table dog horse motor person plant sheep sofa train tv mIOU Results on validation images: Shen et al. [56] 86.8 71.2 32.4 77.0 24.4 69.8 85.3 71.9 86.5 27.6 78.9 40.7 78.5 79.1 72.7 73.1 49.6 74.8 36.1 48.1 59.2 63.0 CIAN [15] 88.2 79.5 32.6 75.7 56.8 72.1 85.3 72.9 81.7 27.6 73.3 39.8 76.4 77.0 74.9 66.8 46.6 81.0 29.1 60.4 53.3 64.3 FickleNet [36] 89.5 76.6 32.6 74.6 51.5 71.1 83.4 74.4 83.6 24.1 73.4 47.4 78.2 74.0 68.8 73.2 47.8 79.9 37.0 57.3 64.6 64.9 SSDD [58] 89.0 62.5 28.9 83.7 52.9 59.5 77.6 73.7 87.0 34.0 83.7 47.6 84.1 77.0 73.9 69.6 29.8 84.0 43.2 68.0 53.4 64.9 Lee et al. [37] 90.8 82.2 35.1 82.4 72.2 71.4 82.7 75.0 86.9 18.3 74.2 29.6 81.1 79.2 74.7 76.4 44.2 78.6 35.4 72.8 63.0 66.5 BBAM (Ours) 92.7 80.6 33.8 83.7 64.9 75.5 91.3 80.4 88.3 37.0 83.3 62.5 84.6 80.8 74.7 80.0 61.6 84.5 48.6 85.8 71.8 73.7</figDesc><table><row><cell cols="2">Results on test images:</cell></row><row><cell>Shen et al. [56]</cell><cell>87.2 76.8 31.6 72.9 19.1 64.9 86.7 75.4 86.8 30.0 76.6 48.5 80.5 79.9 79.7 72.6 50.1 83.5 48.3 39.6 52.2 63.9</cell></row><row><cell>FickleNet [36]</cell><cell>90.3 77.0 35.2 76.0 54.2 64.3 76.6 76.1 80.2 25.7 68.6 50.2 74.6 71.8 78.3 69.5 53.8 76.5 41.8 70.0 54.2 65.0</cell></row><row><cell>SSDD [58]</cell><cell>89.0 62.5 28.9 83.7 52.9 59.5 77.6 73.7 87.0 34.0 83.7 47.6 84.1 77.0 73.9 69.6 29.8 84.0 43.2 68.0 53.4 64.9</cell></row><row><cell>Lee et al. [37]</cell><cell>91.2 84.2 37.9 81.6 53.8 70.6 79.2 75.6 82.3 29.3 76.2 35.6 81.4 80.5 79.9 76.8 44.7 83.0 36.1 74.1 60.3 67.4</cell></row><row><cell>BBAM (Ours)</cell><cell>92.8 83.5 33.4 88.9 61.8 72.8 90.3 83.5 87.6 34.7 82.9 66.1 83.9 81.1 78.3 77.4 55.2 86.7 58.5 81.5 66.4 73.7</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The perturbation unit is a block of image pixels perturbed by a single element of M.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of instance segmentation with inter-pixel relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning pixel-level semantic affinity with image-level supervision for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Weakly supervised instance segmentation by learning annotation consistent instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M Pawan</forename><surname>Jawahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">What&apos;s the point: Semantic segmentation with point supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Bearman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Budget-aware semi-supervised semantic and instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>Bellver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amaia</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Torrres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier Giro-I</forename><surname>Nieto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Explaining image classifiers by counterfactual generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Hao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><surname>Creager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Weaklysupervised semantic segmentation via sub-category exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ting</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaosong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robinson</forename><surname>Piramuthu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IEEE TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Object counting and instance segmentation with image-level supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisham</forename><surname>Cholakkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Fahad Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Real time image saliency for black box classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dabkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Instance-aware semantic segmentation via multi-task network cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The pascal visual object classes (voc) challenge. IJCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Cian: Crossimage affinity net for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Associating inter-image salient instances for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruochen</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi-Min</forename><surname>Ralph R Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Understanding deep networks via extremal perturbations and smooth masks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandela</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Interpretable explanations of black boxes by meaningful perturbation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ruth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Label-penet: Sequential label propagation and enhancement networks for weakly supervised instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semantic contours from inverse detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Arbel?ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Piotr Doll?r, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Weakly supervised semantic segmentation using web-crawled videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghun</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Self-erasing network for integral object attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengtao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Grid saliency for context explanations of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauricio</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Khoreva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Fischer</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Weakly supervised instance segmentation using the bounding box tightness prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Chun</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuang-Jui</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Chi</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yung-Yu</forename><surname>Chuang</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Weakly-supervised semantic segmentation network with deep seeded region growing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Weakly supervised instance segmentation by deep community learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaedong</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seohyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeany</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Integral object mining via online attention accumulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Tao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Simple does it: Weakly supervised instance and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Khoreva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hosang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Efficient inference in fully connected crfs with gaussian edge potentials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Box2seg: Attention weighted loss and discriminative feature learning for weakly supervised segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viveka</forename><surname>Kulharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambrish</forename><surname>Tyagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Instance segmentation with point supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Issam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Negar</forename><surname>Laradji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">O</forename><surname>Rostamzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>V?zquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.06392</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Ficklenet: Weakly and semi-supervised semantic image segmentation using stochastic inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunji</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jangho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Frame-to-frame aggregation of active regions in web videos for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunji</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jangho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Robust tumor localization with pyramid grad-cam</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jangho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chul-Kee</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.11393</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Guided attention inference network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuan-Chuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Weakly supervised instance segmentation using hybrid networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shisha</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenqiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shimamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Sagata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Leveraging instance-, image-and dataset-level information for weakly supervised instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Huan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Song</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Jun</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">maskrcnn-benchmark: Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<ptr target="https://github.com/facebookresearch/maskrcnn-benchmark" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title/>
		<ptr target="https://github.com/kazuto1011/deeplab-pytorch" />
	</analytic>
	<monogr>
		<title level="j">Kazuto Nakashima. DeepLab with PyTorch</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Weakly-and semi-supervised learning of a deep convolutional network for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multiscale combinatorial grouping for image segmentation and object proposal generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferran</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santosh</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Visualizing and measuring the geometry of bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><forename type="middle">B</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Coenen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">grabcut&quot; interactive foreground extraction using iterated graph cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM transactions on graphics</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Restricting the flow: Information bottlenecks for attribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Sixt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Landgraf</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Gradcam: Visual explanations from deep networks via gradientbased localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramprasaath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Bootstrapping the performance of webly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Cyclic guidance for weakly supervised joint detection and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liujuan</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Self-supervised difference detection for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wataru</forename><surname>Shimoda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keiji</forename><surname>Yanai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Smilkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><surname>Vi?gas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Wattenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03825</idno>
		<title level="m">Smoothgrad: removing noise by adding noise</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Box-driven class-wise region masking and filling rate guided loss for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Mining cross-image semantics for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Weakly supervised instance segmentation based on two-stage transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shisha</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenqiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Sagata</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>IEEE Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Normalized cut loss for weakly-supervised cnn segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelaziz</forename><surname>Djelouah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Schroers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Object region mining with adversarial erasing: A simple classification to semantic segmentation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1568" to="1576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Revisiting dilated convolution: A simple approach for weakly-and semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Towards interpretable object detection by unfolding latent structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Unified perceptual parsing for scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tete</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="418" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Weakly supervised instance segmentation using class peak response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanzhao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Learning instance activation maps for weakly supervised instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanzhao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huijuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Doermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
