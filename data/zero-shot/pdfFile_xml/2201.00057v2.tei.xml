<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">OPTIMAL REPRESENTATIONS FOR COVARIATE SHIFT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangjun</forename><surname>Ruan</surname></persName>
							<email>yjruan@cs.toronto.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dubois</surname></persName>
							<email>yanndubois@cs.toronto.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Vector Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">OPTIMAL REPRESENTATIONS FOR COVARIATE SHIFT</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T02:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Machine learning systems often experience a distribution shift between training and testing. In this paper, we introduce a simple variational objective whose optima are exactly the set of all representations on which risk minimizers are guaranteed to be robust to any distribution shift that preserves the Bayes predictor, e.g., covariate shifts. Our objective has two components. First, a representation must remain discriminative for the task, i.e., some predictor must be able to simultaneously minimize the source and target risk. Second, the representation's marginal support needs to be the same across source and target. We make this practical by designing self-supervised objectives that only use unlabelled data and augmentations to train robust representations. Our objectives give insights into the robustness of CLIP, and further improve CLIP's representations to achieve SOTA results on DomainBed. * Authors contributed equally. 1 Our implementation is released at https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>It is hard to build machine learning (ML) systems that are robust to distribution shifts between a source (train) and target (test) domain. One promising approach to domain generalization (DG) is learning robust representations from which predictors trained on source must perform well on target. In practice, however, no current DG methods for learning representation uniformly outperform empirical source-risk minimizers (ERM) <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2021)</ref>. Furthermore, our theoretical understanding of DG is still lacking. Specifically, while previous work have studied properties that would or would not imply robust representations <ref type="bibr" target="#b6">(Ben-David et al., 2007;</ref><ref type="bibr" target="#b7">2010a;</ref><ref type="bibr">Zhao et al., 2019;</ref><ref type="bibr" target="#b23">Johansson et al., 2019)</ref>, the minimal set of achievable requirements for perfect DG is not yet known.</p><p>We introduce the first, simple, variational objective whose optima are exactly the set of all representations on which source risk minimizers are guaranteed to generalize across distribution shifts that preserve the Bayes predictor. We work in an idealized DG (IDG) setting; we assume that a learner has access to the source population risk. Our variational characterization implies that it is both sufficient and necessary for optimal IDG that a representation: (a) remains discriminative for the learning task, i.e., there must exist predictors from the representation to the labels that can simultaneously minimize both source and target risk; and (b) keeps the support of its marginal distribution invariant to shifts. This means that any optimal representation learning method must seek discriminative information about the target. Even worse, we prove that without access to some knowledge about the target, any representation learning algorithm cannot uniformly (over all target domains) outperform a constant representation, which may explain why DG methods struggle to outperform ERM.</p><p>We show, in theory and practice, how to overcome these challenges using only a large set of unlabeled examples and particular data augmentations that retain all discriminative information but minimal domain-specific information. Text descriptions of images are examples of such augmentations, as they are informative for many downstream classification tasks, but they remove a lot of domain-specific information. With such augmentations, we design practical self-supervised learning (SSL) objectives for learning robust representations. Our objectives give insights into the robustness of CLIP <ref type="bibr" target="#b39">(Radford et al., 2021)</ref> over other SSL methods, and lead to improved CLIP-based representations that achieve state-of-the-art (SOTA) results on DomainBed <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2021)</ref>. To summarize, we:</p><p>? provide minimal sufficient objectives whose optima achieve optimal DG under covariate shift; ? prove that it is impossible to learn useful representations without accessing target information; ? provide practical objectives to learn optimally robust representations using specific augmentations; ? obtain SOTA results on typical domain generalization benchmarks. 1 2 BACKGROUND: DOMAIN GENERALIZATION AND REPRESENTATIONS We are interested in predictions that are robust across distribution shifts. We formalize this using domain generalization (DG) language. Given a distribution p X,Y | ds over inputs x ? X and labels y ? Y from the source domain d s ? D, we select a predictor f : X ? ?. The predictions ? ? ? could for example be labels or distributions over labels. Despite being selected on the source domain, we would like f to achieve a small expected risk with respect to a loss function :</p><formula xml:id="formula_0">Y ? ? ? R ?0 , R d f [Y | X] := E p X,Y | d [ (Y, f (X))] ,<label>(1)</label></formula><p>on a distribution p X,Y | d from a target domain d = d t ? D, which is somehow related to d s .</p><p>A common strategy for DG is to learn robust representations, which splits the problem into two. First, learn an encoder p Z | X , which maps inputs X to representations Z. Then, learn a predictor h : Z ? ? from representations Z to labels Y using standard risk minimization. The goal is to design a robust representation Z, so that predictors h trained to minimize the source risk R ds h [Y | Z] also achieve low target risk R dt h [Y | Z]. Many methods have been proposed to try to learn such Z, e.g., by enforcing domain invariance of the marginal p Z | d (e.g., <ref type="bibr" target="#b15">Ganin et al., 2016)</ref>. Still, many of these proposals are not sound <ref type="bibr">(Zhao et al., 2019;</ref><ref type="bibr" target="#b23">Johansson et al., 2019)</ref>. Furthermore, they rarely outperform source empirical risk minimization (ERM) in practice <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2021</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OPTIMAL REPRESENTATIONS FOR DOMAIN GENERALIZATION</head><p>To separate domain generalization from finite sample generalization, we consider an idealized DG (IDG), where the predictor h is selected on the source population risk rather than empirical risk. We assume sample spaces X , Z, Y, D are discrete; formal statements and proofs are in Appxs. A and B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">DEFINING OPTIMAL REPRESENTATIONS FOR IDEALIZED DOMAIN GENERALIZATION</head><p>We want to evaluate the quality of a representation Z of X. In our IDG, the learner is given a random source D s ; she selects any source risk minimizer; and is scored according to her risk on a random target domain D t . To give uniform guarantees while reflecting the uncertainty over the source-target pair (D s , D t ), we measure the quality of Z as the expected risk of the learner's worst-case choice.</p><p>Definition. The idealized domain generalization risk (IDG risk) of an encoder p Z | X is the expected (over domains) worst-case (over source risk minimizers) target risk, i.e.,</p><formula xml:id="formula_1">R IDG [Y | Z] := E p Ds,D t sup h?H * Ds R Dt h [Y | Z]<label>(2)</label></formula><p>where H * Ds := arg min h R Ds h [Y | Z] are the source risk minimizers, and p Ds,Dt is any joint distribution that has full support over D ? D. We call a representation Z * (or its encoder) optimal for IDG if it minimizes the IDG risk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT</head><p>The IDG risk is useful to evaluate representations, but gives few insights into IDG and is impractical to optimize due to the supremum in Eq. (2). Under mild assumptions, we provide a simplified, equivalent objective, which is easier to optimize. For convenience, we assume that there is a unique Bayes predictor f * , which minimizes the expected risk over domains, i.e., f * = arg min f E p D t <ref type="bibr">[R Dt</ref> Published as a conference paper at ICLR 2022 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / s A E Z 2 W X Q G K c + / J x S i c D + Y S N W G 8 = " &gt; A A A B 6 H i c b Z C 7 S g N B F I b P x l u M t 6 i l I I N B s J C w K 6 J 2 B m w s E z A X S J Y w O z m b j J m 9 M D M r h C W l l Y 2 F I r a + g Z 3 P Y e c z 6 E M 4 u R Q a / W H g 4 / / P Y c 4 5 X i y 4 0 r b 9 Y W X m 5 h c W l 7 L L u Z X V t f W N / O Z W T U W J Z F h l k Y h k w 6 M K B Q + x q r k W 2 I g l 0 s A T W P f 6 F 6 O 8 f o N S 8 S i 8 0 o M Y 3 Y B 2 Q + 5 z R r W x K r 1 2 v m A X 7 b H I X 3 C m U D h / / b z d f a t 8 l d v 5 9 1 Y n Y k m A o W a C K t V 0 7 F i 7 K Z W a M 4 H D X C t R G F P W p 1 1 s G g x p g M p N x 4 M O y b 5 x O s S P p H m h J m P 3 Z 0 d K A 6 U G g W c q A 6 p 7 a j Y b m f 9 l z U T 7 Z 2 7 K w z j R G L L J R 3 4 i i I 7 I a G v S 4 R K Z F g M D l E l u Z i W s R y V l 2 t w m Z 4 7 g z K 7 8 F 2 p H R e e k e F y x C 6 V D m C g L O 7 A H B + D A K Z T g E s p Q B Q Y I d / A A j 9 a 1 d W 8 9 W c + T 0 o w 1 7 d m G X 7 J e v g H F N 5 F O &lt; / l a t e x i t &gt; h Y = 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n v 5 k g G 6 Q 4 M L i t f s 2 3 A 6 9 V l l A D + g = " &gt; A  <ref type="figure">Figure 1</ref>: (a) Optimal representations for IDG must have invariant supports while being simultaneously discriminative on all domains: (b) without the discriminative requirement, a source-risk minimizer can mispredict the target, and (c) without support match, some risk minimizer will perform poorly.</p><p>Generalized covariate shift (GCS) ensures that f * is simultaneously optimal on all domains. For log-loss it recovers standard covariate shift, i.e., p Y | x,d = p Y | x . For other losses, GCS is weaker, e.g., it only requires invariance of most likely labels for 0-1 loss, and of conditional expectations for MSE. Invariance of Bayes predictors is necessary to learn useful predictors using a single domain. For example, for 0-1 loss it ensures that each label is seen at least once in each domain.</p><p>The intuition behind our objective is that under GCS any source risk minimizer will make optimal predictions on target samples x that are also in the source. Thus, IDG optimal representations are exactly those that (a) have the same support in Z for all domain, and (b) retain GCS from Z without sacrificing the ability to predict Y , which can be ensured by minimizing the risk from Z. See <ref type="figure">Fig. 1</ref>.</p><p>Theorem 1. Under our assumptions, an encoder p Z * | X is optimal for IDG if and only if it minimizes</p><formula xml:id="formula_2">the risk R [Y | Z] := inf h E p D t R Dt h [Y | Z]</formula><p>while matching the support of Z across domains, i.e.,</p><formula xml:id="formula_3">p Z * | X ? arg min p Z | X R [Y | Z] s.t. ? d ? D, supp(p Z | d ) = supp(p Z )<label>(3)</label></formula><p>Moreover, such encoders exist and their IDG risk is the Bayes risk</p><formula xml:id="formula_4">R IDG [Y | Z * ] = R [Y | X].</formula><p>Theorem 1 provides an objective to learn representations on which performing risk minimization using a single domain and Z * is as good as performing risk minimization on the target domain from inputs X. Other sufficient conditions have previously been hinted towards, e.g., matching the marginal p Z | d instead of its support (e.g., <ref type="bibr" target="#b7">Ben-David et al., 2010a)</ref> which is the focus of most DG methods (e.g., <ref type="bibr" target="#b15">Ganin et al., 2016)</ref>. Note that previous conditions are nevertheless generally not necessary and could be too stringent to be achievable. To our knowledge, Thm. 1 is the first characterization of necessary and sufficient conditions, which gives better insights into the essential goal for optimal IDG and provides a guide for deriving the least stringent objectives in practice.</p><p>The risk minimization (Eq. (3)) shows that one must have some knowledge about the target domains to learn optimal representations for IDG. Access to targets might seem unrealistic, but without such knowledge or additional assumptions it is provably impossible to beat even constant representations. (SSL), which is a technique for training representations without direct access to labels, and a particular class of data augmentations. E.g, in CLIP, images are augmented with alt-text collected on the internet and invariance is enforced between the representations of the image and its text pair <ref type="bibr" target="#b39">(Radford et al., 2021)</ref>. Representations learned like this preserve discriminative information about all downstream tasks Y whose label information is preserved by the augmentation (e.g., <ref type="bibr" target="#b13">Dubois et al., 2021)</ref>.</p><p>More precisely, an augmentation A is a random variable sampled conditionally from the input X. The key requirement is that augmentations retain task information. Specifically, if any samples x, x ? X have the same augmentation conditional p A | x = p A | x , then their Bayes predictions must be the same f * (x) = f * (x (3). This can be overcome under a domain-agnostic assumption, which requires that the set of possible augmentation distributions is the same across domains, i.e.,</p><formula xml:id="formula_5">p A | x | x ? supp(p X | d ) = p A | x | x ? X .</formula><p>Proposition 2. Let p A | X be a domain-agnostic augmenter. Then any optimal solution p Z * | X of the following objective is optimal for IDG:</p><formula xml:id="formula_6">p Z * | X ? arg max p Z | X I[A; Z] s.t. ? d ? D, supp(p Z | d ) = supp(p Z )<label>(4)</label></formula><p>Proposition 2 shows that we can still learn IDG optimal representations without labels if we have access to the right augmentations. How realistic are those augmentations? For 0-1 loss , the most likely label should be preserved, which is satisfied by standard image augmentations like rotations and color jittering. Those augmentations are nevertheless not domain-agnostic for typical domains (e.g. sketches and photos), since outputs A are correlated with the input's domain D. See <ref type="figure">Fig. 2a</ref>.</p><p>A practical choice of augmentation that is nearly domain-agnostic, is a mapping from images to text descriptions, as with CLIP <ref type="bibr" target="#b39">(Radford et al., 2021)</ref> which uses text-image pairs. Image-text augmentations have many advantages. First, text augmentations preserve label information for many downstream tasks. Second, they are close to being domain-agnostic, since images from different domains (e.g., sketches and photos) but similar semantics are often mapped to similar descriptions. 2 <ref type="figure">(Fig. 2c</ref>). This gives insights into the open question <ref type="bibr" target="#b39">(Radford et al., 2021)</ref> about why CLIP's representations are so robust compared to other SSL methods. Finally, image-text pairs are easy to access in practice given their abundance on the internet. Many other multi-modal augmentations, e.g., audio-video , are also likely domain-agnostic and can be explored in practice.</p><p>In practice, even the domain information D is usually unknown. One can nevertheless still optimize (Eq. (4)) by replace the support constraint with a stronger one that does not rely on D e.g., minimizing I[Z; X] (see <ref type="bibr">Sec. 4.2.2)</ref>, . This highlights the potential of Prop. 2: if one can find a large source of inputs X and domain-agnostic augmentations A (e.g., the 400M image-text pairs of CLIP) then one can, in principle, learn optimal representations for IDG on any downstream task Y that A preserves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">PRACTICAL OBJECTIVES</head><p>We now design practical objectives for learning optimal representations without labels. Proposition 2 does provide an objective but it is impractical as it involves constrained optimization. We can nevertheless convert it to the following unconstrained objective by using a Lagrangian relaxation and introducing a domain bottleneck B[Z, D] that enforces support match, arg min</p><formula xml:id="formula_7">p Z | X ? I[A; Z] + ? B[Z, D] ,<label>(5)</label></formula><p>Eq. (5) is a valid reformulation of Prop. 2 as long as minimizing B[Z, D] while maximizing I[A; Z] enforces the support constraint in Eq. (4). Below, we provide different choices of such B[Z, D] each of which results in a different SSL objective. In practice, however, terms in Eq. (5) are hard to estimate from finite samples. We now discuss two variational bounds that can be efficiently estimated and optimized with stochastic gradient descent <ref type="bibr" target="#b9">(Bottou, 2010)</ref>. For simplicity, we use a deterministic encoder e ? : X ? Z for the rest of the paper. Detailed derivations are in Appx. C.</p><p>For both practical objectives we use a contrastive variational lower bound on I[A; Z] based on InfoNCE <ref type="bibr" target="#b36">(Oord et al., 2018)</ref>, which is standard in SSL. Specifically, for a sample X, we first obtain the augmented 'positive' A by sampling from p A | X . We then obtain n augmented 'negatives'</p><formula xml:id="formula_8">A ? i n i=1 i.i.d. from the marginal p A by first independently sampling X := X ? i n i=1 from p X and then sampling A ? i from p A | X ? i . We denote A := A, A ? 1 , . . . , A ? n .</formula><p>InfoNCE then uses a critic s ? to score how likely each A ? A is to be positive, resulting in the following variational bound,</p><formula xml:id="formula_9">I[A; Z] ? log(n + 1) + E p A,X,Z log exp s ? (A, Z) A ?A exp s ? (A , Z) .<label>(6)</label></formula><p>When A = X , one can tie the parameters of the critic and the encoder by passing augmentations through the encoder and taking an inner product, i.e., s ? (A, Z) := e ? (A) T Z.</p><p>Many previous DG regularizers (e.g., <ref type="bibr" target="#b15">Ganin et al., 2016;</ref><ref type="bibr" target="#b31">Li et al., 2018b</ref>;a) could be valid domain bottlenecks. In the following, we discuss two possible B[Z, D] , the first of which is novel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">CONTRASTIVE ADVERSARIAL DOMAIN BOTTLENECK (CAD)</head><p>Algorithm 1 CAD objective Require: e?, s?, D, X, n 1:  <ref type="bibr" target="#b15">Ganin et al., 2016)</ref> does so by ensuring that a domain classifier q ? cannot predict domains from representations, i.e., it max-</p><formula xml:id="formula_10">Z ? e?(X) 2: A ? sample(p A | X ) 3: (D ? i , X ? i , A ? i ) n i=1 i.i.d. ? ? ? sample(pD,X,A) 4: X, A ? X ? i n i=1 ,{A} ? A ? i n i=1 5: X?D ? X ? i | D ? i = D, i ? [n] 6: Laug ? ? log exp s ? (A,Z) A ?A exp s ? (A ,Z) ? I[A; Z] 7: Lsupp ? ? log X ?X ?D exp e?(X ) T Z X ?X exp e?(X ) T Z I[Z; D</formula><formula xml:id="formula_11">imizes E p D,Z [? log q ? (D | Z)] ? H[D | Z] w.r.t. encoder parameter ? but minimizes it w.r.t. ?.</formula><p>However, DANN suffers from two issues: (i) it maximizes an upper bound on the desired term; (ii) it requires adversarial training, which is challenging in practice.</p><p>To overcome these issues, we construct q(D | Z) without introducing additional parameters and with a bound that is tight with enough samples. In short, using the equality p D | Z = E p X | Z p D | X , we set our variational distribution to q(D | Z) = E q ?,X [p(D | X)], where q ?,X (X | Z) is a contrastive variational distribution of p X | Z constructed with samples X and a critic e ? (X) T Z tied with the encoder,p is a count estimate of p D | X . Detailed derivations and explanations are in Appx. C.3. The resulting contrastive adversarial domain (CAD) objective is in Algorithm 1. First, sample domains</p><formula xml:id="formula_12">D := {D ? i } n i=1</formula><p>for each X ? X. Then collect inputs associated with a different domain from the current domain D, i.e., X ?D :</p><formula xml:id="formula_13">= {X ? i | D ? i = D, i ? [n]}.</formula><p>Ignoring constants, the final loss is</p><formula xml:id="formula_14">L CAD (?, ?) := E p D,X,A,Z ? log exp s ? (A, Z) A ?A exp s ? (A , Z) ? ? log X ?X ?D q ?,X (X | Z) .<label>(7)</label></formula><p>In Appx. C.4, we also derive a conditional variation of CAD that minimizes I[Z; D | Y ], which can be used when labels are available and supervised augmentations are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">ENTROPY BOTTLENECK (ENT)</head><p>Our second domain bottleneck is the entropy bottleneck (Ent) that minimizes H[Z] = I[Z; X] ? I[Z; D], where the first equality uses the encoder's determinism. Ent enforces support match by removing all information that is not needed to maximize I[Z; A]. In particular, minimizing I[Z; X] is more stringent than I[Z; D], as it also matches the representations inside a domain. The advantage of Ent is that it does not require domain samples D, which are rarely accessible in SSL. We consider the standard variational bound used in neural compression <ref type="bibr" target="#b2">(Ball? et al., 2016;</ref><ref type="bibr" target="#b51">Theis et al., 2017)</ref>,</p><formula xml:id="formula_15">H[Z] ? E p Z [? log q ? (Z)]</formula><p>, where an entropy model q ? (Z) is used. This leads to  <ref type="bibr">Zhao et al. (2019)</ref> also proves minimizing only the source risk R ds [Y | Z] is not sufficient; but none of them proves the desired necessary condition. Our work distinguishes from previous work on three key aspects: (i) we are the first to study and formalize optimally robust representations, and provide the achievable sufficient and necessary conditions; (ii) we prove that one can practically learn optimal Z * with SSL using domain-agnostic augmentations; (iii) we consider a more general framework with any standard losses and a less stringent generalized covariate shift assumption, Still, our work is more specific than others, as we consider idealized DG and unrestricted predictors H.</p><formula xml:id="formula_16">L Ent (?, ?, ?) := E p X,A,Z ? log exp s ? (A, Z) A ?A exp s ? (A , Z) ? ? log q ? (Z) .<label>(8</label></formula><p>Practical objectives for DG. The most popular DG methods aim to learn domain-invariant representation by minimizing various divergernces between the marginal distributions p Z | d and p Z <ref type="bibr" target="#b32">(Long et al., 2015;</ref><ref type="bibr" target="#b15">Ganin et al., 2016;</ref><ref type="bibr" target="#b48">Sun &amp; Saenko, 2016;</ref><ref type="bibr" target="#b33">Long et al., 2017;</ref><ref type="bibr" target="#b30">Li et al., 2018a;</ref><ref type="bibr" target="#b46">Shen et al., 2018;</ref><ref type="bibr" target="#b35">Nguyen et al., 2021)</ref>. Others propose matching the conditional p Z | y,d across domains instead <ref type="bibr" target="#b17">(Gong et al., 2016;</ref><ref type="bibr" target="#b31">Li et al., 2018b;</ref><ref type="bibr" target="#b49">Tachet des Combes et al., 2020)</ref>. These regularizers would all be valid domain bottlenecks B <ref type="bibr">[Z, D]</ref> . Another line of work aims at learning Z with invariant predictors p Y | z,d across domains (e.g., <ref type="bibr" target="#b1">Arjovsky et al., 2019;</ref><ref type="bibr" target="#b28">Li et al., 2021)</ref>. However, none of these methods outperform ERM with fair model selections <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head><p>In our experiments, we aimed to: (i) verify our theoretical results in practice; (ii) investigate our proposed representation learning objectives in practical DG; (iii) take advantage of pretrained SSL models (in particular, CLIP) to achieve powerful models for DG. Unless stated otherwise, we consider a two-stage training setup. First, the representation learner ("the representor") trains an encoder p Z | X using a specified objective and freezes it. Then, the person performing predictions ("the learner") trains her predictor h from Z by minimizing the risk on source data. Finally, the representation Z and predictor h are evaluated on target data. In all experiments, the learner uses a linear classifier for h. For the Ent bottleneck, we used <ref type="bibr">Ball? et al.'s (2018)</ref> entropy model. For the CAD bottleneck we used its conditional version whenever labels were available. When a model contains no domain bottleneck, we label it as "Base". For experimental details and additional results see Appxs. E and F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">SCIENTIFIC SETTING: EXPLORING OPTIMAL REPRESENTATIONS FOR WORST-CASE DG</head><p>To validate our theory, we studied optimal representations in a scientific setup that is as close to our IDG framework as possible with log-loss . In particular, we used the PACS dataset ) and approximated the idealized DG by treating the dataset as the population distribution, i.e., we did not split datasets into train and test sets. To approximate the worst-case source predictor, we followed <ref type="bibr" target="#b12">Dubois et al. (2020)</ref> by incorporating the wrongly labeled target data to the source domain. The experimental setup goes as follows: (i) the representor trains a ResNet-18 <ref type="bibr" target="#b20">(He et al., 2016)</ref> to minimize the objective on labeled data from all domains; (ii) the learner trains a worst-case source classifier h on every possible pair of (source, target); (iii) the negative target risk (log likelihood) for each h is evaluated. We reported the log likelihood averaged over 5 seeds. For more realistic scenarios (i.e. non-idealized average-case DG) see Appx. F.2 which replicates the following results.</p><formula xml:id="formula_17">Base Ent CAD R[Y |Z] H[A|Z] -5.1?0.3 -0.4?0.1 -0.7?0.1 -3.5?0.1 -0.0?0.0 -0.8?0.2<label>(</label></formula><p>Do our domain bottlenecks improve worst-case DG? In <ref type="figure" target="#fig_2">Fig. 3a</ref>, we compare IDG performance of representations trained with (Ent, CAD) and without (Base) domain bottlenecks. We see that both bottlenecks significantly improve the worst-case DG, and nearly achieve the source-domain performance (0 log likelihood). This shows the importance of support match (Thm. 2) and the effectiveness of our bottlenecks to enforce it. In Appx. F.2, we show that bottlenecks also helps in practical scenarios, i.e., non-idealized average-case DG evaluated with accuracy (95.9% ? 96.7%).</p><p>What is the effect of ?? <ref type="figure" target="#fig_2">Fig. 3b</ref> shows the effect of the bottleneck weight ? on the worst-case target and source performance. We see that increasing ? will decrease the DG gap. As a result the target performance improves until ? ? 10 2 , where source performance starts to decrease.</p><p>What if the representor has access to domain-agnostic augmentations instead of labels? In Sec. 4.2, we provide a contrastive objective for using augmentations. To show the effectiveness of the objective, we compared minimizing H[A | Z] using Eq. (6) to standard supervised risk minimization R [Y | Z] and used the domain-agnostic supervised augmentations <ref type="figure">(Fig. 2b</ref>). The 1 st and 2 nd row of <ref type="figure" target="#fig_2">Fig. 3a</ref> show that our objective performs similarly to direct label prediction.</p><p>How important is the choice of augmentations? Prop. 2 shows that domain-agnostic (DA) augmentations are sufficient for achieving IDG, but it does not give necessary conditions. Here we investigate the effect of using our loss with different choices of augmentations. Specifically, we used L CAD with five augmentations. The first two are DA. 'Supervised': augment inputs inside the label class across all domains as in <ref type="figure">Fig. 2b</ref>; 'SingleDom': augment inputs to same label samples from a fixed domain. The second two are not DA. 'Standard': standard SSL augmentations  as in <ref type="figure">Fig. 2a</ref>; 'IntraDom': augment inputs to same label and same domain samples. Finally, we consider 'ApproxDA', which is approximately DA by augmenting 10% of the time with 'Supervised' and 90% of the time with 'IntraDom'. <ref type="figure" target="#fig_2">Fig. 3c</ref> shows that the non-DA augmentations give terrible results compared to DA. Interestingly, 'ApproxDA' also performs very well, which suggests that approximately DA augmentations might be sufficient to learn optimal representations in practice.</p><p>What if the representor does not have access to target domains? Prop. 1 shows that DG without access to target domains is generally impossible. We empirically verified this by excluding a predefined target d t domain from the representor's training set, i.e., L CAD is optimized on 3 of the 4 domains. The learner then trains a predictor h on each source. We finally evaluate each h on the target domain d t , and average over choices of d t . The resulting worst-case log likelihood was ?4.2 ? 0.2, which is significantly worse than when the representor had access to all domains (?0.8 ? 0.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL</head><p>As discussed in Sec. 4.1, one can learn optimal representations for IDG by performing SSL with a domain bottleneck on a large sample of inputs X and domain-agnostic augmentations A. This is nearly how CLIP was pretrained (SSL with 400M image-text pairs) except it did not include a domain bottleneck. In this section, we investigate how to take advantage of CLIP to approximate optimal representations for IDG. We did so in two simple steps. First, we froze the pretrained CLIP and added a multi-layer perceptron (MLP) that could effectively finetune CLIP's representations. Then, we trained the MLP by minimizing our CAD bottleneck and R [Y | Z] on the available data.</p><p>In all experiments, we used the standard DomainBed benchmark (with non-MNIST datasets) and protocol <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2021)</ref>. In particular, we left out a target domain for evaluation and used the union of other domains for training both the encoder and the classifier. Contrary to our scientific setting, the representor does not get access to the target domain. All our representations were evaluated by fitting a linear classifier on source domains with source validation selection. As in DomainBed we selected the encoder based on 'oracle selection' over 10 hyperparameters, and reported the target accuracy averaged over all choices of targets and 5 random seeds with standard errors. Note that using 'oracle selection' is more consistent with our theory since it gets access to the necessary target information (for model selection), as discussed in Appx. F.3. Due to space limit, we only included as baselines 'ERM' and 'DomainBed SOTA' which for each dataset is the best result over all baselines. The extended results and baselines are in <ref type="table">Table 4</ref>. Details in Appx. E.3. We investigated two pretrained CLIP models with different number of parameters. The larger ViT-B/32 denoted 'CLIP L' and the smaller ResNet-50 denoted 'CLIP S'. Can we approximate optimal representations by exploiting pretrained CLIP? The row 'CLIP L + CAD' in <ref type="table" target="#tab_3">Table 1</ref> shows that finetuning a large pretrained CLIP model with our CAD achieves SOTA on nearly all DomainBed benchmarks by a very large margin (see 2 nd row). Note that the poor performance on TerraIncognita is likely because CLIP's dataset does not cover such images (camera traps monitoring animals). The last row essentially shows an optimal representation, which we approximate by finetuning CLIP L with our CAD on all domains including the target. The gap between CLIP L + CAD and the upper-bound suggests that one can still learn better representations. We hypothesize that end-to-end training of our objective would greatly shrink this gap.</p><p>Are gains due to the architectural differences? DomainBed's baselines finetuned an ImageNet pretrained ResNet-50. In contrast, CLIP L pretrained a larger ViT. To decouple gains due to our objective from architectural gains, we evaluated ResNet-50 pretrained CLIP S. <ref type="table" target="#tab_3">Table 1</ref> shows that CLIP S + CAD still significantly outperforms DomainBed baselines. Note that our theory does not constrain the encoder and so we expect larger encoders to be better as seen in <ref type="table" target="#tab_3">Table 1</ref>.</p><p>What is the effect of domain bottlenecks? In the "CLIP" rows of <ref type="table" target="#tab_3">Table 1</ref>, we investigated the effect of finetuning CLIP with our CAD bottleneck. We see that for both CLIP L and CLIP S, it consistently improves results by around 1 ? 2%. These gains are due to the bottleneck, rather than finetuning on source data as seen by 'CLIP S + Base'. We believe the gains could potentially be much larger if CLIP was trained end-to-end with our bottleneck. Note that raw CLIP S already significantly outperforms baselines. We hypothesize that this is because SGD acts as an information bottleneck that naturally favors support match <ref type="bibr" target="#b47">(Shwartz-Ziv &amp; Tishby, 2017)</ref>.</p><p>Which pretrained SSL model to use? Our theory suggests that we can exploit pretrained SSL models as long as their augmentations are domain-agnostic and their training set covers desired domains. We investigated adaption of SSL models that do not satisfy those properties by finetuning DINO <ref type="bibr" target="#b10">(Caron et al., 2021)</ref>, the current SOTA on SSL ImageNet. DINO is pretraiend using standard augmentations. As a result, <ref type="table" target="#tab_3">Table 1</ref> shows that the finetuned DINO + CAD significantly underperforms compared to CLIP S and DomainBed baselines. This supports our hypothesis that CLIP is much more robust than other SSL methods due to its domain-agnostic augmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">TOWARDS GENERIC ROBUST REPRESENTATIONS WITH SSL</head><p>In the previous section, we finetuned CLIP in a task specific fashion by optimizing R [Y | Z] and our CAD bottleneck. To get generic (task agnostic) robust representations, one should instead directly use our objectives on a sufficiently large dataset with image-text augmentations. Unfortunately, we cannot fully train CLIP with our bottlenecks as we do not have access to CLIP's original dataset and sufficient compute. In this section, we aim to emulate such training of generic robust representations.</p><p>To do so we used LAION-400M <ref type="bibr" target="#b43">(Schuhmann et al., 2021)</ref> that is a public dataset that contains 400M web-crawled image-text pairs. Due to our computational budget, we again froze the pretrained CLIP L and only finetuned an additional MLP with our L Ent . We used L Ent as it only requires access to paired image X and text A but no prior information about domain D. As in CLIP's paper, we evaluated the learned representation Z in <ref type="table">Taori</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We gave a simple variational characterization of all representations on which source-risk minimizers are guaranteed to generalize to target domains that preserve the Bayes predictor. Similar to previous work, our theory strongly implies the need for target information when learning representations for domain generalization. Nevertheless, we identified a domain-agnostic property of data augmentations that make it possible to learn optimal representations from unlabelled data. Thus, we showed that it is possible to learn robust representations using only large sources of inputs X and augmentations A.</p><p>There are caveats that need to be addressed in future work. First, we studied an idealized DG, which assumes access to the population distributions. This gives insights into the challenges that are specific to DG, rather than finite sample challenges faced throughout ML. Second, we considered risk minimizers from an unconstrained hypothesis class. The support constraint can likely be weakened, if the hypothesis class is constrained. Finally, we focus only on optimal representations, but it would be interesting to characterize approximately optimal representations. Nevertheless, in this idealized setting, our characterization is a springboard from which all future objectives can be derived, and, in general, it brings us closer to the goal of robust machine learning systems.  For the most part, we will assume that all spaces are discrete probability spaces. A full list of assumptions is found at Appx. A.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><formula xml:id="formula_18">C Practical objectives 27 C.1 Mutual information bottleneck B[Z, X, Y, D] = I[Z; X] . . . . . . . . . . . . 27 C.2 Entropy bottleneck B[Z, X, Y, D] = H[Z] . . . . . . . . . . . . . . . . . . . . 28 C.3 Contrastive adversarial domain bottleneck B[Z, X, Y, D] = I[Z; D] . . . . . . . 29 C.4 Conditional CAD B[Z, X, Y, D] = I[Z; D | Y ] . . . . . . . . . . . . . . . . .</formula><formula xml:id="formula_19">General The image of a set A ? X under a function f : X ? Y is denoted f ? (A) = {f (x) | x ? A}. The pre-image is denoted f ? (B) = {x ? X | f (x) ? B} for B ? Y.</formula><p>Probability Random variables (r.v.) are denoted by uppercase letters (e.g., X), and their sample space and realizations are denoted by the corresponding calligraphic (e.g., X ) and lowercase letters (e.g., x) respectively. The probability mass function (pmf) of a random variable X is denoted as p X . We use capital P instead of p to denote the measure under p. The support supp(p X ) of a discrete distribution is the set of all points x ? X with positive probability, i.e.,</p><formula xml:id="formula_20">supp(p X ) = {x ? X | p X (x) &gt; 0}. The space of all probability distributions on X is denoted P(X ) = p X | p X (x) ? 0 and x?X p X (x) = 1 .</formula><p>When it is necessary to be explicit, we will denote 'X is distributed as p X ' using the notation X d ? p X . Expectations are written as:</p><formula xml:id="formula_21">E p X [f (X)], independence of two r.v. as ?? ??, conditional independence as ?? ? ? | ?. For jointly distributed random variables (X, Y ) taking value in (t.v.i.) X ? Y, the conditional distribution is denoted as p Y | X : Y ? X ? [0, 1]. For convenience, let p Y | x = p Y | X ( ? | x) be the conditional distribution of Y given x.</formula><p>All random variables are independently distributed, unless an explicit joint distribution or coupling is given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 DEFINITIONS</head><p>We are interested in prediction problems with domain shift. There are three random variables: the target domain D t , the input X, the label Y . They have the following joint distribution:</p><formula xml:id="formula_22">(D t , X, Y ) d ? p Dt ? p X,Y | Dt (9)</formula><p>where we drop the arguments of the probability densities for clarity. We make a variety of convenience assumptions on these random variables (Assumption 6). Crucially, we will be making the Bayes invariance assumption on p Dt,X,Y that can be thought of as a generalized covariate shift assumption (Assumption 4).</p><p>We will be studying the effect of changing the representation of the data. This is done by "encoding" X into a representation Z using a conditional distribution p Z | X .</p><p>Definition 1 (Encoder). An encoder is a conditional distribution p Z | X : Z ? X ? [0, 1] from the input space X to the representation space Z.</p><p>The data together with the representation has the following joint:</p><formula xml:id="formula_23">(D t , X, Y, Z) d ? p Dt ? p X,Y | Dt ? p Z | X<label>(10)</label></formula><p>The key thing to notice here is that Z is conditionally independent of Y, D t given X. In particular, the same encoder is used across all domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.1 RISK MINIMIZATION</head><p>Our ultimate goal is to predict Y from the representation Z of X in a manner that is robust to changes in the domain.</p><p>We formalize this in the standard way by making predictions ? ? ? in a space of predictions or actions. For example the prediction space may be the set of all possible labels ? = Y, in which case we would be predicting deterministic labels. Or we may predict a distribution over labels, in which case the prediction space would be the set of all probability distributions on Y, i.e. ? = P(Y).</p><p>A predictor is a function mapping inputs to predictions, i.e., f : X ? ?, or representations to predictions, i.e., h : Z ? ?. For example, f may be a neural network that takes as input a sample x and outputs a vector of logits that parameterize a softmax distribution over finitely many labels.</p><p>We select predictors according to the risk defined via a loss function :</p><formula xml:id="formula_24">Y ? ? ? R ?0 ? {?}: R f [Y | X] := E p X,Y [ (Y, f (X))] .<label>(11)</label></formula><p>In particular, we are interested in the Bayes (minimum) risk over all predictors:</p><formula xml:id="formula_25">R [Y | X] := inf f R f [Y | X] ,<label>(12)</label></formula><p>We denote the set of all optimal predictors from X as</p><formula xml:id="formula_26">F * := {f | R f [Y | X] = R [Y | X]}<label>(13)</label></formula><p>Similarly, we define the risk R h [Y | Z], the Bayes risk R [Y | Z], and the set of optimal predictors</p><formula xml:id="formula_27">H * Z := {h | R h [Y | Z] = R [Y | Z]}<label>(14)</label></formula><p>from Z, all of which vary as a function of the encoder p Z | X . Note, in the main body of the paper, we omitted the subscript Z from H * Z for clarity, but we will keep it in the Appendices. We assume that together our loss and prediction space always admit optima (Item 2 of Assumption 2), and thus F * , H * Z are always non-empty. We will be assuming that the risk admits unique optimal prediction when predicting from X (Item 3 of Assumption 2). Thus it makes sense to define the following:</p><p>Definition 2 (The Bayes predictor). The Bayes predictor f * : X ? ? is the unique predictor that is optimal for all x ? X :</p><formula xml:id="formula_28">f * (x) = arg min ??? E p Y | x [ (Y, ?)]<label>(15)</label></formula><p>Definition 3 (The Bayes image). The image of all the inputs under the Bayes predictor will be denoted as ? * = f * ? (X ) and called the Bayes image.</p><p>Note that F * becomes a singleton {f * }, but it is not necessarily the case for H * Z since we will not be making any uniqueness assumption on optimal prediction from Z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 DOMAIN GENERALIZATION</head><p>We are interested in controlling the risk in a domain generalization setting, and so we define the domain-conditional risk,</p><formula xml:id="formula_29">R d f [Y | X] := E p X,Y | d [ (Y, f (X))] .<label>(16)</label></formula><p>R d [Y | X] , F * d are defined as Eqs. <ref type="formula" target="#formula_0">(12)</ref> and <ref type="formula" target="#formula_0">(13)</ref>, respectively, but with respect to R d f . Similarly, define the Bayes image for domain d as</p><formula xml:id="formula_30">? * d := f * ? supp(p X | d ) .<label>(17)</label></formula><p>We also define domain-conditional quantities for prediction from a representation Z. The most important term which we will be investigating is an idealization of the domain generalization worstcase risk.</p><p>Definition 4 (IDG risk). Given an encoder p Z | X and a distribution p Dt,Ds over a target domain D t and source domain D s , the idealized domain generalization worst-case risk, IDG risk for short, is the expected worst-case target risk taken over source minimizers, i.e.,</p><formula xml:id="formula_31">R IDG [Y | Z] := E p D t ,Ds sup h?H * Z,Ds R Dt h [Y | Z]<label>(18)</label></formula><p>Note that the IDG risk is well-defined because H * Z,Ds is non-empty by Assumption 2. The desired optimal representations, are then those that minimize the IDG risk.</p><p>Definition 5 (Optimal representations for IDG). An encoder p Z * | X is optimal for idealized domain generalization if and only if it minimizes the IDG risk, i.e.,</p><formula xml:id="formula_32">R IDG [Y | Z * ] = inf p Z | X R IDG [Y | Z]<label>(19)</label></formula><p>A.3 ASSUMPTIONS</p><p>We make a the following assumptions throughout the paper. All these assumptions should hold for practical settings.</p><p>Assumption 1 (Convenience: discrete probability spaces). All data spaces (D, X , Y, Z, A) are discrete spaces. Because the distributions of X, Y, D are fixed, we assume for convenience that supp(p X ) = X , supp(p Y ) = Y, and supp(p Dt ) = D.</p><p>Assumption 1 is a convenience assumption to avoid measure theory for the sake of clarity. It always holds in practice due to finiteness of computers, i.e., all spaces will be finite but arbitrarily large. We believe that our claims can nevertheless be generalized to typical continuous spaces with some minor technical assumptions.</p><p>Assumption 2 (Losses admit optima). We assume that our risk always admits optimal predictions:</p><formula xml:id="formula_33">1. |?| &gt; 1. 2. For all p ? ? P(Y), there exists ? * ? ?, such that E p? [ (?, ? * )] ? E p? [ (?, ?)] ? ? ? ?.<label>(20)</label></formula><p>3. For all x ? X , there exist ? * ? ?, such that</p><formula xml:id="formula_34">E p Y | x [ (Y, ? * )] &lt; E p Y | x [ (Y, ?)] ? ? = ? * .<label>(21)</label></formula><p>Note that for log-loss (y, ?) = ? log ?(y) and finite Y, these assumptions are satisfied if ? = P(Y) where the optimal prediction for Item 3 is ? * = p Y | x by strict properness <ref type="bibr" target="#b16">(Gneiting &amp; Raftery, 2007)</ref>. If we consider the 0-1 loss (reverse accuracy) (y, ?) = 1 ? 1[y = ?] with ? = Y and a finite label space where the optimal prediction for Item 3 is ? * = arg max y?Y p Y | x (y), this assumption is mostly satisfied, except we assume that p Y | x has a unique mode.</p><p>Assumption 2 serves two purposes: Item 2 ensures that for any representation the optimal predictors from Z exists such that the IDG risk is well-defined as in Def. 5; Item 3 ensures a unique Bayes predictor from X, which simplifies the analysis and is satisfied by common losses as described above.</p><p>Assumption 3 (Cardinalities). We assume that</p><formula xml:id="formula_35">|Z| ? |? * | ? 2<label>(22)</label></formula><p>Assumption 3 is very weak and ensures that optimal representations always exists (Prop. 3).</p><p>Assumption 4 (Generalized covariate shift). The Bayes predictor is optimal for all domains. I.e., for</p><formula xml:id="formula_36">all (x, d) ? supp(p X,Dt ), ? ? ? such that ? = f * (x), we have E p Y | x,d [ (Y, f * (x))] &lt; E p Y | x,d [ (Y, ?)] .<label>(23)</label></formula><p>For example, in the case of strictly proper scoring rules, e.g. log loss, covariate shift p Y | X,D = p Y | X is equivalent to the invariance of the Bayes predictor. For the 0-1 loss, this is guaranteed by invariance of the most likely label. For MSE it is guaranteed by the invariance of the expected label. In the latter two cases, Assumption 4 is less stringent than the typical covariate shift assumption.</p><p>Assumption 4 is the core assumption for our theoretical results. It ensures that source and target domains are related in a useful way that can be utilized by the representation.</p><p>Assumption 5 (Constant Bayes image). The Bayes image is invariant across domains, i.e., for all d ? D,</p><formula xml:id="formula_37">? * d = ? * .<label>(24)</label></formula><p>For the case of 0-1 loss, this simply means that the label set for all domains is the same, which is trivial. For log-loss, this means that the set of possible conditional distributions ?</p><formula xml:id="formula_38">* d = {p Y | x | x ? supp(p X | d )} is the same across domains.</formula><p>Assumption 5 is crucial to be able to learn. Without it, in the extreme case, one could set each domain to be all examples associated with a single element from the label set (or the Bayes image set) in which case it is impossible to generalize across different domains. Assumption 5 is also necessary to guarantee the existence of optimal representations as in Prop. 3.</p><p>Assumption 6 (Domain joint). p Dt,Ds is any distribution such that supp(p Dt,Ds ) = D ? D.</p><p>In a simplified scenario, one could define the source D s and target D t as i.i.d. r.v. from p Dt , where p Dt,Ds = p Dt ? p Ds = p Dt ? p Dt and Assumption 6 is trivially satisfied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B PROOFS B.1 LEMMAS FOR GENERAL LOSSES</head><p>An important result that we will be using is the generalized data processing inequality of Bayes risk <ref type="bibr" target="#b56">(Xu &amp; Raginsky, 2020;</ref><ref type="bibr" target="#b13">Dubois et al., 2021)</ref>. We include it here for completeness.</p><p>Lemma 1 (Generalized DPI <ref type="bibr" target="#b56">(Xu &amp; Raginsky, 2020;</ref><ref type="bibr" target="#b13">Dubois et al., 2021)</ref>). Let Z ? X ? Y be a Markov chain of random variables. For any loss function ,</p><formula xml:id="formula_39">R [Y | X] ? R [Y | Z] .<label>(25)</label></formula><p>For the case of strictly proper losses (Assumption 2) we can go one step further.</p><p>Lemma 2. Let Z ? X ? Y be a Markov chain of random variables. Then, under Assumptions 1 and 2 we have that</p><formula xml:id="formula_40">R [Y | Z] = R [Y | X] ?? ?h * ? H * Z , ?(x, z) ? supp(p X,Z ), h * (z) = f * (x). (26) Proof. Suppose that for all h * ? H * Z we have h * (z) = f * (x) on the support of p X,Z . Then, R [Y | X] = E p X,Y [ (Y, f * (X))] (27) = E p X,Y p Z | X [ (Y, f * (X))] (28) = E p X,Y p Z | X [ (Y, h * (Z))] (29) = E p Z,Y [ (Y, h * (Z))] (30) = R [Y | Z] .<label>(31)</label></formula><p>Now suppose there exists a h * ? H * Z and a pair (</p><formula xml:id="formula_41">x , z ) ? supp(p X,Z ) such that h * (z ) = f * (x ). Then R [Y | Z] (32) = E p X,Z p Y | X [ (Y, h * (Z))] (33) = p X,Z (x , z ) E p Y | x [ (Y, h * (z ))] + (x,z) =(x ,z ) p X,Z (x, z) E p Y | x [ (Y, h * (z))]<label>(34)</label></formula><formula xml:id="formula_42">? p X,Z (x , z ) E p Y | x [ (Y, h * (z ))] + (x,z) =(x ,z ) p X,Z (x, z) E p Y | x [ (Y, f * (x))]<label>(35)</label></formula><formula xml:id="formula_43">&gt; p X,Z (x , z ) E p Y | x [ (Y, f * (x ))] + (x,z) =(x ,z ) p X,Z (x, z) E p Y | x [ (Y, f * (x))]<label>(36)</label></formula><formula xml:id="formula_44">= R [Y | X]<label>(37)</label></formula><p>Eq. </p><formula xml:id="formula_45">prevents R [Y | Z] &lt; R [Y | X].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 PROOF OF THEOREM 1</head><p>First we will show that the desired representation exists by taking all inputs for which the Bayes predictor predicts similarly and "bucketing" them to the same representation. This is a direct extension of the example from Dubois et al.'s (2020) Proposition 6, to the case of proper losses.</p><p>Proposition 3 (Existence of optimal representations). Under Assumptions 1 to 5, there exists an encoder p Z * | X that is optimal for Eq.</p><p>(3), i.e.,</p><formula xml:id="formula_46">p Z * | X ? arg min p Z | X R [Y | Z] s.t. ? d ? D, supp(p Z | d ) = supp(p Z ).<label>(38)</label></formula><p>Moreover, we have that</p><formula xml:id="formula_47">R [Y | X] = R [Y | Z * ] .<label>(39)</label></formula><p>Proof. Because we assume arbitrary encoders p Z | X , the essence of this construction is simple: we embed the Bayes image into Z. Indeed, let ? : ? * ? Z be any one-to-one function, which exists due to Assumption 3 (here we use deterministic one-to-one function for simplicity, the construction can be easily extended to stochastic case). Then let Z * = ?(f * (X)). We now verify the properties of p Z * | X .</p><formula xml:id="formula_48">1. Z * satisfies R [Y | X] = R [Y | Z * ]. Indeed, R [Y | X] = E p X,Y [ (Y, f * (X))] (40) = E p X,Y p Z * | X [ (Y, f * (X))] (41) = E p Z * ,Y (Y, ? ?1 (Z * )) (42) ? R [Y | Z * ] .<label>(43)</label></formula><p>Eq. <ref type="formula" target="#formula_1">(42)</ref> is by our construction of Z * and Eq. <ref type="formula" target="#formula_3">(43)</ref> is by the definition of the Bayes risk. Due to the data processing inequality of Bayes risk (Lemma 1) we also have R</p><formula xml:id="formula_49">[Y | X] ? R [Y | Z * ], from which we conclude that R [Y | X] = R [Y | Z * ]</formula><p>and that Eq. (39) holds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Recall that</head><formula xml:id="formula_50">? * = f * ? (X ) and ? * d = f * ? supp(p X | d )</formula><p>. Now let us compute the desired support for all d ? D:</p><formula xml:id="formula_51">supp(p Z * | d ) = ? ? (? * d ) (44) = ? ? (? * ) (45) = supp(p Z * ).<label>(46)</label></formula><p>Eq. (45) is by Assumption 5.</p><p>Because R [Y | X] is the minimum achievable risk by any encoder regardless of constraint (this is by Lemma 1), this implies that p Z * | X is an optimal encoder for Eq. (3).</p><p>The following lemma essentially says that when R [Y | Z] is minimized, then the optimal predictors for each domain all agree on the intersection of their support.</p><formula xml:id="formula_52">Lemma 3. Let p Z | X be an encoder such that R [Y | Z] = R [Y | X].</formula><p>Under Assumptions 1 and 2, we have that for all z ? supp(p Z ), there exists ? * ? ? such that</p><formula xml:id="formula_53">E p Y | z [ (Y, ? * )] &lt; E p Y | z [ (Y, ?)] ? ? = ? * .<label>(47)</label></formula><p>In other words, the restriction of any h * ? H * Z to supp(p Z ) is unique. If, in addition, Assumption 4 holds, then for all (z, d) ? supp(p Z,Dt ), ? ? ? such that ? = h * (z),</p><formula xml:id="formula_54">E p Y | z,d [ (Y, h * (z)] &lt; E p Y | z,d [ (Y, ?)] .<label>(48)</label></formula><p>In other words, the restriction of any h ? H * Z,d to supp(p Z | d ) is unique and equal to h * .</p><p>Proof. For the first result, let z ? supp(p Z ) and consider x ? supp(p X | z ). By Lemma 2, it must be the case that f * is constant on supp(p X | z ). Thus, we can pick ? * = f * (x). Now, let ? = ? * . We have that,</p><formula xml:id="formula_55">E p Y | z [ (Y, ? * )] = E p X | z p Y | X [ (Y, ? * )] (49) = E p X | z p Y | X [ (Y, f * (X))] (50) &lt; E p X | z p Y | X [ (Y, ?)] (51) = E p Y | z [ (Y, ?)] .<label>(52)</label></formula><p>Eq. (49) is due to the conditional independence of Y and Z given X. Eq. (51) is due to Assumption 2 and the definition of the Bayes predictor. Let h * : supp(p Z ) ? ? be the unique Bayes predictor from Z. Now, for the second result, note that</p><formula xml:id="formula_56">R [Y | X] = R f * [Y | X]<label>(53)</label></formula><formula xml:id="formula_57">= d?D p Dt (d) R d f * [Y | X] (54) = d?D p Dt (d) R d [Y | X] ,<label>Assumption 4 (55)</label></formula><p>and</p><formula xml:id="formula_58">R [Y | Z] = R h * [Y | Z] (56) = d?D p Dt (d) R d h * [Y | Z] (57) ? d?D p Dt (d) R d [Y | Z] ,<label>(58)</label></formula><p>where Eq. <ref type="formula" target="#formula_7">(58)</ref> is due to the definition of (domain-conditional) Bayes risk. Then</p><formula xml:id="formula_59">R [Y | Z] ? R [Y | X] ? d?D p Dt (d) R d [Y | Z] ? R d [Y | X] (59) ? 0. Lemma 1 conditioned on d<label>(60)</label></formula><p>Thus, any encoder that achieves R</p><formula xml:id="formula_60">[Y | Z] = R [Y | X] also satisfies R d [Y | Z] = R d [Y | X] for all d ? D since we assume that supp(p Dt ) = D in Assumption 1. Now, let d ? D.</formula><p>An argument analogous to Lemma 2 gives us,</p><formula xml:id="formula_61">?h ? H * Z,d , ?(x, z) ? supp(p X,Z | d ), h(z) = f * (x) = h * (z). (61) Eq. (61) is derived from R d [Y | Z] = R d [Y | X]</formula><p>using Assumption 4 in place of Item 3 of Assumption 2 for a specific domain d.</p><formula xml:id="formula_62">Let z ? supp(p Z | d ) and ? ? ? such that ? = h * (z). Since supp(p X | z,d ) ? supp(p X | z ), f * is a constant on supp(p X | z,d</formula><p>) and equal to h * . Now, as above, we have that </p><formula xml:id="formula_63">E p Y | z,d [ (Y, h * (z))] = E p X | z,d p Y | X,d [ (Y, h * (z))] (62) = E p X | z,d p Y | X,d [ (Y, f * (X))] (63) &lt; E p X | z,d p Y | X,d [ (Y, ?)] (64) = E p Y | z,d [ (Y, ?)] .<label>(65)</label></formula><formula xml:id="formula_64">R dt h [Y | Z] = R dt [Y | Z]<label>(66)</label></formula><formula xml:id="formula_65">Proof. H * Z ? H * Z,d is immediate from Lemma 3. Now, we have that R dt h [Y | Z] ? R dt [Y | Z].</formula><p>So, the result follows by taking any h ? H * Z ? H * Z,ds in the inf of Eq. (66).</p><p>Theorem 2 (Characterizing optimal representations for IDG, equiv. Theorem 1). Under Assumptions 1 to 6, an encoder p Z | X is optimal for idealized domain generalization if and only if it minimizes the Bayes risk while matching the support of p Z | d and p Z for all d ? D, i.e.,</p><formula xml:id="formula_66">p Z | X ? arg min p Z | X R [Y | Z]<label>(67)</label></formula><formula xml:id="formula_67">s.t. ? d ? D, supp(p Z | d ) = supp(p Z )<label>(68)</label></formula><p>Proof. The IDG risk is lower bounded by R [Y | X]:</p><formula xml:id="formula_68">R IDG [Y | Z] ? E p Ds ,D t inf h?H * Z,Ds R Dt h [Y | Z]<label>(69)</label></formula><formula xml:id="formula_69">? E p Ds ,D t R Dt [Y | Z] (70) ? E p Ds ,D t R Dt [Y | X] Lemma 1 (71) = R [Y | X]</formula><p>Assumption 4 (72)</p><p>We will now show that this lower bound is achieved by an encoder if and only if it satisfies Eqs. <ref type="formula" target="#formula_9">(67)</ref> and <ref type="formula" target="#formula_9">(68)</ref>, which exist by Prop. 3.</p><p>Sufficiency ( ?= ): Let p Z | X be an encoder that satisfies Eqs. <ref type="formula" target="#formula_9">(67)</ref> and <ref type="formula" target="#formula_9">(68)</ref>.</p><formula xml:id="formula_70">Note that R [Y | Z] = R [Y | X] by Prop. 3. Let h * ? H * Z , then we have the following IDG risk R IDG [Y | Z] (73) = E p Ds ,D t sup h?H * Z,Ds E p Z,Y | D t [ (Y, h(Z))] (74) = E p Ds,D t sup h?H * Z,Ds E p Z,Y | D t [ (Y, h * (Z))]</formula><p>Lemma 3 under matching support (75)</p><formula xml:id="formula_71">= E p D t E p Z,Y | D t [ (Y, h * (Z))] constant w.r.t D s (76) = R [Y | Z] = R [Y | X]<label>(77)</label></formula><formula xml:id="formula_72">Necessity ( =? ): If the IDG risk is R [Y | X], then it must be the case that R [Y | Z] = R [Y | X] (78) sup h?H * Z,ds R dt h [Y | Z] = R dt [Y | Z] ?(d s , d t ) ? supp(p Ds,Dt )<label>(79)</label></formula><p>We will prove by contrapositive that Eq. (79) implies support match (Eq. <ref type="formula" target="#formula_9">(68)</ref>). Suppose that the support match does not hold. Since supp(p Z ) = ? d?D supp(p Z | d ) and supp(p Ds,Dt ) = D ? D (Assumption 6), there must exist (d s , d t ) ? supp(p Ds,Dt ) such that supp(p Z | ds ) = supp(p Z | ds ).</p><p>Define the set S = supp(p Z | ds ) ? supp(p Z | dt ) andS = supp(p Z | dt ) \ supp(p Z | ds ), let ? = P Z | dt (S), and let h * ? H * Z . Then, sup</p><formula xml:id="formula_73">h?H * Z,ds R dt h [Y | Z] (80) = sup h?H * Z,ds ? E p Y,Z | S,d t [ (Y, h(Z))] + (1 ? ?) E p Y,Z |S,d t [ (Y, h(Z))] (81) = sup h?H * Z,ds ? E p Y,Z | S,d t [ (Y, h * (Z))] + (1 ? ?) E p Y,Z |S,d t [ (Y, h(Z))] Lem. 3 (82) = ? E p Y,Z | S,d t [ (Y, h * (Z))] + (1 ? ?) sup h?H * Z,ds E p Y,Z |S,d t [ (Y, h(Z))]<label>(83)</label></formula><formula xml:id="formula_74">= R dt [Y | Z] + (1 ? ?) sup h?H * Z,ds E p Y,Z |S,d t [ (Y, h(Z)) ? (Y, h * (Z))]<label>(84)</label></formula><formula xml:id="formula_75">&gt; R dt [Y | Z] Lem. 3<label>(85)</label></formula><p>Eq. (85) uses the following reasoning. 1 ? ? &gt; 0 due to support mismatch. For any h ? H * Z,ds such that h = h * onS (such an h exists by Item 1 of Assumption 2), we have that</p><formula xml:id="formula_76">E p Y,Z |S,d t [ (Y, h(Z)) ? (Y, h * (Z))] &gt; 0<label>(86)</label></formula><p>by Lemma 3.</p><p>As a corollary from the proof strategy we directly have that the optimal DG risk is simply R [Y | X]. This means that using the optimal encoder one can actually perform just as well by training on the source as if you were to directly train on the target using the raw data.</p><p>Corollary 2 (Optimal IDG Risk). Under Assumptions 1 to 6,</p><formula xml:id="formula_77">inf p Z | X R IDG [Y | Z] = R [Y | X].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 IMPOSSIBILITY RESULTS</head><p>As a direct corollary of Thm. 2 we know that it is impossible to learn an optimal representation without knowledge or assumptions on the target domain. We can actually prove the following much stronger negative result, which essentially states that it is impossible to find a useful representation without having some information about the target domain. Specifically, we prove that if there exists a non-trivial target domain on which the representation is advantageous then there exists an infinite amount of target domains on which it is disadvantageous compared to predicting from a constant.</p><p>For clarity, we will focus on the proof for the standard accuracy (0-1 loss) which is much shorter and simpler to understand, but note that we can generalize the proof to all losses with the right assumptions.</p><p>The key is that outside of the source domain, the label distribution is unconstrained because generalized covariate shift has no effect. In other words, for any domain which gives some probability mass on an example that has not been seen during training, then all possible labels for that example gives a valid domain. Furthermore, if there exists one domain on which the representation is good, then one can construct a domain on which the representation is bad simply by labelling this point as the constant prediction.</p><p>Proposition 4 (No free lunch for learning representations for IDG, equiv. Proposition 1). Let be the 0-1 loss with prediction space ? = Y. Let Rep : P(X , Y) ? P(Z|X ) be any algorithm for choosing an encoder p Z | X from the data distribution p X,Y , C be any constant r.v. that t.v.i. Z, and p X,Y | ds be any desired source distribution such that</p><formula xml:id="formula_78">? there is a unique constant prediction ? C = arg min y?Y E p Y | ds [ (Y, y)],</formula><p>? and |X \ supp(p X | ds )| &gt; 1.</p><p>Let p Z ds | X := Rep(p X,Y | ds ) be the chosen source encoder. If there exists a target domain p X,Y | d g t such that</p><p>? (Non-trivial support) ? = supp(p X | d g t ) ? X \ supp(p X | ds ); ? (Satisfies Bayes image invariance) ? * d g t = Y, i.e., there is at least one example for every possible label;</p><p>? (Source encoder is useful) p Z ds | X performs better than a constant representation,</p><formula xml:id="formula_79">sup h?H * Z ds ,ds R d g t h [Y | Z ds ] &lt; sup h?H * C,ds R d g t h [Y | C] ,<label>(87)</label></formula><p>Then there exist multiple target domains d b t such that p Z ds | X underperforms a constant encoder,</p><formula xml:id="formula_80">sup h?H * Z ds ,ds R d b t h [Y | Z ds ] &gt; sup h?H * C,ds R d b t h [Y | C] .<label>(88)</label></formula><p>Proof. Let h * ? H * Z ds ,ds be any source Bayes predictor corresponding to our encoder. Partition Z according to whether h * predicts like the constant or not:</p><formula xml:id="formula_81">Z C := {z ? Z | h * (z) = ? C } Z =C := Z \ Z C .<label>(89)</label></formula><p>We know by assumption that d g t is s.t. sup</p><formula xml:id="formula_82">h?H * Z ds ,ds R d g t h [Y | Z ds ] &lt; sup h?H * C,ds R d g t h [Y | C] ,<label>(90)</label></formula><p>which is clearly only possible if</p><formula xml:id="formula_83">P Z ds | d g t (Z =C ) &gt; 0.<label>(91)</label></formula><p>In other words, there exists some input x =C ? X \ supp(p X | ds ) that will get represented outside of the constant region, i.e.,</p><formula xml:id="formula_84">P Z ds | x =C (Z =C ) &gt; 0.<label>(92)</label></formula><p>We will now construct the desired bad domain d b t by giving nearly all mass to this x =C , specifically, let p X | d b t (x =C ) = 1 ? ? for some 0 &lt; ? &lt; 1. We assign this example to the constant label, i.e.,</p><formula xml:id="formula_85">p Y | x =C ,d b t (? C ) = 1.</formula><p>The rest of the target domain mass ? is distributed as with the source domain, i.e., p X,Y | d b t (x, y) = ? ? p X,Y | ds (x, y) for all x, y ? supp(p X,Y | ds ). Importantly, the constructed domain d b t is valid. Indeed, the Bayes image is the same as the source's (Assumption 5), because we removed no prediction ? from the source's Bayes image (? &gt; 0). We added no new prediction ?, because f * (x =C ) = ? C ? Y which must already have been in ? * due to the validity of d g t . Now let us compute the desired risk for that "bad" domain and show that the desired encoder performs worse than a constant encoder.</p><formula xml:id="formula_86">sup h?H * Z ds ,ds R d b t h [Y | Z ds ] (93) = sup h?H * Z ds ,ds (1 ? ?) E p Z ds | x =C [1 ? 1[? C = h(Z ds )]] + ? R ds h [Y | Z ds ] (94) ? (1 ? ?)(1 ? P Z ds | x =C (Z C )) (95) = (1 ? ?)P Z ds | x =C (Z =C )<label>(96)</label></formula><p>In contrast, it is easy to show that sup h?H * C,ds R</p><formula xml:id="formula_87">d b t h [Y | C] ? ? because the constant predictor would be perfect for x =C . So any choice of 0 &lt; ? &lt; P Z ds | x =C (Z =C ) 1+P Z ds | x =C (Z =C )</formula><p>, would satisfy Eq. (88). We conclude the proof by noting that there are infinitely many such choices of ?, and any choice of those would result in a different valid bad domain d b t .</p><p>Note that representations can often be much worse than using a constant r.v. Specifically, if an encoder p Z | X maps an x outside of the source support then there exists an infinite number of target domains where that representation is the worst possible representation.</p><p>Proposition 5 (Worst representation). Let Rep, p Y,X | ds , p Z ds | X , be as in Prop. 4, and &gt; 0. If there exists an example x b ? X \ supp(p X | ds ) that is mapped outside of the source support, i.e., supp(p Z ds | x b ) ? supp(p Z | ds ) = ?, then there exist many target domains p X,Y | dt s.t. p Z ds | X is close to the worst possible loss, i.e.,</p><formula xml:id="formula_88">sup h?H * Z ds ,ds R dt h [Y | Z ds ] ? 1 ? .<label>(97)</label></formula><p>Proof. By assumption there exists an x b whose support is outside the source support. Then similarly to Prop. 4 we construct a bad target domain d t by giving nearly all mass to that example p X | dt (x b ) = 1 ? ? where ? &gt; 0 and assign with probability 1 to some label that is in the source Bayes image,</p><formula xml:id="formula_89">i.e., p Y | x b ,dt (? b ) = 1 for some ? b ? ? * ds .</formula><p>The rest of the target domain mass ? is distributed as in Prop. 4 to the source inputs. As in Prop. 4, such a target domain d t satisfies our assumptions. Now let us compute the risk for that d t and show that the desired encoder performs arbitrarily bad.</p><formula xml:id="formula_90">sup h?H * Z ds ,ds R dt h [Y | Z ds ] (98) = sup h?H * Z ds ,ds (1 ? ?) E p Z ds | x b [1 ? 1[? b = h(Z ds )]] + ? R ds h [Y | Z ds ] Eq. (94) (99) ? sup h?H * Z ds ,ds (1 ? ?) E p Z ds | x b [1 ? 1[? b = h(Z ds )]]<label>(100)</label></formula><p>= 1 ? ? (101) Eq. (101) uses the fact that H * Z ds ,ds is unconstrained outside of the source support and that by assumption supp(p Z ds | x b ) ? supp(p Z ds | ds ) = ?. To achieve the sup 1 ? ? it then suffices to predict an ? = ? b ? ?. We thus see that Eq. (97) holds for d t as long as 0 &lt; ? &lt; . We conclude the proof by noting that there is an infinite possible choices of ? each of which give rise to a bad target domain.</p><p>Published as a conference paper at ICLR 2022 B.4 AUGMENTATIONS Proposition 2 shows that the optimal representations for IDG can be learned with augmentations in a self-supervised fashion. Here, we provide formal definitions, assumptions, and proofs.</p><p>Definition 6 (Augmenter). An augmenter is a conditional distribution p A | X : A ? X ? [0, 1] from the input space X to an augmentation space A. For example, in CLIP X is the space of images and A is the space of text. In standard SSL, A is typically the same as X (e.g., both X and A are the space of images).</p><p>Definition 7 (Augmentation conditional set). Given an augmenter p A | X , define the augmentation conditional set as the set of conditionals of A given X:</p><formula xml:id="formula_91">P * (A | X) := p A | x | x ? X<label>(102)</label></formula><p>Similarly, we can define the augmentation conditional set for domain d:</p><formula xml:id="formula_92">P * d (A | X) := p A | x | x ? supp(p X | d )<label>(103)</label></formula><p>These sets are clearly countable. Note that the augmentation conditional set can be seen as a special case of the Bayes image (Def. 3) if we view the augmentation A as the label and consider the log-loss where the conditional distribution is the Bayes optimal predictor due to its strict properness <ref type="bibr" target="#b16">(Gneiting &amp; Raftery, 2007)</ref>.</p><p>Assumption 7 (Finite augmentation entropy). We consider the augmenter p A | X such that the entropy of the augmentation A is finite, i.e., H[A] &lt; ?.</p><p>Assumption 8 (Cardinalities). We assume that</p><formula xml:id="formula_93">|Z| ? |P * (A | X)| (104)</formula><p>This is a similar assumption as Assumption 3, which ensures the existence of optimal representations.</p><p>Assumption 9 (Domain-agnostic augmentation). We assume that the augmentation A is domainagnostic, i.e., the augmentation conditional set is invariant across domains,</p><formula xml:id="formula_94">P * d (A | X) = P * (A | X), ?d ? D<label>(105)</label></formula><p>This assumption is generalized from the constant Bayes image assumption (Assumption 5), which guarantees the existence of optimal representations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain-agnostic augmentations essentially ensures that each augmentation conditional p</head><formula xml:id="formula_95">A | x ? P * (A | X) is</formula><formula xml:id="formula_96">[x] ? supp(p X | d ) = ?, ?d ? D<label>(106)</label></formula><p>Not all augmentations are domain-agnostic. In particular, the standard image augmentations used by typical SSL models like SimCLR are not domain-agnostic, but the text-image augmentations of CLIP nearly are, as discussed in the main body (Sec. 4).</p><p>Assumption 10 (Bayes-preserving augmentation). We assume that the augmentation A is Bayespreserving, i.e., ?x, x ? X ,</p><formula xml:id="formula_97">p A | x = p A | x =? f * (x) = f * (x ).<label>(107)</label></formula><p>Under the notion of equivalence relation in Assumption 9, this means that for each equivalence class <ref type="bibr">[x]</ref>, all x ? [x] have the same Bayes prediction. Note that most augmentations used in practice like standard image augmentations are Bayes-preserving.</p><p>Next, we show that under the above assumptions, we can learn optimal representations by maximizing the mutual information I[A; Z] (in the case of log-loss ) under the support match constraint. We use log-loss simply because it is typically the loss used for training in practice. Note that the learned representations are optimal for any strict proper losses.</p><p>Proposition 6 (Learning optimal representations without labels, equiv. Proposition 2). Let p A | X be an augmenter. Under Assumptions 1 to 10, any encoder p Z | X such that</p><formula xml:id="formula_98">p Z | X ? arg max p Z | X I[A; Z] (108) s.t. ? d ? D, supp(p Z | d ) = supp(p Z )<label>(109)</label></formula><p>is optimal for idealized domain generalization.</p><p>Proof. The support match constraint Eq. (109) is equivalent to the support match constraint Eq. (68). Thus, Prop. 3 and Thm. 2 state that we only need to prove that maximizing the mutual information of A and Z under the support constraint implies that</p><formula xml:id="formula_99">R [Y | Z] = R [Y | X] .<label>(110)</label></formula><p>We will prove this by constructing an optimal predictor h * .</p><p>Since H[A] &lt; ? (Assumption 7) we have that arg max</p><formula xml:id="formula_100">p Z | X I[A; Z] = arg min p Z | X H[A | Z] .<label>(111)</label></formula><p>Note the fact that the conditional entropy is the Bayes risk under the log-loss <ref type="bibr" target="#b16">(Gneiting &amp; Raftery, 2007)</ref> </p><formula xml:id="formula_101">H[A | Z] = H[A | X] .<label>(112)</label></formula><p>By Assumption 7, we can invoke Lemma 2 with the fact that A ? X ? Z forms a Markove chain to show that for all (x, z) ? supp(p X,Z )</p><formula xml:id="formula_102">p A | z = p A | x ,<label>(113)</label></formula><p>as the conditional distributions are the Bayes optimal predictors due to strict properness of log-loss. Now, define the following equivalence relation on X ,</p><formula xml:id="formula_103">x ? x ?? p A | x = p A | x .<label>(114)</label></formula><p>Because the number of equivalence classes under ? is countable, there exists a maximal invariant M : X ? N from X to the natural numbers (for our definition of a maximal invariant see Definition 2, <ref type="bibr" target="#b13">Dubois et al., 2021)</ref>. By Assumption 10, f * is invariant on the equivalence classes [x] := {x ? X | x ? x} for all x ? X . Thus, there exists a function g : N ? A such that f * = g ? M (Lemma 5, <ref type="bibr" target="#b13">Dubois et al., 2021)</ref>. Given z ? supp(p Z ), we construct h * in the following way. Let x z ? supp(p X | z ) be any input point that could have led to this representation z and define h * (z) = g(M (x z )).</p><p>By Eq. <ref type="formula" target="#formula_0">(113)</ref> we are guaranteed that all x ? supp(p X | z ) share the same value for f * since they are in the same equivalence class. Thus, by the definition of M we have that</p><formula xml:id="formula_105">M (x Z ) = M (X) for (X, Z) ? p X,Z .<label>(116)</label></formula><p>Therefore,</p><formula xml:id="formula_106">R h * [Y | Z] = E p Y,Z [ (Y, h * (Z)] (117) = E p Y | X p X,Z [ (Y, h * (Z)] (118) = E p Y | X p X,Z [ (Y, g(M (x Z )))] Eq. (115) (119) = E p Y | X p X,Z [ (Y, g(M (X)))] Eq. (116) (120) = E p Y | X p X,Z [ (Y, f * (X))] = R [Y | X] .<label>(121)</label></formula><p>C PRACTICAL OBJECTIVES Proposition 6 provides an objective to obtain the desired optimal representations, compared to Thm. 2 it is more practical in that it does not require direct access to the labels and in that it can use augmentations under appropriate assumptions. There are nevertheless multiple remaining issues for deriving objectives that can be trained with in practice. Specifically, (i) the support constraint is hard to satisfy in practice; (ii) mutual information I[A; Z] is hard to estimate from samples <ref type="bibr" target="#b38">(Poole et al., 2019)</ref>; (iii) the objective is constrained which is harder to optimize. We will now show different objectives and variational bounds of them that do not suffer from these issues, and could still recover the desired encoders in their optima. In contrast to the proofs of main theoretical results (previous section), here the derivations will be less formal.</p><p>As we have seen in Proposition 6, the optimal representation achieves I[A; Z] = I[A; X]. In the following, we will rewrite the objective as the constrained optimization:</p><formula xml:id="formula_107">p Z | X ? arg min p Z | X B[Z, X, Y, D]<label>(122)</label></formula><formula xml:id="formula_108">s.t. I[A; Z] = I[A; X]<label>(123)</label></formula><p>where we introduce the domain bottleneck B[Z, X, Y, D] as the objective for enforcing support match (which we denote as B <ref type="bibr">[Z, D]</ref> in the main body for simplicity). The requirement on the domain bottleneck objective is that minimizing Eq. (122) under Eq. <ref type="formula" target="#formula_0">(123)</ref> implies that the support match constraint holds (and can be achieved by some encoder), which leads to optimal representations for IDG. Different domain bottlenecks will be derived later this section. We can then use Lagrangian relaxation to get the following unconstrained objectives.</p><p>arg min</p><formula xml:id="formula_109">p Z | X ? I[A; Z] + ? B[Z, X, Y, D]<label>(124)</label></formula><p>The first term can be easily optimized using variational bounds on MI. Throughout the paper, we will use a contrastive variational lower bound which is based on <ref type="bibr">InfoNCE (Oord et al., 2018)</ref>. Namely, let X be the input sample and A be the 'positive' augmentation sampled from p A | X . We then obtain n 'negative' augmentations A ? i n i=1 by first independently sampling X ? i n i=1 from the marginal p X and then sampling A ? i from p A | X ? i . It is easy to see that the negatives A ? i follow the marginal p A . We construct A := A, A ? 1 , . . . , A ? n . Let Z be the representation of X by passing it through the encoder p ? := p Z | X parameterized by ? and s ? the critic function parametrized by ? used to score which A ? A is the positive augmentation. Then we have the following variational lower bound <ref type="bibr" target="#b38">(Poole et al., 2019)</ref>:  </p><formula xml:id="formula_110">I[A; Z] ? log(n + 1) + E p A,X,Z log exp s ? (A, Z) A ?A exp s ? (A , Z)<label>(125)</label></formula><formula xml:id="formula_111">Z | x = p Z | x ?? M (x) = M (x ).</formula><p>With the assumption of domain-agnostic augmentations (Assumption 9), we have that the set of maximal invariant</p><formula xml:id="formula_112">{M (x) | x ? supp(p X | d )} is invariant across domains. Then we directly have supp(p Z | d ) = ? x?supp(p X | d ) supp(p Z | x ) = ? x?supp(p X ) supp(p Z | x ) = supp(p Z ),</formula><p>where we use the fact that x within the same equivalence class has the the same p Z | x .</p><p>How Essentially, we can use any variational upper bound of mutual information. We consider the one used by Variational Information Bottelenck (Alemi et al., 2016), i.e.,</p><formula xml:id="formula_113">I[Z; X] = E p X,Z log p ? (Z | X) p Z (Z) (126) = E p X,Z log p ? (Z | X) q ? (Z) ? D KL [p Z (Z) q ? (Z)]<label>(127)</label></formula><formula xml:id="formula_114">? E p X,Z log p ? (Z | X) q ? (Z) (128) = E p X [D KL [p ? (Z | X) q ? (Z)]]<label>(129)</label></formula><p>where a variational distribution q ? is used to approximate p Z and is jointly optimized with p ? to minimize the bound. The approximation gap of the bound is D KL [p Z (Z) q ? (Z)]. Ignoring the constant, the final loss becomes</p><formula xml:id="formula_115">L MI (?, ?, ?) := E p X,A,Z ? log exp s ? (A, Z) A ?A exp s ? (A , Z) + ? D KL [p ? (Z | X) q ? (Z)]<label>(130)</label></formula><p>which recovers the optimal encoder in the case of unconstrained variational families for p ? , q ? , s ? , infinite samples n ? ?, and any ? &gt; 1 <ref type="bibr" target="#b13">(Dubois et al., 2021)</ref>.</p><formula xml:id="formula_116">C.2 ENTROPY BOTTLENECK B[Z, X, Y, D] = H[Z]</formula><p>The entropy (Ent) bottleneck introduced in the main body is a special case of the MI bottleneck, where the encoder is a deterministic mapping, i.e., p ? (Z | x) is a dirac delta function for all x ? X and we denote by e ? (x) the deterministic encoder s.t. p ? (e ? (x) | x) = 1. </p><formula xml:id="formula_117">(x) = e ? (x ) ?? M (x) = M (x )</formula><p>, which also satisfies the support match constraint as discussed before.</p><p>How Using the same derivation as the MI bottleneck, we can derive the variational upper bound on entropy</p><formula xml:id="formula_118">H[Z] ? E p Z [? log q ? (Z)]<label>(131)</label></formula><p>which is the standard variational bound used in neural compression <ref type="bibr" target="#b2">(Ball? et al., 2016;</ref><ref type="bibr" target="#b51">Theis et al., 2017)</ref>. Putting all together, we have</p><formula xml:id="formula_119">L Ent (?, ?, ?) := E p X,A,Z ? log exp s ? (A, Z) A ?A exp s ? (A , Z) ? ? log q ? (Z)<label>(132)</label></formula><p>which also recovers the optimal encoder with unconstrained variational families, infinite samples, and ? &gt; 1 as with the MI bottleneck. The detialed algorithm is provided in Algorithm 2. Note that the discreteness of Z could lead to difficulty of gradient-based optimization, and we follow <ref type="bibr" target="#b2">Ball? et al. (2016)</ref> to add uniform noise to Z as a differentiable substitute for rounding during training. In our experiments, we will mostly use the Ent bottleneck instead of the MI bottleneck to avoid introducing stochastic encoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Ent objective</head><p>Require: e ? , s ? , q ? , X, n 1:</p><formula xml:id="formula_120">Z ? e ? (X) 2: A ? sample(p A | X ) 3: {(X ? i , A ? i )} n i=1 i.i.d. ? ? ? sample(p X,A ) 4: A ? {A} ?{A ? i } n i=1 5: L aug ? ? log exp s ? (A,Z) A ?A exp s ? (A ,Z) ? I[A; Z] 6: L supp ? ? log q ? (Z) H[Z] 7: return L Ent = L aug + ?L supp C.3 CONTRASTIVE ADVERSARIAL DOMAIN BOTTLENECK B[Z, X, Y, D] = I[Z; D]</formula><p>The previous two bottlenecks require removing the information of Z (about X) as much as possible, which seems to be unnecessary since our ultimate goal is to match the support of Z across domains. Now we introduce a bottleneck B[Z, X, Y, D] = I[Z; D] which we only seek to remove the information of Z about the domain D. This is very related to the work on invariant representation learning for domain generalization/adaptation (e.g., <ref type="bibr" target="#b15">Ganin et al., 2016;</ref><ref type="bibr" target="#b30">Li et al., 2018a)</ref>. We derive a new variational bound called the contrastive adversarial domain (CAD) bottleneck that is more stable to train and leads to better empirical performance. For simplicity we consider the deterministic encoder e ? (x) as with the main body. How The typical way of minimizing I[Z; D] is to derive the variational bound as</p><formula xml:id="formula_121">I[Z; D] = H[D] ? H[D | Z] (133) = (const) ? E p D,Z ? log p D | Z (D | Z) (134) ? (const) ? E p D,Z [? log q ? (D | Z)]<label>(135)</label></formula><p>where a variational distribution (or domain classifier) q ? is used to approximate p D | Z and jointly trained to maximize the bound. This recovers the domain-adversarial training method as introduced in <ref type="bibr" target="#b15">Ganin et al. (2016)</ref>. However, this has two potential issues: 1) it gives a lower bound instead of the desired upper bound on I[Z; D]; 2) it requires adversarial training which is not stable in practice <ref type="bibr" target="#b18">(Goodfellow, 2016;</ref><ref type="bibr" target="#b26">Kodali et al., 2017)</ref>.</p><p>We propose the contrastive adversarial domain (CAD) bottleneck, which is based on the above explicit version but uses a variational distribution q ? (D | Z) that is tied with other parts of the model, thus no need to learn a domain classifier. Suppose we have access to a set of inputs X, we first introduce a contrastive variational distribution q ?,X (X | Z) of p X | Z as</p><formula xml:id="formula_122">q ?,X (X | Z) := exp s ? (X, Z) X ?X exp s ? (X , Z)<label>(136)</label></formula><p>where s ? (X, Z) := e ? (X) T Z is tied with the encoder e ? . Note that q ?,X has support over X, and equals p X | Z when s ? (X, Z) ? log p X,Z (X, Z) and X recovers X . In practice, we use a variety of crude approximations. Our first crude approximation is that we use the minibatch of samples, i.e., the independently sampled X ? i n i=1 as X. Now, since p D | Z can be rewritten as E p X | Z p D | X using the fact that D ? X ? Z forms a Markov chain, we obtain the following variational distribution:</p><formula xml:id="formula_123">q ?,X (D | Z) = E q ?,X p D | X (D | X)<label>(137)</label></formula><p>which recovers p D | Z when q ?,X = p X | Z . Note that p D | X is still not available. For our second crude approximation, we use a count estimatep D,X . In particular, we obtain a collection D by taking each X ? X and independently sampling D from p D | X to get D :</p><formula xml:id="formula_124">= {D ? i } n i=1 . In other words, {(D ? i , X ? i )} n i=1</formula><p>are all i.i.d. sampled from p D,X . Then we use a count estimat?</p><formula xml:id="formula_125">p D,X (d | x) = n i=1 I (X ? i = x, D ? i = d) n i=1 I (X ? i = x)<label>(138)</label></formula><p>which is an accurate estimate with infinite samples. This leads to our final variational distribution:</p><formula xml:id="formula_126">q ?,X,D (D | Z) = X ?X q ?,X (X | Z)p D,X (D | X )<label>(139)</label></formula><p>Putting all together we get that the loss:</p><formula xml:id="formula_127">L CAD (?, ?) := E p D,X,A.Z ? log exp s ? (A, Z) A ?A exp s ? (A , Z) + ? log X ?X q ?,X (X | Z)p D,X (D | X ) .</formula><p>(140) In practice,p D,X (D | X) is typically a dirac delta function since it is rare to have the same samples in a minibatch. Thus, in Eq. (139) we only need to sum q ?,X (X | Z) over those associated with the same domain label D as X, i.e.,</p><formula xml:id="formula_128">X D := {X ? i | D ? i = D, i ? [n]} where [n] := {1, .</formula><p>. . , n}. This leads to the simplified loss:</p><formula xml:id="formula_129">L CAD (?, ?) := E p D,X,A,Z ? log exp s ? (A, Z) A ?A exp s ? (A , Z) + ? log X ?X D q ?,X (X | Z) .<label>(141)</label></formula><p>In practice, we find that the second term that minimizes the log probability leads to numerical instability. Intuitively, this could be seen by the exploding gradient of the function log(p) when p ? 0. We thus replace it with ? log(1 ? p) which has the same optima. I.e. in practice we maximize the log of the probablity summed over X ?D := X \ X D . This reduces Eq. (141) to Eq. <ref type="formula" target="#formula_14">(7)</ref> described in the main body with a detailed algorithm in Algorithm 1. Note that it is easy to generalize Algorithm 1 to parallel computation within a batch of samples. Indeed, for each sample in the batch, we can view all other samples in the batch as negatives and compute the loss efficiently in parallel.</p><formula xml:id="formula_130">C.4 CONDITIONAL CAD B[Z, X, Y, D] = I[Z; D | Y ]</formula><p>The analysis of the CAD bottleneck also implies that we can minimize the conditional mutual information I[Z; D | M (X)] if we have access to M (X). However, since M (X) is typically not available in practice, we consider the special case where M (X) = Y . In particular, this is the case where the labels are available and the supervised augmentations are used (see <ref type="figure">Fig. 2b</ref>). This reduces the bottleneck to B[Z, X, Y, D] = I[Z; D | Y ] which is related to the conditional version of the domain-adversarial neural network <ref type="bibr" target="#b31">(Li et al., 2018b)</ref>. In practice, minimizing I[Z; D | Y ] could be easier for optimization than I[Z; D], as it does not require to remove the information that D has about Y . In the following, we derive the conditional CAD (C 2 AD) bottleneck using a similar idea as CAD.</p><p>How In this case, we want to minimize</p><formula xml:id="formula_131">I[Z; D | Y ] = H[D | Y ] ? H[D | Z, Y ] (142) = (const) ? H[D | Z, Y ] (143) ? (const) ? E p D,Z,Y [? log q(D | Z, Y )]<label>(144)</label></formula><p>where q(D | Z, Y ) is a variational distribution of p D | Z,Y . Similar to the unconditional case, we also aim to use a non-parametric approximation that is tied with other parts of the model, and we obtain it using the fact p D | Z,Y = E p X | Z,Y p D | X . Specifically, let Y be the label of input X sampled from p Y | X and Y := {Y ? 1 , . . . , Y ? n } be the collection of labels obtained by independently sampling the label from p Y | X for each X ? X. We collect samples associated with the label Y , i.e.,</p><formula xml:id="formula_132">X Y := {X ? i | Y ? i = Y, i ? [n]</formula><p>} and obtain a variational distribution of p X | Z,Y :</p><formula xml:id="formula_133">q ?,X,Y (X | Z, Y ) := exp s ? (X, Z) X ?X Y exp s ? (X , Z)<label>(145)</label></formula><p>where we use the same critic s ? (X, Z) := e ? (X) T Z that is tied with the encoder e ? as before, but only take softmax over those samples with the same label Y . For the term p D | X , we use the same count estimatep D,X in Eq. (138). Then we obtain the variational distribution of p D | Z,Y :</p><formula xml:id="formula_134">q ?,X,D,Y (D | Z, Y ) = X ?X Y q ?,X,Y (X | Z, Y )p D,X (D | X )<label>(146)</label></formula><p>Putting all together we get that the final loss:</p><formula xml:id="formula_135">L C 2 AD (?, ?) := E p D,X,A,Y,Z ? log exp s ? (A, Z) A ?A exp s ? (A , Z) + ? log X ?X Y q ?,X,Y (X | Z, Y )p D,X (D | X ) .</formula><p>(147) Again, since in practicep D,X (D | X) is typically a dirac delta function, the summation in Eq. (146) can be done only over those associated with the same label Y and the same domain label D as X,</p><formula xml:id="formula_136">i.e., X Y,D := {X ? i | Y ? i = Y, D ? i = D, i ? [n]}.</formula><p>Similarly, instead of minimizing the log of the probability summed over X Y,D , we maximize the log of the probability summed over X Y,?D :=</p><formula xml:id="formula_137">X Y \ X Y,D = {X ? i | Y ? i = Y, D ? i = D, i ? [n]}.</formula><p>Finally we obtaine the simplified loss:</p><formula xml:id="formula_138">L C 2 AD (?, ?) := E p D,X,A,Y,Z ? ? ? log exp s ? (A, Z) A ?A exp s ? (A , Z) ? ? log ? ? X ?X Y,?D q ?,X,Y (X | Z, Y ) ? ? ? ? .</formula><p>(148) A detailed algorithm is in Algorithm 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 conditional CAD (C 2 AD) objective</head><p>Require: e?, s?, D, X, Y, n 1:</p><formula xml:id="formula_139">Z ? e?(X) 2: A ? sample(p A | X ) 3: (D ? i , X ? i , A ? i , Y ? i ) n i=1 i.i.d. ? ? ? sample(pD,X,A,Y ) 4: X, A ? X ? i n i=1 ,{A} ? A ? i n i=1 5: XY ? X ? i | Y ? i = Y, i ? [n] 6: XY,?D ? X ? i | Y ? i = Y, D ? i = D, i ? [n] 7: Laug ? ? log exp s ? (A,Z) A ?A exp s ? (A ,Z) ? I[A; Z] 8: Lsupp ? ? log X ?X Y,?D exp e?(X ) T Z X ?X Y exp e?(X ) T Z I[Z; D | Y ] 9: return L C 2 AD = Laug + ?Lsupp</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D EXTENDED RELATED WORK</head><p>Provably optimal representations. Many previous work have theoretically studied advantages of representations in various two-stage settings (representation learning followed by standard training of predictors) by bounding downstream performance (e.g., <ref type="bibr" target="#b6">Ben-David et al., 2007;</ref><ref type="bibr" target="#b44">Shamir et al., 2010;</ref><ref type="bibr" target="#b42">Saunshi et al., 2019)</ref>. As learning theoretical bounds can be loose, it is hard to know whether they give the right insights into the problem. Our work instead proves the properties of optimal representations, which ensure best downstream performance. Those properties need to be approximated but give the right insights into what to aim for. This perspective and our proofs were inspired by <ref type="bibr" target="#b12">Dubois et al. (2020)</ref> who gives sufficient conditions for optimal representations in supervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E EXPERIMENTAL DETAILS E.1 SCIENTIFIC</head><p>In both the scientific setting and the following bridge setting, we consider rather unrealistic setups for verifying our theory where we have access to labels from all domains. We can choose to directly minimize the risk R [Y | Z] with the cross-entropy loss (denoted as CE henceafter), or minimize H[A | Z] (i.e., maximize I[A; Z]) with supervised augmentations as in <ref type="figure">Fig. 2b</ref> detailed below.</p><p>Implementation of supervised augmentations When using supervised augmentations, for each sample we obtain its augmentations from within its label class across all domains. A constrastive loss with such augmentations will essentially reduce to the supervised contrast loss (SupCon, <ref type="bibr" target="#b24">Khosla et al., 2020)</ref>. In particular, for a single sample in a batch, all samples in the batch with the same labels can be used as the positives (could come from the same domain or different domains) and others as the negatives. In <ref type="bibr" target="#b24">Khosla et al. (2020)</ref>, two variants of SupCon loss were introduced for solving the issue of multi-positives depending on whether the summation over multi-positives was located inside (SupCon-In, Eq. (3) in <ref type="bibr" target="#b24">Khosla et al. (2020)</ref>) or outside (SupCon-Out, Eq. (2) in <ref type="bibr" target="#b24">Khosla et al. (2020)</ref>) the log. Though <ref type="bibr" target="#b24">Khosla et al. (2020)</ref> chose SupCon-Out because it worked better than SupCon-In, we hypothesized that this is because SupCon-Out has an implicit bottleneck effect. Intuitively, SupCon-Out upper bounds SupCon-In and achieves its optima only if the logits with positive samples are all the same by Jensen's inequality, which may encourage positive samples from different domains to get clustered. Since this might confound with the effect of our bottlenecks, we chose to use SupCon-In though it performed slightly worse in out initial experiments. For the implementation of SupCon, we followed <ref type="bibr" target="#b24">Khosla et al. (2020)</ref> except that no projection was used. Specifically, the temperature was set to 0.1, and normalization was applied when computing the logits.</p><p>In the scientific setting, we tried to simulate our theory to the greatest extent. In particular, we had two special considerations as detailed below:</p><p>Eliminating empirical generalization As our theory focuses on the idealized domain generalization that assumes access to population distribution, we considered the setup where the empirical generalization was eliminated. Specifically, we treated the dataset as the population distribution and used the same dataset for training the encoder and training/evaluating the predictor. The ResNet-18 encoder was trained to 300 epochs without any regularization, using the Adam optimizer (Kingma &amp; Ba, 2014) with a learning rate of 5e-5, a batch size of 192 (48 for each domain), and a cosine learning rate decay schedule.</p><p>Worst-case approximation To approximate the worst-case source predictor, we included the target data with randomly assigned wrong labels to the training set for training the source predictor. The target data samples were down-weighted with a sample weight that maximizes the target risk while keeping the source risk close to optima (which is 0). We selected the sample weight by sweeping over [10 ?10 , 1] with a logarithmic scale using CE-Base and SupCon-Base, as shown in <ref type="figure" target="#fig_6">Fig. 4</ref>. As the sample weight increases, the target log likelihood (neg. risk) first decreases and then increases. We hypothesized that the increasing trend was due to that the source performance was already not optimal (though not visible from the figure), thus we selected the weight close to the turning point and 10 ?5 seemed to be reasonable for both CE-Base and SupCon-Base. Although we did not adaptively select the sample weight for each setup due to the computational cost, the pre-specified sample turned out to be reasonable for all other losses and different ? combinations. Furthermore, we also removed regularization when training the linear classifier and initialized the linear weight i.i.d. from N (0, 1).</p><p>Next, we provide other experimental details for reproducibility:</p><p>Implementation of standard augmentations We followed SimCLR  for implementing standard image augmentations. For a fair comparison between the cases when using standard augmentations (SimCLR) and supervised augmentations (SupCon), we kept the total batch size the same and also used the same configurations for computing the SupCon loss, i.e., temperature set to 0.1, no projection, and normalization applied. <ref type="figure" target="#fig_2">Fig. 3c</ref> In <ref type="figure" target="#fig_2">Fig. 3c</ref>, we considered different choices of augmentations. The 'Standard' augmentation implementation is described above (Appx. E.1). The 'Supervised' augmentation was essentially implemented using the SupCon loss as described in Appx. E.1. For other augmentations considered, we implemented them by dropout inter-domain supervised augmentations in SupCon. Specifically, for each sample in the batch, we randomly masked the samples from different domains (i.e., both inter-domain positives and negatives) i.i.d. with the specified dropout probability, while samples within the same domain were always kept. 'IntraDom' and 'ApproxDA' correspond to dropout probability 1 and 0.9, respectively. 'SingleDom' were implemented by dropout all interdomain samples with probability 1 except for a fixed domain (the 'A' domain of PACS in our case).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details of</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 BRIDGE</head><p>In the bridge setting (see Appx. F.2), we aimed to bridge the gap between our theoretical setup to the practical setup. The main differences from the scientific setups are that the empirical generalization gap is considered and the average-case source predictor is used, as detailed below:</p><p>Incorporating empirical generalization In practice, empirical-generalization gap should also be considered besides the source-target generalization gap. Thus, we randomly split the PACS dataset to 80% training and 20% validation splits for each domain. The training splits were used to train both the encoder and the source predictor, and the validation splits were used for encoder and source predictor selection as well as evaluation on target domains. We used the ResNet-50 model as the encoder and initialized it from ImageNet pretrained model. The encoder was trained to a maximum of 50 epochs with a 1e-5 weight decay, using the Adam optimizer (Kingma &amp; Ba, 2014) with a learning rate of 5e-5, a batch size of 112 (28 for each domain), and a cosine learning rate decay schedule.</p><p>Using average-case source predictor Instead of approximating the worst-case source predictor in the scientific setting, we considered the average-case 3 source predictor which is closer to the common practice. Specifically, we freezed the encoder and trained a SVM classifier with L2 regularization on did that in our end-to-end training setup since we wanted it to be compeletely comparable to baselines on DomainBed (which did not do refitting).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Selection of ?</head><p>In our experiments, we treated ? as a special hyperparamter. For each model, we used the same ? selected on PACS on all datasets except DomainNet, because our bottleneck is fairly robust to the choice of ?. For the large-scale DomainNet dataset, we selected its ? individually. The ? values chosen for each model were:</p><p>? CLIP S: 1 on DomainNet and 1e-2 on other datasets ? CLIP L: 1e-1 on DomainNet and 1e-2 on other datasets ? DINO: 1e-1 on all datasets</p><p>? End-to-end ResNet-50: 1e-5 on all datasets</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.4 LAION</head><p>Model We used the CLIP L model (i.e., CLIP ViT-B/32) with an additional network on top for finetuning. The additional network were two blocks of 2-layer MLP, each with hidden size 2048, pre-activation batch normalization, residual connection, and dropout probability 0.1. Note that the original CLIP L model was frozen and only the additional network was trained.</p><p>Dataset We used the LAION-400M dataset which contained 400 million image-text pairs for training. Though the dataset might not be as clean as the original CLIP training data (as evidenced by our experimental results), it was the largest publicly available image-text-pair dataset that we could get access to. As we froze the CLIP L model and only did finetuning, we used the 1TB preprocessed embeddings provided by LAION-400M 4 . No further preprocessing was applied.</p><p>Training We used the image-text contrastive loss as introduced in <ref type="bibr" target="#b39">Radford et al. (2021)</ref> for training model. The temperature was learnable which was initialized as 0.07 and clipped with a minimum 0.01. The model was trained for 1 epoch using the Adam optimizer with a batch size of 16384 and a cosine learning rate decay schedule. The learning rate was tuned over the set {3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2} and the ? value for the Ent bottleneck was tuned over {1e-3, 1e-2, 1e-1, 1, 1e1}.</p><p>Evaluation For the evaluation on the ImageNet-related datasets, we followed a similar procedure in <ref type="bibr" target="#b39">Radford et al. (2021)</ref>, where a linear classifier was fitted on ImageNet using the model representations and evaluated on 7 natural distribution shift datasets. In particular, we fitted a logistic regression classifier with 1e-5 L2 regularization on ImageNet training set which was trained with a batch size 512, the Adam optimizer with a learning rate 3e-4 and early stopping. Note that this was different from <ref type="bibr" target="#b39">Radford et al. (2021)</ref>, where a logistic regression classifier was fitted using full-batch data with decent hyperparameter tuning, due to our computational budget. For evaluation on natural distribution shift datasets, we followed <ref type="bibr" target="#b50">Taori et al. (2020)</ref> and used their released testbed 5 . The evaluation datasets and their abbreviations used in <ref type="table" target="#tab_5">Table 2</ref>   <ref type="figure">Figure 5</ref>: The worst-case DG performance of Ent bottleneck is more sensitive to ? than CAD What's the effect of ? for different objectives on the worst-case DG performance? In <ref type="figure">Fig. 5</ref>, the worst-case target log likelihood versus ? values for different objectives is shown. We found that Ent is much more sensitive to the choice of ? than CAD, which was part of the reason why we used the latter in most of our experiments. Note that for SupCon-Ent with small ? values, it was worse than SupCon-Base because of the discretization introduced by the Ent bottleneck, which we verified by observing that setting ? = 0 lead to similar results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 BRIDGE</head><p>The scientific setup is closer to our theory than what we do in practice in that worst-case predictor was considered and empirical generalization gap was ignored. Here we bridged these gaps with a more practical setup. In particular, we split the PACS dataset to training and validation splits for each domain and considered the setting: the representor trains the encoder on all-domain training splits with a validation loss selection; the learner trains the SVM predictor (average-case) on the source training split which is selected over the source validation split, and evaluates on the validation splits of other target domains. The target validation accuracy averaged over all (source, target) setups was reported. For simplicity, we will use CE to denote the objective with the cross-entropy loss that uses labels to minimize R [Y | Z], and SupCon for the contrastive loss that uses supervised augmentations to minimize H[A | Z]. We will use CAD in following experiments unless otherwise specified (chosen with initial experiments). Details in Appx. E.2. <ref type="table">Table 3</ref>: We repeated most empirical analysis (in the scientific setting) in the more practical bridge setting and observed similar results.</p><p>Does domain bottleneck improve the average-case DG performance? Though our theory focuses on the worst-case DG, we empirically showed that adding bottlenecks to enforce support match can also improve the average-case DG performance by comparing CE-Base and CE-CAD in <ref type="table">Table 3</ref>.</p><p>What if the representor only has access to source domains? Similar to what we did in the scientific setting, we considered the setup where one single domain is specified as the target domain and excluded from the training set of the representor and used for evaluation with source predictors trained on other domains. This is denoted as CE+CAD (partial domains) in <ref type="table">Table 3</ref>, which is much worse then CE-CAD. This shows the necessity of getting access to target domain information for DG.</p><p>What if the representor only has access to domain-agnostic augmentations? In <ref type="table">Table 3</ref>, we also compared SupCon-CAD which used supervised augmentations through the labels with CE-CAD and they achieved the same performance. This shows that the representor can still learn good representations without labels but only domain-agnostic augmentations in practice.</p><p>Can we use standard augmentations? In <ref type="figure">Fig. 2</ref>, we point out that standard augmentations are not domain-agnostic and thus not suitable for SSL with our objectives. We empirically showed this by using augmentations of SimCLR (see Appx. E.1 for details) with our objectives (SimCLR-CAD). In <ref type="table">Table 3</ref>, we indeed observed that using standard augmentations performed much worse than using desired augmentations (SupCon-CAD).</p><p>How do augmentations matter? Besides investigating the 'Supervised' augmentations (SupCon-CAD) and 'Standard' augmentations (SimCLR-CAD) above, we also compared other three augmentations as in the scientific section. Specifically, we considered the 'SingleDom', 'IntraDom', and 'ApproxDA' augmentations. As shown in <ref type="table">Table 3</ref>, SupCon-CAD (SingleDom) and (ApproxDA) maintained the DG performance but SupCon-CAD (IntraDom) was slightly worse (0.5 accuracy drop). We assumed the small gap was due to the specific dataset that we used (PACS). We did the same analysis on VLCS, and SupCon-CAD with 'Supervised', 'SingleDom', and 'IntraDom' augmentations gave 84.7 ? 0.4, 83.2 ? 0.3, and 77.5 ? 2.3, respectively. This shows the importance of using domain-agnostic augmentations in practice.</p><p>Do standard augmentations affect source performance? Previously, we showed that using standard augmentations hurt the DG performance measured by the average target accuracy. It is natural to ask whether using standard augmentations also hurt the source performance since we should also be interested in the 'effective robustness' <ref type="bibr" target="#b50">(Taori et al., 2020)</ref>. Thus we also reported the average source accuracy of SupCon-CAD and SimCLR-CAD which were 96.9 ? 0.2 and 90.1 ? 0.2, respectively. The source performance using standard augmentations was indeed worse, but if we consider the source-target gap which was 0.2 for SupCon-CAD and 28.4 for SimCLR-CAD, which still verified that the non-domain-agnostic standard augmentations were harder to force support match. To be even more convincing, we did the same analysis on VLCS, and the average source accuracy of SupCon-CAD and SimCLR-CAD were 86.6 ? 0.1 and 84.6 ? 0.5 which were fairly close, but the average target accuracy were 84.7 ? 0.4 and 57.5 ? 1.7, respectively. <ref type="table" target="#tab_3">Table 1</ref> We included the full result of <ref type="table" target="#tab_3">Table 1</ref> with all baselines on DomainBed as in <ref type="table">Table 4</ref>. We considered most representative baselines from DomainBed, most of which considered learning invariant representations or optimal classifiers across domains. Specifically, we included IRM <ref type="bibr" target="#b1">(Arjovsky et al., 2019)</ref>, GroupDRO <ref type="bibr" target="#b41">(Sagawa et al., 2019</ref><ref type="bibr">), Mixup (Yan et al., 2020</ref>, CORAL <ref type="bibr" target="#b48">(Sun &amp; Saenko, 2016)</ref>, MMD <ref type="bibr" target="#b30">(Li et al., 2018a)</ref>, DANN <ref type="bibr" target="#b15">(Ganin et al., 2016)</ref>, CDANN <ref type="bibr" target="#b31">(Li et al., 2018b)</ref>, and VREx . We also included the result pretrained CLIP S model with a zero-shot classifier using text representations (CLIP S Zero Shot), which demonstrated better DG performance than CLIP S with linear probe. But we observed that it was outperformed by our CLIP S + CAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3 DOMAINBED</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Full result of</head><p>What is the impact of CLIP pretraining? To ensure that our gains are not only due to a novel CAD bottleneck, but the synergy between enforcing support constraint and using desired SSL models, we investigated CAD using the standard DomainBed protocol denoted as CAD in the table. It shows that CAD on its own performs similarly with DomainBed baselines (see <ref type="table">Table 4</ref> for a full comparison). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>A A B 6 n i c d V C 7 S g N B F J 2 N r x h f U U t B B o O Q a p l d s p o U Y s D G M k H z k G Q J s 5 N J M m T 2 w c y s E J a U l j Y W i t h a W + c 7 7 P w G f 8 J J o q C i B y 4 c z r m X e + 7 1 I s 6 k Q u j N S C 0 s L i 2 v p F c z a + s b m 1 v Z 7 Z 2 6 D G N B a I 2 E P B R N D 0 v K W U B r i i l O m 5 G g 2 P c 4 b X j D s 6 n f u K Z C s j C 4 V K O I u j 7 u B 6 z H C F Z a u r g 6 Q Z 1 s D p n I L j o F G y L T d l D J K m n i I K t 0 V I C W i W b I n b 5 M q u 8 3 + 5 N K J / v a 7 o Y k 9 m m g C M d S t i w U K T f B Q j H C 6 T j T j i W N M B n i P m 1 p G m C f S j e Z R R 3 D Q 6 1 0 Y S 8 U u g I F Z + r 3 i Q T 7 U o 5 8 T 3 f 6 W A 3 k b 2 8 q / u W 1 Y t U r u g k L o l j R g M w X 9 W I O V Q i n d 8 M u E 5 Q o P t I E E 8 F 0 V k g G W G C i 9 H c y + g l f l 8 L / S d 0 2 r Y L p V F G u n A d z p M E e O A B 5 Y I F j U A b n o A J q g I A + u A X 3 4 M H g x p 3 x a D z N W 1 P G 5 8 w u + A H j + Q O 7 h p H M &lt; / l a t e x i t &gt; Y = 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 s d K 5 e q g t 6 v t u N Y D o k 1 3 a x A j w 7 g = " &gt; A A A B 6 n i c d V C 7 S g N B F J 3 1 G e M r a i n I Y B B S L b N x F 0 0 h B m w s E z Q P S Z Y w O 5 l N h s w + m J k V w p L S 0 s Z C E V t r 6 3 y H n d / g T z h J F F T 0 w I X D O f d y z 7 1 e z J l U C L 0 Z c / M L i 0 v L m Z X s 6 t r 6 x m Z u a 7 s u o 0 Q Q W i M R j 0 T T w 5 J y F t K a Y o r T Z i w o D j x O G 9 7 g b O I 3 r q m Q L A o v 1 T C m b o B 7 I f M Z w U p L F 1 c n V i e X R 6 a D r J J T g s g s O q h k 2 5 o g C 6 F D G 1 o m m i J / + j K u v t / s j S u d 3 G u 7 G 5 E k o K E i H E v Z s l C s 3 B Q L x Q i n o 2 w 7 k T T G Z I B 7 t K V p i A M q 3 X Q a d Q Q P t N K F f i R 0 h Q p O 1 e 8 T K Q 6 k H A a e 7 g y w 6 s v f 3 k T 8 y 2 s l y j 9 2 U x b G i a I h m S 3 y E w 5 V B C d 3 w y 4 T l C g + 1 A Q T w X R W S P p Y Y K L 0 d 7 L 6 C V + X w v 9 J v W h a t u l U U b 5 c A D N k w C 7 Y B w V g g S N Q B u e g A m q A g B 6 4 B f f g w e D G n f F o P M 1 a 5 4 z P m R 3 w A 8 b z B 6 3 2 k c I = &lt; / l a t e x i t &gt; source target p Z|dt &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N z J / 0 O J q T f P q J L i M 8 d 9 E W M J J F F U = " &gt; A A A B 8 H i c b V D J S g N B E K 1 x j X G L y 8 3 L Y B A 8 S J g R R Y 8 B L x 4 j m E W T Y e j p 9 C R N u n u a 7 h 4 h j P k K L x 5 c 8 O r n e P M X 9 C f s L A d N f F D w e K + K q n q R Z F Q b z / t 0 5 u Y X F p e W c y v 5 1 b X 1 j c 3 C 1 n Z N J 6 n C p I o T l q h G h D R h V J C q o Y a R h l Q E 8 Y i R e t S 7 G P r 1 O 6 I 0 T c S 1 6 U s S c N Q R N K Y Y G S v d y D C 7 v W + H Z h A W i l 7 J G 8 G d J f 6 E F M u 7 3 t e L + J a V s P D R a i c 4 5 U Q Y z J D W T d + T J s i Q M h Q z M s i 3 U k 0 k w j 3 U I U 1 L B e J E B 9 n o 4 I F 7 Y J W 2 G y f K l j D u S P 0 9 k S G u d Z 9 H t p M j 0 9 X T 3 l D 8 z 2 u m J j 4 P M i p k a o j A 4 0 V x y l y T u M P v 3 T Z V B B v W t w R h R e 2 t L u 4 i h b C x G e V t C P 7 0 y 7 O k d l z y T 0 q n V z a N I x g j B 3 u w D 4 f g w x m U 4 R I q U A U M H B 7 g C Z 4 d 5 T w 6 r 8 7 b u H X O m c z s w B 8 4 7 z 9 U p J R r &lt; / l a t e x i t &gt; p Z|ds &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " u n 3 p k M + Q C v s H M L w 7 + A W v f p J S 2 x M = " &gt; A A A B 8 H i c b V D J S g N B E K 1 x j X G L y 8 3 L Y B A 8 S J g R R Y 8 B L x 4 j m E W T Y e j p 9 C R N u n u a 7 h 4 h j P k K L x 5 c 8 O r n e P M X 9 C f s L A d N f F D w e K + K q n q R Z F Q b z / t 0 5 u Y X F p e W c y v 5 1 b X 1 j c 3 C 1 n Z N J 6 n C p I o T l q h G h D R h V J C q o Y a R h l Q E 8 Y i R e t S 7 G P r 1 O 6 I 0 T c S 1 6 U s S c N Q R N K Y Y G S v d y D C 7 v W + H e h A W i l 7 J G 8 G d J f 6 E F M u 7 3 t e L + J a V s P D R a i c 4 5 U Q Y z J D W T d + T J s i Q M h Q z M s i 3 U k 0 k w j 3 U I U 1 L B e J E B 9 n o 4 I F 7 Y J W 2 G y f K l j D u S P 0 9 k S G u d Z 9 H t p M j 0 9 X T 3 l D 8 z 2 u m J j 4 P M i p k a o j A 4 0 V x y l y T u M P v 3 T Z V B B v W t w R h R e 2 t L u 4 i h b C x G e V t C P 7 0 y 7 O k d l z y T 0 q n V z a N I x g j B 3 u w D 4 f g w x m U 4 R I q U A U M H B 7 g C Z 4 d 5 T w 6 r 8 7 b u H X O m c z s w B 8 4 7 z 9 T H 5 R q &lt; / l a t e x i t &gt; (a) discriminative &amp; support match (b) only support match (c) only discriminative</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>with floppy ears." "A pointy-eared dog." (c) image-text augmentations Figure 2: Image-text augmentations are practical domain-agnostic augmentations. Arrows denote augmenters. Bubbles denote inputs that have the same representations, as induced by predicting the augmentations. (a) Standard augmentations are not domain-agnostic. (b) Supervised augmentations uniformly augment inputs inside their label class, irrespective of domains. (c) Image-text augmentations are (nearly) domain-agnostic as they map images across domains to similar descriptions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>(a) Adding bottlenecks significantly improves the worst-case DG performance and using domain-agnostic (DA) augmentations (H[A | Z]) performs as well as with labels (R [Y | Z]). (b) Increasing the domain bottleneck weight ? will improve target performance until it decreases source performance. (c) DA augmentations are crucial but approx. DA aug. might be also be sufficient.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(35) follows by Item 3 of Assumption 2 along with the definition of f * . Eq. (36) follows by Item 3 of Assumption 2 and the fact that h * (z ) = f * (x ). This completes the proof, because Lemma 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>In the case of unconstrained variational families s ? , p ? and infinite samples (n ? ?), the above variational bound recovers I[A; Z] up to a constant (see<ref type="bibr" target="#b36">Oord et al. (2018)</ref>;<ref type="bibr" target="#b13">Dubois et al. (2021)</ref>). Typically the critic is separable, i.e., s ? (A, Z) := g ? (A) T h ? (Z). As discussed in the main body, it can be tied with the encoder p ? when A = X .In the following we focus on the second term B[Z, X, Y, D] and discuss several choices.Throughout this section, the function M : X ? N is the maximal invariant defined in Prop. 6 via the equivalence relation defined in Eq. (114). C.1 MUTUAL INFORMATION BOTTLENECK B[Z, X, Y, D] = I[Z; X] The first bottleneck we consider is so called mutual information (MI) bottleneck B[Z, X, Y, D] = I[Z; X], which was introduced by Tishby et al. (2000) to achieve a tradeoff between the predictive power and the complexity of representations. Intuitively, it tries to remove all information of Z that is not needed for maximizing I[Z; A]. In particular, using the fact that Z ? X ? D forms a Markov chain and the chain rule of MI, we have I[Z; X] = I[Z; X, D] = I[Z; D] + I[Z; X | D]. Thus, it not only minimizes I[Z; D], i.e., matches the representations' distribution across domains, but also minimizes I[Z; X | D], i.e., matches the representations' distribution inside domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Why</head><label></label><figDesc>Similar to the previous analysis, we aim to show that arg min p Z | X I[Z; D] under I[A; Z] = I[A; X] leads to the support match constraint. Using Eq. (116) we have I[Z; D] = I[Z, M (X Z ); D] = I[Z, M (X); D] = I[M (X); D] + I[Z; D | M (X)] where the last equality uses the chain rule of mutual information. Due to the non-negativity of (conditional) mutual information, we have that the minimum of I[Z; D] under I[A; Z] = I[A; X] is I[M (X); D]. Then we show the minimum is achievable by constructing the same optimal encoder e ? (X) as the Ent bottleneck which clearly satisfies I[Z; D | M (X)] = 0. It is then easy to show that the support match constraint has to hold when I[Z; D | M (X)] = 0 by contrapositive. Indeed, suppose that the support constraint does not hold then it must be true that I[Z; D | M (X)] &gt; 0 and so the encoder cannot be optimal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Sweeping the sample weight using CE-Base and SupCon-Base. We selected 10 ?5 which seemed to be reasonble for both cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>F</head><label></label><figDesc>were: ImageNetV2 (IN-V2, Recht et al., 2019), ImageNet-Sketch (IN-S, Wang et al., 2019), Youtube-BB (YT-BB, Shankar et al., 2019), ImageNet-Vid (IN-Vid, Shankar et al., 2019), ObjectNet (Barbu et al., 2019), ImageNet Adversarial (IN-A, Hendrycks et al., 2021), and ImageNet Rendition (IN-R Hendrycks et al., 2020). SupCon (H[A | Z]) objectives</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table><row><cell>Algorithm</cell><cell>VLCS</cell><cell>PACS</cell><cell cols="3">OfficeHome TerraIncognita DomainNet</cell></row><row><cell>ERM</cell><cell cols="2">77.6 ? 0.3 86.7 ? 0.3</cell><cell>66.4 ? 0.5</cell><cell>53.0 ? 0.3</cell><cell>41.3 ? 0.1</cell></row><row><cell>DomainBed SOTA</cell><cell cols="2">79.9 ? 0.2 87.2 ? 0.1</cell><cell>68.4 ? 0.2</cell><cell>54.4 ? 0.3</cell><cell>41.8 ? 0.1</cell></row><row><cell>DINO + CAD</cell><cell cols="2">69.6 ? 0.6 76.1 ? 0.1</cell><cell>56.9 ? 0.5</cell><cell>25.9 ? 1.2</cell><cell>33.6 ? 0.1</cell></row><row><cell>CLIP S</cell><cell cols="2">81.1 ? 0.5 90.3 ? 0.2</cell><cell>70.6 ? 0.1</cell><cell>29.6 ? 0.8</cell><cell>47.7 ? 0.0</cell></row><row><cell>CLIP S + Base</cell><cell cols="2">81.3 ? 0.5 91.2 ? 0.3</cell><cell>70.6 ? 0.1</cell><cell>36.4 ? 0.7</cell><cell>46.8 ? 0.2</cell></row><row><cell>CLIP S + CAD</cell><cell cols="2">82.3 ? 0.3 92.0 ? 0.2</cell><cell>71.9 ? 0.2</cell><cell>36.2 ? 0.8</cell><cell>48.8 ? 0.1</cell></row><row><cell>CLIP L</cell><cell cols="2">80.7 ? 0.4 93.7 ? 0.8</cell><cell>79.6 ? 0.1</cell><cell>36.9 ? 0.6</cell><cell>52.8 ? 0.1</cell></row><row><cell>CLIP L + CAD</cell><cell cols="2">81.6 ? 0.1 94.9 ? 0.3</cell><cell>80.0 ? 0.2</cell><cell>40.6 ? 1.1</cell><cell>53.7 ? 0.1</cell></row><row><cell>Approx. Optimal Z  *</cell><cell cols="2">86.8 ? 0.6 97.2 ? 0.6</cell><cell>86.3 ? 1.6</cell><cell>76.5 ? 4.1</cell><cell>66.7 ? 0.2</cell></row></table><note>CLIP significantly outperforms the previous SOTA result on DomainBed, as supported by our theoretical analysis. Finetuning CLIP with our CAD bottleneck consistently improves the robustness of its representations and achieves SOTA performance.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>et al.'s (2020) realistic setting, where a linear classifier h from Z is trained on ImageNet and tested on 7 natural distribution shift datasets. Details in Appx. E.4.Would training CLIP with a bottleneck have improved its robustness? As shown in the last 2 rows ofTable 2, finetuning CLIP L on LAION with L Ent (Tuned w/ Ent) outperforms finetuning without bottleneck (Tuned w/o Ent) on all 7 distribution shift datasets. This suggests that directly training CLIP with our Ent bottleneck would improve the robustness of learned representations. We hypothesize that the gains could be larger if SSL models trained L Ent end-to-end. In Appx. F.4, we show similar results on DomainBed. Note that both models underperform the original CLIP L, likely due to non-end-to-end training and LAION data with (possibly) lower quality than CLIP's data.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Finetuning CLIP L on LAION with an entropy bottleneck improves its robustness compared to finetuning without on 7 distribution shift datasets. The pretrained CLIP L is still better likely due to end-to-end training with higher quality data. IN denotes ImageNet.</figDesc><table><row><cell></cell><cell>IN</cell><cell cols="8">IN-V2 IN-S YT-BB IN-Vid ObjectNet IN-A IN-R Avg.</cell></row><row><cell>CLIP L</cell><cell>75.2</cell><cell>64.2</cell><cell>41.0</cell><cell>58.4</cell><cell>71.6</cell><cell>42.8</cell><cell>27.5</cell><cell>62.9</cell><cell>52.6</cell></row><row><cell cols="2">Tuned w/o Ent 73.8</cell><cell>62.1</cell><cell>37.0</cell><cell>56.9</cell><cell>68.8</cell><cell>41.3</cell><cell>26.0</cell><cell>58.1</cell><cell>50.0</cell></row><row><cell>Tuned w/ Ent</cell><cell>74.2</cell><cell>62.7</cell><cell>38.9</cell><cell>58.1</cell><cell>70.1</cell><cell>42.1</cell><cell>26.2</cell><cell>60.8</cell><cell>51.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table of</head><label>of</label><figDesc>Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 A.2 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 A.3 Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 Lemmas for general losses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 B.2 Proof of Theorem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 B.3 Impossibility results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 B.4 Augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25</figDesc><table><row><cell>Contents</cell><cell></cell></row><row><cell>A Preliminaries</cell><cell>15</cell></row><row><cell>A.1 B Proofs</cell><cell>19</cell></row><row><cell>B.1</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Scientific . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 E.2 Bridge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 E.3 DomainBed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 E.4 LAION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Scientific . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 F.2 Bridge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 F.3 DomainBed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 F.4 LAION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38</figDesc><table><row><cell>D Extended Related Work E Experimental Details E.1 F Additional Experimental Results F.1 A PRELIMINARIES A.1 NOTATION</cell><cell>30 32 32 36</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>WhyThe key to show is that minimizing Eq. (122), i.e., arg min p Z | X I[Z; X] under I[A; Z] = I[A; X], implies the support match constraint. This can be seen as a specific subcase ofDubois  et al.'s (2021)  Corollary 15 with A in place of Y and M (X) induced by p A | X as in the proof of Prop. 6. From the corollary, we know that min p Z | X I[Z; X] = H[M (X)] which can be achieved by any Z s.t. p</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Why In the deterministic case, the MI bottleneck becomes the entropy bottleneck because I[X;Z] = H[Z] ? H[Z | X] = H[Z], where we use the fact that H[Z | X] = 0. Importantly, considering only deterministic encoders does not constrain our ability to learning optimal encoders. Indeed, just as with the MI bottleneck optimizing the objective with the entropy bottleneck under I[A; Z] = I[A; X] will recover encoders s.t. e ?</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 5 :</head><label>5</label><figDesc>Results on DomainBed with 'source validation' selection. Source validation selected model tends to overfit more to the source domain and diminish the effect of bottlenecks.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Although text descriptions might contain domain information (e.g., referring to "sketch"), they are still much better than standard augmentations that rarely map together images from different domains.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Reproducibility For our theoretical results, we include formal assumptions, statements, and proofs in Appxs. A and B. We include the detailed derivations of our algorithms in Appx. C. For our experiments, we include experimental details for reproducing our results in Appx. E and have released our code at https://github.com/ryoungj/optdom.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Here we have a slight abuse use of the phrase 'average-case' to distinguish from the 'worst-case' that we use in the scientific setting. In fact, the source predictor could be close to the 'best-case' since the max-margin classifier (SVM) was used.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">See https://laion.ai/laion-400-open-dataset/ for details. 5 https://github.com/modestyachts/imagenet-testbed</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We would like to thank Elliot Creager, Roger Grosse, Elan Rosenfeld, Guodong Zhang, Han Zhao, and anonymous reviewers for their helpful feedbacks and encouragements. Resources used in preparing this research were provided, in part, by the Province of Ontario, the Government of Canada through CIFAR, and companies sponsoring the Vector Institute. We acknowledge the support of the Natural Sciences and Engineering Research Council of Canada (NSERC), RGPIN-2021-03445.   </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Why 'oracle' selection? In the main body, we provided the results with 'oracle selection' which was the closest to our theory among the model selection methods in DomainBed (in the sense that we needed target domain information to achieve IDG). Here, we also provided results with 'source validation' selection in <ref type="table">Table 5</ref>. Source validation selection relies on the assumption that source and target data follow similar distributions <ref type="bibr" target="#b19">(Gulrajani &amp; Lopez-Paz, 2021</ref>) thus source and target accuracy are highly correlated, which is not really true in practice. We found some issues with source validation selection results:</p><p>? The selected model with the highest source validation accuracy tends to overfit the source domain, thus possibly leads to worse performance on the target domain. This can be probed by the fact that the finetuned CLIP models (CLIP + Base or CLIP + CAD) were generally worse than the original CLIP model;</p><p>? Selecting model with source validation accuracy tends to diminish the effect of bottlenecks. This can be seen by the fact that the gap between CLIP + Base and CLIP + CAD of source validation selection is much smaller than that of oracle selection;</p><p>? The source accuracy is not a good indicator of target accuracy thus its result has a larger variance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.4 LAION</head><p>Evaluation results on DomainBed We included the evaluation results of trained models on Do-mainBed in <ref type="table">Table 6</ref>, where we followed exactly the same linear evaluation protocal discussed in Appx. E.3. We observed similar results as  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Alexander A Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">V</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.00410</idno>
		<title level="m">Deep variational information bottleneck</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Invariant risk minimization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">End-to-end optimized image compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Ball?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valero</forename><surname>Laparra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eero P</forename><surname>Simoncelli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01704</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Ball?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Minnen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.01436</idno>
		<title level="m">Sung Jin Hwang, and Nick Johnston. Variational image compression with a scale hyperprior</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Barbu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Alverio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danny</forename><surname>Gutfreund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Katz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recognition in terra incognita</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Beery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grant</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="456" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">137</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="151" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Impossibility theorems for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teresa</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pal</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v9/david10a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<editor>Yee Whye Teh and Mike Titterington</editor>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics<address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="13" to="15" />
		</imprint>
		<respStmt>
			<orgName>Chia Laguna Resort</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COMPSTAT&apos;2010</title>
		<meeting>COMPSTAT&apos;2010</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Emerging properties in self-supervised vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.14294</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning optimal representations with the decodable information bottleneck</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Schwab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedantam</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/d8ea5f53c1b1eb087ac2e356253395d8-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="18674" to="18690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Lossy compression for lossless prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Bloem-Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Ullrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.10800</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">N</forename><surname>Rockmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1657" to="1664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Domain-adversarial training of neural networks. The journal of machine learning research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Strictly proper scoring rules, prediction, and estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tilmann</forename><surname>Gneiting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American statistical Association</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">477</biblScope>
			<biblScope unit="page" from="359" to="378" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Domain adaptation with conditional transferable components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2839" to="2848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.00160</idno>
		<title level="m">Nips 2016 tutorial: Generative adversarial networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">In search of lost domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=lQdXeXDoWtI" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The many faces of robustness: A critical analysis of out-of-distribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Dorundo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samyak</forename><surname>Parajuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16241</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Natural adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15262" to="15271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Support and invertibility in domaininvariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fredrik D Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ranganath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prannay</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.11362</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Supervised contrastive learning</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveen</forename><surname>Kodali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Abernethy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07215</idno>
		<title level="m">On convergence and stability of gans</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Out-of-distribution generalization via risk extrapolation (rex)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joern-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Binas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinghuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Le Priol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="5815" to="5826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yezhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Colorado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.06333</idno>
		<title level="m">Invariant information bottleneck for domain generalization</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5542" to="5550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep domain generalization via conditional invariant adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="624" to="639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="97" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep transfer learning with joint adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2208" to="2217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yishay</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afshin</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0902.3430</idno>
		<title level="m">Domain adaptation: Learning bounds and algorithms</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toan</forename><surname>A Tuan Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">At?l?m G?ne?</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baydin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.07780</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">Kl guided domain adaptation. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Moment matching for multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingchao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinxun</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xide</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1406" to="1415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">On variational bounds of mutual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5171" to="5180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v139/radford21a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<editor>Marina Meila and Tong Zhang</editor>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021-07" />
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="18" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Do imagenet classifiers generalize to imagenet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5389" to="5400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tatsunori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.08731</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Theoretical Analysis of Contrastive Unsupervised Representation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orestis</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrishikesh</forename><surname>Khandeparkar</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="http://proceedings.mlr.press/v97/saunshi19a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
		<editor>Kamalika Chaudhuri and Ruslan Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-15" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="5628" to="5637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Laion-400m: Open dataset of clip-filtered 400 million image-text pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Schuhmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Vencu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Beaumont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Kaczmarczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clayton</forename><surname>Mullis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aarush</forename><surname>Katta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theo</forename><surname>Coombes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenia</forename><surname>Jitsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aran</forename><surname>Komatsuzaki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.02114</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning and generalization with the information bottleneck</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ohad</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sivan</forename><surname>Sabato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tcs.2010.04.006</idno>
		<ptr target="https://doi.org/10.1016/j.tcs.2010.04.006" />
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">411</biblScope>
			<biblScope unit="page" from="2696" to="2711" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achal</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02168</idno>
		<title level="m">Do image classifiers generalize across time? arXiv preprint</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Wasserstein distance guided representation learning for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanru</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Opening the black box of deep neural networks via information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravid</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Ziv</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<idno>abs/1703.00810</idno>
		<ptr target="http://arxiv.org/abs/1703.00810" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Domain adaptation with conditional distribution matching and generalized label shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Tachet Des Combes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Measuring robustness to natural distribution shifts in image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achal</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.00644</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Husz?r</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00395</idno>
		<title level="m">Lossy image compression with compressive autoencoders</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bialek</surname></persName>
		</author>
		<title level="m">The information bottleneck method. arXiv preprint physics/0004057</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hemanth</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shayok</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sethuraman</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5018" to="5027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Learning robust global representations by penalizing local predictive power</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songwei</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.13549</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Multimodal self-supervised learning of general audio representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pauline</forename><surname>Luc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adria</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Baptiste</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.12807</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Minimum excess risk in bayesian learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aolin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Raginsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.14868</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Improve unsupervised domain adaptation with mixup training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Shen Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanxiang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lincan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00677</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">On learning invariant representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Tachet Des</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Combes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="7523" to="7532" />
		</imprint>
	</monogr>
	<note>PMLR, 2019. the source training split. The regularization parameter was tuned over {1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3} with the source validation accuracy</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Next, we provide other experimental details for reproducibility: Selection of ? For all different setups considered in bridge settings, the CAD bottleneck was used and the ? was tuned over {1e-3, 1e-2, 1e-1, 1, 1e1} independently for each</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">For each dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">;</forename><surname>Al</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pacs (li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Datasets We used non-MNIST datasets on DomainBed that were non-synthetic, including VLCS (Fang et</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>TerraIncognita (Beery. we split it to 80%/20% training/validation set according to DomainBed</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">We used CLIP ResNet-50 (CLIP S) to obtain the best possible fair comparison with baselines from DomainBed, and CLIP ViT-B/32 (CLIP L) to achieve the best results. Note that the ResNet-50 model of CLIP S was modified as described in Radford et al. (2021) and contained 38M parameters (more than 23M of the original CLIP). The model was trained to 300 epochs for DomainNet and 50 epochs on other datasets (an epoch is defined as a single pass over the smallest domain according to DomainBed). No data augmentation was used and the temperature for scaling the logits in CAD was fixed to 0.05. We used the Adam optimizer with a 1e-5 weight dacay, and a cosine learning rate decay schedule</title>
	</analytic>
	<monogr>
		<title level="m">SSL-based models &amp; Training For all models based on pretrained SSL models (either CLIP-based or DINO-based) with finetuning in this experiment, we freezed the pretrained SSL model and added on top a 1-layer MLP with hidden size 1024, and residual connection</title>
		<imprint>
			<biblScope unit="page" from="3" to="3" />
		</imprint>
	</monogr>
	<note>The hyperparameter search space is: ? Learning rate: discrete set {1e-4, 3e-4, 1e-3</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">? Batch size: discrete set {128, 256, 512} for DomainNet and OfficeHome, and {64, 128, 256} for other datasets</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Mlp</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>discrete set {0., 0.1, 0.5}</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<title level="m">? Learning rate warmup: discrete set {True</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">We used exactly the same model architecture (the original ResNet-50, initialized from ImageNet pretrained model), training procedure and evaluation protocal as baselines on DomainBed. Importantly, the linear classifier was jointly trained with the encoder, and no refitting was applied. The model was trained to a maximum of 5000 steps on each dataset, and data augmentations were applied. The Adam optimizer was used without any particular learning rate schedule. The hyperparameter search space is</title>
	</analytic>
	<monogr>
		<title level="m">&amp; Training In Table 1, we also included an end-to-end trained model without any pretrained SSL models</title>
		<imprint/>
	</monogr>
	<note>same as DomainBed except we added the temperature): ? Learning rate: log-uniform over [1e-5, 1e-3.5</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
				<title level="m">? Batch size: log-uniform over</title>
		<imprint/>
	</monogr>
	<note>8, 64] for DomainNet, and [8, 2 5.5 ] for other datasets ? MLP dropout: discrete set {0., 0.1, 0.5}</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">? Weight decay: log-uniform over</title>
		<imprint/>
	</monogr>
	<note>1e-6, 1e-2</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Temperature</surname></persName>
		</author>
		<title level="m">discrete set {0.05, 0.1}</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Since DomainNet was too large and SVM cannot fit it efficiently, we used the logistic regression classifier which was trained with a batch size 512, the Adam optimizer with a learning rate 5e-4 and early stopping. Note that an alternative was to just use the linear head fitted when training the representor (as we used CE loss with source labels), and we found this could work better than refitting since the classifier was less overfitted to the source domain. However</title>
	</analytic>
	<monogr>
		<title level="m">Linear Probe Evaluation In all the experiments except for the end-to-end training setup, we always followed the procedure of two-stage training</title>
		<imprint/>
	</monogr>
	<note>where we first trained the encoder with specified objectives, and then refit the classifier. For datasets except DomainNet, we fitted the SVM classifier and tuned the regularization parameter over {1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3} with source validation selection. we didn&apos;t do that since we wanted to stick to the representation learning protocol with two-stage training. We Setup Avg. target acc</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
