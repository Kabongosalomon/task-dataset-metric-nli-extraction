<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sequential Learning for Domain Generalization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Samsung AI Centre</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">SketchX</orgName>
								<orgName type="institution" key="instit2">CVSSP</orgName>
								<orgName type="institution" key="instit3">University of Surrey</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
							<email>y.song@surrey.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">SketchX</orgName>
								<orgName type="institution" key="instit2">CVSSP</orgName>
								<orgName type="institution" key="instit3">University of Surrey</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
							<email>t.hospedales@ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Samsung AI Centre</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">SketchX</orgName>
								<orgName type="institution" key="instit2">CVSSP</orgName>
								<orgName type="institution" key="instit3">University of Surrey</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">The University of Edinburgh</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sequential Learning for Domain Generalization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Sequential learning ? meta-learning ? domain generalization</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we propose a sequential learning framework for Domain Generalization (DG), the problem of training a model that is robust to domain shift by design. Various DG approaches have been proposed with different motivating intuitions, but they typically optimize for a single step of domain generalization -training on one set of domains and generalizing to one other. Our sequential learning is inspired by the idea lifelong learning, where accumulated experience means that learning the n th thing becomes easier than the 1 st thing. In DG this means encountering a sequence of domains and at each step training to maximise performance on the next domain. The performance at domain n then depends on the previous n ? 1 learning problems. Thus backpropagating through the sequence means optimizing performance not just for the next domain, but all following domains. Training on all such sequences of domains provides dramatically more 'practice' for a base DG learner compared to existing approaches, thus improving performance on a true testing domain. This strategy can be instantiated for different base DG algorithms, but we focus on its application to the recently proposed Meta-Learning Domain generalization (MLDG). We show that for MLDG it leads to a simple to implement and fast algorithm that provides consistent performance improvement on a variety of DG benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Contemporary machine learning algorithms provide excellent performance when training and testing data are drawn from the same underlying distribution. However, it is often impossible to guarantee prior collection of training data that is representative of the environment in which a model will be deployed, and the resulting train-test domain shift leads to significant degradation in performance. The long studied area of Domain Adaptation (DA) aims to alleviate this by adapting models to the testing domain <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b3">4]</ref>. Meanwhile, the recently topical area of Domain Generalization (DG) aims to build or train models that are designed for increased robustness to such domain-shift without requiring adaptation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b1">2]</ref>.</p><p>A variety of DG methods have been proposed based on different intuitions. To learn a domain-agnostic feature representation, some of these require specific base learner architectures <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b13">14]</ref>. Others are model-agnostic modifications to the training procedure of any base learner, for example by via data augmentation <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b39">40]</ref>. Meta-learning (a.k.a learning to learn) has a long history <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b43">44]</ref>, with primary application to accelerating learning of new tasks <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b40">41]</ref>. Recently, some researchers proposed meta-learning based methods for DG <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b1">2]</ref>. Different from previous DG methods, these are designed around explicitly mimicking train-test domain-shift during model training, to develop improved robustness to domainshift at testing. Such meta-learning has an analogy to human learning, where a human's experience of context change provides the opportunity to develop strategies that are more agnostic to context (domain). If a human discovers that their existing problem-solving strategy fails in a new context, they can try to update their strategy to be more context independent, so that next time they arrive in a new context they are more likely to succeed immediately.</p><p>While effective, recent meta-DG methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b1">2]</ref> provide a 'single-step' of DG meta-learning: training on one set of training domains to optimize performance on a disjoint set of 'validation' domains. However, in human lifelong learning, such learning does not happen once, but sequentially in a continual learning manner. Taking this perspective in algorithm design, one learning update from domain n to n + 1 should have the opportunity to affect the performance on every subsequent domain encountered, n + 2 onwards. Such continual learning provides the opportunity for much more feedback to each learning update. In backpropagation, the update at domain n ? n + 1 can be informed by its downstream impact on all subsequent updates for all subsequent domains. In this way we can generate more unique episodes for meta-learning, which has improved performance in the more common few-shot applications of meta-learning <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b20">21]</ref>. Specifically, in approaches that use a single-pass on all source domains <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b7">8]</ref>, DG models are trained once for a single objective. Approaches doing one-step meta-learning <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b1">2]</ref> by rotating through meta-train and metatest (validation) domain splits of N source domains train DG with N distinct domain-shift episodes. Meanwhile within our sequential learning DG framework, by further simulating all possible sequential learning domain sequences, we train with N ! distinct domain-shift episodes. This greater diversity of domain-shift training experience enables better generalization to a final true testing domain.</p><p>Our proposed framework can be instantiated for multiple base DG algorithms without modifying their underlying design. We focus on its instantiation for a recent architecture-agonstic meta-learning based method MLDG <ref type="bibr" target="#b14">[15]</ref>, but also show that it can be applied to a traditional architecture based method Undo Bias <ref type="bibr" target="#b13">[14]</ref>. In the case of MLDG, we show our sequential-learning generalization S-MLDG, leads to a simple to implement and fast to train meta-learning algorithm that is architecture agnostic and consistently improves performance on a variety of DG benchmarks. This is achieved via a first-order approximation to the full S-MLDG, which leads to a shortest-path descent method analogous to Reptile <ref type="bibr" target="#b25">[26]</ref> in few-shot learning.</p><p>We summarise our contributions as follows:</p><p>-We propose a sequential learning framework for DG that can be applied to different base DG methods. We show that it can be instantiated for at least two different base DG methods, the architecture focused Undo-Bias <ref type="bibr" target="#b13">[14]</ref>, and the architecture agnostic meta-learning algorithm MLDG <ref type="bibr" target="#b14">[15]</ref>. -Our framework improves training by increasing the diversity of unique DG episodes constructed for training the base learner, and enabling future changes in continual-learning performance changes to back-propagate to earlier domain updates. -We provide an analysis of the proposed S-MLDG, to understand the difference in optimization to the base MLDG algorithm, and to derive a fast first-order approximation FFO-S-MLDG. This algorithm is simple to implement and fast to run, while performing comparably to S-MLDG. -The resulting S-MLDG and FFO-S-MLDG algorithms provide state of the art performance on three different DG benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Domain Adaptation (DA) Domain adaptation has received great attention from researchers in the past decade <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32]</ref>. Different from domain generalization, domain adaptation assumes that unlabeled target domain data is accessible at training. Various methods have been proposed to tackle domainshift by reducing discrepancy between source and target domain features. Representative approaches include aligning domains by minimizing distribution shift as measured by MMD <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b18">19]</ref>, or performing adversarial training to ensure that in the learned representation space the domains cannot be distinguished <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b31">32]</ref>, or learning generative models for cross-domain image synthesis <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b10">11]</ref>. However, data may not be available for the target domain, or it may not be possible to adapt the base model, thus requiring Domain Generalization.</p><p>Domain Generalization (DG) A diversity of DG methods have been proposed in recent years <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b39">40]</ref>. These are commonly categorized according to their motivating inductive bias, or their architectural assumptions. Common motivating intuitions include feature learning methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b16">17]</ref> that aim to learn a representation that generates domain invariant features; data augmentation-based methods that aim to improve robustness by synthesizing novel data that better covers the space of domain variability compared to the original source domains <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b34">35]</ref>; and fusion methods that aim to perform well on test domains by recombining classifiers trained on diverse source domains <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b21">22]</ref>. Meanwhile in terms of architecture, some methods impose constraints on the specific base classifier architecture to be used <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b42">43]</ref>, while others provide an architecture agnostic DG training strategy <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b39">40]</ref>.</p><p>Most of the above methods train a single set of source tasks for a DG objective. Recent meta-learning methods use the set of known source domains to simulate train-test domain-shift and optimize to improve robustness to domain-shift. For example, via gradient alignment <ref type="bibr" target="#b14">[15]</ref> or meta-optimizing a robust regularizer for the base model <ref type="bibr" target="#b1">[2]</ref>. Our sequential learning framework aims to simulate continual learning over a sequence of domains, and furthermore averages over many such sequences. This provides a greater diversity of distinct domain-shift experiences to learn from, and stronger feedback in the form of the impact of a parameter change not just on the next validation domain, but its subsequent impact on all domains in the continual learning sequence. We show that our framework can be instantiated primarily for the meta-learning method MLDG <ref type="bibr" target="#b14">[15]</ref>, but also for the classic architecture-specific method Undo-Bias <ref type="bibr" target="#b13">[14]</ref>, and its recently proposed deep extension <ref type="bibr" target="#b15">[16]</ref>.</p><p>Meta-Learning Meta-Learning (learning to learn) has a long history <ref type="bibr" target="#b33">[34]</ref>. It has recently become widely used in few-shot learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b24">25]</ref> applications. A common meta-optimization strategy is to split training tasks into meta-train and meta-test (validation) task sets, and meta-optimization aims to improve the ability to learn quickly on meta-test tasks given the knowledge in meta-train tasks. This is achieved through various routes, by learning a more general feature embedding <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b36">37]</ref>, learning a more efficient optimizer <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b28">29]</ref>, or even simply learning an effective initial condition for optimization <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b25">26]</ref>. Several gradientbased meta-learners induce higher-order gradients that increase computational cost, for example MAML <ref type="bibr" target="#b6">[7]</ref>. This inspired other studies to develop first order approximations for faster meta-learning; such as Reptile <ref type="bibr" target="#b25">[26]</ref> that accelerates MAML. While all these methods meta-optimize for fast adaptation to new tasks, we aim to optimize for domain-generalization: training a model such that it performs well on a novel domain with no opportunity for adaptation. We take inspiration from Reptile <ref type="bibr" target="#b25">[26]</ref> to develop a fast implementation of our proposed S-MLDG.</p><p>Lifelong Learning Our sequential learning is inspired by the vision of lifelong learning (LLL) <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b20">21]</ref> . LLL methods focus on how to accelerate learning of new tasks given a series of sequentially learned previous tasks (and often how to avoid forgetting old tasks). We leverage the idea of optimizing for future performance in a sequence. But different to prior methods: (i) we focus on optimizing for domain invariance, rather than optimizing for speed of learning a new task, and (ii) we back-propagate through the entire sequence of domains so that every update step in the sequence is driven by improving the final domain invariance of the base model. It is important to note that while most lifelong and continual learning studies are oriented around designing a method that is deployed in a lifelong learning setting, we address a standard problem setting with a fixed set of source and target (testing) domains. We aim to use sequential training within our given source domains to learn a more robust model that generalizes better to the true testing domain. To this end, since different potential learning sequences affect the outcome in lifelong learning <ref type="bibr" target="#b26">[27]</ref>, we aim to generate the most unique learning experiences to drive training by simulating all possible sequences through our source domains and optimizing for their expected outcome.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Domain Generalization Background</head><p>In the domain generalization problem setting, a learner receives N labelled do-</p><formula xml:id="formula_0">mains (datasets) D = [D 1 , D 2 , ? ? ? , D N ] where D i = (X i , y i )</formula><p>, and aims to produce a model that works for a different unseen domain D * at testing. We first introduce a simple baseline for DG .</p><p>Aggregation Baseline A simple baseline for DG is to aggregate all domains' data and train a single model on D agg = D 1 ?D 2 ?? ? ??D N . Although not always compared, this obvious baseline often outperforms earlier published DG methods when applied with deep learning <ref type="bibr" target="#b15">[16]</ref>.</p><p>Base Methods Our sequential learning framework can be applied to generalize MLDG <ref type="bibr" target="#b14">[15]</ref> and shallow <ref type="bibr" target="#b13">[14]</ref> or deep <ref type="bibr" target="#b15">[16]</ref> Undo-Bias. Due to space constraints, we focus on the application to MLDG, and leave application to Undo-Bias to Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Meta-Learning Domain Generalization</head><p>In contrast to many DG methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b34">35]</ref>, which require special designs of model architectures, Meta-Learning Domain Generalization (MLDG) <ref type="bibr" target="#b14">[15]</ref> proposes an optimization method to achieve DG that is agnostic to base learner architecture. The idea is to mimic (during training) the cross-domain training and testing encountered in the DG setting -by way of meta-training and metatesting steps.</p><p>In each iteration of training it randomly selects one domain D k , k ? [1, N ] and uses it as the meta-test domain, i.e. D mtst ? D k (here D mtst can be seen as a kind of virtual test domain), and aggregates the remaining to construct the meta-train domain, i.e.,</p><formula xml:id="formula_1">D mtrn ? ? i =k D i .</formula><p>Following the intuition that meta-test will be used to evaluate the effect of the model optimization on meta-train at each iteration, MLDG aims to optimize both the loss on meta-train L 1 = L(D mtrn , ?), and loss on meta-test after updating on meta-train</p><formula xml:id="formula_2">L 2 = L(D mtst , ? ? ? ? ? ? L 1 ) by one gradient descent step ? ? ? ? L 1 with step size ?, where L(.)</formula><p>is the cross-entropy loss here. Overall this leads to optimization of</p><formula xml:id="formula_3">argmin ? L1(Dmtrn, ?) + ?L2(Dmtst, ? ? ?? ? L1).<label>(1)</label></formula><p>After training, the base model with parameters ? will be used for true unseen test domain. A base DG method is trained at every step in a sequence of domains. And this is repeated over different random sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Sequential Learning Domain Generalization</head><p>Domain generalization methods mostly aim to achieve min L(D * |D train ). I.e., low loss on a testing domain D * after training on a set of training domains D train . Of course this can not be optimized in the conventional way since the target D * is not available, so various methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b23">24]</ref> attempt to achieve this indirectly by various kinds of multi-domain training on the domains in D train . As outlined in the previous section, meta-learning approaches such as MLDG aim to achieve this by finding a model that performs well over many different meta-train and meta-test splits of the true training domains: min E (Dmtrn,Dmtst)?Dtrain L(D mtst |D mtrn ).</p><p>Inspired by the idea of human lifelong learning-to-learn <ref type="bibr" target="#b35">[36]</ref> and the benefit of providing 'more practice' <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">13]</ref>, we propose to optimize the performance of a sequentially learned DG model at every step of a trajectory p through the domains, averaged over all possible trajectories P. As illustrated in <ref type="figure" target="#fig_1">Fig. 1</ref>, this corresponds to:</p><formula xml:id="formula_4">min Ep?P d?p L(D d |D [:d) )<label>(2)</label></formula><p>Here L(D d |D [:d) ) denotes the performance on meta-test domain d given a DG model which has been sequentially trained on meta-train domains before the arrival of domain d, and p denotes the sequential trajectory. This covers N ! distinct DG learning problems (at each incremental step of each possible trajectory p), since the order of the path through any fixed set of source domains matters. </p><formula xml:id="formula_5">p = shuffle([1, 2, . . . , N ]) D = [D1,D2, . . . ,DN ] //Sample mini-batchesDi L = L(D p[1] , ?) for i in [2, 3, . . . , |p|] do L += ? L(D p[i] , ? ? ?? ? L) //Inner-loop update end Update ? := ? ? ?? ? L //Meta update end Output: ?</formula><p>one domain as meta-test, and keeps the others as meta-train. But within the meta-train domains, it simply aggregates them. It does not exploit their domain grouping. To instantiate our hierarchical training framework (Eq. 2) for MLDG we imagine recursively applying MLDG. For a given meta-test/meta-train split, we apply MLDG again within the meta-train split until there is only a single domain in the meta-train set. This simulates a lifelong DG learning process, where we should succeed at DG between the first and second training domains, and then the result of that should succeed at DG on the third training domain etc. The objective function to optimize for S-MLDG is:</p><formula xml:id="formula_6">LS-MLDG = Ep?P L1(D p[1] , ?) +? N i=2 Li(D p[i] , ? ? ?? ? i?1 j=1 Lj) = Ep?P L1(D p[1] , ?) +?L2(D p[2] , ? ? ?? ? L1) +?L3(D p[3] , ? ? ?? ? 2 j=1 Lj) + ... +?LN (D p[N ] , ? ? ?? ? N ?1 j=1 Lj) (3)</formula><p>The optimization is carried out over all possible paths p through the training domains. MLDG is model-agnostic and computes a single parameter ? for all domains, so the final ? after optimization is used for inference on unseen domains. The overall algorithm is shown in Alg. 1.</p><p>MLDG The MLDG mechanism was originally analyzed <ref type="bibr" target="#b14">[15]</ref> via a first-order Taylor series. Since MLDG only does one-step DG validation, one domain is sampled as meta-test to split the source domains. Then the objective function is</p><formula xml:id="formula_7">LMLDG =L1(Dmtrn, ?) + ?L2(Dmtst, ? ? ?? ? L1)<label>(4)</label></formula><p>Algorithm 2: Faster First-Order S-MLDG</p><formula xml:id="formula_8">Input: D = [D1, D2, . . . , DN ] N source domains. Initialize: ?, ?, ? and ? while not done training d? ? = ? p = shuffle([1, 2, . . . , N ]) D = [D1,D2, . . . ,DN ] //Sample mini-batchesDi for i in [1, N ] do Li = ?L(D p[i] ,?) ? =? ? ???Li //Inner-loop update end Update ? := ? + ?(? ? ?) //Meta update end Output: ?</formula><p>After Taylor expansion on the second item, it becomes</p><formula xml:id="formula_9">L2(? ? ?? ? L1) = L2(?) + ? ? L2 ? (??? ? L1)<label>(5)</label></formula><p>and then L MLDG becomes</p><formula xml:id="formula_10">LMLDG = L1(?) + ?L2(?) ? ??? ? L1? ? L2<label>(6)</label></formula><p>This led to MLDG's interpretation as a preference for an optimization path with aligned gradients between meta-train and meta-test <ref type="bibr" target="#b14">[15]</ref>. S-MLDG If we use 3 source domains as an example to analyse S-MLDG, the loss function is</p><formula xml:id="formula_11">LS-MLDG-3 =L1(?) + ?L2(? ? ?? ? L1) + ?L3(? ? ?? ? (L1 + L2))<label>(7)</label></formula><p>The first two items are the same as L MLDG . Apply Taylor expansion on the third item in L S-MLDG-3 ,</p><formula xml:id="formula_12">L 3 (? ? ?? ? (L 1 + L 2 )) = L 3 (?) + ? ? L 3 ? (??? ? (L 1 + L 2 ))<label>(8)</label></formula><p>we have,</p><formula xml:id="formula_13">LS-MLDG-3 = L1(?) + ?L2(?) + ?L3(?) ? ??? ? L1? ? L2 ? ??? ? L3? ? L1 ? ??? ? L3? ? L2<label>(9)</label></formula><p>This shows that S-MLDG optimizes all source domains (first three terms), while preferring an optimization path where gradients align across all pairs of domains (second three terms maximising dot products). This is different to MLDG, that only optimizes the inner product of gradients between the current meta-train and meta-test domain splits. In contrast S-MLDG has the chance to optimize for DG on each meta-test domain in the sequential way, thus obtaining more unique experience to 'practice' DG.</p><p>A Direct S-MLDG Implementation A direct implementation of the meta update for S-MLDG in the three domain case would differentiate L S-MLDG-3 (Eq. 9) w.r.t ? as</p><formula xml:id="formula_14">? ? LS-MLDG-3 = ? ? L1(?) + ?? ? L2(? ? ?? ? L1) + ?? ? L3(? ? ?? ? (L1 + L2)) = ?L1(?) ?? + ? ?L2(?1) ??1 ??1 ?? + ? ?L3(?2) ??2</formula><p>??2 ??</p><formula xml:id="formula_15">(10) where ?1 = ? ? ?? ? L1 ?2 = ? ? ?? ? (L1 + L2)<label>(11)</label></formula><p>However, update steps based on Eq. 10 require high-order gradients when computing ??1 ?? , ??2 ?? . These higher-order gradients are expensive to compute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">First-order Approximator of S-MLDG</head><p>FO-S-MLDG: Similar to <ref type="bibr" target="#b6">[7]</ref>, we can alleviate the above issue by stopping the gradient of the exposed first derivative items to omit higher-order gradients. I.e, ? ? L 1 and ? ? (L 1 + L 2 ) in Eq. 11 are constants when computing L 2 and L 3 . Then for FO-S-MLDG, Eq. 10 becomes</p><formula xml:id="formula_16">? ? LS-MLDG-3 = ?L1(?) ?? + ? ?L2(?1) ??1 ??1 ?? + ? ?L3(?2) ??2 ??2 ?? = ?L1(?) ?? + ? ?L2(?1) ??1 ?(? ? ?? ? L1) ?? + ? ?L3(?2) ??2 ?(? ? ?? ? (L1 + L2)) ?? = ?L1(?) ?? + ? ?L2(?1) ??1 + ? ?L3(?2) ??2<label>(12)</label></formula><p>FO-S-MLDG still follows Alg. 1, but saves computation by omitting high-order gradients in back propagation. We use this approximator for S-MLDG by default. However FO-S-MLDG still requires back propagation (as per Eq. 10), to compute gradients of L 1 , L 2 and L 3 , even though higher-order gradients are ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Fast First-Order S-MLDG</head><p>FFO-S-MLDG: If we look at ? ? L S-MLDG-3 in Eq. 12 again, we find</p><formula xml:id="formula_17">?L1(?) ?? + ? ?L2(?1) ??1 + ? ?L3(?2) ??2 = L 1 + ?L 2 + ?L 3<label>(13)</label></formula><p>This means that one-step meta update of FO-S-MLDG is ?(</p><formula xml:id="formula_18">L 1 + ?L 2 + ?L 3 ),</formula><p>where ? is the meta step-size. This indicates that one update of naive first-order S-MLDG is equivalent to updating the parameters towards the result of training on L 1 (D p <ref type="bibr" target="#b0">[1]</ref> ), L 2 (D p <ref type="bibr" target="#b1">[2]</ref> ) and L 3 (D p <ref type="bibr" target="#b2">[3]</ref> ) recursively. In other words, if we regard the initial parameters as ? and the parameters updated recursively on L 1 (D p <ref type="bibr" target="#b0">[1]</ref> ), L 2 (D p <ref type="bibr" target="#b1">[2]</ref> ) and L 3 (D p <ref type="bibr" target="#b2">[3]</ref> ) as?, then Eq. 13 can be expressed as  This means that we can optimize L 1 (D p <ref type="bibr" target="#b0">[1]</ref> ), L 2 (D p <ref type="bibr" target="#b1">[2]</ref> ) and L 3 (D p <ref type="bibr" target="#b2">[3]</ref> ) in sequence (to obtain?, and then use the resulting offset vector as the meta-gradient for updating ?). Thus we do not need to backpropagate to explicitly compute the gradients suggested by Eq. 13. The overall flow of FFO-S-MLDG is shown in Alg. 2. Link between Fast First-Order S-MLDG and S-MLDG We analyze FFO-S-MLDG in Alg. 2 considering two source domains and derive the expectation of the optimization gradient is</p><formula xml:id="formula_19">L 1 + ?L 2 + ?L 3 = ? ??<label>(14)</label></formula><formula xml:id="formula_20">Ep?P [g p[1] + g p[2] ] =?1 +?2 ? ? 2 ?(?1 ??2) ??1 + O(? 2 )<label>(15)</label></formula><p>Here? 1 ,? 2 are the gradient updates for the first and second source domains and g 1 ?? 2 is the inner product between the two gradients. The gradient ? ?(?1??2) ??1 is in the direction that maximizes it. This means in expectation of multiple gradient updates FFO-S-MLDG learns to maximize the inner-product between gradients of different domains. Thus it maintains a similar but slightly different objective to S-MLDG, which maximizes the inner-product of gradients in each meta update. More details can be found in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Datasets and Settings We evaluate our method on three different benchmarks: IXMAS <ref type="bibr" target="#b41">[42]</ref>, where human actions are recognized across different camera views. VLCS <ref type="bibr" target="#b5">[6]</ref>, which requires the domain generalization across different photo datasets. And PACS <ref type="bibr" target="#b15">[16]</ref> which is a more realistic and challenging crossdomain visual benchmark of images with different style depictions.</p><p>Competitors For comparative evaluation we also evaluate the following competitors: The most related alternatives are Undo Bias <ref type="bibr" target="#b13">[14]</ref> and MLDG <ref type="bibr" target="#b14">[15]</ref>, which are the models we extend to realize our sequential learning strategy. We reimplement AGG, DANN, CrossGrad, MetaReg, Undo-Bias and MLDG; and report the numbers stated by MMD-AAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Action Recognition Across Camera Views</head><p>Setup The IXMAS dataset contains 11 different human actions recorded by 5 video cameras with different views (referred as 0,...,4). The goal is to train an action recognition model on a set of source views (domains), and recognize the action from a novel target view (domain). We follow <ref type="bibr" target="#b16">[17]</ref> to keep the first 5 actions and use the same Dense trajectory features as input. For our implementation, we follow <ref type="bibr" target="#b16">[17]</ref> to use a one-hidden layer MLP with 2000 hidden neurons as backbone and report the average of 20 runs. In addition, we normalize the hidden embedding by BatchNorm <ref type="bibr" target="#b11">[12]</ref> as this gives a good start point for AGG.</p><p>Results From the results in <ref type="table" target="#tab_1">Table 1</ref>, we can see that several recent DG methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b16">17]</ref> fail to improve over the strong AGG baseline. Undo-Bias works here, and provides 0.8% improvement. Our extension S-Undo-Bias provides a modest increase of 0.1% on the overall accuracy over vanilla Undo. While the original MLDG <ref type="bibr" target="#b14">[15]</ref> fails to improve on the AGG baseline, our S-MLDG provides a 0.9% gain over MLDG and thus improves 0.6% on AGG. Our FFO-S-MLDG runs on par with S-MLDG, demonstrating the efficacy of our approximator. Overall our S-Undo-Bias, FFO-S-MLDG and S-MLDG all provide a gain in performance over the AGG baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Object Recognition Across Photo Datasets</head><p>Setup VLCS domains share 5 categories: bird, car, chair, dog and person. We use pre-extracted DeCAF6 features and follow <ref type="bibr" target="#b22">[23]</ref> to randomly split each domain into train (70%) and test (30%) and do leave-one-out evaluation. We use a 2 fully connected layer architecture with output size of 1024 and 128 with ReLU activation, as per <ref type="bibr" target="#b22">[23]</ref> and report the average performance of 20 trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In this benchmark, the results in <ref type="table" target="#tab_2">Table 2</ref> show that the simple AGG method works well again. Recent DG methods <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b1">2]</ref> still struggle to beat this baseline. The base DG methods Undo-Bias <ref type="bibr" target="#b13">[14]</ref> and MLDG <ref type="bibr" target="#b14">[15]</ref> work well here, producing comparable results to the state-of-the-art <ref type="bibr" target="#b16">[17]</ref>. Our extensions of these base DG methods, S-Undo-Bias, FFO-S-MLDG and S-MLDG all provide improvements. Overall our S-MLDG performs best, followed closely by S-Undo-Bias and FFO-S-MLDG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Object Recognition Across Styles</head><p>Setup The PACS benchmark <ref type="bibr" target="#b15">[16]</ref> contains 4 domains: photo, art painting, cartoon and sketch and 7 common categories: 'dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house' and 'person'. <ref type="bibr" target="#b15">[16]</ref> showed that this benchmark has much stronger domain shift than others such as Caltech-Office and VLCS. We use a ResNet-18 pre-trained ImageNet as a modern backbone for comparison. We note that MetaReg <ref type="bibr" target="#b1">[2]</ref> used a slightly different setup than the official PACS protocol <ref type="bibr" target="#b15">[16]</ref>, for which their AGG baseline is hard to reproduce. So we stick to the official protocol and rerun MetaReg. To save computational cost, since Undo-Bias and S-Undo-Bias require domain-specific branches that are expensive when applied to ResNet, we only apply these methods to the last ResNet-18 layer -so previous layers are shared as per AGG.</p><p>Results From the results in <ref type="table" target="#tab_3">Table 3</ref>, we can see that: (i) Our sequential learning methods S-Undo-Bias and S-MLDG improve on their counterparts Undo-Bias and MLDG, (ii) FFO-S-MLDG performs comparably with S-MLDG, and (iii) S-MLDG and FFO-S-MLDG perform best overall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Further Analysis</head><p>Analysis for S-MLDG As shown earlier, MLDG and S-MLDG aim to maximize the inner-product between gradients of different source domains. Intuitively, optimizing this gradient alignment will lead to increase domain invariance <ref type="bibr" target="#b7">[8]</ref>. To analyze if this is the case, we use domain-classification loss as a measure of domain invariant feature encoding. We append an additional domain-classifier to the penultimate layer of the original model, creating a domain and category multi-task classifier, where all feature layers are shared. We train the domain classification task for 6000 iterations, then switch to training the category classification task for another 6000 iterations. Using this setup we compare AGG, MLDG and S-MLDG. <ref type="figure" target="#fig_2">From Fig. 2</ref>, we see that the domain-classification loss decreases rapidly in the first phase: the domain is easy to recognise before DG training. In the second phase we switch on categorization and DG training. S-MLDG and MLDG give higher domain classification loss than AGG -indicating that MLDG and S-MLDG learn features that the domain classifier finds harder to distinguish, and hence are the most domain invariant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visualization of Learned Features</head><p>We use t-SNE to visualize the feature embedding of a held-out test domain (V) on VLCS, after training models on L, C and S. From the results in <ref type="figure" target="#fig_3">Fig. 3</ref>, we can see that before training the raw test data points are not separable by category. As baselines we also compare AGG and Naive Ensemble (training an ensemble of domain-specific models and averaging their result) for comparison to the models of interest: MLDG, S-MLDG, FFO-S-MLDG, Undo-Bias and S-Undo-Bias. We can see that all these DG methods exhibit better separability than the two baselines, with S-Undo-Bias and S-MLDG providing the sharpest separation.</p><p>Computational Cost A major contribution of this paper is a DG strategy that is not only effective but simple (Alg. 2) and fast to train. To evaluate this we compare the computational cost of of training various methods on PACS with ResNet-18 for 3k iterations. We run all the methods on a machine with Intel? Xeon(R) CPU (E5-2687W @ 3.10GHz ? 8) and TITAN X (Pascal) GPU. From  the results in <ref type="table" target="#tab_4">Table 4</ref>, we see that CrossGrad is by far the most expensive with S-MLDG in second place. In contrast, our derived FFO-S-MLDG is not noticeably slower than the baseline and lower-bound, AGG. Undo-Bias and S-Undo-Bias run fast due to only applying them into the last layer. But S-Undo-Bias saves training cost over Undo-Bias as explained in B.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We introduced the idea of sequential learning to provide a training regime for a base DG model. This can be seen as generating more unique DG episodes for learning, and as providing more feedback for back-propagation through the chain of domains. Our framework can be applied to different base DG models including Undo-Bias and MLDG. Our final FFO-S-MLDG method provides a simple to implement and fast to train DG method that achieves state of the art results on a variety of benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Analysis of Fast First-order S-MLDG</head><p>If we refer the loss of i th inner-loop step in Alg. 2 as</p><formula xml:id="formula_21">Li = L(D p[i] ,?i)<label>(16)</label></formula><p>where? i are the parameters, the gradient of that step is <ref type="bibr" target="#b16">17)</ref> and updated parameters of that step is</p><formula xml:id="formula_22">gi = ?? i Li = L i<label>(</label></formula><formula xml:id="formula_23">?i+1 =?i ? ?gi<label>(18)</label></formula><p>Then Taylor series of g i at initial point? 1 gives</p><formula xml:id="formula_24">gi =L i (?1 +?i ??1) =L i (?1) + L i (?1)(?i ??1) + O((?i ??1) 2 ) =L i (?1) + L i (?1)(?i ??1) + O(? 2 ) =L i (?1) ? L i (?1) i?1 j=1 ?gj + O(? 2 )<label>(19)</label></formula><p>where the O(? 2 ) items in g i are omitted due to their small effects in ?g i . If we treat the gradient and hessian of L i w.r.t? 1 as? i andH i , we hav?</p><formula xml:id="formula_25">gi = ?Li ??1 = ?Li ??i ??i ??1 = gi ?(?1 ? i?1 j=1 ?gj) ??1 = gi ? O(?)<label>(20)</label></formula><p>Equivalently, we get g i =? i + O(?). Then together withH i , Eq. 19 becomes</p><formula xml:id="formula_26">gi =?i ?Hi( i?1 j=1 ?(?j + O(?))) + O(? 2 ) =?i ? ?Hi i?1 j=1? j + O(? 2 )<label>(21)</label></formula><p>If we consider an example with two source domains D 1 , D 2 . We run FFO-S-MLDG with initial parameters? 1 on D 1 , D 2 recursively, we get two inner-loop steps</p><formula xml:id="formula_27">L1 = L(D1,?1), g1 = ?? 1 L1,?2 =?1 ? ?g1 L2 = L(D2,?2), g2 = ?? 2 L2,?3 =?2 ? ?g2<label>(22)</label></formula><p>after that we get one-step outer-loop gradient,</p><formula xml:id="formula_28">?1 ??3 =?1 ??2 + ?g2 =?1 ??1 + ?g1 + ?g2 = ?(g1 + g2)<label>(23)</label></formula><p>And when we bring Eq. 21 in, we get</p><formula xml:id="formula_29">g1 + g2 =?1 +?2 ? ?H2?1 + O(? 2 )<label>(24)</label></formula><p>then, if we shuffle the order of D 1 , D 2 and run on D 2 , D 1 recursively, we get</p><formula xml:id="formula_30">g2 + g1 =?2 +?1 ? ?H1?2 + O(? 2 )<label>(25)</label></formula><p>Taking the expectation over these two sequences, we get</p><formula xml:id="formula_31">Ep?P [g p[1] + g p[2] ] =?1 +?2 + 1 2 (??H1?2 ? ?H2?1) + O(? 2 )<label>(26)</label></formula><p>The first term? 1 +? 2 in Eq. 26 is the gradient that minimizes the losses on D 1 , D 2 . The second term is</p><formula xml:id="formula_32">1 2 (??H1?2 ? ?H2?1) = ? ? 2 ?(?1 ??2) ??1<label>(27)</label></formula><p>B Application to Undo Bias</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Reinterpreting Vanilla Undo Bias</head><p>Background Undo Bias is a classic domain generalization method that was initially proposed specifically for DG with shallow linear classifiers <ref type="bibr" target="#b13">[14]</ref>, although it has been extended to the multi-linear setting for end-to-end deep learning <ref type="bibr" target="#b15">[16]</ref>. The hypothesis is that classifiers for all domains (datasets) can be modelled as the sum of an underlying domain-agnostic model ? 0 and a domain-specific bias ? i for each domain i. With this assumption, the objective for training on all N source domains in D is,</p><formula xml:id="formula_33">argmin ? 0 ,? 1 ,...? N N i=1 Xi(?0 + ?i ) ? yi 2 2 + ?1 N i=1 ?i 2 2 + ?2 ?0 2 2<label>(28)</label></formula><p>where ? 1 and ? 2 are regularizer weights. After training, the shared parameter ? 0 is assumed to represent a domain-agnostic classifier and used for inference on unseen domains. Reinterpretation We can deduce an equivalent formula to Eq. 28 expressed only in terms of domain-specific models ? i argmin <ref type="bibr" target="#b28">29)</ref> In this equivalent case, the model parameter to use for unseen domains is N i=1 ?i N (i.e., the underlying domain should be close to the mean of the parameters of all source domains). This alternative formulation will be useful for the hierarchical extension later. While the presentation so far is for a regression problem with MSE loss, the general form of Eq. 29 for any loss function L(?) can be written as,</p><formula xml:id="formula_34">? 1 ,...? N N i=1 Xi?i ? yi 2 2 + ?1?2 ?2 + ?1N N i=1 ?i 2 2 + ? 2 1 N ?2 + ?1N N i=1 ?i ? N j=1 ?j N 2 2<label>(</label></formula><formula xml:id="formula_35">argmin ? 1 ,...? N N i=1 L(Di, ?i) + ? ?i ? N j=1 ?j N 2 2 (30)</formula><p>Here we omit the second term in Eq. 29, i.e., the squared 2 norm on parameter, because it is usually realised by weight decay when training a neural network model. And empirically, we find using . 2 for the second item in Eq. 30 is easier to tune.</p><p>Derivation for Eq. 29</p><formula xml:id="formula_36">argmin ?0,?1,...? N N i=1 X i (? 0 + ? i ) ? y i 2 2 + ? 1 N i=1 ? i 2 2 + ? 2 ? 0 2 2<label>(31)</label></formula><p>We denote the objective function in Eq. 31 as L(?, ? 0 ), where we regard the optimal solution for Eq. 31 is ? * and ? * 0 , then we have ?L ??i | ?i=? * i ,?0=? * 0 = 0, ?i ? [1, 2, . . . , N ] and ?L ??0 | ?i=? * i ,?0=? * 0 = 0. Given this solution, we have,</p><formula xml:id="formula_37">X i T (X i ? * i + X i ? * 0 ? y (i) ) + ? 1 ? * i = 0<label>(32)</label></formula><p>and</p><formula xml:id="formula_38">T i=1 X i T (X i ? * i + X i ? * 0 ? y (i) ) + ? 2 ? * 0 = 0<label>(33)</label></formula><p>When we aggregate all Eq. 32, we get,</p><formula xml:id="formula_39">N i=1 X i T (X i ? * i + X i ? * 0 ? y (i) ) + ? 1 N i=1 ? * i = 0<label>(34)</label></formula><p>After the subtraction of the common items in the Eq. 33 and Eq. 34, we get,</p><formula xml:id="formula_40">? * 0 = ? 1 ? 2 N i=1 ? * i<label>(35)</label></formula><p>If we assume for each specific domain i, the parameterized weights are ? i = ? i + ? 0 , then we combine this with Eq. 35, and further obtain that, </p><formula xml:id="formula_41">? * 0 = ? 1 ? 2 + ? 1 N N i=1 ? * i = 1 ?2 ?1 + N N i=1 ? * i<label>(36)</label></formula><formula xml:id="formula_42">N i=1 ? 1 ,? 2 ,...,? N N</formula><p>The obtained Eq. 36 indicates that the shared parameters ? 0 is a (slightly smoothed) average of all the domain-specific parameters ? i . Therefore, we can get</p><formula xml:id="formula_43">argmin ?1,...? N N i=1 X i ? i ? y i 2 2 + ? 1 ? 2 ? 2 + ? 1 N N i=1 ? i 2 2 + ? 2 1 N ? 2 + ? 1 N N i=1 ? i ? N j=1 ? j N 2 2 (37)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Sequential Undo Bias</head><p>Vanilla Undo Bias aims to learn an underlying domain-agnostic model with one optimization on a fixed set of source domains (Section B). To instantiate our proposed framework (Eq. 2) for Undo Bias, we need to extend it to sequential learning. Intuitively, for a given sequence of training domains, we should learn an underlying domain from the first two, and then update this when the third domain comes in, etc. Building on the Undo-Bias formulation in Eq. 30, we define the objective:</p><formula xml:id="formula_44">L S-Undo-Bias =Ep?P L(D p[1] , ? p[1] ) + N i=2 L(D p[i] , ? p[i] ) + ? ? p[i] ??i) 2 2 (38)</formula><p>where p is a path through all possible permutations of domains P, and i ? p iterates over that path.? i is the running average over the parameters in the path before it arrives at ? p[i] , i.e.,? i =</p><formula xml:id="formula_45">i?1 j=1 ? p[j] i?1 .</formula><p>The first term is not directly path-dependent, but it becomes so via shared parameters with the second path-dependent term. In this objective, when training ? i for domain i, backpropagation also updates all domains in the path before domain i. We term this procedure Sequential Undo Bias. And its algorithm flow is shown in Alg. 3.</p><p>To unpack Eq. 38, we use a length-3 path example. The objective function is then: was fixed after training ? p <ref type="bibr" target="#b0">[1]</ref> and ? p <ref type="bibr" target="#b1">[2]</ref> then this would be simple regularization of ? p <ref type="bibr" target="#b2">[3]</ref> training by the Undo Bias source (fifth term regularizer). But backpropagating means that ? p <ref type="bibr" target="#b0">[1]</ref> and ? p <ref type="bibr" target="#b1">[2]</ref> are trained so as not only to solve their domains in an Undo Bias way, but also to help learn ? p <ref type="bibr" target="#b2">[3]</ref> . This is a DG 'practice' for the first trained domainsspecific parameters. Finally, the optimization should be applied for all possible permutations of <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>. In this example ?1+?2+?3 3 would then be used as the final Undo Bias model for the true testing domain. And as the sequential path goes deeper, the former ranking domains get more 'practices'.</p><formula xml:id="formula_46">L S-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computational Cost</head><p>The difference between Undo-Bias and S-Undo-Bias can be found by comparing Eq. 30 and Eq. 38. We can see the computational difference happens in the second terms in the objective functions. In vanilla Undo-Bias, each domain-specific parameter would have a L2 loss to minimize its difference to the mean of all domain-specific parameters. But in S-Undo-Bias, due to the hierarchical structure, each domain would have the same L2 loss to the parameters of the traversed domains. If we regard the computational complexity of the L2 loss of n domain-specific parameters as O(n), the computational complexity for the second item of S-Undo-Bias is n?1 i=2 O(i), which is smaller than that of Undo-Bias nO(n). So, due to the hierarchical learning, S-Undo-Bias saves computation over Undo-Bias. This is proved in the training cost comparison in <ref type="table" target="#tab_4">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Validation of Reformulated (S)-Undo-Bias</head><p>We validate our reformulated Undo-Bias and S-Undo-Bias on VLCS by comparison to a naive ensemble, which trains all the domain specific branches separately and uses fused ensemble of models at inference. The comparison in <ref type="figure" target="#fig_4">Fig. 4</ref> shows that both Undo-Bias and S-Undo-Bias learn better solutions than the simple ensemble of domain-specific models. This shows that the performance gains of our reformulated Undo-Bias and S-Undo-Bias are not merely due to the model ensemble.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Training Hyper Parameters</head><p>We can set different ? and ? (=1 by default) for different inner loops in Alg. 1 and 2 and refer ? i and ? i as the coefficients in the i th inner loop. We use M-SGD with momentum=0.9, weight decay=0.00005. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Work done while DL was at SketchX arXiv:2004.01377v1 [cs.CV] 3 Apr 2020</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>Schematic illustration of our domain generalization training framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Domain classification loss analysis on VLCS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>T-SNE visualization of different models' embeddings of VLCS held-out test data (V) after training on (LCS). Colors represent object categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>IXMASFig. 4 :</head><label>4</label><figDesc>Validation of reformulated (S)-Undo-Bias. -S-MLDG: ? 1 =? 2 =? 3 =0.9, ?=0.001 and ? 4 =2.0. -FFO-S-MLDG: ? 1 =? 2 =? 3 =1.0, ?=0.9 and ? 4 =1.1. -S-Undo-Bias: ?=0.005 and ?=1000.0. VLCS -S-MLDG: ? 1 =0.05, ? 2 =0.6, ?=0.001 and ? 3 =1.2. -FFO-S-MLDG: ? 1 =? 2 =0.3, ?=0.01 and ? 3 =1.5. -S-Undo-Bias: ?=0.01 and ?=50.0. PACS -S-MLDG: ? 1 =? 2 =0.002, ?=0.001 and ? 3 =1.85. -FFO-S-MLDG: ? 1 =? 2 =0.01, ?=0.9 and ? 3 =1.75. -S-Undo-Bias: ?=0.001 and ?=100.0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The framework is DG-algorithm agnostic in that does not stipulate which DG algorithm should be used at each step. Any base DG algorithm which can be sequentially updated could be used. In this paper we show how to instantiate this idea for both Undo Bias<ref type="bibr" target="#b13">[14]</ref> and MLDG<ref type="bibr" target="#b14">[15]</ref> DG algorithms.Vanilla MLDG already optimizes an expectation over meta-train/meta-test splits over the source domains (Section 3.1). At every iteration, it randomly samplesAlgorithm 1: S-MLDG: Sequential Learning MLDG Input:D = [D1, D2, . . . , DN ] N source domains. Initialize: ?, ? ,? and ? while not done training do</figDesc><table><row><cell>4.1 Sequential Learning MLDG (S-MLDG)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Performance on IXMAS action recognition. Leave one camera-view out. Accuracy (%).</figDesc><table><row><cell>4</cell><cell>79.1</cell><cell>80.0</cell><cell>81.6</cell><cell>78.4</cell><cell>79.3</cell><cell>80.7</cell><cell>82.7</cell><cell>79.4</cell><cell>81.1</cell><cell>80.1</cell></row><row><cell>3</cell><cell>94.5</cell><cell>94.5</cell><cell>94.5</cell><cell>94.2</cell><cell>94.5</cell><cell>95.3</cell><cell>94.9</cell><cell>95.2</cell><cell>95.1</cell><cell>95.0</cell></row><row><cell>2</cell><cell>95.6</cell><cell>99.8</cell><cell>100.0</cell><cell>100.0</cell><cell>99.8</cell><cell>99.9</cell><cell>100.0</cell><cell>99.9</cell><cell>100.0</cell><cell>99.8</cell></row><row><cell>1</cell><cell>93.4</cell><cell>93.4</cell><cell>91.7</cell><cell>94.0</cell><cell>92.5</cell><cell>94.8</cell><cell>94.0</cell><cell>95.2</cell><cell>93.1</cell><cell>96.2</cell></row><row><cell>0</cell><cell>96.7</cell><cell>93.5</cell><cell>93.5</cell><cell>91.2</cell><cell>92.8</cell><cell>94.2</cell><cell>93.9</cell><cell>90.4</cell><cell>94.3</cell><cell>92.7</cell></row><row><cell>Ave.</cell><cell>91.9</cell><cell>92.2</cell><cell>92.3</cell><cell>91.6</cell><cell>91.8</cell><cell>93.0</cell><cell>93.1</cell><cell>91.9</cell><cell>92.7</cell><cell>92.8</cell></row></table><note>Unseen MMD-AAE [17] AGG DANN[8] CrossGrad [35] MetaReg [2] Undo-Bias [14] S-Undo-Bias MLDG [15] FFO-S-MLDG S-MLDG</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Performance on VLCS object recognition. Leave one dataset out. Accuracy (%).</figDesc><table><row><cell cols="11">Unseen MMD-AAE[17] AGG DANN [8] CrossGrad [35] MetaReg [2] Undo-Bias[14] S-Undo-Bias MLDG [15] FFO-S-MLDG S-MLDG</cell></row><row><cell>V</cell><cell>67.7</cell><cell>65.4</cell><cell>66.4</cell><cell>65.5</cell><cell>65.0</cell><cell>68.1</cell><cell>68.7</cell><cell>67.7</cell><cell>68.1</cell><cell>68.7</cell></row><row><cell>L</cell><cell>62.6</cell><cell>60.6</cell><cell>64.0</cell><cell>60.0</cell><cell>60.2</cell><cell>60.3</cell><cell>61.8</cell><cell>61.3</cell><cell>63.1</cell><cell>64.8</cell></row><row><cell>C</cell><cell>94.4</cell><cell>93.1</cell><cell>92.6</cell><cell>92.0</cell><cell>92.3</cell><cell>93.7</cell><cell>95.0</cell><cell>94.4</cell><cell>94.8</cell><cell>96.4</cell></row><row><cell>S</cell><cell>64.4</cell><cell>65.8</cell><cell>63.6</cell><cell>64.7</cell><cell>64.2</cell><cell>66.0</cell><cell>66.1</cell><cell>65.9</cell><cell>65.2</cell><cell>64.0</cell></row><row><cell>Ave.</cell><cell>72.3</cell><cell>71.2</cell><cell>71.7</cell><cell>70.5</cell><cell>70.4</cell><cell>72.0</cell><cell>72.9</cell><cell>72.3</cell><cell>72.8</cell><cell>73.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Performance on PACS object recognition across styles (ResNet-18). Accuracy (%). MLDG: A recent DG method that is model-agnostic and meta-learns the domain-generalizable model parameters.</figDesc><table><row><cell cols="10">Unseen AGG DANN [8] CrossGrad [35] MetaReg [2] Undo-Bias [14] S-Undo-Bias MLDG [15] FFO-S-MLDG S-MLDG</cell></row><row><cell>A</cell><cell>77.6</cell><cell>81.3</cell><cell>78.7</cell><cell>79.5</cell><cell>78.4</cell><cell>80.6</cell><cell>79.5</cell><cell>80.0</cell><cell>80.5</cell></row><row><cell>C</cell><cell>73.9</cell><cell>73.8</cell><cell>73.3</cell><cell>75.4</cell><cell>72.5</cell><cell>76.2</cell><cell>77.3</cell><cell>77.4</cell><cell>77.8</cell></row><row><cell>P</cell><cell>94.4</cell><cell>94.0</cell><cell>94.0</cell><cell>94.3</cell><cell>92.8</cell><cell>94.1</cell><cell>94.3</cell><cell>94.6</cell><cell>94.8</cell></row><row><cell>S</cell><cell>70.3</cell><cell>74.3</cell><cell>65.1</cell><cell>72.2</cell><cell>73.3</cell><cell>72.2</cell><cell>71.5</cell><cell>73.8</cell><cell>72.8</cell></row><row><cell cols="2">Ave. 79.1</cell><cell>80.8</cell><cell>77.8</cell><cell>80.4</cell><cell>79.3</cell><cell>80.8</cell><cell>80.7</cell><cell>81.4</cell><cell>81.5</cell></row><row><cell cols="10">-AGG: A simple but effective baseline of aggregating all source domains'</cell></row><row><cell></cell><cell cols="3">data for training [16].</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">-DANN: Domain adversarial neural networks learns a domain invariant rep-</cell></row><row><cell></cell><cell cols="8">resentation such that source domains cannot be distinguished [8].</cell><cell></cell></row><row><cell cols="10">-MMD-AAE: A recent DG method which combines kernel MMD and the</cell></row><row><cell></cell><cell cols="4">adversarial auto encoder [17].</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>-CrossGrad: A recently proposed strategy that learns the manifold of train- ing domains, and uses cross-gradients to generate synthetic data that helps the classifier generalize across the manifold [35].-MetaReg: A latest DG method by meta-learning a regularizer constraining the model parameters to be more domain-generalizable [2].-Undo-Bias: Undo-Bias models [14] each training domain as a linear combi- nation of a domain-agnostic model and domain-specific bias, and then uses the domain-agnostic model for testing. We use the vanilla deep generalization of Undo-Bias explained in [16].-</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Training cost (mins) for PACS with ResNet-18.</figDesc><table><row><cell>AGG</cell><cell>DANN [8]</cell><cell cols="3">CrossGrad [35] MetaReg [2] MLDG [15]</cell></row><row><cell>10.98</cell><cell>11.35</cell><cell>146.51</cell><cell>20.01</cell><cell>49.77</cell></row><row><cell></cell><cell>FFO-S-MLDG</cell><cell>S-MLDG</cell><cell cols="2">Undo-Bias [14] S-Undo-Bias</cell></row><row><cell></cell><cell>11.04</cell><cell>72.64</cell><cell>11.16</cell><cell>11.01</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Algorithm 3: S-Undo-Bias: Sequential Undo Bias Input:D = [D1, D2, . . . , DN ] Initialize: ?, ? and [?1, ?2, . . . , ?N ] while not done training do p = shuffle([1, 2, . . . , N ]) //Randomly sample a trajector? D = [D1,D2, . . . ,DN ] //Sample a mini-batchDi for each domain Di L = L(D p[1] , ? p[1] ) for i in [2, 3, . . . , |p|] do</figDesc><table><row><cell>L += L(D p[i] , ? p[i] ) + ? ? p[i] ?</cell><cell>i?1 j=1 ? p[j] i?1</cell><cell>2 2</cell></row><row><cell>end</cell><cell></cell><cell></cell></row><row><cell>//One-step S-Undo-Bias update</cell><cell></cell><cell></cell></row><row><cell>Update ?i := ?i ? ?? ? i L</cell><cell></cell><cell></cell></row><row><cell>end</cell><cell></cell><cell></cell></row><row><cell>Output:</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Undo-Bias-3 = Ep?P L(D p[1] , ? p[1] ) +L(D p[2] , ? p[2] ) + ? ? p[2] ? ? p[1]This says: train vanilla Undo Bias on the first two domains (first three terms), and then incrementally train Undo Bias for the third domain (fourth and fifth term). If the first Undo Bias model</figDesc><table><row><cell></cell><cell>2</cell><cell></cell></row><row><cell></cell><cell>2</cell><cell>(39)</cell></row><row><cell>+L(D p[3] , ? p[3] ) + ? ? p[3] ?</cell><cell>? p[1] + ? p[2] 2</cell><cell>2 2</cell></row><row><cell>? p[1] +? p[2]</cell><cell></cell><cell></cell></row><row><cell>2</cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Metareg: Towards domain generalization using meta-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7378-metareg-towards-domain-generalization-using-meta-regularization.pdf" />
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Multi-task self-supervised visual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rockmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<title level="m">Domain-adversarial training of neural networks</title>
		<imprint>
			<publisher>JMLR</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Reinforcement learning with unsupervised auxiliary tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Undoing the damage of dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Coupled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Unsupervised domain adaptation with residual transfer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Gradient episodic memory for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Best sources forward: Domain generalization through source-specific nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;apos;</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICIP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">ICML</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">Meta networks. In: ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<title level="m">On first-order meta-learning algorithms. arXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Curriculum learning of multiple tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pentina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sharmanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Lifelong learning with non-i.i.d. tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pentina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Ella: An efficient lifelong learning algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ruvolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eaton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">ICML</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Asymmetric tri-training for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Maximum classifier discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Shifting inductive bias with successstory algorithm, adaptive levin search, and incremental self-improvement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wiering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">On learning how to learn learning strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Generalizing across domains via cross-gradient training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Object name learning provides on-the-job training for attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Landau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gershkoff-Stowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Samuelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<title level="m">Deep domain confusion: Maximizing for domain invariance. arXiv</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Transfer learning via learning to transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Free viewpoint action recognition using motion history volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weinland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ronfard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Boyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVIU</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Exploiting low-rank structure from latent domains for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Learning a synaptic learning rule</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Cloutier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>IJCNN</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
