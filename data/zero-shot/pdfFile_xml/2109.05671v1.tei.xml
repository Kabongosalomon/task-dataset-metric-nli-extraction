<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Shape-Biased Domain Generalization via Shock Graph Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maruthi</forename><surname>Narayanan</surname></persName>
							<email>maruthi.narayanan@jhuapl.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University Applied Physics Laboratory Laurel</orgName>
								<address>
									<postCode>20723</postCode>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vickram</forename><surname>Rajendran</surname></persName>
							<email>vickram.rajendran@jhuapl.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University Applied Physics Laboratory Laurel</orgName>
								<address>
									<postCode>20723</postCode>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Kimia</surname></persName>
							<email>benjaminkimia@brown.edu</email>
							<affiliation key="aff1">
								<orgName type="department">School of Engineering</orgName>
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Shape-Biased Domain Generalization via Shock Graph Embeddings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There is an emerging sense that the vulnerability of Image Convolutional Neural Networks (CNN), i.e., sensitivity to image corruptions, perturbations, and adversarial attacks, is connected with Texture Bias. This relative lack of Shape Bias is also responsible for poor performance in Domain Generalization (DG). The inclusion of a role of shape alleviates these vulnerabilities and some approaches have achieved this by training on negative images, images endowed with edge maps, or images with conflicting shape and texture information. This paper advocates an explicit and complete representation of shape using a classical computer vision approach, namely, representing the shape content of an image with the shock graph of its contour map. The resulting graph and its descriptor is a complete representation of contour content and is classified using recent Graph Neural Network (GNN) methods. The experimental results on three domain shift datasets, Colored MNIST, PACS, and VLCS demonstrate that even without using appearance the shape-based approach exceeds classical Image CNN based methods in domain generalization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The incredible success of deep learning methods has outpaced our understanding of how they work. An avalanche of new Convolutional Neural Networks (CNN) methods, many with computer vision applications, have been developed in the context of improving performance without a simultaneous development of fundamental understanding of its mechanisms. This has side-lined an integration with the traditional classical AI/computer vision approaches and cognitive science studies. The insight from the classical methods on representation and search is ignored mainly because it is not clear how to integrate the two paradigms: one of developing representations based on feedback from degree of success <ref type="bibr" target="#b42">[43]</ref>, and one on developing representations based on the more classic geometric and world scene reasoning <ref type="bibr" target="#b52">[53]</ref>.</p><p>Hand in hand with the continued success of CNNs in difficult problems such as image classification <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b59">60]</ref>, their vulnerabilities have also been identified. Image CNNs struggle with "domain shift" i.e., when the training conditions (resolutions, sensors, etc.) do not match the conditions of the operating domain. Small corruptions e.g., noise, blur, fog, etc., and perturbations which do not affect human perception <ref type="bibr" target="#b1">[2]</ref> affect the performance of Image CNNs as benchmarked by <ref type="bibr" target="#b33">[34]</ref>. In particular, when these small changes are adversarial, i.e., targeted to the architecture of the CNN for maximal effect <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b11">12]</ref>, the performance can be seriously affected (adversarial attack).</p><p>There is an emerging understanding that underlying these vulnerabilities is a lack of representation of shape. While initially it was argued, e.g., by visualizations in <ref type="bibr" target="#b77">[78]</ref>, that Image CNNs construct low-level primitives such as corners and edges in lower layers, which in turn lead to more complex shapes in higher layers <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b40">41]</ref> there is increasing evidence that appearance (texture bias) and not global shape (shape bias) is the cornerstone of correct classification by CNNs <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b65">66]</ref>. Baker et al <ref type="bibr" target="#b2">[3]</ref> explored the role of object shape in CNNs trained for image classification and found that the global object shape, which is arguably the most important cue for human categorization of objects, is not represented. Similarly, Geirhos et al. <ref type="bibr" target="#b24">[25]</ref> show that Image CNNs only rely on object texture rather than object shape and show how with proper training the introduction of a shape bias improves performance. In the field of cognitive science, Malhotra and Bowers <ref type="bibr" target="#b51">[52]</ref> systematically explore the impact of non-shape features in the categorization performance of CNNs on the CIFAR-10 <ref type="bibr" target="#b41">[42]</ref> dataset. They conclude that even though the CNN mimics the hierarchical architecture and learning processes of biological vision, they pick up optimal features to perform prediction which do not include shape. They conjecture that the lack of an intrinsic shape bias in a typical Image CNN architecture can be the key to susceptibility to adversarial attacks. Zhang and Zhu <ref type="bibr" target="#b78">[79]</ref> find that adversarially trained networks are less texture-biased and more shape-biased. More re-arXiv:2109.05671v1 [cs.CV] 13 Sep 2021 cently <ref type="bibr" target="#b3">[4]</ref> shows that CNNs performance is an inversion of human performance with respect to global and local shape priors in that Image CNNs capture only local shape information while humans capture absolute shape information. See also <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b74">75]</ref>. The shape of an object as captured by a binary mask of the images. c) The shock graph of the contour map colored in green (shock dynamics are not shown). We encourage readers to zoom in.</p><p>Shape is an object constancy that dominates object texture, <ref type="figure">Figure 1</ref>, and is invariant to image corruption or perturbation. Observe in <ref type="figure">Figure 2a</ref>, that the objects in the images taken from standard domain generalization datasets exhibit significant variation in color and/or texture. Observe that after delineation of the object of interest, <ref type="figure">Figure 2b</ref>, the variation in shape is much less than the appearance. This concept of "shape constancy" has long been a pillar of classic computer vision and recognized as one of the most important cues in biological object recognition <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. We conjecture that the strong bias of Image CNNs to texture cues coupled with the inability to capture global shape cues is limiting their capability to generalize. Several researchers have aimed to increase the shape bias of CNNs, for example by training on negative images which preserve shape but not appearance <ref type="bibr" target="#b34">[35]</ref>. Borji augments the training by including edge maps <ref type="bibr" target="#b8">[9]</ref>. Li et al. <ref type="bibr" target="#b50">[51]</ref> augment training data with images with conflicting shape and texture information, e.g., an image of chimpanzee shape but with lemon texture, under simultaneous shape and texture supervision to develop each independently. It is clear from these studies that the enhancing and emphasizing the shape cue in the training process improves performance.</p><p>This paper advocates a complete and explicit representation of shape. Instead of forcing the Image CNN to learn shape indirectly, shape is directly extracted and represented based on the most advanced understanding of classical computer vision. In other words, each image is augmented with an explicit representation of its shape content. In fact, the image itself is discarded for the purpose of this study and we solely train on the explicit shape representation to completely characterize how far image classification can proceed on a shape-only platform.</p><p>The segmented images in <ref type="figure">Figure 2b</ref> represent the canonical definition of "shape" in the computer vision community. Shape descriptors aim to capture regional and/or boundary properties of this binary shape. A sampling of popular descriptors include shape context <ref type="bibr" target="#b54">[55]</ref>, medial axis descriptors <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b72">73]</ref>, and shape tree <ref type="bibr" target="#b22">[23]</ref>, just to name a few among many. The vast majority of approaches then rely on some form of assignment or graph matching algorithms to define a distance, and that distance is subsequently used in shape classification pipelines. The medial axis <ref type="bibr" target="#b7">[8]</ref> of a segmented shape is a particular favorite as it captures invariances for many deformations.</p><p>Since segmentation itself is a difficult problem, the notion of shape must be surmised directly from edges or regions. The shock graph <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b26">27</ref>], a refinement of medial axis descriptors, has made the leap from binary images to real images <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref>. Observe in <ref type="figure">Figure 2c</ref>, the shock graph of the original images, <ref type="figure">Figure 2a</ref>, captures the "skeleton" of these various elephants. We can see the delineation of the various common parts of the elephant, distinctive trunk and legs, shared among all elephant exemplars despite originating from disparate domains. Further motivating factors for why we use the shock graph is that it is robust to articulations and occlusion of the underlying shape which are more common in realistic image acquisition settings. Its state of the art performance on standard shape datasets <ref type="bibr" target="#b63">[64]</ref> is an additional reason to use it in this research.</p><p>The shock graph is a complete representation of image contours in that they can be reconstructed back from the shock graph, which encodes both the axis and the dynamics along the axis. In this sense the shock graph is a complete representation of the object contours embedded in an image. Thus, training can take place on the shock graph instead of the original image. Observe, however, that the image pixel topology is now replaced with a graph topology. Recent advancements in Graph Neural Networks (GNN) <ref type="bibr" target="#b76">[77,</ref><ref type="bibr" target="#b79">80]</ref> can capture the information in the graph for the purpose of classification. Specifically, our pipeline is one of transforming the image to an edge map, a contour map, and then a shock graph which is subsequently trained on using a graph neural network for classification. This represents a novel use of graph neural networks as the vast majority of applications of graph neural networks have focused on graph machine learning tasks (node labeling, edge labeling, and graph classification) predominantly for social networks or in chemistry with molecule graphs. We show that this representation of shape information via a shock graph and using GNN to train on them leads to excellent classification performance, even though the appearance is not taken into account. Future work will likely enhance this performance further when both cues are utilized.</p><p>Our contributions can be summarized as follows. 1) To the best of our knowledge the first paper to revisit classic shape descriptors in a modern setting for domain generalization 2) A novel approach of using an image-to-graph transformation instead of the traditional Image CNN input. 3) Combining shock-graphs with graph neural networks to achieve state of the art graph classification performance comparable to the image classification performance achieved by standard Image CNN architectures. 4) A novel image-to-graph framework that shows the power of the shape bias, with the potential to integrate texture cues. From a high-level perspective, the paper also shows that it is possible to bring to bear lessons learned from classical computer vision in the context of modern deep learning techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Domain generalization approaches aim to generalize models to unseen target domains without having any prior information about the target distribution during training. Due to the challenging nature of this problem a wide variety of methods have been tried. From a high-level, DG methods can roughly be organized into one of three families: 1) domain invariant features 2) data augmentation and finally 3) optimization algorithms. We do not claim this taxonomy exhaustive or unique, as many methods may fall into one or more or none of the paradigms, but rather as a way to cover the vast majority of research in this field.</p><p>Learning domain invariant features <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b36">37]</ref> represents the most popular approach to the problem. The intuition being that if we can learn a domaininvariant representation across multiple disparate source domains that this representation will translate well to the target too. Methods such as <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b56">57]</ref> develop learning algorithms that optimize the maximum mean discrepancy (MMD) or variations of it to minimize the feature dissimilarity across multiple domains. Similar to those approaches <ref type="bibr" target="#b49">[50]</ref> also tries to regularize the features space, but utilizes a probabilistic framework to minimize the joint discrepancy of labels and inputs across multiple domains. The contrastive loss is used in <ref type="bibr" target="#b55">[56]</ref> to encourage features from similar classes across multiple domains to cluster in the latent space. The work of <ref type="bibr" target="#b25">[26]</ref> on the other hand utilizes a multi-task auto encoder to directly extract out invariant features robust enough to domain changes. The previous approaches relied on some form of feature-space regularization across domains, while the works of <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b36">37]</ref> alter the model architecture to achieve invariance. <ref type="bibr" target="#b43">[44]</ref> uses a lowrank parametrized CNN. The approach of <ref type="bibr" target="#b36">[37]</ref> decomposes ML models into their domain specific and invariant components to reduce domain shift.</p><p>Data augmentation techniques <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b59">60]</ref> rely on the underlying assumption that more data will lead to more generalizable models and less overfitting. <ref type="bibr" target="#b64">[65]</ref> generates new data samples through gradient perturbations, while <ref type="bibr" target="#b73">[74]</ref> generates adversarial perturbed samples. The recent work of <ref type="bibr" target="#b12">[13]</ref> effectively increases the data by viewing the domain generalization problem of one as puzzle solving where the pieces are the various numerous squares within the source domain images.</p><p>Optimization approaches <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b17">18]</ref> aim to modify traditional learning schemes in domain generalization to achieve a more robust solution during training. The most popular approach is to leverage meta-learning for domain generalization. Specifically the episodic training paradigm, originating from model-agnostic meta-learning (MAML) <ref type="bibr" target="#b23">[24]</ref> has been repurposed to specifically address domain generalization in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b17">18]</ref>. The work <ref type="bibr" target="#b44">[45]</ref> can be seen as direct adaptation of MAML <ref type="bibr" target="#b23">[24]</ref> for domain generalization. While the approach of <ref type="bibr" target="#b46">[47]</ref> uses an episodic training scheme to alternate learning domain specific features/classifiers across domains, it ignores the innergradient update. In <ref type="bibr" target="#b4">[5]</ref> the feature extractor and classifier are treated separately where the classifier is regularized according to a learned function the feature extractor remains the same. The approach of <ref type="bibr" target="#b17">[18]</ref> can be seen as hybrid approach as it incorporates semantic feature space knowledge into the meta-learning process.</p><p>There has been minimal work in the last few years as it relates to the shock graph. Recent work has focused exclusively on computational algorithms to compute the shock graph/medial axis <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b70">71]</ref> from real images with no further applications to computer vision tasks. Different from previous works, our is the first to combine the shock graph with recent advancements in graph based deep learning , with applications to domain generalization. Our approach to domain generalization falls under the invariant-feature approach. Given that our work proposes a new feature ex-tractor it can be used in any family of methods i.e. drop in replacement for Image CNN features. The other major distinction with our work compared to others is the use of Graph Neural Networks. We are not aware of any other works using GNNs in the DG area. We don't claim a novel new GNN architecture but rather the novelty of applying to the problem of domain generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Shock Graph</head><p>The medial axis is a popular region-based description of shape. <ref type="figure">Figure 3</ref> shows the medial axis of a simple closed contour, which is defined as the closure of the set of centers of the contour's maximal circles. The shock graph <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b26">27]</ref>, a refinement of the Medial Axis, arises from viewing the medial axis as the locus of singularities (shocks) formed in the course of wave propagation (grassfire) from contour boundaries, <ref type="figure">Figure 3</ref>. During this wave propagation process, the edges and nodes that comprise the shock graph are formed. At each step, the interaction of waves emanating from contour elements quench at shock edges i.e. bisector of curves. Shock edges are the valid portion of these infinite bisector curves, and nodes are formed where endpoints of curves interact and/or bisector curves intersect. Further details about the computational algorithm can be found in the supplementary material. The resulting shock graph, at the end of this process is a richer descriptor of the contour map than the medial axis as it allows us to refine the classification of nodes/edges according to the underlying dynamics of wave propagation as well as the presence or absence or shock edges/nodes which identify interacting contour pairs and triplets. This graph capturing the relationship between contours is our proposed "shape" cue for domain generalization. Formally, Definition 1 The shock graph is a directed attributed relational graph, G = (V, E, A), where V is the vertex set of shock nodes, E is the edge set of shock segments, and A is the continuous intrinsic geometry and classification labels, specifically A is the set of unary attributes a i attached to each vertex v i ? V , namely normal, tangent, time of formation and discrete labels sink, source, or junction. The shock link binary attributes a ij attached to each e k = (v i , v j ) ? E consist of length, curvature, and acceleration and discrete labels degenerate, semi-degenerate, or regular.</p><p>Our intuition for using the shock graph for domain generalization can be seen in in <ref type="figure" target="#fig_1">Figure 4</ref>. Despite drastic differences in visual appearances we qualitatively observe that the shock graph 4c, remains roughly the same even as we vary the domain. Furthermore, observe that the shock graphs of the various giraffes capture the common parts, distinctive neck and legs, shared among all giraffe exemplars. We argue that this type of shape information is needed <ref type="figure">Figure 3</ref>. A closed contour in black and the resulting medial axis and shock graph delineated in blue/red. From <ref type="bibr" target="#b27">[28]</ref>. The advantage of the shock graph over medial axis is its qualitative description of the boundary: given a medial axis segment any of the six shapes in the top row can occur, while a shock graph segment (a monotonically flowing subsegment of the medial axis) qualitatively represents one type of shape. to bridge the domain gap. Also observe that texture cues such as the distinctive spots manifest as loops in the shock graph. Thus, the shock graph provides a rich descriptor of the global shape, and as shown in this giraffe case, the very distinctive surface texture. The shock graph is not limited to prominent shapes in an image. General scenes have a natural implicit shape or texture images contain repeating shape patterns which can also be captured by the shock graph.</p><p>Our quantitative framework then relies on defining an appropriate distance between shock graphs and subsequently using that in classification. Previous approaches defined a pairwise distance as the cost of transforming one shock graph to another using the edit distance algorithm <ref type="bibr" target="#b63">[64]</ref>. We instead rely on the very popular state of the art approach of graph neural networks (GNN) to learn shock graph embeddings and subsequently classify them.</p><p>Graph neural networks are a very large and growing field, and a full discussion of the architectures, methods, and challenges are beyond the scope of the paper. We refer the reader to two excellent surveys <ref type="bibr" target="#b76">[77,</ref><ref type="bibr" target="#b79">80]</ref> covering the field. We give a brief overview of GNNs and discuss the relevant aspects as it pertains to this paper. Identical to their Image CNN counterparts, GNNs mimic the same operations such as convolution, and pooling to extract information from the graph. For example, analogous to image based 2D convolution, graph convolution can be expressed as a weighted linear combination of neighborhood node information. We can make the weights (possibly bias) learnable coupled with non-linear activation functions to achieve a functionality similar to standard Image CNN convolutional layers. The stacking of such blocks, SoftMax of final layer output, and a cross-entropy loss function leads to a GNN architecture capable of performing node labeling, edge labeling, or graph classification. Differences in Convolution GNN architectures primarily alter how neighboring node information is aggregated (mean, max, sum, etc.) and how the neighborhood is defined (1 hop, 2 hops, etc.) for a node under consideration. Finally, in order to use shock graphs in a Convolutional GNN framework we need to augment each node or possibly edge with an initial fixed length feature vector.</p><p>Feature selection: Given a vertex v, graph convolutional layers generate the node's representation by aggregating its own features h v , and its neighboring features h u where u ? N (v) where N represents the neighborhood. Stacking multiple graph convolution layers aggregates and extracts higher level node information. Initially, a starting set of features need to be assigned to each node. The analogy in Image CNN is the three channel RGB value attached to each pixel location of the input. We assigned each node and edge a set of first order geometric properties, <ref type="figure" target="#fig_3">Figure 5</ref>  Observe in <ref type="figure" target="#fig_3">Figure 5a</ref> a typical degree two node. Each shock edge (bisector) is associated with the two contours, B + and B ? , that gave rise to it. Each node of an edge is also paired with the two interacting points on the curve, bp + and bp ? , which represent the boundary points tangent to the maximally inscribed circle of radius r. A feature vector, h u , consisting of the following is assigned to each node:</p><formula xml:id="formula_0">h u = (x, y, r, l, ?, ?, ?)<label>(1)</label></formula><p>where (x, y) specifies the position of the shock node, r is the shock radius, l is a label of the type (sink,source,junction) of node, ? is the angle of the tangent to the shock curve, and ? represents the angle between the shock tangents and normals. ? represents the set of oriented boundary points bp + and bp ? which are endowed with a position (x, y) and tangent ? respective to their associated boundaries. For a degree two node then, we have six node features and six boundary point features leading to a feature vector of length twelve. A degree three node is associated with a triplet of interacting contours, leading to an increase in the number of shock edge tangents, shock edge normals, and boundary points to three. Different from many of the graphs used in the GNN literature is that the shock graph is endowed with edge features. <ref type="figure" target="#fig_3">Figure 5b</ref> shows the local picture of each edge. Each shock edge is assigned a feature vector h e consisting of the following:</p><formula xml:id="formula_1">h e = (s, ?, a, l, ?)<label>(2)</label></formula><p>where s refers to the arc-length, ? the curvature of the shock edge, a the area spanned by the shock edge and its two boundaries, l is the label of the type (degenerate, semidegenerate, regular) <ref type="bibr" target="#b27">[28]</ref> of edge, and finally ? refers to the properties associated with the pair of boundary curves leading rise to that particular shock edge. ? represents the set of curve properties, arc-length s and curvature ?, associated with each of the respective contours B + and B ? . This leads to an eight-dimensional vector composed of the four attributes attached to each shock edge coupled with the curve properties of the pair of boundaries. Our intuition for using edge features derives from the fact that the contours associated with each shock link provide a strong shape cue. For example, we would expect images of cars and chairs to exhibit many straights lines leading to low curvature values while natural images of dogs and giraffes to exhibit higher values due to the presence of wavy and circular smooth contours. How to properly exploit edge features is still an open problem in the GNN community, and while there is some minimal work on the problem, we found the simplest way of just attaching edge features to each node to be most effective. For example, a degree two node would have a node feature vector h u of length twelve coupled with two edge feature vectors h e of length eight leading to a twenty-eight dimensional feature vector. A difficulty with this is that nodes of varying degree will have a different feature vector length. To deal with this, we zero pad the feature vectors to a fixed length of fifty-eight so that it covers nodes with degrees varying from two to four.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head><p>Our approach comprises two algorithmic steps: computation of the individual image shock graphs across a dataset and subsequently training/evaluating a graph neural net-work on this collection. Given an input image we initially compute an edge map using the Structured Forest approach of <ref type="bibr" target="#b16">[17]</ref>. The orientation of the edges are corrected using the third-order approach of <ref type="bibr" target="#b67">[68]</ref>. These edges are subsequently grouped into contour fragments (ordered set of edges) utilizing <ref type="bibr" target="#b31">[32]</ref>. The resulting set of contour fragments, typically on the order of eighty to hundred, are fed into the computational algorithm of <ref type="bibr" target="#b68">[69]</ref> to produce the shock graph output.</p><p>The choice of Graph Neural Network architecture i.e. type of graph convolution, number of layers, activation function, etc. is determined by experimentation on STL-10 <ref type="bibr" target="#b15">[16]</ref>. We picked this dataset as it is outside the domain generalization community and will not bias our results in any way. We utilized the Deep Graph Library <ref type="bibr" target="#b75">[76]</ref> to evaluate three common graph architectures: Topological Adaptive Networks <ref type="bibr" target="#b18">[19]</ref> (TAG), Graph attention networks <ref type="bibr" target="#b71">[72]</ref> (GAT), and graph convolutional networks <ref type="bibr" target="#b39">[40]</ref> (GCN)) and chose the architecture that performed best on our benchmark dataset. TAG achieved 58%, while GAT and GCN achieved 56.2% and 54.3%, respectively. Our final network depth is four layers, composed of three TAG convolutional layers and an ultimate linear layer coupled with SoftMax activation to produce class scores. The input layer transforms the initial 58-dimensional feature vector, described in Section 3, for each node in the graph to a hidden dimension of 192 with subsequent TAG layers also having a hidden dimension of 192. Note that since we are doing graph classification, the node embeddings learned across multiple layers need to be merged into a single representation for the entire graph -we used simple mean pooling as an input into the final layer. Finally, following best practices in Image CNN architectures, we introduce batch norm and drop out between convolutional layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We evaluated our framework on three popular image classification benchmarks: Colored MNIST <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b30">31]</ref>, PACS <ref type="bibr" target="#b43">[44]</ref>, and VLCS <ref type="bibr" target="#b20">[21]</ref>. We follow the literature and perform "leave-one-domain-out" testing. In this paradigm we designate N ? 1 domains, where N represents the number of domains, as "source" domains, and train our shock graph approach to completion on this collection. We then test this model on the "leave-one" "target" domain, with the expectation that a model with domain generalization capabilities will achieve similar performance on the source and the target datasets. We repeat this process across all source/target splits and report the image accuracy per domain and the average accuracy across all N target domains. We compare our approach on these three datasets against a wide variety of state-of-the-art methods, <ref type="table" target="#tab_0">Table 1</ref>. In each column of <ref type="table" target="#tab_0">Table 1</ref> we have highlighted the best and second best methods in terms of classification performance in green and red, respectively.</p><p>There are two major challenges in fairly comparing our approach with the existing state-of-the-art methods: 1) the model complexity, and 2) the utility of pretrained Ima-geNet weights. For the first challenge, note that all existing methods are highly dependent on the backbone architecture being used -for example, the performance may greatly differ if a ResNet18 model is used compared to a ResNet50. While we are able to use a consistent backbone architecture for all of the Image CNN methods, our approach uses a GNN and thus cannot make use of the same architecture. In particular, we note that most literature uses AlexNet (61M parameters), ResNet18 (11M parameters), or ResNet50 (25M parameters) backbones for their DG methods. Our method, in contrast, uses only 257k parameters, which has significant benefits not explicitly shown in the experimental metrics. These small neural networks coupled with the sparsity of the graphs allows us to achieve extremely fast inference times and process extremely large batch sizes on modern GPUs. So while we do incur some extra processing converting an image to graph, that is mostly offset by the major speed increase achieved during graph inference. Furthermore, when considering the results in <ref type="table" target="#tab_0">Table 1</ref> if we were to enforce Image CNN architectures to have similar parameter complexity to our approach, its performance would be drastically poorer.</p><p>The second major challenge in comparing our approach to the state-of-the-art domain generalization results is the use of pretrained ImageNet weights. It is very common for domain generalization methods to find powerful invariant deep features that are originally generated by training on the very large and diverse ImageNet dataset. While recent work such as <ref type="bibr" target="#b32">[33]</ref> claim that CNN's can achieve the same performance without ImageNet pretraining, the initial feature extraction from ImageNet provides a strong baseline for the invariant features that domain generalization methods discover, and in some cases are used directly for transfer learning. However, since our approach has not been trained on ImageNet, comparing it to domain generalization methods that utilize pretrained CNNs is not a fair comparison! This is because one method has benefited significantly from pretraining and the other has not. To mitigate this, we compare our results to the performance of state-of-the-art domain generalization methods with backbones starting from scratch (random weights). Training from scratch is NOT the best that these methods can do and the paper does not pretend it is, but it is necessary to have a fair comparison between the various approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Colored MNIST</head><p>We evaluated our approach on Colored MNIST <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b30">31]</ref> to empirically confirm that our approach utilizes the shapebased features when available, and also that existing methods fail to use shape-based features in favor of texture-based  <ref type="bibr" target="#b13">[14]</ref> and Episodic-DG <ref type="bibr" target="#b47">[48]</ref> only provided code to run on PACS. Observe our approach is the best performing method across all datasets in average domain accuracy.</p><p>features. This dataset is a binary classification variant of the MNIST dataset and has three domains, <ref type="figure" target="#fig_5">Figure 6</ref>, denoted ? = 0.1, ? = 0.2, and ? = 0.9, each with varying degrees of how correlated the colors of the digits are with the true labels. For all domains, the shape of the digit has a 75% correlation with the true label. While we leave the exact details of the construction of the dataset to the supplemental material, intuitively, the difference between these domains is that for ? = 0.1, red is predictive of the label 0, while for ? = 0.9, green is predictive of the label 0. Note that by construction, each individual domain has color more highly correlated with the label, which means that effective domain generalization requires that the shape is used (since the same color is not predictive of the same label across domains).</p><p>Observe that Image CNN based methods, <ref type="table" target="#tab_0">Table 1</ref>, perform poorly on this dataset -in particular, they all perform reasonably well when testing on the ? = 0.1 and the ? = 0.2 domain, but perform significantly worse when test-  ing on the ? = 0.9 domain. This makes sense, as training with a mixture of the ? = 0.9 domain and either of the other two domains necessitates the Image CNN based methods to focus on shape in order to achieve high performance because color is no longer highly correlated with the label. As expected, our graph method focuses more on the shape-based cues and thus has consistent performance across the domains. We also note that, for the Image CNN methods, the results were the same when pretrained Ima-geNet weights were used.</p><p>This experiment verifies that Image CNN based domain generalization methods do neglect shape-based cues in favor of texture based cues when more predictive, even when the shape-based cues may be more generalizable. Further, it validates that our GNN domain generalization method works as intended and can focus on the shape-based features which are more generalizable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">PACS and VLCS</head><p>For a more traditional comparison, we use the heavily benchmarked VLCS and PACS datasets to evaluate our approach. VLCS <ref type="bibr" target="#b20">[21]</ref> includes images from four datasets (domains): PASCAL VOC2007 (V) <ref type="bibr" target="#b19">[20]</ref>, LabelMe (L) <ref type="bibr" target="#b61">[62]</ref>, Caltech (C) <ref type="bibr" target="#b21">[22]</ref> and SUN09 (S) <ref type="bibr" target="#b14">[15]</ref>. PACS <ref type="bibr" target="#b43">[44]</ref> exhibits a larger cross domain shift than VLCS <ref type="bibr" target="#b20">[21]</ref>, and contains four domains covering Photo (P), Art Painting (A), Cartoon (C) and Sketch (S) images. Our results in <ref type="table" target="#tab_0">Table 1</ref> show our method is consistently in the top two in performance across individual domains, and our method is the top performing method when considering the mean classification performance across domains for both datasets.</p><p>Observe that in PACS our performance on "Art" and "Cartoon" is worse than "Sketch" and "Photo". We attribute this to the fact that in the "Sketch" and "Photos" domains the role of shape and texture appear distinctly or not at all while in the "Art" and "Cartoon" domains texture is often itself represented as shape (internal contour patterns), thus confounding the role of shape. Further, observe that our performance in "Sketch" is vastly superior to all methods. This is a clear demonstration of the role of shape, as the black/white nature of sketches nullifies the role of appearance and methods generalizing from color-centric domains will suffer. We also notice in VLCS, our performance on the SUN domain is the best performing method. This is somewhat surprising as SUN is a scene dataset, but shows that even in scenes the shock graph and GNN are able to recover an amorphous notion of shape that is predictive of the underlying class.</p><p>When assessing our results against other methods, we first look at how well we compare against DeepAll <ref type="bibr" target="#b43">[44]</ref>, sometimes known as empirical risk minimization (ERM). DeepAll <ref type="bibr" target="#b43">[44]</ref> trains an Image CNN with standard backbones (ResNet-18, ResNet-50, etc.) on the source domains and evaluates its performance on the target domains. Since DeepAll is simple and is one of the earliest approaches, it generally serves as a baseline to measure relative performance. Further, DeepALL is the closest analogue of our own work as we also do not do any complex training or evaluation procedures, but simply train our approach normally on the source domain and then evaluate on the target domain. Observe that our results exceed DeepALL (ResNet-50) by 32% on PACS and 13% on VLCS in terms of aver-age domain accuracy regardless of backbone. Furthermore if we look at the individual target domains across PACS and VLCS we see our approach is better across the board. When comparing our approach against the rest of the methods, we notice that our approach is consistently the best or second best, where as the relative ranking of the other best performing methods differ according to the dataset (including Colored MNIST). This demonstrates that using the shape cue is more generalizable across different datasets than exclusively relying on learned appearance or texture cues. Finally, we note that our approach, despite not having the benefit of more advanced techniques like episodic training and meta-learning commonly employed by state-of-the-art approaches, is quite competitive across all domains and methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work, we merge classical computer vision techniques with recent develops in graph neural networks in order to build a model that is inherently robust to domain shift. We enforce the inductive bias that our models focus on the shape of the images by transforming an image to a graph by means of the shock graph, and then train graph neural networks for subsequent classification tasks. With no other changes, our proposed model shows competitive results in domain generalization tasks. Contrary to existing methods, we bypass the difficulty that classical CNN's have in domain generalization by transforming the problem to the space of graphs, using invariant shape features to accomplish the task. An interesting area of future research would be to combine the strong feature extraction capabilities of CNN's with the shape features we obtain from the shock graph to achieve domain generalization. Finally, this work is scoped entirely to the task of image classification, but it could be extended to scene classification and object detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .Figure 2</head><label>12</label><figDesc>Observe that shape is dominant in forming perception when object features have not been experienced before (a), or are completely contradictory where the percept is a giraffe and not a zebra (b)<ref type="bibr" target="#b69">[70]</ref>. . a) Various images of an elephant across the four domains from the PACS<ref type="bibr" target="#b43">[44]</ref> dataset. b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4</head><label>4</label><figDesc>. a) Various images of a giraffe across the four domains from the PACS<ref type="bibr" target="#b43">[44]</ref> dataset. b) The contour map on top of a grayscale version for clarity. c) The shock graph of the contour map colored in green (shock dynamics are not shown). We encourage readers to zoom in.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>!</head><label></label><figDesc>= ( ! , ! , ! ) " = ( " , " , " ) (% " , ' " ) ! " = (% ) , ' ) ) * = (%, ', +, ,)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>a) First Order Geometric Attributes assigned to each Node. b) Edge Attributes composing geometric and differential geometric features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>a) Samples images from the Colored MNIST dataset. Note that the color of specific numbers significantly varies across domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of our approach (bottom row) to Domain Generalization methods. Each dataset column represents the target domain on which we test. The best classification accuracy is highlighted in green and the second best in red. The authors of Jigsaw</figDesc><table><row><cell>Colored MNIST [1, 31]</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank the Tactical Intelligent Systems Group at JHU/APL for partially funding this research. Part of this research was conducted using computational resources and services at the Center for Computation and Visualization, Brown University. Benjamin Kimia gratefully acknowledges the support of NSF Award 1910530.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Invariant risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Why do deep convolutional networks generalize so poorly to small image transformations?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aharon</forename><surname>Azulay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
		<idno>184:1-184:25</idno>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep convolutional networks do not classify based on global object shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongjing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gennady</forename><surname>Erlikhman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">J</forename><surname>Kellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Local features and global shape information in object classification by deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongjing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gennady</forename><surname>Erlikhman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">J</forename><surname>Kellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="46" to="61" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Towards domain generalization using metaregularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Metareg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing</title>
		<meeting><address><addrLine>NeurIPS; Montr?al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recognition by components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irving</forename><surname>Biederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Review</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="147" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Surface versus edge-based determinants of visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irving</forename><surname>Biederman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ginny</forename><surname>Ju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="38" to="64" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A transformation for extracting new descriptors of shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Blum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of a Symposium</title>
		<meeting>a Symposium<address><addrLine>Cambridge, MA, U.S.A.; Boston, MA, U.S.A.</addrLine></address></meeting>
		<imprint>
			<publisher>M.I.T. Press</publisher>
			<date type="published" when="1964" />
			<biblScope unit="page" from="362" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Shape defense. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Borji</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Approximating cnns with bag-of-local-features models works surprisingly well on imagenet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Appearance shock grammar for fast medial axis extraction from real images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles-Olivier Dufresne</forename><surname>Camaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morteza</forename><surname>Rezanejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stavros</forename><surname>Tsogkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaleem</forename><surname>Siddiqi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><forename type="middle">J</forename><surname>Dickinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14370" to="14379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Towards evaluating the robustness of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 ieee symposium on security and privacy (sp)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="39" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Maria</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio D&amp;apos;</forename><surname>Innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Maria</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio D&amp;apos;</forename><surname>Innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploiting hierarchical context on a large database of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myung</forename><forename type="middle">Jin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS2011</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast edge detection using structured forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1558" to="1570" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Domain generalization via model-agnostic learning of semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Coelho De Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-14" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Topology adaptive graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanhang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Jos?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soummya</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mark Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Ali Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="136" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">N</forename><surname>Rockmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1657" to="1664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning generative visual models from few training examples: an incremental Bayesian approach tested on 101 object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE CVPR Workshop on Generative Model Based Vision</title>
		<meeting>of IEEE CVPR Workshop on Generative Model Based Vision</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hierarchical matching of deformable shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">D</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the intrinsic reconstruction of shape from its symmetries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">B</forename><surname>Giblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2003-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the local form and transitions of symmetry sets, medial axes, and shocks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">B</forename><surname>Giblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2003-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Local forms and transitions of the medial axis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">B</forename><surname>Giblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medial Representations: Mathematics, Algorithms and Applications</title>
		<editor>Kaleem Siddiqi and Stephen Pizer</editor>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="37" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<title level="m">Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">In search of lost domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A multi-stage approach to curve extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maruthi</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">B</forename><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision</title>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="663" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Rethinking imagenet pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4918" to="4927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Assessing shape bias property of convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baicen</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayoore</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radha</forename><surname>Poovendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops</title>
		<meeting><address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-18" />
			<biblScope unit="page" from="1923" to="1931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Self-challenging improves cross-domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Undoing the damage of dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision</title>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Toward a computational theory of shape: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><forename type="middle">R</forename><surname>Kimia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">W</forename><surname>Tannenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision</title>
		<editor>Olivier D. Faugeras</editor>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1990" />
			<biblScope unit="volume">427</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Shapes, shocks, and deformations, I: The components of shape and the reaction-diffusion space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><forename type="middle">R</forename><surname>Kimia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">W</forename><surname>Tannenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR2017</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep neural networks: A new framework for modeling biological vision and brain information processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaus</forename><surname>Kriegeskorte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Vision Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="417" to="446" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="5543" to="5551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AAAI</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Episodic training for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Episodic training for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deep domain generalization via conditional invariant adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision, Lecture Notes in Computer Science</title>
		<meeting>European Conference on Computer Vision, Lecture Notes in Computer Science</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Shapetexture debiased neural network training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qihang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieru</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cihang</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The contrasting roles of shape in human vision and convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bowers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41th Annual Meeting of the Cognitive Science Society</title>
		<meeting>the 41th Annual Meeting of the Cognitive Science Society<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2261" to="2267" />
		</imprint>
	</monogr>
	<note>CogSci 2019: Creativity + Cognition + Computation</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Representation Visual Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Marr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deepfool: a simple and accurate method to fool deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alhussein</forename><surname>Seyed-Mohsen Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2574" to="2582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Efficient shape matching using shape contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1832" to="1837" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krikamol</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning, ICML 2013</title>
		<meeting>the 30th International Conference on Machine Learning, ICML 2013<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Bottom-up perceptual organization of images into object part hypotheses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maruthi</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">B</forename><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision</title>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="257" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Generic object recognition via shock patch fragments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ozge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">B</forename><surname>Ozcanli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference</title>
		<editor>Nasir M. Rajpoot and Abhir Bhalerao</editor>
		<meeting>the British Machine Vision Conference<address><addrLine>Coventry, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Warwick Print</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1030" to="1039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning to learn single domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengchun</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Cognitive psychology for deep neural networks: A shape bias case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><forename type="middle">M</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-11" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2940" to="2949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Labelme: A database and web-based tool for image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">P</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">T</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="157" to="173" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Distributionally robust neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsunori</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno>ICLR, 2020. 7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Recognition of shapes by editing their shock graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2004-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Generalizing across domains via cross-gradient training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Informative dropout for robust representation learning: A shape-bias perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baifeng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinghuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<idno>PMLR, 2020. 1</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="8828" to="8839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6199</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">No grouping left behind: From edges to curve fragments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Tamrakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">B</forename><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision<address><addrLine>Rio de Janeiro, Brazil</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Intrinsic shock representation and shock computation from points, lines and circular arcs in an eulerian-lagrangian framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Tamrakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">B</forename><surname>Kimia</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Skeleton Search: Category-specific object recognition and segmentation using a skeletal shape model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nhon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">B</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="240" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">AMAT: medial axis transform for natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stavros</forename><surname>Tsogkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><forename type="middle">J</forename><surname>Dickinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2727" to="2736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR2018</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Object representation and comparison inferred from its medial axis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bardinet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Malandain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Damas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">P</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blanca</forename><surname>Capilla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">00</biblScope>
			<biblScope unit="page" from="712" to="715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongseok</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018</title>
		<meeting><address><addrLine>NeurIPS; Montr?al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Learning robust global representations by penalizing local predictive power</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songwei</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno>NIPS2019. 2</idno>
		<imprint>
			<biblScope unit="page" from="10506" to="10518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Deep graph library: A graph-centric, highly-performant package for graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihao</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mufei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianjun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01315</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">A comprehensive survey on graph neural networks. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1901" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision</title>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Texture and shape biased two-stream networks for clothing classification and attribute recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13535" to="13544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Graph neural networks: A review of methods and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganqu</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<idno>abs/1812.08434</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
