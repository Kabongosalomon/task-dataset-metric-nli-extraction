<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PADS: Policy-Adapted Sampling for Visual Similarity Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Roth</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Heidelberg Collaboratory for Image Processing / IWR Heidelberg University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Milbich</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Heidelberg Collaboratory for Image Processing / IWR Heidelberg University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bj?rn</forename><surname>Ommer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Heidelberg Collaboratory for Image Processing / IWR Heidelberg University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PADS: Policy-Adapted Sampling for Visual Similarity Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning visual similarity requires to learn relations, typically between triplets of images. Albeit triplet approaches being powerful, their computational complexity mostly limits training to only a subset of all possible training triplets. Thus, sampling strategies that decide when to use which training sample during learning are crucial. Currently, the prominent paradigm are fixed or curriculum sampling strategies that are predefined before training starts. However, the problem truly calls for a sampling process that adjusts based on the actual state of the similarity representation during training. We, therefore, employ reinforcement learning and have a teacher network adjust the sampling distribution based on the current state of the learner network, which represents visual similarity. Experiments on benchmark datasets using standard triplet-based losses show that our adaptive sampling strategy significantly outperforms fixed sampling strategies. Moreover, although our adaptive sampling is only applied on top of basic triplet-learning frameworks, we reach competitive results to state-of-the-art approaches that employ diverse additional learning signals or strong ensemble architectures. Code can be found under https: //github.com/Confusezius/CVPR2020_PADS.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Capturing visual similarity between images is the core of virtually every computer vision task, such as image retrieval <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b35">36]</ref>, pose understanding <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b53">54]</ref>, face detection <ref type="bibr" target="#b48">[49]</ref> and style transfer <ref type="bibr" target="#b27">[28]</ref>. Measuring similarity requires to find a representation which maps similar images close together and dissimilar images far apart. This task is naturally formulated as Deep Metric Learning (DML) in which individual pairs of images are compared <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b37">38]</ref> or contrasted against a third image <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b56">57]</ref> to learn a distance metric that reflects image similarity. Such triplet learning constitutes the basis of powerful learning algorithms <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b61">62]</ref>. However, with growing training * Authors contributed equally to this work. <ref type="figure">Figure 1</ref>: Progression of negative sampling distributions over training iterations. A static sampling strategy <ref type="bibr" target="#b59">[60]</ref> follows a fixed probability distribution over distances d an between anchor and negative images. In contrast, our learned, discretized sampling distributions change while adapting to the training state of the DML model. This leads to improvements on all datasets close to 4% compared to static strategies (cf. Tab. 1). Moreover, the progression of the adaptive distributions varies between datasets and, thus, is difficult to model manually which highlights the need for a learning based approach. set size, leveraging every single triplet for learning becomes computationally infeasible, limiting training to only a subset of all possible triplets. Thus, a careful selection of those triplets which drive learning best, is crucial. This raises the question: How to determine which triplets to present when to our model during training? As training progresses, more and more triplet relations will be correctly represented by the model. Thus, ever fewer triplets will still provide novel, valuable information. Conversely, leveraging only triplets which are hard to learn <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b62">63]</ref> but therefore informative, impairs optimization due to high gradient variance <ref type="bibr" target="#b59">[60]</ref>. Consequently, a reasonable mixture of triplets with varying difficulty would provide an informative and stable training signal. Now, the question remains, when to present which triplet? Sampling from a fixed distribution over difficulties may serve as a simple proxy <ref type="bibr" target="#b59">[60]</ref> and is a typical remedy in representation learning in general <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b4">5]</ref>. However, (i) choosing a proper distribution is difficult; (ii) the abilities and state of our model evolves as training progresses and, thus, a fixed distribution cannot optimally support every stage of training; and (iii) triplet sampling should actively contribute to the learning objective rather than being chosen independently. Since a manually predefined sampling distribution does not fulfill these requirements, we need to learn and adapt it while training a representation. Such online adaptation of the learning algorithm and parameters that control it during training is typically framed as a teacher-student setup and optimized using Reinforcement Learning (RL). When modelling a flexible sampling process (the student), a controller network (the teacher) learns to adjusts the sampling such that the DML model is steadily provided with an optimal training signal. <ref type="figure">Fig. 1</ref> compares progressions of learned sampling distributions adapted to the DML model with a typical fixed sampling distribution <ref type="bibr" target="#b59">[60]</ref>.</p><p>This paper presents how to learn a novel triplet sampling strategy which is able to effectively support the learning process of a DML model at every stage of training. To this end, we model a sampling distribution so it is easily adjustable to yield triplets of arbitrary mixtures of difficulty. To adapt to the training state of the DML model we employ Reinforcement Learning to update the adjustment policy. Directly optimizing the policy so it improves performance on a held-back validation set, adjusts the sampling process to optimally support DML training. Experiments show that our adaptive sampling strategy significantly improves over fixed, manually designed triplet sampling strategies on multiple datasets. Moreover, we perform diverse analyses and ablations to provide additional insights into our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Metric learning has become the leading paradigm for learning distances between images with a broad range of applications, including image retrieval <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b59">60]</ref>, image classification <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b63">64]</ref>, face verification <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b31">32]</ref> or human pose analysis <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b7">8]</ref>. Ranking losses formulated on pairs <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b16">17]</ref>, triplets <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b11">12]</ref> or even higher order tuples of images <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b57">58]</ref> emerged as the most widely used basis for DML <ref type="bibr" target="#b45">[46]</ref>. As with the advent of CNNs datasets are growing larger, different strategies are developed to cope with the increasing complexity of the learning problem. Complexity management in DML: The main line of research are negative sampling strategies <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b17">18]</ref> based on distances between an anchor and a negative image. FaceNet <ref type="bibr" target="#b48">[49]</ref> leverages only the hard negatives in a minibatch. Wu et al. <ref type="bibr" target="#b59">[60]</ref> sample negatives uniformly over the whole range of distances to avoid large variances in the gradients while optimization. Harwood et al. <ref type="bibr" target="#b17">[18]</ref> restrict and control the search space for triplets using pre-computed sets of nearest neighbors by linearly regressing the training loss. Each of them successfully enable effective DML training. However, these works are based on fixed and manually predefined sampling strategies. In contrast, we learn an adaptive sampling strategy to provide an optimal input stream of triplets conditioned on the training state of our model. Orthogonal to sampling negatives from the training set is the generation of hard negatives in form of images <ref type="bibr" target="#b8">[9]</ref> or feature vectors <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b62">63]</ref>. Thus, these approaches also resort to hard negatives, while our sampling process yields negatives of any mixture of difficulty depending on the model state. Finally, proxy based techniques reduce the complexity of the learning problem by learning one <ref type="bibr" target="#b36">[37]</ref> or more <ref type="bibr" target="#b42">[43]</ref> virtual representatives for each class, which are used as negatives. Thus, these approaches approximate the negative distributions, while our sampling adaptively yields individual negative samples. Advanced DML: Based on the standard DML losses many works improve model performance using more advanced techniques. Ensemble methods <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b46">47]</ref> learn and combine multiple embedding spaces to capture more information. HORDE <ref type="bibr" target="#b22">[23]</ref> additionally forces feature representations of related images to have matching higher moments. Roth et al. <ref type="bibr" target="#b44">[45]</ref> combines class-discriminative features with features learned from characteristics shared across classes. Similarly, Lin et al. <ref type="bibr" target="#b30">[31]</ref> proposes to learn the intra-class distributions, next to the inter-class distribution. All these approaches are applied in addition to the standard ranking losses discussed above. In contrast, our work presents a novel triplet sampling strategy and, thus, is complementary to these advanced DML methods. Adaptive Learning: Curriculum Learning <ref type="bibr" target="#b3">[4]</ref> gradually increases the difficulty of the the samples presented to the model. Hacohen et al. <ref type="bibr" target="#b15">[16]</ref> employ a batch-based learnable scoring function to provide a batch-curriculum for training, while we learn how to adapt a sampling process to the training state. Graves et al. <ref type="bibr" target="#b14">[15]</ref> divide the training data into fixed subsets before learning in which order to use them from training. Further, Gopal et al. <ref type="bibr" target="#b13">[14]</ref> employs an empirical online importance sampling distribution over inputs based on their gradient magnitudes during training. Similarly, Shreyas et al. <ref type="bibr" target="#b47">[48]</ref> learn an importance sampling over instances. In contrast, we learn an online policy for selecting triplet negatives, thus instance relations. Meta Learning aims at learning how to learn. It has been successfully applied for various components of a learning process, such as activation functions <ref type="bibr" target="#b43">[44]</ref>, input masking <ref type="bibr" target="#b9">[10]</ref>, self-supervision <ref type="bibr" target="#b5">[6]</ref>, finetuning <ref type="bibr" target="#b51">[52]</ref>, loss functions <ref type="bibr" target="#b20">[21]</ref>, optimizer parameters <ref type="bibr" target="#b1">[2]</ref> and model architectures <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b60">61]</ref>. In this work, we learn a sampling distribution to improve triplet-based learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Distance-based Sampling for DML</head><formula xml:id="formula_0">Let ? i := ?(I i ; ?) be a D-dimensional embedding of an image I i ? R H?W ?3 with ?(I i ; ?)</formula><p>being represented by a deep neural network parametrized by ?. Further, ? is normalized to a unit hypersphere S for regularization purposes <ref type="bibr" target="#b48">[49]</ref>. Thus, the objective of DML is to learn ? : R H?W ?3 ? ? ? S such that images I i , I j ? I train are mapped close to another if they are similar and far otherwise, under a standard distance function d(? i , ? j ). Commonly, d is the euclidean distance, i.e. d ij := ? i ? ? j 2 . A popular family of training objectives for learning ? are ranking losses <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b16">17]</ref> operating on tuples of images. Their most widely used representative is arguably the triplet loss <ref type="bibr" target="#b48">[49]</ref> which is defined as an ordering task between images {I a , I p , I n }, formulated as</p><formula xml:id="formula_1">L triplet ({I a , I p , I n }; ?) = max(0, d 2 ap ? d 2 an + ?) (1)</formula><p>Here, I a and I p are the anchor and positive with the same class label. I n acts as the negative from a different class. Optimizing L triplet pushes I a closer to I p and further away from I n as long as a constant distance margin ? is violated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Static Triplet sampling strategies</head><p>While ranking losses have proven to be powerful, the number of possible tuples grows dramatically with the size of the training set. Thus, training quickly becomes infeasible, turning efficient tuple sampling strategies into a key component for successful learning as discussed here. When performing DML using ranking losses like Eq.1, triplets decreasingly violate the triplet margin ? as training progresses. Naively employing random triplet sampling entails many of the selected triplets being uninformative, as distances on ? are strongly biased towards larger distances d due to its regularization to S. Consequently, recent sampling strategies explicitly leverage triplets which violate the triplet margin and, thus, are difficult and informative. (Semi-)Hard negative sampling: Hard negative sampling methods focus on triplets violating the margin ? the most, i.e. by sampling negatives I * n = arg min In?I:dan&lt;dap d an . While it speeds up convergence, it may result in collapsed models <ref type="bibr" target="#b48">[49]</ref> due to a strong focus on few data outliers and very hard negatives. Facenet <ref type="bibr" target="#b48">[49]</ref> proposes a relaxed, semi-hard negative sampling strategy restricting the sampling set to a single mini-batch B by employing negatives I * n = arg min In?B:dan&gt;dap d an . Based on this idea, different online <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b52">53]</ref> and offline <ref type="bibr" target="#b17">[18]</ref> strategies emerged. (Static) Distance-based sampling: By considering the hardness of a negative, one can successfully discard easy and uninformative triplets. However, triplets that are too hard lead to noisy learning signals due to overall high gradient variance <ref type="bibr" target="#b59">[60]</ref>. As a remedy, to control the variance while maintaining sufficient triplet utility, sampling can be extended to also consider easier negatives, i.e. introducing a sampling distribution I n ? p(I n |I a ) over the range of distances d an between anchor and negatives. Wu et al. <ref type="bibr" target="#b59">[60]</ref> propose to sample from a static uniform prior on the range of d an , thus equally considering negatives from the whole spectrum of difficulties. As pairwise distances on ? are strongly biased towards larger d an , their sampling distribution requires to weigh p(I n |I a ) inversely to the analytical</p><formula xml:id="formula_2">distance distribution on ?: q(d) ? d D?2 1 ? 1 4 d 2 D?3 2</formula><p>for large D ? 128 <ref type="bibr" target="#b0">[1]</ref>. Distance-based sampling from the static, uniform prior is then performed by</p><formula xml:id="formula_3">I n ? p(I n |I a ) ? min ?, q ?1 (d an )<label>(2)</label></formula><p>with ? being a clipping hyperparameter for regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Learning an Adaptive Negative Sampling</head><p>Distance-based sampling of negatives I n has proven to offer a good trade-off between fast convergence and a stable, informative training signal. However, a static sampling distribution p(I n |I a ) provides a stream of training data independent of the the changing needs of a DML model during learning. While samples of mixed difficulty may be useful at the beginning, later training stages are calling for samples of increased difficulty, as e.g. analyzed by curriculum learning <ref type="bibr" target="#b3">[4]</ref>. Unfortunately, as different models and even different model intializations <ref type="bibr" target="#b12">[13]</ref> exhibit distinct learning dynamics, finding a generally applicable learning schedule is challenging. Thus, again, heuristics <ref type="bibr" target="#b15">[16]</ref> are typically employed, inferring changes after a fixed number of training Our proposed adaptive negative sampling is shown in green: <ref type="bibr" target="#b0">(1)</ref> We compute the current training state s using I val . (2) Conditioned on s, our policy ? ? (a|s) predicts adjustments to p k . (3) We perform bin-wise adjustments of p(I n |I a ). (4) Using the adjusted p(I n |I a ) we train the DML model. (5) Finally, ? ? is updated based on the reward r. epochs or iterations. To provide an optimal training signal, however, we rather want p(I n |I a ) to adapt to the training state of the DML model than merely the training iteration. Such an adaptive negative sampling allows for adjustments which directly facilitate maximal DML performance. Since manually designing such a strategy is difficult, learning it is the most viable option. Subsequently, we first present how to find a parametrization of p(I a |I n ) that is able to represent arbitrary, potentially multi-modal distributions, thus being able to sample negatives I n of any mixture of difficulty needed. Using this, we can learn a policy which effectively alters p(I n |I a ) to optimally support learning of the DML model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Modelling a flexible sampling distribution</head><p>Since learning benefits from a diverse distribution p(I n |I a ) of negatives, uni-modal distributions (e.g. Gaussians, Binomials, ? 2 ) are insufficient. Thus, we utilize a discrete probability mass function p(I n |I a ) := P r{d an ? u k } = p k , where the bounded intervall U = [? min , ? max ] of possible distances d an is discretized into disjoint equidistant bins u 1 , . . . , u K . The probability of drawing I n from bin u k is p k with p k ? 0 and k p k = 1. <ref type="figure" target="#fig_0">Fig. 2</ref> illustrates this discretized sampling distribution. This representation of the negative sampling distribution effectively controls which samples are used to learn ?. As ? changes during learning, p(I n |I a ) should also adapt to always provide the most useful training samples, i.e. to control when to use which sample. Hence the probabilities p k need to be updated while learning ?. We subsequently solve this task by learning a stochastic adjustment policy ? ? for the p k , implemented as a neural network parametrized by ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Learning an adjustment policy for p(I n |I a )</head><p>Our sampling process based on p(I n |I a ) should provide optimal training signals for learning ? at every stage of train-ing. Thus, we adjust the p k by a multiplicative update a ? A conditioned on the current representation (or state) s ? S of ? during learning. We introduce a conditional distribution ? ? (a|s) to control which adjustment to apply at which state s of training ?. To learn ? ? , we measure the utility of these adjustments for learning ? using a reward signal r = r(s, a). We now first describe how to model each of these components, before presenting how to efficiently optimize the adjustment policy ? ? alongside ?. Adjustments a: To adjust p(I n |I a ), ? ? (a|s) proposes adjustments a to the p k . To lower the complexity of the action space, we use a limited set of actions A = {?, 1, ?} to individually decrease, maintain, or increase the probabilities p k for each bin u k , i.e. a := [a k ? {?, 1, ?}] K k=1 . Further, ?, ? are fixed constants 0 &lt; ? &lt; 1, ? &gt; 1 and ?+? 2 = 1. Updating p(I n |I a ) is then simply performed by bin-wise updates p k ? p k ? a k followed by re-normalization. Using a multiplicative adjustment accounts for the exponential distribution of distances on ? (cf. Sec. 3.1). Training states s: Adjustments a depend on the present state s ? S of the representation ?. Unfortunately, we cannot use the current model weights ? of the embedding network, as the dimensionality of s would be to high, thus making optimization of ? ? infeasible. Instead, we represent the current training state using representative statistics describing the learning progress: running averages over Recall@1 <ref type="bibr" target="#b23">[24]</ref>, NMI <ref type="bibr" target="#b32">[33]</ref> and average distances between and within classes on a fixed held-back validation set I val . Additionally we use past parametrizations of p(I n |I a ) and the relative training iteration (cf. Implementation details, Sec. 5). Rewards r: An optimal sampling distribution p(I n |I a ) yields triplets whose training signal consistently improves the evaluation performance of ? while learning. Thus, we compute the reward r for for adjustments a ? ? ? (a|s) by directly measuring the relative improvement of ?(?; ?) over ?(?; ? ) from the previous training state. This improvement is quantified through DML evaluation metrics e(?(.; ? t ), I val ) on the validation set I val . More precisely, we define r as</p><formula xml:id="formula_4">r = sign (e(?(.; ?), I val ) ? e(?(.; ? ), I val )))<label>(3)</label></formula><p>where ? was reached from ? after M DML training iterations using p(I n |I a ). We choose e to be the sum of Recall@1 <ref type="bibr" target="#b23">[24]</ref> and NMI <ref type="bibr" target="#b32">[33]</ref>. Both metrics are in the range [0, 1] and target slightly different performance aspects. Further, similar to <ref type="bibr" target="#b20">[21]</ref>, we utilize the sign function for consistent learning signals even during saturated training stages.</p><p>Learning of ? ? : Adjusting p(I n |I a ) is a stochastic process controlled by actions a sampled from ? ? (a|s) based on a current state s. This defines a Markov Decision Process (MDP) naturally optimized by Reinforcement Learning. The policy objective J(?) is formulated to maximize the total ex-</p><formula xml:id="formula_5">pected reward R(? ) = t r t (a t , s t ) over training episodes of tuples ? = {(a t , s t , r t )|t = 0, . . . , T ]} collected from sequences of T time-steps, i.e. J(?) = E ? ?? ? (? ) [R(? )]<label>(4)</label></formula><p>Hence, ? ? is optimized to predict adjustments a for p(I n |I a ) which yield high rewards and thereby improving the performance of ?. Common approaches use episodes ? comprising long state trajectories which potentially cover multiple training epochs <ref type="bibr" target="#b9">[10]</ref>. As a result, there is a large temporal discrepancy between model and policy updates. However, in order to closely adapt p(I n |I a ) to the learning of ?, this discrepancy needs to be minimized. In fact, our experiments show that single-step episodes, i.e. T = 1, are sufficient for optimizing ? ? to infer meaningful adjustments a for p(I n |I a ). Such a setup is also successfully adopted by contextual bandits [30] 1 . In summary, our training episodes ? consists of updating p(I n |I a ) using a sampled adjustment a, performing M DML training iterations based on the adjusted p(I n |I a ) and updating ? ? using the resulting reward r. Optimizing Eq. 4 is then performed by standard RL algorithms which approximate different variations of the policy gradient based on the gain G(s, a),</p><formula xml:id="formula_6">? ? J(?) = E ? ?? ? (? ) [? ? log ? ? (a|s)G(s, a)]<label>(5)</label></formula><p>The choice of the exact form of G = G(s, a) gives rise to different optimization methods, e.g REINFORCE <ref type="bibr" target="#b58">[59]</ref> (G = R(? )), Advantage Actor Critic (A2C) <ref type="bibr" target="#b54">[55]</ref> (G = A(s, a)), etc. Other RL algorithms, such as TRPO <ref type="bibr" target="#b49">[50]</ref> or PPO <ref type="bibr" target="#b50">[51]</ref> replace Eq. 4 by surrogate objective functions. <ref type="figure" target="#fig_1">Fig. 3</ref> provides an overview over the learning procedure. Moreover, in the supplementary material we compare different RL algorithms and summarizes the learning procedure in Alg. 1 using PPO <ref type="bibr" target="#b50">[51]</ref> for policy optimization. Initialization of p(I n |I a ): We find that an initialization with a slight emphasis towards smaller distances d an works best. However, as shown in Tab. 5, also other initializations work well. In addition, the limits of the distance interval U = [? min , ? max ] can be controlled for additional regularization as done in <ref type="bibr" target="#b59">[60]</ref>. This means ignoring values above ? max and clipping values below ? min , which is analysed in Tab. 5. Self-Regularisation: As noted in <ref type="bibr" target="#b44">[45]</ref>, the utilisation of intra-class features can be beneficial to generalization. Our approach easily allows for a learnable inclusion of such features. As positive samples are generally closest to anchors, we can merge positive samples into the set of negative samples and have the policy learn to place higher sampling probability on such low-distance cases. We find that this additionally improves generalization performance.</p><p>Computational costs: Computational overhead over fixed sampling strategies <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b59">60]</ref> comes from the estimation of r requiring a forward pass over I val and the computation of the evaluation metrics. For example, setting M = 30 increases the computation time per epoch by less than 20%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In this section we provide implementation details, evaluations on standard metric learning datasets, ablations studies and analysis experiments. Implementation details. We follow the training protocol of <ref type="bibr" target="#b59">[60]</ref> with ResNet50. During training, images are resized to 256 ? 256 with random crop to 224 ? 224 and random horizontal flipping. For completeness, we also evaluate on Inception-BN <ref type="bibr" target="#b21">[22]</ref> following standard practice in the supplementary. The initial learning rates are set to 10 ?5 . We choose triplet parameters according to <ref type="bibr" target="#b59">[60]</ref>, with ? = 0.2. For margin loss, we evaluate margins ? = 0.6 and ? = 1.2. Our policy ? is implemented as a two-layer fully-connected network with ReLU-nonlinearity inbetween and 128 neurons per layer. Action values are set to ? = 0.8, ? = 1.25. Episode iterations M are determined via cross-validation within <ref type="bibr" target="#b29">[30,</ref><ref type="bibr">150]</ref>. The sampling range [? min , ? min ] of p(I n |I a ) is set to [0.1, 1.4], with K = 30. The sampling probability of negatives corresponding to distances outside this interval is set to 0. For the input state we use running averages of validation recall, NMI and average intra-and interclass distance based on running average lengths of 2, 8, 16 and 32 to account for short-and longterm changes. We also incorporate the metrics of the previous 20 iterations. Finally, we include the sampling distributions of the previous iteration and the training progress normalized over the total training length. For optimization, we utilize an A2C + PPO setup with ratio limit = 0.2. The history policy is updated every 5 policy iterations. For implementation we use the Dataset CUB200-2011 <ref type="bibr" target="#b55">[56]</ref> CARS196 <ref type="bibr" target="#b28">[29]</ref> SOP <ref type="bibr" target="#b37">[38]</ref> Approach  <ref type="bibr" target="#b37">[38]</ref>, containing 120,053 images divided in 22,634 classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Results</head><p>In Tab. 1 we apply our adaptive sampling strategy on two widely adopted basic ranking losses: triplet <ref type="bibr" target="#b48">[49]</ref> and margin loss <ref type="bibr" target="#b59">[60]</ref>. For each loss, we compare against the most commonly used static sampling strategies, semi-hard <ref type="bibr" target="#b48">[49]</ref>  (semihard) and distance-based sampling <ref type="bibr" target="#b59">[60]</ref> (U-dist) on the CUB200-2011, CARS196 and SOP dataset. We measure image retrieval performance using recall accuracy R@k <ref type="bibr" target="#b23">[24]</ref> following <ref type="bibr" target="#b38">[39]</ref>. For completeness we additonally show the normalized mutual information score (NMI) <ref type="bibr" target="#b32">[33]</ref>, despite not fully correlating with retrieval performance. For both losses and each dataset, our learned negative sampling significantly improves the performance over the non-adaptive sampling strategies. Especially the strong margin loss greatly benefits from the adaptive sampling, resulting in boosts up to 3.8% on CUB200-2011, 3.4% on CARS196 and 1.9% on SOP. This clearly demonstrates the importance of adjusting triplet sampling to the learning process a DML model, especially for smaller datasets. Next, we compare these results with the current state-ofthe-art in DML which extend these basic losses using diverse additional training signals (MIC <ref type="bibr" target="#b44">[45]</ref>, DVML <ref type="bibr" target="#b30">[31]</ref>, HORDE <ref type="bibr" target="#b22">[23]</ref>, A-BIER <ref type="bibr" target="#b38">[39]</ref>), ensembles of embedding spaces (DREML <ref type="bibr" target="#b61">[62]</ref>, D&amp;C <ref type="bibr" target="#b46">[47]</ref>, Rank <ref type="bibr" target="#b57">[58]</ref>) and/or significantly more network parameters (HORDE <ref type="bibr" target="#b22">[23]</ref>, SOFT-TRIPLE <ref type="bibr" target="#b42">[43]</ref>). Tab. 2 shows that our results, despite not using such additional extensions, compete and partly even surpass these strong methods. On CUB200-2011 we outperform all methods, including the powerful ensembles, by at least 1.2% in Recall accuracy. On CARS196 <ref type="bibr" target="#b28">[29]</ref> we rank second behind the top performing non-ensemble method D&amp;C <ref type="bibr" target="#b46">[47]</ref>. On SOP <ref type="bibr" target="#b37">[38]</ref> we lose 0.7% to MIC <ref type="bibr" target="#b44">[45]</ref> which, in turn, we surpass on both CUB200-2011 and CARS196. This highlights the strong benefit of our adaptive sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Analysis</head><p>We now present various analysis experiments providing detailed insights into our learned adaptive sampling strategy. Training progression of p(I n |I a ): We now analyze in <ref type="figure" target="#fig_2">Fig. 4</ref>    <ref type="table">Table 3</ref>: Transferring a fixed trained policy ? ? and fixed final distribution p(I n |I a ) to training runs with different ( =) and the same network initialization (=). Reference denotes the training run from which ? ? and p(I n |I a ) is obtained. (=) initialized training runs. We find that applying a fixed trained policy (fix ? ? ) to a new training run with the same network initialization (=) improves performance by 0.4% due to the immediate utility of ? ? for learning ? as ? ? is already fully adapted to the reference learning process. In contrast, applying the trained policy to a differently initialized training run ( =) drops performance by 1.5%.</p><p>Since the fixed ? ? cannot adapt to the learning states of the new model, its support for optimizing ? is diminished. Note that the policy has only been trained on a single training run, thus it cannot fully generalize to different training dynamics. This shows the importance of an adaptive sampling. Next, we investigate if the distribution p(I n |I a ) obtained at the end of training can be regarded as an optimal sampling distribution over d an , as ? ? is fully trained. To this end we fix and apply the distribution p(I n |I a ) after its last adjustment by ? ? (fix last p(I n |I a )) in training the reference run. As intuitively expected, in both cases performance drops strongly as (i) we now have a static sampling process   and (ii) the sampling distribution is optimized to a specific training state. Given our strong results, this proves that our sampling process indeed adapts to the learning of ?.</p><p>Curriculum Learning: To compare our adaptive sampling with basic curriculum learning strategies, we pre-define two sampling schedules: (1) A linear increase of negative hardness, starting from a semi-hard distance intervall <ref type="bibr" target="#b48">[49]</ref> and (2) a non-linear schedule using distance-based sampling <ref type="bibr" target="#b59">[60]</ref>, where the distribution is gradually shifted towards harder negatives. We visualize the corresponding progression of the sampling distribution in the supplementary material. Tab. 4 illustrates that both fixed, pre-defined curriculum schedules perform worse than our learned, adaptive sampling distribution by at least 3.6% on CUB200-2011. On CARS196 the performance gap is even larger. The strong difference in datasets further demonstrates the difficulty of finding broadly applicable, effective fixed sampling strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Ablation studies</head><p>Subsequently we ablate different parameters for learning our sampling distribution p(I n |I a ) on the CUB200-2011 dataset. More ablations are shown in the appendix. To make the following experiments comparable, no learning rate scheduling was applied, as convergence may significantly change with different parameter settings. In contrast, the results in Tab 1-2 are obtained with our best parameter settings and a fixed learning rate scheduling. Without scheduling, our best parameter setting achieves a recall value of 65.7 and NMI of 69.2 on CUB200-2011.</p><p>Distance interval U : As presented in Sec. 4.1,p(I n |I a ) is defined on a fixed interval U = [? min , ? max ] of distances. Similar to other works <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b17">18]</ref>, this allows us to additionally regularize the sampling process by clipping the tails of the true range of distances [0, 2] on ?. Tab. 5 (a) compares different combinations of ? min , ? max . We observe that, while each option leads to significant performance boost compared to the static sampling strategies, an interval U = [0.1, 1.4] results in the most effective sampling process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of bins K:</head><p>Next, we analyze the impact of the U resolution in Tab. 5 (b), i.e. the number of bins K. This affects the flexibility of p(I n |I a ), but also the complexity of the actions a to be predicted. As intuitively expected, increasing K allows for better adaption and performance until the complexity grows too large.</p><p>Initialization of p(I n |I a ): Finally, we analyze how the initialization of p(I n |I a ) impacts learning. Tab. 5 (c) compares the performance using different initial distributions, such as a neutral uniform initialization (i.e. random sampling) (U [0.1,1.4] ), emphasizing semi-hard negatives I n early on (U [0.3,0.7] ) or a proxy to <ref type="bibr" target="#b59">[60]</ref> (N (0.5, 0.05)). We observe that our learned sampling process benefits from a meaningful, but generic initial configuration of p(I n |I a ), U [0.3,0.7] , to effectively adapt the learning process of ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper presents a learned adaptive triplet sampling strategy using Reinforcement Learning. We optimize a teacher network to adjust the negative sampling distribution to the ongoing training state of a DML model. By training the teacher to directly improve the evaluation metric on a held-back validation set, the resulting training signal optimally facilitates DML learning. Our experiments show that our adaptive sampling strategy improves significantly over static sampling distributions. Thus, even though only built on top of basic triplet losses, we achieve competitive or even superior performance compared to the state-of-the-art of DML on multiple standard benchmarks sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Additional Ablation Experiments</head><p>We now conduct further ablation experiments for different aspects of our proposed approach based on the CUB200-2011 <ref type="bibr" target="#b55">[56]</ref> dataset. Note, that like in our main paper we did not apply any learning rate scheduling for the results of our approach to establish comparable training settings. Performance with Inception-BN: For fair comparison, we also evaluate using Inception-V1 with Batch-Normalization <ref type="bibr" target="#b21">[22]</ref>. We follow the standard pipeline (see e.g. <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b42">43]</ref>), utilizing Adam <ref type="bibr" target="#b25">[26]</ref> with images resized and random cropped to 224x224. The learning rate is set to 10 ?5 . We retain the size of the policy network and other hyperparameters. The results on CUB200-2011 <ref type="bibr" target="#b55">[56]</ref> and CARS196 <ref type="bibr" target="#b28">[29]</ref> are listed in <ref type="table" target="#tab_6">Table 6</ref>. On CUB200, we achieve results competitive to previous state-of-the-art methods. On CARS196, we achieve a significant boost over baseline values and competitive performance to the state-of-the-art. Validation set I val : The validation set I val is sampled from the training set I train , composed as either a fixed disjoint, held-back subset or repetitively re-sampled from I train during training. Further, we can sample I val across all classes or include entire classes. We found (Tab. 7 (d)) that sampling I val from each class works much better than doing it per class. Further, resampling I val provides no significant benefit at the cost of an additional hyperparameter to tune. Composition of states s and target metric e: Choosing meaningful target metrics e(?(?; ?), I val ) for computing rewards r and a representative composition of the training state s increases the utility of our learned policy ? ? . To this end, Tab. 8 compares different combinations of state compositions and employed target metrics e. We observe that incorporating information about the current structure of the embedding space ? into s, such as intra-and inter-class distances, is most crucial for effective learning and adaptation. Moreover, also incorporating performance metrics into s which directly represent the current performance of the model ?, e.g. Recall@1 or NMI, additional adds some useful information. Frequency of updating ? ? : We compute the reward r for an adjustment a to p(I n |I a ) every M DML training iterations. High values of M reduce the variance of the rewards r, however, at the cost of slow policy updates which result in potentially large discrepancies to updating ?. Tab. 9 (a) shows that choosing M from the range <ref type="bibr" target="#b29">[30,</ref><ref type="bibr">70]</ref> results in a good trade-off between the stability of r and the adaptation of p(I n |I a ) to ?. Moreover, we also show the result for setting M = ?, i.e. using the initial distribution throughout  <ref type="bibr" target="#b48">[49]</ref> negatives to hard negatives; bottom row: shifting a static distance-based sampling <ref type="bibr" target="#b59">[60]</ref> to gradually sample harder negatives. training without adaptation. Fixing this distribution performs worse than the reference method Margin loss with static distance-based sampling <ref type="bibr" target="#b59">[60]</ref>. Nevertheless, frequently adjusting p(I n |I a ) leads to significant superior performance, which indicates that our policy ? ? effectively adapts p(I n |I a ) to the training state of ?. Importance of long-term information for states s: For optimal learning, s should not only contain information about the current training state of ?, but also about some history of the learning process. Therefore, we compose s of a set of running averages over different lengths R for various training state components, as discussed in the implementation details of the main paper. Tab. 9 (b) confirms the importance of long-term information for stable adaptation and learning. Moreover, we see that the set of moving averages R = {2, 8, 16, 32} works best.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Curriculum Evaluations</head><p>In <ref type="figure" target="#fig_3">Fig. 5</ref> we visually illustrate the fixed curriculum schedules which we applied for the comparison experiment in Sec. 5.3 of our main paper. We evaluated various schedules -Linear progression of sampling intervals starting at semihard negatives going to hard negatives, and progressively moving U-dist <ref type="bibr" target="#b59">[60]</ref> towards harder negatives. The schedules visualized were among the best performing ones to work for both CUB200 and CARS196 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison of RL Algorithms</head><p>We evaluate the applicability of the following RL algorithms for optimizing our policy ? ? (Eq. 4 in the main paper):</p><p>? REINFORCE algorithm <ref type="bibr" target="#b58">[59]</ref> with and without Exponential Moving Average (EMA)  ? Advantage Actor Critic (A2C) <ref type="bibr" target="#b54">[55]</ref> ? Rainbow Q-Learning <ref type="bibr" target="#b18">[19]</ref> without extensions (vanilla) and using Priority Replay and 2-Step updates</p><p>? Proximal Policy Optimization (PPO) <ref type="bibr" target="#b50">[51]</ref> applied to REINFORCE with EMA and to A2C.</p><p>For a comparable evaluation setting we use the CUB200-2011 <ref type="bibr" target="#b55">[56]</ref> dataset without learning rate scheduling and fixed 150 epochs of training. Within this setup, the hyperparameters related to each method are optimized via crossvalidation. Tab. 10 shows that all methods, except for vanilla Q-Learning, result in an adjustment policy ? ? for p(I n |I a ) which outperforms static sampling strategies. Moreover, policy-based methods in general perform better than Q-Learning based methods with PPO being the best performing algorithm. We attribute this to the reduced search space (Q-Learning methods need to evaluate in state-actions space,   <ref type="table">Table 10</ref>: Comparison of different RL algorithms. For policybased algorithms (REINFORCE, PPO) we either use Exponential Moving Average (EMA) as a variance-reducing baseline or employ Advantage Actor Critic (A2C). In addition, we also evaluate Q-Learning methods (vanilla and Rainbow Q-Learning). For the Rainbow setup we use Priority Replay and 2-Step value approximation. Margin loss <ref type="bibr" target="#b59">[60]</ref> is used as a representative reference for static sampling strategies.</p><p>acting off-policy, since state-action pairs of previous training iterations may no longer be representative for current training stages. <ref type="figure">Figure 6</ref> shows a UMAP <ref type="bibr" target="#b33">[34]</ref> embedding of test image features for CUB200-2011 <ref type="bibr" target="#b55">[56]</ref> learned by our model using PADS. We can see clear groupings for birds of the same and similar classes. Clusterings based on similar background is primarily due to dataset bias, e.g. certain types of birds occur only in conjunction with specific backgrounds. <ref type="figure">Figure 6</ref>: UMAP embedding based on the image embeddings ?(?; ?) obtained from our proposed approach on CUB200-2011 <ref type="bibr" target="#b55">[56]</ref> (Test Set).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Qualitative UMAP Visualization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Pseudo-Code</head><p>Algorithm 1 gives an overview of our proposed PADS approach using PPO with A2C as underlying RL method. Before training, our sampling distributions p(I n |I a ) is initialized with an initial distribution. Further, we initialize both the adjustment policy ? ? and the pre-update auxiliary policy ? old ? for estimating the PPO probability ratio. Then, DML training is performed using triplets with random anchorpositive pairs and sampled negatives from the current sampling distribution p(I n |I a ). After M iterations, all reward and state metrics E, E * are computed on the embeddings ?(?; ?) of I val . These values are aggregated in a training reward r and input state s. While r is used to update the current policy ? ? , s is fed into the updated policy to estimate adjustments a to the sampling distribution p(I n |I a ). Finally, after M old iterations (e.g. we set to M old = 3) ? old ? is updated with the current policy weights ?. F. Typical image retrieval failure cases <ref type="figure">Fig. 7</ref> shows nearest neighbours for good/bad test set retrievals. Even though the nearest neighbors do not always share the same class label as the anchor, all neighbors are very similar to the bird species depicted in the anchor images. Failures are due to very subtle differences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Sampling distribution p(I n |I a ). We discretize the distance interval U = [? min , ? max ] into K equisized bins u k with individual sampling probabilities p k .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Overview of approach. Blue denotes the standard Deep Metric Learning (DML) setup using triplets {I a , I p , I n }.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Averaged progression of p(I n |I a ) over multiple training runs on CUB200-2011, CARS196 and SOP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Visual comparison between fixed sampling curriculums and a learned progression of p(I n |I a ) by PADS. Left: log-scale over p(I n |I a ), right: original scale. Top row: learned sampling schedule (PADS); middle row: linear shift of a sampling interval from semihard</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Dim R@1 R@2 R@4 NMI R@1 R@2 R@4 NMI R@1 R@10 R@100 NMI Margin[60] + U-dist (orig) 128 63.6 74.4 83.1 69.0 79.6 86.5 90.1 69.1 72.7 86.2 93.8 90.7 Margin[60] + U-dist (ReImp, ? = 1.2) 128 63.5 74.9 84.4 68.1 80.1 87.4 91.9 67.6 74.6 87.5 94.2 90.7 Margin[60] + U-dist (ReImp, ? = 0.6) 128 63.0 74.3 83.0 66.9 79.7 87.0 91.8 67.1 73.5 87.2 93.9 89.3 ReImp. denotes our re-implementations and Dim the dimensionality of ?.</figDesc><table><row><cell>Margin[60] + PADS (Ours)</cell><cell>128 67.3 78.0 85.9 69.9 83.5 89.7 93.8 68.8 76.5 89.0 95.4 89.9</cell></row><row><cell>Triplet[49] + semihard (orig)</cell><cell>64 42.6 55.0 66.4 55.4 51.5 63.8 73.5 53.4 66.7 82.4 91.9 89.5</cell></row><row><cell>Triplet[49] + semihard (ReImp)</cell><cell>128 60.6 72.3 82.1 65.5 71.9 81.5 88.5 64.1 73.5 87.5 94.9 89.2</cell></row><row><cell>Triplet[49] + U-dist (ReImp)</cell><cell>128 62.2 73.2 82.8 66.3 78.0 85.6 91.4 65.7 73.9 87.7 94.5 89.3</cell></row><row><cell>Triplet[49] + PADS (Ours)</cell><cell>128 64.0 75.5 84.3 67.8 79.9 87.5 92.3 67.1 74.8 88.2 95.0 89.5</cell></row><row><cell cols="2">Table 1: Comparison of our proposed adaptive negative sampling (PADS) against common static negative sampling strategies:</cell></row><row><cell cols="2">semihard negative mining[38] (semihard) and static distance-based sampling (U-dist)[60] using triplet[49] and margin loss[60].</cell></row></table><note>PyTorch framework[41] on a single NVIDIA Titan X. Benchmark datasets. We evaluate the performance on three common benchmark datasets. For each dataset the first half of classes is used for training and the other half is used for testing. Further, we use a random subset of 15% of the training images for our validation set I val . We use: CARS196[29], with 16,185 images from 196 car classes. CUB200-2011[56], 11,788 bird images from 200 classes. Stanford Online Products (SOP)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>65.7 76.7 62.6 79.1 87.1 92.1 69.7 68.7 83.2 92.4 89.3 HTL[12] 512 57.1 68.8 78.7 -81.4 88.0 92.7 -74.8 88.3 94.</figDesc><table><row><cell>Dataset</cell><cell>CUB200-2011[56]</cell><cell>CARS196[29]</cell><cell></cell><cell cols="2">SOP[38]</cell></row><row><cell>Approach</cell><cell cols="6">Dim R@1 R@2 R@4 NMI R@1 R@2 R@4 NMI R@1 R@2 R@4 NMI</cell></row><row><cell>HTG[63]</cell><cell cols="2">512 59.5 71.8 81.3 -76.5 84.7 90.4 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>HDML[65]</cell><cell cols="6">512 53.7 8 -</cell></row><row><cell>DVML[31]</cell><cell cols="6">512 52.7 65.1 75.5 61.4 82.0 88.4 93.3 67.6 70.2 85.2 93.8 90.8</cell></row><row><cell>A-BIER[39]</cell><cell cols="6">512 57.5 68.7 78.3 -82.0 89.0 93.2 -74.2 86.9 94.0 -</cell></row><row><cell>MIC[45]</cell><cell cols="6">128 66.1 76.8 85.6 69.7 82.6 89.1 93.2 68.4 77.2 89.4 95.6 90.0</cell></row><row><cell>D&amp;C[47]</cell><cell cols="6">128 65.9 76.6 84.4 69.6 84.6 90.7 94.1 70.3 75.9 88.4 94.9 90.2</cell></row><row><cell>Margin[60]</cell><cell cols="6">128 63.6 74.4 83.1 69.0 79.6 86.5 90.1 69.1 72.7 86.2 93.8 90.8</cell></row><row><cell>Ours (Margin[60] + PADS)</cell><cell cols="6">128 67.3 78.0 85.9 69.9 83.5 89.7 93.8 68.8 76.5 89.0 95.4 89.9</cell></row><row><cell cols="2">Significant increase in network parameter:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">HORDE[23]+contrastive loss[17] 512 66.3 76.7 84.7 -83.9 90.3 94.1 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>SOFT-TRIPLE[43]</cell><cell cols="6">512 65.4 76.4 84.5 -84.5 90.7 94.5 70.1 78.3 90.3 95.9 92.0</cell></row><row><cell>Ensemble Methods:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Rank[58]</cell><cell cols="6">1536 61.3 72.7 82.7 66.1 82.1 89.3 93.7 71.8 79.8 91.3 96.3 90.4</cell></row><row><cell>DREML[62]</cell><cell cols="3">9216 63.9 75.0 83.1 67.8 86.0 91.7 95.0 76.4 -</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>ABE[25]</cell><cell cols="6">512 60.6 71.5 79.8 -85.2 90.5 94.0 -76.3 88.4 94.8 -</cell></row><row><cell></cell><cell></cell><cell cols="5">how our adaptive sampling distribution progresses</cell></row><row><cell></cell><cell cols="6">during training by averaging the results of multiple training</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Further, on each dataset, during the first half of training p(I n |I a ) quickly peaks on a sparse set of bins u k , as intuitively expected, since most triplets are still informative. As training continues, p(I n |I a ) begins to yield both harder and easier negatives, thus effectively sampling from a wider distribution. This observation confirms the result of Wu et al.<ref type="bibr" target="#b59">[60]</ref> which proposes to ease the large gradient variance introduced by hard negatives with also adding easier negatives. Moreover, for each dataset we observe a different progression of p(I n |I a ) which indicates that manually designing similar sampling strategies is difficult, as also confirmed by our results in Tab. 1 and 4.Transfer of ? ? and p(I n |I a ): Tab. 3 investigates how well a trained policy ? ? or final sampling distribution p(I n |I a ) from a reference run transfer to differently ( =) or equally Init. Reference fix ? ? fix last p(I n |I a )</figDesc><table><row><cell>R@1</cell><cell>=</cell><cell>65.4</cell><cell>64.3</cell><cell>59.0</cell></row><row><cell>R@1</cell><cell>=</cell><cell>65.4</cell><cell>65.8</cell><cell>57.6</cell></row></table><note>Comparison to the state-of-the-art DML methods on CUB200-2011[56], CARS196[29] and SOP[38]. Dim denotes the dimensionality of ?.runs with different network initializations. While on CARS196 the distribution p(I n |I a ) strongly emphasizes smaller distances d an , we observe on CUB200-2011 and SOP generally a larger variance of p(I n |I a ).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison to curriculum learning strategies with predefined linear and non-linear progression of p(I n |I a ). [? min , ? max ] [0, 2] [0.1, 1.4] [0.25, 1.0] [0.5, 1.4] Varying the interval U = [?min, ?max] of distances dan used for learning p(In|Ia). The number of bins u k is kept fixed to K = 30.</figDesc><table><row><cell>Recall@1</cell><cell>64.7</cell><cell>65.7</cell><cell cols="2">64.8</cell><cell>63.7</cell></row><row><cell>NMI</cell><cell>67.5</cell><cell>69.2</cell><cell cols="2">68.2</cell><cell>67.5</cell></row><row><cell cols="2">(a) Num. bins K</cell><cell>10</cell><cell>30</cell><cell>50</cell><cell>100</cell></row><row><cell cols="2">Recall@1</cell><cell cols="4">63.8 65.7 65.3 64.9</cell></row><row><cell>NMI</cell><cell></cell><cell cols="4">67.8 69.2 68.7 68.6</cell></row><row><cell cols="6">(b) Varying the number of bins u k used to discretize the range of</cell></row><row><cell cols="5">distances U = [0.1, 1.4] used for learning p(In|Ia).</cell></row><row><cell cols="6">Init. Distr. U [0.1,1.4] N (0.5, 0.05) U [0.3,0.7]</cell></row><row><cell>Recall@1</cell><cell cols="2">63.9</cell><cell>65.0</cell><cell></cell><cell>65.7</cell></row><row><cell>NMI</cell><cell cols="2">67.0</cell><cell>68.6</cell><cell></cell><cell>69.2</cell></row></table><note>(c) Comparison of p(In|Ia)-initializations on distance interval U = [0.1, 1.4]. U [a,b] denotes uniform emphasis in [a, b] with low probabil- ities outside the interval. N (?, ?) denotes a normal distribution.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note>Ablation experiments analyzing various parameters for learning p(I n |I a ).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Comparison to the state-of-the-art DML methods on CUB200-2011<ref type="bibr" target="#b55">[56]</ref> and CARS196<ref type="bibr" target="#b28">[29]</ref> using the Inception-BN Backbone (see e.g.<ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b42">43]</ref>) and embedding dimension of 512.</figDesc><table><row><cell cols="2">Validation Set: I By val</cell><cell>I Per val</cell><cell>I By, R val</cell><cell>I Per, R val</cell></row><row><cell>Recall@1</cell><cell cols="3">62.6 65.7 63.0</cell><cell>65.8</cell></row><row><cell>NMI</cell><cell cols="3">67.7 69.2 67.8</cell><cell>69.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Composition of I val . Superscript By/P er denotes usage of entire classes/sampling across classes. R denotes re-sampling during training with best found frequency of</figDesc><table><row><cell>1 50 epochs .</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Comparison of different compositions of the training state s and reward metric e. Dist. denotes average intraand inter-class distances. Recall in state composition denotes all Recall@k-values, whereas for the target metric only Recall@1 was utilized. unlike policy-methods, which work directly over the action space), as well as not employing replay buffers, i.e. not R@1 64.4 65.7 65.4 65.2 65.1 61.9 63.5 NMI 68.3 69.2 69.2 68.9 69.0 67.0 68.1 (a) Evaluation of the policy update frequency M . Evaluation of various sets R of moving average lengths.</figDesc><table><row><cell>M</cell><cell>10</cell><cell>30</cell><cell>50</cell><cell>70</cell><cell>100</cell><cell>?</cell><cell>[60]</cell></row><row><cell>R</cell><cell>2</cell><cell cols="6">2, 32 2, 8, 16, 32 2, 8, 16, 32, 64</cell></row><row><cell cols="3">R@1 64.5 65.4</cell><cell></cell><cell>65.7</cell><cell></cell><cell>65.6</cell><cell></cell></row><row><cell cols="3">NMI 68.6 69.1</cell><cell></cell><cell>69.2</cell><cell></cell><cell>69.3</cell><cell></cell></row><row><cell>(b)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>Ablation experiments: (a) evaluates the influence of the number of DML iterations M performed before updating the policy ? ? using a reward r and, thus, the update frequency of ? ? . (b) analyzes the benefit of long-term learning progress information added to training states s by means of using various moving average lengths R.</figDesc><table><row><cell>Approach</cell><cell>R@1 NMI</cell></row><row><cell>Margin[60]</cell><cell>63.5 68.1</cell></row><row><cell>REINFORCE</cell><cell>64.2 68.5</cell></row><row><cell cols="2">REINFORCE, EMA 64.8 68.9</cell></row><row><cell cols="2">REINFORCE, A2C 65.0 69.0</cell></row><row><cell>PPO, EMA</cell><cell>65.4 69.0</cell></row><row><cell>PPO, A2C</cell><cell>65.7 69.2</cell></row><row><cell>Q-Learn</cell><cell>63.2 67.9</cell></row><row><cell cols="2">Q-Learn, PR/2-Step 64.9 68.5</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Opposed to bandits, in our RL setup, actions which are sampled from ? ? influence future training states of the learner. Thus, the policy implicitly learns state-transition dynamics.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank David Yu-Tung Hui (MILA) for valuable insights regarding the choice of RL Methods. This work has been supported in part by Bayer AG, the German federal ministry BMWi within the project "KI Absicherung", and a hardware donation from NVIDIA corporation.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>This part contains supporting or additional experiments to the main paper, such as additional ablations and qualitative evaluations.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The sphere game in n dimensions</title>
		<ptr target="http://faculty.madisoncol-lege.edu/alehnen/sphere/hypers.htm" />
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Misha</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>G?mez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando</forename><surname>Shillingford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cliquecnn: Deep unsupervised exemplar learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miguel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artsiom</forename><surname>Bautista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Sanakoyeu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Tikhoncheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3846" to="3854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?r?me</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised learning by predicting noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improving spatiotemporal self-supervision by deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>B?chler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brattoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bj?rn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Beyond triplet loss: a deep quadruplet network for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Human motion analysis with deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huseyin</forename><surname>Coskun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">Joseph</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sailesh</forename><surname>Conjeti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Nassir Navab, and Federico Tombari</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep adversarial metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueqi</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Learning what data to learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Self-supervised representation learning by rotation feature decoupling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep metric learning with hierarchical triplet loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR Proceedings</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptive sampling for sgd by exploiting side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Gopal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automated curriculum learning for neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">On the power of curriculum learning in training deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Hacohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphna</forename><surname>Weinshall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Smart mining for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2821" to="2829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Rainbow: Combining improvements in deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Modayil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Hado Van Hasselt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Dabney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Horgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Discriminative deep metric learning for face verification in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Addressing the loss-metric mismatch with adaptive loss alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuangfei</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Talbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel?ngel</forename><surname>Bautista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Susskind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Metric learning with horde: High-order regularizer for deep embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aymeric</forename><surname>Histace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Product quantization for nearest neighbor search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Jegou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Attention-based ensemble for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonsik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhavya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keunjoo</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Content and style disentanglement for artistic style transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Kotovenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artsiom</forename><surname>Sanakoyeu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bj?rn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Intl. Conf. on Computer Vision (ICCV)</title>
		<meeting>the Intl. Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The epoch-greedy algorithm for multi-armed bandits with side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>J. C. Platt, D. Koller, Y. Singer, and S. T. Roweis</editor>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="817" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep variational metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueqi</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiyuan</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sphereface: Deep hypersphere embedding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhiksha</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Introduction to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prabhakar</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Umap: Uniform manifold approximation and projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leland</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathaniel</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Grossberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">29</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unsupervised video understanding by reconciliation of posture similarities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Milbich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Bautista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Sutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bj?rn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by discovering reliable image relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Milbich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omair</forename><surname>Ghori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferran</forename><surname>Diego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bj?rn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition (PR)</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">102</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">No fuss distance metric learning using proxies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="4004" to="4012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep metric learning with bier: Boosting independent embeddings robustly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Waltner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Possegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameter sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melody</forename><forename type="middle">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Softtriple loss: Deep metric learning without triplet sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baigui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Searching for activation functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno>abs/1710.05941</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Mic: Mining interclass characteristics for improved metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biagio</forename><surname>Brattoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Revisiting training strategies and generalization performance in deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Milbich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samarth</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bj?rn</forename><surname>Ommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">Paul</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Divide and conquer the embedding space for metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artsiom</forename><surname>Sanakoyeu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vadim</forename><surname>Tschernezki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uta</forename><surname>Buchler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Data parameters: A new family of parameters for learning a differentiable curriculum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreyas</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Decoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Trust region policy optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Moritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Proximal policy optimization algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning where to sample in structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Improved deep metric learning with multiclass n-pair loss objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Selfsupervised learning of pose embeddings from spatiotemporal relations in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?mer</forename><surname>S?mer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Dencker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bj?rn</forename><surname>Ommer</surname></persName>
		</author>
		<idno>2017. 1</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Reinforcement Learning: An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>The MIT Press</publisher>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">The caltech-ucsd birds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deep metric learning with angular loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilei</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanqing</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2593" to="2601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Ranked list loss for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinshao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elyor</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Garnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><forename type="middle">M</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Sampling matters in deep embedding learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chao-Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">SNAS: stochastic neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Deep randomized ensembles for metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Souvenir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Pless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">An adversarial approach to hard triplet generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiru</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongming</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongtao</forename><surname>Guo-Jun Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian-Sheng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Directional statistics-based deep metric learning for image classification and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuefei</forename><surname>Zhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Hardness-aware deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaodong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ours</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">512</biblScope>
		</imprint>
	</monogr>
	<note>Margin[60] + PADS</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dist</forename><surname>Recall</surname></persName>
		</author>
		<imprint>
			<publisher>NMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dist</surname></persName>
		</author>
		<idno>NMI 65</idno>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
