<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Weakly Supervised Contrastive Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkai</forename><surname>Zheng</surname></persName>
							<email>zhengmingkai@sensetime.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
							<email>wangfei91@mail.ustc.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>You</surname></persName>
							<email>youshan@sensetime.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">SenseTime Research</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Automation</orgName>
								<orgName type="department" key="dep2">Institute for Artificial Intelligence</orgName>
								<orgName type="department" key="dep3">Beijing National Research Center for Information Science and Technology (BNRist)</orgName>
								<orgName type="institution" key="instit1">Tsinghua University</orgName>
								<orgName type="institution" key="instit2">Tsinghua University (THUAI)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
							<email>qianchen@sensetime.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Automation</orgName>
								<orgName type="department" key="dep2">Institute for Artificial Intelligence</orgName>
								<orgName type="department" key="dep3">Beijing National Research Center for Information Science and Technology (BNRist)</orgName>
								<orgName type="institution" key="instit1">Tsinghua University</orgName>
								<orgName type="institution" key="instit2">Tsinghua University (THUAI)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
							<email>xgwang@ee.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="laboratory">SenseTime Research</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<settlement>Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
							<email>c.xu@sydney.edu.au</email>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Faculty of Engineering</orgName>
								<orgName type="institution">The University of Sydney</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Weakly Supervised Contrastive Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unsupervised visual representation learning has gained much attention from the computer vision community because of the recent achievement of contrastive learning. Most of the existing contrastive learning frameworks adopt the instance discrimination as the pretext task, which treating every single instance as a different class. However, such method will inevitably cause class collision problems, which hurts the quality of the learned representation. Motivated by this observation, we introduced a weakly supervised contrastive learning framework (WCL) to tackle this issue. Specifically, our proposed framework is based on two projection heads, one of which will perform the regular instance discrimination task. The other head will use a graphbased method to explore similar samples and generate a weak label, then perform a supervised contrastive learning task based on the weak label to pull the similar images closer. We further introduced a K-Nearest Neighbor based multi-crop strategy to expand the number of positive samples. Extensive experimental results demonstrate WCL improves the quality of self-supervised representations across different datasets. Notably, we get a new state-of-the-art result for semi-supervised learning. With only 1% and 10% labeled examples, WCL achieves 65% and 72% ImageNet Top-1 Accuracy using ResNet50, which is even higher than SimCLRv2 with ResNet101.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Modern deep convolutional neural networks demonstrate outstanding performance on various computer vision * Equal contributions. ? Corresponding author. <ref type="figure" target="#fig_1">Figure 1</ref>. A example of the class collision problem. A typical instance discrimination method will treats the first column and the third column as a negative pair since there are different instance. However, the semantic information of the first column and the third column are very similar, treat them as positive pair should be much more reasonable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Similar Samples</head><p>datasets <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b29">30]</ref> and edge devices <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b34">35]</ref>. However, most successful methods are trained in the supervised fashion; they usually require a large volume of labeled data that is very hard to collect. Meanwhile, the quality of data annotations dramatically affects the performance. Recently, self-supervised learning shows its superiority and achieves promising results for unsupervised and semi-supervised learning in computer vision (e.g. <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b50">50]</ref>). These methods can learn generalpurpose visual representations without labels and have a good performance on linear classification and transferability to different tasks or datasets. Notably, a big part of the recent self-supervised representation learning framework is based on the idea of contrastive learning.</p><p>A typical contrastive learning based method adopts the noise contrastive estimation (NCE) <ref type="bibr" target="#b26">[27]</ref> to perform the nonparametric instance discrimination <ref type="bibr" target="#b40">[41]</ref> as the pretext task, which encourages the two augmented views of the same image to be pulled closer on the embedding space but pushes apart all the other images. Most of the recent works mainly improve the performance of contrastive learning from the image augmentation for positive samples and the exploration for negative samples. However, instance discrimination based methods will inevitably induce class collision problem, which means even for very similar instances, they still need to be pushed apart, as shown in <ref type="figure" target="#fig_1">Figure 1</ref>. This instance similarities thus tend to hurt the representation quality <ref type="bibr" target="#b0">[1]</ref>. In this way, identifying and even leveraging these similar instances plays a key role in the performance of learned representations. Surprisingly, the class collision problem seems to attract much lesser attention in contrastive learning. As far as we know, there has been little effort to identify similar samples. AdpCLR <ref type="bibr" target="#b49">[49]</ref> finds the top-K closest samples on the embedding space and treats these samples as their positives. However, in the early stage of training, the model cannot effectively extract the semantic information from the images; therefore, this method needs to use SimCLR <ref type="bibr" target="#b5">[6]</ref> to pre-train for a period of time, and then switch to AdpCLR to get the best performance. FNCancel <ref type="bibr" target="#b22">[23]</ref> proposed a similar idea but adopts a very different way to find the top-K similar instances; that is, for each sample, it generates a support set that contains different augmented views from the same image, then use mean or max aggregation strategy over the cosine similarity score between the augmented views in support set and finally identify the top-K similar samples. Nevertheless, the optimal support size is 8 in their experiments, requiring 8 additional forwarding passes to generate the embedding vectors. Obviously, these methods have two shortcomings. Firstly, they are both time-consuming. In the second place, the result of top-K closest samples might not be reciprocal, i.e. x i is the K closest sample of x j , but x j might not be the K closest sample of x i . In this case, x j will treat x i as a positive sample, but x i will treat x j as a negative sample, which will result in some conflicts.</p><p>In this paper, we regard the instance similarities as intrinsically weak supervision in representation learning and propose a weakly supervised contrastive learning framework (WCL) to address the class collision issue accordingly. In WCL, similar instances are assumed to share the same weak label comparing to other instances, and instances with the same weak label are expected to be aggregated. To determine the weak label, we model each batch of instances as a nearest neighbor graph; weak labels are thus determined and reciprocal for each connected component of the graph. Besides, we can further expand the graph by a KNN-based multi-crop strategy to propagate weak labels, such that we can have more positives for each weak label. In this way, similar instances with the same weak label can be pulled closer via the supervised contrastive learning <ref type="bibr" target="#b24">[25]</ref> task. Nevertheless, since the mined instance similarities might be noisy and not completely reliable, in practice, we adopt a two-head framework, one of which handles this weakly supervised task while the other is to perform the regular instance discrimination task. Extensive experiments demonstrate the effectiveness of our proposed method across different settings and various datasets.</p><p>Our contribution can be summarized as follows:</p><p>? We proposed a two-head based framework to address the class collision problem, with one head focusing on the instance discrimination and the other head for attracting similar samples.</p><p>? We proposed a simple graph based and parameter-free method to find similar samples adaptively.</p><p>? We introduced a K-Nearest Neighbor based multicrops strategy that can provide much more diverse information than the standard multi-crops strategy.</p><p>? The experimental result shows WCL establishes a new state-of-the-art performance for contrastive learning based methods. With only 1% and 10% labeled samples, WCL achieves 65% and 72% Top-1 accuracy on ImageNet using ResNet50. Notably, this result is even higher than SimCLRv2 with ResNet101.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Self-Supervised Learning.</p><p>Early work in selfsupervised learning mainly focuses on the designing of different pretext tasks. For example, predict a relative offset for a pair of patches <ref type="bibr" target="#b11">[12]</ref>, solving the jigsaw puzzles <ref type="bibr" target="#b32">[33]</ref>, colorize the gay-scaled images <ref type="bibr" target="#b48">[48]</ref>, image inpainting <ref type="bibr" target="#b13">[14]</ref>, predicting the rotation angle <ref type="bibr" target="#b15">[16]</ref>, unsupervised deep clustering <ref type="bibr" target="#b3">[4]</ref> and image reconstruction <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b27">28]</ref>. Although these methods have shown their effectiveness, they lack the generality of the learned representations.</p><p>Contrastive Learning. Contrastive learning <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b39">40]</ref> has become one of the most successful methods in the field of self-supervised learning. As we mentioned, most recent works mainly focus on the augmentation for positive samples and the exploration for negative samples. For example, SimCLR <ref type="bibr" target="#b5">[6]</ref> proposed composition of data augmentations e.g. Grayscale, Random Resized Cropping, Color Jittering, and Gaussian Blur to making the model robust to these transformations. InfoMin <ref type="bibr" target="#b36">[37]</ref> further introduced an "InfoMin principle" which suggests that a good augmentation strategy should reduce the mutual information between the positive pairs while keeping the downstream task-relevant information intact. To explore the use of negative samples, InstDisc <ref type="bibr" target="#b40">[41]</ref> proposed a memory bank store</p><formula xml:id="formula_0">1 2 1 = ?( 1 ) 2 = ?( 2 ) ?( 1 ) ?( 2 ) Instance Discrimination ? NCE ? swap 1 2 ?( 1 ) ?( 2 )</formula><p>Shared Encoder <ref type="figure">Figure 2</ref>. The overall framework of our proposed method. We adopt a two head based structure (g and ?). The first head g will play a regular instance discrimination task. The second head ? will generate a weak label based on the connected component labeling process, then use the weak label to perform a supervised contrastive learning task. Please see more details in section 3.</p><p>the representation of all the images in the dataset. MoCo <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b7">8]</ref> increasing the number of negatives by using a momentum contrast mechanism that forces the query encoder to learn the representation from a slowly progressing key encoder and maintains a long queue to provide a large number of negative examples.</p><p>Contrastive Learning Without Negatives. Unlike the typical contrastive learning framework, BYOL <ref type="bibr" target="#b17">[18]</ref> can learn a high-quality visual representation without the negative samples. Specifically, it trains an online network to predict the target network representation of the same image under a different augmented view and using an additional predictor network on top of the online encoder to avoiding the model collapse. SimSiam <ref type="bibr" target="#b8">[9]</ref> extends BYOL to explore the siamese structure in contrastive learning further. Surprisingly, SimSiam prevents the model collapse even without the target network and large batch size; although the linear evaluation result is lower than BYOL, it performs better in the downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>In this section, we will first revisit the preliminary work on contrastive learning and address its limitations. Then we will introduce our proposed weakly supervised contrastive learning framework (WCL), which automatically mines similar samples while doing the instance discrimination. After that, the algorithm and the implementation details will also be explained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Revisiting Contrastive Learning</head><p>Typical contrastive learning methods adopt the noise contrastive estimation (NCE) objective for discriminating different instance in the dataset. Concretely, NCE objective encourages different augmentations of the same instance to be pulled closer in a latent space yet pushes away different instances' augmentations. Following the setup of SimCLR <ref type="bibr" target="#b5">[6]</ref>, given a batch of unlabeled samples {x} N i=1 , we randomly apply a composition of augmentation functions T (?) to obtain two different views of the same instance, which can be written as</p><formula xml:id="formula_1">{x 1 } N i=1 = T (x, ? 1 ) and {x 2 } N i=1 = T (x, ? 2 )</formula><p>where ? is random seed for T . Then, a convolutional neural network based encoder F(?) will extract the information from different augmentations, that can be expressed by</p><formula xml:id="formula_2">{h 1 } = F({x 1 } N i=1 ) and {h 2 } = F({x 2 } N i=1</formula><p>). Finally, a non-linear projection head z = g(h) maps representations h to the space where the NCE objective is applied. If we denote (z i , z j ) as a positive pair, the NCE objective can be expressed as</p><formula xml:id="formula_3">L N CE = ? log exp(sim(z i , z j )/? ) N k=1 1 [k? =i] exp(sim(z i , z k )/? ) . (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Instance Similarities as Weak Supervision</head><p>The instance discrimination based methods have already shown promising performance for unsupervised pretraining. However, this line of solution ignores the relationships between different images because only the augmentations from the same image will be regarded as the same class. Inspired by previous works, we can leverage the embedding vectors to explore the relations between different images. Specifically, we will generate a weak label based on the embedding vectors and then use it as a supervisory signal to attract similar samples in the embedding space. However, direct use of weak supervision will cause two problems. First, there is a natural conflict between "instance discrimination" and "similar sample attraction" since one wants to push all the different instances away, and the other wants to pull similar samples closer. Second, there might be noise in the weak label, especially in the early training stages. Simply attracting similar samples based on the weak label will slow down the convergence of the model.</p><p>Two-head framework. To resolve these issues, we proposed an auxiliary projection head ?(?). In this case, the primary projection head g(?) will still perform a regular instance discrimination task to focus on the instance level information; the auxiliary projection head consists of the same structure with g(?) and will explore the similar samples and generate a weak label as the supervisory signal to attract similar samples. With these two heads of distinct responsibilities, we can further transform the features extracted by the encoder F into different embedding spaces to resolve the conflict. Moreover, the primary projection head will ensure the model's convergence even when the weak label has some noise. The information extracted from the auxiliary projection head can be written as</p><formula xml:id="formula_4">v i = ?(F(T (x i , ?)))).<label>(2)</label></formula><p>Suppose we have obtained a weak label y ? R N ?N based on v which denotes whether a pair of samples is similar (i.e. y ij = 1 means x i and x j are similar). Different from Eq.</p><p>(1) that naturally forms positive pairs through augmentations, we can then leverage the label y ij to indicate whether x i and x j can produce a positive pair or not. By introducing an indicator 1 yij =1 into Eq. (1), we achieve the supervised contrastive loss <ref type="bibr" target="#b24">[25]</ref> </p><formula xml:id="formula_5">L sup = 1 N N i=0 L i sup (3) L i sup = ? N j 1 yij =1 log exp(sim(v i , v j )/? ) N k=1 1 [k? =i] exp(sim(v i , v k )/? ) ,<label>(4)</label></formula><p>which has been shown to be more effective than the traditional supervised cross-entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Weak Label Generation</head><p>In this section, we will elaborate how to generate the weak label for the mini-batch of samples. The overall idea can be summarized into two points: First, for each sample, the closest sample can be regarded as a similar sample. Second, if (x i , x j ) and (x j , x k ) are two pairs of similar samples, then we can think that x i and x k are also similar.</p><p>Suppose we use the auxiliary projection head ? to map a batch of samples to N embeddings</p><formula xml:id="formula_6">V = {v 1 , v 2 , ..., v N }.</formula><p>Then, for each sample v i , we find the closest sample v j by computing the cosine similarity score. Now, we can define an adjacency matrix by:</p><formula xml:id="formula_7">A(i, j) = 1, if i = k 1 j or j = k 1 i 0, otherwise<label>(5)</label></formula><p>Here, we use k 1 i to denote the 1-nearest neighbour of v i . Basically, Eq.(5) will generate a sparse and symmetric 1nearest neighbor graph where each vertex is linked with its closest sample. To find out all similar samples, we can convert this problem into a Connected Components Labeling (CCL) process; that is, for each sample, we want to find all the reachable samples based on the 1-nearest neighbor graph. This is a traditional graph problem that can be easily solved by the famous Hoshen-Kopelman algorithm <ref type="bibr" target="#b21">[22]</ref> (also known as the two-pass algorithm). We define an undirected graph by G = (V, E) where V is the embedding from ?, and edges E connecting the vertex A(i, j) = 1. The algorithm adopts a Disjoint-set data structure that consists of three operations: makeSet, union and find (see the definition in Algorithm 1). Basically, it first creates a singleton set for each v in V , then traverses each edge in E and merges different sets through the edges; finally, it returns the set for each vertex that belongs to. Back to our proposed idea, we will treat the samples in the same set as similar samples. Now, the weak label can be defined as:</p><formula xml:id="formula_8">y ij = 1, if find(v i ) = find(v j ) and i ? = j 0, otherwise<label>(6)</label></formula><p>Such weak label generation method has several advantages.</p><p>? This is a parameter-free process, so we do not need any hyperparameter optimization. ? Based on the definition of an undirected graph and connected components, the weak label is always reciprocal. (i.e. y ij = y ji ) ? This is a deterministic process; the final result does not depend on any initial state. </p><formula xml:id="formula_9">v for v in V do makeSet(v) end for each (v i , v j ) in E do if find(v i ) ? = find(v j ) then union(find(v i ), find(v j )) end end for each v in V do</formula><p>return the set contains v: find(v) end Output: The corresponding identification of the connected component for each v.</p><p>The weak label will be used as the supervisory signal for the auxiliary projection head ?. However, if v i and v j are in the same set, sim(v i , v j ) is very likely to be a large number. According to Eq. (4), directly using the weak label will cause L sup to be very small, which is not conducive to the model's optimization. To resolve this issue, we can simply swap the weak label to supervise the same batch of samples with different augmentations. Concretely, we derive embeddings V 1 and V 2 from two types of augmentations, based on which we generate the corresponding weak label y 1 , y 2 . Then y 1 will be used as the supervisory signal for V 2 and vice versa. The swapped version of Eq. (3) can be written as:</p><formula xml:id="formula_10">L swap = L sup (V 1 , y 2 ) + L sup (V 2 , y 1 ).<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Label Propagation with Multi-Crops</head><p>Since the comparison between random crops of an image plays the key role in contrastive learning, there are lots of previous works <ref type="bibr" target="#b9">[10]</ref> pointing out that increasing the number of crops or views can significantly increase the representation quality. SwAV <ref type="bibr" target="#b4">[5]</ref> introduced a multi-crop strategy that adds K additional low-resolution crops in each batch. Using low-resolution images can greatly reduce computational costs. However, the multiple crops of the same image may have many overlap areas. In this case, more crops may not provide additional effective information. To address this issue, we proposed a K-Nearest Neighbor based Multi-crops strategy. Specifically, we will store the feature h 1 for every batch and then use these features to find the K closest samples based on the cosine similarity at the end of each epoch. Finally, we will use the low-resolution crops of the K closest images in the next epoch. If we apply the L swap on the K-NN multi-crops, the number of positive samples can be expended to K times. Note that the K-NN result is unre-</p><formula xml:id="formula_11">Algorithm 2: Weakly Supervised Contrastive Learning (WCL) Input: {x 1 } N i=1 and {x 2 } N i=1</formula><p>: a batch of samples with different augmentations. F: the backbone network. g: the first projection head. ?: the auxiliary projection head. while network not converge do Initialize an empty list L ; for i=1 to step do</p><formula xml:id="formula_12">h 1 = F({x 1 } N i=1 ) h 2 = F({x 2 } N i=1 ) z 1 = g(h 1 ) z 2 = g(h 2 ) v 1 = ?(h 1 ) v 2 = ?(h 2 ) Calculate contrastive loss L N CE Eq. (1) Generate weak label y 1 , y 2 based on v 1 , v 2</formula><p>Calculate swapped loss L swap Eq. <ref type="formula" target="#formula_10">(7)</ref> Calculate L cN CE and L cswap Optimize the network by L overall Eq. (8) Append h 1 to list L ; end Compute the K-NN for each sample based on L. end Output: The well trained model F liable in the early training; hence, we should use the standard multi-crops strategy to warm up the model for a certain number of epochs and then switch to our K-NN multi-crops to get better performance. (See more details in our experiments.) If we use L cN CE and L cswap to denote the contrastive loss and swapped loss for the multi-crops images, then the overall training objective for our weakly supervised contrastive learning framework can be expressed as</p><formula xml:id="formula_13">L overall = LNCE + ?LcNCE + ?Lswap + ?Lcswap,<label>(8)</label></formula><p>where ?, ? and ? are the hyper-parameters. We simply take ? = 1, ? = 0.5 and ? = 0.5 in our implementation. Please see more details in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Ablation Studies</head><p>In this section, we will empirically study our Weak Supervised Contrastive Learning (WCL) framework under different batch sizes, epochs, datasets(CIFAR-10, CIFAR-100, ImageNet100) and show the effectiveness of each component by extensive experiments.</p><p>CIFAR-10 and CIFAR-100. The CIFAR-10 [26] dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. CIFAR-100 is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. We use the ResNet50 <ref type="bibr" target="#b19">[20]</ref> as our backbone network. Because the training images only contain 32x32 pixels, we replace the first 7x7 Conv of stride 2 with 3x3 Conv of stride 1 and also remove the first max pooling operation. We use 2-Layer-MLP for the two non-linear projection heads. For data augmentation, we use the random resized crops (the lower bound of random crop ratio is set to 0.2), color distortion (strength=0.5), and leaving out Gaussian blur. The model is trained using LARS optimizer <ref type="bibr" target="#b45">[46]</ref> with a momentum of 0.9 and weight decay of 1e ?6 . We linear warm up the learning rate for 10 epochs until it reaches 0.25 ? BatchSize/256, then switch to the cosine decay scheduler <ref type="bibr" target="#b30">[31]</ref>. The temperature parameter ? is always set to 0.1. To perform the Connected Components Labeling process, we simply use the "connected components" function from the Scipy Library <ref type="bibr" target="#b38">[39]</ref>. We will use the same training strategy for both CIFAR-10 and CIFAR-100. ImageNet-100. ImageNet-100 dataset is a randomly chosen subset from ILSVRC2010 ImageNet <ref type="bibr" target="#b10">[11]</ref>. (We simply take the first 100 class in our experiments.) For training the ImageNet-100, we strictly follow the training strategy reported in SimCLR <ref type="bibr" target="#b5">[6]</ref>. Specifically, we set the BatchSize = 2048, and use the LARS optimizer with lr = 0.075 ? ? BatchSize. Moreover, we found that the default augmentation that used in SimCLR might be too strong, which makes the model very hard to converge in the beginning; thus, we adopt the same but a little bit weaker version of the augmentation (the one that used in MoCoV2 <ref type="bibr" target="#b7">[8]</ref>) in the first 10 epochs and then switch it back to the original augmentations after warm-up. The model will be optimized for 200 epochs, and the rest of the settings (including temperature, weight decay, etc.) are the same as our CIFAR training.</p><p>Evaluation Protocol. For testing the representation quality, we evaluate our well-trained model on the widely adopted linear evaluation protocol -We will freeze the encoder parameters and train a linear classifier on top of it by using the standard SGD optimizer with a momentum of 0.9, learning rate of 0.1 ? BatchSize/256 and cosine decay scheduler. We don't use any regularization techniques such as weight decay and gradient clipping. The model will be trained for 80 epochs, then evaluated on the testing set.</p><p>Effect of weak supervision. We choose SimCLR as our baseline, and compare it with our method on BatchSize = 64, 128, 256 and Epoch = 100, 200, 300, 400. Note, in these experiments; we do not use any multi-crops strategy; only an additional L swap is applied on top of the SimCLR. <ref type="table" target="#tab_0">Table 1</ref> shows the results. Obviously, our proposed method substantially outperforms the baseline across all settings. For CIFAR-10, we have various improvements from 0.98% to 2.91% based on different settings. For CIFAR-100, the improvement is from 0.73% to 1.80%. Effect of two-head framework. We also perform an extensive ablation study to examine the effectiveness of our two head based framework. The experiments are mainly performed on the ImageNet-100 dataset, and the result is shown in <ref type="table" target="#tab_1">Table 2</ref>. Note, the L cN CE and L cswap in this experiment is based on the standard multi-crops strategy (without KNN). The first row is the SimCLR baseline. The second row is the case that only L swap is applied; the model can still learn a meaningful representation but result in a worse accuracy than the baseline. We also try to apply both L N CE and L swap on the same head; from the third row, we can see there is a 0.53% performance drop. We doubt this is because of the conflicts between the instance discrimination and similar sample attraction. The fourth row shows our proposed method, which separates the two tasks on different heads. In this case, we get 1.72% improvements over the baseline, which verified our hypothesis. The last three rows show the result with the multi-crops strategy, and the performance can be further improved by 2.26%.</p><p>Effect of K-NN Multi-Crops. As we have mentioned, the K-NN result is unreliable in the early training, and we need to use the standard multi-crops strategy to warm up the model for a certain number of epochs. <ref type="table" target="#tab_2">Table 3</ref> shows the result for a different number of warm up epochs. We can see clearly that with 50 epochs of warm up, our K-NN multi-crops strategy has 1% improvements over the standard multi-crops (see the last row in <ref type="table" target="#tab_1">Table 2</ref>). Finally, our proposed method achieved 80.78% Top-1 accuracy on linear evaluation, which has 5% improvements than the Sim-CLR baseline (75.79%). Visualization. <ref type="figure" target="#fig_3">Figure 4</ref> shows the t-SNE visualization <ref type="bibr" target="#b37">[38]</ref> of h from a randomly selected 10 classes. Compare to SimCLR; our weakly supervised contrastive learning framework can enhance a much better intra-class compactness and inter-class discrepancy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison on ImageNet-1K Dataset</head><p>We also performed our algorithm on the large-scale ImageNet-1k dataset <ref type="bibr" target="#b10">[11]</ref>. The training strategy is the same as our ImageNet-100 training, except we adopt a larger batch size (4096) and use the 3-Layer-MLP for the two projection heads. For the K-NN Multi-crops, we simply take the best strategy from <ref type="table" target="#tab_2">Table 3</ref>, which means we will use the standard multi-crops strategy for the first 25% epochs, and then switch to our K-NN version. Compare to FNCancel.</p><p>[23] <ref type="table" target="#tab_3">Table 4</ref> shows the comparison between our proposed method with FNCancel and SimCLR. Note, for a fair comparison, all models are trained with a 3-Layer-MLP projection head. As we can see, with a negligible additional computational cost (0.01), our proposed method can surpass the SimCLR baseline 1.7% and achieved the same result with FNCancel. FNCancel does not report the standard time usage on the paper, but since it requires 8 additional forward passes to generate the support view embeddings, their actual computational cost will be much higher than ours. We also compare the result with the multi-crops strategy. In this case, we use 2 160?160 images as our main views and 6 additional 96 ? 96 K-NN crops. Look at the last row; our proposed method can achieve 71.0 top-1 accuracy with only 31% more additional cost than SimCLR. This is twice faster than FNCancel and has 0.6% improvements on linear evaluation. Linear Evaluation.</p><p>For the linear evaluation of ImageNet-1k, we strictly follow the setting in SimCLR <ref type="bibr" target="#b5">[6]</ref>. <ref type="table">Table 5</ref> and 6 shows our result for 200 epochs and 800 epochs of training. We also report the result with 2 224 ? 224 and 6 additional 96 ? 96 K-NN crops (as in SwAV <ref type="bibr" target="#b4">[5]</ref>). We can see clearly that when the model is optimized for 200 epochs, our proposed method achieved state- of-the-art performance among all the recent self-supervised learning frameworks. When the model is trained for 800 epochs, our model can still outperform most recent works but slightly lower than SwAV. Semi-Supervised Learning. Next, we evaluate the performance obtained when fine-tuning the model representation using a small subset of labeled data. For a fair comparison, we take the same labeled list from SimCLR <ref type="bibr" target="#b5">[6]</ref>. Specifically, we report our results on two different settings. First, we follow the strategy in PCL <ref type="bibr" target="#b28">[29]</ref>, and fine-tuning from the average pooling layer of the ResNet50 <ref type="bibr" target="#b19">[20]</ref> network. In this setting, our model outperforms the previous state-of-the-art (SwAV) 4.4% on 1% labels and 0.9% on 10% labels. Then, we also follow the strategy in SimCLRv2 <ref type="bibr" target="#b6">[7]</ref> to fine-tuning from the first layer of the projection head. In this case, our method has 1.3% and 0.9% improvement on 1% and 10% labels over FNCancel. Notably, this result is even higher than the SimCLRv2 with ResNet101 backbone.</p><p>Transfer Learning. Finally, We further evaluate the quality of the learned representations by transferring them to other datasets. Following <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b4">5]</ref>, we perform linear classification on the PASCAL VOC2007 dataset <ref type="bibr" target="#b14">[15]</ref>. Specif-ically, we resize all images to 256 pixels along the shorter side and taking a 224 ? 224 center crop. Then, we train a linear SVM on top of corresponding global average pooled final representations. To study the transferability of the representations in few-shot scenarios, we vary the number of labeled examples k and report the mAP. <ref type="table" target="#tab_5">Table 7</ref> shows the comparison between our method with previous works. We report the average performance over 5 runs (except for k=full). The result of our method and SwAV are both based on the multi-crop version. When the model has 200 epochs of pretraining, our method and SwAV can already outperform the supervised pretraining on the full dataset. Interestingly, our method is significantly better than all other works, especially when k is small. When the model has more pretraining epochs, our method can even surpass the supervised pretraining with k = 64 and consistently has higher performance than SwAV across all different k values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we proposed a weakly supervised contrastive learning framework that consist of two projection heads, one of which focus on the instance discrimination task, and the other head adopts the Connected Components Labeling process to generate a weak label, then perform the supervised contrastive learning task by swapping the weak label to different augmentations. Finally, we introduced a new K-NN based multi-crops strategy which has much more effective information and expanding the number of positive samples to K times. Experiments on CIFAR-10, CIFAR-100, ImageNet-100 show the effectiveness of each component. The results of semi-supervised learning and transfer learning demonstrate the state-of-the-art performance for unsupervised representation learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>The procedure of weak label generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 :</head><label>1</label><figDesc>Connected Components Labeling Input: An adjacency matrix G = (V, E) Define makeSet(v) : Create a new set with element v Define union(A, B): Return the set A ? B Define find(v): Return the set which contains</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>t-SNE visualization for SimCLR and our method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Experiments on CIFAR-10 and CIFAR-100 with different batch size and training epochs</figDesc><table><row><cell>Batch Size</cell><cell>Method</cell><cell>100 ep</cell><cell cols="2">CIFAR10 200 ep 300 ep</cell><cell>400 ep</cell><cell>100 ep</cell><cell cols="2">CIFAR100 200 ep 300 ep</cell><cell>400 ep</cell></row><row><cell>64</cell><cell>SimCLR</cell><cell>77.20</cell><cell>80.64</cell><cell>82.77</cell><cell>84.48</cell><cell>52.35</cell><cell>55.86</cell><cell>58.18</cell><cell>59.96</cell></row><row><cell>64</cell><cell>WCL (Ours)</cell><cell>79.17 (+1.97)</cell><cell>83.54 (+2.90)</cell><cell>85.68 (+2.91)</cell><cell>86.64 (+2.16)</cell><cell>53.54 (+1.19)</cell><cell>56.57 (+0.71)</cell><cell>59.29 (+1.11)</cell><cell>60.76 (+0.80)</cell></row><row><cell>128</cell><cell>SimCLR</cell><cell>79.64</cell><cell>83.57</cell><cell>85.70</cell><cell>86.72</cell><cell>54.72</cell><cell>59.19</cell><cell>60.88</cell><cell>62.20</cell></row><row><cell>128</cell><cell>WCL (Ours)</cell><cell>81.82 (+2.18)</cell><cell>85.65 (+2.08)</cell><cell>87.81 (+2.91)</cell><cell>88.65 (+1.93)</cell><cell>55.46 (+0.74)</cell><cell>60.30 (+1.11)</cell><cell>61.73 (+0.85)</cell><cell>63.17 (+0.97)</cell></row><row><cell>256</cell><cell>SimCLR</cell><cell>81.78</cell><cell>85.34</cell><cell>87.29</cell><cell>88.48</cell><cell>57.16</cell><cell>61.18</cell><cell>63.49</cell><cell>64.20</cell></row><row><cell>256</cell><cell>WCL (Ours)</cell><cell>83.12 (+1.34)</cell><cell>87.57 (+2.23)</cell><cell>88.85 (+1.56)</cell><cell>89.47 (+0.98)</cell><cell>57.85 (+0.70)</cell><cell>62.98 (+1.80)</cell><cell>64.21 (+0.72)</cell><cell>64.93 (+0.73)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell cols="6">Effectiveness of two-head framework (ImageNet100)</cell></row><row><cell>g</cell><cell cols="6">? LNCE Lswap LcNCE Lcswap Top-1</cell></row><row><cell>?</cell><cell></cell><cell>?</cell><cell></cell><cell></cell><cell></cell><cell>75.79</cell></row><row><cell></cell><cell>?</cell><cell></cell><cell>?</cell><cell></cell><cell></cell><cell>71.33</cell></row><row><cell>?</cell><cell></cell><cell>?</cell><cell>?</cell><cell></cell><cell></cell><cell>75.26</cell></row><row><cell cols="2">? ?</cell><cell>?</cell><cell>?</cell><cell></cell><cell></cell><cell>77.51</cell></row><row><cell cols="2">? ?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell>79.06</cell></row><row><cell cols="2">? ?</cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell>79.08</cell></row><row><cell cols="2">? ?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>79.77</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell cols="5">Warm up epochs for K-NN Multi-Crops (K=4)</cell></row><row><cell>Epochs</cell><cell>0</cell><cell>25</cell><cell>50</cell><cell>75</cell><cell>100</cell></row><row><cell cols="6">Accuracy 79.73 80.25 80.78 80.63 80.23</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Compare to FNCancel on ImageNet-1K</figDesc><table><row><cell>Method</cell><cell cols="3">Epochs GPU(time) Acc</cell></row><row><cell>SimCLR</cell><cell>100</cell><cell>1.00</cell><cell>66.4</cell></row><row><cell>FNCancel</cell><cell>100</cell><cell>-</cell><cell>68.1</cell></row><row><cell>WCL (Ours)</cell><cell>100</cell><cell>1.01</cell><cell>68.1</cell></row><row><cell>SimCLR</cell><cell>1000</cell><cell>10.00</cell><cell>70.3</cell></row><row><cell>FNCancel + multi-crops</cell><cell>100</cell><cell>2.85</cell><cell>70.4</cell></row><row><cell>WCL (Ours) + multi-crops</cell><cell>100</cell><cell>1.31</cell><cell>71.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .Table 6 .</head><label>56</label><figDesc>Top-1 accuracy under the linear evaluation on ImageNet with the ResNet-50 backbone. The table compares the methods over 200 epochs of pretraining. * denotes multi-crops strategy. Top-1 accuracy under the linear evaluation on ImageNet. The table compares the methods with more epochs of pretraining. * denotes multi-crops strategy.</figDesc><table><row><cell>Method</cell><cell cols="4">Arch Param Epochs Top-1</cell></row><row><cell>Supervised</cell><cell>R50</cell><cell>24</cell><cell>-</cell><cell>76.5</cell></row><row><cell>InstDisc [41]</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>58.5</cell></row><row><cell cols="2">LocalAgg [51] R50</cell><cell>24</cell><cell>200</cell><cell>58.8</cell></row><row><cell>SimCLR [6]</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>66.8</cell></row><row><cell>MoCo [19]</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>60.8</cell></row><row><cell>MoCo v2 [8]</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>67.5</cell></row><row><cell>MoCHi [24]</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>68.0</cell></row><row><cell>CPC v2 [27]</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>63.8</cell></row><row><cell>PCL v2 [29]</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>67.6</cell></row><row><cell>SimSiam [9]</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>70.0</cell></row><row><cell>SwAV [5]</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>69.1</cell></row><row><cell>SwAV* [5]</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>72.7</cell></row><row><cell>WCL (Ours)</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>70.3</cell></row><row><cell>WCL* (Ours)</cell><cell>R50</cell><cell>24</cell><cell>200</cell><cell>73.3</cell></row><row><cell>Method</cell><cell cols="4">Arch Param Epochs Top-1</cell></row><row><cell>Supervised</cell><cell>R50</cell><cell>24</cell><cell>-</cell><cell>76.5</cell></row><row><cell>SeLa [43]</cell><cell>R50</cell><cell>24</cell><cell>400</cell><cell>61.5</cell></row><row><cell>SimCLR [6]</cell><cell>R50</cell><cell>24</cell><cell>800</cell><cell>69.1</cell></row><row><cell>SimCLR v2 [7]</cell><cell>R50</cell><cell>24</cell><cell>800</cell><cell>71.7</cell></row><row><cell>MoCo v2 [8]</cell><cell>R50</cell><cell>24</cell><cell>800</cell><cell>71.1</cell></row><row><cell>SimSiam [9]</cell><cell>R50</cell><cell>24</cell><cell>800</cell><cell>71.3</cell></row><row><cell>SwAV [5]</cell><cell>R50</cell><cell>24</cell><cell>800</cell><cell>71.8</cell></row><row><cell>BYOL [18]</cell><cell>R50</cell><cell>24</cell><cell>1000</cell><cell>74.3</cell></row><row><cell cols="2">FNCancel* [23] R50</cell><cell>24</cell><cell>1000</cell><cell>74.4</cell></row><row><cell>AdpCLR [49]</cell><cell>R50</cell><cell>24</cell><cell>1100</cell><cell>72.3</cell></row><row><cell>WCL (Ours)</cell><cell>R50</cell><cell>24</cell><cell>800</cell><cell>72.2</cell></row><row><cell>WCL* (Ours)</cell><cell>R50</cell><cell>24</cell><cell>800</cell><cell>74.7</cell></row><row><cell>Others</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SwAV* [5]</cell><cell>R50</cell><cell>24</cell><cell>800</cell><cell>75.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7 .</head><label>7</label><figDesc>Low-shot image classification on VOC07 10.42 10.82 11.34 11.96 12.42 Supervised 90 54.46 68.15 73.79 79.51 82.26 84.00 85.13 87.27 MoCo v2 [8] 200 46.30 58.40 64.85 72.47 76.14 79.16 81.52 84.60 PCL v2 [29] 200 47.88 59.59 66.21 74.45 78.34 80.72 82.67 85.43 SwAV [5] 200 43.07 55.65 64.82 73.17 78.38 81.86 84.40 87.47 WCL (Ours) 200 48.06 60.12 68.52 76.16 80.24 82.97 85.01 87.75</figDesc><table><row><cell>Method</cell><cell>Epochs</cell><cell>k=1</cell><cell>k=2</cell><cell>k=4</cell><cell>k=8</cell><cell>k=16</cell><cell>k=32</cell><cell>k=64</cell><cell>Full</cell></row><row><cell cols="10">Random 10.10 SwAV [5] -8.92 9.33 400 42.14 55.34 64.31 73.08 78.47 82.09 84.62 87.78</cell></row><row><cell>SwAV [5]</cell><cell>800</cell><cell cols="8">42.85 54.90 64.03 72.94 78.65 82.32 84.90 88.13</cell></row><row><cell>WCL (Ours)</cell><cell>800</cell><cell cols="8">48.25 60.68 68.52 76.48 81.05 83.89 85.88 88.64</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 .</head><label>8</label><figDesc>ImageNet semi-supervised evaluation.</figDesc><table><row><cell></cell><cell>1%</cell><cell></cell><cell>10%</cell><cell></cell></row><row><cell>Method</cell><cell cols="4">Top-1 Top-5 Top-1 Top-5</cell></row><row><cell>Supervised</cell><cell>25.4</cell><cell>56.4</cell><cell>48.4</cell><cell>80.4</cell></row><row><cell>Semi-supervised</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>S4L [47]</cell><cell>-</cell><cell>53.4</cell><cell>-</cell><cell>83.8</cell></row><row><cell>UDA [42]</cell><cell>-</cell><cell>68.8</cell><cell>-</cell><cell>88.5</cell></row><row><cell>FixMatch [34]</cell><cell>-</cell><cell>-</cell><cell>71.46</cell><cell>89.1</cell></row><row><cell>Self-Supervised</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>From AvgPool</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>InstDisc [41]</cell><cell>-</cell><cell>39.2</cell><cell>-</cell><cell>77.4</cell></row><row><cell>PCL [29]</cell><cell>-</cell><cell>75.6</cell><cell>-</cell><cell>86.2</cell></row><row><cell>PIRL [32]</cell><cell>30.7</cell><cell>60.4</cell><cell>57.2</cell><cell>83.8</cell></row><row><cell>SimCLR v1 [6]</cell><cell>48.3</cell><cell>75.5</cell><cell>65.6</cell><cell>87.8</cell></row><row><cell>BYOL [18]</cell><cell>53.2</cell><cell>78.4</cell><cell>68.8</cell><cell>89.0</cell></row><row><cell>SwAV [5]</cell><cell>53.9</cell><cell>78.5</cell><cell>70.2</cell><cell>89.9</cell></row><row><cell>WCL (Ours)</cell><cell>58.3</cell><cell>79.9</cell><cell>71.1</cell><cell>90.3</cell></row><row><cell>From Projection Head</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SimCLR v2 (R50) [7]</cell><cell>57.9</cell><cell>-</cell><cell>68.4</cell><cell>-</cell></row><row><cell>SimCLR v2 (R101)[7]</cell><cell>62.1</cell><cell>-</cell><cell>71.4</cell><cell>-</cell></row><row><cell>FNCancel [23]</cell><cell>63.7</cell><cell>85.3</cell><cell>71.1</cell><cell>90.2</cell></row><row><cell>WCL (Ours)</cell><cell>65.0</cell><cell>86.3</cell><cell>72.0</cell><cell>91.2</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A theoretical analysis of contrastive unsupervised representation learning. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrishikesh</forename><surname>Khandeparkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orestis</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Autoencoders, unsupervised learning and deep architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 International Conference on Unsupervised and Transfer Learning Workshop</title>
		<meeting>the 2011 International Conference on Unsupervised and Transfer Learning Workshop</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="37" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<idno>abs/1809.11096</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<title level="m">A simple framework for contrastive learning of visual representations</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Big self-supervised models are strong semi-supervised learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10029</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<title level="m">Improved baselines with momentum contrastive learning</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Exploring simple siamese representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Debiased contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Yao</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Yen-Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR09</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Large scale adversarial representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image inpainting: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Elharrouss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Noor Almaadeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Al-M?adeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Akbari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Processing Letters</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">51</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The PASCAL Visual Object Classes Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html.1,8" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno>abs/1803.07728</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Bootstrap your own latent: A new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><forename type="middle">Daniel</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Valko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.05722</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>R Devon Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.06670</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Percolation and cluster distribution. i. cluster multiple labeling technique and critical concentration algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoshen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kopelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. B</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="3438" to="3445" />
			<date type="published" when="1976-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Boosting contrastive self-supervised learning with false negative cancellation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maryam</forename><surname>Khademi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.11765</idno>
		<imprint>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hard negative mixing for contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bulent</forename><surname>Mert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noe</forename><surname>Sariyildiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Pion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Larlus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prannay</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Supervised contrastive learning. ArXiv, abs/2004.11362, 2020. 2, 4</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Contrastive predictive coding based feature for automatic speaker verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-I</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.01575</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Prototypical contrastive learning of unsupervised representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>cite arxiv:1405.0312Comment: 1) updated annotation pipeline description and figures</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Self-supervised learning of pretext-invariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semisupervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bcnet: Searching for network width with bilaterally coupled network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2175" to="2184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">K-shot NAS: learnable weight-sharing for NAS with k-shot supernets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<idno>PMLR, 2021. 1</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="9880" to="9890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05849</idno>
		<title level="m">Contrastive multiview coding</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">0: Fundamental Algorithms for Scientific Computing in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pauli</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Gommers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Travis</forename><forename type="middle">E</forename><surname>Oliphant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Haberland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeni</forename><surname>Burovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pearu</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Warren</forename><surname>Weckesser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Bright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>St?fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Van Der Walt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Brett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Jarrod</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolay</forename><surname>Millman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mayorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C J</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilhan</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Polat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">A</forename><surname>Moore ; E</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">R</forename><surname>Quintero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><forename type="middle">M</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ant?nio</forename><forename type="middle">H</forename><surname>Archibald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="261" to="272" />
			<date type="published" when="2020" />
			<publisher>Paul van Mulbregt</publisher>
		</imprint>
	</monogr>
	<note>Ian Henriksen. and SciPy 1.0 Contributors. SciPy 1.</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.10242</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6256" to="6268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Self-labelling via simultaneous clustering and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rupprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Conference on Learning Representations</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Greedynas: Towards fast one-shot nas with greedy supernet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingmin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning from multiple teacher networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1285" to="1294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Large batch training of convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Gitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">S4l: Self-supervised semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Xiaohua Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1476" to="1485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Selfsupervised representation learning via adaptive hard-positive mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaofeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Ressl: Relational self-supervised learning with weak augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.09282</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Local aggregation for unsupervised learning of visual embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxu</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">Lin</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Yamins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
