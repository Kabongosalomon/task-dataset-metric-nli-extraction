<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph Rationalization with Environment-based Augmentations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-08-14">2022. August 14-18, 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
							<email>tzhao2@nd.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Luo</surname></persName>
							<email>tluo@nd.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
							<email>mjiang2@nd.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Luo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Notre Dame Notre Dame</orgName>
								<address>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dame Notre Dame</orgName>
								<orgName type="institution">University of Notre</orgName>
								<address>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Dame Notre Dame</orgName>
								<orgName type="institution">University of Notre</orgName>
								<address>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Dame Notre Dame</orgName>
								<orgName type="institution">University of Notre</orgName>
								<address>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Dame Notre Dame</orgName>
								<orgName type="institution">University of Notre</orgName>
								<address>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Graph Rationalization with Environment-based Augmentations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining KDD &apos;22</title>
						<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining KDD &apos;22 <address><addrLine>Washington, DC, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published" when="2022-08-14">2022. August 14-18, 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3534678.3539347</idno>
					<note>ACM Reference Format: (KDD &apos;22), August 14-18, 2022, Washington, DC, USA. ACM, New York, NY, USA, 10 pages. https://</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Applied computing ? Chemistry;</term>
					<term>Computing methodolo- gies ? Learning latent representations KEYWORDS Graph Learning, Graph Neural Network, Molecule Property, Data Augmentation, Rationalization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Rationale is defined as a subset of input features that best explains or supports the prediction by machine learning models. Rationale identification has improved the generalizability and interpretability of neural networks on vision and language data. In graph applications such as molecule and polymer property prediction, identifying representative subgraph structures named as graph rationales plays an essential role in the performance of graph neural networks. Existing graph pooling and/or distribution intervention methods suffer from the lack of examples to learn to identify optimal graph rationales. In this work, we introduce a new augmentation operation called environment replacement that automatically creates virtual data examples to improve rationale identification. We propose an efficient framework that performs rationale-environment separation and representation learning on the real and augmented examples in latent spaces to avoid the high complexity of explicit graph decoding and encoding. Comparing against recent techniques, experiments on seven molecular and four polymer datasets demonstrate the effectiveness and efficiency of the proposed augmentation-based graph rationalization framework. Data and the implementation of the proposed framework are publicly available 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graph property prediction has attracted attention in different research fields like chemoinformatics and bioinformatics where small molecules are represented as labelled graphs of atoms <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b47">48]</ref>. Besides, materials informatics for polymers has emerged in recent years from property prediction to inverse design <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11]</ref>. Polymer are materials consisting of macromolecules, composed of many repeating units. They are ubiquitous in applications ranging from plastic cups and electronics to aerospace structures. New engineering and environmental challenges demand that polymers possess unconventional properties such as high-temperature stability, excellent thermal conductivity, and biodegradability <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b32">33]</ref>. It's important to integrate data science and machine learning into polymer informatics on the tasks of graph classification and regression.</p><p>To automate feature extraction from graph data, graph neural network (GNN) models learn node representations through nonlinear functions and layers that aggregate information from node neighborhood <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b41">42]</ref>. Graph pooling is a central component of the GNN architecture that learns a cluster assignment for nodes and passes cluster nodes and their representations to the next layer <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b39">40]</ref>. The final layer returns the representations of entire graphs. Despite the advances of various GNN models, the limitation of data size makes them easily fall into over-fitting and poor generalizability. For example, the number of graphs in molecule benchmark datasets is usually in the range of 1,000 and 10,000; and the size of polymer datasets is even smaller (e.g., ?600) <ref type="bibr" target="#b16">[17]</ref>.</p><p>Rationalization techniques have been designed to solve the above problem in vision and language data, where the rationale is defined as a subset of input features that best explains or supports the prediction by machine learning models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b22">23]</ref>. However, graph rationalization has not been extensively studied, which aims at identifying representative subgraph structures for accurate and interpretable graph property prediction. Related work mainly focused on advancing graph pooling methods, but cluster assignment could not reflect the most essential part that led to accurate prediction <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">19]</ref>. A very recent technique named DIR <ref type="bibr" target="#b33">[34]</ref> employed two GNN modules to discover invariant graph rationales: one module separates each input graph into a rationale subgraph and an environment subgraph; the other is a graph property predictor based on the rationale subgraph. As shown at the top in <ref type="figure">Figure 1</ref>  <ref type="figure">Figure 1</ref>: Graph rationalization identifies a rationale subgraph that best explains or supports the prediction of graph property. Our work makes the first attempt to improve graph rationalization by graph data augmentations with environment subgraphs which are the remaining parts after rationale identification. It proposes new augmentation operations, designs and develops a novel graph rationalization framework, and conducts experiments on a large set of molecule and polymer data.</p><p>graph , the separator identifies rationale <ref type="bibr">( )</ref> , and the predictor gives label?( ) based on the rationale. DIR conducted interventions on training distribution to improve the invariance. Unfortunately, when the data size was small, could hardly find good rationales, as reported in our later experiments.</p><p>In this work, we make the first attempt to enhance graph rationalization by graph data augmentations. Existing augmentation methods were mainly heuristic modification of graph structure, which could not directly support the identification of graph rationales <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b45">46]</ref>. We present two augmentation methods based on environment subgraphs that are the remaining parts in the graph after rationale identification. First, rationales are used to train the property predictor, which can be considered as graph examples augmented by environment removal. Second, we replace the environment of input graph with the environment of another graph in the batch: to generate an augmented example: this augmentation method is called environment replacement. The idea is that the rationale can be accurately identified and/or separated from the input graph when the augmented examples are expected to have the same label of the input graph example. <ref type="figure">Figure 1</ref> presents the idea of generating virtual data for small datasets via data augmentations. Suppose we have rationale ( ) separated from input graph . We use the same GNN-based separator to find environment subgraph ( ) from another graph in the batch. The example augmented by environment replacement is denoted by ( , ) = ( ) ? ( ) . The model is trained on this example to predict label?, to be the same as that is the observed label of . We compute two losses on the augmented examples, L and L ("rem" for removal and "rep" for replacement), and jointly optimize and by their combination. The key challenge in the idea implementation is the high computational complexity of decoding for explicit graph forms of rationales, environment subgraphs, and augmented examples, as well as encoding them for representation learning and property prediction. Moreover, it is scientifically and technically difficult to explicitly combine rationale ( ) and environment ( ) from different graphs, as shown in the three augmented examples ( , ) in <ref type="figure">Figure 1</ref>. To address these challenges, we hypothesize that the contextualized representations of nodes play a significant role in rationales, environment subgraphs, and augmented graphs. Thus, we create the representations of all these objects from one latent space.</p><p>In this paper, we propose a novel, efficient framework of Graph Rationalization enhanced by Environment-based Augmentations (GREA). It performs rationale-environment separation and representation learning on the real and augmented examples in one latent space to avoid the high complexity of explicit subgraph decoding and encoding. <ref type="figure" target="#fig_1">Figure 2</ref> presents the architecture of GREA with a few steps. First, it employs GNN 1 and MLP 1 models to infer the probability of nodes being classified into rationale subgraph m. Second, it employs GNN 2 to create contextualized node representations H. Then, it directly creates the representation vectors of rationales, environment subgraphs and environment-replaced examples, denoted by h ( ) , h ( ) , and h ( , ) , respectively. Note that DIR <ref type="bibr" target="#b33">[34]</ref> used a GNN to generate a matrix of masks that indicate the importance of edges and then select the top-edges with the highest masks to construct the rationale. Then it had to run GNNs on all the explicit graph objects. Instead, our GREA uses m and H to compute the representation vectors of the artificial graphs.</p><p>We conduct experiments on seven molecule and four polymer datasets. Results demonstrate the advantages of GREA over baselines. For example, it significantly reduces the prediction error on oxygen permeability of polymer membrane with only 595 training examples. The oxygen permeability defines how easily oxygen passes through a particular material. Accurate prediction will speed up material discovery for healthcare and energy utilization.</p><p>The main contributions of this work are summarized below:</p><p>? the first attempt to improve graph rationale identification using data augmentations, including environment replacement, for accurate and interpretable property prediction; ? a novel and efficient framework that performs rationaleenvironment separation and representation learning on real and augmented examples in one latent space; ? extensive experiments on more than ten molecule and polymer datasets to demonstrate the effectiveness and efficiency of the proposed framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>There are four research topics related to the proposed work. We briefly present their recent studies and compare with ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph Property Prediction</head><p>Learning representations and predicting properties of entire graphs is important for chemistry, biology, and material sciences, where molecule and polymer data can be structured as graphs <ref type="bibr" target="#b8">[9]</ref>. When RDKit is widely used to generate molecular fingerprints <ref type="bibr" target="#b12">[13]</ref>, graph neural networks (GNNs) such as Graph Convolutional Network (GCN) <ref type="bibr" target="#b11">[12]</ref>, Graph Attention Networks (GAT) <ref type="bibr" target="#b25">[26]</ref>, and Graph-SAGE <ref type="bibr" target="#b7">[8]</ref> have automated representation learning with nonlinear functions from graph data <ref type="bibr">[10, 18, 27-30, 35, 42, 43]</ref>.</p><p>In the GNN models, graph pooling is a central component of their architectures as a cluster assignment function to find local patches in graphs <ref type="bibr" target="#b18">[19]</ref>. For example, DiffPool presented a differentiable graph pooling module that learned a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapped nodes to a set of clusters, and then formed the coarsened input for the next GNN layer <ref type="bibr" target="#b39">[40]</ref>. Lee et al. proposed self-attention graph convolution that allows graph pooling to consider both node features and graph topology <ref type="bibr" target="#b13">[14]</ref>. Gao and Ji proposed graph pooling and unpooling operations in Graph U-Nets <ref type="bibr" target="#b5">[6]</ref>. Xu et al. presented a theoretical framework for analyzing the representational power of GNNs through the graph pooling functions <ref type="bibr" target="#b36">[37]</ref>. While graph pooling identifies soft clusters that effectively aggregate information from nodes <ref type="bibr" target="#b38">[39]</ref>, our work identifies representative subgraph structures for accurate and interpretable predictions of GNN models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Rationalization</head><p>Most rationalization techniques identify the small subset of input features by maximizing the predictive performance based only on the subset itself, called rationale. To rule out spurious correlation between the input features and the output, Chang et al. proposed the concept of invariant rationalization by modeling different environments as non-causal input to train predictors <ref type="bibr" target="#b1">[2]</ref>. Rosefeld et al. offered formal guarantees for improvement of the invariant causal prediction on out-of-distribution generalization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>By introducing causal modeling into GNN optimization, Fan et al. presented a causal representation framework for GNN models to perform on out-of-distribution graphs <ref type="bibr" target="#b4">[5]</ref>. Li et al. proposed OOD-GNN that employed a novel nonlinear graph representation decorrelation method that used random Fourier features to encourage GNNs to eliminate the statistical dependence between relevant and irrelevant graph representations <ref type="bibr" target="#b14">[15]</ref>. Very recently, Wu et al. proposed the first work called DIR to approach causal rationales for GNNs to improve the interpretability and predictive performance on out-of-distribution data <ref type="bibr" target="#b33">[34]</ref>. DIR conducted interventions on the training distribution to create multiple distributions. Unfortunately, distribution intervention might not be the optimal solution to graph rationale identification. Also, the edge selection method suffers from high computational complexity for rationale creation. Moreover, the studies were mainly performed on synthetic data. In this paper, we make the first attempt to define "environment" in graph data, augment data examples by environment replacement, develop an efficient framework, and conduct experiments on a large set of real molecule and polymer data. We find that augmentationenhanced graph rationalization is more effective than DIR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Graph Data Augmentation</head><p>Graph data augmentation (GDA) techniques <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47]</ref> have improved the performance on semi-supervised node classification, such as DropEdge <ref type="bibr" target="#b21">[22]</ref>, NodeAug <ref type="bibr" target="#b31">[32]</ref>, and GAug <ref type="bibr" target="#b45">[46]</ref>. Besides, many GDA techniques have been designed for graph-level tasks, aiming at creating new training examples by modifying input graph data examples. For example, GraphCrop regularized GNN models for better generalization by cropping subgraphs or motifs to simulate real-world noise of sub-structure omission <ref type="bibr" target="#b30">[31]</ref>. M-Evolve presented two heuristic algorithms including random mapping and motif-similarity mapping to generate weakly labeled data for small datasets <ref type="bibr" target="#b47">[48]</ref>. MH-Aug adopted the Metropolis-Hastings algorithm to create augmented graphs from an explicit target distribution for semi-supervised learning <ref type="bibr" target="#b20">[21]</ref>. Meanwhile, graph contrastive learning learned unsupervised representations of graphs using graph data augmentations to incorporate various priors <ref type="bibr" target="#b40">[41]</ref>. Zhu et al. <ref type="bibr" target="#b48">[49]</ref> proposed adaptive augmentation that incorporated various priors for topological and semantic aspects of graphs. Specifically, it designed augmentation schemes based on node centrality measures to highlight important connective structures and corrupted node features by adding noise to unimportant node features. A comprehensive survey of GDA is given by Zhao et al. <ref type="bibr" target="#b43">[44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Graph Learning on Polymer Data</head><p>Material informatics uses machine learning approaches to fast screen material candidates or generate new materials meeting certain criteria, so as to reduce the time of material development. When most related research performed on molecule data <ref type="bibr" target="#b6">[7]</ref>, polymer researchers have developed a benchmark database and developed machine learning techniques for polymer data, called polymer embeddings <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11]</ref>. They can be used to perform several polymer informatics regression tasks for density, glass transition temperature, melting temperature, and dielectric constants <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b32">33]</ref>.</p><formula xml:id="formula_0">? * * GNN 1 (?) MLP 1 (?) ? GNN 2 (?) Graph ! " ($) : Environment " ($) # ! (&amp;) # (!,") AGG(?, ?) MLP 2 (?) MLP 2 (?) ! (&amp;) : Rationale ! (&amp;) (environment-removed example) ! ($) : Environment ! ($) (!,") : Environment-replaced example (!,") = ! (&amp;) ? " ($)</formula><p>Graph " ? : Node representations : Node probability of being classified into Rationale </p><formula xml:id="formula_1">" ? ? " ? ( # ? )?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM DEFINITION</head><p>Graph Property Prediction. Let = (V, E) be a graph of nodes and edges, where V is the set of nodes (e.g., atoms) and E ? V ? V is the set of edges (e.g., bonds between atoms). We use ? Y to denote the graph-level property of , where Y is the value space. It can have a categorical or numerical value, corresponding to the task of classification or regression, respectively.</p><p>A graph property predictor takes a graph as input and predicts its label?. Specifically, a GNN-based predictor employs a GNN encoder to generate node representations H from :</p><formula xml:id="formula_2">H = ? ? ? , ? ? , ? ? ? ? ?V = GNN( ) ? R ? ,<label>(1)</label></formula><p>where ? ? ? R is the representation vector of node in graph . GNN encoder GNN(?) can be chosen as GCN <ref type="bibr" target="#b11">[12]</ref> or GIN <ref type="bibr" target="#b36">[37]</ref>.</p><p>Once the node representations are ready, a multilayer perceptron (MLP) can project them into a one-dimensional space to obtain a scalar for each node as = MLP( ? ? ). As we are more interested in graph-level classification or regression, we first use a readout operator (e.g., average pooling) to get the graph representation h and then apply a MLP to project it to a graph label:</p><formula xml:id="formula_3">h = READOUT(H) ? R ,?= MLP(h) ? Y.<label>(2)</label></formula><p>Graph Rationalization. Following the existing literature on graph rationalization <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b39">40]</ref> and GNN explanation <ref type="bibr" target="#b38">[39]</ref>, we use rationale ( ) = (V ( ) , E ( ) ) to indicate the causal subgraph of the property , where ( ) is a subgraph of such that V ( ) ? V and E ( ) ? E. We use ( ) to denote the environment subgraph, which is the complementary subgraph of ( ) in . In contrast with the rationale subgraph ( ) , the environment subgraph ( ) corresponds to the non-causal part of the graph data, which has no causal relationship with the target graph property <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>Let be a GNN-based graph rationalization model that splits an input graph into a rationale subgraph ( ) and an environment subgraph ( ) . Existing graph rationalization methods used only the rationale subgraph as input for property prediction <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b39">40]</ref>:</p><formula xml:id="formula_4">=?( ) = ( ) ,<label>(3)</label></formula><p>where (?) = MLP(READOUT(GNN(?))) and?( ) denotes the predicted property of the rationale subgraph ( ) . Unfortunately, when suffering from lack of training examples, these methods chose to discard environment subgraphs at the training stage. In the next section, we present a novel framework showing our idea that environment subgraphs can provide natural noise through data augmentation to improve graph rationalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PROPOSED FRAMEWORK</head><p>In this section, we introduce a novel graph rationalization framework GREA. The key idea is to augment the rationale subgraph by removing its own environment subgraph and/or combining it with different environment subgraphs. <ref type="figure" target="#fig_1">Figure 2</ref> shows the overall architecture of GREA: GNN 1 and MLP 1 first separate input graph into rationale subgraph ( ) and environment subgraph ( ) ; GNN 2 next generates node representations H using Eq. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Rationale-Environment Separation</head><p>To separate input graph into rationale subgraph ( ) and environment subgraph ( ) , the rationale-environment separator consists of two components: a GNN encoder (GNN 1 ) that generates latent node representations and a MLP decoder (MLP 1 ) that maps the node representations to a mask vector m ? (0, 1) on the nodes in the set V. = ( ? V ( ) ) is the node-level mask that indicates the probability of node ? V being classified into the rationale subgraph. The mask can be on either a node or an edge <ref type="bibr" target="#b33">[34]</ref>. we choose to learn masks on the nodes to avoid the computational complexity of edge selection. Hence, m can be calculated as m = (MLP 1 <ref type="figure">(GNN 1 ( )</ref></p><formula xml:id="formula_5">)),<label>(4)</label></formula><p>where denotes the sigmoid function. Based on m, we have (1 ? m) that indicates the probability of nodes being classified into the environment subgraph. GNN 1 and MLP 1 make up the GNN-based graph rationalization model mentioned in Section 3. GREA uses another GNN encoder to generate contextualized node representations H: H = GNN 2 ( ). With m and H, the rationale subgraph and environment subgraph can be easily separated in the latent space. Using sum pooling, we have</p><formula xml:id="formula_6">h ( ) = 1 ? ? (m ? H), h ( ) = 1 ? ? ((1 ? m) ? H),<label>(5)</label></formula><p>where 1 denotes the -size column vector with all entries as 1, and h ( ) , h ( ) ? R are the representation vectors of graph ( ) and ( ) , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Environment-based Augmentations</head><p>Suppose 1 , 2 , . . . , are the input graphs in one batch for training, where is known as batch size. The rationale-environment separator has generated the graph representations of rationale and environment subgraphs for each graph . That is, we have</p><formula xml:id="formula_7">{(h ( ) 1 , h ( ) 1 ), (h ( ) 2 , h ( ) 2 ), . . . , (h ( )</formula><p>, h ( ) )}. We design environmentbased augmentations in the latent space of graph representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Environment Removal Augmentation.</head><p>As graph rationalization aims to find the rationale subgraph which is regarded as the causal factor of graph property, the rationale itself should be good for property prediction. As in the graph pooling methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14]</ref> and the graph rationalization as defined in Eq. (3), the environment removal augmentation uses the rationale subgraph only for training the graph property predictor. That is, given the rationale subgraph representation h ( ) of graph , the predicted label i?</p><formula xml:id="formula_8">( ) = MLP 2 h ( ) .<label>(6)</label></formula><p>4.2.2 Environment Replacement Augmentation. As aforementioned in Section 3, the environment subgraphs can be viewed as natural noises on the rationale subgraphs. Hence, in order to enhance the model's robustness against the noise signal brought by the environment subgraphs, for each graph , we combine its rationale subgraph ( ) not only with its own environment subgraph ( ) , but also with all other environment subgraphs <ref type="bibr">( )</ref> , ? {1, 2, . . . , } \ { } in the batch. By replacing the environment subgraph with other environment subgraphs in the batch, the environment replacement augmentation generates ? 1 augmented data samples for each graph during training. As the environment replacement happens on the latent space, an aggregation function AGG(?, ?) is used to combine the rationale subgraph representation h ( ) and environment subgraph representation h ( ) . The aggregation function can be any combining/pooling functions such as concatenation, sum pooling, and max pooling. Taking the elementwise sum pooling as an example, the graph representation h ( , )</p><p>of a combined graph of rationale subgraph ( ) and environment subgraph ( ) can be calculated as below: For the graph representations h ( , ) generated by the environment replacement augmentation, the MLP property predictor is trained to predict . That is,</p><formula xml:id="formula_9">h ( , ) = AGG h ( ) , h ( ) = h ( ) + h ( ) .<label>(7)</label></formula><formula xml:id="formula_10">( , ) = MLP 2 h ( , ) .<label>(8)</label></formula><p>The graph representations generated by both environment removal augmentation and environment replacement augmentation (i.e., h ( ) and h ( , ) ) are fed into the same property predictor MLP 2 .</p><p>The GNN-based property predictor defined in Section 3 includes MLP 2 and GNN 2 that generates the contextualized node representation H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Optimization. During training, the type of loss function on the observed graph property ( ) and predicted labels (?(</head><p>) and</p><p>( , ) ) depends on the type of the property label. For example, when the graph property has binary values in the binary classification task, we use the standard binary cross-entropy loss. When the graph property has real values in the graph regression task, we use the mean squared error (MSE) loss. Without loss of generality, suppose we focus on the binary classification task. Given a batch of graphs 1 , 2 , . . . , , the loss functions for each graph example and its label are defined as</p><formula xml:id="formula_11">L = ? log?( ) + (1 ? ) ? log 1 ??( ) ,<label>(9)</label></formula><formula xml:id="formula_12">L = 1 ?? =1 ? log?( , ) + (1 ? ) ? log(1 ??( , ) ) ,<label>(10)</label></formula><p>where L is the loss for the examples created by environment removal augmentation, and L is the loss for the examples created by the environment replacement augmentation.</p><p>Moreover, the following regularization term is used to control the size of the selected rationale subgraph:</p><formula xml:id="formula_13">L = 1 ? ? m ? ,<label>(11)</label></formula><p>where ? [0, 1] is a hyperparamter to control the expected size of the rationale subgraph ( ) . We penalize the number of nodes in the rationale when it deviates from our expectations.   <ref type="bibr" target="#b4">[5]</ref> 0.7218?0.0078 0.6485?0.0025 0.7381?0.0123 0.6695?0.0120 0.7229?0.0122 0.8559?0.0224 0.5593?0.0172 OOD-GNN <ref type="bibr" target="#b14">[15]</ref> 0.7799?0.0078 0.6697?0.0051 0.7646?0.0038 0.6710?0.0188 0.7800?0.0228 0.8416?0.0496 0.5916?0.0169 IRM <ref type="bibr" target="#b0">[1]</ref> 0.7817?0.0120 0.6641?0.0065 0.7542?0.0084 0.6835?0.0071 0.7977?0.0208 0.8485?0.0215 0.5778?0.0206 DIR <ref type="bibr" target="#b33">[34]</ref> 0.7533?0.0117 0.5927?0.0097 0.5078?0.0313 0.5843?0.0443 0.6115?0.0587 0.6911?0.0810 0.5406?0.0127 DIR+RepAug 0.7725?0.0249 0.6454?0.0061 0.7453?0.0080 0.6813?0.0203 0.7590?0.0642 0.8561?0.0159 0.5730?0.0115 GREA?RepAug 0.7770?0.0178 0.6681?0.0066 0.7690?0.0117 0.6737?0.0235 0.7997?0.0380 0.8574?0.0442 0.5988?0.0169 GREA (ours) 0.7932?0.0092 0.6750?0.0067 0.7723?0.0119 0.6970?0.0128 0.8237?0.0237 0.8789?0.0368 0.6014?0.0204</p><p>We use the alternate training schema in Chang et al. <ref type="bibr" target="#b1">[2]</ref> to train GREA. That is, we iteratively train (GNN 1 and MLP 1 ) and (GNN 2 and MLP 2 ) for a fixed number of epochs and , respectively. The loss functions for training GREA are</p><formula xml:id="formula_14">L = L + ? L ,<label>(12)</label></formula><formula xml:id="formula_15">L = L + ? L + ? L ,<label>(13)</label></formula><p>where L in Eq. (12) and L in Eq. (13) are used to train (GNN 1 and MLP 1 ) and (GNN 2 and MLP 2 ), respectively. and are hyperparameters that control the weights of L and L , respectively. During inference,?( ) is used as the final predicted property of input graph .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We conduct experiments to answer the following questions:</p><p>? Q1) Effectiveness: Does the proposed GREA make more accurate prediction on molecule and polymer properties than existing graph classification/regression methods? ? Q2) Ablation study: Do the environment-based augmentations make positive effect on the performance? ? Q3) Case study: Based on domain expertise, are the polymer rationale examples identified by GREA representative? ? Q4) Efficiency: Does the latent space-based design for augmentations perform faster than explicit graph decoding and encoding? Can we empirically analyze the complexity?</p><p>? Q5) Sensitivity analysis: Is the performance of GREA sensitive to hyperparameters such as , , and AGG(?)?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Datasets.</head><p>We conduct experiments on four polymer datasets and seven molecule datasets. The statistics of the datasets are given in <ref type="table" target="#tab_0">Table 1</ref>, such as number of graphs and average size of graphs. The four datasets GlassTemp, MeltingTemp, PolyDensity, and O 2 Perm are used to predict different properties of polymers such as glass transition temperature ( ? C), polymer density g/cm 3 , melting temperature ( ? C), and oxygen permeability (Barrer). For all the polymer datasets, we randomly split by 60%/10%/30% for training, validation, and test. Besides polymer datasets, we use seven molecule datasets from the graph property prediction task on Open Graph Benchmark or known as OGBG. For all molecule datasets, we use the scaffold splitting procedure as OGBG adopted <ref type="bibr" target="#b8">[9]</ref>. It attempts to separate structurally different molecules into different subsets, which provides a more realistic estimate of model performance in experiments <ref type="bibr" target="#b35">[36]</ref>. Dataset descriptions with details are presented in the Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Evaluation Metrics.</head><p>On the polymer datasets, we perform the tasks of graph regression. We use the coefficient of determination (R 2 ) and Root Mean Square Error (RMSE) as evaluation metrics according to previous works <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b16">17]</ref>. On the molecule datasets, we perform the tasks of graph binary classification using the Area under the ROC curve (AUC) as the metric. To evaluate model efficiency, we use the computational time per training batch (in seconds).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Baseline Methods.</head><p>There are three categories of related methods that we can compare GREA with. The first category is graph pooling methods that aim at finding (soft) cluster assignment of nodes towards aggregated representations of graph. They are U-NetsPool <ref type="bibr" target="#b5">[6]</ref> and SelfAttnPool <ref type="bibr" target="#b13">[14]</ref>. The second category improves the optimization and generalization of learned representations. They include StableGNN <ref type="bibr" target="#b4">[5]</ref>, OOD-GNN <ref type="bibr" target="#b14">[15]</ref>, and IRM <ref type="bibr" target="#b0">[1]</ref>. The third is DIR for graph rationale identification that was proposed in a very recent work by Wu et al. <ref type="bibr" target="#b33">[34]</ref>. To investigate the effect of environment replacement augmentation (denoted by RepAug as a module that may be used or not in the methods), we implement two method variants: (1) DIR+RepAug: We add environment-replaced augmentation to DIR <ref type="bibr" target="#b33">[34]</ref> to identify rationales, however, it has to explicitly decode and encode the rationales; (2) GREA?RepAug: We disable the environment replacement augmentation and use only the environment removal augmentation, i.e., rationale subgraphs in GREA. In the experiments, we study two types of GNN models (GCN <ref type="bibr" target="#b11">[12]</ref> and GIN <ref type="bibr" target="#b36">[37]</ref>) as graph encoders for all the methods. Please refer to Appendix B for details of implementation. <ref type="table" target="#tab_1">Table 2</ref> presents the results on polymer property regression with R 2 and RMSE metrics. <ref type="table" target="#tab_2">Table 3</ref> presents the results on molecule property classification using AUC. Underlined are for the best baseline(s). The best baseline is OOD-GNN for its elimination of the statistical dependence between property-relevant graph representation and property-irrelevant graph representation. The first graph rationalization method DIR was evaluated on synthetic data <ref type="bibr" target="#b33">[34]</ref>; unfortunately, it performs poorly on real polymer and molecule (1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results on Effectiveness (Q1)</head><p>(3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3: Three polymer examples in O 2</head><p>Perm test set to compare graph rationales and property predictions by DIR <ref type="bibr" target="#b33">[34]</ref> and our GREA. DIR selects edges to decode rationale subgraphs. Our GREA estimates the probability of nodes being classified into rationales in latent space. The red boxes indicate incoherent edges that DIR selects. The blue boxes indicate coherent node sets that contribute to accurate predictions on oxygen permeability of polymer membrane.</p><p>datasets because it selects edges to create rationale subgraphs and thus loses the original contextual information of atoms in the the rationale representations. Compared to them, our GREA with either GCN or GIN consistently achieves the best performance on all the polymer and molecule datasets. On the PolyDensity dataset, GREA with GCN improves R 2 over OOD-GNN relatively by +3.91%. On MeltingTemp, GREA with GIN produces 1.56? R 2 over DIR. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ablation Study on GREA (Q2)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Case Study on Polymer Data (Q3)</head><p>Given test polymer examples in the O 2 Perm dataset, we visualize and compare the rationale subgraphs that are identified by from DIR <ref type="bibr" target="#b33">[34]</ref> and our GREA in <ref type="figure">Figure 3</ref>. We have three observations. First, the rationales identified by GREA have more coherent structures of atom nodes than those identified by DIR. The red boxes show that quite a few edges in the rationales by DIR are far separated. This is because DIR explicitly decodes the subgraphs by selecting edges. Our GREA estimates the probability of nodes being   <ref type="figure">Figure 5</ref>: On two polymer datasets, the performance of GREA is not sensitive to rationale size with wide ranges for tuning. included in the rationales and uses the contextualized representations of atoms in the input graphs to create the representations of rationales. So the rationales have coherent structures of nodes. Second, the rationales from GREA are more interpretable and beneficial than the ones from DIR, based on domain expertise in polymer science. Take a look at the first polymer example in <ref type="figure">Figure 3</ref>. The rationale from GREA includes non-aromatic rings and methyl groups. The former group allows larger free volume elements and lower densities (i.e., enlarge microporousity) in the polymer's repeating units, which positively contributes to the gas permeability <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b37">38]</ref>. The latter group is hydrophobic and contributes to steric frustration between polymer chains <ref type="bibr" target="#b37">[38]</ref>, inducing a positive correlation to the permeability. On the other hand, the rationale from DIR would make property predictor overestimate the oxygen permeability, because it suggests that the double-bonded oxygens, ethers, and nitrogen atoms are positively correlated with the property. However, it conflicts with observations and conclusions from chemical experiments in previous literature <ref type="bibr" target="#b37">[38]</ref> where researchers argue that the double-bonded oxygens, ethers, and nitrogen atoms are negatively correlated with gas permeability. For the second and  <ref type="figure">Figure 6</ref>: On four polymer datasets, the performance of GREA (in R 2 ) is not sensitive to hyperparameters and in Eq. <ref type="bibr" target="#b12">(13)</ref>.</p><p>third examples, DIR also predicts through double-bonded oxygens, ethers, and nitrogen atoms, and it overestimates the permeability. Our GREA realizes and employs the true relationship between the functional groups and property and successfully suppresses the representations of non-aromatic rings and methyl groups in the prediction. GREA intrinsically discovers correct relationships between rationale subgraphs and the property. Third, the rationales from GREA are commonly observed across different polymers. We expect rationales to have universal indication on the polymer properties. The rationales identified in the second and third examples both have the fused heterocyclic rings (at the right end of the monomers and highlighted by blue boxes).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Results on Efficiency (Q4)</head><p>We conduct efficiency analysis using the ogbg-HIV dataset without losing the generality. Results are presented in <ref type="figure" target="#fig_5">Figure 4</ref>. When batch size increases, in other words, when a batch has more and more graphs, the time cost per batch of DIR increases significantly; our proposed GREA spends much less time than DIR. Empirically we show that our GREA is more efficient than DIR. This is because GREA does not explicitly decode or encode the subgraphs but directly creates their representations in latent space. <ref type="figure" target="#fig_5">Figure 4(b)</ref> shows that compared to three most competitive baselines, GREA delivers the highest AUC by learning augmented examples, while spending comparable amount of time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Sensitivity Analysis (Q5)</head><p>Without losing the generality, we conduct three series of sensitivity analyses. First, <ref type="figure">Figure 6</ref> shows that on four polymer datasets, the performance of GREA in terms of R 2 is insensitive to the hyperparameters and in Eq. <ref type="bibr" target="#b12">(13)</ref>. Second, <ref type="figure">Figure 5</ref> shows that the performance is insensitive to rationale size in Eq. <ref type="bibr" target="#b10">(11)</ref>. Third, on two polymer datasets and one of the most popular molecule datasets, <ref type="table" target="#tab_4">Table 4</ref> compares the effects of different choices of AGG(?) function that aggregates the representations of rationale and environment subgraphs. Sum pooling is generally the best choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>In this work, we made the first attempt to improve graph rationale identification using data augmentations, including environment replacement, for accurate and interpretable graph property prediction. We proposed an efficient framework that performs rationaleenvironment separation and representation learning on real and augmented examples in one latent space. Experiments on molecule and polymer datasets demonstrated its effectiveness and efficiency.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>?</head><label></label><figDesc>&amp;*. ( &amp; % &amp; , % ) ? &amp;*+ ( &amp; %,( , % ) !</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The architecture of the proposed graph rationalization framework: It performs the creation and representation learning of environment-based augmented examples in a latent space, instead of decoding every example into a graph form and running a GNN encoder on it. This design aligns graph representation spaces and avoids high computational complexity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(1); the rationale subgraph's representation h ( ) is then combined with different environment subgraph's representations h ( ) for the augmented graph's representations h ( , ) ; finally, both h ( ) and h ( , ) are fed into MLP 2 for the prediction of during training as Eq.(2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>CC1=C(*)C(C)=C(N2C(=O)C3=CC=C(OC4=CC5=C(C=C4)C(=O)N(*)C5=O)C=C3C2=O)C2=C1CCC2(C)C O 2 Permeability: Truth: 43 DIR: 67.52 GREA (ours): 42.98CC(C)(C1=CC2C(C=C1)C(=O)N(C2=O)C1=CC=C(O*)C=C1)C1=CC=C2C(=C)N(C(=C)C2=C1)C1=CC=C(OC2=CC=C(C=C2)C(=O) C2=CC=C3C(=C2)C(C)(C)CC3(C)C2=CC=C(C=C2)C(=O)C2=CC=C(*)C=C2)C=C1 O 2 Permeability: Truth: 1.83 DIR: 22.23 GREA (ours): 1.87 CC1(C)CC(C)(C2=CC=C(C=C12)C(=O)C1=CC=C(OC2=CC=C(C=C2)N2C(=C)C3=CC=C(C=C3C2=C)S(=O)(=O)C2=CC3C(C=C2)C (=O)N(C3=O)C2=CC=C(O*)C=C2)C=C1)C1=CC=C(C=C1)C(=O)C1=CC=C(*)C=C1 O 2 Permeability: Truth: 1.32 DIR: 35.29 GREA (ours): 1.78</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Our GREA runs much faster than DIR when batch size (# graphs) increases. GREA spends comparable amount of training time to deliver the highest AUC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Efficiency analysis on the ogbg-HIV dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of eleven datasets for graph property prediction: The four top rows are polymer datasets. The prediction tasks are graph regression. The seven bottom rows are molecule datasets. Their tasks are graph classification.</figDesc><table><row><cell>Dataset</cell><cell cols="3"># Graphs Avg./Max # Nodes Avg./Max # Edges</cell></row><row><cell>GlassTemp</cell><cell>7,174</cell><cell>36.7 / 166</cell><cell>79.3 / 362</cell></row><row><cell>MeltingTemp</cell><cell>3,651</cell><cell>26.9 / 102</cell><cell>55.4 / 212</cell></row><row><cell>PolyDensity</cell><cell>1,694</cell><cell>27.3 / 93</cell><cell>57.6 / 210</cell></row><row><cell>O 2 Perm</cell><cell>595</cell><cell>37.3 / 103</cell><cell>82.1 / 234</cell></row><row><cell>ogbg-HIV</cell><cell>41,127</cell><cell>25.5 / 222</cell><cell>54.9 / 502</cell></row><row><cell>ogbg-ToxCast</cell><cell>8,576</cell><cell>18.8 / 124</cell><cell>38.5 / 268</cell></row><row><cell>ogbg-Tox21</cell><cell>7,831</cell><cell>18.6 / 132</cell><cell>38.6 / 290</cell></row><row><cell>ogbg-BBBP</cell><cell>2,039</cell><cell>24.1 / 132</cell><cell>51.9 / 290</cell></row><row><cell>ogbg-BACE</cell><cell>1,513</cell><cell>34.1 / 97</cell><cell>73.7 / 202</cell></row><row><cell>ogbg-ClinTox</cell><cell>1,477</cell><cell>26.2 / 136</cell><cell>55.8 / 286</cell></row><row><cell>ogbg-SIDER</cell><cell>1,427</cell><cell>33.6 / 492</cell><cell>70.7 / 1010</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results on polymer property prediction: GREA consistently achieves the highest R 2 and smallest RMSE.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">GlassTemp R 2 ? RMSE ?</cell><cell>MeltingTemp R 2 ? RMSE ?</cell><cell>PolyDensity R 2 ? RMSE ?</cell><cell>O 2 Perm R 2 ? RMSE ?</cell></row><row><cell></cell><cell>U-NetsPool [6]</cell><cell>0.839?0.005</cell><cell cols="2">44.9?0.7 0.685?0.012 63.4?1.2 0.615?0.053 0.100?0.007 0.833?0.084</cell><cell>865?214</cell></row><row><cell>GCN [12] as encoder</cell><cell cols="4">SelfAttnPool [14] 0.848?0.007 StableGNN [5] 0.809?0.013 OOD-GNN [15] 0.852?0.006 IRM [1] 0.830?0.008 DIR [34] 0.697?0.061 DIR+RepAug 0.800?0.006 GREA?RepAug 0.685?0.172 60.6?16.5 0.679?0.034 64.0?3.3 0.686?0.007 0.090?0.001 0.459?0.254 1556?395 43.5?1.0 0.709?0.008 61.0?0.9 0.688?0.019 0.090?0.003 0.656?0.135 1251?266 48.8?1.6 0.635?0.033 70.0?4.5 0.667?0.070 0.093?0.009 0.676?0.127 1219?241 43.0?0.9 0.714?0.025 60.4?2.6 0.676?0.010 0.092?0.001 0.921?0.059 576?212 46.1?1.1 0.677?0.006 64.2?0.6 0.690?0.016 0.090?0.002 0.871?0.043 770?141 61.2?6.0 0.380?0.214 87.8?14. 0.656?0.036 0.094?0.005 0.135?0.068 2028?80 56.5?3.2 0.520?0.101 77.8?8.2 0.671?0.033 0.092?0.005 0.915?0.031 626?115</cell></row><row><cell></cell><cell>GREA (ours)</cell><cell cols="3">0.855?0.003 42.6?0.5 0.716?0.016 60.2?1.6 0.717?0.023 0.086?0.003 0.941?0.018</cell><cell>524?91</cell></row><row><cell></cell><cell>U-NetsPool [6]</cell><cell>0.852?0.006</cell><cell cols="2">42.9?0.9 0.703?0.009 61.6?0.9 0.635?0.029 0.097?0.004 0.868?0.085</cell><cell>753?250</cell></row><row><cell>GIN [37] as encoder</cell><cell cols="2">SelfAttnPool [14] 0.848?0.003 StableGNN [5] 0.794?0.007 OOD-GNN [15] 0.862?0.007 IRM [1] 0.842?0.004 DIR [34] 0.594?0.070 DIR+RepAug 0.744?0.029 GREA?RepAug 0.494?0.110</cell><cell cols="2">43.5?0.4 0.726?0.009 59.2?1.0 0.654?0.024 0.095?0.003 0.601?0.267 1265?546 50.8?0.9 0.535?0.061 76.9?5.0 0.642?0.045 0.096?0.006 0.501?0.266 1487?404 41.6?1.1 0.721?0.006 59.7?0.6 0.666?0.025 0.093?0.003 0.917?0.029 620?109 44.5?0.5 0.681?0.008 63.8?0.8 0.682?0.031 0.091?0.004 0.890?0.042 709?146 71.0?6.0 0.287?0.121 95.1?7.9 0.617?0.045 0.099?0.006 0.501?0.309 1446?537 56.4?3.2 0.542?0.083 76.2?7.0 0.647?0.058 0.095?0.008 0.743?0.150 1054?338 79.0?9.3 0.660?0.107 65.2?9.5 0.717?0.022 0.086?0.003 0.400?0.286 1623?474</cell></row><row><cell></cell><cell>GREA (ours)</cell><cell cols="3">0.864?0.005 41.2?0.8 0.736?0.012 58.0?1.2 0.723?0.030 0.085?0.005 0.930?0.020</cell><cell>569?86</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results on molecule property prediction: GREA consistently achieves the highest AUC (?). 7527?0.0104 0.6507?0.0086 0.7492?0.0093 0.6709?0.0176 0.7757?0.0173 0.8450?0.0403 0.6181?0.0121 SelfAttnPool [14] 0.7733?0.0187 0.6510?0.0076 0.7563?0.0080 0.6602?0.0220 0.7383?0.0541 0.8291?0.0791 0.5718?0.0219 7533?0.0247 0.6351?0.0137 0.7507?0.0110 0.6624?0.0167 0.7348?0.0194 0.7912?0.0995 0.5702?0.0137 StableGNN</figDesc><table><row><cell></cell><cell></cell><cell>ogbg-HIV</cell><cell>ogbg-ToxCast</cell><cell>ogbg-Tox21</cell><cell>ogbg-BBBP</cell><cell>ogbg-BACE</cell><cell>ogbg-ClinTox</cell><cell>ogbg-SIDER</cell></row><row><cell>GCN [12] as encoder</cell><cell cols="7">U-NetsPool [6] 0.StableGNN [5] 0.7218?0.0099 0.6520?0.0109 0.7454?0.0059 0.6552?0.0184 0.6607?0.0500 0.7681?0.0778 0.5644?0.0274 OOD-GNN [15] 0.7580?0.0176 0.6613?0.0046 0.7673?0.0109 0.6795?0.0165 0.8096?0.0132 0.8874?0.0143 0.6133?0.0095 IRM [1] 0.7702?0.0107 0.6599?0.0063 0.7654?0.0072 0.6892?0.0053 0.7947?0.0186 0.8819?0.0231 0.6035?0.0195 DIR [34] 0.7466?0.0093 0.5954?0.0154 0.4727?0.0129 0.6559?0.0298 0.6751?0.0323 0.6251?0.0956 0.5331?0.0216 DIR+RepAug 0.7494?0.0225 0.6632?0.0098 0.7437?0.0054 0.6630?0.0118 0.7677?0.0226 0.8606?0.0144 0.5934?0.0170 GREA?RepAug 0.7377?0.0210 0.6614?0.0048 0.7808?0.0061 0.6736?0.0077 0.7655?0.0529 0.8708?0.0514 0.6222?0.0166</cell></row><row><cell></cell><cell>GREA (ours)</cell><cell cols="6">0.7794?0.0065 0.6662?0.0041 0.7822?0.0093 0.6986?0.0175 0.8191?0.0240 0.8961?0.0150 0.6316?0.0151</cell></row><row><cell></cell><cell>U-NetsPool [6]</cell><cell cols="6">0.7375?0.0362 0.6524?0.0126 0.7560?0.0093 0.6809?0.0163 0.8026?0.0105 0.8146?0.0703 0.5929?0.0114</cell></row><row><cell>GIN [37] as encoder</cell><cell cols="2">SelfAttnPool [14] 0.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Tables 2 and 3have presented the results of DIR+RepAug and GREA?RepAug. DIR+RepAug is a variant of baseline method DIR by enabling environment replacement augmentations for training. GREA?RepAug is a variant of our GREA that disables the replacement augmentations and uses environment removal only for training. Clearly, DIR+RepAug outperforms DIR, showing positive effect of the replacement augmentations. And the performance of GREA?RepAug is not satisfactory. Environment replacement augmentations are effective for training graph rationalization methods.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Effect of AGG h in Eq.<ref type="bibr" target="#b6">(7)</ref>. We use Sum Pooling by default because it generally performs the best.</figDesc><table><row><cell></cell><cell>( )</cell><cell>, h</cell><cell>( )</cell></row><row><cell></cell><cell cols="3">MeltingTemp (R 2 )</cell><cell>O 2 Perm (R 2 )</cell><cell>ogbg-HIV (AUC)</cell></row><row><cell>Sum Pooling</cell><cell cols="2">0.7362?0.0115</cell><cell></cell><cell>0.9304?0.0202</cell><cell>0.7932?0.0092</cell></row><row><cell>Mean Pooling</cell><cell cols="2">0.7328?0.0068</cell><cell></cell><cell>0.9288?0.0331</cell><cell>0.7810?0.0117</cell></row><row><cell>Max Pooling</cell><cell cols="2">0.7164?0.0094</cell><cell></cell><cell>0.8984?0.0494</cell><cell>0.7809?0.0137</cell></row><row><cell>Concatenation</cell><cell cols="2">0.7145?0.0127</cell><cell></cell><cell>0.9240?0.0143</cell><cell>0.7771?0.0096</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/liugangcode/GREA 3 https://github.com/Wuyxin/DIR-GNN 4 https://github.com/pyg-team/pytorch_geometric 5 https://github.com/facebookresearch/InvariantRiskMinimization 6 https://github.com/xxgege/StableNet</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported in part by NSF Grants IIS-1849816, IIS-2142827, IIS-2146761, and CBET-2102592.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A DATASET DETAILS</head><p>Polymer datasets. The four datasets GlassTemp, MeltingTemp, PolyDensity, and O 2 Perm are used to predict different properties of polymers such as glass transition temperature ( ? C), polymer density g/cm <ref type="bibr" target="#b2">3</ref> , melting temperature ( ? C), and oxygen permeability (Barrer). GlassTemp, MeltingTemp, and PolyDensity are collected from Poly-Info, which is the largest web-based polymer database <ref type="bibr" target="#b19">[20]</ref>. The O 2 Perm dataset is created from the Membrane Society of Australasia portal, consisting of a variety of gas permeability data <ref type="bibr" target="#b24">[25]</ref>. However, the limited size (i.e., 595 polymers) brings great challenges to rationale identification and property prediction. Since a polymer is built from repeated monomer units, researchers use monomers as polymer graphs to predict properties. Different from molecular graphs, the monomer graphs have two special nodes (see " * " in the molecular structures in <ref type="figure">Figure 1</ref>), indicating the polymerization points of monomers <ref type="bibr" target="#b16">[17]</ref>. For all the polymer datasets, we randomly split by 60%/10%/30% for training, validation, and test.</p><p>Molecule datasets. Besides polymer datasets, we use seven molecule datasets from the graph property prediction task on Open Graph Benchmark or known as OGBG. They were originally collected by MoleculeNet <ref type="bibr" target="#b35">[36]</ref> and used to predict the properties of molecules, including (1) inhibition to HIV virus replication in ogbg-HIV, (2) toxicological properties of 617 types in ogbg-ToxCast, (3) toxicity measurements such as nuclear receptors and stress response in ogbg-Tox21, (4) blood-brain barrier permeability in ogbg-BBBP, (5) inhibition to human -secretase 1 in ogbg-BACE, (6) FDA approval status or failed clinical trial in ogbg-ClinTox, and <ref type="formula">(7)</ref> having drug side effects of 27 system organ classes in ogbg-SIDER. For all molecule datasets, we use the scaffold splitting procedure as OGBG adopted <ref type="bibr" target="#b8">[9]</ref>. It attempts to separate structurally different molecules into different subsets, which provides a more realistic estimate of model performance in experiments <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B IMPLEMENTATION DETAILS</head><p>All the experiments in this work are conducted on an Linux server with Intel Xeon Gold 6130 Processor (16 Cores @2.1Ghz), 96 GB of RAM, and a single RTX 2080Ti card (11 GB of RAM). Our method is implemented with Python 3.9.9 and PyTorch 1.10.1. We manually tune the hyperparameters over the following ranges:</p><p>? We use sum pooling as the default AGG(?) in GREA for the experiments in <ref type="table">Tables 2 and 3</ref>. We set GIN as the default encoder for all ablation studies, case studies, and efficiency analysis. We employ the virtual node trick <ref type="bibr" target="#b8">[9]</ref> for all methods on the ogbg-HIV, ogbg-Tox21, ogbg-BBBP, and all polymer datasets. For PolyDensity, we train and evaluate the models using the logarithm of the property <ref type="bibr" target="#b16">[17]</ref>. We report the mean and standard deviation of the test performance over 10 runs with different random initialization of the parameters.</p><p>Our code and data are available on the GitHub 2 . To implement the baseline methods, we use the official code package 3 from the authors for DIR <ref type="bibr" target="#b33">[34]</ref>. For U-NetsPool <ref type="bibr" target="#b5">[6]</ref> and SelfAttnPool <ref type="bibr" target="#b13">[14]</ref>, we use the public implementation provided by the PyG 4 package. For IRM <ref type="bibr" target="#b0">[1]</ref>, we implement it's graph version based on its official repository. <ref type="bibr" target="#b4">5</ref> As source codes of OOD-GNN <ref type="bibr" target="#b14">[15]</ref> and StableGNN <ref type="bibr" target="#b4">[5]</ref> are not publically available, we implement then with the official code package of StableNet 6 and the PyG package.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Invariant risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Invariant rationalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1448" to="1458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Measuring and relieving the over-smoothing problem for graph neural networks from the topological view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deli</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AAAI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3438" to="3445" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Polymer informatics: Current status and critical next steps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghanshyam</forename><surname>Pilania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tran</forename><surname>Doan Huan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiho</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Kuenneth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rampi</forename><surname>Ramprasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Materials Science and Engineering: R: Reports</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page">100595</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Generalizing Graph Neural Networks on Out-Of-Distribution Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Shaohua Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bai</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.10657</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graph U-Nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Few-Shot Graph Learning for Molecular Property Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichun</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Herr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Wiest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitesh V</forename><surname>Chawla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2559" to="2567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Open Graph Benchmark: Datasets for Machine Learning on Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Federated Dynamic Graph Neural Networks with Secure Aggregation for Video-based Distributed Surveillance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taeho</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Karl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIST</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Polymer genome: a data-powered polymer informatics platform for property predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiho</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tran</forename><surname>Doan Huan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deya</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rampi</forename><surname>Ramprasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Physical Chemistry C</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page" from="17575" to="17585" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">RDKit: A software suite for cheminformatics, computational chemistry, and predictive modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Landrum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Self-attention graph pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhyun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inyeop</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3734" to="3743" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">OOD-GNN: Outof-Distribution Generalized Graph Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.03806</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evaluating polymer representations via quantifying structure-property relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruimin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="3110" to="3119" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">PI1M: a benchmark database for polymer informatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruimin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page">4684</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A unified view on graph neural networks as graph signal denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaorui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yozen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1202" to="1211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Rethinking pooling in graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Mesquita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amauri</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Kaski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">PoLyInfo: Polymer database for polymeric materials design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shingo</forename><surname>Otsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isao</forename><surname>Kuwajima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junko</forename><surname>Hosoya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Yamazaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Emerging Intelligent Data and Web Technologies</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Metropolis-Hastings Data Augmentation for Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonjin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sihyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyoung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jisu</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyung-Min</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunwoo J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">DropEdge: Towards Deep Graph Convolutional Networks on Node Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Risks of Invariant Risk Minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elan</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Kumar Ravikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Risteski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Energy-efficient polymeric gas separation membranes for a sustainable future: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><forename type="middle">P</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruilan</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">E</forename><surname>Lloyd M Robeson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">R</forename><surname>Mcgrath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benny</forename><forename type="middle">D</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Polymer</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="4729" to="4761" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Polymer Gas Separation Membrane Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thornton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robeson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uhlmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Graph Attention Networks. In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Calendar graph neural networks for modeling time structures in spatiotemporal user behaviors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munira</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Juneja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriram</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitesh V</forename><surname>Chawla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2581" to="2589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Modeling co-evolution of attributed and structural information in graph sequence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitesh</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Modeling co-evolution of attributed and structural information in graph sequence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitesh</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamic Attributed Graph Prediction with Conditional Normalizing Flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM. IEEE</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1385" to="1390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Graphcrop: Subgraph cropping for graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Hooi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.10564</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Nodeaug: Semi-supervised node classification with data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Hooi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="207" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Thermal Transport in Polymers: A</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingfei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Review. Journal of Heat Transfer</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">72101</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An Zhang, Xiangnan He, and Tat-Seng Chua. 2022. Discovering Invariant Rationales for Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S Yu</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TNNLS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4" to="24" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">MoleculeNet: a benchmark for molecular machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenqin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><forename type="middle">N</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caleb</forename><surname>Geniesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Aneesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pappu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Leswing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemical science</title>
		<imprint>
			<biblScope unit="page" from="513" to="530" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">How Powerful are Graph Neural Networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Discovery of Innovative Polymers for Next-Generation Gas-Separation Membranes using Interpretable Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinlong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Mccutcheon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Li</surname></persName>
		</author>
		<idno>chemrxiv-2021-p4g7z</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Gnnexplainer: Generating explanations for graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Bourgeois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Hierarchical graph representation learning with differentiable pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4805" to="4815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Graph contrastive learning with augmentations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongduo</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5812" to="5823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep learning on graphs: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A synergistic approach for graph anomaly detection with pattern mining and feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TNNLS</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.08871</idno>
		<title level="m">Graph Data Augmentation for Graph Machine Learning: A Survey</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning from Counterfactual Links for Link Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Data Augmentation for Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yozen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Woodford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Shah</surname></persName>
		</author>
		<idno>AAAI. 11015</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Action Sequence Augmentation for Early Graph-based Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichun</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2668" to="2678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Data Augmentation for Graph Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2341" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Graph contrastive learning with adaptive augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2069" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
