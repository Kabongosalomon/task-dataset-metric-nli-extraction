<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Shape Biased Unsupervised Representation Learning for Domain Generalization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nader</forename><surname>Asadi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Shahid Bahonar University of Kerman</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><forename type="middle">M</forename><surname>Sarfi</surname></persName>
							<email>a.m.sarfi@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Shahid Bahonar University of Kerman</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrdad</forename><surname>Hosseinzadeh</surname></persName>
							<email>mehrdad@cs.umanitoba.ca</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Manitoba</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahra</forename><surname>Karimpour</surname></persName>
							<email>karimpour.zhr@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Shahid Bahonar University of Kerman</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdi</forename><surname>Eftekhari</surname></persName>
							<email>m.eftekhari@eng.uk.ac.ir</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Shahid Bahonar University of Kerman</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Shape Biased Unsupervised Representation Learning for Domain Generalization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Shape bias plays an important role in self-supervised learning paradigm. The ultimate goal in self-supervised learning is to capture a representation that is based as much as possible on the semantic of objects (i.e. shape bias) and not on individual objects' peripheral features. This is inline with how human learns in general; our brain unconsciously focuses on the general shape of objects rather than superficial statistics of context. On the other hand, unsupervised representation learning allows discovering label-invariant features which helps generalization of the model. Inspired by these observations, we propose a learning framework to improve the learning performance of self-supervised methods by further hitching their learning process to shape bias. Using distinct modules, our method learns semantic and shape biased representations by integrating domain diversification and jigsaw puzzles. The first module enables the model to create a dynamic environment across arbitrary domains and provides a domain exploration vs. exploitation trade-off, while the second module allows it to explore this environment autonomously. The proposed framework is universally adaptable since it does not require prior knowledge of the domain of interest. We empirically evaluate the performance of our framework through extensive experiments on several domain generalization datasets, namely, PACS, Office-Home, VLCS, and Digits. Results show that the proposed method outperforms the other state-of-the-arts on most of the datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Convolutional Neural Networks have achieved significant success in a wide variety of visual recognition tasks, demonstrating an excellent ability to learn the spatial structure of image data. Despite the promising results, the performance of these models diminishes considerably when applied to environments different than training. This frag-ile phenomenon is known as domain shift. This is due to the significant dependency of these models on large-scale annotated datasets. This issue imposes severe issues toward practical applications of deep neural networks and their generalization to domains beyond their own training one <ref type="bibr" target="#b51">[49]</ref>.</p><p>In order to alleviate domain shift problem, several domain adaptation methods have been proposed <ref type="bibr" target="#b3">[6,</ref><ref type="bibr" target="#b43">41,</ref><ref type="bibr" target="#b54">52]</ref> Due to the cost of manually annotating target domain data, unsupervised domain adaptation, i.e. adapting a trained model to a new target domain without annotating the target dataset, has been the foundation for a considerable amount of research. Early works in this domain tackled the problem by learning to match the distribution of source and target domains <ref type="bibr" target="#b50">[48,</ref><ref type="bibr" target="#b37">36]</ref>. In these methods, the goal is to reduce the difference between covariance matrices of source and target domains. Similarly <ref type="bibr" target="#b47">[45]</ref> proposed Domain-specific Whitening Transform which computes domain-specific covariance matrices of intermediate features by whitening the source and the target features and projecting them into a common spherical distribution. Another recent approach used for unsupervised domain adaptation, embeds domainspecific alignment layers, inspired by BatchNorm <ref type="bibr" target="#b22">[22]</ref> layers, within the network <ref type="bibr">[3,</ref><ref type="bibr" target="#b36">35]</ref> Another category of domain translation methods focuses on the appearance translation of source domain towards the target domain. Since many image translation methods are imperfect, these approaches have severe drawbacks especially when there is a significant gap between source and target domains <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b48">46]</ref>.</p><p>Due to the fact that unsupervised representation learning helps the model to learn label-invariant and high-level representation of data, they can improve generalizability as well as the robustness of the model <ref type="bibr" target="#b1">[4,</ref><ref type="bibr" target="#b18">18]</ref>. Furthermore, unsupervised representation learning can solve the lack of large-scale annotated benchmarks since a sheer volume of unlabeled data is publicly available. Subsequently, these methods are less susceptible to unfavorable biases of data <ref type="bibr" target="#b51">[49]</ref>. Inspired by what mentioned above, <ref type="bibr" target="#b1">[4]</ref> proposed a method capable of learning spatial co-location of image parts simultaneously with supervised learning. Moreover, they show that self-supervision can have a considerable impact on the generalizability of the model. Although selfsupervised methods learn general feature embeddings, one major question is how much is the learned representation by these methods biased towards superficial statistics of image e.g., textures and local features?</p><p>It is proved that humans' biological visual system has a considerable robust performance against domain shifts. It is known that humans display shape bias when classifying new objects and that is the reason behind the robustness of human's visual system <ref type="bibr" target="#b46">[44,</ref><ref type="bibr" target="#b11">13]</ref>. In recent years, shape-bias property and unfavorable bias of CNNs towards textures and local features has been studied extensively <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr">2]</ref>. Our model is partly inspired by some work of Geirhos et al. <ref type="bibr" target="#b10">[12]</ref>. Geirhos et al. <ref type="bibr" target="#b10">[12]</ref> proves that CNNs are highly biased towards learning superficial characteristics e.g., textures rather than general shape of objects which is in clear contrast with the human visual system. In this paper, we use a similar idea and develop a CNN architecture to improve the generalization of Self-supervised methods against arbitrary domain shifts.</p><p>Furthermore, we investigate the learned feature representation of self-supervised methods. We state that, though unsupervised representation learning is capable of learning a label-invariant and high-level representation of the image, it is severely biased to unfavorable and superficial statistics of the data. We use jigsaw puzzle <ref type="bibr" target="#b40">[39]</ref> pretext task as the baseline of our method and analysis. We prove that context-based self-supervised methods are significantly biased to the texture and local features of the image.</p><p>To remedy it, a novel shape-biased framework for selfsupervised methods is proposed as a means to learn more generalized representation and reduce domain shift problem. A texture diversification method is used in order to enforce the model to solve jigsaw task based on the general shape of each object rather than local textures and superficial features. Thereupon, we propose a self-supervised learning system based on jigsaw task which enables the model to explore arbitrary domains during the training process. Furthermore, an extensive analysis is conducted on domain exploration vs. exploitation trade-off, and the behavior of the model is discussed in each setting.</p><p>Since self-supervised methods learn an invariant representation of the data, improving shape bias property, and unbiasing them from superficial statistics, enhances the generalizability of these models to a significant extent. Finally, in order to prove the effectiveness of our method, we conduct extensive experiments on domain generalization benchmarks and illustrate that our method outperforms state-of-the-art works on domain generalization. To summarize the contribution of this paper is manifold:</p><p>? We analyze the dependency of unsupervised represen-tation learning methods on textures as well as local features of image.</p><p>? We structurize an unsupervised representation learning paradigm by integrating domain diversification and jigsaw puzzles pretext task.</p><p>? Through extensive experiments, we show that our method outperforms state-of-the-art methods on domain generalization. Furthermore, the robustness of our method against distortions is studied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>As discussed in the previous section, in this work, we study the generalization of self-supervised methods across arbitrary domains. Correspondingly, a model based on Jigsaw pretext task is proposed as a domain generalization method. Our work encompasses DomainDomain Adaptation and Unsupervised Representation Learning problems. We briefly discuss each problem in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Unsupervised Domain Adaptation</head><p>Domain adaptation, the challenge of distilling the most general and transferable knowledge from a limited source, has been studied intensively for both shallow and deep neural networks. However, in this section, our primary focus is on deep domain adaptation methods due to the significant success of these models <ref type="bibr" target="#b23">[23]</ref>.</p><p>Generally, these methods lay into generative-based methods <ref type="bibr" target="#b56">[54,</ref><ref type="bibr" target="#b44">42,</ref><ref type="bibr" target="#b57">55]</ref>, free-semantic based methods <ref type="bibr" target="#b45">[43]</ref>, and context-based methods <ref type="bibr" target="#b40">[39,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b24">24]</ref>. One category of research tackles the domain adaptation problem using a set of unannotated target data to guide training on the source domain <ref type="bibr" target="#b3">[6]</ref>. However, real-world applications of domain generalization target domain data are not available, which is considered as a drawback of the aforementioned approaches. Some works use the first-order <ref type="bibr" target="#b33">[32,</ref><ref type="bibr" target="#b53">51]</ref> and second-order statistics <ref type="bibr" target="#b50">[48,</ref><ref type="bibr" target="#b37">36]</ref> to diminish the domain shift problem. Some other works try to alleviate domain shift problem by introducing domain alignment layers <ref type="bibr" target="#b36">[35,</ref><ref type="bibr">3]</ref>, inspired by BachNorm layer <ref type="bibr" target="#b22">[22]</ref>.</p><p>Another category of feature level approaches work on Maximum Mean Discrepancy minimization <ref type="bibr" target="#b33">[32,</ref><ref type="bibr" target="#b50">48,</ref><ref type="bibr">3]</ref>. Using Generative Adversarial Networks(GANs), source-totarget transformation methods have shown promising results <ref type="bibr" target="#b57">[55,</ref><ref type="bibr" target="#b26">25,</ref><ref type="bibr" target="#b57">55]</ref>. However, since translation models are imperfect, GAN-based methods have significant drawbacks in case of complex datasets. Several unsupervised domain adaptation methods used entropy minimization <ref type="bibr" target="#b16">[16]</ref>, exploiting the high-confidence predictions of unlabeled samples as pseudo-labels, due to the effectiveness of this method <ref type="bibr" target="#b35">[34,</ref><ref type="bibr" target="#b49">47,</ref><ref type="bibr" target="#b48">46]</ref>. <ref type="figure">Figure 1</ref>. Illustration of our proposed framework. Our framework enables the model(Convnet) to learn from both ordered and shuffled images. Our framework consists of Domain Diversification followed by Exploration Controller modules which create a dynamic environment across arbitrary domains. Consequently, the model can explore this environment autonomously, which improves the shape bias property of the network to a significant extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Unsupervised Representation Learning</head><p>Self-supervised learning is a framework in which the model is explicitly trained with automatically generated labels from pretext task, in an effort to learn useful representations for downstream task. In this section, we focus on self-supervised methods for image representation learning.</p><p>Patch-based unsupervised representation learning is one of the major approaches which was first introduced by <ref type="bibr" target="#b5">[8]</ref>. On the same research line, <ref type="bibr" target="#b40">[39]</ref> proposed a method that predicts the permutation of jigsaw puzzles. Some other methods are built on top of jigsaw task with an effort to improve the learned feature representation for downstream task <ref type="bibr" target="#b42">[40,</ref><ref type="bibr" target="#b24">24]</ref>. Other methods generate image-level tasks. <ref type="bibr" target="#b15">[15]</ref> proposed a method based on the random rotation of the image at specific angles. <ref type="bibr" target="#b2">[5]</ref> used clustering of images in the latent space of the network to generate pseudo-labels for training the model. Other category of works are based on generative-based methods. Some noteworthy examples are super-resolution[27], image inpainting <ref type="bibr" target="#b44">[42]</ref>, image colorization <ref type="bibr" target="#b56">[54]</ref>, and generative adversarial networks <ref type="bibr" target="#b57">[55]</ref>.</p><p>[4] proposed a method with respect to previous literature by investigating the importance of jointly exploiting supervised and unsupervised inherent signals from the images for domain generalization. However, we study the unfavorable biases of learned feature representation of self-supervised methods. We propose a method in an effort of focusing on domain-agnostic signals and improving the shape bias property of these models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>It is known that the human visual system generally displays shape bias. On the other hand, humans seem to rely crucially on learning autonomously. As a matter of fact, the human visual system adaptability relies on both of the aforementioned approaches <ref type="bibr" target="#b46">[44,</ref><ref type="bibr" target="#b11">13]</ref>. This is particularly effective, since unsupervised representation learning methods are label-invariant, they can help the model to discover invariances and regularities that help to generalize <ref type="bibr" target="#b1">[4]</ref>. However, the learned feature representation in these methods is highly dependent on the pretext task e.g., jigsaw puzzles which might cause unfavorable biases in learned feature representation. In order to solve this task, the model can also use superficial statistics which severely harm shape bias property as well as the generalizability of the model.</p><p>We propose a learning paradigm to improve the shape bias property of unsupervised representation learning by alleviating unfavorable biases to superficial statistics of the image. Our framework is based on domain diversification and self-supervision together, which allows the model to be free from a single static domain. In other words, the agent(model) is able to autonomously explore a dynamic environment across arbitrary domains in an effort of learning domain invariant and shape biased characteristics of the problem. Also, we demonstrate that exploration vs. exploitation trade-off can help the model learn useful and unbiased representations. Our method has two major modules, Domain Diversification followed by exploration vs. exploitation controller and unsupervised representation learning by solving jigsaw puzzles. In the following, we describe each module in detail, and finally, a domain invariant learning framework is introduced. <ref type="figure">Figure 1</ref> demonstrates conceptual description of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Jigsaw Puzzles for Domain Generalization</head><p>Previous work <ref type="bibr" target="#b1">[4]</ref> has shown the efficiency of solving jigsaw puzzles on learning a general representation of the image. We use the same approach as the baseline of our framework. This module consists of a convolutional feature extractor and two fully connected parts. Consider x as the input of the network, y as the correct label, and ? f , ? c , ? j as parameters of convolutional feature extractor, cross-entropy classifier, jigsaw classifier respectively. The objective of the first fully-connected module is to minimize the crossentropy loss between ground-truth label y and predicted label by the model parameterized by ? f and ? c . This module, as well as the feature extractor, are trained through</p><formula xml:id="formula_0">argmin ? f ,?c Ni j=1 L c (h(x i j |? f , ? c ), y i j )<label>(1)</label></formula><p>The objective of the second module is to predict permutation set in a decomposed image of n ? n grid of patches being randomly shuffled. The overall number of possible permutations is n 2 !, however, similar to <ref type="bibr" target="#b1">[4]</ref>, a set of P elements is selected following the Hamming distance-based algorithm presented in <ref type="bibr" target="#b40">[39]</ref>. This module, as well as the feature extractor, are trained through</p><formula xml:id="formula_1">argmin ? f ,?j Ki k=1 L j (h(z i k |? f , ? j ), p i k ) (2)</formula><p>where z i k indicates the decomposed samples and p i k the corresponding permutation index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Domain Diversification</head><p>Domain Diversification is a method which diversifies the source domain by intentionally generating distinctive domain discrepancy through these domain shifters. Without harming general shape of the object, the domain of each jigsaw puzzle tile is shifted arbitrarily. Consequently, superficial statistics of the image like textures, have no benefits for solving the pretext task. Thus, the model is enforced to extract features relevant to the general shape of each object. As a result, the self-supervised model will be biased to the high-level shape of objects rather than local textures and background.</p><p>Due to the imperfect performance of domain-shifters, they can cause issues when directly used for domain adaptation problems. However, our framework is utilized by domain diversification to create a dynamic environment in which the self-supervised module is enforced to learn domain-invariant representations. So, we use a modification of Adaptive Instance Normalization method due to its high speed and acceptable performance. Consider x s as the feature representation of source data and x t as the feature representation of an arbitrary target domain. In general, style transfer methods align the channel-wise mean and variance of x s to match those of x t .</p><formula xml:id="formula_2">AdaIN(x s , x t ) = ?(x t )( x s ? ?(x s ) ?(x s ) ) + ?(x s ) (3)</formula><p>as one can see, AdaIN simply scales the normalized content input with ?(x t ), and shift it with ?(x t ). It is crucial to keep the overall shape of each tile intact. The loss function below matches the style of source image to the target image.</p><formula xml:id="formula_3">L s (t, s) = N i=1 ?(? i (g(t))) ? ?(? i (s)) 2 + N i=1 ?(? i (g(t))) ? ?(? i (s)) 2 (4)</formula><p>where ? denotes a layer in VGG-19 used to computer the style loss. Meanwhile, adjacent tiles should be of distant domains in order to enforce the self-supervised model learn shape biased representations. Moreover, since the texture of each tile is changed randomly in each iteration of training, the superficial statistics of the image have no benefits for solving the jigsaw puzzle. To redeem this problem, we add an objective function to enforce the model diversify adjacent tiles without harming the shape of objects.</p><formula xml:id="formula_4">L j = K?1 j=2 L s (z k , z k?1 ) + L s (z k , z k+1 )<label>(5)</label></formula><p>where K is the number of jigsaw tiles and z k indicates the decomposed samples . A pretrained VGG-19 is used to compute the loss function:</p><formula xml:id="formula_5">L = L c + ?L s ? ? L j<label>(6)</label></formula><p>which is a weighted combination of the content loss and style losses where L c is</p><formula xml:id="formula_6">L c = f (g(t)) ? t 2<label>(7)</label></formula><p>In order to keep the overall shape of the object intact, ? and ? parameters should be chosen smaller compared to style transfer problems. Finally, the output of translation module is computed as:</p><formula xml:id="formula_7">T (x s , x t , ?) = g((1 ? ?)f (x s ) + ?AdaIN(f (x s ), f (x t )))<label>(8)</label></formula><p>where f is the pretrained VGG19 encoder, g is the trained decoder using Eq 3.2, and ? allows content-style trade-off at test time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Structured Framework</head><p>In this section, we structurize our learning paradigm by integrating Domain Diversification and solving jigsaw puzzles into a framework. As previously discussed, though self-supervised methods learn general and high-level representation of data, they can be highly biased to superficial statistics of the image e.g., textures and local features. The objective of our work is to create a dynamic environment across domains for the agent(model) to autonomously learn texture-invariant and shape-biased statistics of the data. To achieve this goal, we randomly shift each jigsaw tile to an arbitrary domain. Subsequently, the superficial context and texture of the piles have no advantage for solving the pretext task; thus, the model is enforced to rely on the overall shape of each object to solve the task. The overall objective function of the framework can be written as follows:</p><formula xml:id="formula_8">argmin ? f ,?c,?j N i=1 L c (h(x i |? f , ? c ), y i )+ K k=1 ?L j (h(D(z k , ?)|? f , ? j ), p k ) (9)</formula><p>Here, N is the number of labeled instances, z k indicates the recomposed samples for jigsaw task, ? is the weight parameter for jigsaw loss, ? is the domain shift probability parameter, and D stands for domain diversification model trained using Eq3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exploration vs Exploitation Trade-off</head><p>Our framework has four important hyper-parameters. Two of which, namely ? and ?, are related to solving jigsaw puzzles <ref type="bibr" target="#b1">[4]</ref>. The ? parameter, as mentioned before, controls the significance of jigsaw loss on the overall objective function. The ? parameter defines the ratio between ordered and shuffled images.</p><p>Two other parameters, namely ? and ?, are highly correlated with exploration vs. exploitation trade-off. The ? parameter indicates the probability of domain shift, in other words, exploration weight. For instance, ? = 0.7 means that for each batch, 70% of the shuffled images have arbitrarily shifted patches. On the other hand, ? (Eq. 3.2) defines the magnitude of texture translation; in other words, the step size towards arbitrary domain at exploration time. These two parameters enable the model to explore a dynamic environment across arbitrary domains autonomously. In the following section, we conduct extensive analysis on the impact of these parameters on the learned feature representation of the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we elaborate comprehensive experiments to evaluate the performance of our framework against stateof-the-art methods on domain generalization. We also present an ablation study to analyze the impact of each parameter of our framework on the exploration vs. exploitation trade-off.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup</head><p>Datasets We consider the following datasets for evaluation of our framework: PACS. The PACS dataset <ref type="bibr" target="#b29">[28]</ref> comprises four distinct domains, each corresponding to seven categories. The domains are: Photo, Art, Cartoon, and Sketch. We followed the protocol represented by <ref type="bibr" target="#b1">[4]</ref> and trained our framework over multiple sources and evaluated on the target domain.</p><p>VLCS. The VLCS dataset <ref type="bibr" target="#b51">[49]</ref> contains five object categories shared between PASCAL VOC 2007, LabelMe, Caltech, and Sun datasets. Again, we followed the evaluation protocol used in <ref type="bibr" target="#b1">[4]</ref> for multi-source generalization.</p><p>Office-Home. Office-Home <ref type="bibr" target="#b53">[51]</ref> is a four domain dataset, each corresponding to 65 different categories. Since there are 15,500 images in this dataset, it represents a large scale benchmark for domain adaptation problem. Using this dataset, we evaluate both multi-source and singlesource generalization of our method. Correspondingly, we follow <ref type="bibr" target="#b1">[4]</ref> and <ref type="bibr" target="#b47">[45]</ref> for each section.</p><p>MNIST ? SVHN . MNIST dataset <ref type="bibr" target="#b27">[26]</ref> contains grayscale digits(28?28) ranging from 0 to 9. On the other hand, SVHN <ref type="bibr" target="#b39">[38]</ref> is a color dataset with 32?32 images. However, in order to have a comparison, we scale MNIST images to 32?32 treated as RGB. We followed the protocol used by <ref type="bibr" target="#b47">[45]</ref>.</p><p>Implementation Details To fairly demonstrate the effectiveness of our framework in improving shape bias property of unsupervised representation learning, we adopt the same base networks proposed in <ref type="bibr" target="#b1">[4]</ref>. In all of our experiments, we train the networks using SGD optimizer with a batchsize of 128 images, an initial learning rate of 0.001, weight decay of 5 ? 10 ?5 , and momentum value of 0.9. For each experiment, the value of hyper-parameters related to either the jigsaw task or exploration vs. exploitation trade-off is stated accordingly. For domain diversification model, we used The Behance Artistic Media Datasets(BAM) <ref type="bibr" target="#b55">[53]</ref> due to the availability of a wide variety of domains. Another</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ar</head><p>Ar salient advantage of BAM dataset is the uniform distribution of samples across different domains; which is of significant importance to our approach since it enables the framework to create a dynamic uniform environment across arbitrary domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>In this section, we present an extensive experimental analysis of our framework. First, we compare our approach with state-of-the-art methods on the aforementioned benchmarks. Second, we conduct an extensive ablation study to demonstrate the impact of our framework on leaning a robust feature representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Source Domain Generalization</head><p>We start our experiments by comparing our framework with state-of-theart methods on PACS dataset <ref type="bibr" target="#b29">[28]</ref>. The convolutional architecture of our approach is the same as the main structure of Alexnet or Resnet. As discussed in section 3.3, our framework creates a dynamic environment for the model to ex-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>SVHN MNIST MNIST SVHN DANN <ref type="bibr" target="#b9">[11]</ref> 73.9 35.7 ADDA <ref type="bibr" target="#b52">[50]</ref> 76.0 -DRCN <ref type="bibr" target="#b13">[14]</ref> 82.0 40.1 ATT <ref type="bibr" target="#b49">[47]</ref> 86.2 52.8 ADA <ref type="bibr" target="#b17">[17]</ref> 97.6 -AutoDIAL <ref type="bibr">[3]</ref> 89.12 10.78 SBADA-GAN <ref type="bibr" target="#b48">[46]</ref> 76.1 61.1 GAM <ref type="bibr" target="#b21">[21]</ref> 74.6 -MEGA <ref type="bibr" target="#b37">[36]</ref> 95.2 -DWT <ref type="bibr" target="#b47">[45]</ref> 97.7</p><p>28.9 Jigen <ref type="bibr" target="#b1">[4]</ref> 57.6 33.8 Ours 71.7 53.7 plore arbitrary domains autonomously by shifting each pile of jigsaw puzzle to an arbitrary domain of BAM dataset. <ref type="table">Table 1</ref> demonstrates the performance of our method as well as a comparison with state-of-the-art methods on this dataset. In this experiment, the ? parameter value, exploration rate, is of 0.5(50%) and the ? parameter, domain shift magnitude, is chosen between 0.5 and 0.75 randomly. As one can see, our framework enforces the self-supervision signals to focus on the general shape of objects rather than local textures. The significance of enhancement in learned feature representation is salient for challenging domains such as sketches or art paint. <ref type="table">Table 3</ref> demonstrates the performance of our framework on VLCS <ref type="bibr" target="#b51">[49]</ref> dataset using backbone architecture of Resnet-18, same as <ref type="bibr" target="#b1">[4]</ref>. We used the same setting as the previous experiment. From the table, it can be observed that our method outperforms the existing methods on VLCS <ref type="bibr" target="#b51">[49]</ref> dataset with a considerable margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Single-Source Domain Generalization</head><p>We compare the performance of our framework with several methods on single-source domain generalization. We used <ref type="bibr" target="#b47">[45]</ref> as reference for the performance of other methods. However, for Jigen <ref type="bibr" target="#b1">[4]</ref>, we used their public source code. <ref type="table">Table 2</ref> demonstrates the prominence of our method on Office-Home <ref type="bibr" target="#b53">[51]</ref> dataset. As one can see, our method outperforms other methods in all domains by a considerable margin. Also, table 4 presents a comparison on MNIST ? SVHN generalization problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>In this section, we perform thorough ablation experiments to investigate the effect of different modules and parameters in our framework. These experiments demonstrate the contributions of different modules and provide more insight into our approach. All experiments of this section are conducted on PACS dataset <ref type="bibr" target="#b29">[28]</ref> with art painting as the target domain and Alexnet architecture is used as the backbone network.</p><p>Activation Visualization In this experiment, we visualize feature representation at the final layer of the convolutional network(Alexnet). As can be seen in figure 2, deep network alone barely captures any useful classification patterns relevant to the target domain. Though vanilla selfsupervision signals can help improve learned feature representation, they are biased to superficial statistics of data. Since our framework tackles the unfavorable biases of selfsupervised methods toward textures and local features, it helps the model learn shape biased representations which are robust across domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exploration vs Exploitation Analysis</head><p>In this experiment, we perform ablation study for investigating the effect of exploration vs. exploitation trade-off parameters, namely ? and ?. The ? parameter defines exploration rate across arbitrary domains. With a high value of ?, the agent(model) is mostly exploring random domains rather than exploiting static source domains. <ref type="figure" target="#fig_1">Figure 3</ref> illustrates the impact of ? parameter on the learning process of the network. As one can observe, with high values of ? (0.75 and above), the accuracy on test-set fluctuates considerably, which hinders the convergence process of the network. Conversely, low values of ? (0.25 and below) do not allow the agent to sufficiently explore new domains. As a result, the shape bias property of the model is not improved enough, and the learned feature representation is not robust against domain shifts.</p><p>The second and equally significant parameter is ?, which defines the magnitude of domain translations during the exploration phase. Same as ?, high values of ? results in sub-stantial fluctuations in test-loss during the training process of the network. On the other hand, low values of ? do not allow the model to shift toward arbitrary domains sufficiently. <ref type="figure" target="#fig_2">Figure 4</ref> clearly demonstrates the effect of ? parameter. For all experiments in section 4.2, we used ? value of 0.5 and ? was chosen randomly between 0.75 and 1.0. Another satisfactory approach is to initialize ? and ? parameters with high values and gradually diminish them for better convergence.</p><p>Attention Visualization In this experiment, we visualize some attention maps for the network trained by our method and JiGen <ref type="bibr" target="#b1">[4]</ref> to provide more insight into our approach. These attention maps are computed based on the magnitude of activations at each spatial cell of a convolutional layer and essentially reflect where the network puts most of its focus in order to classify an input image. <ref type="figure">Figure 5</ref> provides a comparison between attention maps generated by our framework and JiGen <ref type="bibr" target="#b1">[4]</ref>. As discussed in section 3.3, our framework enforces the network to focus on the general shape of objects rather than superficial statistics of context e.g., textures. <ref type="figure">Figure 5</ref> clearly demonstrates the prominence of shape bias and domain-invariance properties of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Works</head><p>In this paper, we studied unfavorable biases of unsupervised representation learning and introduced a learning paradigm to alleviate this problem. Our framework achieves this goal by integrating domain diversification and selfsupervision signals. Domain diversification module creates a dynamic environment across arbitrary domains for the agent to explore autonomously. Also, our framework provides an exploration vs. exploitation trade-off setting. Finally, we formulized our framework for domain generalization problem and conducted extensive experiments and analysis to demonstrate the effectiveness of our method.</p><p>There are many opportunities for contributing to this research thread. The key idea behind this paper was to increase the integration between agent and environment by creating a dynamic environment across arbitrary domains so that the agent can explore this environment autonomously rather than just exploiting a static source dataset. However, the exploration phase can be improved drastically using Meta-Learning or Reinforcement Learning methods to robustify learned feature representations against domain shifts.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2</head><label>2</label><figDesc>. t-SNE visualizations of the feature representations for art painting as target domain of PACS dataset. Obviously, (a) supervised learning barely captures any robust classification patterns. (b) Though self-supervised learning(JiGen[4]) improves learned feature representation, it is not sufficiently robust against domain shifts. However, (c) our method enforces the model to learn shape biased and domain-invariant representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Analysis of the behavior of our framework with different ? values on PACS dataset<ref type="bibr" target="#b29">[28]</ref> with art painting as target domain. The ? value is equal to 0.75 and Alexnet is used as the backbone network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Analysis of the behavior of our framework with different ? values on PACS dataset<ref type="bibr" target="#b29">[28]</ref> with art painting as target domain. The ? value is equal to 0.75 and Alexnet is used as the backbone network.works. InProceedings of the IEEE conference on computer vision and pattern recognition, pages 3722-3731, 2017. 1 [2] Wieland Brendel and Matthias Bethge. Approximating cnns with bag-of-local-features models works surprisingly well on imagenet. arXiv preprint arXiv:1904.00760, 2019. 2 [3] Fabio Maria Cariucci, Lorenzo Porzi, Barbara Caputo, Elisa Ricci, and Samuel Rota Bul?. Autodial: Automatic domain alignment layers. In 2017 IEEE International Conference on Computer Vision (ICCV), pages 5077-5085. IEEE, 2017. 1,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>50.0 58.0 37.4 41.9 46.2 38.5 31.2 60.4 53.9 41.2 59.9 46.1 DAN[32] 43.6 57.0 67.9 45.8 56.5 60.4 44.0 43.6 67.7 63.1 51.5 74.3 56.3 DANN[11] 45.6 59.3 70.1 47.0 58.5 60.9 46.1 43.7 68.5 63.2 51.8 76.8 57.Table 2. Single-source domain generalization results(%) on Office-Home dataset[51] with Resnet-50 as base network and comparison with state-of-the-art methods. Top row of each column title indicates the source domain and the bottom row represents the target domain.</figDesc><table><row><cell></cell><cell></cell><cell>Cl</cell><cell>Pr</cell><cell>Ar Rw</cell><cell>Cl Ar</cell><cell>Cl Pr</cell><cell>Cl Rw</cell><cell>Pr Ar</cell><cell>Pr Cl</cell><cell>Pr Rw</cell><cell>Rw Ar</cell><cell>Rw Cl</cell><cell>Rw Avg. Pr</cell></row><row><cell>ResNet-50</cell><cell></cell><cell cols="11">34.9 6</cell></row><row><cell>JAN[34]</cell><cell></cell><cell cols="11">45.9 61.2 6.9 50.4 59.7 61.0 45.8 43.4 70.3 63.9 52.4 76.8 58.3</cell></row><row><cell cols="13">CDAN-RM[33] 49.2 64.8 72.9 53.8 63.9 62.9 49.8 48.8 71.5 65.8 56.4 79.2 61.6</cell></row><row><cell cols="2">CDAN-M[33]</cell><cell cols="11">50.6 65.9 73.4 55.7 62.7 64.2 51.8 49.1 74.5 68.2 56.9 80.7 62.8</cell></row><row><cell>SE[10]</cell><cell></cell><cell cols="11">48.8 61.8 72.8 54.1 63.2 65.1 50.6 49.2 72.3 66.1 55.9 78.7 61.5</cell></row><row><cell>DWT[45]</cell><cell></cell><cell cols="11">50.8 72.0 75.8 58.9 65.6 60.2 57.2 49.5 78.3 70.1 55.3 78.2 64.3</cell></row><row><cell cols="13">DWT-MEC[45] 54.7 72.3 77.2 56.9 68.5 69.8 54.8 47.9 78.1 68.6 54.9 81.2 65.4</cell></row><row><cell>Jigen[4]</cell><cell></cell><cell cols="11">48.6 66.6 77.4 53.9 60.1 64.9 51.7 47.7 78.1 70.7 51.4 79.3 62.5</cell></row><row><cell>Ours</cell><cell></cell><cell cols="11">56.6 73.5 80.7 61.7 70.2 74.38 60.1 52.7 81.1 73.2 59.7 81.9 68.8</cell></row><row><cell>Methods</cell><cell cols="6">Caltech Labelme Pascal Sun Avg.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DeepC[31]</cell><cell></cell><cell>87.47</cell><cell>62.06</cell><cell cols="3">63.97 61.51 68.89</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CIDDG[31]</cell><cell></cell><cell>88.83</cell><cell>63.06</cell><cell cols="3">64.38 62.10 69.59</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CCSA[37]</cell><cell></cell><cell>92.30</cell><cell>62.10</cell><cell cols="3">67.10 59.10 70.15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SLRC[7]</cell><cell></cell><cell>92.76</cell><cell>62.34</cell><cell cols="3">65.25 63.54 70.15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TF[28]</cell><cell></cell><cell>93.63</cell><cell>63.49</cell><cell cols="3">69.99 61.32 72.11</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">MMD-AAE[30] 94.40</cell><cell>62.60</cell><cell cols="3">67.70 64.40 72.28</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>D-SAM[9]</cell><cell></cell><cell>91.75</cell><cell>56.95</cell><cell cols="3">58.59 60.84 67.03</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>JiGen[4]</cell><cell></cell><cell>96.93</cell><cell>60.90</cell><cell cols="3">70.62 64.30 73.19</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ours</cell><cell></cell><cell>98.11</cell><cell>63.61</cell><cell cols="3">74.33 67.11 75.79</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Table 3. Multi-source domain generalization results(%) on VLCS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">dataset[49] with Resnet-18 as base network and comparison with</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">state-of-the-art methods. Each column title represents the name of</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>target domain.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .</head><label>4</label><figDesc>Single-source domain generalization results(%) on MNIST and SVHN datasets with LeNet as base network. Top row of each column title indicates the source domain and the bottom row represents the target domain.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Unsupervised pixellevel domain adaptation with generative adversarial net-2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fabio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio D&amp;apos;</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="132" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Domain adaptation in computer vision applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriela</forename><surname>Csurka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep domain generalization with structured low-rank constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="304" to="313" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Domain generalization with domain-specific aggregation modules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Dinnocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<biblScope unit="page" from="187" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Self-ensembling for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Fisher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05208</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Felix A Wichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brendel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.12231</idno>
		<title level="m">Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generalisation in humans and deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Carlos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Temme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Heiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Sch?tt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wichmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Attention maps generated by our framework(third row) and JiGen[4](second row) on PACS dataset[28] using Alexnet as backbone network. As one can observe, our framework enforces the model to focus on the general shape of objects</title>
		<imprint/>
	</monogr>
	<note>Figure 5. As a result, the value of attention maps on the background and context of the image has diminished</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep reconstructionclassification networks for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<biblScope unit="page">597</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07728</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Associative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Haeusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Frerix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Mordvintsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2765" to="2773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Using self-supervised learning can improve model robustness and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.12340</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.03213</idno>
		<title level="m">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Assessing shape bias property of convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baicen</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayoore</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radha</forename><surname>Poovendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1923" to="1931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Domain transfer through deep activation matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoshuo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="590" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Self-supervised visual feature learning with deep neural networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longlong</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingli</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.06162</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning image representations by completing damaged jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyeon</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donggeun</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">In</forename><forename type="middle">So</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<biblScope unit="page" from="793" to="802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to discover cross-domain relations with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taeksoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moonsu</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunsoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1857" to="1865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Photorealistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep domain generalization via conditional invariant adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1502.02791</idno>
		<title level="m">Learning transferable features with deep adaptation networks</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Conditional adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1640" to="1650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep transfer learning with joint adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Boosting domain adaptation by discovering latent domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3771" to="3780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Minimal-entropy correlation alignment for unsupervised deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Morerio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacopo</forename><surname>Cavazza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Murino</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.10288</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5715" to="5725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Boosting self-supervised learning via knowledge transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananth</forename><surname>Vinjimoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Pirsiavash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9359" to="9367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Cross-domain selfsupervised multi-task feature learning using synthetic imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongzheng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Jae</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="762" to="771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Cognitive psychology for deep neural networks: A shape bias case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><forename type="middle">M</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation using feature-whitening and consensus loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhankar</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksandr</forename><surname>Siarohin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enver</forename><surname>Sangineto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">From source to target and back: symmetric bi-directional adaptive gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="8099" to="8108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Asymmetric tri-training for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniaki</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Unbiased look at dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7167" to="7176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hemanth</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shayok</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sethuraman</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep visual domain adaptation: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihong</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">312</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="135" to="153" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Bam! the behance artistic media dataset for recognition beyond photography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Wilber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Collomosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycleconsistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
