<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Modal Deep Clustering: Unsupervised Partitioning of Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Shiran</surname></persName>
							<email>guy.shiran@mail.huji.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Hebrew University of Jerusalem Jerusalem</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphna</forename><surname>Weinshall</surname></persName>
							<email>daphna@cs.huji.ac.il</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering Hebrew</orgName>
								<orgName type="institution">University of Jerusalem Jerusalem</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Modal Deep Clustering: Unsupervised Partitioning of Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T07:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The clustering of unlabeled raw images is a daunting task, which has recently been approached with some success by deep learning methods. Here we propose an unsupervised clustering framework, which learns a deep neural network in an end-to-end fashion, providing direct cluster assignments of images without additional processing. Multi-Modal Deep Clustering (MMDC), trains a deep network to align its image embeddings with target points sampled from a Gaussian Mixture Model distribution. The cluster assignments are then determined by mixture component association of image embeddings. Simultaneously, the same deep network is trained to solve an additional self-supervised task of predicting image rotations. This pushes the network to learn more meaningful image representations that facilitate a better clustering. Experimental results show that MMDC achieves or exceeds state-of-the-art performance on six challenging benchmarks. On natural image datasets we improve on previous results with significant margins of up to 20% absolute accuracy points, yielding an accuracy of 82% on CIFAR-10, 45% on CIFAR-100 and 69% on STL</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Clustering involves the organization of data in an unsupervised manner, based on the distribution of datapoints and the distances between them. Since these properties are closely tied to the representation of the data, the problems of clustering and data representation are firmly connected and are therefore sometimes solved jointly. In accordance, in this work we start from a recent method for the unsupervised computation of effective data representation (or features discovery), and develop a clustering method whose results significantly improve the state of the art in the clustering of natural images. The method is illustrated in <ref type="figure" target="#fig_0">Fig 1.</ref> The task of unsupervised image clustering is challenging and interesting, as the algorithm needs to discover patterns in highly entangled data, and produce separated groups without explicitly specifying the grouping features. A large body of work has been devoted to the problem of clustering <ref type="bibr" target="#b19">[20]</ref>, see Section II for a brief review of some recent related work. In recent years, with the emergence of deep learning as the method of choice in visual object recognition and image classification, emphasis has shifted to the computation of effective representations that will support successful clustering <ref type="bibr" target="#b29">[30]</ref>. Vice versa, unsupervised clustering loss has been used to drive the computation of image representation and the discovery of enhanced image features by making it possible to use unsupervised data in the training of deep networks, which traditionally require massive amounts of labeled data.</p><p>When learning feature representation from unsupervised data by minimizing a clustering-based loss function, one danger is cluster collapse -the representation may collapse to the trivial solution of a single cluster. In <ref type="bibr" target="#b2">[3]</ref>, a similar problem of representation collapse is managed by mapping the network's representation to a fixed set of randomly chosen points in some target features space. Here we borrow this mapping idea, and incorporate it into a clustering algorithm.</p><p>More specifically, we first sample a fixed set of points in some target space. Since our method is designed to partition the data into k clusters, the target points are chosen from a matched density function -Gaussian Mixture Model (GMM) with k components. Our model trains a randomly initialized neural network to align its image embeddings with the sampled target points, directly inducing a partition that is based on the mixture components. This is done by simultaneously learning a one-to-one mapping between the output of the network and the target points, and updating the networks parameters to best fit images with their target points as assigned by the mapping.</p><p>In the absence of ground truth, the proposed approach is prone to instability as target points are continuously reassigned between images, creating a non-stationary online learning environment. Such instability is often linked with unsupervised learning tasks. To alleviate this problem, unsupervised tasks such as representation learning may be combined with selfsupervision tasks to achieve better results <ref type="bibr" target="#b9">[10]</ref>. Here we adopt the approach taken by <ref type="bibr" target="#b5">[6]</ref> to deal with the notorious instability of training generative adversarial networks. Thus the model is jointly trained on the main clustering task and on a selfsupervised auxiliary task as defined in RotNet <ref type="bibr" target="#b13">[14]</ref>, where all images are subjected to 4 rotation angles. In this auxiliary task the network is trained to recognize the 2D rotation of each rotated image.</p><p>For computation engine, our method uses off the shelf Con-vNets and standard SGD training with mini-batch sampling in an end-to-end fashion. It is therefore scalable to large datasets. We evaluate our method on several standard benchmarks in image clustering, which is the goal of our method, significantly exceeding the state of the art on the 5 natural image datasets.</p><p>The rest of the paper is organized as follows: In Section II we briefly review recent related work. In Section III we describe our method in detail and elaborate on its various ingredients. Experimental results are reported in Section IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Data clustering. The objective of data clustering is to partition data points into groups such that points in each group are more similar to each other than to data points in the other groups. Traditionally, clustering methods have been divided into density-based methods <ref type="bibr" target="#b23">[24]</ref>, partition-based methods <ref type="bibr" target="#b11">[12]</ref>, and hierarchical methods <ref type="bibr" target="#b10">[11]</ref>. Partition-based methods, such as the popular k-means <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b31">[32]</ref>, minimize a given clustering criterion by iteratively relocating data points between clusters until a (locally) optimal partition is attained. Density-based methods define clusters as areas with high density of points, separated by areas with low density of points <ref type="bibr" target="#b36">[37]</ref>. Hierarchical based methods build a hierarchy of clusters in a top-to-bottom <ref type="bibr" target="#b33">[34]</ref> or bottom-to-top <ref type="bibr" target="#b15">[16]</ref> manner to determine clustering.</p><p>Representation Learning. Na?vely attempting to cluster images with traditional approaches does not produce a pleasing partitions of the images, as they work on the raw representations of the images in pixel space, whereas semantically similar images are not necessarily similar in the high-dimensional pixel space in which the images reside. In recent years learning useful image representations in an unsupervised manner has been dominated by deep-learning-based approaches. Autoencoders (AEs) <ref type="bibr" target="#b1">[2]</ref> encode images with a deep network and are trained by reconstructing the image using a decoder network. These include several variations such as sparse AEs, denoising AEs <ref type="bibr" target="#b35">[36]</ref>, and more <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b40">[41]</ref>. Generative models such as Generative Adversarial Networks (GAN) <ref type="bibr" target="#b14">[15]</ref> and variational autoencoders (VAE) <ref type="bibr" target="#b21">[22]</ref> learn representations as a byproduct of learning to generate images. Tightly connected to our work, Noise-As-Targets (NAT) <ref type="bibr" target="#b2">[3]</ref> and DeepCluster <ref type="bibr" target="#b3">[4]</ref> adopt a training strategy of iteratively reassigning psuedo-labels to points while training the network to fit them (see Section III).</p><p>Self-supervised learning. A family of unsupervised learning algorithms that gained popularity in recent years are selfsupervised methods. They learn representations by training a deep network to solve a pretext task, where labels can be produced directly from the data. Such tasks can be jigsaw puzzle solving <ref type="bibr" target="#b30">[31]</ref>, predicting the relative position of patches in an image <ref type="bibr" target="#b8">[9]</ref>, generating image regions conditioned on their surroundings <ref type="bibr" target="#b32">[33]</ref>, or more recently predicting image rotations (RotNet) <ref type="bibr" target="#b13">[14]</ref>. In self-supervised GANs <ref type="bibr" target="#b5">[6]</ref>, predicting image rotations is used as an auxiliary task to stabilize and improve training, by enhancing the discriminator's representation capabilities. Here we adopt this approach as well, as elaborated later on.</p><p>Deep clustering. The dominant and most successful approach to clustering of images in recent years has been to incorporate the tasks of representation learning and clustering into a single framework. Prominent works in the past years have been Joint Unsupervised Learning (JULE) <ref type="bibr" target="#b39">[40]</ref>, where the authors adopt an agglomerative clustering approach by iteratively merging clusters of deep representations and updating the networks parameters. Deep Adaptive Clustering (DAC) <ref type="bibr" target="#b4">[5]</ref> recasts the clustering problem into a binary pairwiseclassification framework, where cosine distances between image features of image pairs are used as a similarity measure to decide if they belong to the same cluster. Associative Deep Clustering (ADC) <ref type="bibr" target="#b16">[17]</ref> jointly learns network parameters and embedding centroids with an association loss in order to estimate cluster membership. More recently, Invariant Information Clustering (IIC) <ref type="bibr" target="#b20">[21]</ref> adopts an approach that achieves clustering based on maximizing the mutual information between two sets: deep embeddings of images, and instances of the images that underwent random image transformations while keeping the image semantic meaning intact. IIC leverages auxiliary over-clustering to increase expressivity in the learned feature representation, improving the representation capabilities of its network. This tactic bears resemblance to our incorporation of rotation prediction as an auxiliary task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHOD</head><p>Our goal is to partition a set of images into k clusters, which reflect internal structure in the data. <ref type="figure">Fig. 2</ref> shows an overview of the proposed approach. The algorithm alternates between solving the main unsupervised clustering task, and an auxiliary self-supervised task that helps the training process. The ingredients of the method are described next. The full method is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Unsupervised learning</head><p>The starting point for this work is an unsupervised learning framework for learning image representation from unlabeled Our approach takes a set of images and solves two tasks in alternating epochs. In the primary task, a CNN is trained to produce output which matches some predefined set of target points sampled from a Gaussian mixture model, and optimally aligned with the training set. In the secondary task, given a rotated image, the same CNN is trained to predict the rotation angle of the image.</p><p>data. The method, Noise as Targets <ref type="bibr" target="#b2">[3]</ref>, learns useful representations of images by training a deep network to align its images' embeddings with a fixed set of target points. The target points are uniformly scattered on the d-dimensional unit sphere.</p><p>More specifically, let X = {x i } n i=1 denote a set of images, and f ? : X ? Z the parameterized deep network we wish to train. The output of f ? is normalized to have 2 norm of 1, entailing that Z is the d-dimensional unit sphere. NAT starts by uniformly sampling n targets on this unit sphere. Let {t i } n i=1 denote the set of target points, which remain fixed throughout the training. Each image x i is assigned a unique target y i through a permutation P : [n] ? [n]. The optimization objective is formulated as</p><formula xml:id="formula_0">min ?,P 1 n i (f ? (x i ), y i ) y i = t P (i)<label>(1)</label></formula><p>where is the Euclidean distance. This optimization problem is solved in a stochastic manner, by iteratively solving it over randomly sampled mini-batches. Given a mini-batch of images X b , the current representation vectors f ? (X b ) are first computed. Subsequently, Equation <ref type="formula" target="#formula_0">(1)</ref> is optimized for P over the points in mini-batch X b using the Hungarian method <ref type="bibr" target="#b25">[26]</ref>, which reassigns the currently assigned targets of the mini-batch to minimize the Euclidean distance ( 2 ) between images and their assigned target points. Finally, the gradients of f ? on X b with respect to ? are computed, and an SGD step is executed.</p><p>Intuitively, NAT permutes the assignment of image representation vectors to target points delivered by f ? , so that nearby embedding vectors are mapped to nearby target vectors, and then updates ? accordingly. This process leads to the grouping of semantically similar images in target space, and to effective representations that perform well in downstream computer vision classification and detection tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multi-modal distribution of target points</head><p>The uniform distribution of target points on the unit sphere, as described above, is not well suited for unsupervised clustering, since it is likely to blur the dividing lines between clusters rather than sharpen them. Instead, multi-modal distribution seems like a natural choice for the objective of clustering, as it directly produces separated groups in target space.</p><p>In this work, we propose to use the mixture of Gaussians distribution, projected to the unit sphere, for the sampling of target points. Formally, this implies:</p><formula xml:id="formula_1">p(u) = K k=1 ? k ? p k (u) u ? R d p(t i ) = u u 2 =ti p(u)du t i ? Z<label>(2)</label></formula><p>where K denotes the number of Gaussians in the mixture, d the dimension of the embedding space, ? k=1..K a categorical random variable, and p k (u) the multivariate normal distribution N (? k , ? k ), parameterized by mean vector ? k and covariance matrix ? k . In the absence of prior knowledge we assume that the mixture components are equally likely,</p><formula xml:id="formula_2">namely ? k = 1 K ?k ? [K]</formula><p>. Finally, since the target points are constrained to lie on the unit sphere, we project the sample in R d to the unit sphere by t i = u u 2 . We define the cluster assignment c i of image x i as follows</p><formula xml:id="formula_3">c i = arg min k f ? (x i ) ? ? k 2<label>(3)</label></formula><p>Algorithm 1: Input:</p><formula xml:id="formula_4">{x i } n i=1</formula><p>-images f ? -ConvNet with two heads k -number of clusters epochs -number of epochs to train iters -number of iterations in an epoch ? -variance of normal distribution d -dimension of embedding space ? c , ? r -learning rates g -random image transformation r -number of instances of g in a batch Init: P ? initialize with random assignments ? ? initialize with random weights T ? initialize empty list</p><formula xml:id="formula_5">for i = 1...n do sample c ? Categ( 1 K , ..., 1 K ) sample u ? N (? c , ? ? I d?d ) T [i] ? t i = u u end for for e = 1...epochs do for i = 1...iters do sample batch X b and assigned targets T b compute f ? (X b ) update P by minimizing Equation (1) w.r.t P compute ? ? L c (?) of Equation (1) for g(X b ) update ? ? ? ? ? c ? ? L c (?) end for for i = 1...iters do sample batch X b rotate X b ?r ? {0?, 90?, 180?, 270?} compute ? ? L r (?) // L r is cross-entropy loss update ? ? ? ? ? r ? ? L r (?) end for end for</formula><p>Note that if the final network f ? fits that target points exactly, namely f ? (x i ) = y i , and if ? k are the same ?k, then with high probability c i is the index of the mixture component from which target point y i has been sampled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Image Transformations</head><p>Data augmentation is a useful and common technique to improve performance of machine learning algorithms. Usually, random image transformations such as cropping, flipping, rotation, scaling and photometric transformations are applied to images in order to expand the dataset with new and unique images. In our task of unsupervised clustering, these random transformations are essential, because they provide several instances of the same image that appear different but share the same semantic meaning as they contain the same object. Let g denote a random image transformation. In our method, we use the center crop of an image when minimizing Equation <ref type="formula" target="#formula_0">(1)</ref> w.r.t P . When minimizing the same equation w.r.t ?, we first apply g to the image. Why is this algorithmic ingredient useful? When training the ConvNet, it must find common patterns between the original images and transformed images when fitting them to the same target. These common patterns are likely to appear in other images in the dataset belonging to the same class. This pushes the network to map images that contain the same objects closer to each other, in a similar manner to the beneficial effect of self-supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Auxiliary task</head><p>While optimizing the clustering objective (1), the ConvNet model simultaneously learns image representation and partitions the images. The success of unsupervised clustering is highly correlated with the quality of the learnt representation. It has been repeatedly shown that self-supervision methods can significantly improve the quality of representations in an unsupervised learning scenario. To benefit from this idea, we employ RotNet <ref type="bibr" target="#b13">[14]</ref>, which is a self-supervised learning algorithm that learns image features by training a ConvNet to predict image rotations. Specifically, images are rotated by r degrees where r ? {0?, 90?, 180?, 270?}, and the model is subsequently trained to predict their rotation by optimizing the cross-entropy loss. RotNet produces competitive performance in representation learning benchmarks, and has been shown to benefit training in other tasks, when incorporated into a model as an auxiliary task <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b27">[28]</ref>. We incorporate RotNet into our method, modifying the ConvNet training procedure to alternate between optimizing the main clustering task and this secondary auxiliary task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Refinement Stage</head><p>As we have no prior knowledge regarding the size of the clusters, we begin by assuming that clusters' sizes are equal. When this assumption cannot be justified, we propose to augment the algorithm with an additional step, performed after the main training is concluded. In this step the assumption is relaxed, while target points are iteratively reassigned based on the outcome of k-means applied to f ? (x 1 ), ..., f ? (x n ), and assigning image x i to target ? j with label j ? [K] derived from the outcome of k-means. This ingredient is similar to DeepCluster <ref type="bibr" target="#b3">[4]</ref>, proposed by Caron et al. as an approach for representation learning, where they perform the clustering on the latent vectors of the model and not the final output layer. A possible alternative method may start with this stage and discard the first one altogether, as this approach makes no assumption on the size of the clusters. However, we found that starting off with reassigning labels based on k-means is not competitive and produces less accurate clusters. For example, training on MNIST results in low accuracy of 81% (?2.67).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>We tested our method on several image datasets that are commonly used as benchmark for clustering, see results in <ref type="table" target="#tab_0">Table I</ref>. We compare ourselves to state-of-the-art methods such as DEC <ref type="bibr" target="#b38">[39]</ref>, JULE <ref type="bibr" target="#b39">[40]</ref>, DAC <ref type="bibr" target="#b4">[5]</ref>, IIC <ref type="bibr" target="#b20">[21]</ref> and DCCM <ref type="bibr" target="#b37">[38]</ref>.  In almost all cases our method improves on previous results significantly <ref type="bibr" target="#b0">1</ref> . Examples of clustering results on the STL-10 dataset of natural images are shown in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>In the rest of this section we specify the implementation details of our method, and analyze the results. Subsequently, we report the results of an ablation study evaluating the various ingredients of the algorithm, which demonstrate how they contribute to its success. Our code is available online 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation details and evaluation scores</head><p>Datasets. Six datasets are used in our empirical study: MNIST <ref type="bibr" target="#b26">[27]</ref>, CIFAR-10 <ref type="bibr" target="#b24">[25]</ref>, the 20 superclasses of CIFAR-100 <ref type="bibr" target="#b24">[25]</ref>, STL-10 <ref type="bibr" target="#b6">[7]</ref>, ImageNet-10 (a subset of ImageNet <ref type="bibr" target="#b7">[8]</ref>) and Tiny-ImageNet <ref type="bibr" target="#b7">[8]</ref>, <ref type="table" target="#tab_0">see Table II</ref>. We are most interested <ref type="bibr" target="#b0">1</ref> Note that with STL-10, IIC reports an accuracy of 0.596 when using the much larger unlabeled data segment that includes distractor classes.</p><p>2 https://github.com/guysrn/mmdc in the datasets that consist of natural images. These datasets are commonly used to evaluate clustering methods. Architectures. For the MNIST experiments we use a small VGG model <ref type="bibr" target="#b34">[35]</ref> with batch normalization <ref type="bibr" target="#b18">[19]</ref>. Each block in this neural network consists of one convolution layer, followed by a batch normalization layer and ReLU activation function, and ends with a max pooling layer. Our model has four blocks. For all other experiments we use a ResNet model <ref type="bibr" target="#b17">[18]</ref> with 18 layers. These base models are followed by a linear prediction layer, that outputs the cluster assignments. When trained on the auxiliary task, the base model is also followed by another linear head, which predicts the image rotation.</p><p>Training details. The network is trained with stochastic gradient descent with learning rate 0.05 and momentum of 0.9. We apply weight decay of 0.0001 for CIFAR-100 and Tiny-ImageNet, and 0.0005 for all other datasets. We use batch size 128 and perform random image augmentations which include cropping, flipping and color jitter. When training on the auxiliary rotation task, we rotate each image to all four orientations, resulting in an effective batch size of 512. We train the network for 400 epochs and decay learning rate by a factor of 5 after 350 epochs. For MNIST we train for 50 epochs and decay learning rate by a factor of 10 after 40 epochs. Training on CIFAR-10 takes 10.5 hours on a single GTX-1080 GPU.</p><p>Mixture of Gaussians. We examined several initialization heuristics to determine the Gaussian means {? k } in the GMM distribution defined in (2) and the covariance matrices {? k }. A comparison of different initialization schemes is provided in <ref type="figure" target="#fig_3">Figure 4</ref>, where all vectors lie on the d-dimensional unit sphere. Gaussian means {? k } are sampled from a multi-variate uniform distribution within the range [?0.1, 0.1] and projected onto the unit sphere. We always set ? k = ? ? I K?K ?k ? [K]. We compare different values for the dimension d and the variance parameter ?. Smaller variance usually performs best with the added benefit of similar performance for different choices of dimension d. We therefore opted to use K different one-hot vectors in R K for {? k } with variance ? = 0, as this achieved good performance while reducing the number of free hyperparameters.</p><p>Evaluation scores. To evaluate clustering performance we adopt two commonly used scores: Normalized Mutual Information (NMI), and Clustering Accuracy (ACC). Clustering accuracy measures the accuracy of the hard-assignment to clusters, with respect to the best permutation of the dataset's ground-truth labels. Normalized Mutual Information measures the mutual information between the ground-truth labels and the predicted labels based on the clustering method. The range of both scores is [0, 1], where a larger value indicates more precise clustering results. We use centrally cropped images for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Empirical Analysis</head><p>The results of our method when applied to the six image datasets are reported in <ref type="table" target="#tab_0">Table I</ref>. Clearly, our clustering algorithm is able to separate unlabeled images into distinct groups of semantically similar images with high accuracy, improving the state-of-the-art in the five datasets of natural images. Compared to previous state-of-the-art, we improve clustering accuracy on CIFAR-10 by 20%, CIFAR-100 by 12%, STL-10 by 20%, ImageNet-10 by 10% and Tiny-ImageNet by 1%.</p><p>In the results reported in <ref type="table" target="#tab_0">Table I</ref>, the refinement stage was invoked only when using the MNIST dataset. A more complete ablation study of the refinement stage is reported in Table V. The auxiliary task of RotNet, which was shown to be beneficial when learning natural images, was used to enhance the clustering of all the datasets except MNIST. For reference, we used the same image augmentations as in <ref type="bibr" target="#b20">[21]</ref>, which uses a larger ResNet-34 as the backbone for the model. Benefits of auxiliary task. Applying the Sobel filter to an image emphasizes edges and discards colors. This preprocessing is commonly done in the context of unsupervised representation learning and clustering algorithms, presumably to avoid sub-optimal solutions based on trivial cues such as color <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b20">[21]</ref>. We observed an interesting interaction between Sobel filtering and training with the auxiliary task of predicting image rotations. Without the auxiliary task, Sobel filtering indeed improves clustering performance as seen in <ref type="table" target="#tab_0">Table III.</ref> In contrast, when training with an auxiliary task and adding the rotation loss, pre-processing with the Sobel filter degrades the algorithms performance. Furthermore, without the rotation loss the learning rate has to be reduced to 0.01 for training to converge. The reason may be that trivial cues such as color are not beneficial for the task of predicting image rotations, and therefore the auxiliary task forces the ConvNet to learn features that focus on the object in the image. Once the focus is on the object, additional cues such as color can be beneficial for clustering, and as a result pre-processing with the Sobel filter is detrimental to the algorithm's performance.</p><p>Feature Evaluation. Our algorithm borrows some of its ingredients from NAT and RotNet. However, while these two methods address representation learning, the final goal of our method is clustering. Nevertheless, we compare our method to NAT and RotNet in two ways. First, we examine the clustering capabilities of the methods by applying k-means to the penultimate layer of the networks. Second, we evaluate the learnt features by training a linear classifier with the image labels on top of the frozen features of the networks. We use the same architecture and image transformations as our model for both methods. We follow the training procedure from <ref type="bibr" target="#b22">[23]</ref> for training RotNet and <ref type="bibr" target="#b2">[3]</ref> for training NAT.</p><p>More specifically, we train the linear classifier with stochastic gradient descent with learning rate 0.1, momentum of 0.9, weight decay of 0.00001, batch size of 128, cosine annealing for learning rate scheduling, and 100 training epochs. Results with CIFAR-10 and CIFAR-100 are reported in <ref type="table" target="#tab_0">Table IV</ref>. As shown our method outperforms the others in all cases except one, where NAT+RotNet performs better when clustering CIFAR-10 image features. As a reference for the linear classifier performance, we also evaluate a model pretrained with ImageNet (first row in <ref type="table" target="#tab_0">Table IV</ref>). Note that we use the same image augmentations as for training the unsupervised methods, including 20?20 cropping, which may degrade performance for this model.</p><p>Refinement stage. We compare clustering performance with and without the proposed refinement stage in <ref type="table">Table V.</ref> MNIST is the only dataset with class imbalance, as its smallest class has 6313 samples while its largest has 7877. Reassuringly, the refinement stage helps the algorithm achieve near perfect clustering with accuracy of 99.0%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. SUMMARY</head><p>For the task of unsupervised semantic image clustering, we presented an end-to-end deep clustering framework, that trains a ConvNet to align image embeddings with targets sampled from a Gaussian Mixture Model by solving a linear assignment problem using the Hungarian algorithm. To achieve effective training, we incorporated an additional auxiliary task -the prediction of image rotation. Our ablation study shows that the contribution of this component is essential for the success of the method. Even though the proposed method is quite simple, it yields a significant improvement on previous state-of-the-art methods on a variety of challenging benchmarks. Furthermore, it is quite efficient and takes less time to train than previous state-of-the-art methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Our algorithm partitions a set of images into k clusters by aligning image embeddings with target points sampled from a Gaussian Mixture Model on the k-dimensional unit sphere.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Fig. 2. Our approach takes a set of images and solves two tasks in alternating epochs. In the primary task, a CNN is trained to produce output which matches some predefined set of target points sampled from a Gaussian mixture model, and optimally aligned with the training set. In the secondary task, given a rotated image, the same CNN is trained to predict the rotation angle of the image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Unsupervised image clustering results on STL-10. Each column shows images from a different cluster. The top three images in each column are examples of images from the same class successfully clustered together. The images in the fourth row illustrate failure cases, where the image is assigned to the wrong cluster (e.g., an airplane assigned to the 'bird' cluster).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Comparison of clustering performance on MNIST with different Mixture of Gaussians initializations. We compare different dimensions for the target vectors and different coefficient parameters (?) for the covariance matrices of the gaussians. These results do not include performing the refinement stage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I</head><label>I</label><figDesc>UNSUPERVISED CLUSTERING RESULTS. THE RESULTS OF OUR METHOD ARE SHOWN BELOW THE SEPARATION LINE. FOR EACH DATASET, WE SHOW THE AVERAGE RESULT OVER FIVE RUNS, STANDARD ERROR (STE) AND THE BEST RUN. ABOVE THE SEPARATION LINE WE LIST STATE OF THE ART RESULTS FOR COMPARISON, SEE REVIEW IN SECTION II. UNREPORTED RESULTS ARE MARKED WITH (-).</figDesc><table><row><cell></cell><cell></cell><cell cols="2">MNIST</cell><cell cols="2">CIFAR-10</cell><cell cols="2">CIFAR-100</cell><cell cols="2">STL-10</cell><cell cols="2">ImageNet-10</cell><cell cols="2">Tiny-ImageNet</cell></row><row><cell></cell><cell></cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell></row><row><cell cols="2">k-means</cell><cell>0.499</cell><cell>0.572</cell><cell>0.087</cell><cell>0.228</cell><cell>0.083</cell><cell>0.129</cell><cell>0.124</cell><cell>0.192</cell><cell>0.119</cell><cell>0.241</cell><cell>0.065</cell><cell>0.025</cell></row><row><cell>SC</cell><cell></cell><cell>0.663</cell><cell>0.696</cell><cell>0.103</cell><cell>0.247</cell><cell>0.090</cell><cell>0.136</cell><cell>0.098</cell><cell>0.159</cell><cell>0.151</cell><cell>0.274</cell><cell>0.063</cell><cell>0.022</cell></row><row><cell>AE</cell><cell></cell><cell>0.725</cell><cell>0.812</cell><cell>0.239</cell><cell>0.313</cell><cell>0.100</cell><cell>0.164</cell><cell>0.249</cell><cell>0.303</cell><cell>0.210</cell><cell>0.317</cell><cell>0.131</cell><cell>0.041</cell></row><row><cell cols="2">DEC (2016)</cell><cell>0.772</cell><cell>0.843</cell><cell>0.257</cell><cell>0.301</cell><cell>0.136</cell><cell>0.185</cell><cell>0.276</cell><cell>0.359</cell><cell>0.282</cell><cell>0.381</cell><cell>0.115</cell><cell>0.037</cell></row><row><cell cols="2">JULE (2016)</cell><cell>0.913</cell><cell>0.964</cell><cell>0.192</cell><cell>0.272</cell><cell>0.103</cell><cell>0.137</cell><cell>0.182</cell><cell>0.277</cell><cell>0.175</cell><cell>0.300</cell><cell>0.102</cell><cell>0.033</cell></row><row><cell cols="2">DAC (2017)</cell><cell>0.935</cell><cell>0.978</cell><cell>0.396</cell><cell>0.522</cell><cell>0.185</cell><cell>0.238</cell><cell>0.249</cell><cell>0.303</cell><cell>0.394</cell><cell>0.527</cell><cell>0.190</cell><cell>0.066</cell></row><row><cell cols="2">IIC (2019)</cell><cell>0.978</cell><cell>0.992</cell><cell>0.513</cell><cell>0.617</cell><cell>0.224</cell><cell>0.257</cell><cell>0.431</cell><cell>0.499 1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">DCCM (2019)</cell><cell>-</cell><cell>-</cell><cell>0.496</cell><cell>0.623</cell><cell>0.285</cell><cell>0.327</cell><cell>0.376</cell><cell>0.482</cell><cell>0.608</cell><cell>0.710</cell><cell>0.224</cell><cell>0.108</cell></row><row><cell></cell><cell>avg.</cell><cell>0.971</cell><cell>0.990</cell><cell>0.703</cell><cell>0.820</cell><cell>0.418</cell><cell>0.446</cell><cell>0.593</cell><cell>0.694</cell><cell>0.719</cell><cell>0.811</cell><cell>0.274</cell><cell>0.119</cell></row><row><cell>Ours</cell><cell>ste</cell><cell cols="7">?.000 ?.000 ?.011 ?.019 ?.003 ?.006 ?.005</cell><cell>?.013</cell><cell cols="4">?.008 ?.012 ?.001 ?.001</cell></row><row><cell></cell><cell>best</cell><cell>0.973</cell><cell>0.991</cell><cell>0.720</cell><cell>0.843</cell><cell>0.423</cell><cell>0.464</cell><cell>0.609</cell><cell>0.741</cell><cell>0.732</cell><cell>0.830</cell><cell>0.277</cell><cell>0.121</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II THE</head><label>II</label><figDesc>IMAGE DATASETS USED IN OUR EXPERIMENTS.</figDesc><table><row><cell>Name</cell><cell cols="3">Classes Samples Dimension</cell></row><row><cell>MNIST</cell><cell>10</cell><cell>70,000</cell><cell>28?28</cell></row><row><cell>CIFAR-10</cell><cell>10</cell><cell>60,000</cell><cell>32?32?3</cell></row><row><cell>CIFAR-100</cell><cell>20</cell><cell>60,000</cell><cell>32?32?3</cell></row><row><cell>STL-10</cell><cell>10</cell><cell>13,000</cell><cell>96?96?3</cell></row><row><cell>ImageNet-10</cell><cell>10</cell><cell>13,000</cell><cell>96?96?3</cell></row><row><cell>Tiny-ImageNet</cell><cell>200</cell><cell>100,000</cell><cell>64?64?3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III CLUSTERING</head><label>III</label><figDesc>PERFORMANCE ON CIFAR-10, SHOWING THE COMBINED EFFECT OF PRE-PROCESSING WITH THE SOBEL FILTER AND ADDING A ROTATION LOSS. FIRST ROW: NO PRE-PROCESSING AND NO ROTATION LOSS, SECOND ROW: PRE-PROCESSING AND NO ROTATION LOSS, THIRD ROW: NO PRE-PROCESSING WITH A ROTATION LOSS, FOURTH ROW: BOTH.</figDesc><table><row><cell>Sobel Rotation loss</cell><cell>NMI</cell><cell>ACC</cell></row><row><cell></cell><cell cols="2">0.428 ? .005 0.492 ? .003</cell></row><row><cell></cell><cell cols="2">0.463 ? .003 0.560 ? .006</cell></row><row><cell></cell><cell cols="2">0.703 ? .011 0.820 ? .019</cell></row><row><cell></cell><cell cols="2">0.610 ? .010 0.725 ? .020</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV EVALUATION</head><label>IV</label><figDesc>OF UNSUPERVISED FEATURE LEARNING METHODS ON CIFAR-10 AND CIFAR-100. WE USE THE PENULTIMATE LAYER OF THE NETWORK AS IMAGE FEATURES AND TEST PERFORMANCE WITH TWO PROCEDURES. WE PERFORM K-MEANS CLUSTERING ON THE IMAGE FEATURES AND TRAIN A LINEAR CLASSIFIER USING THE IMAGE LABELS. AS A REFERENCE, WE REPORT RESULTS USING AN IMAGENET-PRETRAINED RESNET-18. ? .001 0.162 ? .001 0.315 ? .002 0.037 ? .001 0.095 ? .001 0.177 ? .001 RotNet 0.329 ? .011 0.349 ? .012 0.740 ? .002 0.261 ? .006 0.284 ? .013 0.543 ? .001 NAT+RotNet 0.413 ? .005 0.511 ? .002 0.764 ? .001 0.190 ? .007 0.232 ? .006 0.499 ? .002 Ours 0.428 ? .011 0.397 ? .018 0.869 ? .002 0.395 ? .002 0.347 ? .007 0.662 ? .001</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">CIFAR-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">CIFAR-100</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>K-means</cell><cell></cell><cell></cell><cell>Linear</cell><cell></cell><cell cols="2">K-means</cell><cell></cell><cell>Linear</cell></row><row><cell></cell><cell></cell><cell>NMI</cell><cell></cell><cell>ACC</cell><cell></cell><cell>ACC</cell><cell></cell><cell>NMI</cell><cell>ACC</cell><cell></cell><cell>ACC</cell></row><row><cell cols="2">ImageNet labels</cell><cell>0.321</cell><cell></cell><cell>0.407</cell><cell></cell><cell>0.782</cell><cell cols="2">0.247</cell><cell>0.281</cell><cell></cell><cell>0.646</cell></row><row><cell cols="2">NAT</cell><cell cols="5">0.044 TABLE V</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="10">COMPARISON OF CLUSTERING PERFORMANCE BEFORE AND AFTER THE REFINEMENT STAGE.</cell><cell></cell></row><row><cell></cell><cell cols="2">MNIST</cell><cell cols="2">CIFAR-10</cell><cell cols="2">CIFAR-100</cell><cell cols="2">STL-10</cell><cell cols="2">ImageNet-10</cell><cell cols="2">Tiny-ImageNet</cell></row><row><cell></cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell></row><row><cell>Before</cell><cell cols="12">avg. 0.950 ste ?.002 ?.001 ?.011 ?.019 ?.003 ?.006 ?.005 ?.013 ?.008 ?.012 ?.001 ?.001 0.981 0.703 0.820 0.418 0.446 0.593 0.694 0.719 0.811 0.274 0.119</cell></row><row><cell>After</cell><cell cols="12">avg. 0.971 ste ?.000 ?.000 ?.009 ?.021 ?.002 ?.005 ?.005 ?.013 ?.008 ?.012 ?.001 ?.002 0.990 0.715 0.829 0.422 0.446 0.596 0.696 0.725 0.815 0.254 0.095</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work was supported in part by a grant from the Israel Science Foundation (ISF), Phenomics -a grant from the Israel Innovation Authority, and by the Gatsby Charitable Foundations.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">K-means++: The advantages of careful seeding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergei</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annu. ACM-SIAM Symp. on Discrete Algorithms</title>
		<meeting>of the Annu. ACM-SIAM Symp. on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1027" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised learning by predicting noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Shiming Xiang, and Chunhong Pan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5880" to="5888" />
		</imprint>
	</monogr>
	<note>Deep adaptive image clustering</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Self-supervised gans via auxiliary rotation loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lu?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12146" to="12155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An analysis of singlelayer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Track</title>
		<meeting>Track</meeting>
		<imprint>
			<publisher>JMLR</publisher>
			<date type="published" when="2011-01" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-task self-supervised visual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2051" to="2060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Pattern recognition and scene analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">E</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Partition-based clustering in object bases: From theory to practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Gerlhof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfons</forename><surname>Kemper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Kilger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Moerkotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Foundations of Data Organization and Algorithms</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="301" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Boosting few-shot visual learning with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Agglomerative clustering using the concept of mutual nearest neighbourhood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chidananda</forename><surname>Gowda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="105" to="112" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Associative deep clustering: Training a classification network with no labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>H?usser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Plapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elie</forename><surname>Aljalbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition (GCPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Data clustering: a review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anil K Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick J</forename><surname>Narasimha Murty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM computing surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="264" to="323" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jo?o</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9865" to="9874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Revisiting selfsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Density-based clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peer</forename><surname>Kr?ger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rg</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Zimek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="231" to="240" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryn</forename><surname>Yaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Res. Logist. Quart</title>
		<imprint>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">High-fidelity image generation with fewer labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lu?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><forename type="middle">Frederic</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stacked convolutional auto-encoders for hierarchical feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ueli</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">C</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks (ICANN)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A survey of clustering with deep learning: From the perspective of network architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erxue</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianjing</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="39501" to="39514" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The effectiveness of lloyd-type methods for the k-means problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ostrovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rabani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Swamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Foundations of Computer Science (FOCS)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="165" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A comparative study of divisive and agglomerative hierarchical clustering algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Roux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Classification</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adaptive density-based spatial clustering of applications with noise (dbscan) according to data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning and Cybernetics (ICMLC)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="445" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep comprehensive correlation mining for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyu</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8150" to="8159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Stacked what-where auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
