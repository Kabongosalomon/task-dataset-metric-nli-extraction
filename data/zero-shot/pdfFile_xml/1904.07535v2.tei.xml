<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Doc2EDAG: An End-to-End Document-level Framework for Chinese Financial Event Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shun</forename><surname>Zheng</surname></persName>
							<email>zhengs14@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Interdisciplinary Information Sciences</orgName>
								<orgName type="institution">Tsinghua University ? Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Cao</surname></persName>
							<email>wei.cao@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Interdisciplinary Information Sciences</orgName>
								<orgName type="institution">Tsinghua University ? Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
							<email>weixu@mail.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Interdisciplinary Information Sciences</orgName>
								<orgName type="institution">Tsinghua University ? Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Bian</surname></persName>
							<email>jiang.bian@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Interdisciplinary Information Sciences</orgName>
								<orgName type="institution">Tsinghua University ? Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Doc2EDAG: An End-to-End Document-level Framework for Chinese Financial Event Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most existing event extraction (EE) methods merely extract event arguments within the sentence scope. However, such sentence-level EE methods struggle to handle soaring amounts of documents from emerging applications, such as finance, legislation, health, etc., where event arguments always scatter across different sentences, and even multiple such event mentions frequently co-exist in the same document. To address these challenges, we propose a novel end-to-end model, Doc2EDAG, which can generate an entity-based directed acyclic graph to fulfill the document-level EE (DEE) effectively. Moreover, we reformalize a DEE task with the no-trigger-words design to ease document-level event labeling. To demonstrate the effectiveness of Doc2EDAG, we build a large-scale real-world dataset consisting of Chinese financial announcements with the challenges mentioned above. Extensive experiments with comprehensive analyses illustrate the superiority of Doc2EDAG over state-of-the-art methods. Data and codes can be found at https://github.com/ dolphin-zs/Doc2EDAG.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Event extraction (EE), traditionally modeled as detecting trigger words and extracting corresponding arguments from plain text, plays a vital role in natural language processing since it can produce valuable structured information to facilitate a variety of tasks, such as knowledge base construction, question answering, language understanding, etc.</p><p>In recent years, with the rising trend of digitalization within various domains, such as finance, legislation, health, etc., EE has become an increasingly important accelerator to the development of * This work was done during the internship of Shun Zheng at Microsoft Research Asia, <ref type="bibr">Beijing, China. 2005</ref><ref type="bibr" target="#b1">2006</ref><ref type="bibr">2007</ref><ref type="bibr">2008</ref><ref type="bibr">2009</ref><ref type="bibr">2010</ref><ref type="bibr">2011</ref><ref type="bibr">2012</ref><ref type="bibr">2013</ref><ref type="bibr">2014</ref><ref type="bibr">2015</ref><ref type="bibr">2016</ref><ref type="bibr">2017</ref><ref type="bibr">2018</ref> Year 0 10 20 30 # Announcements (x1000) <ref type="figure">Figure 1</ref>: The rapid growth of event-related announcements considered in this paper. business in those domains. Take the financial domain as an example, continuous economic growth has witnessed exploding volumes of digital financial documents, such as financial announcements in a specific stock market as <ref type="figure">Figure 1</ref> shows, specified as Chinese financial announcements (ChFi-nAnn). While forming up a gold mine, such large amounts of announcements call EE for assisting people in extracting valuable structured information to sense emerging risks and find profitable opportunities timely.</p><p>Given the necessity of applying EE on the financial domain, the specific characteristics of financial documents as well as those within many other business fields, however, raise two critical challenges to EE, particularly arguments-scattering and multi-event. Specifically, the first challenge indicates that arguments of one event record may scatter across multiple sentences of the document, while the other one reflects that a document is likely to contain multiple such event records. To intuitively illustrate these challenges, we show a typical ChFinAnn document with two Equity Pledge event records in <ref type="figure">Figure 2</ref>. For the first event, the entity 1 "[SHARE1]" is the correct Pledged Shares at the sentence level (ID 5). However, due to the capital stock increment (ID 7), ID Sentence Figure 2: A document example with two Equity Pledge event records whose arguments scatter across multiple sentences, where we use ID to denote the sentence index, substitute entity mentions with corresponding marks, and color event arguments outside the scope of key-event sentences as red.</p><p>the correct Pledged Shares at the document level should be "[SHARE2]". Similarly, "[DATE3]" is the correct End Date at the sentence level (ID 9) but incorrect at the document level (ID 10). Moreover, some summative arguments, such as "[SHARE5]" and " <ref type="bibr">[RATIO]</ref>", are often stated at the end of the document. Although a great number of efforts <ref type="bibr" target="#b1">(Ahn, 2006;</ref><ref type="bibr">Ji and Grishman, 2008;</ref><ref type="bibr">Liao and Grishman, 2010;</ref><ref type="bibr">Hong et al., 2011;</ref><ref type="bibr">Riedel and McCallum, 2011;</ref><ref type="bibr">Li et al., 2013</ref><ref type="bibr">Li et al., , 2014</ref><ref type="bibr">Chen et al., 2015;</ref><ref type="bibr">Yang and Mitchell, 2016;</ref><ref type="bibr">Nguyen et al., 2016;</ref><ref type="bibr">Liu et al., 2017;</ref><ref type="bibr">Sha et al., 2018;</ref><ref type="bibr">Zhang and Ji, 2018;</ref><ref type="bibr">Nguyen and Nguyen, 2019;</ref><ref type="bibr">Wang et al., 2019)</ref> have been put on EE, most of them are based on ACE 2005 2 , an expert-annotated benchmark, which only tagged event arguments within the sentence scope. We refer to such task as the sentence-level EE (SEE), which obviously overlooks the arguments-scattering challenge. In contrast, EE on financial documents, such as ChFi-nAn, requires document-level EE (DEE) when facing arguments-scattering, and this challenge gets much harder when coupled with multi-event.</p><p>The most recent work, <ref type="bibr">DCFEE (Yang et al., 2018)</ref>, attempted to explore DEE on ChFinAnn, by employing distant supervision (DS) <ref type="bibr">(Mintz et al., 2009)</ref> to generate EE data and performing a two-stage extraction: 1) a sequence tagging model for SEE, and 2) a key-event-sentence detection model to detect the key-event sentence, coupled with a heuristic strategy that padded missing arguments from surrounding sentences, for DEE. However, the sequence tagging model for SEE cannot handle multi-event sentences elegantly, and even worse, the context-agnostic argumentscompletion strategy fails to address the argumentsscattering challenge effectively.</p><p>In this paper, we propose a novel end-to-end model, Doc2EDAG, to address the unique challenges of DEE. The key idea of Doc2EDAG is to transform the event table into an entity-based directed acyclic graph (EDAG). The EDAG format can transform the hard table-filling task into several sequential path-expanding sub-tasks that are more tractable. To support the EDAG generation efficiently, Doc2EDAG encodes entities with document-level contexts and designs a memory mechanism for path expanding. Moreover, to ease the DS-based document-level event labeling, we propose a novel DEE formalization that removes the trigger-words labeling and regards DEE as directly filling event tables based on a document. This no-trigger-words design does not rely on any predefined trigger-words set or heuristic to filter multiple trigger candidates, and still perfectly matches the ultimate goal of DEE, mapping a document to underlying event tables.</p><p>To evaluate the effectiveness of our proposed Doc2EDAG, we conduct experiments on a realworld dataset, consisting of large scales of financial announcements. In contrast to the dataset used by DCFEE where 97% 3 documents just contained one event record, our data collection is ten times larger where about 30% documents include multiple event records. Extensive experiments demonstrate that Doc2EDAG can significantly outper-3 Estimated by their <ref type="table" target="#tab_3">Table 1</ref> as 2 * NO.ANN?NO.POS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NO.ANN</head><p>. form state-of-the-art methods when facing DEEspecific challenges.</p><p>In summary, our contributions include:</p><p>? We propose a novel model, Doc2EDAG, which can directly generate event tables based on a document, to address unique challenges of DEE effectively.</p><p>? We reformalize a DEE task without trigger words to ease the DS-based document-level event labeling.</p><p>? We build a large-scale real-world dataset for DEE with the unique challenges of arguments-scattering and multi-event, the extensive experiments on which demonstrate the superiority of Doc2EDAG.</p><p>Note that though we focus on ChFinAnn data in this work, we tackle those DEE-specific challenges without any domain-specific assumption. Therefore, our general labeling and modeling strategies can directly benefit many other business domains with similar challenges, such as criminal facts and judgments extraction from legal documents, disease symptoms and doctor instructions identification from medical reports, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Recent development on information extraction has been advancing in building the joint model that can extract entities and identify structures (relations or events) among them simultaneously. For instance, <ref type="bibr">(Ren et al., 2017;</ref><ref type="bibr">Zheng et al., 2017;</ref><ref type="bibr">Zeng et al., 2018a;</ref><ref type="bibr">Wang et al., 2018)</ref> focused on jointly extracting entities and inter-entity relations. In the meantime, the same to the focus of this paper, a few studies aimed at designing joint models for the entity and event extraction, such as handcrafted-feature-based <ref type="bibr">(Li et al., 2014;</ref><ref type="bibr">Yang and Mitchell, 2016;</ref><ref type="bibr">Judea and</ref><ref type="bibr">Strube, 2016) and</ref><ref type="bibr">neural-network-based (Zhang and</ref><ref type="bibr">Ji, 2018;</ref><ref type="bibr">Nguyen and Nguyen, 2019)</ref> models. Nevertheless, these models did not present how to handle argument candidates beyond the sentence scope. <ref type="bibr">(Yang and Mitchell, 2016)</ref> claimed to handle event-argument relations across sentences with the prerequisite of well-defined features, which, unfortunately, is nontrivial.</p><p>In addition to the modeling challenge, another big obstacle for democratizing EE is the lack of training data due to the enormous cost to obtain expert annotations. To address this problem, some researches attempted to adapt distant supervision (DS) to the EE setting, since DS has shown promising results by employing knowledge bases to automatically generate training data for relation extraction <ref type="bibr">(Mintz et al., 2009</ref>). However, the vanilla EE required the trigger words that were absent on factual knowledge bases. Therefore, <ref type="bibr">(Chen et al., 2017;</ref><ref type="bibr">Yang et al., 2018</ref>) employed either linguistic resources or predefined dictionaries for trigger-words labeling. On the other hand, another recent work <ref type="bibr">(Zeng et al., 2018b)</ref> showed that directly labeling event arguments without trigger words was also feasible. However, they only considered the SEE setting and their methods cannot be directly extended to the DEE setting, which is the main focus of this work.</p><p>Traditionally, when applying DS to relation extraction, researchers put huge efforts into alleviating labeling noises <ref type="bibr">(Riedel et al., 2010;</ref><ref type="bibr">Lin et al., 2016;</ref><ref type="bibr">Feng et al., 2018;</ref><ref type="bibr">Zheng et al., 2019)</ref>. In contrast, this work shows that combining DS with some simple constraints can obtain pretty good labeling quality for DEE, where the reasons are two folds: 1) both the knowledge base and text documents are from the same domain; 2) an event record usually contains multiple arguments, while a common relational fact only covers two entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</head><p>We first clarify several key notions: 1) entity mention: an entity mention is a text span that refers to an entity object; 2) event role: an event role corresponds to a predefined field of the event table; 3) event argument: an event argument is an entity that plays a specific event role; 4) event record: an event record corresponds to an entry of the event table and contains several arguments with required roles. For example, <ref type="figure">Figure 2</ref> shows two event records, where the entity "[PER]" is an event argument with the Pledger role.</p><p>To better elaborate and evaluate our proposed approach, we leverage the ChFinAnn data in this paper. ChFinAnn documents contain firsthand official disclosures of listed companies in the Chinese stock market and have hundreds of types, such as annual reports and earnings estimates. While in this work, we focus on those eventrelated ones that are frequent, influential, and mainly expressed by the natural language.</p><p>As a prerequisite to DEE, we first conduct the DSbased event labeling at the document level. More specifically, we map tabular records from an event knowledge base to document text and regard wellmatched records as events expressed by that document. Moreover, we adopt a no-trigger-words design and reformalize a novel DEE task accordingly to enable end-to-end model designs.</p><p>Event Labeling. To ensure the labeling quality, we set two constraints for matched records: 1) arguments of predefined key event roles must exist (non-key ones can be empty) and 2) the number of matched arguments should be higher than a certain threshold. Configurations of these constraints are event-specific, and in practice, we can tune them to directly ensure the labeling quality at the document level. We regard records that meet these two constraints as the well-matched ones, which serve as distantly supervised ground truths. In addition to labeling event records, we assign roles of arguments to matched tokens as token-level entity tags. Note that we do not label trigger words explicitly. Besides not affecting the DEE functionality, an extra benefit of such no-trigger-words design is a much easier DS-based labeling that does not rely on predefined trigger-words dictionaries or manually curated heuristics to filter multiple potential trigger words.</p><p>DEE Task Without Trigger Words. We reformalize a novel task for DEE as directly filling event tables based on a document, which generally requires three sub-tasks: 1) entity extraction, extracting entity mentions as argument candidates, 2) event detection, judging a document to be triggered or not for each event type, and 3) event table filling, filling arguments into the table of triggered events. This novel DEE task is much different from the vanilla SEE with trigger words but is consistent with the above simplified DS-based event labeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Doc2EDAG</head><p>The key idea of Doc2EDAG is to transform tabular event records into an EDAG and let the model learn to generate this EDAG based on documentlevel contexts. Following the example in <ref type="figure">Figure 2</ref>, <ref type="figure">Figure 3</ref> typically depicts an EDAG generation process and <ref type="figure">Figure 4</ref> presents the overall workflow of Doc2EDAG, which consists of two key stages:  <ref type="figure">Figure 3</ref>: An EDAG generation example that starts from event triggering and expands sequentially following the predefined order of event roles. document-level entity encoding (Section 5.1) and EDAG generation (Section 5.2). Before elaborating each of them in this section, we first describe two preconditioned modules: input representation and entity recognition.</p><p>Input Representation. In this paper, we denote a document as a sequence of sentences. Formally, after looking up the token embedding table V ? R dw?|V | , we denote a document d as a sentence sequence [s 1 ; s 2 ; ? ? ? ; s Ns ] and each sentence s i ? R dw?Nw is composed of a sequence of token embeddings as</p><formula xml:id="formula_0">[w i,1 , w i,2 , ? ? ? , w i,Nw ],</formula><p>where |V | is the vocabulary size, N s and N w are the maximum lengths of the sentence sequence and the token sequence, respectively, and w i,j ? R dw is the embedding of j th token in i th sentence with the embedding size d w .</p><p>Entity Recognition. Entity recognition is a typical sequence tagging task. We conduct this task at the sentence level and follow a classic method, BI-LSTM-CRF <ref type="bibr">(Huang et al., 2015)</ref>, that first encodes the token sequence and then adds a conditional random field (CRF) layer to facilitate the sequence tagging. The only difference is that we employ the Transformer <ref type="bibr">(Vaswani et al., 2017)</ref> instead of the original encoder, LSTM (Hochreiter and Schmidhuber, 1997). Transformer encodes a sequence of embeddings by the multiheaded self-attention mechanism to exchange contextual information among them. Due to the superior performance of the Transformer, we employ it as a primary context encoder in this work and name the Transformer module used in this stage as Transformer-1. Formally, for each sentence tensor s i ? R dw?Nw , we get the encoded one as h i = Transformer-1(s i ), where h i ? R dw?Nw shares the same embedding size d w and sequence length N w . During training, we employ roles of matched arguments as entity labels with the classic BIO (Begin, Inside, Other) scheme and wrap h i with a CRF layer to get the entity-recognition loss L er . As for the inference, we use the Viterbi decoding to get the best tagging sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Document-level Entity Encoding</head><p>To address the arguments-scattering challenge efficiently, it is indispensable to leverage global contexts to better identify whether an entity plays a specific event role. Consequently, we utilize document-level entity encoding to encode extracted entity mentions with such contexts and produce an embedding of size d w for each entity mention with a distinct surface name.</p><p>Entity &amp; Sentence Embedding. Since an entity mention usually covers multiple tokens with a variable length, we first obtain a fixed-sized embedding for each entity mention by conducting a max-pooling operation over its covered token embeddings. For example, given l th entity mention covering j th to k th tokens of i th sentence, we conduct the max-pooling over [h i,j , ? ? ? , h i,k ] to get the entity mention embedding e l ? R dw . For each sentence s i , we also take the maxpooling operation over the encoded token sequence [h i,1 , ? ? ? , h i,Nw ] to obtain a single sentence embedding c i ? R dw . After these operations, both the mention and the sentence embeddings share the same embedding size d w .</p><p>Document-level Encoding. Though we get embeddings for all sentences and entity mentions, these embeddings only encode local contexts within the sentence scope. To enable the awareness of document-level contexts, we employ the second Transformer module, Transformer-2, to facilitate the information exchange between all entity mentions and sentences. Before feeding them into Transformer-2, we add them with sentence position embeddings to inform the sentence order. After the Transformer encoding, we utilize the max-pooling operation again to merge multiple mention embeddings with the same entity surface name into a single embedding. Formally, after this stage, we obtain document-level contextaware entity mention and sentence embeddings as</p><formula xml:id="formula_1">e d = [e d 1 , ? ? ? , e d Ne ] and c d = [c d 1 , ? ? ? , c d Ns ]</formula><p>, respectively, where N e is the number of distinct entity surface names. These aggregated embeddings serve the next stage to fill event tables directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">EDAG Generation</head><p>After the document-level entity encoding stage, we can obtain the document embedding t ? R dw by operating the max-pooling over the sentence tensor c d ? R dw?Ns and stack a linear classifier over t to conduct the event-triggering classification for each event type. Next, for each triggered event type, we learn to generate an EDAG.</p><p>EDAG Building. Before the model training, we need to build the EDAG from tabular event records. For each event type, we first manually define an event role order. Then, we transform each event record into a linked list of arguments following this order, where each argument node is either an entity or a special empty argument NA. Finally, we merge these linked lists into an EDAG by sharing the same prefix path. Since every complete path of the EDAG corresponds to one row of the event table, recovering the table format from a given EDAG is simple.</p><p>Task Decomposition. The EDAG format aims to simplify the hard table-filling task into several tractable path-expanding sub-tasks. Then, a natural question is how the task decomposition works, which can be answered by the following EDAG recovering procedure. Assume the event triggering as the starting node (the initial EDAG), there comes a series of path-expanding sub-tasks following a predefined event role order. When considering a certain role, for every leaf node of the current EDAG, there is a path-expanding sub-task that decides which entities to be expanded. For each entity to be expanded, we create a new node of that entity for the current role and expand the path by connecting the current leaf node to the new entity node. If no entity is valid for expanding, we create a special NA node. When all sub-tasks for the current role finish, we move to the next role and repeat until the last. In this work, we leverage the above logic to recover the EDAG from pathexpanding predictions at inference and to set associated labels for each sub-task when training.</p><p>Memory. To better fulfill each path-expanding sub-task, it is crucial to know entities already contained by the path. Hence, we design a memory mechanism that initializes a memory tensor m with the sentence tensor c d at the beginning and updates m when expanding the path by appending either the associated entity embedding or the zero-padded one for the NA argument. With this design, each sub-task can own a distinct memory tensor, corresponding to the unique path history. e r <ref type="figure">Figure 4</ref>: The overall workflow of Doc2EDAG, where we follow the example in <ref type="figure">Figure 2</ref> and the EDAG structure in <ref type="figure">Figure 3</ref>, and use stripes to differentiate different entities (note that the number of input tokens and entity positions are imaginary, which do not match previous ones strictly, and here we only include the first three event roles and associated entities for brevity).</p><p>Path Expanding. For each path-expanding subtask, we formalize it as a collection of multiple binary classification problems, that is predicting expanding (1) or not (0) for all entities. To enable the awareness of the current path state, history contexts and the current event role, we first concatenate the memory tensor m and the entity tensor e d , then add them with a trainable eventrole-indicator embedding, and encode them with the third Transformer module, Transformer-3, to facilitate the context-aware reasoning. Finally, we extract the enriched entity tensor e r from outputs of Transformer-3 and stack a linear classifier over e r to conduct the path-expanding classification.</p><p>Optimization. For the event-triggering classification, we calculate the cross-entropy loss L tr . During the EDAG generation, we calculate a cross-entropy loss for each path-expanding subtask, and sum these losses as the final EDAGgeneration loss L dag . Finally, we sum L tr , L dag and the entity-recognition loss L er together as the final loss, L all = ? 1 L er + ? 2 L tr + ? 3 L dag , where ? 1 , ? 2 and ? 3 are hyper-parameters.</p><p>Inference. Given a document, Doc2EDAG first recognizes entity mentions from sentences, then encodes them with document-level contexts, and finally generates an EDAG for each triggered event type by conducting a series of pathexpanding sub-tasks.</p><p>Practical Tips. During training, we can utilize both ground-truth entity tokens and the given EDAG structure. While at inference, we need to first identify entities and then expand paths sequentially based on embeddings of those entities to recover the EDAG. This gap between training and inference can cause severe error-propagation problems. To mitigate such problems, we utilize the scheduled sampling <ref type="bibr">(Bengio et al., 2015)</ref> to gradually switch the inputs of document-level entity encoding from ground-truth entity mentions to model recognized ones. Moreover, for pathexpanding classifications, false positives are more harmful than false negatives, because the former can cause a completely wrong path. Accordingly, we can set ?(&gt; 1) as the negative class weight of the associated cross-entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>In this section, we present thorough empirical studies to answer the following questions: 1) to what extent can Doc2EDAG improve over stateof-the-art methods when facing DEE-specific challenges? 2) how do different models behave when facing both arguments-scattering and multievent challenges? 3) how important are various components of Doc2EDAG?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup</head><p>Data Collection with Event Labeling. We utilize ten years (2008-2018) ChFinAnn 4 documents and human-summarized event knowledge bases to conduct the DS-based event labeling. We focus on five event types: Equity Freeze (EF), Equity Repurchase (ER), Equity Underweight (EU), Equity Overweight (EO) and Equity Pledge (EP), which belong to major events required to be disclosed by the regulator and may have a huge impact on the company value. To ensure the labeling quality, we set constraints for matched document-record pairs   as Section 4 describes. Moreover, we directly use the character tokenization to avoid error propagations from Chinese word segmentation tools. Finally, we obtain 32, 040 documents in total, and this number is ten times larger than 2, 976 of DCFEE and about 53 times larger than 599 of ACE 2005. We divide these documents into train, development, and test set with the proportion of 8 : 1 : 1 based on the time order. In <ref type="table" target="#tab_3">Table 1</ref>, we show the number of documents and the multi-event ratio (MER) for each event type on this dataset. Note that a few documents may contain multiple event types at the same time.</p><p>Data Quality. To verify the quality of DS-based event labeling, we randomly select 100 documents and manually annotate them. By regarding DS-generated event tables as the prediction and human-annotated ones as the ground-truth, we evaluate the labeling quality based on the metric introduced below. <ref type="table" target="#tab_4">Table 2</ref> shows this approximate evaluation, and we can observe that DS-generated data are pretty good, achieving high precision and acceptable recall. In later experiments, we directly employ the automatically generated test set for evaluation due to its much broad coverage.</p><p>Evaluation Metric. The ultimate goal of DEE is to fill event tables with correct arguments for each role. Therefore, we evaluate DEE by directly comparing the predicted event table with the groundtruth one for each event type. Specifically, for each document and each event type, we pick one predicted record and one most similar ground-truth record (at least one of them is non-empty) from associated event tables without replacement to calculate event-role-specific true positive, false positive and false negative statistics until no record left. After aggregating these statistics among all evaluated documents, we can calculate role-level precision, recall, and F1 scores (all reported in percentage format). As an event type often includes multiple roles, we calculate micro-averaged rolelevel scores as the final event-level metric that reflects the ability of end-to-end DEE directly.</p><p>Hyper-parameter Setting. For the input, we set the maximum number of sentences and the maximum sentence length as 64 and 128, respectively. During training, we set ? 1 = 0.05, ? 2 = ? 3 = 0.95 and ? = 3. We employ the Adam (Kingma and Ba, 2015) optimizer with the learning rate 1e ?4 , train for at most 100 epochs and pick the best epoch by the validation score on the development set. Besides, we leverage the decreasing order of the non-empty argument ratio as the event role order required by Doc2EDAG, because more informative entities in the path history can better facilitate later path-expanding classifications.</p><p>Note that, due to the space limit, we leave other detailed hyper-parameters, model structures, data preprocessing configurations, event type specifications and pseudo codes for EDAG generation to the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Performance Comparisons</head><p>Baselines. As discussed in the related work, the state-of-the-art method applicable to our setting is DCFEE. We follow the implementation described in <ref type="bibr">(Yang et al., 2018)</ref>, but they did not illustrate how to handle multi-event sentences with just a sequence tagging model. Thus, we develop two versions, DCFEE-O and DCFEE-M, where DCFEE-O only produces one event record from one keyevent sentence, while DCFEE-M tries to get multiple possible argument combinations by the closest relative distance from the key-event sentence. To be fair, the SEE stages of both versions share the same neural architecture as the entity recognition part of Doc2EDAG. Besides, we further employ a simple decoding baseline of Doc2EDAG, Greedy-Dec, that only fills one event table entry greedily by using recognized entity roles to verify the necessity of end-to-end modeling.</p><p>Main Results. As <ref type="table" target="#tab_6">Table 3</ref> shows, Doc2EDAG achieves significant improvements over all base-    Ablation Tests. To demonstrate key designs of Doc2EDAG, we conduct ablation tests by evaluating four variants: 1) -PathMem, removing the memory mechanism used during the EDAG generation, 2) -SchSamp, dropping the scheduled sampling strategy during training, 3) -DocEnc, removing the Transformer module used for documentlevel entity encoding, and 4) -NegCW, keeping the negative class weight as 1 when doing pathexpanding classifications. From <ref type="table" target="#tab_8">Table 5</ref>, we can observe that 1) the memory mechanism is of prime importance, as removing it can result in the most drastic performance declines, over 10 F1 scores on four event types except for the ER type whose MER is very low on the test set; 2) the scheduled sampling strategy that alleviates the mismatch of entity candidates for event table filling between training and inference also contributes greatly, improving by 5 F1 scores on average; 3) the document-level entity encoding that enhances global entity representations contributes 2.1 F1 scores on average; 4) the larger negative class weight to penalize false positive path expanding can also make slight but stable contributions for all event types.</p><p>Case Studies. Let us follow the example in <ref type="figure">Figure 2, Doc2EDAG</ref> can successfully recover the correct EDAG, while DCFEE inevitably makes many mistakes even with a perfect SEE model, as discussed in the introduction. Due to the space limit, we leave another three fine-grained case studies to the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>Towards the end-to-end modeling for DEE, we propose a novel model, Doc2EDAG, associated with a novel task formalization without trigger words to ease DS-based labeling. To validate the effectiveness of the proposed approach, we build a large-scale real-world dataset in the financial domain and conduct extensive empirical studies. Notably, without any domain-specific assumption, our general labeling and modeling strategies can benefit practitioners in other domains directly. As this work shows promising results for the end-to-end DEE, expanding the inputs of Doc2EDAG from pure text sequences to richly formatted ones <ref type="bibr">(Wu et al., 2018)</ref> is appealing, and we leave it as future work to explore.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>In the appendix, we incorporate the following details that are omitted in the main body due to the space limit.</p><p>? Section A.1 presents event type specifications and corresponding preprocessing details.</p><p>? Section A.2 includes the hyper-parameter setting that we use to run experiments.</p><p>? Section A.3 provides pseudo codes to facilitate understanding of the EDAG generation.</p><p>? Section A.4 complements additional evaluation results for entity extraction and event triggering.</p><p>? Section A.5 studies another three sophisticated cases to intuitively illustrate necessities and advantages of end-to-end modeling. <ref type="table" target="#tab_10">Table 6</ref> shows detailed illustrations for event types used in our paper, where we mark some key roles that should be non-empty when conducting the document-level event labeling. In addition to requiring non-empty key roles, we empirically set the minimum number of matched roles for EF, ER, EU, EO and EP events as 5, 4, 4, 4 and 5, respectively. Though we set these constraints empirically when processing our data, practitioners of other domains can adjust these configurations freely to fulfill the task-specific requirements by making a desirable trade-off between precision and recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Event Type Specifications</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Hyper-parameters Setting</head><p>We summarize all hyper-parameters in <ref type="table" target="#tab_11">Table 7</ref> for better reproducibility.</p><p>Moreover, when training models, we follow the decreasing order of the non-empty arguments ratio of the role, based on the intuition that more informative (non-empty) arguments in the path history can facilitate better subsequent argument identifications during the recurrent decoding, and we also validate this intuition by comparing with models trained on some randomly permuted role orders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Pseudo Codes for the EDAG Generation</head><p>We provide pseudo codes about how to calculate the EDAG loss for a given EDAG structure (Algorithm 1) and how to generate an EDAG at inference (Algorithm 2) to facilitate better understanding of the EDAG generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Additional Evaluation Results</head><p>In the main body, we show the end-to-end evaluation results of DEE for different models when facing arguments-scattering and multi-event challenges. Here, <ref type="table">Table 8</ref> complemented both evaluation results and corresponding analyses for entity extraction and event triggering, two preceding sub-tasks before filling the event table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Case Studies</head><p>In addition to the Equity Pledge example included by the paper, we show another three cases in <ref type="figure">Figure 5, 6</ref> and 7 for the Equity Overweight, Equity Underweight and Equity Freeze events, respectively, to intuitively illustrate why Doc2EDAG, the truly end-to-end model, is better. For all figures, we color the wrong predicted arguments as red and present detailed explanations.    <ref type="table">Table 8</ref>: Evaluation results of entity extraction and event triggering for each event type on the test set, where we can observe that 1) different models produce roughly consistent entity-extraction performance, which corresponds to our setting that all models share the same architecture when extracting entities; 2) the document-level event triggering is superior to the sentence-level event triggering (key-event sentence detection used in DCFEE), because both the DS-based labeling and the event-triggering learning can be more accurate and robust at the document level, and the assumption to identify key-event sentences used by DCFEE is hard to fit all event types well.</p><p>Event  <ref type="figure">Figure 6</ref>. Since our model can perform the end-to-end context-aware inference, it produces much better results than existing solutions, though it also misses two arguments for the Later Holding Shares role. After the careful examination, we find that the empty ratio of this role is pretty high during training, and thus our model prefers to be conservative in assigning entities with this role. This case also implies that there still exists some promotion spaces for the Doc2EDAG paradigm. [ORG1] (abbreviated at "the company" below) was informed in [DATE1] that the shares hold by [ORG2] (abbreviated as "Fukong Media" below), the controlling shareholder, and Mr.</p><p>[PER1], the actual controller, were froze judicially in turn, the detailed information is listed as follows:</p><p>4</p><p>First, the information about the controlling shareholder being froze 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[ORG3]</head><p>The legal institution conducting this freeze: [ORG3] ;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6</head><p>[SHARE1]</p><p>The number of shares being froze: [SHARE1], froze in turn;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7</head><p>[DATE1]</p><p>The start date of this freeze: [DATE1];</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9</head><p>Second, the information about the actual controller being froze 10</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[ORG3]</head><p>The legal institution conducting this freeze: [ORG3] ;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11</head><p>[SHARE2]</p><p>The number of shares being froze: [SHARE2], froze in turn;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12</head><p>[DATE1]</p><p>The start date of this freeze: Shanghai Fukong Interactive Entertainment</p><p>Co.,Ltd.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[ORG2]</head><p>Shanghai Fukong Culture Media Co., Ltd.</p><p>[ORG3]  <ref type="figure">Figure 7</ref>: This case, containing two Equity Freeze events, is a typical example that violates the key-sentence labeling assumption of DCFEE, which assumes the sentence containing the most arguments as the key-event one. We can observe that the core arguments of the event scatter across multiple sub-sentences, such as ID 5, 6, 7, 10, 11 and 12, but DCFEE-O and DCFEE-M treat the summary sentence (ID 14) as the key-event one. However, the single sentence (ID 14) summarizes these two event records, and DCFEE models cannot address such multi-event sentences elegantly. Note that, each text snippet of ID 5, 6, 7, 10, 11 and 12 is not a complete sentence, but these text snippets are presented in a list manner and some of them even do not have ending punctuations <ref type="bibr">(ID 4,</ref><ref type="bibr">9)</ref>. We have tried to merge such short snippets into a single long sentence, but applying this merge on the whole dataset can hurt the performance of DCFEE models on other event types. Thus, we drop this preprocessing option. In contrast, our model is immune to such merging and even benefit with a faster speed due to fewer sentences to be encoded. In terms of the extraction performance, our model correctly identifies these two events and arranges entities into proper table columns with only one missing argument for the Total Holding Ratio role. While DCFEE models miss one event and inevitably make mistakes when completing missing arguments for the key-event sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Jinan</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table of Equity Pledge Pledger Pledged Shares Pledgee Begin Date End Date Total Holding Shares Total Holding Ratio</head><label></label><figDesc>After the company carried out the transferring of the capital accumulation fund to the capital stock, his pledged shares became [SHARE2].The aforementioned pledged and supplementary pledged shares added up to [SHARE4], and the original repurchase date was [DATE3].As of the date of this announcement, [PER] hold [SHARE5] of the company, accounting for [RATIO] of the total share capital of the company.</figDesc><table><row><cell cols="5">Event [PER] [SHARE2] [ORG] [DATE1]</cell><cell>[DATE4]</cell><cell>[SHARE5]</cell><cell>[RATIO]</cell></row><row><cell cols="2">[PER]</cell><cell>[SHARE3]</cell><cell>[ORG]</cell><cell>[DATE2]</cell><cell>[DATE4]</cell><cell>[SHARE5]</cell><cell>[RATIO]</cell></row><row><cell>5</cell><cell cols="2">[DATE1] [PER]</cell><cell>[SHARE1]</cell><cell>[ORG]</cell><cell></cell><cell></cell></row><row><cell>7</cell><cell></cell><cell></cell><cell></cell><cell>[SHARE2]</cell><cell></cell><cell></cell></row><row><cell>8</cell><cell cols="6">[DATE2] [PER] In [DATE2], [PER] pledged [SHARE3] to [ORG], as a supplementary pledge to the above pledged shares. [SHARE3] [ORG]</cell></row><row><cell>9</cell><cell></cell><cell></cell><cell>[SHARE4]</cell><cell cols="2">[DATE3]</cell><cell></cell></row><row><cell>10</cell><cell cols="6">[DATE3] [PER] In [DATE3], [PER] extended the repurchase date to [DATE4] for [SHARE4] he pledged. [SHARE4] [DATE4]</cell></row><row><cell>12</cell><cell></cell><cell>[PER]</cell><cell>[SHARE5]</cell><cell></cell><cell>[RATIO]</cell><cell></cell></row></table><note>In [DATE1], [PER] pledged his [SHARE1] to [ORG].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Pledged Shares Role 3 Pledgee Event Triggering Path Expanding</head><label></label><figDesc></figDesc><table><row><cell>Role 1</cell><cell>Role 2</cell><cell></cell></row><row><cell>Pledger</cell><cell></cell><cell></cell></row><row><cell>[PER]</cell><cell>[SHARE2]</cell><cell>[ORG]</cell></row><row><cell></cell><cell>[SHARE3]</cell><cell>[ORG]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Dataset statistics about the number of documents for the train (#Train), development (#Dev) and test (#Test), the number (#Total) and the multi-event ratio (MER) of all documents.</figDesc><table><row><cell cols="3">Precision Recall F1 MER (%)</cell></row><row><cell>98.8</cell><cell>89.7 94.0</cell><cell>31.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>The quality of the DS-based event labeling evaluated on 100 manually annotated documents (randomly select 20 for each event type).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>40.7 45.6 83.7 78.0 80.8 49.5 39.9 44.2 42.5 47.5 44.9 59.8 66.4 62.9 GreedyDec 79.5 46.8 58.9 83.3 74.9 78.9 68.7 40.8 51.2 69.7 40.6 51.3 85.7 48.7 62.1 Doc2EDAG 77.1 64.5 70.2 91.3 83.6 87.3 80.2 65.0 71.8 82.1 69.0 75.0 80.0 74.8 77.3</figDesc><table><row><cell>Model</cell><cell>P.</cell><cell>EF R.</cell><cell>F1</cell><cell>P.</cell><cell>ER R.</cell><cell>F1</cell><cell>P.</cell><cell>EU R.</cell><cell>F1</cell><cell>P.</cell><cell>EO R.</cell><cell>F1</cell><cell>P.</cell><cell>EP R.</cell><cell>F1</cell></row><row><cell>DCFEE-O</cell><cell cols="15">66.0 41.6 51.1 84.5 81.8 83.1 62.7 35.4 45.3 51.4 42.6 46.6 64.3 63.6 63.9</cell></row><row><cell>DCFEE-M</cell><cell>51.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Overall event-level precision (P.), recall (R.) and F1 scores evaluated on the test set.</figDesc><table><row><cell>Model</cell><cell>EF</cell><cell>ER</cell><cell>EU</cell><cell>EO</cell><cell>EP</cell><cell>Avg.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>F1 scores for all event types and the averaged ones (Avg.) on single-event (S.) and multi-event (M.) sets.</figDesc><table><row><cell>Model</cell><cell>EF ER</cell><cell>EU</cell><cell>EO</cell><cell>EP Avg.</cell></row><row><cell cols="5">Doc2EDAG 70.2 87.3 71.8 75.0 77.3 76.3</cell></row><row><cell>-PathMem</cell><cell cols="4">-11.2 -0.2 -10.1 -16.3 -10.9 -9.7</cell></row><row><cell>-SchSamp</cell><cell>-5.3 -4.8</cell><cell>-5.3</cell><cell>-6.6</cell><cell>-3.0 -5.0</cell></row><row><cell>-DocEnc</cell><cell>-4.7 -1.5</cell><cell>-1.6</cell><cell>-1.1</cell><cell>-1.5 -2.1</cell></row><row><cell>-NegCW</cell><cell>-1.4 -0.4</cell><cell>-0.7</cell><cell>-1.3</cell><cell>-0.4 -0.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Performance differences of Doc2EDAG variants for all event types and the averaged ones (Avg.).</figDesc><table><row><cell>lines for all event types. Specifically, Doc2EDAG</cell></row><row><cell>improves 19.1, 4.2, 26.5, 28.4 and 13.4 F1 scores</cell></row><row><cell>over DCFEE-O, the best baseline, on EF, ER,</cell></row><row><cell>EU, EO and EP events, respectively. These vast</cell></row><row><cell>improvements mainly owe to the document-level</cell></row><row><cell>end-to-end modeling of Doc2EDAG. Moreover,</cell></row><row><cell>since we work on automatically generated data,</cell></row><row><cell>the direct document-level supervision can be more</cell></row><row><cell>robust than the extra sentence-level supervision</cell></row><row><cell>used in DCFEE, which assumes the sentence con-</cell></row><row><cell>taining most event arguments as the key-event one.</cell></row><row><cell>This assumption does not work well on some event</cell></row><row><cell>types, such as EF, EU and EO, on which DCFEE-</cell></row><row><cell>O is even inferior to the most straightforward base-</cell></row><row><cell>line, GreedyDec. Besides, DCFEE-O achieves</cell></row><row><cell>better results than DCFEE-M, which demonstrates</cell></row><row><cell>that naively guessing multiple events from the key-</cell></row><row><cell>event sentence cannot work well. By comparing</cell></row><row><cell>Doc2EDAG with GreedyDec that owns high pre-</cell></row><row><cell>cision but low recall, we can clearly see the benefit</cell></row><row><cell>of document-level end-to-end modeling.</cell></row></table><note>Single-Event vs. Multi-Event. We divide the test set into a single-event set, containing docu- ments with just one event record, and a multi- event set, containing others, to show the extreme difficulty when arguments-scattering meets multi- event. Table 4 shows F1 scores for different sce- narios. Although Doc2EDAG still maintains the highest extraction performance for all cases, the multi-event set is extremely challenging as the ex- traction performance of all models drops signif- icantly. Especially, GreedyDec, with no mecha- nism for the multi-event challenge, decreases most drastically. DCFEE-O decreases less, but is still far away from Doc2EDAG. On the multi-event set, Doc2EDAG increases by 17.7 F1 scores over DCFEE-O, the best baseline, on average.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Equity Holder (key) the equity holder whose shares are froze Froze Shares (key) the number of shares being froze Legal Institution (key) the legal institution that executes this freeze Start Date the start date of this freeze End Date the end date of this freeze Unfroze Date the date in which these shares are unfroze</figDesc><table><row><cell>Event Type</cell><cell>Event Role</cell><cell>Detailed Explanations</cell></row><row><cell>Equity</cell><cell></cell><cell></cell></row><row><cell>Freeze</cell><cell></cell><cell></cell></row><row><cell>(EF)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Total Holding Shares</cell><cell>the total number of shares being hold at disclosing time</cell></row><row><cell></cell><cell>Total Holding Ratio</cell><cell>the total ratio of shares being hold at disclosing time</cell></row><row><cell></cell><cell>Company Name (key)</cell><cell>the name of the company</cell></row><row><cell>Equity Repurchase (ER)</cell><cell cols="2">Highest Trading Price the highest trading price Lowest Trading Price the lowest trading price Closing Date the closing date of this disclosed repurchase Repurchased Shares the number of shares being repurchased before the closing date</cell></row><row><cell></cell><cell>Repurchase Amount</cell><cell>the repurchase amount before the closing date</cell></row><row><cell></cell><cell>Equity Holder (key)</cell><cell>the equity holder who conducts this underweight</cell></row><row><cell>Equity Underweight (EU)</cell><cell>Traded Shares (key) Start Date End Date Average Price</cell><cell>the number of shares being traded the start date of this underweight the end date of this underweight the average price during this underweight</cell></row><row><cell></cell><cell>Later Holding Shares</cell><cell>the number of shares being hold after this underweight</cell></row><row><cell></cell><cell>Equity Holder (key)</cell><cell>the equity holder who conducts this overweight</cell></row><row><cell>Equity Overweight (EO)</cell><cell>Traded Shares (key) Start Date End Date Average Price</cell><cell>the number of shares being traded the start date of this overweight the end date of this overweight the average price during this overweight</cell></row><row><cell></cell><cell>Later Holding Shares</cell><cell>the number of shares being hold after this overweight</cell></row><row><cell></cell><cell>Pledger (key)</cell><cell>the equity holder who pledges some shares to an institution</cell></row><row><cell></cell><cell>Pledged Shares (key)</cell><cell>the number of shares being pledged</cell></row><row><cell></cell><cell>Pledgee (key)</cell><cell>the institution who accepts the pledged shares</cell></row><row><cell>Equity</cell><cell>Start Date</cell><cell>the start date of this pledge</cell></row><row><cell>Pledge</cell><cell>End Date</cell><cell>the end date of this pledge</cell></row><row><cell>(EP)</cell><cell>Released Date</cell><cell>the date in which these pledged shares are released</cell></row><row><cell></cell><cell>Total Pledged Shares</cell><cell>the total number of shares being pledged at disclosing time</cell></row><row><cell></cell><cell>Total Holding Shares</cell><cell>the total number of shares being hold at disclosing time</cell></row><row><cell></cell><cell>Total Holding Ratio</cell><cell>the total ratio of shares being hold at disclosing time</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Event type specifications.</figDesc><table><row><cell>Module</cell><cell>Hyper-parameter</cell><cell>Value</cell></row><row><cell>Input Representation</cell><cell>the maximum sentence number the maximum sentence length dw (the embedding size)</cell><cell>64 128 768</cell></row><row><cell>Entity</cell><cell>the tagging scheme</cell><cell>BIO (Begin, Inside, Other)</cell></row><row><cell>Recognition</cell><cell>the hidden size</cell><cell>768 (same to dw)</cell></row><row><cell>Transformer-1</cell><cell>the number of layers</cell><cell>4</cell></row><row><cell>Transformer-2</cell><cell>the size of the hidden layer</cell><cell>768 (same to dw)</cell></row><row><cell>Transformer-3</cell><cell>the size of the feed-forward layer</cell><cell>1, 024</cell></row><row><cell></cell><cell>the optimizer</cell><cell>Adam</cell></row><row><cell></cell><cell>the learning rate</cell><cell>1e ?4</cell></row><row><cell></cell><cell>the batch size</cell><cell>64 (with 32 P40 GPUs)</cell></row><row><cell></cell><cell>the training epoch</cell><cell>100</cell></row><row><cell></cell><cell>the loss reduction type</cell><cell>sum</cell></row><row><cell>Optimization</cell><cell>?1 ?2, ?3</cell><cell>0.05 0.95</cell></row><row><cell></cell><cell>?</cell><cell>3</cell></row><row><cell></cell><cell>the dropout probability</cell><cell>0.1</cell></row><row><cell></cell><cell>the scheduled-sampling beginning</cell><cell>10 th epoch</cell></row><row><cell></cell><cell>the scheduled-sampling ending</cell><cell>20 th epoch</cell></row><row><cell></cell><cell>the scheduled probability of employing</cell><cell>decreasing from 1.0 to 0.1 linearly</cell></row><row><cell></cell><cell>gold entity mentions</cell><cell>during the scheduled epochs</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>The hyper-parameter setting. Pseudo codes to calculate the loss for the EDAG generation Input: the EDAG structure G for each triggered event, the entity tensor e d = [e d 1 , ? ? ? , e d Ne ], the sentence tensor c d = [c d 1 , ? ? ? , c d Ns ]; Output: the EDAG generation loss L dag ; Initialize the loss L dag = 0; for each event type do if is triggered then Initialize the memory tensor of the virtual starting node as c d ; for each role type following the predefined order do for each entity node of the last role in G do Look up the memory tensor of this node as m t ; Get path-expanding labels from G; Calculate the path-expanding classification loss L pe ; Update the EDAG generation loss as L dag = L dag + L pe ; for each entity i known to be expanded in the current role do Set the memory tensor for the corresponding entity node of the current role as Output: the EDAG structure for each triggered event; for each event type do if is triggered then Initialize the EDAG structure with a virtual starting node; Initialize the memory tensor of the virtual starting node as c d ; for each role type following the predefined order do for each leaf node of the current EDAG do Look up the memory tensor of this node as m t ; Get path-expanding predictions; for each entity i predicted to be expanded in the current role do Create a new node of entity i for the current role; Update the EDAG structure by connecting the leaf node to the new entity node;</figDesc><table><row><cell>Algorithm 1: [m t , e d i ];</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>Algorithm 2: Pseudo codes to generate an EDAG at inference</cell></row><row><cell>Input: the entity tensor e d = [e d 1 , ? ? ? , e d Ne ], the sentence tensor c d = [c d 1 , ? ? ? , c d Ns ];</cell></row><row><cell>Set the memory tensor of that new node as [m t , e d i ];</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>end</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table (</head><label>(</label><figDesc>Mr. [PER1], the director and the general manager of the company, bought [SHARE1] of the company via the trading system of Shenzhen Stock Exchange, Mr. [PER2], the finance manager, bought [SHARE2] of the company via the trading system of Shenzhen Stock Exchange, and Mr. [PER3], the secretary of the board, bought [SHARE3] of the company via the trading system of Shenzhen Stock Exchange. In this case, there are three equity overweight (EO) events mentioned by the documents. Although DCFEE-O correctly identifies the key sentence (ID 3), it cannot decide how many events being expressed by this sentence, as its SEE module can only fulfill the sequence tagging task. Therefore, we implement another version, DCFEE-M, which guess possible events by the position closeness, and indeed DCFEE-M produce multiple partially correct events in this case. However, the arguments-completion stage of DCFEE-M is context-agnostic, which is the reason that DCFEE-M does not produce correct arguments for the End Date role ("DATE1" is already assigned with the Start Date role) and the Later Holding Shares role (the closest valid entity is "[SHARE4]"). Moreover, though achieving better results for this case, DCFEE-M is inferior to DCFEE-O in terms of the whole test set (shown in the paper), since the naive multi-event guessing fails on many other cases, such as the case shown in</figDesc><table><row><cell></cell><cell cols="5">Event Table (DCFEE-O, key sentences: 3)</cell><cell></cell><cell></cell><cell></cell><cell cols="3">Event Table (Our Model)</cell></row><row><cell>Equity Holder</cell><cell>Traded Shares</cell><cell>Start Date</cell><cell>End Date</cell><cell></cell><cell>Later Holding Shares</cell><cell cols="2">Average Price</cell><cell>Equity Holder</cell><cell>Traded Shares</cell><cell>Start Date</cell><cell>End Date</cell><cell>Later Holding Shares</cell><cell>Average Price</cell></row><row><cell>[PER1]</cell><cell>[SHARE1]</cell><cell>[DATE1]</cell><cell>NA</cell><cell></cell><cell>[SHARE4]</cell><cell></cell><cell>NA</cell><cell>[PER1]</cell><cell>[SHARE1]</cell><cell>[DATE1]</cell><cell>[DATE1]</cell><cell>NA</cell><cell>NA</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[PER2]</cell><cell>[SHARE2]</cell><cell>[DATE1]</cell><cell>[DATE1]</cell><cell>[SHARE2]</cell><cell>NA</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[PER3]</cell><cell>[SHARE1]</cell><cell>[DATE1]</cell><cell>[DATE1]</cell><cell>NA</cell><cell>NA</cell></row><row><cell></cell><cell cols="5">Event Table (DCFEE-M, key sentences: 3)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ground-truth)</cell></row><row><cell>Equity Holder</cell><cell>Traded Shares</cell><cell>Start Date</cell><cell>End Date</cell><cell></cell><cell>Later Holding Shares</cell><cell cols="2">Average Price</cell><cell>Equity Holder</cell><cell>Traded Shares</cell><cell>Start Date</cell><cell>End Date</cell><cell>Later Holding Shares</cell><cell>Average Price</cell></row><row><cell>[PER1]</cell><cell>[SHARE1]</cell><cell>[DATE1]</cell><cell>NA</cell><cell></cell><cell>[SHARE4]</cell><cell></cell><cell>NA</cell><cell>[PER1]</cell><cell>[SHARE1]</cell><cell>[DATE1]</cell><cell>[DATE1]</cell><cell>[SHARE4]</cell><cell>NA</cell></row><row><cell>[PER2]</cell><cell>[SHARE2]</cell><cell>[DATE1]</cell><cell>NA</cell><cell></cell><cell>[SHARE4]</cell><cell></cell><cell>NA</cell><cell>[PER2]</cell><cell>[SHARE2]</cell><cell>[DATE1]</cell><cell>[DATE1]</cell><cell>[SHARE2]</cell><cell>NA</cell></row><row><cell>[PER3]</cell><cell>[SHARE3]</cell><cell>[DATE1]</cell><cell>NA</cell><cell></cell><cell>[SHARE4]</cell><cell></cell><cell>NA</cell><cell>[PER3]</cell><cell>[SHARE3]</cell><cell>[DATE1]</cell><cell>[DATE1]</cell><cell>[SHARE5]</cell><cell>NA</cell></row><row><cell></cell><cell cols="2">Entity Mark Table</cell><cell></cell><cell>ID</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sentence</cell><cell></cell><cell></cell></row><row><cell>Mark</cell><cell>Entity</cell><cell>Entity (English)</cell><cell></cell><cell></cell><cell cols="2">[PER2]</cell><cell>[DATE1]</cell><cell>[PER1]</cell><cell cols="2">[SHARE2]</cell><cell cols="2">[SHARE1] [PER3]</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[SHARE3]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[PER1] [PER2] [PER3] [SHARE1] [SHARE2]</cell><cell>30000 20000</cell><cell>Bing Li Zunping Mao Baoqi Xia 30000 shares 20000 shares</cell><cell></cell><cell cols="7">3 The company was informed that, in [DATE1], 7 [PER1] [SHARE4] After this overweight, Mr. [PER1] hold [SHARE4] of the company in total.</cell><cell></cell></row><row><cell>[SHARE3]</cell><cell>17300</cell><cell>17300 shares</cell><cell></cell><cell></cell><cell></cell><cell cols="2">[PER2]</cell><cell>[SHARE2]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[SHARE4]</cell><cell>63750</cell><cell>63750 shares</cell><cell></cell><cell>8</cell><cell cols="6">After this overweight, Mr. [PER2] hold [SHARE2] of the company in total.</cell><cell></cell></row><row><cell>[SHARE5]</cell><cell>20675</cell><cell>20675 shares</cell><cell></cell><cell></cell><cell></cell><cell cols="2">[PER3]</cell><cell>[SHARE5]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[DATE1]</cell><cell>2018 12 21</cell><cell cols="2">Dec. 21st, 2018</cell><cell>10</cell><cell cols="6">After this overweight, Mr. [PER3] hold [SHARE5] of the company in total.</cell><cell></cell></row><row><cell>Figure 5:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>(abbreviated as "Tongyu Heavy Industries" or "the company") received the "Notifications on that reduced holding-share ratio of Tongyu Heavy Industries reached [RATIO2]" from the shareholder Mr. [PER1] , who hold the company equities more than [RATIO1], which stated that from [DATE2] to [DATE3], [PER1] sold some shares of the company via the block trading, ......, the detailed information is as follows:Figure 6: This case shows the typical false positive errors made by DCFEE models. Although the document only contains two distinct Equity Underweight events in total, different sentences mention these events multiple times (ID 4, 6 and 8). However, the key-sentence detection module of DCFEE models cannot differentiate duplicated event mentions elegantly. Therefore, both of them produce duplicated event records. Especially, DCFEE-M, guessing multiple event mentions from a single sentence, suffers severe false positive errors in this case. In contrast, our model is naturally robust to such data characteristics, since we conduct the event table filling at the document level. The only missing arguments, belong to the Later Holding Shares role, are partially caused by the restriction of the maximum sentence length at the input stage (ID 8).</figDesc><table><row><cell></cell><cell cols="7">Event Table (DCFEE-O, key sentences: 4, 6, 8) Event Table (DCFEE-O, key sentences: 14)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Event Table (Our Model)</cell></row><row><cell>Equity Holder Equity Holder</cell><cell cols="3">Traded Shares Froze Shares Legal Institution</cell><cell>Start Date Start Date</cell><cell>End Date End Date</cell><cell cols="4">Later Holding Shares Total Unfroze Holding Average Price Total Holding Date Shares Ratio</cell><cell></cell><cell>Equity Holder</cell><cell>Traded Shares</cell><cell>Start Date</cell><cell>End Date</cell><cell>Later Holding Shares</cell><cell>Average Price</cell></row><row><cell>[PER1]</cell><cell>[SHARE2]</cell><cell>[ORG3]</cell><cell></cell><cell>[DATE1]</cell><cell>NA</cell><cell>NA</cell><cell cols="2">[SHARE1]</cell><cell>[RATIO2]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[PER1]</cell><cell cols="2">[SHARE1]</cell><cell cols="2">[DATE2]</cell><cell>[DATE3]</cell><cell></cell><cell>NA</cell><cell></cell><cell>NA</cell><cell></cell><cell>[PER1]</cell><cell>[SHARE1]</cell><cell>[DATE2]</cell><cell>[DATE2]</cell><cell>NA</cell><cell>NA</cell></row><row><cell>[PER1]</cell><cell cols="2">[SHARE1]</cell><cell cols="2">[DATE2]</cell><cell>[DATE3]</cell><cell></cell><cell>NA</cell><cell></cell><cell>NA</cell><cell></cell><cell>[PER1]</cell><cell>[SHARE3]</cell><cell>[DATE3]</cell><cell>[DATE3]</cell><cell>NA</cell><cell>NA</cell></row><row><cell>[PER1]</cell><cell cols="2">[SHARE1]</cell><cell cols="2">[DATE2]</cell><cell>[DATE3]</cell><cell></cell><cell>NA</cell><cell></cell><cell>NA</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="6">Event Table (DCFEE-M, key sentences: 14)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Equity Holder</cell><cell cols="8">Event Table (DCFEE-M, key sentences: 4, 6, 8) Froze Shares Legal Institution Start Date End Date Total Unfroze Holding Date Shares</cell><cell>Total Holding Ratio</cell><cell></cell><cell></cell><cell cols="2">Event Table (Ground-truth)</cell></row><row><cell>Equity Holder [PER1]</cell><cell cols="2">Traded Shares [SHARE2] [ORG3]</cell><cell></cell><cell>Start Date [DATE1]</cell><cell>End Date NA</cell><cell cols="4">Later Holding Shares NA [SHARE1] Average Price [RATIO2]</cell><cell></cell><cell>Equity Holder</cell><cell>Traded Shares</cell><cell>Start Date</cell><cell>End Date</cell><cell>Later Shares Holding</cell><cell>Price Average</cell></row><row><cell>[PER1]</cell><cell cols="2">[SHARE1]</cell><cell cols="2">[DATE2]</cell><cell>[DATE3]</cell><cell>ID</cell><cell>NA</cell><cell></cell><cell>NA</cell><cell></cell><cell>[PER1]</cell><cell>[SHARE1] Sentence</cell><cell>[DATE2]</cell><cell>[DATE2]</cell><cell>[SHARE5]</cell><cell>NA</cell></row><row><cell>[PER1]</cell><cell cols="2">[SHARE1]</cell><cell cols="2">[DATE2]</cell><cell>[DATE1]</cell><cell></cell><cell>NA [ORG1]</cell><cell></cell><cell>NA</cell><cell>[DATE1]</cell><cell>[PER1]</cell><cell>[SHARE3] [ORG2]</cell><cell>[DATE3]</cell><cell>[DATE3] [PER1]</cell><cell>[SHARE6]</cell><cell>NA</cell></row><row><cell>[PER1]</cell><cell cols="2">[SHARE1]</cell><cell cols="2">[DATE3]</cell><cell>[DATE1]</cell><cell>3</cell><cell>NA</cell><cell></cell><cell>NA</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[PER1]</cell><cell cols="2">[SHARE3]</cell><cell cols="2">[DATE2]</cell><cell>[DATE1]</cell><cell></cell><cell>NA</cell><cell></cell><cell>NA</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[PER1]</cell><cell cols="2">[SHARE1]</cell><cell cols="2">[DATE2]</cell><cell>[DATE1]</cell><cell></cell><cell>NA</cell><cell></cell><cell>NA</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[PER1]</cell><cell cols="2">[SHARE5]</cell><cell cols="2">[DATE2]</cell><cell>[DATE1]</cell><cell></cell><cell>NA</cell><cell></cell><cell>NA</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Entity Mark Table</cell><cell></cell><cell></cell><cell>ID</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Sentence</cell></row><row><cell>Mark</cell><cell></cell><cell cols="3">Entity</cell><cell>Entity (English)</cell><cell></cell><cell></cell><cell cols="3">[DATE1] [ORG1] [RATIO2]</cell><cell></cell><cell cols="2">[RATIO1] [DATE2] [DATE3] [PER1]</cell><cell>[PER1]</cell></row><row><cell>[ORG1] [PER1] [DATE1] [DATE2] [DATE3]</cell><cell cols="3">2018 10 10 2014 6 23 2018 9 28</cell><cell cols="2">Tongyu Heavy Industry Co.,Ltd. Jinzhi Zhu Oct. 10th, 2018 Jun. 23nd, 2014 Sept. 28th, 2018</cell><cell></cell><cell cols="6">?? In [DATE1], [ORG1] 5 4 First, the information of this equity underweight</cell></row><row><cell cols="2">[SHARE1]</cell><cell cols="2">8000000</cell><cell cols="2">8000000 shares</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">[SHARE2]</cell><cell cols="2">900000000</cell><cell cols="2">900000000 shares</cell><cell></cell><cell></cell><cell cols="3">[PER1] [SHARE3] [DATE2]</cell><cell></cell><cell>[SHARE1] [RATIO4]</cell><cell>[SHARE2]</cell><cell>[RATIO3] [DATE3]</cell></row><row><cell cols="2">[SHARE3]</cell><cell cols="2">12090000</cell><cell cols="2">12090000 shares</cell><cell></cell><cell>6</cell><cell cols="6">In [DATE2], Mr. [PER1] sold [SHARE1] via the block trading, accounting for [RATIO3] of the capital stock of the</cell></row><row><cell cols="2">[SHARE4] [SHARE5]</cell><cell cols="2">80075625 72075625</cell><cell cols="2">80075625 shares 72075625 shares</cell><cell></cell><cell></cell><cell cols="6">company at that time; in [DATE3], he sold [SHARE3] again, accounting for [RATIO4] of the capital stock of the company currently.</cell></row><row><cell cols="2">[SHARE6]</cell><cell cols="2">204136875</cell><cell cols="2">204136875 shares</cell><cell></cell><cell>7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[RATIO1]</cell><cell></cell><cell></cell><cell cols="2">5%</cell><cell>5%</cell><cell></cell><cell></cell><cell cols="6">Second, the holding information before and after this equity underweight</cell></row><row><cell>[RATIO2] [RATIO4] [RATIO3]</cell><cell></cell><cell cols="3">1% 0.3700% 0.8889%</cell><cell>1% 0.3700% 0.8889%</cell><cell></cell><cell>8</cell><cell></cell><cell cols="5">[PER1] [SHARE5] ?? [DATE3] [PER1] [SHARE4] [SHARE3]</cell><cell>[SHARE2] [RATIO5] [DATE2] [SHARE6] ??</cell><cell>[SHARE1]</cell></row><row><cell>[RATIO5]</cell><cell></cell><cell cols="3">8.8973%</cell><cell>8.8973%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>Before this underweight, [PER1] hold [SHARE4] of the company, accounting for [RATIO5] of the total capital stock of the company, [SHARE2]; while in [DATE2], after selling [SHARE1], he hold [SHARE5] of the company; ??; In [DATE3], after selling [SHARE3], Mr. [PER1] hold [SHARE6] of the company.?</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>As of the date of this announcement, Fukong Media hold [SHARE1] of the company, accounting for [RATIO1] of the total share capital, where [SHARE1] is froze in turn; Mr. [PER1] hold [SHARE2] of the company, accounting for [RATIO2] of the total share capital, where [SHARE2] is froze in turn;</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Event Table (Our Model)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Equity Holder</cell><cell>Froze Shares</cell><cell>Legal Institution</cell><cell>Start Date</cell><cell>End Date</cell><cell>Unfroze Date</cell><cell>Total Holding Shares</cell><cell>Total Holding Ratio</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>[ORG2]</cell><cell>[SHARE1]</cell><cell>[ORG3]</cell><cell>[DATE1]</cell><cell>NA</cell><cell>NA</cell><cell>[SHARE1]</cell><cell>[RATIO2]</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>[PER1]</cell><cell>[SHARE2]</cell><cell>[ORG3]</cell><cell>[DATE1]</cell><cell>NA</cell><cell>NA</cell><cell>[SHARE2]</cell><cell>NA</cell></row><row><cell></cell><cell>Entity Mark Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Mark</cell><cell>Entity</cell><cell>Entity (English)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[DATE1]</cell><cell>2018 11 1</cell><cell>Nov. 1st, 2018</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[ORG1]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>[DATE1];</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>[SHARE1]</cell><cell cols="2">[RATIO1]</cell><cell cols="2">[SHARE1] [PER1]</cell><cell>[SHARE2]</cell></row><row><cell></cell><cell></cell><cell>14</cell><cell>[RATIO2]</cell><cell>[SHARE2]</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In this paper, we use "entity" as a general notion that includes named entities, numbers, percentages, etc., for brevity.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.ldc.upenn.edu/ collaborations/past-projects/ace</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Crawling from http://www.cninfo.com.cn/ new/index</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is supported in part by the National Natural Science Foundation of China (NSFC) Grant 61532001 and the Zhongguancun Haihua Institute for Frontier Information Technology.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The stages of event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">References</forename><surname>David Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Annotating and Reasoning about Time and Events</title>
		<meeting>the Workshop on Annotating and Reasoning about Time and Events</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
