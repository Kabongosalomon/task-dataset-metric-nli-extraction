<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Qingqing Long, Guojie Song, and Kunqing Xie. 2021. Spatial-Temporal Graph ODE Networks for Traffic Flow Forecasting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 14-18, 2021. August 14-18, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Fang</surname></persName>
							<email>fang_z@pku.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Long</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guojie</forename><surname>Song</surname></persName>
							<email>gjsong@pku.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunqing</forename><surname>Xie</surname></persName>
							<email>kunqing@cis.pku.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Machine Perception (Ministry of Education)</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Key Laboratory of Machine Perception (Ministry of Education)</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">Key Laboratory of Machine Perception (Ministry of Education)</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Qingqing Long, Guojie Song, and Kunqing Xie. 2021. Spatial-Temporal Graph ODE Networks for Traffic Flow Forecasting</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Singapore ACM Reference Format: Zheng Fang</title>
						<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD &apos;21)						</meeting>
						<imprint>
							<biblScope unit="volume">21</biblScope>
							<date type="published">August 14-18, 2021. August 14-18, 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3447548.3467430</idno>
					<note>* These authors contributed equally to the work. ? Work performed as a student of Peking University. ? Corresponding Author. 1 Codes are available at https://github.com/square-coder/STGODE ACM ISBN 978-1-4503-8332-5/21/08. . . $15.00 Event, Singapore. ACM, New York, NY, USA, 10 pages. https://</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Spatial-temporal forecasting has attracted tremendous attention in a wide range of applications, and traffic flow prediction is a canonical and typical example. The complex and long-range spatialtemporal correlations of traffic flow bring it to a most intractable challenge. Existing works typically utilize shallow graph convolution networks (GNNs) and temporal extracting modules to model spatial and temporal dependencies respectively. However, the representation ability of such models is limited due to: (1) shallow GNNs are incapable to capture long-range spatial correlations, (2) only spatial connections are considered and a mass of semantic connections are ignored, which are of great importance for a comprehensive understanding of traffic networks. To this end, we propose Spatial-Temporal Graph Ordinary Differential Equation Networks (STGODE). 1 . Specifically, we capture spatial-temporal dynamics through a tensor-based ordinary differential equation (ODE), as a result, deeper networks can be constructed and spatial-temporal features are utilized synchronously. To understand the network more comprehensively, semantical adjacency matrix is considered in our model, and a well-design temporal dialated convolution structure is used to capture long term temporal dependencies. We evaluate our model on multiple real-world traffic datasets and superior performance is achieved over state-of-the-art baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Information systems ? Spatial-temporal systems; ? Networks ? Network structure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Spatial-temporal forecasting has been widely studied in recent years. It has large scale applications in our daily life, such as traffic flow forecasting <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref>, climate forecasting <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15]</ref>, urban monitoring system analysis <ref type="bibr" target="#b21">[22]</ref> and so on. For this reason, accurate spatial-temporal forecasting plays a significant role in improving the service quality of these applications. In this paper, we study one of the most representative in spatial-temporal forecasting, traffic flow forecasting, which is an indispensable component in Intelligent Transportation System (ITS). Traffic flow forecasting attempts to predict the future traffic flow given historical traffic conditions and underlying road networks.</p><p>This task is challenging principally due to the complex and longrange spatial-temporal dependencies in traffic networks. As an intrinsic phenomenon of traffic, the travel distances of different people vary a lot <ref type="bibr" target="#b24">[25]</ref>, which means that nearby and distant spatial dependencies largely exist at the same time. <ref type="figure" target="#fig_0">As Fig 1(a)</ref> shows, a node is not only connected to its geographical neighbors but also distant relevant nodes. Furthermore, traffic flow series exhibit diversified temporal pattern for their distinct behavior attributes as <ref type="figure" target="#fig_0">Fig 1(b)</ref> shows. Moreover, when the spatial attributes and temporal patterns are united, the complex interactions in between leading to an intractable problem for traffic flow forecasting.</p><p>Graph Neural Networks (GNNs) for traffic forecasting have attracted tremendous attention in recent years. Owing to its strong ability to deal with graph-structured data, GNN enables to update node representations by aggregating representations from their neighbors, whereby GNN yields effective and efficient performance in various tasks like node classification and graph classification <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21]</ref>. A large number of works have been proposed to utilize GNNs to extract spatial features in traffic networks, STGCN [32] and DCRNN <ref type="bibr" target="#b17">[18]</ref> are the representative. Most of them combine GNNs with RNNs to obtain spatial representations and temporal representation respectively <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b34">35]</ref>, and multiple works improve recurrent structure with convolution structure for better training stability and efficiency <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>However, there are two problems that have been persistently neglected. On the one hand, most methods model spatial patterns and temporal patterns separately without considering their interactions, which restricts the representation ability of the models a lot. On the other hand, neural networks generally perform better with the stack of more layers, while GNNs benefit little from the depth. On the contrary, the best results are achieved when two-layer graph neural networks are cascaded, and more layers may lead to inferior performance in practice <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">36]</ref>. Ordinary GNNs have been proved to suffer from the over-smoothing problem, i.e. all node representations will converge to the same value with deeper layers. Such drawbacks severely limit the depth of GNNs and make it hardly possible to obtain deeper and richer spatial features. However, to the best of our knowledge, there are few works considering network depth in spatial-temporal forecasting, which is of great importance for capturing long-range dependencies.</p><p>In our Spatial-Temporal Graph Ordinary Differential Equation Network (STGODE), several components are elaborately designed to tackle the aforementioned problems. First, in order to depict spatial correlations from both geographical and semantic views, we construct two types of adjacency matrices, i.e. spatial adjacency matrix and semantic adjacency matrix, based on spatial connectivity and semantical similarity of traffic flow respectively. Second, motivated by residual networks <ref type="bibr" target="#b11">[12]</ref>, residual connections are added between layers to alleviate the over-smoothing problem. Furthermore, it is proved that the discrete layers with residual connections can be viewed as a discretization of an Ordinary Differential Equation (ODE) <ref type="bibr" target="#b4">[5]</ref>, and so a continuous graph neural network (CGNN) is derived <ref type="bibr" target="#b30">[31]</ref>. Here in this paper, a continuous GNN with residual connections is introduced to avoid the over-smoothing problem and hence be able to model long-range spatial-temporal dependencies. Last but not least, a spatial-temporal tensor is constructed to consider spatial and temporal patterns simultaneously and model complex spatial-temporal interactions. We present the superiority of our model with a toy example. As <ref type="figure">Fig 2 shows</ref>, compared with STGCN, STGODE possesses a wider receptive field and thus can adjust outputs according to shifting circumstances to achieve better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STGODE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STGCN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2: A performance schematic of STGODE</head><p>Our main contributions are summarized as follows,</p><p>? We propose a novel continuous representation of GNNs in tensor form for traffic flow forecasting, which breaks through the limit of network depth and improves the capacity of extracting longer-range spatial-temporal correlations, and a theoretical analysis is given in detail. ? We utilize both spatial neighbors and semantical neighbors of road nodes to consider spatial correlations comprehensively. ? Extensive experiments are conducted on real-world traffic datasets, and the results show that our model outperforms existing baseline models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Traffic Flow Forecasting</head><p>In recent years a large body of research has been conducted on traffic flow forecasting, which has always been a critical problem in intelligent transportation systems(ITS) <ref type="bibr" target="#b22">[23]</ref>. Traffic flow forecasting can be viewed as a spatial-temporal forecasting task leveraging spatial-temporal data collected by various sensors to predict future traffic conditions. Classic methods, including autoregressive integrated moving average (ARIMA), k-nearest neighbors algorithm (kNN), and support vector machine (SVM), can only take temporal information into account, without considering spatial features. <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref>. Due to the limitation of modeling complex spatial-temporal relationships with classical methods, deep neural network models are proposed, which have been widely used in various challenging traffic prediction tasks. Specifically, FC-LSTM combines CNN and LSTM to model spatial and temporal relations through an extended fully-connected LSTM with embedded convolutional layers <ref type="bibr" target="#b25">[26]</ref>. ST-ResNet utilizes a deep residual CNN network to predict citywide crowd flow <ref type="bibr" target="#b32">[33]</ref>, where the strong power of the residual network is exhibited. Despite impressive results that have been achieved, all above-mentioned methods are designed for grid data, thus not suitable for the traffic scene with graph-structured data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Neural Networks</head><p>GNN is an effective framework for the representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the computation of node representation is carried out by sampling and aggregating features of neighboring nodes <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b19">20]</ref>. Strenuous efforts have been made to utilize graph convolution methods in traffic forecasting considering that traffic data is a classic kind of non-Euclidean structured graph data. For example, DCRNN <ref type="bibr" target="#b17">[18]</ref> view the traffic flow as a diffusion process and captures the spatial dependency with bidirectional random walks on a directed graph. STGCN <ref type="bibr" target="#b31">[32]</ref> builds a model with complete convolutional structures on both spatial and temporal view, which enables faster training speed with fewer parameters. ASTGCN <ref type="bibr" target="#b9">[10]</ref> introduces attention mechanism to capture dynamics of spatial dependencies and temporal correlations. All these methods use two separate components to capture temporal and spatial dependencies respectively instead of simultaneously, thus STSGCN <ref type="bibr" target="#b26">[27]</ref> makes attempts to incorporate spatial and temporal blocks altogether through an elaborately designed spatial-temporal synchronous modeling mechanism. Long-range spatial-temporal relationship, as a common-sense in traffic circumstances, is expected to be explored with deeper neural networks. However, the over-smoothing phenomenon of deep GNNs, which has been proved in a great number of studies <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">36]</ref>, will lead to similar node representations. Thus the depth of GNNs is restricted, and the long-range dependencies between nodes are largely ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Continuous GNNs</head><p>Neural Ordinary Differential Equation(ODE) <ref type="bibr" target="#b4">[5]</ref> models a continuous dynamic system based on parameterizing the derivative of the hidden state using a neural network, instead of specifying discrete sequences of hidden layers. CGNN <ref type="bibr" target="#b30">[31]</ref> first extends this method to graph-structured data, which develops a continuous message-passing layer through defining the derivatives as combined representations of current and initial nodes. The key factor for alleviating the over-smoothing effect is the use of restart distribution, which motivates us in this paper. With proving simple GCN as a discretization of a kind of ODE, they characterize the continuous dynamics of node representations and enable deeper networks. To the best of our knowledge, there are no works about graph ODE in spatial-temporal forecasting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES Definition 1. (Traffic network G)</head><p>We represent the road network as a graph G = ( , , ), where is a set of nodes; E is a set of edges; ? R ? is an adjacency matrix. Here in this paper, two kinds of adjacency matrix are adopted, spatial adjacency matrix and semantic adjacency matrix .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2. (Graph signal tensor X)</head><p>We use x ? R to denote the observation of node at time , and is the length of an observation vector. = x 1 , x 2 , ? ? ? , x ? R ? denotes the observations of all nodes at time . X = ( 1 , 2 , ? ? ? , ) ? R ? ? denotes the observations of all nodes at all time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Formulation</head><p>Given the tensor X observed on a traffic network G, the goal of traffic forecasting is to learn a mapping function from the historical observations to predict future ? traffic observations,</p><formula xml:id="formula_0">[ ? +1 , ? +2 , ? ? ? , ; G] ?? [ +1 , +2 , ? ? ? , + ? ] .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Regularized adjacency matrix</head><p>Given an adjacency matrix ? R ? , we typically normalize it</p><formula xml:id="formula_1">as?= ? 1 2 ? 1 2 ,</formula><p>where is the degree matrix of .?has an eigenvalue decomposition <ref type="bibr" target="#b5">[6]</ref> and the eigenvalues are in the interval [?1, 1]. Negative eigenvalues can lead to unstable training process, thus a self-loop is commonly added to avoid it. The regularized form <ref type="bibr" target="#b15">[16]</ref> of?is adopted in this paper:</p><formula xml:id="formula_2">= 2 + ? 1 2 ? 1 2 ,<label>(1)</label></formula><p>where ? (0, 1) is a hyperparameter, as a result the eigenvalues of are in the interval [0, ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Neural ODE</head><p>We consider a continuous-time(depth) model,</p><formula xml:id="formula_3">x( ) = x(0) + ? 0 dx d d = x(0) + ? 0 (x( ), )d ,<label>(2)</label></formula><p>where (x( ), ) will be parameterised by a neural network to model the hidden dynamic. We can backpropagate the process through an ODE solver without any internal operations <ref type="bibr" target="#b4">[5]</ref>, which allows us to build it just as a block for the whole neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Tensor Calculation</head><p>A tensor T can be viewed as a multidimensional array, and a tensormatrix multiplication is defined on some mode fiber, for example,</p><formula xml:id="formula_4">(T ? 2 ) = 2 ?? =1 T ? ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_5">T ? R 1 ? 2 ? 3 , ? R 2 ? ? 2 , T ? 2 ? R 1 ? ? 2 ? 3 , ? 2</formula><p>denotes that the tensor-matrix multiplication is conducted on mode-2, i.e. the second subscript. There are some mathematical properties about tensor-matrix multiplication which will be used in this paper,</p><formula xml:id="formula_6">? T ? 1 ? 2 = T ? ( 1 2 ) ? T ? 1 ? 2 = T ? 2 ? 1 ( ? ).</formula><p>Above properties can be easily proved with Eq 3 through the multiplication rule. <ref type="figure" target="#fig_1">Figure 3</ref>(a) shows the overall framework of our proposed model, i.e. Spatial-Temporal Graph ODE. It mainly consists of three components, two Spatial-Temporal Graph ODE (STGODE) layers composed of multiple STGODE blocks, a max-pooling layer, and an output layer. A STGODE block consists of two temporal dilation convolution (TCN) blocks and a tensor-based ODE solver in between, which is applied to capture complex and long-range spatialtemporal relationships simultaneously. The spatial adjacency matrix and the semantical adjacency matrix will be fed into the solver separately to obtain features from different levels. The details of the model will be described in the following section.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MODEL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Adjacency Matrix Construction</head><p>Two kinds of adjacency matrix are leveraged in our model. Following STGCN <ref type="bibr" target="#b31">[32]</ref>, the spatial adjacency matrix is defined as</p><formula xml:id="formula_7">= ? ? ? ? ? ? ? ? ? exp ? 2 2 , if exp ? 2 2 ? 0 , otherwise ,<label>(4)</label></formula><p>where is the distance between node and node . <ref type="bibr" target="#b1">2</ref> and are thresholds to control sparsity of matrix . Besides, contextual similarities between nodes provide a wealth of information and should be taken into consideration. For example, similar traffic patterns are shared among roads near commercial areas regardless of the remote geographical distance, while such correlations cannot be revealed in spatial graph. To capture above mentioned semantic correlations, the Dynamic Time Warping (DTW) algorithm is applied to calculate the similarity of two time series <ref type="bibr" target="#b0">[1]</ref>, which is superior to other metric methods on account of its sensitivity to shape similarity rather than point-wise similarity. As shown in <ref type="figure" target="#fig_3">Fig 4,</ref> the point of series X will be related to the point but not of series Y by the DTW algorithm. Specifically, given two time series = ( 1 , 2 , ? ? ? , ) and = ( 1 , 2 , ? ? ? , ), DTW is a dynamic programming algorithm defined as</p><formula xml:id="formula_8">( , ) = ( , ) +min ( ( ? 1, ), ( , ? 1), ( ? 1, ? 1)) ,<label>(5)</label></formula><p>where ( , ) represents the shortest distance between subseries = ( 1 , 2 , ? ? ? , ) and = ( 1 , 2 , ? ? ? , ), and ( , ) is some distance metric like absolute distance. As a result, ( , ) = ( , ) is set as the final distance between and , which better reflects the similarity of two time series compared to the Euclidean distance.  Accordingly, we define the semantic adjacency matrix through the DTW distance as following,</p><formula xml:id="formula_9">= 1, ( , ) &lt; 0, otherwise<label>(6)</label></formula><p>where denotes time series of node , and determine the sparsity of the adjacency matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Tensor-based Spatial-Temporal Graph ODE</head><p>GNNs update embeddings of nodes through aggregating features of their own and neighbors with a graph convolution operation. The classic form of convolution operation can be formulated as:</p><formula xml:id="formula_10">+1 = ( ) = (?),<label>(7)</label></formula><p>where ? R ? denotes the input of the -th graph convolutional layer,?? R ? is the normalized adjacency matrix, and ? R ? ? is a learnable parameter matrix, which models the interaction among different features. However, such GNNs have been proved to suffer from over-smoothing problem when networks go deeper <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">36]</ref>, which largely limits the capacity of modeling long-range dependencies. For this reason, our STGODE block is proposed.</p><p>A discrete version is first shown as:</p><formula xml:id="formula_11">H +1 = H ? 1??2 ? 3 + H 0 ,<label>(8)</label></formula><p>where H ? R ? ? is a spatial-temporal tensor representing nodes' hidden embedding of the -th layer, ? denotes the tensormatrix multiplication on mode ,?is the regularized adjacency matrix, is the temporal transform matrix, is the feature transform matrix, and H 0 denotes the initial input of GNN, which can be acquired through another neural network. Different from existing works, we treat the spatial-temporal tensor as input and hence enable to handle spatial information and temporal information simultaneously. The intricate spatial-temporal correlation is coupled through tensor multiplication on each mode. Motivated by CGNN <ref type="bibr" target="#b30">[31]</ref>, a restart distribution H 0 is involved to alleviate the over-smoothing problem. Specifically, the expansion of Eq 8 is shown as below,</p><formula xml:id="formula_12">H = ?? =0 H 0 ? 1??2 ? 3 ,<label>(9)</label></formula><p>where we can see clearly that the output representation H aggregates information from all layers, that's to say, the final outputs collect information from all no more than -order neighbors without losing initial features. To show the necessity of the restart distribution, let's suppose another version without H 0 like</p><formula xml:id="formula_13">H +1 = H ? 1??2 ? 3 ,</formula><p>where the final output will be</p><formula xml:id="formula_14">H = H 0 ? 1??2 ? 3 .</formula><p>Take?as a simple example, assuming?has an eigenvalue decomposition as?= ? , where ? = diag( 1 , 2 , ? ? ? , ) is a diagonal matrix. Obviously, = diag 1 , 2 , ? ? ? , = 1 diag 1, (</p><p>) , ? ? ? , ( 1 ) ?? 1 diag (1, 0, ? ? ? , 0)</p><p>when n goes to infinity with 1 &gt; 2 &gt; ? ? ? . The diagonal elements converge to zero except the largest one, which causes much loss of information. Such residual structure as Eq 8 is powerful but tough to train due to its enormous amount of parameters, thus we aim to extend the discrete formulation to a continuous expression. Intuitively, we replace with a continuous variable , and view the expansion equation as a Riemann sum from 0 to on , which is,</p><formula xml:id="formula_17">H = ?? =0 H 0 ? 1??2 ? 3 = +1 ?? =1 H 0 ? 1?( ?1)?? ? 2 ( ?1)?? ? 3 ( ?1)?? ?<label>(11)</label></formula><p>where ? = +1 +1 with = . When n goes to ?, we can formulate the following integral:</p><formula xml:id="formula_18">H ( ) = ? +1 0 H 0 ? 1??2 ? 3 d ,<label>(12)</label></formula><p>The critical point here is to transform the residual structure to an ODE structure, obviously we already have an ordinary differential equation given by</p><formula xml:id="formula_19">dH ( ) d = H 0 ? 1?+ 1 ? 2 +1 ? 3 +1 ,<label>(13)</label></formula><p>but?+ 1 , +1 , +1 are intractable to compute especially when t is a non-integer. Motivated by the work in <ref type="bibr" target="#b30">[31]</ref>, we have the following corollary.</p><p>Corollary 1. The discrete update in Eq 8 is a discretization of following ODE:</p><formula xml:id="formula_20">dH ( ) d = H ( ) ? 1 ln?+ H ( ) ? 2 ln + H ( ) ? 3 ln + H 0 ,<label>(14)</label></formula><p>where H 0 = (X) is the output of upstream networks.</p><p>Proof. Starting from Eq 13, we consider the second-derivative of H ( ) through derivative rules,</p><formula xml:id="formula_21">d 2 H ( ) d 2 = dH ( ) d ? 1 ln?+ dH ( ) d ? 2 ln + dH ( ) d ? 3 ln<label>(15)</label></formula><p>Then integrate over in both sides of the above equation, we can get:</p><formula xml:id="formula_22">dH ( ) d = H ( ) ? 1 ln?+ H ( ) ? 2 ln + H ( ) ? 3 ln +<label>(16)</label></formula><p>To solve the , we can put Eq 13 and Eq 16 together, thus we have:</p><formula xml:id="formula_23">=H 0 ? 1?+ 1 ? 2 +1 ? 3 +1 ? H ( ) ? 1 ln?+ H ( ) ? 2 ln + H ( ) ? 3 ln .<label>(17)</label></formula><p>By letting ? ?1 mathematically, we can easily get = H 0 . So the corollary is proved. ?</p><p>In practice, we can approximate the logarithm operation with its first order of Taylor expansion, i.e. ln ? ? . As a result, a simpler form is obtained,</p><formula xml:id="formula_24">dH ( ) d = H ( ) ? 1 (?? ) + H ( ) ? 2 ( ? ) + H ( ) ? 3 ( ? ) + H 0<label>(18)</label></formula><p>(a) ODE Solver (b) TCN <ref type="figure">Figure 5</ref>: (a) is the illustration of a ODE solver, which shows that the derivation of the hidden states is a function of current states and initial states. (b) represents the structure of TCN, which consists of a dilated convolution and a residual connection.</p><p>The above ODE we deduced can be analytically solved as the following corollary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 2. The analytic solution of the Eq 18 is given by</head><formula xml:id="formula_25">H ( ) =H 0 ? 1 (?? ) ? 2 ( ? ) ? 3 ( ? ) + ? 0 H 0 ? 1 (?? ) ( ? ) ? 2 ( ? ) ( ? ) ? 3 ( ? ) ( ? ) d<label>(19)</label></formula><p>Proof. Suppose</p><formula xml:id="formula_26">H * ( ) = H ( ) ? 1 (?? ) ? 2 ( ? ) ? 3 ( ? ) ,<label>(20)</label></formula><p>then we have dH * ( ) d</p><formula xml:id="formula_27">=H 0 ? 1 (?? ) ? 2 ( ? ) ? 3 ( ? ) ,<label>(21)</label></formula><p>and this is derived from Eq 18. Integrate Eq 21 on both sides, and we can get the following result,</p><formula xml:id="formula_28">H * ( ) = H * 0 + ? 0 H 0 ? 1 (?? ) ? 2 ( ? ) ? 3 ( ? ) d ,<label>(22)</label></formula><p>and hence H ( ) can be formulated as</p><formula xml:id="formula_29">H ( ) =H 0 ? 1 (?? ) ? 2 ( ? ) ? 3 ( ? ) + ? 0 H 0 ? 1 (?? ) ( ? ) ? 2 ( ? ) ( ? ) ? 3 ( ? ) ( ? ) d (23) ?</formula><p>In fact, the last integration can be solved further, but limited by space, we put it in the supplementary. Notice that the eigenvalues of?? is in the interval [?1, 0), as a result, (?? ) will go to zero when t goes to ?. However, unrestricted and will lead to divergent integrations as t goes to ?. To enforce and to be a diagonalizable matrix with all the eigenvalues less than 1, we follow previous work <ref type="bibr" target="#b6">[7]</ref> to parameterise and as = ( ) and = ( ) respectively, where and are learnable orthogonal matrices, and are learnable vectors whose elements will be clamped to the interval (0, 1).</p><p>So far, we have proved a continuous form of tensor-based hidden representation theoretically. Motivated by Neural ODE <ref type="bibr" target="#b4">[5]</ref>, we propose an STGODE learning framework,</p><formula xml:id="formula_30">H ( ) = dH ( ) d , H 0 , ,<label>(24)</label></formula><p>where</p><formula xml:id="formula_31">dH ( ) d = H ( ) ? 1 (?? ) + H ( ) ? 2 ( ? ) + H ( ) ? 3 ( ? ) + H 0 ,</formula><p>H 0 denotes the initial value, which comes from the upstream network and the ODESolver is chosen as the Euler solver in our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Temporal Convolutional Blocks</head><p>Besides spatial correlations among different nodes, the long-term temporal correlations of the nodes themselves also matter. Although RNN-based models, like LSTM and GRU, are widely applied in timeseries analysis, recurrent networks still suffer from some intrinsic drawbacks like time-consuming iterations, unstable gradients, and delayed responses to dynamic changes.</p><p>To enhance the performance of extracting long term temporal dependencies, a 1-D dilated temporal convolutional network along the time axis is adopted here.</p><formula xml:id="formula_32">= , = 0 ( * ?1 ) , = 1, 2, ? ? ? ,<label>(25)</label></formula><p>where ? R ? ? is the input of TCN, ? R ? ? is the output of the -th layer of TCN, and denotes the -th convolution kernel. To expand the receptive field , an exponential dilation rate = 2 ?1 is adopted in temporal convolution. In the process, zero-padding strategy is utilized to keep time sequence length unchanged. What's more, a residual structure <ref type="bibr" target="#b11">[12]</ref> is added to strengthen convolution performance as shown in <ref type="figure">Fig 5(b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">STGODE Layer</head><p>In this part, the overall STGODE layer is presented in detail. As illustrated in <ref type="figure" target="#fig_1">Fig 3(b)</ref>, the "sandwich" structure is adopted which consist of two TCN blocks and a STGODE solver. Such structure enables flexible and sensible spatial-temporal information flows, and all-convolution structures have the superiority of fast training and parallelization. Stacked "sandwiches" further extend the model's ability to discover complex correlations.</p><p>In the construction of the model, we deploy two kinds of STGODE blocks, which accept different adjacency matrices, i.e. the spatial adjacency matrix and the semantic adjacency matrix. Two kinds of adjacency matrices are utilized to combine local dynamics and semantical relationships altogether, which greatly enhance the representation ability. Multiple blocks are deployed in parallel so that more complicated and multi-level correlations can be captured.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Others</head><p>After the STGODE layers, a max-pooling operation is carried out to aggregate information from different blocks selectively. Finally, a two-layer MLP is designed as the output layer to transform the output of the max-pooling layer to the final prediction.</p><p>Huber loss is selected as the loss function since it is less sensitive to outliers than the squared error loss <ref type="bibr" target="#b12">[13]</ref>,</p><formula xml:id="formula_33">( ,?) = ? ? ? ? ? ? ? ? ? 1 2 ( ??) 2 , | ??| ? | ??| ? 1 2 2 , otherwise<label>(26)</label></formula><p>where is a hyperparameter which controls the sensitivity to outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS 5.1 Datasets</head><p>We verify the performance of STGODE on six real-world traffic datasets, PeMSD7(M), PeMSD7(L), PeMS03, PeMS04, PeMS07, and PeMS08, which are collected by the Caltrans Performance Measurement System(PeMS) in real time every 30 seconds <ref type="bibr" target="#b3">[4]</ref>. The traffic data are aggregated into 5-minutes intervals, which means there are 288 time steps in the traffic flow for one day. The system has more than 39,000 detectors deployed on the highway in the major metropolitan areas in California. There are three kinds of traffic measurements contained in the raw data, including traffic flow, average speed, and average occupancy. Specifically, PeMSD3 has 358 sensors, and the time span of it is from September to November in 2018, including 91 days in total. PeMSD7(M) and PeMSD7(L) are two datasets selected from District 7 of California, which contains 288 and 1,026 sensors respectively. The time range of PeMSD7 is in the weekdays of May and June of 2012. And PeMSD8 is collected from July to August in 2016, which contains 170 sensors. The detail of datasets is listed in <ref type="table">Table 1</ref>. Zscore normalization is applied to the input data, i.e. removing the mean and scaling to unit variance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baselines</head><p>We compare STODE with following baseline models:</p><p>? ARIMA [2]: Auto-Regressive Integrated Moving Average model, which is a well-known statistical model of time series analysis. ? STGCN <ref type="bibr" target="#b31">[32]</ref>: Spatio-Temporal Graph Convolution Network, which utilizes graph convolution and 1D convolution to capture spatial dependencies and temporal correlations respectively. ? DCRNN <ref type="bibr" target="#b17">[18]</ref>: Diffusion Convolution Recurrent Neural Network, which integrates graph convolution into an encoderdecoder gated recurrent unit. ? GraphWaveNet <ref type="bibr" target="#b29">[30]</ref>: Graph WaveNet, which combines adaptive graph convolution with dilated casual convolution to capture spatial-temporal dependencies. ? ASTGCN(r) <ref type="bibr" target="#b9">[10]</ref>: Attention based Spatial Temporal Graph Convolutional Networks, which utilize spatial and temporal attention mechanisms to model spatial-temporal dynamics respectively. In order to keep the fairness of comparison, only recent components of modeling periodicity are taken. ? STSGCN <ref type="bibr" target="#b26">[27]</ref>: Spatial-Temporal Graph Synchronous Graph Convolutional Networks, which utilize multiple localized spatial-temporal subgraph modules to synchronously capture the localized spatial-temporal correlations directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experimental Settings</head><p>We split all datasets with a ratio 6: 2: 2 into training sets, validation sets, and test sets. One hour of historical data is used to predict traffic conditions in the next 60 minutes. All experiments are conducted on a Linux server(CPU: Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz, GPU: NVIDIA TESLA V100 16GB). The hidden dimensions of TCN blocks are set to 64, 32, 64, and 3 STGODE blocks are contained in each layer. The regularized hyperparameter is set to 0.8, the thresholds and of the spatial adjacency matrix are set to 10 and 0.5 respectively, and the threshold of the semantic adjacency matrix is set to 0.6. We train our model using Adam optimizer with a learning rate of 0.01. The batch size is 32 and the training epoch is 200. Three kinds of evaluation metrics are adopted, including root mean squared errors(RMSE), mean absolute errors(MAE), and mean absolute percentage errors(MAPE). <ref type="table" target="#tab_3">Table 2</ref> shows the results of our and competitive models for traffic flow forecasting. Our STGODE model is obviously superior to the baselines. Specifically, deep learning methods achieve better results than traditional statistical methods, as traditional methods like ARIMA only take temporal correlations into consideration and ignore spatial dependencies, whereas deep learning models can take advantage of spatial-temporal information. Among the deep learning baselines, all except STSGCN utilize two modules to model spatial dependencies and temporal correlations respectively, which overlook complex interactions between spatial information and temporal information, and STSGCN hence surpasses other models. But STSGCN only concentrates on localized spatial-temporal correlations, and turns turtle in global dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experimental Results and Analysis</head><p>Our model yields the best performance regarding all the metrics for all datasets, which suggests the effectiveness of our spatialtemporal dependency modeling. The result can be attributed to three aspects:</p><p>(1) We utilize a tensor-based ODE framework to extract longerrange spatial-temporal dependencies; (2) The semantical neighbors are introduced to establish global and comprehensive spatial relationships; (3) Temporal dilated convolution networks with residual connections help to capture long term temporal dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Case Study</head><p>Here we select two nodes from the road network to carry out a case study. As <ref type="figure" target="#fig_4">Fig 6 shows</ref>, the prediction results of STGODE are remarkably closer to the ground truth than STGCN <ref type="bibr" target="#b31">[32]</ref>. In normal circumstances, the model generates a smooth prediction ignoring small oscillations to fight against noise. But when an abrupt change arises, our model enables a rapid response to it. This is because STGODE is able to utilize feature information from longer range geographical neighbors and semantic neighbors, which helps to accurately capture real-time dynamics and filter invalid information, while STGCN as a shallow network, is susceptible to few nearby neighbors and thus performs unstably.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Model Analysis</head><p>which means that the input tensor will be viewed as multiple matrices separately without considering temporal feature transform in ODE blocks. The results are presented in <ref type="figure">Fig 7.</ref> Here we put STGCN and our STGCN* together on account of their similar sandwich structures and the same way of convolution. The result shows that our STGCN* performs much better than previous STGCN, which is contributed to our novel temporal convolution and the introduction of  <ref type="figure">Figure 7</ref>: Ablation experiments of STGODE semantical neighbors, and the poor result of STGODE with only spatial neighbors reinforces the latter point. The performance of the matrix-based version is also inferior to the tensor-based one, as it is incapable to consider spatial-temporal dependency simultaneously. And the result of STGODE without H 0 shows the importance of connecting the initial state. 5.6.2 Parameter Analysis. One major advantage of our STGODE model over other existing methods is that is robust to the oversmoothing problem and thus capable to construct deeper network structures. Here in <ref type="figure" target="#fig_6">Fig 8,</ref> we represent the performance of STGODE and STGCN* under different depths, i.e. the input time length of STGODE solver and the number of convolution layers in STGCN*. It is easy to see that, as the network depth increases, the performance of STGCN* drops dramatically while the performance of our model is stable, which clearly shows the strong robustness of our model to extract longer-range dependencies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>A tremendous number of works have been proposed to tackle the complex spatial-temporal problems, but few of them focus on how to extract long-range dependencies without being affected by the over-smoothing problem. In this paper, we present a novel tensorbased spatial-temporal forecasting model named STGODE. To the best of our knowledge, this is the first attempt to bridge continuous differential equations to the node representations of road networks in the area of traffic, which enables to construct deeper networks and leverage wider-range dependencies. Furthermore, the participation of semantic neighbors largely enhances the performance of the model. Extensive experiments prove the effectiveness of STGODE over many existing methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(a) shows the geographical and semantic connections of nodes. (b) shows examples of traffic flow with diverse patterns, like morning peak, evening peak and relatively steady patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>(a) is the framework of the STGODE network. Several STGODE blocks in parallel constitute a STGODE layer, and two STGODE layers are cascaded to extract higher-order features. (b) is the detail of STGODE blocks, where an ODE solver is sandwiched between two TCNs with residual connections and two kinds of adjacency matrices are utilized for more comprehensive characterization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>An example of the difference between the Euclidean distance and the DTW distance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>The comparison of prediction results between our model and STGCN. ? STGODE only spatial: This model does not consider semantic neighbors to verify the necessity of introducing a semantic adjacency matrix. ? STGODE-no-h0: The initial state is removed in the derivation of hidden states (Eq 14). ? STGODE-matrix-based: Reformulate the tensor-based ODE (Eq 14) to a matrix-based version as following, d ( ) d = ln?( ) + ( ) ln + 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>The performance of STGODE and STGCN when the network depth increasing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison of baseline models and STGODE on PeMS datasets.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">APPENDIX 7.1 The calculation of the integration in Eq 19</head><p>Proof. Suppose?? , ? , ? have eigenvalue decomposi-</p><p>consider the integral element-wise, then we have,</p><p>thus, the result of the integration is as the following, ?</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Using dynamic time warping to find patterns in time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Berndt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD workshop</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="359" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Distribution of residual autocorrelations in autoregressive-integrated moving average time series models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David A</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pierce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American statistical Association</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="1509" to="1526" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Making short-term climate forecasts useful: Linking science and action</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Buizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharine</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="4597" to="4602" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Freeway performance measurement system: mining loop detector data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Petty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Skabardonis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Record</title>
		<imprint>
			<biblScope unit="volume">1748</biblScope>
			<biblScope unit="page" from="96" to="102" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>Pravin Varaiya, and Zhanfeng Jia</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duvenaud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.07366</idno>
		<title level="m">Neural ordinary differential equations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><forename type="middle">Chung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Graham</surname></persName>
		</author>
		<title level="m">Spectral graph theory. Number 92</title>
		<imprint>
			<publisher>American Mathematical Soc</publisher>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Parseval networks: Improving robustness to adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. PMLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="854" to="863" />
		</imprint>
	</monogr>
	<note>Yann Dauphin, and Nicolas Usunier</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Traffic flow forecasting based on hybrid deep learning framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengdong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianrui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi Jinn</forename><surname>Horng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 12th international conference on intelligent systems and knowledge engineering (ISKE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">GSTNet: Global Spatial-Temporal Network for Traffic Flow Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Shen Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2286" to="2293" />
		</imprint>
	</monogr>
	<note>Shiming Xiang, and Chunhong Pan</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Attention based spatial-temporal graph convolutional networks for traffic flow forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="922" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02216</idno>
		<title level="m">Inductive representation learning on large graphs</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust estimation of a location parameter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Breakthroughs in statistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="492" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Supervised weighting-online learning algorithm for short-term traffic flow prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Seon</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Ji</forename><surname>Byon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manoel</forename><surname>Mendonca Castro-Neto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Said</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Easa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1700" to="1707" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">How machine learning could help to improve climate forecasts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature News</title>
		<imprint>
			<biblScope unit="volume">548</biblScope>
			<biblScope unit="page">379</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deeper insights into graph convolutional networks for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qimai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao-Ming</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rose</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Graph Structuraltopic Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guojie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1065" to="1073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guojie</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.02995</idno>
		<title level="m">Theoretically Improving Graph Neural Networks via Anonymous Walk Graph Kernels</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hierarchical Community Structure Preserving Network Embedding: A Subspace Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guojie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="409" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Crowd-sourced data collection for urban monitoring via mobile sensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonella</forename><surname>Longo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Zappatore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Bochicchio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shamkant B Navathe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Internet Technology (TOIT)</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Survey on traffic prediction in smart cities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Attila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vilmos</forename><surname>Nagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pervasive and Mobile Computing</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="148" to="163" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Urban traffic prediction from spatio-temporal data using deep meta learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheyi</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1720" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On the distribution of individual daily driving distances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pl?tz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niklas</forename><surname>Jakobsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frances</forename><surname>Sprei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation research part B: methodological</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="213" to="227" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjian</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhourong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dit</forename><forename type="middle">Yan</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><forename type="middle">Kin</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangchun</forename><surname>Woo</surname></persName>
		</author>
		<title level="m">Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting. Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Spatialtemporal synchronous graph convolutional networks: A new framework for spatial-temporal network data forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="914" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Short-term traffic and travel time prediction models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jwc Van Lint</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Hinsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Applications to Critical Transportation Issues</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="22" to="41" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Modeling and forecasting vehicular traffic flow as a seasonal ARIMA process: Theoretical basis and empirical results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Billy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of transportation engineering</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="664" to="672" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Graph WaveNet for Deep Spatial-Temporal Graph Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 28th International Joint Conference on Artificial Intelligence (IJCAI). International Joint Conferences on Artificial Intelligence Organization</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Continuous graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Pascal</forename><surname>Xhonneux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. PMLR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10432" to="10441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph convolutional networks: a deep learning framework for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoteng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3634" to="3640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep spatio-temporal residual networks for citywide crowd flows prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Shiming Xiang, and Chunhong Pan. 2020. Spatio-temporal graph structure learning for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1177" to="1185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">T-gcn: A temporal graph convolutional network for traffic prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujiao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3848" to="3858" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganqu</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changcheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.08434</idno>
		<title level="m">Graph neural networks: A review of methods and applications</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
