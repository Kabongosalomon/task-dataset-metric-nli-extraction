<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Support Few-Shot Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Fan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">HKUST</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Pei</surname></persName>
							<email>wenjiecoder@outlook.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Tai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">HKUST</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Kuaishou Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Keung</forename><surname>Tang</surname></persName>
							<email>cktang@cs.ust.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">HKUST</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Self-Support Few-Shot Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T18:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>few-shot semantic segmentation</term>
					<term>self-support prototype (SSP)</term>
					<term>self-support matching</term>
					<term>adaptive background prototype generation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing few-shot segmentation methods have achieved great progress based on the support-query matching framework. But they still heavily suffer from the limited coverage of intra-class variations from the few-shot supports provided. Motivated by the simple Gestalt principle that pixels belonging to the same object are more similar than those to different objects of same class, we propose a novel self-support matching strategy to alleviate this problem, which uses query prototypes to match query features, where the query prototypes are collected from high-confidence query predictions. This strategy can effectively capture the consistent underlying characteristics of the query objects, and thus fittingly match query features. We also propose an adaptive self-support background prototype generation module and self-support loss to further facilitate the self-support matching procedure. Our self-support network substantially improves the prototype quality, benefits more improvement from stronger backbones and more supports, and achieves SOTA on multiple datasets. Codes are at https://github.com/fanq15/SSP.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic segmentation has achieved remarkable advances tapping into deep learning networks <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b33">34]</ref> and large-scale datasets such as <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b93">93]</ref>. However, current high-performing semantic segmentation methods rely heavily on laborious pixel-level annotations, which has expedited the recent development of few-shot semantic segmentation (FSS).</p><p>Few-shot semantic segmentation aims to segment arbitrary novel classes using only a few support samples. The dilemma is that the support images are limited and fixed (usually {1, 3, 5, 10} supports per class), while the query images can be massive and arbitrary. Limited few-shot supports can easily fail to cover underlying appearance variations of the target class in query images, regardless of the support quality. This is clearly caused by the inherent data scarcity and diversity, two long standing issues in few-shot learning.  <ref type="figure">Fig. 1</ref>. The left image illustrates the core idea of our self-support matching. We use the initial query mask prediction to collect query features in high-confidence regions and then use the generated query prototype to perform self-matching with query features. The right top image illustrates the motivation of our self-support matching: pixels/regions of the same objects are more similar than those from different objects. The numbers in boxes represent the cosine similarities between two objects. The right bottom image illustrates that our self-support matching is fundamentally distinct from conventional matching methods.</p><p>Existing methods try to solve the problem by making full use of the limited supports, such as proposing better matching mechanism <ref type="bibr" target="#b70">[70,</ref><ref type="bibr" target="#b54">54,</ref><ref type="bibr" target="#b83">83,</ref><ref type="bibr" target="#b74">74,</ref><ref type="bibr" target="#b87">87,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b96">96]</ref> or generating representative prototypes <ref type="bibr" target="#b71">[71,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b64">64,</ref><ref type="bibr" target="#b56">56,</ref><ref type="bibr" target="#b82">82,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b62">62,</ref><ref type="bibr" target="#b81">81,</ref><ref type="bibr" target="#b88">88,</ref><ref type="bibr" target="#b26">27]</ref>. Despite their success, they still cannot fundamentally solve the appearance discrepancy problem, bounded by the scarce few-shot supports.</p><p>We propose a novel self-support matching strategy to narrow the matching appearance discrepancy. This strategy uses query prototypes to match query features, or in other words, use the query feature to self-support itself. We thus call the query prototype as self-support prototype because of its self-matching property. This new idea is motivated by the classical Gestalt law <ref type="bibr" target="#b40">[41]</ref> that pixels belonging to the same object are more similar than those to different objects.</p><p>Refer to <ref type="figure">Figure 1</ref> for a high-level understanding of our novel self-support matching. First we generate the initial mask predictions by directly matching the support prototype and query features. Based on the initial query mask, we collect confident query features to generate the self-support prototype, which is used to perform matching with query features. Our self-support module (SSM) collects confident features of the cat head which are used to segment the entire black cat. Our model is optimized on base classes to retrieve other object parts supported by object fragments, i.e., self-support prototype.</p><p>We apply our self-support module on both foreground and background prototypes for self-support matching. While SSM directly benefits foreground prototypes, note that the background is usually cluttered, which does not have the global semantic commonality shared among all background pixels. Thus, rather than generating a global background prototype by aggregating all the background pixels, we propose to adaptively generate self-support background prototypes for each query pixel, by dynamically aggregating similar background pixels in the query image. The adaptive self-support background prototype (ASBP)</p><p>is motivated by the fact that separate background regions have local semantic similarity. Finally, we propose a self-support loss (SSL) to further facilitate the self-support procedure.</p><p>Our self-support matching strategy is thus fundamentally different than conventional support-query matching. We use the flexible self-support prototypes to match query features, which can effectively capture the consistent underlying characteristics of the query objects, and thus fittingly match query features. As shown in <ref type="figure">Figure 1</ref>, the cats in the query and support images are very different in color, parts and scales, The garfield cat support has large appearance discrepancy to the black cat query, and undoubtedly conventional support-query matching produces inferior segmentation. In our self-support matching, our self-support prototype (the black cat head) is more consistent to the query (the entire black cat), and thus our method produces satisfactory results.</p><p>We are the first to perform self-support matching between query prototype and query features. As shown in <ref type="figure">Figure 1</ref>, our self-support matching fundamentally differs from conventional matching. Other methods learn better support prototypes for support-query matching from extra unlabeled images (PPNet <ref type="bibr" target="#b57">[57]</ref> and MLC <ref type="bibr" target="#b82">[82]</ref>) or builds various support prototype generation modules <ref type="bibr" target="#b71">[71,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b81">81]</ref> or feature priors (PFENet <ref type="bibr" target="#b73">[73]</ref>) based on support images. Although PANet <ref type="bibr" target="#b75">[75]</ref> and CRNet <ref type="bibr" target="#b55">[55]</ref> also explore query prototypes, they use query prototypes to match support features as a query-support matching only for auxiliary training, and cannot solve the appearance discrepancy.</p><p>Our self-support method significantly improves the prototype quality by alleviating the intra-class appearance discrepancy problem, evidenced by the performance boost on multiple datasets in our experimental validation. Despite the simple idea, our self-support method is very effective and has various advantages, such as benefiting more from stronger backbone and more supports, producing high-confidence predictions, more robustness to weak support labels, higher generalization to other methods and higher running efficiency. We will substantiate these advantages with thorough experiments. In summary, our contributions are:</p><p>-We propose novel self-support matching and build a novel self-support network to solve the appearance discrepancy problem in FSS. -We propose self-support prototype, adaptive self-support background prototype and self-support loss to facilitate our self-support method. -Our self-support method benefits more improvement from stronger backbones and more supports, and outperforms previous SOTAs on multiple datasets with many desirable advantages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Semantic Segmentation. Semantic segmentation is a fundamental computer vision task to produce pixel-wise dense semantic predictions. The state-of-theart has recently been greatly advanced by the end-to-end fully convolutional network (FCN) <ref type="bibr" target="#b58">[58]</ref>. Subsequent works have since followed this FCN paradigm and contributed many effective modules to further promote the performance, such as encoder-decoder architectures <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b67">67]</ref>, image and feature pyramid modules <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b91">91,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b50">50]</ref>, context aggregation modules <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b92">92,</ref><ref type="bibr" target="#b95">95,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b85">85,</ref><ref type="bibr" target="#b89">89]</ref> and advance convolution layers <ref type="bibr" target="#b84">[84,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b63">63]</ref>. Nevertheless, the above segmentation methods rely heavily on abundant pixel-level annotations. This paper aims to tackle the semantic segmentation problem in the few-shot scenario.</p><p>Few-Shot Learning. Few-shot learning targets at recognizing new concepts from very few samples. This low cost property has attracted a lot of research interests over the last years. There are three main approaches. The first is the transfer-learning approach <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b65">65]</ref> by adapting the prior knowledge learned from base classes to novel classes in a two-stage finetuning procedure. The second is the optimized-based approach <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b68">68]</ref>, which rapidly updates models through meta-learning the optimization procedures from a few samples. The last is the metric-based approach <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47]</ref>, which applies a siamese network <ref type="bibr" target="#b39">[40]</ref> on support-query pairs to learn a general metric for evaluating their relevance. Our work, including many few-shot works <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b90">90,</ref><ref type="bibr" target="#b80">80,</ref><ref type="bibr" target="#b21">22]</ref> on various high-level computer vision tasks, are inspired by the metric-based approach.</p><p>Few-Shot Semantic Segmentation. Few-shot semantic segmentation is pioneered by Shaban et al. <ref type="bibr" target="#b69">[69]</ref>. Later works have mainly adopted the metricbased mainstream paradigm <ref type="bibr" target="#b17">[18]</ref> with various improvements, e.g., improving the matching procedure between support-query images with various attention mechanisms <ref type="bibr" target="#b70">[70,</ref><ref type="bibr" target="#b54">54,</ref><ref type="bibr" target="#b83">83]</ref>, better optimizations <ref type="bibr" target="#b94">[94,</ref><ref type="bibr" target="#b53">53]</ref>, memory modules <ref type="bibr" target="#b77">[77,</ref><ref type="bibr" target="#b79">79]</ref>, graph neural networks <ref type="bibr" target="#b78">[78,</ref><ref type="bibr" target="#b74">74,</ref><ref type="bibr" target="#b87">87]</ref>, learning-based classifiers <ref type="bibr" target="#b72">[72,</ref><ref type="bibr" target="#b59">59]</ref>, progressive matching <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b96">96]</ref>, or other advanced techniques <ref type="bibr" target="#b86">[86,</ref><ref type="bibr" target="#b52">52,</ref><ref type="bibr" target="#b61">61,</ref><ref type="bibr" target="#b48">48]</ref>.</p><p>We are the first to perform self-support matching between query prototype and query features. Our self-support matching method is also related to the prototype generation methods. Some methods leverage extra unlabeled data <ref type="bibr" target="#b82">[82,</ref><ref type="bibr" target="#b57">57]</ref> or feature priors <ref type="bibr" target="#b73">[73]</ref> for further feature enhancement. Other methods generate representative support prototypes with various techniques, e.g., attention mechanism <ref type="bibr" target="#b88">[88,</ref><ref type="bibr" target="#b26">27]</ref>, adaptive prototype learning <ref type="bibr" target="#b71">[71,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b64">64]</ref>, or various prototype generation approaches <ref type="bibr" target="#b62">[62,</ref><ref type="bibr" target="#b81">81]</ref>. Although the query prototype has been explored in some methods <ref type="bibr" target="#b75">[75,</ref><ref type="bibr" target="#b55">55]</ref>, they only use query prototypes to match support features for prototype regularization. Finally, existing methods heavily suffer from the intra-class discrepancy problem in the support-query matching. On the other hand, we propose a novel self-support matching strategy to effectively address this matching problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Self-Support Few-Shot Semantic Segmentation</head><p>Given only a few support images, few-shot semantic segmentation aims to segment objects of novel classes using the model generalized from base classes. Existing mainstream few-shot semantic segmentation solution can be formulated as follows: The input support and query images {I s , I q } are processed by a weight-shared backbone to extract image features {F s , F q } ? R C?H?W , where C is the channel size and H ? W is the feature spatial size. Then the support </p><formula xml:id="formula_0">= {P s,f , P s,b } ? R C?1?1</formula><p>for foreground and background regions respectively. Finally, two distance maps D = {D f , D b } are generated by evaluating the cosine similarity between P s and F q , which is then processed by a softmax operation as the final prediction M 1 = softmax(D).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Motivation</head><p>Current FSS methods rely heavily on the support prototype to segment query objects, by densely matching each query pixel with the support prototype. However, such cross-object matching severely suffers from intra-class appearance discrepancy, where objects in support and query can look very different even belonging to the same class. Such high intra-class variation cannot be reconciled by only a few supports, thus leading to poor matching results due to the large appearance gap between the query and supports.</p><p>To validate the relevance of Gestalt law <ref type="bibr" target="#b40">[41]</ref> in narrowing such appearance discrepancy, we statistically analyze the feature cosine similarity of cross-object and intra-object pixels of Pascal VOC <ref type="bibr" target="#b18">[19]</ref>, where the pixel features are extracted from the ImageNet <ref type="bibr" target="#b14">[15]</ref>-pretrianed ResNet-50 <ref type="bibr" target="#b33">[34]</ref>. <ref type="table" target="#tab_1">Table 1</ref> shows that pixels belonging to the same object are much more similar than the cross-object pixels. Notably, background pixels share similar characteristics on their own, where intra-image background pixels are much more similar than cross-image pixels.</p><p>Thus, we propose to leverage the query feature to generate self-support prototypes to match the query feature itself. Notably, such prototype aligns the query along the homologous query features and thus can significantly narrow the feature gap between the support and query. In hindsight, the crucial reason the self-support matching works better than traditional support-query matching is that for a given visual object class, the intra-object similarities are much higher than the cross-object similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Self-Support Prototype</head><p>Our core idea ( <ref type="figure">Figure 2</ref>) is to aggregate query features to generate the query prototype and use it to self-support the query feature itself.</p><p>To recap, the regular support prototype generation procedure is:</p><formula xml:id="formula_1">P s = MAP (M s , F s ),<label>(1)</label></formula><p>where MAP is the masked average pooling operation, which is used to generate the matching prediction with query feature F q :</p><formula xml:id="formula_2">M 1 = softmax(cosine(P s , F q )),<label>(2)</label></formula><formula xml:id="formula_3">Fig. 2.</formula><p>Overall self-support network architecture. We first generate the initial mask predictions using the traditional support prototype based matching network. Then we leverage the initial query mask to aggregate query features to generate self-support prototypes, i.e., the self-support foreground prototype (SSFP) and adaptive self-support background prototype (ASBP). Finally, we combine the support prototype and selfsupport prototypes to perform matching with query features.</p><p>where cosine is the cosine similarity metric. Now, we can generate the query prototype P q in the same manner, except the groundtruth masks of query images M q are unavailable during inference. Thus, we need to use a predicted query mask M q to aggregate query features. The query prototype generation procedure can be formulated as:</p><formula xml:id="formula_4">P q = MAP ( M q , F q ),<label>(3)</label></formula><p>where M q = 1(M 1 &gt; ? ), and M 1 is the estimated query mask generated by Equation 2, 1 is the indicator function. The mask threshold ? is used to control the query feature sampling scope which is set as {? f g = 0.7, ? bg = 0.6} for foreground and background query masks respectively. The estimated selfsupport prototype P q = {P q,f , P q,b } will be utilized to match query features.</p><p>We understand the reader's natural concern about the quality of self-support prototype, which is generated based on the estimated query mask, i.e., whether the estimated mask is capable of effective self-support prototype generation. We found that even the estimated query mask is not perfect, as long as it covers some representative object fragments, it is sufficient to retrieve other regions of the same object. To validate partial object or object fragment is capable of supporting the entire object, we train and evaluate models with partial prototypes, which are aggregated from randomly selecting features based on the groundtruth mask labels. We conduct the 1-shot segmentation experiments on Pascal VOC dataset with the ResNet-50 backbone. As shown in <ref type="table" target="#tab_2">Table 2</ref>, while reducing the aggregated object regions for prototype generation, our self-support prototype consistently achieves high segmentation performance. By contrast, the traditional support prototype consistently obtains much inferior performance, even using perfect support features from the entire object.  We further introduce noisy features (with 20% noise ratio) into partial prototypes to mimic realistic self-support generation during inference, by randomly selecting image features from non-target regions and aggregating these features into the above partial prototypes. To our pleasant surprise, our self-support prototype still works much better than the traditional support prototype in such noisy situation. Note that each image may contain multiple objects, thus the good performance indicates that our self-support prototype can also handle well the multiple objects scenarios. These results confirm the practicability and advantages of our self-support prototypes in the realistic applications.</p><formula xml:id="formula_5">R T R C x H x W C x (HW) C x M M x (HW) C x (HW) C x H x W ? ! ? !,# ? ! !,# ? !,# ? C x H x W MAP !,% ? ! S Softmax R Reshape MAP Masked Average Pooling T Transpose Matrix Multi. M&amp;R Multiplication &amp; Reshape (b) Adaptive Self-support Background Prototype $ ? !,% $ ? !,# 0 1 0 0 1 0 0 0 0 (a) SS Foreground Prototype</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Adaptive Self-Support Background Prototype</head><p>Foreground pixels share semantic commonalities <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>, which constitutes the rationale behind our self-support prototype generation and matching procedure between query feature and support prototypes for foreground objects. Therefore, we can utilize a masked average pooling to generate the self-support foreground prototype <ref type="figure" target="#fig_0">(Figure 3</ref> (a)):</p><formula xml:id="formula_6">P q,f = MAP ( M q,f , F q ),<label>(4)</label></formula><p>where M q,f is the aforementioned estimated query mask.</p><p>On the other hand, background can be cluttered, where commonalities can be reduced to local semantic similarities in disjoint regions, without a global semantic commonality shared among all background pixels. For example, for a query image with dog as the target class, other objects such as person and car are both treated as background, but they are different in both appearance and semantic levels. This observation is also validated by the smaller background pixel similarity compared to foreground pixels as shown in <ref type="table" target="#tab_1">Table 1</ref>, especially in the intra-object/image situation. This motivates us to generate multiple selfsupport background prototypes for different query semantic regions.</p><p>A straightforward solution is to directly group multiple background prototypes using a clustering algorithm, and then choose the most similar prototype at each query pixel for background matching. This explicit background grouping heavily relies on the clustering algorithm, which is unstable and time-consuming. Therefore, we propose a more flexible and efficient method to adaptively generate self-support background prototypes for each query pixel <ref type="figure" target="#fig_0">(Figure 3 (b)</ref>).</p><p>The idea is to dynamically aggregate similar background pixels for each query pixel to generate adaptive self-support background prototypes. Specifically, we first gather the background query features F q,b ? R C?M through the masked multiplication on the query feature F q with the background mask M q,b , where M is the pixel number of the background region. Then we can generate the affinity matrix A between pixels of the reshaped background query feature F q,b and full query feature F q through a matrix multiplication operation MatMul :</p><formula xml:id="formula_7">A = MatMul (F q,b T , F q ),<label>(5)</label></formula><p>where A is in size of R M ?(H?W ) . The affinity matrix is normalized through a softmax operation along the first dimension, which is used to weighted aggregate background query features for each query pixel to generate the adaptive selfsupport background prototypes P ? q,b ? R C?H?W :</p><formula xml:id="formula_8">P ? q,b = MatMul (F q,b , softmax(A)).<label>(6)</label></formula><p>The self-support prototype is updated with the adaptive self-support background prototype: P q = {P q,f , P ? q,b }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Self-Support Matching</head><p>We weighted combine the support prototype P s and self-support prototype P q :</p><formula xml:id="formula_9">P ? s = ? 1 P s + ? 2 P q ,<label>(7)</label></formula><p>where ? 1 and ? 2 are the tuning weights and we set ? 1 = ? 2 = 0.5 in our experiments. Then we compute the cosine distance between the augmented support prototype P ? s and query feature F q to generate the final matching prediction:</p><formula xml:id="formula_10">M 2 = softmax(cosine(P ? s , F q )).<label>(8)</label></formula><p>Then we apply the training supervision on the generated distance maps:</p><formula xml:id="formula_11">L m = BCE (cosine(P ? s , F q ), G q ),<label>(9)</label></formula><p>where BCE is the binary cross entropy loss and G q is the groundtruth mask of the query image.</p><p>To further facilitate the self-support matching procedure, we propose a novel query self-support loss. For the query feature F q and its prototype P q , we apply the following training supervision:</p><formula xml:id="formula_12">L q = BCE (cosine(P q , F q ), G q ).<label>(10)</label></formula><p>We can apply the same procedure on the support feature to introduce the support self-matching loss L s . Finally, we train the model in an end-to-end manner by jointly optimizing all the aforementioned losses:</p><formula xml:id="formula_13">L = ? 1 L m + ? 2 L q + ? 3 L s ,<label>(11)</label></formula><p>where ? 1 = 1.0, ? 2 = 1.0, ? 3 = 0.2 are the loss weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Datasets. We conduct experiments on two FSS benchmark datasets: PASCAL-5 i <ref type="bibr" target="#b18">[19]</ref> and COCO-20 i <ref type="bibr" target="#b51">[51]</ref>. We follow previous works <ref type="bibr" target="#b73">[73,</ref><ref type="bibr" target="#b82">82]</ref> to split the data into four folds for cross validation, where three folds are used for training and the remaining one for evaluation. During inference, we randomly sample 1,000/4,000 support-query pairs to perform evaluation for PASCAL-5 i and COCO-20 i , respectively. We use the popular mean Intersection-over-Union (mIoU, ? 1 ) as the default metric to evaluate our model under 1-shot and 5-shot settings. We also apply the Mean Absolute Error (MAE, ?) to evaluate our prediction quality. By default, all analyses are conducted on PASCAL-5 i dataset with ResNet-50 backbone in the 5-shot setting. Implementation details. We adopt the popular ResNet-50/101 <ref type="bibr" target="#b33">[34]</ref> pretrained on ImageNet <ref type="bibr" target="#b14">[15]</ref> as the backbone. Following previous work MLC <ref type="bibr" target="#b82">[82]</ref>, we discard the last backbone stage and the last ReLU for better generalization. We use SGD to optimize our model with the 0.9 momentum and 1e-3 initial learning rate, which decays by 10 times every 2,000 iterations. The model is trained for 6,000 iterations where each training batch contains 4 support-query pairs. Both images and masks are resized and cropped into (473, 473) and augmented with random horizontal flipping. The evaluation is performed on the original image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Comparison with State-of-the-Arts</head><p>To validate the effectiveness of our method, we conduct extensive comparisons with SOTA methods under different backbone networks and few-shot settings. PASCAL-5 i . We present the results of our self-support method and the improved version with one extra self-support refinement. As shown in <ref type="table">Table 3</ref>, our method substantially outperforms MLC <ref type="bibr" target="#b82">[82]</ref> by a large margin in the 5-shot setting, with the improvement jumping from 2.7% to 3.7% with the ResNet-50 backbone replaced by the stronger ResNet-101 network. In the 1-shot setting, our slightly inferior performance is remedied by using the stronger ResNet-101 backbone, where we surpass MLC [82] by 1.4% improvement. We can further promote the overall performance on PASCAL-5 i up to 73.1% with the self-support refinement, which is a simple and straightforward extension by repeating the self-support procedure. It surpasses the previous SOTA [61] by 2.7%. Note that our method is non-parametric and thus our model uses fewest parameters while achieving the best performance. COCO-20 i . This is a very challenging dataset whose images usually contain multiple objects against a complex background. As shown in , we adopt their evaluation protocol to evaluate our method. Our method achieves SOTA when using the ResNet-101 backbone. Our method also performs best on FSS-1000 <ref type="bibr" target="#b48">[48]</ref>, shown in the supplementary material. <ref type="table">Table 5</ref>. Self-support model ablation results. "SSM" denotes the self-support module (containing the self-support foreground/background prototypes) , "SSL" denotes the self-support loss and "ASBP" denotes the adaptive self-support background prototype.  <ref type="figure">Fig. 4</ref>. Visualization for the working mechanism of our self-support matching. We omit the original support in self-support matching and the first row caption for clarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SSM</head><p>Note that our method benefits more improvement from stronger backbones and more supports because they provide better self-support prototypes, which will be validated later in <ref type="table">Table 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablation Studies</head><p>As shown in <ref type="table">Table 5</ref>, our self-support module significantly improves the performance by 2.5 %. The self-support loss further facilitates the self-support procedure and promotes the performance to 68.1%. The baseline model also benefits from the extra supervision of self-support loss. After equipped with the adaptive self-support background prototype, the self-support module can obtain extra 0.9% gain. Integrating all modules, our self-support method significantly improves the performance from 64.8% to 68.8% based on the strong baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Self-Support Analysis</head><p>We conduct extensive experiments and analysis to understand our method. Self-support working mechanism. As shown in <ref type="figure">Figure 4</ref>, we first generate the Initial query predictions using the support prototype (as in Equation 2), and leverage the confident predictions to extract query features to generate selfsupport prototype (as in <ref type="figure" target="#fig_0">Equation 3</ref>). Then we use the self-support prototype to match with query features (as in <ref type="figure">Equation 16</ref>) and produce the final output. Note that because of the large inter-object/inter-background variation, the Init predictions usually only capture some small representative regions, e.g., the cat/dog heads. Notwithstanding, our self-support method can handle well these hard cases by bridging the gap between query and support prototypes.   <ref type="table">Table 6</ref>. Ablation results of self-support module (SSM) by respectively removing foreground support prototype (FP), background support prototype (BP), self-support foreground prototype (SFP) and self-support background prototype (SBP Mask threshold. The threshold ? controls the query feature selection for self-support prototype generation (as in <ref type="figure" target="#fig_0">Equation 3</ref>). While we need to select high-confidence features for the foreground prototype, the background prototype requires more query features with a relative low threshold. This is because foreground pixels exhibit strong similarities with relatively low noise tolerance, while background is cluttered and the aggregated diverse features should tolerate more noises. <ref type="figure" target="#fig_2">Figure 5</ref> (a) summarizes the model performance on Pascal dataset with different thresholds, where a good balance between foreground and background thresholds are respectively ? f g ? [0.7, 0.9] and ? bg ? [0.5, 0.7]. Prototype ablation. We investigate the effect of each of the prototypes by respectively removing them from the overall prototype. <ref type="table">Table 6</ref> summarizes the results. Both our self-support foreground and background prototypes play a critical role to account for good matching performance. The support foreground prototype is also essential for the prototype quality thanks to its foreground semantic information aggregated from multiple support images. The support background prototype can be discarded with slight impact because of the large background variation between query and support. Distinction from self-attention. Readers may compare our self-support method with self-attention mechanisms. Our self-support method shares some concepts but is different from self-attention. Self-attention augments the image feature at each position by weighted aggregation of the features from all positions according to the affinity matrix. In contrast, our self-support method leverages representative query features to generate prototypes according to the querysupport matching results. In <ref type="table" target="#tab_7">Table 7</ref> we experiment with multiple self-attention modules on the baseline. Unfortunately, all of them impose various degrees of  <ref type="table">Table 8</ref>. Comparison with other methods on performance improvement across different backbones and support shots.</p><p>PFENet <ref type="bibr" target="#b73">[73]</ref> ReRPI <ref type="bibr" target="#b6">[7]</ref> CWT <ref type="bibr" target="#b59">[59]</ref> MLC <ref type="bibr" target="#b82">[82]</ref> Ours</p><formula xml:id="formula_14">R50 ? R101 ?0.5 ?1.2 +1.0 +2.7 +3.7 1shot ? 5shot +1.3 +6.2 +6.7 +6.2 +8.5</formula><p>harm on the matching performance, which are resulted by their self-attention augmentation which can destroy feature similarity between query and supports.</p><p>Adaptive self-support background prototype. This is designed to address the background clutter problem by adaptively aggregating background prototypes for each position. As shown in <ref type="figure" target="#fig_2">Figure 5</ref> (b), the target cat is lying on a cluttered background consisting of the wardrobe, bed, quilt, baby, pillow and sheet. For each star-marked query position, the self-support background prototypes are aggregated from the corresponding semantic regions. Note that this adaptive background prototype generation is specifically designed for selfsupport prototypes, which cannot be directly applied to support prototype generation because it will collapse to trivial solutions by greedily aggregating similar pixels without semantic consideration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Self-Support Advantages</head><p>Our self-support method has many desirable properties.</p><p>Benefits from backbones and supports. As shown before, our self-support method benefits more improvement from stronger backbones and more supports. <ref type="table">Table 8</ref> summarizes the improvement of different methods. When switching the backbone from ResNet-50 to ResNet-101, our method obtains 3.7% performance improvement, while other methods obtain at most 2.7% improvement or even performance degradation. Our method also obtains the largest improvement of 8.5% by increasing support images from 1-shot to 5-shot. The behind reason is that our self-support method benefits from the Matthew effect <ref type="bibr" target="#b60">[60]</ref> of accumulated advantages, where better predictions induce better self-support prototypes and produce better predictions. High-confident predictions. Our self-support method not only improves hard segmentation results with 0-1 labels, but also improves the soft confidence scores to produce high-confident predictions. As shown in <ref type="table" target="#tab_8">Table 9</ref>, our selfsupport method significantly reduces the Mean Absolute Error (MAE) by 4.9% compared to the baseline. We further evaluate the MAE in the truth positive (TP) regions for a fair comparison, where the MAE can still be largely reduced by 5.0%. These results demonstrate that our self-support method can significantly  improve the output quality by producing high-confident predictions, a desirable property for many real-world applications.</p><p>Robust to weak support labels. As shown in <ref type="table" target="#tab_1">Table 10</ref>, when replacing the support mask with bounding box or scribble annotations for prototype generation, our self-support method still works very well with high robustness against support noises. This is because our method mainly relies on self-support prototypes and thus is less affected by from noisy support prototypes.</p><p>Generalized to other methods. Our self-support method is general and can be applied to other methods. As shown in <ref type="table" target="#tab_1">Table 11</ref>, equipped with our self-support module, both the strong PANet <ref type="bibr" target="#b75">[75]</ref> and PPNet <ref type="bibr" target="#b56">[56]</ref> report further boost in their performance by a large improvement. High efficiency. Our self-support method is very efficient, which is a nonparametric method with few extra computation and ?28 FPS running speed on a Tesla V100 GPU (with the ResNet-50 backbone in the 1-shot setting).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we address the critical intra-class appearance discrepancy problem inherent in few-shot segmentation, by leveraging the query feature to generate self-support prototypes and perform self-support matching with query features. This strategy effectively narrows down the gap between support prototypes and query features. Further, we propose an adaptive self-support background prototype and a self-support loss to facilitate the self-support procedure. Our selfsupport network has various desirable properties, and achieves SOTA on multiple benchmarks. We have thoroughly investigated the self-support procedure with extensive experiments and analysis to substantiate its effectiveness and deepen our understanding on its working mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">More Implementation Details</head><p>Our baseline model is adopted from MLC <ref type="bibr" target="#b82">[82]</ref> with a metric learning framework consisting of only an encoder. Our improved model with self-support refinement is to repeat the self-support procedure based on the predicted mask M 2 produced by our self-support network. Specifically, the refined self-support foreground prototype P r q,f generation can be formulated as:</p><formula xml:id="formula_15">P r q,f = MAP ( M 2,q,f , F q ),<label>(12)</label></formula><p>where F q is the query feature. Similarly, we can generate the refined self-support background prototype P ?,r q,b by</p><formula xml:id="formula_16">P ?,r q,b = ASBP ( M 2,q,b , F q ),<label>(13)</label></formula><p>where ASBP is the adaptive self-support background prototype generation mod- </p><p>where ? 1 , ? 2 and ? 3 are the tuning weights which are set as ? 1 = 0.5, ? 2 = 0.2 and ? 3 = 0.3 in our experiments. Then we compute the cosine distance between the augmented support prototype with self-support refinement P ?,r s and query feature F q to generate the matching prediction output M 3 :</p><formula xml:id="formula_18">M 3 = softmax(cosine(P ?,r s , F q )).<label>(15)</label></formula><p>The final output M f inal is the weighted combination of M 2 and M 3 for good performance:</p><formula xml:id="formula_19">M f inal = ? 1 M 2 + ? 2 M 3 ,<label>(16)</label></formula><p>where ? 1 and ? 2 are the tuning weights and we set ? 1 = 0.3 and ? 2 = 0.7 in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">More Quantitative Results</head><p>In the main paper, we repeat the evaluation procedure of all our experiments by 5 times with different random seeds to obtain stable results.  To further validate the effectiveness of our self-support method, we evaluate our model on FSS-1000 <ref type="bibr" target="#b48">[48]</ref>, which is a recently proposed large-scale few-shot segmentation dataset containing 1000 classes. The dataset is split into train/val/test sets with 520, 240, 240 classes respectively. We follow the common practice <ref type="bibr" target="#b48">[48]</ref> to evaluate performance on FSS-1000 using the intersection-over-union (IoU) of positive labels in a binary segmentation map. The evaluation procedure is conducted on 2400 randomly sampled support-query pairs. As shown in Table 12, our self-support matching model outperforms other methods. And the self-support refinement step can further promote our performance to 87.3/88.6 mIoU in 1/5-shot settings.</p><p>As shown in <ref type="table" target="#tab_1">Table 13</ref>, we present the performance improvement on Pascal VOC dataset <ref type="bibr" target="#b18">[19]</ref> of our self-support method on the baseline models. Our method can consistently improve the performance by a large margin with different backbone models and support shots. We can also observe more performance gains on the stronger backbone model and more support shots, which is consistent with the advantage conclusion in the main paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">More Qualitative Results</head><p>We present more qualitative results in 1-shot setting with ResNet-50 backbone for better visualization. As shown in <ref type="figure">Figure 6, Figure 7</ref>, <ref type="figure">Figure 8</ref>, and <ref type="figure" target="#fig_5">Figure 9</ref>, objects in support and query images have large appearance discrepancy even belonging to the same class. Thus the initial predictions generated by the traditional matching network can cover only a small region of the target object. On the other hand, equipped with our self-support method, the model can produce satisfactory results with substantial qualitative improvement. Note that the initial masks are obtained by setting foreground and background thresholds on the original mask prediction M 1 .  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Prototype generations of (a) self-support (SS) foreground prototype and (b) adaptive self-support background prototype.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) Ablation results of mask thresholds (b) Visualization results of ASBP feature aggregation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>(a) Results of mask threshold variations for self-support prototypes. (b) Visualization of the feature aggregation for adaptive self-support background prototypes (ASBP) at each star-marked position. They are aggregated from the activated background regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>ule. The M 2,q,f = 1(M 2,f &gt; ? f g ) and M 2,q,b = 1(M 2,b &gt; ? bg ) are defined according to the estimated query mask M 2 = {M 2,f , M 2,b } by Equation 8 in the main paper. We use the same {? f g = 0.7, ? bg = 0.6} settings as in the main paper. Finally, we weight-combine the original support prototype P s = {P s,f , P s,b }, self-support prototype P q = {P q,f , P ? q,b } and refined self-support prototype P r q = {P r q,f , P ?,r q,b }: P ?,r s = ? 1 P s + ? 2 P q + ? 3 P r q ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>This research was supported by Kuaishou Technology, the Research Grant Council of the HK SAR under grant No. 16201420, and NSFC fund (U2013210, 62006060). ? Corresponding author.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9 .</head><label>9</label><figDesc>The 1-shot visualization results of our model containing the Init and final outputs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Cosine similarity for cross/intra object pixels.</figDesc><table><row><cell cols="2">FG Pixels Similarity</cell><cell cols="2">BG Pixels Similarity</cell></row><row><cell>cross-object</cell><cell>intra-object</cell><cell>cross-image</cell><cell>intra-image</cell></row><row><cell>0.308</cell><cell>0.416 ?0.108</cell><cell>0.298</cell><cell>0.365 ?0.067</cell></row></table><note>feature F s and its groundtruth mask M s are fed into the masked average pool- ing layer to generate the support prototype vectors P s</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>The 1-shot matching results (mIoU) of support/self-support prototypes aggregated from full/partial objects.</figDesc><table><row><cell>Object Ratio</cell><cell>full</cell><cell>10%</cell><cell>1%</cell><cell>1%+noise</cell></row><row><cell>Support Prototype</cell><cell>58.2</cell><cell>57.1</cell><cell>52.4</cell><cell>48.7</cell></row><row><cell>Self-support Prototype</cell><cell>83.0</cell><cell>82.5</cell><cell>79.2</cell><cell>74.6</cell></row><row><cell></cell><cell>M&amp;R</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1 0 1</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1 0 1</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1 1 1</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>S</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .Table 4 .</head><label>34</label><figDesc>Quantitative comparison results on PASCAL-5 i dataset. The best and second best results are highlighted with bold and underline, respectively. Quantitative comparison results on COCO-20 i dataset. ? denotes the results are evaluated on the HSNet's evaluation protocol. 39.9 30.6 30.0 37.7 57.8 47.0 40.2 39.9 46.2 27.7 M HSNet ? [61] 37.2 44.1 42.4 41.3 41.2 45.9 53.0 51.8 47.1 49.5 45.2 M SSP ? (Ours) 39.1 45.1 42.7 41.2 42.0 47.4 54.5 50.4 49.6 50.2 27.7 M</figDesc><table><row><cell></cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>Method</cell><cell cols="3">Backbone fold0 fold1 fold2 fold3 Mean fold0 fold1 fold2 fold3 Mean Params</cell></row><row><cell>PANet [75]</cell><cell></cell><cell cols="2">44.0 57.5 50.8 44.0 49.1 55.3 67.2 61.3 53.2 59.3 23.5 M</cell></row><row><cell>PPNet [56]</cell><cell></cell><cell cols="2">48.6 60.6 55.7 46.5 52.8 58.9 68.3 66.8 58.0 63.0 31.5 M</cell></row><row><cell>PFENet [73]</cell><cell></cell><cell cols="2">61.7 69.5 55.4 56.3 60.8 63.1 70.7 55.8 57.9 61.9 34.3 M</cell></row><row><cell>CWT [59] HSNet [61]</cell><cell>Res-50</cell><cell cols="2">56.3 62.0 59.9 47.2 56.4 61.3 68.5 68.5 56.6 63.7 64.3 70.7 60.3 60.5 64.0 70.3 73.2 67.4 67.1 69.5 26.1 M -</cell></row><row><cell>MLC [82]</cell><cell></cell><cell cols="2">59.2 71.2 65.6 52.5 62.1 63.5 71.6 71.2 58.1 66.1 8.7 M</cell></row><row><cell>SSP (Ours)</cell><cell></cell><cell cols="2">61.4 67.2 65.4 49.7 60.9 68.0 72.0 74.8 60.2 68.8 8.7 M</cell></row><row><cell>SSPrefine</cell><cell></cell><cell cols="2">60.5 67.8 66.4 51.0 61.4 67.5 72.3 75.2 62.1 69.3 8.7 M</cell></row><row><cell>FWB [62]</cell><cell></cell><cell cols="2">51.3 64.5 56.7 52.2 56.2 54.8 67.4 62.2 55.3 59.9 43.0 M</cell></row><row><cell>PPNet [56]</cell><cell></cell><cell cols="2">52.7 62.8 57.4 47.7 55.2 60.3 70.0 69.4 60.7 65.1 50.5 M</cell></row><row><cell>PFENet [73]</cell><cell></cell><cell cols="2">60.5 69.4 54.4 55.9 60.1 62.8 70.4 54.9 57.6 61.4 53.4 M</cell></row><row><cell>CWT [59] HSNet [61]</cell><cell>Res-101</cell><cell cols="2">56.9 65.2 61.2 48.8 58.0 62.6 70.2 68.8 57.2 64.7 67.3 72.3 62.0 63.1 66.2 71.8 74.4 67.0 68.3 70.4 45.2 M -</cell></row><row><cell>MLC [82]</cell><cell></cell><cell cols="2">60.8 71.3 61.5 56.9 62.6 65.8 74.9 71.4 63.1 68.8 27.7 M</cell></row><row><cell>SSP (Ours)</cell><cell></cell><cell cols="2">63.7 70.1 66.7 55.4 64.0 70.3 76.3 77.8 65.5 72.5 27.7 M</cell></row><row><cell>SSPrefine</cell><cell></cell><cell cols="2">63.2 70.4 68.5 56.3 64.6 70.5 76.4 79.0 66.4 73.1 27.7 M</cell></row><row><cell></cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>Method</cell><cell cols="3">Backbone fold0 fold1 fold2 fold3 Mean fold0 fold1 fold2 fold3 Mean Params</cell></row><row><cell>PANet [75]</cell><cell></cell><cell cols="2">31.5 22.6 21.5 16.2 23.0 45.9 29.2 30.6 29.6 33.8 23.5 M</cell></row><row><cell>PPNet [56]</cell><cell></cell><cell cols="2">36.5 26.5 26.0 19.7 27.2 48.9 31.4 36.0 30.6 36.7 31.5 M</cell></row><row><cell>CWT [59]</cell><cell></cell><cell cols="2">32.2 36.0 31.6 31.6 32.9 40.1 43.8 39.0 42.4 41.3</cell><cell>-</cell></row><row><cell>MLC [82]</cell><cell>Res-50</cell><cell cols="2">46.8 35.3 26.2 27.1 33.9 54.1 41.2 34.1 33.1 40.6 8.7 M</cell></row><row><cell>SSP (Ours)</cell><cell></cell><cell cols="2">46.4 35.2 27.3 25.4 33.6 53.8 41.5 36.0 33.7 41.3 8.7 M</cell></row><row><cell>HSNet ? [61]</cell><cell></cell><cell cols="2">36.3 43.1 38.7 38.7 39.2 43.3 51.3 48.2 45.0 46.9 26.1 M</cell></row><row><cell>SSP ? (Ours)</cell><cell></cell><cell cols="2">35.5 39.6 37.9 36.7 37.4 40.6 47.0 45.1 43.9 44.1 8.7 M</cell></row><row><cell>PMMs [81]</cell><cell></cell><cell cols="2">29.5 36.8 28.9 27.0 30.6 33.8 42.0 33.0 33.3 35.5 38.6 M</cell></row><row><cell>CWT [59]</cell><cell></cell><cell cols="2">30.3 36.6 30.5 32.2 32.4 38.5 46.7 39.4 43.2 42.0</cell><cell>-</cell></row><row><cell>MLC [82] SSP (Ours)</cell><cell>Res-101</cell><cell cols="2">50.2 37.8 27.1 30.4 36.4 57.0 46.2 37.3 37.2 44.4 27.7 M 50.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>, our method</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Initial Query Prediction For Self-Support Prototype Query Final Query Prediction Support Self-Support Matching Initial Query Prediction For Self-Support Prototype Query Final Query Prediction Support Self-Support Matching</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>SSL</cell><cell>ASBP</cell><cell>fold0</cell><cell>fold1</cell><cell>fold2</cell><cell>fold3</cell><cell>Mean</cell></row><row><cell></cell><cell></cell><cell></cell><cell>62.2</cell><cell>70.5</cell><cell>70.7</cell><cell>55.7</cell><cell>64.8</cell></row><row><cell>?</cell><cell></cell><cell></cell><cell>65.3</cell><cell>71.1</cell><cell>73.6</cell><cell>59.2</cell><cell>67.3 ?2.5</cell></row><row><cell></cell><cell>?</cell><cell></cell><cell>63.6</cell><cell>71.0</cell><cell>71.7</cell><cell>56.3</cell><cell>65.7 ?0.9</cell></row><row><cell>?</cell><cell>?</cell><cell></cell><cell>67.0</cell><cell>72.4</cell><cell>72.9</cell><cell>59.9</cell><cell>68.1 ?3.3</cell></row><row><cell>?</cell><cell></cell><cell>?</cell><cell>67.0</cell><cell>71.4</cell><cell>74.7</cell><cell>59.8</cell><cell>68.2 ?3.4</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>68.0</cell><cell>72.0</cell><cell>74.8</cell><cell>60.2</cell><cell>68.8 ?4.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 .</head><label>7</label><figDesc>Comparison with self-attention modules. " ? " means the improved version by removing the transformation layer.</figDesc><table><row><cell>Baseline</cell><cell>NL [76]</cell><cell>NL  ? [76]</cell><cell>GCNet [8]</cell><cell>Our SSM</cell></row><row><cell>64.8</cell><cell>62.1 ?2.7</cell><cell>64.3 ?0.5</cell><cell>63.9 ?0.9</cell><cell>67.3 ?2.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 .</head><label>9</label><figDesc>Results of prediction quality in MAE (?) metric. "All/TP" means evaluating models on all/truth positive regions of the image.Table 10. Results of using weak support annotations.</figDesc><table><row><cell></cell><cell>Baseline</cell><cell></cell><cell>SSM</cell><cell>SSM+SSL</cell><cell>SSM+ASBP</cell><cell>Full</cell></row><row><cell>All</cell><cell>17.6</cell><cell cols="2">14.6 ?3.0</cell><cell>14.8 ?2.8</cell><cell>12.9 ?4.7</cell><cell>12.7 ?4.9</cell></row><row><cell>TP</cell><cell>13.2</cell><cell></cell><cell>9.6 ?3.6</cell><cell>10.1 ?3.1</cell><cell>7.8 ?5.4</cell><cell>8.2 ?5.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Mask</cell><cell>Scribble</cell><cell>Bounding Box</cell></row><row><cell></cell><cell cols="2">Baseline</cell><cell>64.8</cell><cell>63.3 ?1.5</cell><cell>61.7 ?3.1</cell></row><row><cell></cell><cell>Ours</cell><cell></cell><cell>68.8</cell><cell>68.0 ?0.8</cell><cell>66.9 ?2.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 11 .</head><label>11</label><figDesc>Results of applying our method to other models.</figDesc><table><row><cell>PANet [75]</cell><cell>PANet + Ours</cell><cell>PPNet [56]</cell><cell>PPNet + Ours</cell></row><row><cell>55.7</cell><cell>58.3 ?2.6</cell><cell>62.0</cell><cell>64.2 ?2.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 12 .Table 13 .</head><label>1213</label><figDesc>Quantitative comparison results on FSS-1000 dataset with the mIoU metric of positive labels in a binary segmentation map. Performance improvement on Pascal VOC dataset of our self-support method on baseline models with different backbones and support shots.</figDesc><table><row><cell>Method</cell><cell cols="2">Publication</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>OSLSM [69]</cell><cell cols="2">BMVC'17</cell><cell>70.3</cell><cell>73.0</cell></row><row><cell>GNet [66]</cell><cell cols="2">Arxiv'18</cell><cell>71.9</cell><cell>74.3</cell></row><row><cell>FSS [48]</cell><cell cols="2">CVPR'20</cell><cell>73.5</cell><cell>80.1</cell></row><row><cell>DoG-LSTM [3]</cell><cell cols="2">WACV'21</cell><cell>80.8</cell><cell>83.4</cell></row><row><cell>DAN [74]</cell><cell cols="2">ECCV'20</cell><cell>85.2</cell><cell>88.1</cell></row><row><cell>SSP (Ours)</cell><cell>-</cell><cell></cell><cell>86.9</cell><cell>88.2</cell></row><row><cell>SSP refine</cell><cell>-</cell><cell></cell><cell>87.3</cell><cell>88.6</cell></row><row><cell>Backbone</cell><cell>Shot</cell><cell>Baseline</cell><cell>Ours</cell><cell>?</cell></row><row><cell>ResNet-50</cell><cell>1-shot 5-shot</cell><cell>57.8 64.8</cell><cell>60.9 68.8</cell><cell>+3.1 +4.0</cell></row><row><cell>ResNet-101</cell><cell>1-shot 5-shot</cell><cell>60.1 67.8</cell><cell>64.0 72.5</cell><cell>+3.9 +4.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>The 1-shot visualization results of our model containing the Init and final outputs. The 1-shot visualization results of our model containing the Init and final outputs. The 1-shot visualization results of our model containing the Init and final outputs.</figDesc><table><row><cell>Support Fig. 6. Support Fig. 7. Support Fig. 8. Support</cell><cell>Query Query Query Query</cell><cell>FG Init FG Init FG Init FG Init</cell><cell>FG Output FG Output FG Output FG Output</cell><cell>BG Init BG Init BG Init BG Init</cell><cell>BG Output BG Output BG Output BG Output</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The "?" ("?") means that the higher (lower) is better.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This research was supported by Kuaishou Technology, the Research Grant Council of the HKSAR (16201420), and NSFC fund (U2013210, 62006060). ? Corresponding author.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Infinite mixture prototypes for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">How to train your maml</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">On the texture bias for few-shot cnn segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Azad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Fayjie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kauffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ben Ayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pedersoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>WACV</publisher>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large-scale interactive object segmentation with human annotators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Popov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Meta-learning with differentiable closed-form solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Few-shot segmentation without meta-learning: A good transductive inference is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Boudiaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kervadec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">I</forename><surname>Masud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Piantanida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ben Ayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Gcnet: Non-local networks meet squeezeexcitation networks and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPRW</publisher>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Attention to scale: Scaleaware semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Spgnet: Semantic prediction guidance for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Crosstransformers: spatially-aware few-shot transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Few-shot semantic segmentation with prototype learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMVC</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Group collaborative learning for co-salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Commonality-parsing network across shape and appearance for partially supervised instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.14805</idno>
		<title level="m">Few-shot video object detection</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Few-shot object detection with attention-rpn and multi-relation detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Dual attention network for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Adaptive context network for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simpropnet: Improved similarity propagation for few-shot image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gairola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hemani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT Press</publisher>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Meta-learning probabilistic inference for prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bronskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Turner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Recasting gradient-based meta-learning as hierarchical bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Progressive one-shot human parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thuraisingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Adaptive pyramid context network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cross attention network for fewshot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Ccnet: Criss-cross attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Few-shot object detection via feature reweighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Uncertainty-aware semi-supervised few shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chikontwe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Panoptic feature pyramid networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICMLW</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Principles of Gestalt psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Koffka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Routledge</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="1935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Gradient-based meta-learning with learned layerwise metric and subspace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Adaptive prototype learning and allocation for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sevilla-Lara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Finding task-relevant features for few-shot learning by category traversal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Revisiting local descriptor based image-to-class measure for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Fan</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Fss-1000: A 1000-class dataset for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR (2020)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Refinenet: Multi-path refinement networks for high-resolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Efficient piecewise training of deep structured models for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Hengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ECCV</publisher>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Anti-aliasing semantic reconstruction for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Learning a few-shot embedding model with contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>AAAI</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Dynamic extension nets for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM (2020)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Crnet: Cross-reference networks for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR (2020)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Part-aware prototype network for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV (2020)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Part-aware prototype network for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV (2020)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Simpler is better: Fewshot semantic segmentation with classifier weight transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV (2021)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">The matthew effect in science: The reward and communication systems of science are considered</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Merton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Hypercorrelation squeeze for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV (2021)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Feature weighting and boosting for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Todorovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Self-supervision with superpixels: Training few-shot medical image segmentation without annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Low-shot learning with imprinted weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Few-shot segmentation propagation with guided networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rakelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.07373</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>MICCAI</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">One-shot learning for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Essa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boots</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Weakly supervised few-shot object segmentation using co-attention with visual and semantic embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Siam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Doraiswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jagersand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Amp: Adaptive masked proxies for fewshot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Siam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jagersand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Differentiable meta-learning model for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>AAAI</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Prior guided feature enrichment network for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Few-shot semantic segmentation with democratic attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV (2020)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Panet: Few-shot image semantic segmentation with prototype alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV (2019) 3, 4</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Learning meta-class memory for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Scale-aware graph neural network for fewshot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Few-shot semantic segmentation with cyclic memory network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Meta r-cnn : Towards general solver for instance-level low-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Prototype mixture models for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note>In: ECCV (2020) 2, 3, 4</note>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Mining latent classes for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note>In: ICCV (2021) 2, 3, 4, 9</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Brinet: Towards bridging the intra-class and inter-class gaps in one-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMVC</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Dilated residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Object-contextual representations for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Self-guided and cross-guided learning for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR (2021)</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Pyramid graph networks with connection attentions for region-based one-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Canet: Class-agnostic segmentation networks with iterative refinement and attentive few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Acfnet: Attentional class feature network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ding</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Few-shot action recognition with permutation-invariant attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Psanet: Point-wise spatial attention network for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Scene parsing through ade20k dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barriuso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Self-supervised tuning for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">J</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Asymmetric non-local neural networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Deep reasoning network for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhuge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ACM MM</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
