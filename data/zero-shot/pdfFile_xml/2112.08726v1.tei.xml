<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NEUROLOGIC A esque Decoding: Constrained Text Generation with Lookahead Heuristics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ximing</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Welleck</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>West</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungo</forename><surname>Kasai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianhui</forename><surname>Qin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjae</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Allen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Artificial Intelligence ? Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">NEUROLOGIC A esque Decoding: Constrained Text Generation with Lookahead Heuristics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The dominant paradigm for neural text generation is left-to-right decoding from autoregressive language models. Constrained or controllable generation under complex lexical constraints, however, requires foresight to plan ahead feasible future paths.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Drawing inspiration from the A* search algorithm, we propose NEUROLOGIC A esque, 1 a decoding algorithm that incorporates heuristic estimates of future cost. We develop efficient lookahead heuristics that are efficient for large-scale language models, making our method a drop-in replacement for common techniques such as beam search and top-k sampling. To enable constrained generation, we build on NEUROLOGIC decoding , combining its flexibility in incorporating logical constraints with A esque estimates of future constraint satisfaction.</p><p>Our approach outperforms competitive baselines on five generation tasks, and achieves new state-of-the-art performance on table-totext generation, constrained machine translation, and keyword-constrained generation. The improvements are particularly notable on tasks that require complex constraint satisfaction or in few-shot or zero-shot settings. NEU-ROLOGIC A esque illustrates the power of decoding for improving and enabling new capabilities of large-scale language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The dominant paradigm for neural text generation is based on left-to-right decoding from autoregressive language models such as GPT-2/3 <ref type="bibr" target="#b46">(Radford et al., 2019;</ref><ref type="bibr" target="#b5">Brown et al., 2020)</ref>. Under this paradigm, common decoding techniques such as beam search or top-k/p sampling <ref type="bibr" target="#b19">(Holtzman et al., 2020)</ref>   <ref type="figure">Figure 1</ref>: NEUROLOGIC leverages lookahead heuristics to guide generations towards those that satisfy the given task-specific constraints. In this example from the COMMONGEN task, although summer is a more likely next word given the already-generated past, NEUROLOGIC looks ahead to see that selecting winter results in a generation that incorporates unsatisfied constraint snow with a higher probability later on. Thus, winter is preferred despite being lower probability than summer.</p><p>next based on what happened in the past, without explicitly looking ahead into the future. While this lack of foresight often suffices for open-ended text generation -where any coherent text can be acceptable -for constrained text generation, planning ahead is crucial for incorporating all desired content in the generated output <ref type="bibr" target="#b22">(Hu et al., 2017;</ref><ref type="bibr" target="#b10">Dathathri et al., 2019)</ref>. Classical search algorithms such as A* search <ref type="bibr" target="#b16">(Hart et al., 1968;</ref><ref type="bibr" target="#b40">Pearl, 1984;</ref><ref type="bibr" target="#b26">Korf, 1985)</ref> address the challenge of planning ahead by using heuristic estimation of future cost when making decisions. Drawing inspiration from A* search, we develop NEUROLOGIC A esque (shortened to NEUROLOGIC ), which combines A*-like heuristic estimates of future cost (e.g. perplexity, constraint satisfaction) with common decoding algorithms for neural text generation (e.g. beam search, top-k sampling), while preserving the efficiency demanded by large-scale neural language models.</p><p>As selecting the next token to generate based on the optimal future cost is NP-complete <ref type="bibr" target="#b9">(Chen et al., 2018)</ref>, we develop lookahead heuristics, which approximate cost at each decoding step based on continuations of the sequence-so-far. <ref type="figure">Figure 1</ref> shows an example, where NEUROLOGIC A esque guides generation towards a decision that would have been ignored based on the past alone, but is selected after looking ahead and incorporating the probability that constraints are satisfied in the future.</p><p>Our approach builds on NEUROLOGIC Decoding of , a variation of beam-search for controlling generation through rich logic-based lexical constraints expressed in Conjunctive Normal Form (CNF). Our work generalizes  by <ref type="formula" target="#formula_0">(1)</ref> incorporating novel lookahead heuristics to estimate future contraint satisfaction, and (2) developing additional unconstrained variants that can work with an empty set of constraints. These new algorithm variants support broad applications of NEUROLOGIC , including unconstrained generation, as demonstrated in our experiments.</p><p>Extensive experiments across five generation tasks demonstrate that our approach outperforms competitive baselines. We test NEUROLOGIC in conjunction with both supervised and unsupervised models and find that the performance gain is pronounced especially in zero-shot or few-shot settings. In particular, on the COMMONGEN benchmark, using our proposed decoding algorithm with an off-the-shelf language model outperforms a host of supervised baselines with conventional decoding algorithms. This demonstrates that a strong inference-time algorithm such as NEUROLOGIC can alleviate the need for costly datasets that are manually annotated for explicit supervision. Moreover, we find that NEUROLOGIC achieves stateof-the-art performance in various settings, including WMT17 English-German machine translation with lexical constraints <ref type="bibr" target="#b11">(Dinu et al., 2019)</ref> and fewshot E2ENLG table-to-text generation <ref type="bibr" target="#b8">(Chen et al., 2020b)</ref>.</p><p>In summary, we develop NEUROLOGIC A esque, a new decoding algorithm for effective and efficient text generation. To our knowledge this is the first A*-like algorithm for guided text generation via lookahead heuristics. Our algorithm is versatile, as it can be applied to a variety of tasks via inference-time constraints, reducing the need for costly labeled data. Extensive experiments show its effectiveness on several important generation benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">NEUROLOGIC A esque Decoding</head><p>We describe NEUROLOGIC A esque Decoding (shortened as NEUROLOGIC ), our decoding algorithm motivated by A * search <ref type="bibr" target="#b16">(Hart et al., 1968</ref>), a best-first search algorithm that finds high-scoring paths using a heuristic estimate of future return. We first introduce the decoding problem, and then describe our heuristics with a novel lookahead procedure for adapting NEUROLOGIC search to unconstrained and constrained generation with largescale autoregressive models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Decoding With A esque Lookahead</head><p>Decoding. Sequence-to-sequence generation is the task of generating an output sequence y given an input sequence x. We consider standard left-to-right, autoregressive models, p ? (y|x) = |y| t=1 p ? (y t |y &lt;t , x), and omit x to reduce clutter. Decoding consists of solving,</p><formula xml:id="formula_0">y * = arg max y?Y F (y).<label>(1)</label></formula><p>Where Y is the set of all sequences. In our setting, the objective F (y) takes the form s(y) + H(y), where s(y) is log p ? (y), and H(y) is either zero or is a score for satisfying constraints on y.</p><p>Our method takes the perspective of decoding as discrete search, in which states are partial prefixes, y &lt;t , actions are tokens in vocabulary V (i.e. y t ? V) and transitions add a token to a prefix, y &lt;t ? y t . Each step of decoding consists of 1) expanding a set of candidate next-states, 2) scoring each candidate, and 3) selecting the k best candidates:</p><formula xml:id="formula_1">Y t = {y &lt;t ? y t | y &lt;t ? Y t?1 , y t ? V}, Y t = arg topk (y&lt;t,yt)?Y t {f (y &lt;t , y t )} ,<label>(2)</label></formula><p>where Y 0 = { bos } and f (?) is a scoring function that approximates the objective F . Common decoding algorithms such as beam search score candidates without considering future tokens, e.g., f (y &lt;t , y t ) = log p ? (y ?t ).</p><p>Lookahead heuristics. Our method incorporates an estimate of the future into candidate selection. Ideally, we want to select candidates that are on optimal trajectories, replacing Equation 2 with:</p><formula xml:id="formula_2">Y t = arg topk (y&lt;t,yt)?Y t max y&gt;t F (y &lt;t , y t , y &gt;t ) .<label>(3)</label></formula><p>However, computing Equation 3 presents two difficulties: 1) the objective F (y) may be unknown or difficult to compute, and 2) the space of future trajectories y &gt;t is prohibitively large. Motivated by A * search <ref type="bibr" target="#b16">(Hart et al., 1968</ref>), a best-first search algorithm that finds high-scoring paths by selecting actions that maximize,</p><formula xml:id="formula_3">f (a) = s(a) + h(a),</formula><p>where s(a) is the score-so-far and h(a) is a heuristic estimate of the future score. We approximate the objective using a lightweight heuristic h(?),</p><formula xml:id="formula_4">Y t = arg topk y ?t ?Y t s(y ?t ) + max y&gt;t h(y &lt;t , y t , y &gt;t ) ,<label>(4)</label></formula><p>where s(y ?t ) = log p ? (y ?t ). To make the search tractable, we search over a set of lookahead continuations, approximating Equation 3 as,</p><formula xml:id="formula_5">Y t = arg topk y ?t ?Y t s(y ?t ) + max L (y ?t ) h(y ?t+ ) ,<label>(5)</label></formula><p>where each element y t+1:t+ of L (y ?t ) is a lengthcontinuation of y ?t . Beam search corresponds to setting and h to 0.</p><p>A esque decoding. Beam search, A* search, and our method fall under a general class of algorithms that differ based on (1) which candidates are expanded, (2) which candidates are pruned, (3) how candidates are scored <ref type="bibr" target="#b34">(Meister et al., 2020)</ref>. We inherit the practical advantages of beam search-style expansion and pruning, while drawing on A*-like heuristics to incorporate estimates of the future, and refer to our method as A esque decoding.</p><p>Generating lookaheads. We compare several methods for generating the lookaheads L (y ?t ).</p><p>The greedy lookahead produces a single sequence, L = {y t+1:t+ }, starting from y ?t and selecting each token according to y t = arg max y?V p ? (y|y &lt;t ).</p><p>We also consider a relaxation which interpolates between providing the greedy token and a uniform mixture of tokens as input at each step. Specifically, we adjust the model's probabilities with a temperature,p ? (y t |y &lt;t ) = softmax(s t /? ), where s t ? R |V| is a vector of logits, and feed the expected token embedding as input at step t,</p><formula xml:id="formula_6">e t = E yt?p(yt|y&lt;t) [E(y t )],<label>(6)</label></formula><p>where E ? R |V|?d is the model's token embedding matrix. This soft lookahead moves from providing the greedy token as input (? ? 0) to a uniform mixture of tokens (? ? ?) based on the value of temperature ? . When using the soft lookahead, we usep in place of p when scoring tokens. The soft (and greedy) lookahead is efficient, but only explores a single trajectory. The beam lookahead trades off efficiency for exploration, returning a set L containing the top-k candidates obtained by running beam search for steps starting from y &lt;t .</p><p>Finally, the sampling lookahead explores beyond the highly-probable beam search continuations, generating each y t+1:t+ ? L using,</p><formula xml:id="formula_7">y t ? p ? (y|y &lt;t ),</formula><p>for t from t+1 to t+k.</p><p>Next, we move to our proposed lookahead heuristics, starting with the unconstrained setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Unconstrained Generation with NEUROLOGIC</head><p>First we consider a standard decoding setting,</p><formula xml:id="formula_8">arg max y?Y log p ? (y|x).</formula><p>We score candidates based on a combination of the history and estimated future, by using the likelihood of the lookahead as a heuristic. That is, at the tth step of decoding, we use Equation <ref type="formula" target="#formula_5">5</ref>:</p><formula xml:id="formula_9">h(y ?t+ ) = ? log p ? (y t+1:t+ |y ?t , x),<label>(7)</label></formula><p>where ? controls how much we rely on the estimated future versus the history, similar to weighted A* <ref type="bibr" target="#b41">(Pohl, 1970)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">NEUROLOGIC for Constrained Generation</head><p>Our lookahead heuristics lend themselves to decoding with lexical constraints in a way that standard beam search does not. For constrained generation, we build on and generalize NEUROLOGIC decoding algorithm of Lu et al. (2021)-a beam-based search algorithm that supports a wide class of logical constraints for lexically constrained generationwith estimates of future contraint satisfaction.</p><p>Background of NEUROLOGIC. NEUROLOGIC  accepts lexical constraints in Conjunctive Normal Form (CNF):</p><formula xml:id="formula_10">D 1 ? D 2 ? ? ? ? D i C 1 ? ? ? ?? D i ? D i +1 ? ? ? ? D N C M</formula><p>where each D i represents a single positive or negative constraint, D(a, y) or ?D(a, y), enforcing the phrase a to be included in or omitted from y.  refer to each constraint D i as a literal, and each disjunction C j of literals as a clause. NEUROLOGIC is a beam-based approximate search for an objective which seeks fluent sequences in which all clauses are satisfied:</p><formula xml:id="formula_11">arg max y?Y p ? (y|x) ? ? M j=1 (1 ? C j ),</formula><p>where ? 0 penalizes unsatisfied clauses. At each step of the search, NEUROLOGIC scores each of the k?|V| candidates (y &lt;t , y t ) based on whether they (partially) satisfy new constraints,</p><formula xml:id="formula_12">f (y ?t ) = log p ? (y ?t |x) + ? 1 max D(a,y ?t ) |?| |a| ,<label>(8)</label></formula><p>where the maximization is over a set of unsatisfied multi-token constraints a tracked by NEURO-LOGIC, and? is the prefix of a in the ongoing generation. For example, for y ?t ="The boy climbs an apple" and constraint a="apple tree",? is "apple". Intuitively, this function rewards candidates that are in the process of satisfying a constraint.</p><p>In lieu of taking the top-k scoring candidates (Equation 5), NEUROLOGIC prunes candidates that contain clauses that violate constraints, groups the candidates to promote diversity, and selects highscoring candidates from each group. We use the same pruning and grouping approach, and refer the reader to  for further details.</p><p>NEUROLOGIC decoding. Our method improves upon the NEUROLOGIC scoring function with an estimate of future constraint satisfaction.</p><p>Our key addition is a lookahead heuristic that adjusts a candidate (y &lt;t , y t )'s score proportional to the probability of satisfying additional constraints in the lookahead y t+1:t+ :</p><formula xml:id="formula_13">h future (y ?t+ ) = ? 2 max D(a,y ?t ) log p ? (D(a, y t+1:t+ )|x, y ?t ), (9)</formula><p>where we define the probability that constraint a is satisfied using the most probable subsequence,</p><formula xml:id="formula_14">p ? (D(a, y t+1:t+ )|x, y ?t ) = max t ?[t,t+ ]</formula><p>p ? (y t :t +|a| = a|x, y &lt;t ), (10) ? 2 is a scaling hyperparameter for the heuristic.</p><p>Intuitively, this lookahead heuristic brings two benefits. When y t is a token that would satisfy a multi-token constraint, the lookahead incorporates the score of the full constraint. When y t is a token that is not part of a constraint, the lookahead allows for incorporating the score of a future constraint that would be satisfied if y t was selected.</p><p>We add our lookahead heuristic to the NEU-ROLOGIC scoring function <ref type="formula" target="#formula_12">(Equation 8</ref>), and call the resulting decoding procedure NEUROLOGIC A esque (or, NEUROLOGIC in short).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Supervision Constraints</head><p>Commonsense Generation zero+full w/ Machine Translation full w/  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments: Constrained Generation</head><p>We present experimental results on various constrained generation benchmarks: COMMONGEN ( ?3.1), constrained machine translation ( ?3.2), table-to-text generation ( ?3.3), and interrogative sentence generation ( ?3.4). NEUROLOGIC consistently outperforms NEUROLOGIC and all previous approaches. The improvement is especially substantial in zero-shot and few-shot cases where the search problem is much harder.</p><p>Experimental setups. We explore a variety of experimental setups <ref type="table" target="#tab_2">(Table 1</ref>). In terms of supervision, we consider different configurations of zeroshot, few-shot and full-shot. The former two supervision regimes are particularly important as many realistic generation application do not come with many manually-annotated labeled data. Additionally, we study both constrained and unconstrained tasks, even though we focus on the former.</p><p>Evaluation metrics. We use the following automatic metrics that are commonly used for evaluating text generation: BLEU <ref type="bibr" target="#b39">(Papineni et al., 2002)</ref>, ROUGE <ref type="bibr" target="#b31">(Lin, 2004)</ref>, METEOR <ref type="bibr" target="#b3">(Banerjee and Lavie, 2005)</ref>, CIDEr <ref type="bibr" target="#b48">(Vedantam et al., 2015)</ref>, SPICE <ref type="bibr" target="#b0">(Anderson et al., 2016)</ref> and NIST <ref type="bibr" target="#b32">(Lin and Hovy, 2003)</ref>. Any other domain specific metrics are detailed in each task description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Constrained Commonsense Generation</head><p>COMMONGEN <ref type="bibr" target="#b30">(Lin et al., 2020</ref>) is a constrained commonsense generation task with lexical constraints.    <ref type="bibr" target="#b18">(Hokamp and Liu, 2017)</ref>, DBA <ref type="bibr" target="#b42">(Post and Vilar, 2018a)</ref>, and NEUROLOGIC  Given a set of concepts (e.g., {throw, run, javelin, track}), the task is to generate a coherent sentence describing a plausible scenario using all of the given concepts (e.g., "a man runs on a track and throws a javelin.").</p><p>Approach and Baselines. Following , we enforce that each given concept c i must appear in output y under some morphological inflection. We experiment with both supervised and zero-shot settings. In the supervised setting, we formulate it as conditional sentence generation task and finetune GPT-2 <ref type="bibr" target="#b46">(Radford et al., 2019)</ref> as a sequence-to-sequence model. In the zero-shot setting, we use GPT-2 off-the-shelf (no fine-tuning), and rely on constrained decoding to guide the generations. We compare with previous constrained decoding algorithms, including CBS <ref type="bibr" target="#b1">(Anderson et al., 2017)</ref>, GBS <ref type="bibr" target="#b18">(Hokamp and Liu, 2017)</ref>, DBA <ref type="bibr" target="#b42">(Post and Vilar, 2018a)</ref>, NEUROLOGIC  and TSMH <ref type="bibr" target="#b55">(Zhang et al., 2020)</ref> Metrics Following <ref type="bibr" target="#b30">Lin et al. (2020)</ref>, we report automatic generation metrics as well as coverage, defined as the average percentage of the provided concepts that are present in lemmatized outputs. Additionally, we conduct human evaluation on 100 test examples with workers from Amazon Mechanical Turk (AMT). We include our evaluation template in <ref type="figure" target="#fig_3">Figure 5</ref> of Appendix A. Workers are given a pair of concepts and a model generation, and asked to rate each pair on language quality, scenario plausibility, coverage of given concepts, and an overall score, in the Likert scale: Agree, Neutral, and Disagree. Each pair is rated by 3 workers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>. <ref type="table" target="#tab_4">Table 2</ref> compares different constrained decoding methods on top of the finetuned and offthe-shelf GPT-2, in supervised and zero-shot settings respectively. The key observations are: 1. NEUROLOGIC outperforms all previous constrained-decoding methods in both supervised and zero-shot settings. Surprisingly, unsupervised NEUROLOGIC outperforms all supervised methods based on human evaluation. 2. Compared to vanilla NEUROLOGIC, NEUROLOGIC improves the generation quality while maintaining high constraint satisfaction. The difference is especially substantial in the zero-shot case, where there is more room for incorporating constraint-driven signals due to the lack of supervision and the large output space. 3. NEUROLOGIC reaches similar performance with different lookahead strategies, among which beam lookahead slightly outperforms the others based on human evaluation, and greedy lookahead has the lowest runtime.</p><p>Studying lookahead strategies. With an infinite lookahead length and number of lookaheads |L |, lookahead decoding exactly solves Equation 3. For practical choices of and |L |, we empirically study how varying the lookahead strategy and hyperparameters affects performance. In <ref type="figure" target="#fig_0">Figure 2</ref>, we study the greedy, soft, beam, and sampling lookahead strategies ( ?2.1). <ref type="figure" target="#fig_0">Figure 2(a)</ref> shows the effect of increasing the lookahead horizon for the greedy strategy. Increasing the horizon improves up to one pointe.g., 5-7 steps -then decreases thereafter, likely due to the difficulty of long-horizon approximation. <ref type="figure" target="#fig_0">Figure 2</ref>(b) studies the temperature in the soft lookahead, showing that greedy (? = 0.0) performs well, with slight gains if ? is carefully selected. The results suggest that one can safely bypass tuning ? using fast, greedy lookahead.</p><p>Next, <ref type="figure" target="#fig_0">Figure 2</ref>(c) shows that with beam lookahead, increasing the beam width improves performance up to a certain point <ref type="bibr">(here, 11)</ref>. Similarly, increasing the number of samples with sampling lookahead improves over a single sample, and then reaches an inflection point <ref type="figure" target="#fig_0">(Figure 2(d)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Constrained Machine Translation</head><p>It is often critical to have control over machine translation output. For example, domain-specific dictionaries can be incorporated to force a model   to use certain terminology <ref type="bibr" target="#b42">(Post and Vilar, 2018a;</ref><ref type="bibr" target="#b11">Dinu et al., 2019)</ref>. To achieve this goal, much recent work proposed constrained decoding algorithms <ref type="bibr" target="#b18">Hokamp and Liu, 2017;</ref><ref type="bibr" target="#b17">Hasler et al., 2018;</ref><ref type="bibr">Hu et al., 2019, inter alia)</ref> or specialized training <ref type="bibr" target="#b11">(Dinu et al., 2019)</ref>. We demonstrate that NEUROLOGIC can be readily applied to off-the-shelf MT systems for constrained machine translation. Specifically, we follow the setup in <ref type="bibr" target="#b11">Dinu et al. (2019)</ref>    and also specialized training proposed by <ref type="bibr" target="#b11">Dinu et al. (2019)</ref>. Following <ref type="bibr" target="#b11">Dinu et al. (2019)</ref>, we report BLEU scores and term use rates, computed as the percentage of times a given constraint term was generated in the output out of the total number of constraint terms.</p><p>Results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Table-to-text Generation</head><p>The table-to-text task aims to generate natural language text conditioned on structured table data; their applications include automatic generation of weather/sports reports <ref type="bibr" target="#b29">(Liang et al., 2009;</ref><ref type="bibr" target="#b53">Wiseman et al., 2017)</ref> or dialogue responses <ref type="bibr" target="#b51">(Wen et al., 2016)</ref>. Constrained generation algorithms can be used to ensure that the output text is consistent with the input structured data. We follow the few-shot setup of <ref type="bibr" target="#b8">Chen et al. (2020b)</ref> on the E2ENLG <ref type="bibr" target="#b13">(Du?ek et al., 2018)</ref> dataset, where we use randomly-sampled 0.1%, 0.5%, 1%, 5% of training instances for finetuning.</p><p>Approach, Baselines, and Metrics. Following <ref type="bibr" target="#b47">Shen et al. (2019)</ref>, we linearize the given table into a string and finetune GPT-2 with given few-shot examples. We first compare NEUROLOGIC with three previous constrained decoding algorithms: CBS <ref type="bibr" target="#b1">(Anderson et al., 2017)</ref>, GBS <ref type="bibr" target="#b18">(Hokamp and Liu, 2017)</ref>, and NEUROLOGIC , based on few-shot GPT-2 finetuned with 0.1% data. Then we compare our approach, NEUROLOGIC on top of GPT-2, with previous table-to-text methods, including TGen <ref type="bibr" target="#b12">(Du?ek and Jur???ek, 2016)</ref>, Template-GPT-2 <ref type="bibr" target="#b7">(Chen et al., 2020a)</ref>, KGPT <ref type="bibr" target="#b8">(Chen et al., 2020b)</ref>, in multiple few-shot settings with various numbers of training instances. We report standard automatic metrics used in the E2ENLG challenge, as well as information coverage-the   average percentage of given information that is present in the generation.</p><p>Results. <ref type="table" target="#tab_12">Table 6</ref> presents results from varying decoding algorithms based on few-shot GPT-2 finetuned with 0.1% of the data. NEUROLOGIC substantially outperforms all previous methods with respect to all metrics; it consistently improves generation quality while achieving (almost) perfect constraint satisfaction. Previous work, like CBS and GBS, improves constraint satisfaction, but negatively affects the text quality, as indicated by drops in BLEU and ROUGE. Table 7 compares NEUROLOGIC on top of GPT-2 with previous table-to-text approaches. As before, NEUROLOGIC outperforms all prior approaches by a large margin, even if the latter ones leverage either specialized model architecture or additional pretraining on massive table-to-text corpora. Additionally, <ref type="figure" target="#fig_1">Figure 3</ref> compares the performance (y-axis) of few-shot GPT-2 with NEUROLOGIC (purple line), NEUROLOGIC (blue line), and conventional beam search (black line) as a function of the varying amount of training instances (x-axis). We find the relative gain brought by NEUROLOGIC increases as we reduce the amount of few-shot examples. Results above demonstrate the promise of decoding algorithms to address unsatisfying performance in few-shot scenarios due to insufficient learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Decode Method</head><p>Automatic Evaluation Human Evaluation ROUGE BLEU METEOR CIDEr SPICE Coverage Grammar Fluency Meaningfulness Overall CGMH <ref type="bibr" target="#b35">(Miao et al., 2019)</ref> 28.8 2.0 18.0 5.5 21.5 18.3 2.28 2.34 2.11 2.02 TSMH <ref type="bibr" target="#b55">(Zhang et al., 2020)</ref> 42.0 4.3 25.9 10.4 37.7 92.7 2.35 2.28 2.37 2.22 NEUROLOGIC  38   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Constrained Question Generation</head><p>Despite the success of supervised techniques in natural language generation, it needs to be trained with massive task-specific data, which is non-trivial to acquire. We investigate a zero-shot text generation task proposed by <ref type="bibr" target="#b55">Zhang et al. (2020)</ref>: constrained question generation, where no training data is available. Given a set of keywords (e.g., Nevada, desert, border), the task is to use an off-the-self language model to generate an interrogative question containing given keywords (e.g., "What is the name of the desert near the border of Nevada?"). Two types of constraints are enforced for this task: 1) keyword constraints -the output question must include all the keywords provided, and 2) syntactic constraints -the output question must be in the interrogative form, the first word must be whquestion words, and the second or third word must be auxiliary verbs or copula words.</p><p>Approach, Baselines, and Metrics. We leverage off-the-shelf language model GPT-2 and compare NEUROLOGIC with three previous constrained decoding methods, CGMH <ref type="bibr" target="#b35">(Miao et al., 2019)</ref>, TSMH <ref type="bibr" target="#b55">(Zhang et al., 2020)</ref> and NEURO-LOGIC . CGMH and TSMH are two Metropolis-Hastings sampling-based decoding algorithms that have shown strong performance in unsupervised constrained generation. For automatic evaluation, we report standard generation metrics and keyword Coverage similar to previ- ous task COMMONGEN. For the human evaluation, we sample 100 test examples and employ workers from AMT to evaluate the generated interrogative questions. Workers are given a set of keywords and model generation. They are asked to evaluate the generation based on 3 individual qualities (i.e., grammar, fluency, meaningfulness) and provide an overall quality score, using the 3-point Likert scale. Each example is averaged across 3 workers. We include the human evaluation template in <ref type="figure" target="#fig_4">Figure 6</ref> of the Appendix A.</p><p>Results. <ref type="table" target="#tab_15">Table 8</ref> presents comparisons across different decoding methods based on off-the-shelf language models. We can see that NEUROLOGIC outperforms all previous methods with respect to both automatic and manual metrics; it remarkably enhances the generation quality while achieves perfect constraint satisfaction. The difference between NEUROLOGIC and NEUROLOGIC is particularly large compared to other tasks. The search problem is much harder here, due to the lack of supervision and complex logical constraint involving both keywords and syntax. Results above demonstrate the effectiveness of NEUROLOGIC in tackling more challenging constrained generation problems.   <ref type="bibr" target="#b19">(Holtzman et al., 2020;</ref><ref type="bibr" target="#b50">Welleck et al., 2019b)</ref>, (ii) improve sampling algorithms that are commonly used in open-ended generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Commonsense Story Generation</head><p>We investigate story generation with RocStories <ref type="bibr" target="#b36">(Mostafazadeh et al., 2016)</ref>. Given the first sentence as a prompt x, the task is to generate the rest of story continuation y.</p><p>Approach, Baselines and Metrics. We consider storytelling as a conditional generation task, and finetune GPT-2 as a sequence-to-sequence model. We apply A esque decoding with our unconstrained lookahead heuristic (Equation 7) to (i) beam search, the setting used so far in the experiments, and (ii) top-k sampling <ref type="bibr" target="#b14">(Fan et al., 2018)</ref>, a commonly used sampling algorithm in open-ended generation. For top-k sampling, we use the heuristic to adjust the probability scores, then renormalize.</p><p>For automatic evaluation, besides commonly used automatic metrics for storytelling, including perplexity and BLEU, we also report unique ngrams as a measure for diversity. For the human evaluation, we sample 100 stories from the test set and we employ workers from AMT to evaluate the model generations. Workers are given the first sentence of the story (i.e., prompt), and the model-generated continuation of the story. They are asked to evaluate the continuation of the story on 4 individual qualities (i.e., grammar, fluency, story flow, interestingness) and provide an overall quality score, using the 3-point Likert scale. Each example is averaged across 3 workers. We include the human evaluation template in <ref type="figure" target="#fig_5">Figure 7</ref> of the Appendix A.</p><p>Results. <ref type="table" target="#tab_17">Table 9</ref> presents the results of beam search and top-k sampling with and without A esque heuristics. We can see that A esque heuristics enable both beam search and top-k sampling to generate more fluent, coherent and interesting stories. For beam search, our A esque heuristic not only enhances generation quality-e.g. improving human evaluation scores from 2.32 to 2.63but also boosts generation diversity, as reflected by the number of unique n-grams. For top-k sampling, A* heuristics also improves generation quality, while maintaining comparable diversity. We notice that beam lookahead works the best for beam search, and greedy lookahead works the best for top-k sampling. We suspect that beam lookahead gives the most accurate estimate of the future path that beam search is likely to reach, while the greedy lookahead provides an estimate that is lower than what obtained by beam search, which may better resemble a continuation from top-k sampling.</p><p>Ablations. We study the effect of A esque decoding with different decoding hyperparameters: beam size in beam search and k value in top-k sampling. <ref type="figure" target="#fig_2">Figure 4</ref> plots the fluency (measured by likelihood) versus diversity (measured by unique 3-grams) for generations with various beam sizes or k values. Ideally, we want generations to be both fluent and diverse, centering around the top-right center. However, we observe a fluency and diversity tradeoff in practice. Interestingly, we observe that A esque decoding flattens this trend and results in larger area under the curve. The effect is especially obvious for beam search. The results above demonstrate that A esque decoding can guide generation towards a more favorable output space that cannot be reached with conventional decoding methods, regardless of decoding hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>A* search in NLP. Many classical NLP problems (e.g., parsing, text alignment) can be seen as structured prediction subject to a set of taskspecific constraints. For many such problems, A* search has been used effectively <ref type="bibr" target="#b38">(Och et al., 2001;</ref><ref type="bibr" target="#b15">Haghighi et al., 2007;</ref><ref type="bibr" target="#b20">Hopkins and Langmead, 2009;</ref><ref type="bibr" target="#b34">Meister et al., 2020)</ref>. For example, <ref type="bibr" target="#b25">Klein and Manning (2003)</ref>; <ref type="bibr" target="#b54">Zhang and Gildea (2006)</ref>; <ref type="bibr" target="#b2">Auli and Lopez (2011)</ref>; <ref type="bibr" target="#b28">Lee et al. (2016)</ref> have used it in the context of parsing. Similar approaches are used for finding high-probability alignments <ref type="bibr" target="#b37">(Naim et al., 2013)</ref>. Despite these applications, applying informed heuristic search to text generation with autoregressive language models has been underexplored, which is the focus of this work.</p><p>Decoding strategies for text generation. The rise of autoregressive language models like GPT <ref type="bibr" target="#b45">(Radford et al., 2018)</ref> has inspired a flurry of work on decoding strategies <ref type="bibr" target="#b42">(Post and Vilar, 2018a;</ref><ref type="bibr" target="#b23">Ippolito et al., 2019;</ref><ref type="bibr" target="#b56">Zheng et al., 2020;</ref><ref type="bibr">Leblond et al., 2021;</ref>. These works often focus on incorporating factors like diversity <ref type="bibr" target="#b23">(Ippolito et al., 2019)</ref>, fluency <ref type="bibr" target="#b19">(Holtzman et al., 2020)</ref> or constraints <ref type="bibr" target="#b1">(Anderson et al., 2017;</ref><ref type="bibr" target="#b18">Hokamp and Liu, 2017;</ref><ref type="bibr" target="#b43">Post and Vilar, 2018b;</ref><ref type="bibr" target="#b35">Miao et al., 2019;</ref><ref type="bibr" target="#b49">Welleck et al., 2019a;</ref><ref type="bibr" target="#b55">Zhang et al., 2020;</ref><ref type="bibr" target="#b44">Qin et al., 2020;</ref>. Among constrained decoding methods, previous works such as constrained beam search <ref type="bibr" target="#b1">(Anderson et al., 2017)</ref> and grid beam search <ref type="bibr" target="#b18">(Hokamp and Liu, 2017)</ref>, have worked on extending beam search to satisfy lexical constraints during generation.</p><p>Other works have focused on the mismatch between monotonic decoding and satisfying constraints that may depend on a full generation. <ref type="bibr" target="#b35">Miao et al. (2019)</ref> propose a sampling-based conditional generation method using Metropolis-Hastings sampling (CGMH), where the constrained words are inserted/deleted/edited by the Metropolis-Hastings scheme, allowing a full generation to be edited towards desired properties. <ref type="bibr" target="#b49">Welleck et al. (2019a)</ref> develop a tree-based constrained text generation, which recursively generates text in a nonmonotonic order given constraint tokens, ensuring constraints are satisfied. <ref type="bibr" target="#b55">Zhang et al. (2020)</ref> proposes tree search enhanced MCMC that handles combinatorial constraints (TSMH). <ref type="bibr" target="#b44">Qin et al. (2020)</ref> instead casts constrained decoding as a con-tinuous optimization problem that permits gradientbased updates.  encodes constraints as generated contexts which models condition on to encourage satisfaction. Compared to these past works, NEUROLOGIC A esque explicitly samples future text to estimate viability of different paths towards satisfying constraints. Our approach is based on , which incorporates constraints in Conjunctive Normal Form (CNF), but we extend this into the future with our lookahead heuristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Inspired by the A* search algorithm, we introduce NEUROLOGIC A esque decoding, which brings A*-like heuristic estimates of the future to common left-to-right decoding algorithms for neural text generation. NEUROLOGIC A esque's lookahead heuristics improve over existing decoding methods (e.g., NEUROLOGIC, beam, greedy, sample decoding methods) in both constrained and unconstrained settings across a wide spectrum of tasks. Our work demonstrates the promise of moving beyond the current paradigm of unidirectional decoding for text generation, by taking bidirectional information from both the past and future into account to generate more globally compatible text.</p><p>We include screenshots of the human evaluation templates for CommonGen ( <ref type="figure" target="#fig_3">Figure 5</ref>), Interrogative Sentence Generation ( <ref type="figure" target="#fig_4">Figure 6)</ref>, and RocStories ( <ref type="figure" target="#fig_5">Figure 7)</ref> tasks.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Performance (y-axis) of supervised GPT-2 in terms of BLEU-4 and Coverage with varying lookahead parameters (x-axis) on COMMONGEN validation set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Performance (y-axis) of supervised GPT-2 on E2ENLG, with a varying amount of training data for supervision (x-axis). The purple, blue, and black line denote decoding with NEUROLOGIC , NEUROLOGIC and conventional beam search respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Likelihood (y-axis) vs. number of unique 3grams (x-axis) using supervised GPT-2 on RocStories. Figure (a) denotes decoding with beam search, with a varying amount of beam size. Figure (b) denotes decoding with top-k sampling, with a varying amount of k value. The brown and blue line denotes with and without A esque heuristics separately.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Human evaluation template for the Constrained Commonsense Generation task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Human evaluation template for the Interrogative Sentence Generation task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Human evaluation template for the RocStories task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>determine which token to generate ? Co-second-authors. Other authors are listed alphabetically, as all contributed significantly.</figDesc><table><row><cell cols="2">Write a sentence with these concepts</cell></row><row><cell cols="2">car drive snow</cell></row><row><cell></cell><cell>summer on the road p (w | p a st ) = 0 .4</cell><cell>? A ?</cell></row><row><cell>I drive my car during the</cell><cell cols="2">winter through the snow ? p( w | pa st ) = 0. 2</cell></row></table><note>1 pronounced [ey stAr Esk].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table -</head><label>-</label><figDesc></figDesc><table><row><cell>to-text Generation</cell><cell>few</cell><cell>w/</cell></row><row><cell>Question Generation</cell><cell>zero</cell><cell>w/</cell></row><row><cell>Commonsense Story Generation</cell><cell>full</cell><cell>w/o</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Tasks and setups considered in this work.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Performance of various decoding methods with supervised or off-the-shelf GPT-2 on the COMMONGEN test set, measured with automatic and human evaluations. We only tried NEUROLOGIC (greedy) in the unsupervised setting because of the computational cost. The best numbers are bolded and the second best ones are underlined. run over by a ball and bites his mouth. mouth NEUROLOGIC A dog is running and chewing on a ball in its mouth.</figDesc><table><row><cell>Words</cell><cell>Method</cell><cell>Generation</cell></row><row><cell>cut</cell><cell>GBS</cell><cell>Cut a piece of wood to use as a fence.</cell></row><row><cell cols="2">piece DBA</cell><cell>Cut a piece of wood to use as a fence.</cell></row><row><cell>use</cell><cell cols="2">NEUROLOGIC Piece of wood used for cutting.</cell></row><row><cell cols="3">wood NEUROLOGIC A man cuts a piece of wood using a circular saw.</cell></row><row><cell>ball</cell><cell>GBS</cell><cell>A dog is run over by a ball and mouth agape.</cell></row><row><cell>dog</cell><cell>DBA</cell><cell>A dog is</cell></row></table><note>run NEUROLOGIC A dog running with a ball in its mouth.dog GBS Soap and water scrubbed dog with a towel. scrub DBA Soap and water on a dog and scrubbed skin. soap NEUROLOGIC A dog is scrubbing his paws with soap and water. water NEUROLOGIC A man is scrubbing a dog with soap and water.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Example generations for the COMMONGEN task across supervised NEUROLOGIC and baselines, including GBS</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Results on constrained machine translation.</figDesc><table><row><cell cols="5">The left section uses the same two-layer transformer</cell></row><row><cell cols="5">model as Dinu et al. (2019) for fair comparisons. The</cell></row><row><cell cols="5">right one decodes a stronger Marian MT EN-DE model.</cell></row><row><cell cols="5">The highlighted methods modify training data specifi-</cell></row><row><cell cols="5">cally for constrained decoding, and thus cannot be ap-</cell></row><row><cell cols="5">plied to off-the-shelf models. The best numbers are</cell></row><row><cell cols="5">bolded and the second best ones are underlined.</cell></row><row><cell># T</cell><cell># Sents.</cell><cell>Decode Method</cell><cell>BLEU</cell><cell>Term%</cell></row><row><cell></cell><cell></cell><cell>Beam search</cell><cell>25.4</cell><cell>79.6</cell></row><row><cell>1</cell><cell>378</cell><cell>NEUROLOGIC</cell><cell>26.2</cell><cell>95.2</cell></row><row><cell></cell><cell></cell><cell>NEUROLOGIC</cell><cell>26.3</cell><cell>95.8</cell></row><row><cell></cell><cell></cell><cell>Beam search</cell><cell>28.1</cell><cell>85.0</cell></row><row><cell>2+</cell><cell>36</cell><cell>NEUROLOGIC</cell><cell>28.9</cell><cell>93.7</cell></row><row><cell></cell><cell></cell><cell>NEUROLOGIC</cell><cell>29.3</cell><cell>96.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note>Constrained Machine Translation performance broken down by the number of constraint terms (# T). All configurations use the two-layer tranformer from Dinu et al. (2019). The best numbers are bolded and the second best ones are underlined.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>presents experimental results</cell></row><row><cell>with Dinu et al.'s model and Marian MT. We can</cell></row><row><cell>see that in either case, NEUROLOGIC outper-</cell></row><row><cell>forms all prior methods both in BLEU and term</cell></row><row><cell>coverage. Besides better generation quality and</cell></row><row><cell>constraint coverage, NEUROLOGIC also benefits</cell></row><row><cell>from its plug-and-play flexibility with any off-the-</cell></row><row><cell>shelf MT system compared to previous training-</cell></row><row><cell>based methods. Table 5 breaks down the model</cell></row><row><cell>performance by the number of constraint terms.</cell></row><row><cell>We see that NEUROLOGIC improves upon the</cell></row><row><cell>others, especially when the constraint is complex</cell></row><row><cell>with multiple constraint terms. (e.g., 96.5 vs. 93.7</cell></row><row><cell>from NEUROLOGIC in term coverage).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 6 :</head><label>6</label><figDesc>Performance of different decoding methods with few-shot GPT-2 finetuned on 0.1% E2ENLG data. The best numbers are bolded and the second best ones are underlined.</figDesc><table><row><cell>Method</cell><cell cols="2">0.1% 0.5% 1% 5%</cell></row><row><cell>TGen (Du?ek and Jur???ek, 2016)</cell><cell>3.6</cell><cell>27.9 35.2 57.3</cell></row><row><cell cols="2">Template-GPT-2 (Chen et al., 2020a) 22.5</cell><cell>47.8 53.3 59.9</cell></row><row><cell>KGPT-Graph (Chen et al., 2020b)</cell><cell>39.8</cell><cell>53.3 55.1 61.5</cell></row><row><cell>KGPT-Seq (Chen et al., 2020b)</cell><cell>40.2</cell><cell>53.0 54.1 61.1</cell></row><row><cell>GPT-2</cell><cell>42.8</cell><cell>57.1 56.8 61.1</cell></row><row><cell>GPT-2 + NEUROLOGIC</cell><cell>47.6</cell><cell>56.9 58.0 62.9</cell></row><row><cell>GPT-2 + NEUROLOGIC (greedy)</cell><cell>49.2</cell><cell>58.0 58.4 63.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell>: Few-shot results (BLEU-4) on E2ENLG test</cell></row><row><cell>set with 0.1%, 0.5%, 1%, 5% of training instances. The</cell></row><row><cell>best numbers are bolded and the second best ones are</cell></row><row><cell>underlined.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 8 :</head><label>8</label><figDesc>Performance of different unsupervised decoding algorithms on interrogative question generation.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 9 :</head><label>9</label><figDesc>Performance of different decoding algorithms on RocStories test set.</figDesc><table><row><cell>4 Experiments: Unconstrained</cell></row><row><cell>Generation</cell></row><row><cell>So far we have experimented with constrained</cell></row><row><cell>text generation, but here we demonstrate that</cell></row><row><cell>NEUROLOGIC decoding can also improve un-</cell></row><row><cell>constrained generation. Specifically, we investigate</cell></row><row><cell>whether A esque decoding with our unconstrained</cell></row><row><cell>lookahead heuristic (Equation 7) can (i) improve</cell></row><row><cell>beam search, which typically struggles in open-</cell></row><row><cell>ended settings</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/mtresearcher/ terminology_dataset.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work was supported in part by Natural Sciences and Engineering Research Council of Canada (NSERC) (funding reference number 401233309), DARPA MCS program through NIWC Pacific (N66001-19-2-4031), Google Cloud Compute, and Allen Institute for AI, Microsoft PhD Fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Spice: Semantic propositional image caption evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basura</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="382" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Guided open vocabulary image captioning with constrained beam search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basura</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1098</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="936" to="945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient CCG parsing: A* versus adaptive supertagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1577" to="1585" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Meteor: An automatic metric for mt evaluation with improved correlation with human judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satanjeev</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization</title>
		<meeting>the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Findings of the 2017 conference on machine translation (WMT17)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ond?ej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Rubino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-4717</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Conference on Machine Translation</title>
		<meeting>the Second Conference on Machine Translation<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="169" to="214" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kr?ger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Benjamin Chess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Guiding neural machine translation decoding with external knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Blain</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-4716</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Conference on Machine Translation</title>
		<meeting>the Second Conference on Machine Translation<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="157" to="168" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Logical natural language generation from open-domain tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.708</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7929" to="7942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">KGPT: Knowledge-grounded pretraining for data-to-text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.697</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8635" to="8648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Recurrent neural networks as weighted language recognizers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sorcha</forename><surname>Gilroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Maletti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1205</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2261" to="2271" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Plug and play language models: A simple approach to controlled text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumanth</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janice</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piero</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosanne</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Training neural machine translation to apply terminology constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashant</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Al-Onaizan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1294</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3063" to="3068" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sequence-tosequence generation for spoken dialogue via deep syntax trees and strings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ond?ej</forename><surname>Du?ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Jur???ek</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-2008</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="45" to="51" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Findings of the E2E NLG Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ond?ej</forename><surname>Du?ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jekaterina</forename><surname>Novikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><surname>Rieser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 11th International Conference on Natural Language Generation</title>
		<meeting>of the 11th International Conference on Natural Language Generation<address><addrLine>Tilburg, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="322" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hierarchical neural story generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1082</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="889" to="898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Approximate factoring for A* search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference</title>
		<meeting><address><addrLine>Rochester, New York</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="412" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A formal basis for the heuristic determination of minimum cost paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><forename type="middle">J</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertram</forename><surname>Raphael</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSSC.1968.300136</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems Science and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="100" to="107" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural machine translation decoding with terminology constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Hasler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adri?</forename><surname>De Gispert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gonzalo</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Byrne</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2081</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Short Papers; New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="506" to="512" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lexically constrained decoding for sequence generation using grid beam search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1141</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1535" to="1546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The curious case of neural text degeneration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cube pruning as heuristic search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Langmead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="62" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improved lexically constrained decoding for translation and monolingual rewriting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Edward</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Culkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1090</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="839" to="850" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Toward controlled generation of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1587" to="1596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Comparison of diverse decoding methods from conditional language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reno</forename><surname>Kriz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><surname>Sedoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Kustikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3752" to="3762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Marian: Fast neural machine translation in C++</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Dwojak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Neckermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Germann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alham</forename><surname>Fikri Aji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nikolay Bogoychev, Andr? F. T. Martins, and Alexandra Birch</title>
		<meeting><address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="116" to="121" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL 2018, System Demonstrations. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A* parsing: Fast exact Viterbi parse selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Depth-first iterative-deepening: An optimal admissible tree search. Artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Korf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="97" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Leblond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Baptiste</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miruna</forename><surname>Pislar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Baptiste</forename><surname>Lespiau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.05336</idno>
		<title level="m">Ioannis Antonoglou, Karen Simonyan, and Oriol Vinyals. 2021. Machine translation decoding beyond beam search</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Global neural CCG parsing with optimality guarantees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1262</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2366" to="2376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning semantic correspondences with less supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Commongen: A constrained text generation challenge for generative commonsense reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangchunshu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Rouge: A package for automatic evaluation of summaries. Text Summarization Branches Out</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Automatic evaluation of summaries using n-gram cooccurrence statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="150" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Neuro-Logic decoding: (un)supervised neural text generation with predicate logic constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ximing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.339</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="4288" to="4299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Best-first beam search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Meister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="795" to="809" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Cgmh: Constrained sentence generation by metropolis-hastings sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6834" to="6842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A corpus and cloze evaluation for deeper understanding of commonsense stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1098</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="839" to="849" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Text alignment for real-time crowd captioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iftekhar</forename><surname>Naim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Lasecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="201" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An efficient a* search algorithm for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Ueffing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2001 Workshop on Data-Driven Methods in Machine Translation</title>
		<meeting>the ACL 2001 Workshop on Data-Driven Methods in Machine Translation</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Heuristics -intelligent search strategies for computer problem solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Addison-Wesley series in artificial intelligence</title>
		<imprint>
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">First Results on the Effect of Error in Heuristic Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Pohl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Fast lexically constrained decoding with dynamic beam allocation for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1119</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Long Papers; New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1314" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Fast lexically constrained decoding with dynamic beam allocation for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1314" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Backpropagationbased decoding for unsupervised counterfactual and abductive reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianhui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jena</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Tim Salimans, and Ilya Sutskever</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI Blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Pragmatically informative text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1410</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4060" to="4067" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Cider: Consensus-based image description evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4566" to="4575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Non-monotonic sequential text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiant?</forename><surname>Brantley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><forename type="middle">Daum?</forename><surname>Iii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6716" to="6726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Neural text generation with unlikelihood training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilia</forename><surname>Kulikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Multi-domain neural network language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Ga?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">M</forename><surname>Mrk?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1015</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="120" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Reflective decoding: Beyond unidirectional generation with off-the-shelf language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ximing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jena</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL/IJCNLP</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Challenges in data-to-document generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Efficient search for inversion transduction grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="224" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Language generation via combinatorial constraint satisfaction: A tree search enhanced Monte-Carlo approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yexiang</forename><surname>Xue</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.115</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1286" to="1298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Opportunistic decoding with timely correction for simultaneous translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingbo</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baigong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaibo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="437" to="442" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
