<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unified Negative Pair Generation toward Well-discriminative Feature Space for Face Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junuk</forename><surname>Jung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University of Technology and Education (KOREATECH)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seonhoon</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University of Technology and Education (KOREATECH)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heung-Seon</forename><surname>Oh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University of Technology and Education (KOREATECH)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Park</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University of Technology and Education (KOREATECH)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joochan</forename><surname>Park</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University of Technology and Education (KOREATECH)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungbin</forename><surname>Son</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University of Technology and Education (KOREATECH)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Unified Negative Pair Generation toward Well-discriminative Feature Space for Face Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Figure 1</ref><p>: Similarity distributions viewed from pair generation perspective for approximating WDFS. The bottom line presents similarity distributions in feature space after sufficiently learning in their own ways with the top line. S p and S n are positive and negative similarity sets and? p and? n are subsets of S p and S n , respectively. (a) The ideal similarity sets satisfying inf S p &gt; sup S n after learning with S p and S n . ? p max and ? n min are the max and min angles among positive and negative pairs. (b) Using a vanilla loss, no overlap between? p and? n results in an overlap between S p and S n . (c) Using a marginal loss, an overlap between? p and? n by shifting? p reduces an overlap after learning. (d) Using more negative pairs, an overlap between? p and? n by shifting? p and enlarging? n significantly reduces the overlap after learning. deficiency. Moreover, it includes filtering the similarities of noisy negative pairs to guarantee reliable convergence and improved performance. Exhaustive experiments show the superiority of UNPG by achieving state-of-the-art performance across recent loss functions on public benchmark datasets. Our code and pretrained models are publicly available ? .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>The goal of face recognition (FR) can be viewed as a pair similarity optimization problem, maximizing a similarity set S p over positive pairs, while minimizing similarity set S n over negative pairs. Ideally, it is expected that FR models form a well-discriminative feature space (WDFS) that satisfies inf S p &gt; sup S n . With regard to WDFS, the existing deep feature learning paradigms (i.e., metric and classification losses) can be expressed as a unified perspective on different pair generation (PG) strategies. Unfortunately, * corresponding author in the metric loss (ML), it is infeasible to generate negative pairs taking all classes into account in each iteration because of the limited mini-batch size. In contrast, in classification loss (CL), it is difficult to generate extremely hard negative pairs owing to the convergence of the class weight vectors to their center. This leads to a mismatch between the two similarity distributions of the sampled pairs and all negative pairs. Thus, this paper proposes a unified negative pair generation (UNPG) by combining two PG strategies (i.e., MLPG and CLPG) from a unified perspective to alleviate the mismatch. UNPG introduces useful information about negative pairs using MLPG to overcome the CLPG</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of face recognition (FR) can be viewed as a pair similarity optimization problem that maximizes a similarity set S p over positive pairs while minimizing a similarity set S n over negative pairs. Regardless of FR tasks such as face verification (1:1) and face identification (1:N), it is expected that FR models form a well-discriminative feature space (WDFS) that satisfies inf S p &gt; sup S n as shown in <ref type="figure">Fig. 1 (a)</ref>. To this end, previous research advances pair similarity optimization <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b38">39]</ref> by enhancing intra-class compactness and inter-class dispersion.</p><p>In deep feature learning paradigms for pair similarity optimization, loss functions in FR can be categorized based on two approaches: metric loss (ML; e.g., triplet loss <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23]</ref> and N-pair loss <ref type="bibr" target="#b25">[26]</ref>) and classification loss (CL; e.g., softmax loss <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30]</ref>). The former directly performs the optimization with a pair of deep feature vectors using a pairwise label whereas the latter performs indirectly with a pair of deep feature and class weight vectors using a class-level label. Recently, in circle loss <ref type="bibr" target="#b26">[27]</ref>, two different approaches were expressed as a unified loss function since their intent and behaviors pursued the same objective of maximizing a similarity set S p over positive pairs, while minimizing it over negative pairs. We decomposed the unified loss function into pair generation (PG) and similarity computation (SC) without loss of generality. While SC focuses on computing the similarity between two samples in a pair, PG focuses on generating a pair using vectors of deep features or class weights. In the unified loss function, the only difference between ML and CL is PG, because various methods in SC can be applied to both ML and CL in the same manner. Consequently, the core of FR research from a unified perspective is the generation of informative pairs, i.e., PG. This is crucial because only a limited number of pairs are trainable in each iteration owing to the large computational costs incurred. Based on the assumption that pairs sampled from mini-batches can represent the entire feature space, the existing methods decrease the loss to a pair as it approaches WDFS, whereas they increase the loss in the opposite case.</p><p>We observed the reason why FR models trained sufficiently fail to approach WDFS. This stems from the mismatch of similarity distributions between the sampled pairs ? https://github.com/Jung-Jun-Uk/UNPG.git and all pairs. <ref type="figure">Fig. 1 (b)</ref> shows an example of two similarity sets? p and? n of positive and negative pairs, respectively, sampled from mini-batches. A FR model is rarely trainable with? p and? n because they are well-separated with almost no overlap. To deal with this problem, a line of research <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b38">39]</ref> devises marginal loss functions to reduce the gap by shifting? p , as shown in <ref type="figure">Fig.  1 (c)</ref>. In general, marginal CL functions show better performance than ML functions on large-scale datasets <ref type="bibr" target="#b4">[5]</ref>. However, there still exists a mismatch between the sampled pairs and all pairs because it is difficult to obtain too-hard negative pairs. This paper proposes unified negative pair generation (UNPG) by combining two PG strategies (i.e., MLPG and CLPG) from a unified perspective to alleviate the mismatch. Moreover, it includes filtering noise-negative pairs, such as too-easy/hard negative pairs, in order to guarantee reliable convergence and improve performance. Consequently, UNPG helps approach WDFS, as shown in <ref type="figure">Fig. 1  (d)</ref>. Through experiments, we demonstrate the superiority of UNPG by achieving state-of-the-art performance using recent loss functions equipped with UNPG on public benchmark datasets (IJB-B <ref type="bibr" target="#b36">[37]</ref>, IJB-C <ref type="bibr" target="#b16">[17]</ref>, MegaFace <ref type="bibr" target="#b11">[12]</ref>, LFW <ref type="bibr" target="#b9">[10]</ref>, CFPFP <ref type="bibr" target="#b23">[24]</ref>, AgeDB-30 <ref type="bibr" target="#b18">[19]</ref>, CALFW <ref type="bibr" target="#b40">[41]</ref>, and K-FACE <ref type="bibr" target="#b1">[2]</ref>) and deliver an in-depth analysis of the reasons behind UNPG. The contributions of this study are summarized as follows:</p><p>? We propose unified negative pair generation (UNPG), which alleviates the mismatch between the distributions of the sampled pairs and entire negative pairs. UNPG is simple and easy to adapt to existing CL functions with only a minor modification.</p><p>? We demonstrate the superiority of UNPG by achieving state-of-the-art performance using recent loss functions equipped with UNPG on public benchmark datasets for face verification and identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>FR is one of the most promising computer-vision tasks. In recent times, the combination of the following three factors has contributed to the rapid growth of this technology: 1) introduction to large-scale face datasets <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b37">38]</ref>, 2) development of effective backbone models <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29]</ref>, 3) novel loss functions <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b33">34]</ref>. Among them, loss functions have been actively developed and can be categorized into metric and classification losses. Metric Loss. Early direct optimization methods include contrastive loss <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6]</ref> and triplet loss <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23]</ref>, which use the similarity between pairs or triplets in the feature space. They try to make positive samples close and push negative samples far away, but often suffer from slow conver-gence and poor local optima because they only learn 1:1 relationships in positive and negative pairs. Thus, liftedstructure loss <ref type="bibr" target="#b19">[20]</ref> and N-pair loss <ref type="bibr" target="#b25">[26]</ref> were designed to address this issue. They build massive negative samples and one positive sample based on the same anchor point and learn their relationship simultaneously. Subsequently, other methods have been developed to create more informative pairs. Multi-similarity loss <ref type="bibr" target="#b34">[35]</ref> classifies existing studies into three types of similarities and devises pair mining and pair weighting methods that satisfy them simultaneously. Tuplet-margin loss <ref type="bibr" target="#b38">[39]</ref> provides a slack margin to prevent overfitting from hard triplets. Despite these efforts, ML still faces a problem: The negative pairs generated by each iteration cannot represent all identities because FR datasets <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b37">38]</ref> usually have more classes than a mini-batch size.</p><p>Classification Loss. Early indirect optimization methods include softmax loss <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30]</ref>, which uses the similarity between the deep feature and class weight vectors. Softmax loss has been widely applied in classification problems, but it is not appropriate for FR because testing is done by similarity comparison, not classification. Hence, two methods are being investigated to modify the softmax logit to form a feature space suitable for FR. The first is the normalization of the deep feature and class weight vectors <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34]</ref> to reduce the gap between the training and test phases mapped to the cosine similarity space. This is motivated by the interpretation of the feature space of studies such as centerloss <ref type="bibr" target="#b35">[36]</ref>, L-softmax <ref type="bibr" target="#b14">[15]</ref>, and NormFace <ref type="bibr" target="#b32">[33]</ref>. The second is a margin assignment technique <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34]</ref>, which is performed in various ways to enhance intra-class compactness and inter-class dispersion. CosFace <ref type="bibr" target="#b33">[34]</ref> and Arc-Face <ref type="bibr" target="#b3">[4]</ref>, which are typical margin-based loss functions, add external and internal margins to cosine angles, respectively. Recently, MagFace <ref type="bibr" target="#b17">[18]</ref> introduced a new margin and regularizer technique within several constraints that assumed a positive correlation between magnitude and face quality and ensured convergence. This improved FR performance by creating discriminative features. However, in our interpretation, there is a problem that extremely hard negative similarities in the feature space cannot be expressed by the indirect optimization method alone.</p><p>Multi Objective Loss &amp; Unified Loss. Multi-objective loss tried to combine two different losses with a mixture weight at the surface level. MixFace <ref type="bibr" target="#b10">[11]</ref> attempted to combine the metric and classification losses (i.e., L mix = L arc + L sn?pair ) with an analysis of their advantages and disadvantages. However, it is a mixture at the surface level and not a unified loss function. According to the Circleloss <ref type="bibr" target="#b26">[27]</ref>, the two existing approaches (i.e., metric and classification losses) can be expressed as a unified loss function. It also adds independent weight factors to deal with ambiguous convergence but is limited in generating pairs (e.g., Circle-loss <ref type="bibr" target="#b26">[27]</ref> used only MLPG).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>Unified Loss. According to <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>, the classification and metric losses can be expressed as a unified loss function (i.e., cross-entropy loss). Suppose that? p = {s p i |i = 1, 2, ..., K} and? n = {s n j |j = 1, 2, ..., L} are the similarity scores for K positive and L negative pairs, respectively. Then, the unified loss function is defined as:</p><formula xml:id="formula_0">L uni = 1 K K i=1 L uni i , L uni i = ? log e ?s p i e ?s p i + L j=1 e ?s n j = log [1 + L j=1 e ?(s n j ?s p i ) ]<label>(1)</label></formula><p>where ? is a positive scale factor. The only difference between the two losses is the method of computing? p and? n . We break down this step into PG and SC to clearly explain our proposed method without loss of generality. Pair Generation (PG). In a feature space, let us assume that x i and x j are i-th and j-th samples in N -sized minibatch and y i and y j are corresponding target classes, respectively. w yj is a class weight vector of j-th class. Then, we generate positive and negative pair sets P and N for the metric (Eq. 2) and classification (Eq. 3) losses, respectively:</p><formula xml:id="formula_1">P ml = {(x i , x j )|y i = y j } N ml = {(x i , x j )|y i = y j } (2) P cl i = (x i , w yi ) N cl i = {(x i , w j )|j = y i }<label>(3)</label></formula><p>In ML, a pair is composed of two samples (e.g., x i and x j ) from a mini-batch, and is composed of a sample and a class weight vector (e.g., x i and w yi ) in CL. We denote MLPG and CLPG for PG of the metric and classification losses, respectively. Similarity Computation (SC). We can compute the similarity sets? p and? n obtained from PG. The metric and classification losses employ the same similarity method for the same type of pair sets (i.e., positive sets P ml and P cl and negative sets N ml and N cl ). Recent research has focused on improving the cosine similarity using a margin. Let us define the angle between two vectors as ?(a, b) = arccos (a T b/ a b ). Then, SN-pair <ref type="bibr" target="#b10">[11]</ref> computes? p and? n for P ml and N ml as: There is a line <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b33">34]</ref> of research that employs a margin in cosine similarity. In CosFace <ref type="bibr" target="#b32">[33]</ref>, margin m is placed outside cosine for? p . Thus,? p and? n are computed for P cl i and N cl i as:</p><formula xml:id="formula_2">S p = {cos ?(x i , x j )|y i = y j } S n = {cos ?(x i , x j )|y i = y j }<label>(4)</label></formula><formula xml:id="formula_3">S p i = {cos ?(x i , w yi ) + m} S n i = {cos ?(x i , w j )|j = y i }<label>(5)</label></formula><p>On the other hand, ArcFace <ref type="bibr" target="#b3">[4]</ref> places margin m inside cosine:</p><formula xml:id="formula_4">? p i = {cos (?(x i , w yi ) + m)}<label>(6)</label></formula><p>In other research using margins such as SphereFace <ref type="bibr" target="#b13">[14]</ref> and MagFace <ref type="bibr" target="#b17">[18]</ref>,? p and? n can be derived similarly without loss of generality. Unified Negative Pair Generation (UNPG). We address the fact that PG is the only difference between metric and classification losses from a unified perspective. Previous studies <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b38">39]</ref> attempted to reduce the gap between S p and? p by devising various margin-based methods. Evidently, there is no concern about the gap between S n and? n even though it is a critical component in computing a loss. There are several reasons that cause the gap between S n and? n . In ML, it is infeasible to generate negative pairs taking all classes into account in each iteration because of the limited mini-batch size. In CL, it is difficult to generate too-hard negative pairs owing to the convergence of the class weight vectors to their center. This paper proposes unified negative pair generation (UNPG) by combining MLPG and CLPG strategies from a unified perspective to alleviate the mismatches of (S n ,? n ) and (S p ,? p ), together. UNPG introduces useful information about negative pairs using MLPG to overcome the CLPG deficiency. In UNPG, a negative pair set N uni i and the corresponding similarity set? n i are defined as:</p><formula xml:id="formula_5">N uni i = N cl i ? N ml S n i = {cos ?(x i , w j )|j = y i } ? {cos ?(x i , x j )|y i = y j } (7) S n i can be computed from N uni i</formula><p>using various methods such as Eqs. 4 and 5. Decomposing SC and PG can lead to wide research directions in FR. As a result, the unified loss with UNPG is defined as:</p><formula xml:id="formula_6">L uni i = ? log P i = ? log e ?s p i e ?s p i + L cl j=1 e ?s n j + L ml k=1 e ?s n k<label>(8)</label></formula><p>where L cl = |N cl i | and L ml = |N ml |. Note that the normalization term in Eq. 8 uses the scores from N ml . <ref type="figure" target="#fig_0">Fig.  2</ref> visualizes Eq. 8, where UNPG uses the similarity score matrix obtained from N ml at each mini-batch and then duplicates it by the size of the mini-batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Noise Negative Pair Filtering.</head><p>Require: s n j ?? n from N ml , wisker size r Extract the lower 25% similarity s n l Extract the upper 25% similarity s n u IQR = s n u ? s n l Min = s n l ? r * IQR, Max = s n u + r * IQR N ml = {(x i , x j )|y i = y j ? s n j &gt;=Min ?s n j &lt;=Max} Ensure:? ml Noise Negative Pair Filtering. According to our preliminary experiments, directly utilizing N ml produced by MLPG causes performance degradation and divergence of a loss because many noise-negative pairs cause a side-effect. We assumed that there are two types of noise pairs: too-easy and too-hard pairs. In the former case, FR models need not pay attention to the pairs but they do, owing to the size of the pairs. In the latter case, FR models cannot allow them because they exceed the representation power of the models. To address this problem, we developed noise-negative pair filtering using a box and whisker algorithm <ref type="bibr" target="#b30">[31]</ref> as follows:</p><p>As a result, UNPG adopting Algorithm 1 is defined as:</p><formula xml:id="formula_7">N uni i = N cl i ?? ml<label>(9)</label></formula><p>Geometrical Interpretation of Feature Space We interpret the role of UNPG by associating a feature space, as shown in <ref type="figure">Fig. 3</ref>. To form WDFS satisfying inf S p &gt; sup S n , a loss function should assign a large loss in the feature space with low discriminability, whereas it should assign a small loss, and vice versa. The unified loss function in Eq. 1 follows this intent but fails to form WDFS <ref type="figure">Figure 3</ref>: Geometrical interpretation of feature space associated with similarity space. (a) As ideal behavior of the loss function, it imposes a large loss in feature space with low discriminability. A shading area in the same color represents the target region of the same class. ? p max and ? n min are the respective angles of max positive and min negative pairs in the feature space. S p and S n represent similarity sets. (b) In spite of being equally low discriminative, a very small loss is given by vanilla loss (e.g., norm-softmax). w 1 and w 2 are the normalized weight vectors of classes 1 and 2, while x 1 and x 2 are the normalized feature vector.? p max and? n min represent the angle of max positive and min negative pairs in? p ? S p and S n ? S n , respectively. (c) Mismatch between S p and? p is reduced by using a marinal classification loss (e.g., ArcFace). However, still a small loss is given because of a mismatch between S n and? n . (d) Marginal classification loss with UNPG behaves closest to ideal by alleviating mismatch between S n and? n . because of the mismatch between similarity sets of the sampled pairs and all pairs. <ref type="figure">Fig. 3 (a)</ref> depicts the ideal behavior of a loss function that assigns a large loss in the feature space with low discriminability for inf S p sup S n . In contrast, in <ref type="figure">Fig. 3 (b)</ref>, a small loss is assigned in the feature space with low discriminability because sampled? p and? n are well-separated. This problem is alleviated using a similarity score with a margin, as shown in <ref type="figure">Fig. 3 (c)</ref>. This makes? p informative and worthy of training, as the interval of? p shifts to the left. <ref type="figure">Fig. 3 (d)</ref> shows the effect of UNPG. The interval of? n becomes wider as more negative pairs are included in? n . Consequently, a large loss is assigned, satisfying inf? p &gt; sup? n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Implementation Details</head><p>Datasets. For training, MS1M-V2 <ref type="bibr" target="#b3">[4]</ref> and K-FACE:T4 <ref type="bibr" target="#b10">[11]</ref> datasets were employed. MS1M-V2, a semi-automatically refined version of MS-Celeb-1M <ref type="bibr" target="#b4">[5]</ref>, has 5.8M images and 85K identities. K-FACE:T4 is a preprocessed version of K-FACE <ref type="bibr" target="#b1">[2]</ref> utilized in MixFace <ref type="bibr" target="#b10">[11]</ref> and has 3.8M images and   370 identities. For testing, several benchmark datasets (IJB-B <ref type="bibr" target="#b36">[37]</ref>, IJB-C <ref type="bibr" target="#b16">[17]</ref>, MegaFace <ref type="bibr" target="#b11">[12]</ref>, LFW <ref type="bibr" target="#b9">[10]</ref>, CFPFP <ref type="bibr" target="#b23">[24]</ref>, AgeDB-30 <ref type="bibr" target="#b18">[19]</ref>, CALFW <ref type="bibr" target="#b40">[41]</ref>, and K-FACE:Q1-Q4 <ref type="bibr" target="#b10">[11]</ref>) were used to evaluate FR models. <ref type="table" target="#tab_0">Table 1</ref> summarizes the datasets used in our experiments.</p><p>Training. For preprocessing, face images were resized to 112 ? 112 and normalized using the mean (0.485, 0.456, 0.406) and standard deviations (0.229, 0.224, 0.225). For data augmentation, a horizontal flip was applied with a 50% of chance. All experiments were performed using two NVIDIA-RTX A6000 GPUs with a mini-batch size of 512. ResNet-34 (R34) and ResNet-100 (R100) were used as backbone models. We re-implemented the state-of-the-art models: CosFace <ref type="bibr" target="#b33">[34]</ref>, ArcFace <ref type="bibr" target="#b3">[4]</ref>, and MagFace <ref type="bibr" target="#b17">[18]</ref>. The hyper-parameters used in our experiments were as follows: In ArcFace and CosFace, scale factor ? = 64 and margin m = 0.5 were set. In MagFace, ? = 64, l a = 10, u a = 110, l m = 0.4, l m = 0.8, ? g = 35 were used. For K-FACE, SN-pair <ref type="bibr" target="#b10">[11]</ref> and circle-loss <ref type="bibr" target="#b26">[27]</ref> employed ? = 64 and ? = 32, m = 0.25, respectively. In Mix-Face <ref type="bibr" target="#b10">[11]</ref>, = 1e ? 22 and m = 0.5 were set. In MSloss <ref type="bibr" target="#b34">[35]</ref>, ? = 2, ? = 0.5, ? = 50 were used. Triplet loss employed m = 0.5. In contrastive loss, positive and negative margins were set to 0 and 1, respectively. Finally, in UNPG, the wisker size r = 1.0 was used with ResNet-34, whereas r = 1.5 was used ResNet-100. The stochastic gradient descent (SGD) optimizer was utilized in conjunction with a cosine annealing scheduler <ref type="bibr" target="#b15">[16]</ref> to control the learning rate, which started from 0.1. The momentum, weight decay, and warm-up epochs were set to 0.9, 0.0005, and 3,  respectively. The maximum number of training epochs was set to 20 for all models, except that it was set to 25 with MagFace for a fair comparison. The size of the deep feature space extracted from the backbone model was set to 512. Test. Cosine similarity was used as a similarity score. Different evaluation metrics were applied depending on the FR tasks. In the verification task (1:1), verification accuracy using the best threshold was exploited for a dataset that has a small number of test images with the same ratio between positive and negative pairs, such as LFW, CFP-FP, AgeDB-30, CALFW, and CPLFW. Otherwise, TAR@FAR was used on IJB-B, IJB-C, and K-FACE. In the identification task (1:N) on MegaFace, rank-1accuracy was utilized.  <ref type="table" target="#tab_1">Table 2</ref>, all FR models with UNPG improved at every interval compared to those without UNPG. In particular, TAR@(FAR=1e-4), an interval widely used in FR improved consistently. For example, Mag+UNPG obtained gains of 1.22% and 0.84% in IJB-B and IJB-C, respectively, compared to MagFace, and gains of 0.7% and 0.41%, respectively, compared to MagFace*. Results on MegaFace. MegaFace consists of a gallery set of 1 M images with 690 K classes and probe photos of 100 K images with 530 classes. We followed the test protocol of ArcFace <ref type="bibr" target="#b3">[4]</ref>. We removed noisy images and measured rank- 1 accuracy for the 1 M distractor after following the identification scenarios using the devkit provided by MegaFace. <ref type="table" target="#tab_2">Table 3</ref> present the results of this study. FR models with UNPG performed better than those without it. ArcFace and CosFace using UNPG obtained gains of 0.26% and 0.19%, respectively, compared to those without it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Results</head><p>Results on LFW, CFP-FP, AgeDB-30, and CALFW. FR on LFW, CFP-FP, AgeDB-30, and CALFW is straightforward. Thus, the performance was saturated. LFW, AgeDB-30, and CALFW contain 6,000 images, and CFP-FP has 6,000 images. They have 1:1 ratios between the positive and negative pairs. Verification accuracy was employed with the best threshold separating the positive and negative pairs. In <ref type="table" target="#tab_3">Table 4</ref>, the FR models with UNPG obtained competitive performance on the four datasets.</p><p>Results on K-FACE. K-FACE focuses on FR under finegrained conditions. It consists of 4.3 M images with 6 accessories, 30 illuminations, 3 expressions, and 20 poses for 400 persons. We adopted the same training and test splits used in MixFace <ref type="bibr" target="#b40">[41]</ref>. The training split was composed of 3.8 M images with 370 persons. In particular, the test split, including the remaining 30 persons, was partitioned into Q1, Q2, Q3, and Q4. The number next to Q indicates the variance of conditions where it increases as more conditions are included. Q4 is the most challenging task, whereas Q1 is the most straightforward task among the four. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis</head><p>Does it sufficiently satisfy WDFS? We conclude that UNPG helps FR models to form WDFS by reducing the gap between? p and? n . As shown in <ref type="figure" target="#fig_1">Fig. 4</ref>, we measured the number of overlapping similarity scores between? p and S n using ArcFace, CosFace, and MagFace with and without UNPG after training with R100. We randomly sampled 256 positive pairs and 256 most hard negative pairs at each iteration from MS1M-V2. After 1000 iterations, we generated S p and? n , each with a total of 257,992, and calculated the overlap between them using a histogram. Obviously, applying UNPG reduced the gaps of 260 (ArcFace), 321 (Cos-Face), and 440 (MagFace) consistently. This proves the effect of UNPG, as expected. Effect of Noise-negative Pair Filtering. To approximate WDFS, N ml was assumed to include extremely hard negative pairs because it can produce similarity scores similar to sup S n . In <ref type="figure" target="#fig_2">Fig. 5 (a)</ref>, we observe that an FR model using N ml without filtering (+UNPG w/o filtering) at each iteration leads to performance degradation and the divergence of a loss on LFW, whereas it achieves better performance and convergence of a loss with filtering (+UNPG). Although FR models should adequately distinguish too-hard negative pairs ultimately, we argue that it causes adverse effects using a model lacking representation power to cover them. <ref type="figure" target="#fig_2">Fig. 5 (b)</ref> shows certain negative pairs, categorized as tooeasy, informative, and too-hard pairs, sampled from MS1M-V2, where the similarity scores are computed using ArcFace with UNPG. It is difficult to distinguish two hard pairs, even for humans, because they are very similar. However, tooeasy pairs are useless because they are already well separated. Consequently, it is reasonable to focus on the informative pairs in N ml . We can deal with too-hard pairs by enlarging the model capacity, as depicted in <ref type="figure" target="#fig_3">Fig. 6</ref>. We conducted experiments using ArcFace with different backbones, R34 and R100, on IJB-B, IJB-C and MegaFace for verification and identification. In R34, the highest performance was obtained at whisker size r = 1.0 on all datasets, whereas it was obtained at r = 1.5 in R100 with a gain of approximately 0.2%. This reveals that the informative range determined by whisker size r also increases as a model has a large representation power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper is based on two insights. First, from a unified perspective, CL and ML have the same purpose of approaching WDFS, except for PG. Second, CL and ML show a mismatch between two similarity distributions of sampled pairs and all negative pairs. Based on these insights, we developed UNPG by combining two PG strategies (MLPG and CLPG) to alleviate the mismatch. Filtering was also applied to remove negative pairs in both too-easy and toohard pairs. It was observed that UNPG increases the ability to learn existing FR models compared to MLPG and CLPG by providing more informative pairs. Finally, we suggest two research directions in FR: 1) pair generation strategies in the qualitative aspect and 2) loss functions considering the capability of representation power.</p><p>6 Acknowledgement</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Unified loss with UNPG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Comparison of overlapping similarities for positive and negative pairs with and without UNPG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Results on IJB-B and IJB-C. IJB-B consists of 21.8 K images of 1,845 subjects and 55 K frames of 7,011 videos. IJB-C, an extended version of IJB-B, contains 31.3 K images of 3,531 subjects and 117.5 K frames of 11,799 videos. 10 k / 8 M and 19 K / 15 M of positive / negative pairs in IJB-B and IJB-C were used for 1:1 verification. Owing to the severe imbalance between positive and negative pairs, performance was measured by TAR@FAR at different in-(a) Effects of noise negative pair filtering in UNPG with ResNet-34 (b) Examples of three negative pair types in ascending order of similarity scores. tervals such as [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]. As shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Effects of backbone capacity and whisker size on IJB-B (verification), IJB-C (verification), and MegaFace (identification).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>A brief overview of FR datasets. (P) and (G) refer to the probe set the gallery set on MegaFace, respectively.</figDesc><table><row><cell>Train</cell><cell># Identities</cell><cell># Images</cell></row><row><cell>MS1M-V2 [4]</cell><cell>85K</cell><cell>5.8M</cell></row><row><cell>K-FACE:T4 [2]</cell><cell>370</cell><cell>3.8M</cell></row><row><cell>Test</cell><cell># Identities</cell><cell># Images</cell></row><row><cell>IJB-B [37]</cell><cell>1,845</cell><cell>76.8K</cell></row><row><cell>IJB-C [17]</cell><cell>3,531</cell><cell>148.8K</cell></row><row><cell>MegaFace (P) [12]</cell><cell>530</cell><cell>100K</cell></row><row><cell>MegaFace (G) [12]</cell><cell>690K</cell><cell>1M</cell></row><row><cell>LFW [10]</cell><cell>5,749</cell><cell>13,233</cell></row><row><cell>CFPFP [24]</cell><cell>500</cell><cell>7,000</cell></row><row><cell>AgeDB-30 [19]</cell><cell>568</cell><cell>16,488</cell></row><row><cell>CALFW [41]</cell><cell>5,749</cell><cell>12,174</cell></row><row><cell>Test [2]</cell><cell># Pairs</cell><cell># Variance</cell></row><row><cell>K-FACE:Q1</cell><cell>1,000</cell><cell>Very Low</cell></row><row><cell>K-FACE:Q2</cell><cell>10K</cell><cell>Low</cell></row><row><cell>K-FACE:Q3</cell><cell>10K</cell><cell>Middle</cell></row><row><cell>K-FACE:Q4</cell><cell>10K</cell><cell>High</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Verification accuracy of TAR@FAR on IJB-B and IJB-C. "*" indicates results from the original paper. 90.93 95.21 96.50 97.63 90.01 94.70 96.38 97.51 98.32</figDesc><table><row><cell>Method</cell><cell>Backbone</cell><cell>1e-6</cell><cell cols="3">IJB-B(TAR@FAR) 1e-5 1e-4 1e-3</cell><cell>1e-2</cell><cell>1e-6</cell><cell cols="3">IJB-C(TAR@FAR) 1e-5 1e-4 1e-3</cell><cell>1e-2</cell></row><row><cell>VGGFace2* [1]</cell><cell>R50</cell><cell>-</cell><cell cols="2">67.10 80.00</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">74.70 84.00</cell><cell>-</cell><cell>-</cell></row><row><cell>Circle-loss* [27]</cell><cell>R34</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="3">86.78 93.44 96.04</cell><cell>-</cell></row><row><cell>Circle-loss* [27]</cell><cell>R100</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="3">89.60 93.95 96.29</cell><cell>-</cell></row><row><cell>ArcFace* [4]</cell><cell>R100</cell><cell>-</cell><cell>-</cell><cell>94.20</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>95.60</cell><cell>-</cell><cell>-</cell></row><row><cell>MagFace* [18]</cell><cell>R100</cell><cell cols="3">42.32 90.36 94.51</cell><cell>-</cell><cell>-</cell><cell cols="3">90.24 94.08 95.97</cell><cell>-</cell><cell>-</cell></row><row><cell>Triplet-loss</cell><cell>R34</cell><cell>4.42</cell><cell cols="4">12.57 32.65 61.33 88.78</cell><cell>4.04</cell><cell cols="4">15.32 36.86 66.46 90.77</cell></row><row><cell>contrastive-loss</cell><cell>R34</cell><cell cols="10">33.10 59.40 72.18 81.98 90.11 57.84 66.41 76.16 85.03 92.21</cell></row><row><cell>CosFace [34]</cell><cell>R34</cell><cell cols="10">39.70 87.47 93.55 95.71 97.05 85.95 92.57 95.23 96.81 97.94</cell></row><row><cell>Cos+UNPG</cell><cell>R34</cell><cell cols="10">43.33 87.51 93.58 95.96 97.24 87.84 92.49 95.33 96.94 98.06</cell></row><row><cell>ArcFace</cell><cell>R34</cell><cell cols="10">40.61 86.28 93.38 95.74 97.22 85.47 92.21 95.08 96.79 97.94</cell></row><row><cell>Arc+Triplet</cell><cell>R34</cell><cell cols="10">38.31 86.46 93.22 95.72 97.28 86.40 92.19 94.97 96.68 97.94</cell></row><row><cell>Arc+Contrastive</cell><cell>R34</cell><cell cols="10">38.07 86.54 93.03 95.61 97.33 85.21 92.54 94.86 96.60 98.01</cell></row><row><cell>Arc+UNPG</cell><cell>R34</cell><cell cols="10">40.27 88.05 93.66 95.96 97.17 87.99 93.02 95.33 96.88 97.92</cell></row><row><cell>CosFace</cell><cell>R100</cell><cell cols="10">42.27 89.38 94.39 96.17 97.35 86.56 94.42 96.35 97.57 98.26</cell></row><row><cell>Cos+UNPG</cell><cell>R100</cell><cell cols="10">49.13 90.61 94.99 96.50 97.36 86.95 94.48 96.39 97.57 98.24</cell></row><row><cell>ArcFace</cell><cell>R100</cell><cell cols="10">40.68 89.99 94.89 96.40 97.59 86.57 93.93 96.25 97.43 98.31</cell></row><row><cell>Arc+UNPG</cell><cell>R100</cell><cell cols="10">44.03 90.57 95.04 96.60 97.70 88.06 94.47 96.33 97.53 98.39</cell></row><row><cell>MagFace</cell><cell>R100</cell><cell cols="10">43.71 89.03 93.99 96.11 97.32 87.19 93.30 95.54 97.00 98.05</cell></row><row><cell>Mag+UNPG</cell><cell>R100</cell><cell>46.33</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Identification results on MegaFace datasets withResNet-100 backbone except for AdaCos. "*" indicates the results from the original paper.</figDesc><table><row><cell>Method</cell><cell>Rank-1 accuracy (%)</cell></row><row><cell>AdaCos* [40]</cell><cell>97.41</cell></row><row><cell>ArcFace*</cell><cell>98.35</cell></row><row><cell>Circle-loss*</cell><cell>98.50</cell></row><row><cell>MagFace</cell><cell>98.51</cell></row><row><cell>Mag+UNPG</cell><cell>98.03</cell></row><row><cell>ArcFace</cell><cell>98.56</cell></row><row><cell>Arc+UNPG</cell><cell>98.82</cell></row><row><cell>CosFace</cell><cell>99.08</cell></row><row><cell>Cos+UNPG</cell><cell>99.27</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Verification accuracy on LFW, CFP-FP, AgeDB-30, and CALFW with ResNet-100 backbone.</figDesc><table><row><cell>Method</cell><cell cols="4">LFW CFP-FP AgeDB CALFW</cell></row><row><cell cols="2">Circle-loss* 99.73</cell><cell>96.02</cell><cell>-</cell><cell>-</cell></row><row><cell>ArcFace*</cell><cell>99.82</cell><cell>-</cell><cell>-</cell><cell>95.45</cell></row><row><cell>MagFace*</cell><cell>99.83</cell><cell>98.46</cell><cell>98.17</cell><cell>96.15</cell></row><row><cell>CosFace</cell><cell>99.83</cell><cell>97.72</cell><cell>98.11</cell><cell>96.11</cell></row><row><cell cols="2">Cos+UNPG 99.81</cell><cell>98.50</cell><cell>98.31</cell><cell>96.15</cell></row><row><cell>ArcFace</cell><cell>99.83</cell><cell>98.60</cell><cell>98.23</cell><cell>96.11</cell></row><row><cell>Arc+UNPG</cell><cell>99.83</cell><cell>98.60</cell><cell>98.25</cell><cell>96.13</cell></row><row><cell>MagFace</cell><cell>99.81</cell><cell>98.62</cell><cell>98.30</cell><cell>96.15</cell></row><row><cell cols="2">Mag+UNPG 99.81</cell><cell>98.52</cell><cell>98.38</cell><cell>96.21</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Verification accuracy of TAR@FAR on K-FACE with ResNet-34 backbone.</figDesc><table><row><cell>Method</cell><cell cols="3">Q4(TAR@FAR) 1e-5 1e-4 1e-3</cell><cell cols="3">Q3(TAR@FAR) 1e-5 1e-4 1e-3</cell><cell cols="2">Q2(TAR@FAR) 1e-5 1e-4 1e-3</cell><cell cols="3">Q1(TAR@FAR) 1e-3 1e-2 1e-1</cell></row><row><cell>ArcFace</cell><cell>0.05</cell><cell>0.29</cell><cell>4.04</cell><cell>2.06</cell><cell>4.40</cell><cell cols="4">18.27 26.56 41.29 63.91 94.00</cell><cell>100</cell><cell>100</cell></row><row><cell>AdaCos</cell><cell>0.28</cell><cell>2.57</cell><cell>16.68</cell><cell>4.11</cell><cell>9.94</cell><cell>34.57</cell><cell>7.16</cell><cell cols="2">26.31 66.88 94.00</cell><cell>100</cell><cell>100</cell></row><row><cell>SN-pair [11]</cell><cell>3.50</cell><cell>7.21</cell><cell cols="9">17.45 17.67 21.16 30.85 21.93 33.26 55.92 91.80 97.60 100</cell></row><row><cell>MS-loss [35]</cell><cell>5.68</cell><cell>8.70</cell><cell cols="9">25.01 15.15 18.74 38.36 38.33 46.64 66.63 94.60 99.20 100</cell></row><row><cell>MixFace [11]</cell><cell>7.11</cell><cell cols="2">10.92 19.92</cell><cell>9.19</cell><cell cols="5">22.55 37.67 39.09 44.48 67.44 97.00</cell><cell>100</cell><cell>100</cell></row><row><cell cols="9">Circle-loss [27] 18.08 25.05 43.46 33.56 41.54 64.88 71.38 77.93 89.97</cell><cell>100</cell><cell>100</cell><cell>100</cell></row><row><cell>Arc+UNPG</cell><cell cols="8">29.89 50.43 64.05 51.59 60.88 78.68 91.28 93.26 95.68</cell><cell>100</cell><cell>100</cell><cell>100</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc>presents the results of the FR models. Surprisingly, ArcFace with UNPG outperformed the other FR models on Q1, Q2, Q3, and Q4. Specifically, it obtained gains of 25.38%, 19.34%, and 15.33% in TAR@(FAR=1e-4) compared to the circle loss.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Vggface2: A dataset for recognising faces across pose and age</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th IEEE international conference on automatic face &amp; gesture recognition (FG 2018)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">K-face: A large-scale kist face database in consideration with unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I.-J</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.02211</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Arcface: Additive angular margin loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4690" to="4699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Msceleb-1m: A dataset and benchmark for large-scale face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="87" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep metric learning using triplet network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ailon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International workshop on similarity-based pattern recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Labeled faces in the wild: A database forstudying face recognition in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mattar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on faces in&apos;Real-Life&apos;Images: detection, alignment, and recognition</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-S</forename><surname>Oh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.01717</idno>
		<title level="m">Mixface: Improving face verification focusing on finegrained conditions</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The megaface benchmark: 1 million faces for recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4873" to="4882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sphereface: Deep hypersphere embedding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="212" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Large-margin softmax loss for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICML</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<title level="m">Sgdr: Stochastic gradient descent with warm restarts</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Iarpa janus benchmark-c: Face dataset and protocol</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Niggel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 International Conference on Biometrics</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="158" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Magface: A universal representation for face recognition and quality assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="14225" to="14234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Agedb: the first manually collected, in-the-wild age database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moschoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Papaioannou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kotsia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPRW</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="51" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4004" to="4012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="41" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">L2-constrained softmax loss for discriminative face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.09507</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Frontal to profile face verification in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Winter Conference on Applications of Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Improved deep metric learning with multiclass n-pair loss objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1857" to="1865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Circle loss: A unified perspective of pair similarity optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6398" to="6407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deeply learned face representations are sparse, selective, and robust</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2892" to="2900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deepface: Closing the gap to human-level performance in face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1701" to="1708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Exploratory data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="volume">2</biblScope>
			<pubPlace>Reading, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Additive margin softmax for face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Sign. Process. Letters</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="926" to="930" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Normface: L2 hypersphere embedding for face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1041" to="1049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Cosface: Large margin cosine loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5265" to="5274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-similarity loss with general pair weighting for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5022" to="5030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="499" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Iarpa janus benchmark-b face dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Whitelam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Taborsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blanton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPRW</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="90" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.7923</idno>
		<title level="m">Learning face representation from scratch</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep metric learning with tuplet margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6490" to="6499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Adacos: Adaptively scaling cosine logits for effectively learning deep face representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10823" to="10832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Cross-age lfw: A database for studying cross-age face recognition in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.08197</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
